{"cells":[{"metadata":{"_uuid":"f9ba17be566d326c191fb75542574d92360d4885"},"cell_type":"markdown","source":"# Collaborative Filtering\n\nThis is notebook is my follow along for lesson 5 of the Fast.ai course part 1. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai.learner import *\nfrom fastai.column_data import *\nfrom sklearn.decomposition import PCA\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"path='../input/'\ntmp_path='/kaggle/working/tmp/'\nmodels_path='/kaggle/working/models/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b7e4284c4bce2cf5addc9f3855ceb78e50200d4"},"cell_type":"markdown","source":"Lets load our dataset:"},{"metadata":{"trusted":true,"_uuid":"2d44e3966dcd00a1813ec77f9e2af3632b413906"},"cell_type":"code","source":"ratings = pd.read_csv(path+'ratings.csv')\nratings.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76161b4f8812f5d8f29650ea8026ec3c9be15744"},"cell_type":"code","source":"movies = pd.read_csv(path+'movies.csv')\nmovies.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2fd6ea74b431d829020879485a105d3f718411b"},"cell_type":"markdown","source":"# Lets jump into it\n\nCollaborative filtering"},{"metadata":{"trusted":true,"_uuid":"3ef3250e639431a361ffb151eb0a5af8bde61b8c"},"cell_type":"code","source":"val_idxs = get_cv_idxs(len(ratings))\nwd=2e-4\nn_factors = 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52b025d2108c85ff5cfc1ebca491ace564c1c78e"},"cell_type":"code","source":"cf = CollabFilterDataset.from_csv(path, 'ratings.csv', 'userId', 'movieId', 'rating')\nlearn = cf.get_learner(n_factors, val_idxs, 64, opt_fn=optim.Adam, tmp_name=tmp_path, models_name=models_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a54f7fe7ddfb1dc0175cded26f42e332e6399325"},"cell_type":"code","source":"learn.fit(1e-2,2,wds=wd,cycle_len=1,cycle_mult=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59cec42da58dc00d8c7890bccc7666c23d6d2d47"},"cell_type":"markdown","source":"Some other benchmarks use RMSE as their metric:"},{"metadata":{"trusted":true,"_uuid":"151ed61981f4360aaf0d1f07cfb5c0387446eccb"},"cell_type":"code","source":"math.sqrt(0.765)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b14dfb0e58d4d57222d0b693789f146fe5109909"},"cell_type":"markdown","source":"We are able to grab our predictions which enable us to visualize them. "},{"metadata":{"trusted":true,"_uuid":"6dabe3794ac848ccb88cd87130565dba901a21dc"},"cell_type":"code","source":"preds = learn.predict()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd9c8e4d7d44d3eabdf133b943858dacbdbaf351"},"cell_type":"markdown","source":"    \n   The  `preds`  are our predictions while our actuals is `y`. What we notice is that when we predict high values such as 3.5 it gets up to 4. Meaning it is predicting well. A histogram is located top of the plot while a bar plot is on the right of the plot. "},{"metadata":{"trusted":true,"_uuid":"5b5464c6ab6b9d43802a68d4b4a1e1a151f06f26"},"cell_type":"code","source":"y=learn.data.val_y\nsns.jointplot(preds, y, kind='hex', stat_func=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a60993f8760c1301dcb4ca8950e73cea90a7ab0e"},"cell_type":"markdown","source":"# Results Anaysis\n\n#### Movie Bias"},{"metadata":{"_uuid":"a0525c6aa24af6e0af7be81e938d02c8c4c6a4a6"},"cell_type":"markdown","source":"Below we grab the titles of all movies and store it in a dictonary. Then we proceed to grab the total ratings for each movie.  Eg: Movie => ({The Mummy Returns})  Ratings => ({25})\n\n`['The Mummy Returns','25'] = Movie, Ratings`\n\nThen we create  `topMovies` by sorting them and proceed to create a numpy array of indices. "},{"metadata":{"trusted":true,"_uuid":"7fd97f2debd02234da014afbfff00a67078b6b05"},"cell_type":"code","source":"movie_names = movies.set_index('movieId')['title'].to_dict()\ng=ratings.groupby('movieId')['rating'].count()\ntopMovies=g.sort_values(ascending=False).index.values[:3000]\ntopMovieIdx = np.array([cf.item2idx[o] for o in topMovies])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7791a2b62b04b2cb1704dc23b08475498acb656"},"cell_type":"markdown","source":"`movie_names` is a series. Will need to provide a detailed explantion of what you can do with it."},{"metadata":{"trusted":true,"_uuid":"b46e564a1bf79068aa4c6a1113008178633afdca"},"cell_type":"code","source":"print(movie_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5f7369b3f40cf76ae7245f82fd7283a902235ed"},"cell_type":"code","source":"movie_names.items","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f614a5f271b549e5701e7537e50ceefd0aed23e7"},"cell_type":"markdown","source":"`g` is a series. Will need to provide a detailed explantion of what you can do with it."},{"metadata":{"trusted":true,"_uuid":"968c932172e7a24dfd3c26a41a8f6444600d521b"},"cell_type":"code","source":"print(g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc07404753f90a1e8b1df999339039dcb579bbb3"},"cell_type":"code","source":"learn.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4238fc504aeb4db5119e6348c3578bf19843801a"},"cell_type":"markdown","source":"`ib` - movie bias embedding\nWhat are the the other embeddings : `u`, `i`, `ub` ?"},{"metadata":{"trusted":true,"_uuid":"7ddd3e2d656de21f72e045b256bd96ea46d8d25b"},"cell_type":"code","source":"m=learn.model; m.cuda()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57416b96039042eaedbb61cbf6b73e9e9368cde4"},"cell_type":"markdown","source":"Attempt to look at the movie bias term. It has the input of the movie it and the output is the movie bisa."},{"metadata":{"trusted":true,"_uuid":"5570b13968ff74117e9334a96c14982b86a2e505"},"cell_type":"code","source":"movie_bias = to_np(m.ib(V(topMovieIdx)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe89fd3a96d98e8c3067118c87769d79b30d2e77"},"cell_type":"code","source":"movie_bias","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de8f8601c818da086f46b7cafbaaa5ef5bfdc657"},"cell_type":"markdown","source":"We use the movie names to loop over the zip of the `topMovies` and the `movie_bias`"},{"metadata":{"trusted":true,"_uuid":"6a29856d357437c00c54411327104005207b9356"},"cell_type":"code","source":"movie_ratings = [(b[0],movie_names[i]) for i,b in zip(topMovies, movie_bias) ]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10b528cfb9f2b6b968e7175de9e0bbf82d28ac1d"},"cell_type":"markdown","source":"Via a lambda function we sort the ratings and display the first 15. `movie_ratings` is a tuple, because we used the movie names to loop over the top movies and their associated id. And also mapped them using the biases. "},{"metadata":{"trusted":true,"_uuid":"5740653364ee1f12015549d455d0caca0c0b9f73"},"cell_type":"code","source":"sorted(movie_ratings, key=lambda o:  o[0])[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34ee9dcc43dba19601d68b2e92e8f97eb66dd530"},"cell_type":"code","source":"sorted(movie_ratings, key=itemgetter(0))[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87521e49b7ca01a6efbf6ce97b541815a27efc40"},"cell_type":"code","source":"sorted(movie_ratings, key=lambda o:  o[0],reverse=True)[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f312562b6b9d75fb3d3716b15ba8c068669d4d0"},"cell_type":"code","source":"len(sorted(movie_ratings, key=lambda o:  o[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7535dffa6855a4f90d7be2292b04daf405015d4d"},"cell_type":"markdown","source":"We are also able to interpert embeddings:"},{"metadata":{"trusted":true,"_uuid":"cad120c1a3b75a556f5850f2884fc1ed4007bb78"},"cell_type":"code","source":"movie_emb = to_np(m.i(V(topMovieIdx)))\nmovie_emb.shape             ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d812971b8d69c65426e789c61b7d8ed5c88d1baa"},"cell_type":"markdown","source":"# Principle Component Analysis (PCA)\n\nPCA is used identitfy patterns in data by detecting the correlation between variables. PCA projects the entire dataset into a subspace, which is done by reducing the dimensions of d-dimensional dataset to project it onto k-dimensional subspace to increase computational efficiency to retain msot of the information. \n\nWe will decompose the 50 embeddings into 3 vectors using PCA:\n\n\n"},{"metadata":{"trusted":true,"_uuid":"062c8262adae4527c9c2d50346121ee03f83ea54"},"cell_type":"code","source":"pca = PCA(n_components=3)\nmovie_pca = pca.fit(movie_emb.T).components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9edeca46844b8e4842bf54c91a94a6fb875f784c"},"cell_type":"code","source":"movie_pca.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9737b97b65a5203a4b2e928e20e2e9b22597330f"},"cell_type":"code","source":"fac0 = movie_pca[0]\nmovie_comp = [(f, movie_names[i]) for f,i in zip(fac0, topMovies)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33fa87a104072e4f443c3180b4ca08ea1d375de8"},"cell_type":"markdown","source":"Our first component: "},{"metadata":{"trusted":true,"_uuid":"64d8f5798240905f36a24f7605afe4cd68a5d9de"},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1d4a50ca984ca6e2f2dc9f25208d697d75774d5"},"cell_type":"markdown","source":"Serious movies"},{"metadata":{"trusted":true,"_uuid":"764a357547556366a531485bec175a1d6158aa6b"},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0))[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3aa1d8df2de6f30d05b6e94ed060cabce426de35"},"cell_type":"markdown","source":"So easy going films.\n\nLets grab our next component:"},{"metadata":{"trusted":true,"_uuid":"0c84aeba688be310d20b9168a2f2c8e7ded8f519"},"cell_type":"code","source":"fac1 = movie_pca[1]\nmovie_comp = [(f, movie_names[i]) for f,i in zip(fac1, topMovies)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d86cc7c0010709e86fac6df1fe4316545a997d50"},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c09c1514a1bceced318dd4b622e51d0e269db112"},"cell_type":"markdown","source":"CGI Films"},{"metadata":{"trusted":true,"_uuid":"b508483dc5e1d6ceffbab4838fb54d60fbb792c8"},"cell_type":"code","source":"sorted(movie_comp, key=itemgetter(0))[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d2afcd7dea2664ff1cf8326d8825b83c48c48c1"},"cell_type":"markdown","source":"We can put a plot together to see how various films appear on the map of the components:"},{"metadata":{"trusted":true,"_uuid":"e8af7cd243d46a8f0155fb5a6d7350fa5a2c61d6"},"cell_type":"code","source":"idxs = np.random.choice(len(topMovies), 50, replace=False)\nX = fac0[idxs]\nY = fac1[idxs]\nplt.figure(figsize=(15,15))\nplt.scatter(X,Y)\nfor i, x, y in zip(topMovies[idxs], X, Y):\n    plt.text(x,y,movie_names[i], color=np.random.rand(3)*0.7, fontsize=11)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80fb403567c3f3a3c61a6b02febf4bc41ea06a07"},"cell_type":"markdown","source":"# Collaborative filtering from scratch\n\n### Dot product example"},{"metadata":{"_uuid":"cb67c3d5048574bbf189351e22dcc75148a7d2b9"},"cell_type":"markdown","source":"Here we simply declear our tensors of n-dimesonal matrices"},{"metadata":{"trusted":true,"_uuid":"e0119cc2b1439d1a6f2ec5a66fb91fddc85f4791"},"cell_type":"code","source":"a = T([[1,2],[3,4]])\nb = T([[2,2],[10,10]])\na,b","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b81fdeab7bda85b180f64bc195da92f435ce1d2"},"cell_type":"markdown","source":"Then we apply some element-wise multiplcation:"},{"metadata":{"trusted":true,"_uuid":"5e550bed25355b2abdc0b02f3f717107d767ca50"},"cell_type":"code","source":"a*b","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6287c9e8c852583c16a834b15ae8183c0cb3c97"},"cell_type":"markdown","source":"Here we do element-wise multplication but sum across all the columns, which helds a tensor dot product. "},{"metadata":{"trusted":true,"_uuid":"cbbb72b0fea769cff798579003c3a3a7b2c2c3f8"},"cell_type":"code","source":"(a*b).sum(1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d02a28dd7d9727e069366cd053eb3447efc056a"},"cell_type":"markdown","source":"Here we are going to build our own NN to process inputs and compute activations. The PyTorch module is derived from `nn.Module` which will contain a function called `forward` to compute the forward pass. "},{"metadata":{"trusted":true,"_uuid":"0f0e338d3ac45395f139d5a4bb1d38a276e52308"},"cell_type":"code","source":"class DotProduct(nn.Module):\n    def forward(self, u, m): return (u*m).sum(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a0933d7122e546c8967a9ed1bed63f71a8011c4"},"cell_type":"code","source":"model=DotProduct()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2ad2fa9799f1ae3d233a692dda7d8ccf9d74ca6"},"cell_type":"markdown","source":"This will call the forward function"},{"metadata":{"trusted":true,"_uuid":"2404e2163bcee7fc4715858f2457cb89cda7c8d6"},"cell_type":"code","source":"model(a,b)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37acf604ffff4639301b4bf1636085a357668265"},"cell_type":"markdown","source":"We need to fix some of the data to make it sequential and contiguous IDs. We do thatr getting the unique user IDs, then grab a list of sequential IDs using enumerate, then map the userIds in ratings using the `user_to_index`"},{"metadata":{"trusted":true,"_uuid":"8eb113308add3d2e3a4da74a58179c426a59c944"},"cell_type":"code","source":"unique_users = ratings.userId.unique()\nuser_to_index= {o:i for i,o in enumerate(unique_users)}\nratings.userId = ratings.userId.apply(lambda x: user_to_index[x])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de5b13d84ad8af4e3a1e1a63db56219d8e799f0d"},"cell_type":"code","source":"unique_movies = ratings.movieId.unique()\nmovie_to_index = {o:i for i,o in enumerate(unique_movies)}\nratings.movieId = ratings.movieId.apply(lambda x:movie_to_index[x] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dece813ebd4e761320838ac677163e2c9023430a"},"cell_type":"code","source":"n_users=int(ratings.userId.nunique())\nn_movies=int(ratings.movieId.nunique())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b54ce4eeebbca10f163c4c9c2fff5039c925d1a"},"cell_type":"markdown","source":"# Creating the module"},{"metadata":{"_uuid":"c3f96cc61cb4511cd53ac13fd384396d5e89b7cf"},"cell_type":"markdown","source":"We will create a module that looks up the factors for the users and movies from the embedding matrix and then take the dot product. \n\nin `EmbeddingDot` we create embedding matrices for users and movies, then they are initialized. With the forward pass we take categorical and contiuous variables."},{"metadata":{"trusted":true,"_uuid":"56a606876467cd5cc8a492644e0c9fdd6a22073e"},"cell_type":"code","source":"class EmbeddingDot(nn.Module):\n    def __init__(self, n_users, n_movies):\n        super().__init__()\n        self.u = nn.Embedding(n_users, n_factors)\n        self.m = nn.Embedding(n_movies, n_factors)\n        self.u.weight.data.uniform_(0,0.05)\n        self.m.weight.data.uniform_(0,0.05)\n        \n    def forward(self, cats, const):\n        users,movies = cats[:,0],cats[:,1]\n        u,m = self.u(users),self.m(movies)\n        return (u*m).sum(1).view(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8cdd197b767a07b29e23157f8d2273828ac6ba5"},"cell_type":"markdown","source":"We set up our crosstabe where `x` is everything besides the rating and timestamp, while `y` is the rating. "},{"metadata":{"trusted":true,"_uuid":"c17fa336b308da750858810cba5fac40dea4f925"},"cell_type":"code","source":"x = ratings.drop(['rating','timestamp'],axis=1)\ny =ratings['rating'].astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0ac62ddf090c40fde76b0941dc216562c0f4e9d"},"cell_type":"markdown","source":"We set up a Fast.ai data loader. "},{"metadata":{"trusted":true,"_uuid":"774af31471b931998a788c9422d33af93bb649fe"},"cell_type":"code","source":"data = ColumnarModelData.from_data_frame(path, val_idxs, x, y,['userId', 'movieId'], 64)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba7989d7ce1355f45619ae111ce50d9f173af828"},"cell_type":"markdown","source":"Then we initialize a optimization function."},{"metadata":{"trusted":true,"_uuid":"4bc75c1f55fb5e37012d875f60ba937387a1f26c"},"cell_type":"code","source":"wd=1e-5\nmodel = EmbeddingDot(n_users, n_movies).cuda()\nopt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd,momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfcf0a0379d4c430099bfe095087b633602e0705"},"cell_type":"markdown","source":"`fit()` calls the PyTorch training Loop. "},{"metadata":{"trusted":true,"_uuid":"80530d23b803f83dce60035590a283a0c51d1abd"},"cell_type":"code","source":"fit(model,data, 3, opt, F.mse_loss)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faae250404324a2146bf98860647d2c98e9fbf35"},"cell_type":"markdown","source":"Since our loss is still high, we will do learning rate annealing."},{"metadata":{"trusted":true,"_uuid":"68fed450b74ba2cff90c84a5d55a1be4ab29c836"},"cell_type":"code","source":"set_lrs(opt, 0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80ab3716945b0710e7ef4dcb092d19f3ea13eb27"},"cell_type":"code","source":"fit(model,data, 3, opt, F.mse_loss)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70d2b951c6f1b63c426bd428161a289c2f04c84d"},"cell_type":"markdown","source":"# Bias\n\nWe need bias for cases where a user gives low scores to movies. \nWe will need to create a new model that takes the bias into account, however, it will differ in that that it uses a convience method to make embeddings and normalizes scores returns from the forward pass.  "},{"metadata":{"trusted":true,"_uuid":"c1b4def73ef1a6dca77890f07a6904bd7252b471"},"cell_type":"code","source":"min_rating, max_rating =ratings.rating.min(), ratings.rating.max()\nmin_rating, max_rating","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"469f6f21bdbdc56c1e8ae1e907d02a9a3aed2877"},"cell_type":"markdown","source":"What is going on here? \n\n1. We are getting the number of rows and factors from the rows and columns in the embedding matrix\n2. The embedding matrices and bias vectors are initialized.\n3.  We apply a dot product, add our bias vectors and normilize the results"},{"metadata":{"trusted":true,"_uuid":"155178027e25ebbebfc208e85f9963fc4e40096b"},"cell_type":"code","source":"# 1\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni, nf)\n    e.weight.data.uniform_(-0.01,0.01)\n    return e\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self, n_users, n_movies):\n        super().__init__()\n        # 2\n        (self.u, self.m, self.ub, self.mb) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_movies, n_factors), (n_users,1),(n_movies,1)\n        ]]\n        \n        # 3\n    def forward(self, cats, conts):\n        users,movies = cats[:,0],cats[:,1]\n        um = (self.u(users)*self.m(movies)).sum(1)\n        res = um + self.ub(users).squeeze() + self.mb(movies).squeeze()\n        res = F.sigmoid(res) * (max_rating-min_rating) + min_rating\n        return res.view(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3edc5ad2b27f31f66bfddfbb9c7747a1c05fa0b"},"cell_type":"code","source":"wd=2e-4\nmodel = EmbeddingDotBias(cf.n_users, cf.n_items).cuda()\nopt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5a18229c856bfb9398c2d35664c1c4c53242a24"},"cell_type":"code","source":"fit(model, data, 3, opt, F.mse_loss)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e750e63406397862b92a1775292d8bf48744f4f"},"cell_type":"markdown","source":"## Mini Neural Net\n\nWe are going to take the embedding values of the users and movies and feed them into a linear layer. "},{"metadata":{"trusted":true,"_uuid":"1387a47a931834406191b8caba711ec9a210600f"},"cell_type":"code","source":"class EmbeddingNet(nn.Module):\n    def __init__(self, n_users, n_movies, nh=10, p1=0.05,p2=0.5):\n        super().__init__()\n        (self.u, self.m) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_movies, n_factors)\n        ]]\n        self.lin1 = nn.Linear(n_factors*2, nh)\n        self.lin2 = nn.Linear(nh,1)\n        self.drop1 = nn.Dropout(p1)\n        self.drop2 = nn.Dropout(p2)\n        \n    def forward(self, cats, conts):\n        users,movies = cats[:,0],cats[:,1]\n        x = self.drop1(torch.cat([self.u(users), self.m(movies)], dim=1))\n        x = self.drop2(F.relu(self.lin1(x)))\n        return F.sigmoid(self.lin2(x)) * (max_rating-min_rating+1) + min_rating-0.5\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a8c5215dc29256d9c3425edce21d5799e3ec936"},"cell_type":"code","source":"wd=1e-5\nmodel = EmbeddingNet(n_users, n_movies).cuda()\nopt = optim.Adam(model.parameters(), 1e-3, weight_decay=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f46a9585edd13121f27e0ea9c49299aa7b88452d"},"cell_type":"code","source":"fit(model, data, 3, opt, F.mse_loss)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}