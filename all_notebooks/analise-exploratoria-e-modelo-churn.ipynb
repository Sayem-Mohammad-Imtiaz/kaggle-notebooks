{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling as pp\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import plot_confusion_matrix, roc_curve, auc, confusion_matrix, plot_roc_curve, accuracy_score\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nraw_data = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\nprint(raw_data.dtypes)\npd.set_option('display.max_columns', None)\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Existem apenas 3 variáveis numéricas (SeniorCitizen, tenure e MonthlyCharges) e muitas variáveis categóricas. Aparentemente não tem NaN ou missing data. Quero primeiro ver se existe alguma relação clara entre alguma variável e churn e depois tentar visualizar a combinação de algumas variáveis e o churn. Também vou procurar por outliers e ver a distribuição das duas variáveis numéricas."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', \n        'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n        'Contract', 'PaperlessBilling', 'PaymentMethod']\n\nplt.subplots(4, 4, sharex=True, sharey=True, figsize=(15,15))\ni = 1\nfor column in cols:\n    plt.subplot(4, 4, i)\n    plt.title(column)\n    raw_data[column].value_counts(normalize=True).sort_values().plot(kind = 'barh', fontsize=9, sharex=False)\n    i = i + 1\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Perfil do Cliente \n\n*  Os produtos extras (além da linha de telefone e internet) mais consumidos parecem ser Streaming TV e Streaming Movies, com aproximadamente 40% do total dos clientes.\n*  Os outros produtos, Backup Online e Device PRotection, menos de 40% dos clientes usam e Tech Support menos de 30%.\n*  A maioria dos contratos (mais de 50%) são mês a mes e mais de 60% paperless\n*  O método de pagamento mais usado é eletronick check. Os outros 3 métodos restantes são similares (20% cada)\n* Das variáveis sociais, apenas dependentes me chamou a atenção. Mais de 60% não possuem, embora quase 50% possuam conjuge, então talvez não valha a pena pensar em produtos pra família ou crianças."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', \n        'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n        'Contract', 'PaperlessBilling', 'PaymentMethod']\n\nplt.subplots(4, 4, sharex=True, sharey=True, figsize=(15,15))\ni = 1\nfor column in cols:\n    plt.subplot(4, 4, i)\n    plt.title(column)\n    raw_data[ raw_data['Churn'] == 'Yes'][column].value_counts(normalize=True).sort_values().plot(kind = 'barh', fontsize=9)\n    i = i + 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Perfil dos Clientes onde Churn = Yes\n\n*   O percentual dos clientes com contrato de dois anos ou um ano que dão churn é menor que o percentual total de clientes com esses contratos. Talvez esse modo de contrato tenha alguma multa ou alguma vantagem para o cliente permanecer com o produto.\n*    A maioria dos clientes não possuem serviços extras como Streaming. Talvez clientes que compram o streaming veja mais valor no produto e decidam permanecer ou quem desiste são pessoas que tem um plano de serviços muito básico e mesmo assim não conseguem pagar.\n*    80% não possuem tech support, talvez eles não consigam resolver problemas e decidem encerrar a conta. Uma sugestão pra tentar reduzir o churn é fornecer algum nível de suporte técnico gratuito.\n*    Em relação as variáveis sociais: a) a proporção de senior que dá churn é maior que a proporção de seniors clientes b) a proporção de clientes sem conjuge é maior também e c) a proporção de clientes sem dependentes tbm é maior. Então talvez valha a pena fazer produtos pra família pra tentar reduzir o churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', \n        'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n        'Contract', 'PaperlessBilling', 'PaymentMethod']\n\nfig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(15,15))\n#fig.subplots_adjust(left = 0.4)\ni = 1\nfor column in cols:\n    plt.subplot(4, 4, i)\n    plt.title(column)\n    raw_data[ raw_data['Churn'] == 'No'][column].value_counts(normalize=True).sort_values().plot(kind = 'barh', fontsize=9, sharex=True)\n\n    i = i + 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Perfil Churn = No\n\nEsse perfil é complementar ao anterior e eu só fiz por motivos de completude. Note como contratos do tipo two year and one year aparecem em uma proporção maior entre os que não dão churn.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = sns.jointplot(x=\"tenure\", y=\"MonthlyCharges\", data=raw_data[raw_data['Churn']=='Yes'], kind=\"kde\", height=5)\nplt.title('Churn Yes')\nb = sns.jointplot(x=\"tenure\", y=\"MonthlyCharges\", data=raw_data[raw_data['Churn']=='No'], kind=\"kde\", height=5)\nplt.title('Churn No')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variáveis númericas e Churn\n\nOs dois gráficos acima mostram:\n*    O churn alto ocorre em mensalidades elevadas e em pouco tempo.\n*    Os clientes que não dão churn estão em mensalidades baratas. Note que a distribuição de churn = no para o preço parece ser bimodal. Provavelmente porque essa faixa de preço consegue fidelizar clientes e talvez essa variável seja algo como: se tenure > 70 tenure = 70\n*    Existem alguns clientes que fidelizaram mesmo pagando muito, acho que vale a pena ver o perfil desses clientes."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', \n        'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n        'Contract', 'PaperlessBilling', 'PaymentMethod']\n\nfig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(15,15))\n#fig.subplots_adjust(left = 0.4)\ni = 1\nfor column in cols:\n    plt.subplot(4, 4, i)\n    plt.title(column)\n    raw_data[ (raw_data['Churn'] == 'No') & (raw_data['tenure'] > 40) & (raw_data['MonthlyCharges'] > 60)  ][column].value_counts(normalize=True).sort_values().plot(kind = 'barh', fontsize=9, sharex=True)\n\n    i = i + 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Perfil dos clientes fidelizados\n\n*     Os clientes fidelizados (com tenure > 40) e MonthlyCharge > 60 compram todos os produtos, pagam com métodos automáticos, possuem múltiplas linhas, dependentes e conjuge."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_embedded = TSNE(n_components=2).fit_transform(pd.get_dummies(raw_data.loc[:, raw_data.columns != 'Churn']))\ntsne_df = pd.DataFrame(data=X_embedded, columns=[\"X\", \"Y\"])\ntsne_df['Churn'] = raw_data['Churn']\nsns.scatterplot(data=tsne_df, x=\"X\", y=\"Y\", hue=\"Churn\", Alpha = 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Projeção dos dados\n\nO gráfico acima mostra os dados dos clientes projetados em um plano onde a cor informa o padrão de churn. Podemos ver que existem agrupamentos de clientes onde acontece mais churn e agrupamentos com menos churn, então é provavel que os métodos de aprendizagem de máquina sejam capazes de encontrar um hiperplano que separe as duas classes."},{"metadata":{},"cell_type":"markdown","source":"# Modelagem\n\nVou testar diversos modelos e como temos um problema de classificação binário vou usar a matriz de confusão como métrica para discussão do ajuste do modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"# tem duas variáveis numericas que podemos criar categorias: tenure e MonthlyCharges, vou fazer isso mas manter também a variável numérica..\nnew_df = pd.DataFrame()\n#coloquei 12 pra ter a informação do churn de 6 em 6 meses, talvez valha a pena aumentar (por exemplo pra 3 em 3 meses)\nnew_df['tenure_cat'] = pd.cut(raw_data['tenure'], 12, labels=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'] ) \n#pelo gráfico da densidade do ChurnxTenurexCusto parece ter 3 ou 4 categorias do MonthlyCharges, talvez valesse a pena fazer um ajuste fino maior, mas vou cortar em 5\nnew_df['charges_cat'] = pd.cut(raw_data['MonthlyCharges'], 5, labels=['1', '2', '3', '4', '5'] ) \n\n# essas colunas possuem um valor repetido em todas, que é o valor No Internet Service, mas esse valor já está descrito na coluna InternetService\n# então eu separei as colunas que já possuem essa informação de No Internet Service repetido para remove-las depois do dummies\ncol_dummies_repeated = ['OnlineSecurity', 'OnlineBackup',  'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies' ]\ndummies = pd.get_dummies( raw_data[col_dummies_repeated ] ) \ndummies = dummies.drop( columns=['OnlineSecurity_No internet service', 'OnlineBackup_No internet service', 'DeviceProtection_No internet service', 'TechSupport_No internet service', 'StreamingTV_No internet service', 'StreamingMovies_No internet service'] )\n\ncol_dummies = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'PaperlessBilling', 'PaymentMethod']\ndummies2 = pd.get_dummies( raw_data[col_dummies ], drop_first=True)\n\n#concatenando os dummies\nnew_df = pd.concat([new_df, dummies], axis=1)\nnew_df = pd.concat([new_df, dummies2], axis=1)\n\n#pegando os dummies das variaveis categoricas que foram criadas\nnew_df = pd.get_dummies(new_df, drop_first=True )\n\n#adicionando as duas colunas numericas\n\nnew_df['tenure'] = raw_data['tenure']\nnew_df['MonthlyCharges'] = raw_data['MonthlyCharges']\n\nnew_df['Churn'] = raw_data['Churn']\nnew_df = new_df.replace({'Yes': 1, 'No': 0})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split( new_df.loc[:, new_df.columns != 'Churn'], new_df['Churn'], test_size=0.2, random_state=42)\n\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'n_estimators':[10, 20, 50, 100], 'criterion':['gini', 'entropy'], 'max_features':['auto', 'sqrt', 'log2'] }\nrf = RandomForestClassifier()\nclf = GridSearchCV(rf, parameters, n_jobs=4)\nclf.fit(X_train, y_train)\nprint('Best Params:', clf.best_params_)\ny_pred = clf.predict(X_test)\nm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(clf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_score = cross_val_score(rf, X_train, y_train, cv=10)\nprint(clf_score)\nclf_score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.DataFrame(clf.best_estimator_.feature_importances_)\nfeatures[\"Feature\"] = list(new_df.columns[:-1]) \nfeatures.sort_values(by=0, ascending=False).head()\n\n\ng = sns.barplot(0,\"Feature\",data = features.sort_values(by=0, ascending=False)[0:10], palette=\"Pastel1\",orient = \"h\")\ng.set_xlabel(\"Weight\")\ng = g.set_title(\"Random Forest\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo Random Forest\n\nO modelo teve uma acurácia em torno de 78% mas errou bastante a classe mais difícil de prever, que é Churn = 1. Aproveitei para plotar o peso das variáveis que o modelo encontrou e como esperado, o que pesou mais foram as variáveis numéricas seguido por OnlineSecurity_No e Contract_Two_year. "},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'C':[0.9, 1.0, 1.1] }\nsvm = SVC()\nclf = GridSearchCV(svm, parameters, n_jobs=4)\nclf.fit(X_train, y_train)\nprint('Best Params:', clf.best_params_)\ny_pred = clf.predict(X_test)\nm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(clf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_score = cross_val_score(svm, X_train, y_train, cv=10)\nprint(clf_score)\nclf_score.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo SVM\n\nA SVM tem um resultado melhor, com o melhor modelo acertando 81% e isso se refletiu em uma ligeira redução nos erros tipo I e tipo II. Nesse caso o melhor tipo de kernel retornado foi o linear e não o rbf, que é melhor para funções não lineares."},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'penalty':['l1', 'l2', 'elasticnet', 'none'], 'C':[0.9, 1.0, 1.1] }\nreglog = LogisticRegression()\nclf = GridSearchCV(reglog, parameters, n_jobs=4)\nclf.fit(X_train, y_train)\nprint('Best Params:', clf.best_params_)\ny_pred = clf.predict(X_test)\nm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_score = cross_val_score(reglog, X_train, y_train, cv=10)\nprint(clf_score)\nclf_score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(clf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_proba_df = pd.DataFrame(clf.best_estimator_.predict_proba(X_test))\nthreshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,.7,.75,.8,.85,.9,.95,.99]\nfor i in threshold_list:\n    print ('\\n******** For i = {} ******'.format(i))\n    Y_test_pred = pred_proba_df.applymap(lambda x: 1 if x>i else 0)\n    test_accuracy = accuracy_score(y_test, Y_test_pred.iloc[:,1].to_numpy())\n    print('Our testing accuracy is {}'.format(test_accuracy))\n\n    print(confusion_matrix(y_test, Y_test_pred.iloc[:,1].to_numpy()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelo Regressão Logística\n\nA regressão logística teve uma acurácia similar à SVM mas teve uma ligeira inversão nos erros, com a regressão logística acertando mais os casos de churn mas errado mais os casos de não churn. Note que ambos deram acurácia similar, mas como é mais importante pro negócio acertar o maior numéro possível de casos de churn, modelos que consigam isso provavelmente seriam escolhidos.\n\nNo último bloco de código eu variei o limiar da probabilidade da classificação. Podemos reduzir bastante o erro do churn = 1 se estivermos dispostos a aceitar um erro maior de classificar churn = 0 como = 1. Pode ser uma alternativa, por exemplo, caso o modelo identifique uma chance de churn podemos tentar alguma intervenção com o cliente, como oferecer algum serviço gratuito por um período de tempo. Por exemplo, como na análise exploratória vimos que quem tem streaming de filmes tem menos churn, pode ser que valha a pena oferecer alguns meses do serviço gratuitamente ou um upgrade nos serviçs com desconto. O limiar de 25% faz com que acertamos 313 churns e erramos 60, mas teriamos 292 falso positivos. Se os custos da intervenção desses 292 for menor que o custo do churn, então pode valer a pena.\n\n# Conclusão sobre a modelagem\n\nApesar de eu ainda achar que os modelos poderiam ser melhorados, por exemplo, com um gridsearch melhor, trabalhando mais as variáveis (repensando os pontos de corte das variáveis numéricas, tentando combinações e removendo variáveis) e testando mais modelos e tentar estratégias para datasets desbalanceados."},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}