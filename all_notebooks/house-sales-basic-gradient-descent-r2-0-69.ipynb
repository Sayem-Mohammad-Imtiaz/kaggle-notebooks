{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","version":"3.6.3","name":"python","codemirror_mode":{"version":3,"name":"ipython"}}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"collapsed":true,"_cell_guid":"64c02b0a-291b-40fe-803a-40555c08bed4","_uuid":"f1eb12cd2ee5fa87164ca3039d1889e19e4e2aa4"},"outputs":[],"source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, date, time\nfrom sklearn.metrics import r2_score","cell_type":"code","execution_count":null},{"metadata":{},"outputs":[],"source":"# data pre-processing\ndata = pd.read_csv('../input/kc_house_data.csv')\ndata['date'] = pd.to_datetime(data['date'])\ndata['date'] = data['date'].dt.dayofyear\n\n# convert yr_built to age in years\ncurrYear = datetime.now().year\ndata['yr_built'] = currYear - data['yr_built']\ndata = data.rename(columns = {'yr_built':'house_age'})\n\n# drop id column\ndata = data.drop('id',axis=1)\n# drop zipcode column (location already in lat/lon columns)\ndata = data.drop('zipcode', axis=1)\n\n# convert yr_renovated to years since renovation\ndata['yr_renovated'] = currYear - data['yr_renovated']\ndata['yr_renovated'] = data['yr_renovated'].where(data['yr_renovated'] != currYear, 0)\ndata = data.rename(columns = {'yr_renovated': 'yrs_since_renov'})\ndata.head()","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"train,test = np.split(data.sample(frac=1), [int(.7*len(data))])","cell_type":"code","execution_count":null},{"metadata":{},"outputs":[],"source":"# convert to a matrix to allow for matrix operations on the data\ntrain_matrix = train.as_matrix()\ntest_matrix = test.as_matrix()","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"# y is the house price\ny = np.array(([train_matrix[:,1]]),dtype=float)\ntrain_matrix = np.delete(train_matrix, 1, 1)","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"# X is the rest of the columns\nX = np.array([train_matrix[:,:]])\nl,m,n = X.shape\nX.shape = (m,n)","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"# resizing to vectors\ny_test = np.array(([test_matrix[:,1]]),dtype=float)\ntest_matrix = np.delete(test_matrix, 1, 1)\nX_test = np.array([test_matrix[:,:]])\nl_test,m_test,n_test = X_test.shape\nX_test.shape = (m_test, n_test)\n\nm_test = y_test.size\ny_test = y_test.reshape(m_test,1)\ny_test = np.matrix(y_test)","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"# setup\nnum_iters = 500;\nalpha = 0.01;\ntheta = np.zeros((n+1,1),dtype=np.int)\ntheta = np.matrix(theta)\nlam = 1","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"def featureNormalize(A):\n    mu = np.mean(A, axis=0)\n    m = mu.size\n    mu = mu.reshape(1,m)\n    sigma = np.std(A, axis=0)\n    sigma = sigma.reshape(1,m)\n    A_norm = (A - mu) / sigma\n    return A_norm","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"# normalize x for training and test set. No need to normalize y. \nX_norm = featureNormalize(X)\nX_test_norm = featureNormalize(X_test)","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"# add a columns of ones for the bias unit to the training set\nm,n = X.shape\nI = np.ones((m,1),dtype=int)\nX_norm = np.c_[I,X_norm]","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"# add a columns of ones for the bias unit to the test set\nm_test,n_test = X_test.shape\nI = np.ones((m_test,1),dtype=int)\nX_test_norm = np.c_[I,X_test_norm]","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"def computeCost(X,y,theta, lam):\n    m = y.size\n    h = X*theta\n    n = theta.size\n    theta_tmp = np.matrix(theta)\n    theta_tmp[[1,1]] = 0 # this will make sure theta_0 is not updated\n    J = 1./(2.*m) * np.sum(np.square(h-y)) + (lam/(2.*m))* np.sum(np.square(theta_tmp))\n    return J","cell_type":"code","execution_count":null},{"metadata":{},"outputs":[],"source":"# some resizing, test cost function\nm = y.size\ny = y.reshape(m,1)\ny = np.matrix(y)\ncomputeCost(X_norm,y,theta,lam)","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"def gradientDescent(X, y, theta, alpha, num_iters, lam):\n    m = y.size\n    J_history = np.zeros((num_iters,1),dtype=float)\n    J_history = np.matrix(J_history)\n    \n    for i in range(1,num_iters):\n        h = X * theta\n        theta_tmp = np.matrix(theta)\n        theta_tmp[[1,1]] = 0 # this will make sure theta_0 is not updated\n    \n        delta = (1./m) * (X.T * (h-y)) + np.sum((lam/m)*theta_tmp)\n        theta = theta - alpha*delta  \n        J_history[[i,1]] = computeCost(X,y,theta,lam)\n    return J_history,theta","cell_type":"code","execution_count":null},{"metadata":{},"outputs":[],"source":"J_history,theta = gradientDescent(X_norm, y, theta, alpha, num_iters, lam)","cell_type":"code","execution_count":null},{"metadata":{},"outputs":[],"source":"# plot cost function\nfig, ax = plt.subplots()\nx_axis = np.arange(1,num_iters+1)\nx_axis = x_axis.reshape(num_iters,1)\nax.plot(x_axis, J_history, label=\".01\")\nlegend = ax.legend(loc='upper center', shadow=True)\nplt.ylabel(\"Cost (J)\")\nplt.xlabel(\"Num Iterations\")\nplt.show()","cell_type":"code","execution_count":null},{"metadata":{},"outputs":[],"source":"# predictions and r-square\ny_pred = X_test_norm * theta;\nm_pred = y_pred.size\ny_pred = y_pred.reshape(m_pred,1)\ny_pred = np.matrix(y_pred)\nr2 = r2_score(y_test, y_pred)\nprint (r2)","cell_type":"code","execution_count":null}]}