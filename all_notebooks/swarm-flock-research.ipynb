{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-07-23T09:46:16.337633Z","iopub.execute_input":"2021-07-23T09:46:16.338271Z","iopub.status.idle":"2021-07-23T09:46:16.354712Z","shell.execute_reply.started":"2021-07-23T09:46:16.338232Z","shell.execute_reply":"2021-07-23T09:46:16.353839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id = \"stepend\"> Table of contents </a>\n1. [Dataset Description](#1)\n    * [Description of features](#2)\n2. [A quick look at the data](#3)\n3. [Baseline Model](#4)   \n4. [Conclusion](#5)","metadata":{}},{"cell_type":"markdown","source":"# <a id = \"1\"> 1. Dataset Description</a>\n\nThis dataset is a set of measurements (24 016 units) of [boids](https://en.wikipedia.org/wiki/Boids), by which we can judge whether the birds are **grouped** at the moment, whether they are in a **flock** or **aligned**.\n\nIn this work, we will solve the *classification problem* for only one target variable - in a **flock** boids or not. (Class labels are binary, which 1 refers to flocking, grouped, and aligned, and 0 refers to not flocking, not grouped, and not aligned).\n> Flocking behaviour refers to the way that groups of birds, insects, fish or other animals, move close to each other. They are able to move as a group with the same velocity, yet without running into each other.","metadata":{}},{"cell_type":"markdown","source":"## <a id = \"2\"> Description of features</a>\n\nThe features are:\n 1. *xm* and *ym* as the (X,Y) position of each boid;\n 2. *xVeln* and *yVeln* as the velocity vector;\n 3. *xAm* and *yAm* as the alignment vector;\n 4. *xSm* and *ySm* as the separation vector;\n 5. *xCm* and *yCm* as the cohesion vector;\n 6. *nACm* as the number of boids in the radius of Alignment/Cohesion;\n 7. *nSm* as the number of boids in the radius of Separation.\n\nThese attributes are repeated for all m boids, where m = 1,...,200. (12*200 = 2 400 features)\n\nSo, as we can see, the dataset is very massive! Therefore, the main goal will be to create a high-quality predictive model on as few lines and features as possible.","metadata":{}},{"cell_type":"markdown","source":"# <a id = \"3\"> 2. A quick look at the data</a>","metadata":{}},{"cell_type":"code","source":"%%time\ndata = pd.read_csv(\"/kaggle/input/swarm-behavior/Swarm Behavior Data/Flocking.csv\", low_memory = False) \ndata","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:16.356356Z","iopub.execute_input":"2021-07-23T09:46:16.356891Z","iopub.status.idle":"2021-07-23T09:46:42.387647Z","shell.execute_reply.started":"2021-07-23T09:46:16.356857Z","shell.execute_reply":"2021-07-23T09:46:42.386476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:42.390235Z","iopub.execute_input":"2021-07-23T09:46:42.390677Z","iopub.status.idle":"2021-07-23T09:46:42.525947Z","shell.execute_reply.started":"2021-07-23T09:46:42.390631Z","shell.execute_reply":"2021-07-23T09:46:42.524991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's immediately fix the bug in the name of the class column and x1[24015]\ndata['Class'] = data['Class ']\ndata = data.drop(['Class '], axis=1)\ndata.x1[24015] = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:42.527596Z","iopub.execute_input":"2021-07-23T09:46:42.527913Z","iopub.status.idle":"2021-07-23T09:46:42.733314Z","shell.execute_reply.started":"2021-07-23T09:46:42.527882Z","shell.execute_reply":"2021-07-23T09:46:42.732112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <a id = \"4\"> 3. Baseline Model </a>","metadata":{}},{"cell_type":"markdown","source":"A baseline is a model that is both simple to set up and has a reasonable chance of providing decent results.\nAs such a model, we will choose the *RandomForestClassifier* in the basic configuration (without selection of parameters) on all the presented data. Yes, it is resource-intensive, but as long as we can afford it, we will do it. We need this result for a comparative analysis to show that on a modified dataset we will not lose accuracy, while improving accuracy (we count on this).","metadata":{}},{"cell_type":"code","source":"X_train = data.copy()\ny = X_train['Class']\nX_train = X_train.drop(['Class'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:42.73474Z","iopub.execute_input":"2021-07-23T09:46:42.735055Z","iopub.status.idle":"2021-07-23T09:46:43.102136Z","shell.execute_reply.started":"2021-07-23T09:46:42.735024Z","shell.execute_reply":"2021-07-23T09:46:43.100882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.apply(pd.to_numeric)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:43.103407Z","iopub.execute_input":"2021-07-23T09:46:43.103694Z","iopub.status.idle":"2021-07-23T09:46:43.89275Z","shell.execute_reply.started":"2021-07-23T09:46:43.103661Z","shell.execute_reply":"2021-07-23T09:46:43.891501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\ns_X_train, s_X_test, s_y_train, s_y_test = train_test_split(X_train, y, train_size = 0.2, test_size = 0.8, random_state = 0)\n\nmodel_baseline = RandomForestClassifier()\nmodel_baseline.fit(s_X_train, s_y_train)\n\nbaseline_predictions = model_baseline.predict(s_X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:43.894344Z","iopub.execute_input":"2021-07-23T09:46:43.894642Z","iopub.status.idle":"2021-07-23T09:46:51.671696Z","shell.execute_reply.started":"2021-07-23T09:46:43.894613Z","shell.execute_reply":"2021-07-23T09:46:51.670599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's evaluate the model. As the metric of the classification problem, we choose ROC_AUC\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot as plt\n\nroc_auc_score(s_y_test, baseline_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:51.67418Z","iopub.execute_input":"2021-07-23T09:46:51.674768Z","iopub.status.idle":"2021-07-23T09:46:51.689083Z","shell.execute_reply.started":"2021-07-23T09:46:51.674724Z","shell.execute_reply":"2021-07-23T09:46:51.688123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(baseline_predictions, s_y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:51.69026Z","iopub.execute_input":"2021-07-23T09:46:51.690674Z","iopub.status.idle":"2021-07-23T09:46:51.698611Z","shell.execute_reply.started":"2021-07-23T09:46:51.690632Z","shell.execute_reply":"2021-07-23T09:46:51.697824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model has extremely high prediction accuracy, let's determine how many rows we need to achieve almost 100% prediction accuracy.","metadata":{}},{"cell_type":"code","source":"s_X_train_1, s_X_test_1, s_y_train_1, s_y_test_1 = train_test_split(X_train, y, train_size = 0.0003, test_size = 0.9997, random_state = 0)\nmodel_baseline.fit(s_X_train_1, s_y_train_1)\nbaseline_predictions_1 = model_baseline.predict(s_X_test_1)\na_1 = roc_auc_score(s_y_test_1, baseline_predictions_1)\n\ns_X_train_2, s_X_test_2, s_y_train_2, s_y_test_2 = train_test_split(X_train, y, train_size = 0.0005, test_size = 0.9995, random_state = 0)\nmodel_baseline.fit(s_X_train_2, s_y_train_2)\nbaseline_predictions_2 = model_baseline.predict(s_X_test_2)\na_2 = roc_auc_score(s_y_test_2, baseline_predictions_2)\n\ns_X_train_3, s_X_test_3, s_y_train_3, s_y_test_3 = train_test_split(X_train, y, train_size = 0.0007, test_size = 0.9993, random_state = 0)\nmodel_baseline.fit(s_X_train_3, s_y_train_3)\nbaseline_predictions_3 = model_baseline.predict(s_X_test_3)\na_3 = roc_auc_score(s_y_test_3, baseline_predictions_3)\n\ns_X_train_4, s_X_test_4, s_y_train_4, s_y_test_4 = train_test_split(X_train, y, train_size = 0.001, test_size = 0.999, random_state = 0)\nmodel_baseline.fit(s_X_train_4, s_y_train_4)\nbaseline_predictions_4 = model_baseline.predict(s_X_test_4)\na_4 = roc_auc_score(s_y_test_4, baseline_predictions_4)\n\ns_X_train_5, s_X_test_5, s_y_train_5, s_y_test_5 = train_test_split(X_train, y, train_size = 0.0012, test_size = 0.9988, random_state = 0)\nmodel_baseline.fit(s_X_train_5, s_y_train_5)\nbaseline_predictions_5 = model_baseline.predict(s_X_test_5)\na_5 = roc_auc_score(s_y_test_5, baseline_predictions_5)\n\ns_X_train_6, s_X_test_6, s_y_train_6, s_y_test_6 = train_test_split(X_train, y, train_size = 0.004, test_size = 0.996, random_state = 0)\nmodel_baseline.fit(s_X_train_6, s_y_train_6)\nbaseline_predictions_6 = model_baseline.predict(s_X_test_6)\na_6 = roc_auc_score(s_y_test_6, baseline_predictions_6)\n\ns_X_train_7, s_X_test_7, s_y_train_7, s_y_test_7 = train_test_split(X_train, y, train_size = 0.05, test_size = 0.95, random_state = 0)\nmodel_baseline.fit(s_X_train_7, s_y_train_7)\nbaseline_predictions_7 = model_baseline.predict(s_X_test_7)\na_7 = roc_auc_score(s_y_test_7, baseline_predictions_7)\n\nprint(\"Using to train 0.03% of data:\", a_1, \"\\nUsing to train 0.05% of data:\", a_2, \n      \"\\nUsing to train 0.07% of data:\", a_3, \"\\nUsing to train 0.1% of data:\", a_4, \n      \"\\nUsing to train 0.12% of data:\", a_5,\"\\nUsing to train 0.4% of data:\",  a_6, \n      \"\\nUsing to train 5% of data:\", a_7)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:46:51.700028Z","iopub.execute_input":"2021-07-23T09:46:51.700372Z","iopub.status.idle":"2021-07-23T09:46:59.975052Z","shell.execute_reply.started":"2021-07-23T09:46:51.700342Z","shell.execute_reply":"2021-07-23T09:46:59.973603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5% of data it is just 0.05 * 24016 = 1 201 rows to predict other 22 815 rows!","metadata":{}},{"cell_type":"markdown","source":"# <a id = \"5\"> 4. Conclusions </a>","metadata":{}},{"cell_type":"markdown","source":"As far as can be judged from this analysis, predicting whether birds are in flock or not based on so many features is fairly straightforward for the base model.","metadata":{}}]}