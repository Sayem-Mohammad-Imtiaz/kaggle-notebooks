{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"R codes analaysis on Telecom churn dataset, prepeared for anyone looking for Telecom churn dataset analaysis using R. ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"#attach customer dataset and explore the information in it\nattach(customer)\nView(customer)\nhead(customer,5)\ndim(customer)\nsummary(customer)\nnames(customer)\nsapply(customer,class)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split the dataset in to trainig and validation ratio(80/20)\nset.seed(2)\ntr.id <- sample(1:nrow(customer),nrow(customer)*.8)\ntrain <- customer[tr.id , ]\nvalidation <- customer[-tr.id , ]\ndim(train)\ndim(validation)\nsummary(train)\nnames(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# logistic regression using GLM fucntion\nmodel2= glm(Churn~.,data=customer,family=binomial)\nsummary.glm(model2)\npar(mfrow=c(2,2))\nplot(model2)\n\nmodel3= glm(Churn~State,data=customer,family=binomial)\nsummary.glm(model3)\nmodel4= glm(Churn~`International plan`,data=customer,family=binomial)\nsummary.glm(model4)\nmodel5= glm(Churn~`International plan`+`Total day charge`+`Customer service calls`+`Voice mail plan`,data=validation,family=binomial)\nsummary.glm(model5)\nanova(model5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Construct the Misclassification Martrix\n#predict probability of chustomer will churn on given the values of the predictors\nglm_prob<-predict(model5, type=\"response\")\nglm_pred<-rep(\"FALSE\", 3333)\nglm_pred[glm_prob>0.5]=\"TRUE\"\ntable(glm_pred,Churn)\nMisclassification_Rate<-(458+94)/(2756+458+94+25)*100\nFalse_Positive_Rate<-(94)/(2756+94)*100\nFalse_Negative_rate<-(458)/(458+25)*100\nMisclassification_Rate\nFalse_Positive_Rate \nFalse_Negative_rate\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tree model on complete dataset \n# tree model on complete dataset \ntree_model=tree(as.factor(Churn)~., customer)\nplot(tree_model)\ntext(tree_model, pretty = 0)\nsummary(tree_model)\nhead(tree_model)\nstr(`Total day minutes`)\nhead(`Total day minutes`)\n# check how model is doing misclassifiction or confusion matrix \ntree_pred=predict(tree_model,customer,type=\"class\")\nhead(tree_pred)\ntable(tree_pred,Churn)\nhead(tree_pred)# predicted values\nhead(Churn)# actual predictions\nMisclassification_Rate<-(240+41)/(2809+240+243+41)*100\nFalse_Positive_Rate<-(41)/(2809+41)*100\nFalse_Negative_rate<-(240)/(240+243)*100\nMisclassification_Rate\nFalse_Positive_Rate \nFalse_Negative_rate\n#Cross Validation using Training and Testing data Sets\n#training dataset 80%\n#testing 20%\nset.seed(3)\ntrain=sample(1:nrow(customer), nrow(customer)*.8)\ncustomer.train=customer[train,]\ncustomer.test=customer[-train,]\ndim(customer.train) #training dataset\ndim(customer.test) #testing dataset\n\n#Set the HighSales variable (Target Variable) in training and testing datasets\nChurn.train=Churn[train]\nChurn.test=Churn[-train]\n# building tree model using training dataset\ntree_model1=tree(as.factor(Churn)~., customer.train)\nplot(tree_model1)\ntext(tree_model1,pretty=0)\nsummary(tree_model1)\n#testing dataset on training model \ntree_pred1=predict(tree_model1,customer.test,type=\"class\")\ntable(tree_pred1,Churn.test)\nMisclassification_Rate<-(42+8)/(558+42+8+59)*100\nFalse_Positive_Rate<-(8)/(558+8)*100\nFalse_Negative_rate<-(42)/(42+59)*100\nMisclassification_Rate\nFalse_Positive_Rate \nFalse_Negative_rate\n# cross validation and prune\nset.seed(3)\ncv.customer=cv.tree(tree_model1,FUN=prune.misclass)\nnames(cv.customer)\ncv.customer\nplot(cv.customer$size, cv.customer$dev, type = \"b\")\n#Pruning The Tree with best no of nodes 11 to get best model...this is validation\nprune.customer=prune.misclass(tree_model1,best=9)\nplot(prune.customer)\ntext(prune.customer,pretty=0)\nprune.customer\n#now on best model test testing dataset \ntree.pred2=predict(prune.customer,customer.test,type='class')\ntable(tree.pred2,Churn.test)\nMisclassification_Rate<-(42+8)/(558+42+8+59)*100\nFalse_Positive_Rate<-(8)/(558+8)*100\nFalse_Negative_rate<-(42)/(42+59)*100\nMisclassification_Rate\nFalse_Positive_Rate \nFalse_Negative_rate\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#k means clustering \nX = customer[,6:19]\nkm = kmeans(X, centers = 12)\n# randowm start function\nkm2 = kmeans(customer[,6:19], 12, nstart = 20, iter.max=500)\nkm2$cluster\nkm\n# cluster allocation\nfitted(km, \"classes\")\n#Plotting k-means Clusters\npp = prcomp(X)\nplot(pp$x[,1:2], col=fitted(km, \"classes\")+1,\n     xaxt=\"n\", yaxt=\"n\")\n#Comparing Cluster Lables with churn\ntable(Churn=customer$Churn, cluster=fitted(km, \"classes\"))\nkm\nkm$size\nkm$tot.withinss\nkm$tot.withinss\n#km2 Output\nkm2$betweenss\n#Hierarchical Clustering...with number of clusters \nhh = hclust(dist(X))\nplot(hh, main = \"Cluster Dendrogram\")\nrect.hclust(hh, k=4)\n#dist first to get distances, then hclust\nhh = hclust(dist(X), method=\"complete\")\nhh = hclust(dist(X), method=\"average\")\nhh = hclust(dist(X), method=\"single\")\nhc.complete = hclust(dist(X), method = \"complete\")\nhc.complete\nhc.average = hclust(dist(X), method = \"average\")\nhc.average\nhc.single = hclust(dist(X), method = \"single\")\nhc.single\npar(mfrow = c(1,3))\nplot(hc.complete, main = \"Complete Linkage\", xlab = \"\", sub = \"\", cex = 0.9)\nplot(hc.average, main = \"Average Linkage\", xlab = \"\", sub = \"\", cex = 0.9)\nplot(hc.single, main = \"Single Linkage\", xlab = \"\", sub = \"\", cex = 0.9)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cluster membership, we have to decide how many clusters\ncutree(hh, k=4)\nplot(hh, xlab=\" \", sub=\"Single link cluster analysis\")\nplot(hh, xlab=\" \", sub = \"Single link cluster analysis\")\nrect.hclust(hh, k=4)\nplot(pp$x[,6:17], col=cutree(hh, k=4)+1,\n     xaxt=\"n\", yaxt=\"n\")\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}