{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tic Tac Toe Decision Tree"},{"metadata":{},"cell_type":"markdown","source":"## Full Tree Visualization\nFirstly, the entire dataset was used as training to make one huge DecisionTree that should accurately Tic Tac Toe wins and losses for x."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas import DataFrame, Series\nfrom IPython.display import Image\nfrom io import StringIO\nimport pydotplus\nfrom sklearn import preprocessing\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_decision_tree(clf, features, classes):\n    dot_data = StringIO()\n    tree.export_graphviz(clf, out_file=dot_data, feature_names=features, class_names=classes, filled=True, rounded=True, special_characters=True)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n    return Image(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/tictactoe-endgame-dataset-uci/tic-tac-toe-endgame.csv',',')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['V1'],v1 = pd.factorize(df['V1'], sort=True)\ndf['V2'],v2 = pd.factorize(df['V2'], sort=True)\ndf['V3'],v3 = pd.factorize(df['V3'], sort=True)\ndf['V4'],v4 = pd.factorize(df['V4'], sort=True)\ndf['V5'],v5 = pd.factorize(df['V5'], sort=True)\ndf['V6'],v6 = pd.factorize(df['V6'], sort=True)\ndf['V7'],v7 = pd.factorize(df['V7'], sort=True)\ndf['V8'],v8 = pd.factorize(df['V8'], sort=True)\ndf['V9'],v9 = pd.factorize(df['V9'], sort=True)\ndf['V10'],v10 = pd.factorize(df['V10'], sort=True)\n[v1, v2, v3, v4, v5, v6, v7, v8, v9, v10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = [v10[0], v10[1]]\nclass_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = ['V1','V2','V3','V4', 'V5', 'V6', 'V7', 'V8', 'V9']\nx_train = df[feature_names] # Features\nx_train\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df['V10'] # Target\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(criterion='entropy')\nclf = clf.fit(x_train, y_train)\nclf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_decision_tree(clf, feature_names, class_names) # clf = Tree; feature_names = features; class_names = classes;","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing\nThe tests were conducted by recreating the Decision Tree trained only on 70% of the Dataset and testing it against the remaining 30%. This was done using the train_test_split function imported in the beginning of this notebook, and the .predict() method from the DecisionTreeClassifier. In the end there was also an example of 2 manually inputed tests to prove the results do match the classifications expected in a Tic Tac Toe game."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=1)\n[x_train, x_test, y_train, y_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(criterion='entropy', min_samples_split=80) # change this classifier and check the impact\nclf = clf.fit(x_train,y_train)\nplot_decision_tree(clf, feature_names, class_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the model to make predictions with the test data\ny_pred = clf.predict(x_test)\n# how did our model perform?\ncount_misclassified = (y_test != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))\naccuracy = metrics.accuracy_score(y_test, y_pred)\nprint('Accuracy: {:.2f}'.format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_test = np.array ([2, 2, 1, 2, 1, 0, 1, 0, 0])\npositive_test = np.array ([2, 2, 2, 1, 1, 0, 1, 0, 0])\ntest_group = [negative_test, positive_test]\ny_pred = clf.predict(test_group)\ny_pred # should give [0, 1]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}