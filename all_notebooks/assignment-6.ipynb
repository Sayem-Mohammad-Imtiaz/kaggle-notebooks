{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport struct\nfrom array import array\nfrom os.path  import join\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.metrics import accuracy_score, mean_squared_error, plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \nfrom matplotlib.pyplot import figure","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part A: MLP for Classification"},{"metadata":{},"cell_type":"markdown","source":"(a) **Data Pre-processing**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class MnistDataloader(object):\n    def __init__(self, training_images_filepath,training_labels_filepath,\n                 test_images_filepath, test_labels_filepath):\n        self.training_images_filepath = training_images_filepath\n        self.training_labels_filepath = training_labels_filepath\n        self.test_images_filepath = test_images_filepath\n        self.test_labels_filepath = test_labels_filepath\n    \n    def read_images_labels(self, images_filepath, labels_filepath):        \n        labels = []\n        with open(labels_filepath, 'rb') as file:\n            magic, size = struct.unpack(\">II\", file.read(8))\n            if magic != 2049:\n                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n            labels = array(\"B\", file.read())        \n        \n        with open(images_filepath, 'rb') as file:\n            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n            if magic != 2051:\n                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n            image_data = array(\"B\", file.read())        \n        images = []\n        for i in range(size):\n            images.append([0] * rows * cols)\n        for i in range(size):\n            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n            img = img.reshape(28, 28)\n            images[i][:] = img            \n        \n        return images, labels\n            \n    def load_data(self):\n        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n        return (x_train, y_train),(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MnistDataProcessor:\n    def __init__(self, pos_class, neg_class, training_samples=2000):\n        input_path = '../input/mnist-dataset'\n        training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n        training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n        test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n        test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n        mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n        (self.__x_train, self.__y_train), (self.__x_test, self.__y_test) = mnist_dataloader.load_data()\n        self.__train_pos_class = np.where(self.__y_train == np.uint8(pos_class))[0]\n        self.__train_neg_class = np.where(self.__y_train == np.uint8(neg_class))[0]\n        self.__test_pos_class = np.where(self.__y_test == np.uint8(pos_class))[0]\n        self.__test_neg_class = np.where(self.__y_test == np.uint8(neg_class))[0]\n        self.__train_samples = training_samples\n    \n    def train_data(self):\n        random.shuffle(self.__train_pos_class)\n        random.shuffle(self.__train_neg_class)\n        train_positive_class_idx = self.__train_pos_class[:self.__train_samples]\n        train_negative_class_idx = self.__train_neg_class[:self.__train_samples]\n        _train_vector = np.array([self.__x_train[i] for i in train_positive_class_idx] + [self.__x_train[i] for i in train_negative_class_idx])\n        nsamples, nx, ny = _train_vector.shape\n        train_vector = _train_vector.reshape((nsamples,nx*ny))\n        train_label = [1]*len(train_positive_class_idx) + [-1]*len(train_negative_class_idx)\n        return train_vector, train_label\n    \n    def test_data(self):\n        random.shuffle(self.__test_pos_class)\n        random.shuffle(self.__test_neg_class)\n        _test_vector = np.array([self.__x_test[i] for i in self.__test_pos_class] + [self.__x_test[i] for i in self.__test_neg_class])\n        nsamples, nx, ny = _test_vector.shape\n        test_vector = _test_vector.reshape((nsamples,nx*ny))\n        test_label = [1]*len(self.__test_pos_class) + [-1]*len(self.__test_neg_class)\n        return test_vector, test_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = MnistDataProcessor(3, 8)\nX_train, y_train = dataset.train_data()\nX_test, y_test = dataset.test_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(b) **Train an MLP each with 1, 2, 3 and 4 hidden layers using Backpropagation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for hidden_layers_count in range(1, 5):\n    clf = MLPClassifier(hidden_layer_sizes=tuple([100]*hidden_layers_count)).fit(X_train, y_train)\n    print(\"Accuracy score for MLP classifier with {} hidden layers: {:.2f}%\".format(hidden_layers_count, accuracy_score(clf.predict(X_test), y_test)*100))\n    disp = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n    disp.ax_.set_title(\"Confusion matrix for MLP classifier with {} hidden layers\".format(hidden_layers_count))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(c) **Pick the best MLP based on (a) and (b) and vary the following:**\n- Number of nodes in the hidden layers.\n- Tanh, Relu, and Logistic activation functions\n- Hyperparameters: Momentum term, Early stopping, and Learning Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'hidden_layer_sizes': [50,100],\n    'activation': ['logistic', 'tanh', 'relu'],\n    'early_stopping': [True, False],\n    'momentum': [0.25, 0.5,0.75],\n    'learning_rate': ['constant', 'adaptive']\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_grid = []\ni=0\nfor hidden_layer_size in param_grid['hidden_layer_sizes']:\n    for activation in param_grid['activation']:\n        for early_stopping in param_grid['early_stopping']:\n            for momentum in param_grid['momentum']:\n                for learning_rate in param_grid['learning_rate']:\n                    clf = MLPClassifier(hidden_layer_sizes=tuple([hidden_layer_size]*3), \n                                        activation = activation, early_stopping = early_stopping,\n                                        momentum = momentum, learning_rate = learning_rate, solver = 'sgd').fit(X_train, y_train)\n                    acc = accuracy_score(clf.predict(X_test), y_test)*100\n                    res = {\n                        'hidden_layer_size': hidden_layer_size,\n                        'activation': activation,\n                        'early_stopping': early_stopping,\n                        'momentum': momentum,\n                        'learning_rate': learning_rate,\n                        'accuracy_score': acc\n                    }\n                    i+=1\n                    print(\"Model trained: {}\".format(i))\n                    \n                    result_grid.append(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(result_grid).head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(result_grid).to_csv(\"classification_results.csv\", index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part B: MLP for Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"class HousingDataLoader:\n    def __init__(self):\n        raw_data = pd.read_csv('../input/california-housing-prices/housing.csv')\n        raw_data['total_bedrooms'] = raw_data.total_bedrooms.fillna(1)\n        self.raw_data = raw_data.drop(columns=['longitude', 'latitude'])\n    \n    def get_data(self):\n        X_cols = ['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n        Y_col = 'median_house_value'\n        data = self.raw_data.sample(frac=1).reset_index(drop=True)\n        return train_test_split(data[X_cols], data[Y_col], test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = HousingDataLoader()\nX_train, X_test,y_train, y_test = dataset.get_data()\nfor hidden_layers_count in range(1, 5):\n    clf = MLPRegressor(hidden_layer_sizes=tuple([100]*hidden_layers_count)).fit(X_train, y_train)\n    print(\"Squared error for MLP regressor with {} hidden layers: {:.2f}\".format(hidden_layers_count, mean_squared_error(clf.predict(X_test), y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'hidden_layer_sizes': [50,100],\n    'activation': ['logistic', 'tanh'],\n    'early_stopping': [True, False],\n    'momentum': [0.25, 0.5,0.75],\n    'learning_rate': ['constant', 'adaptive']\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_result_grid = []\ni=0\nfor hidden_layer_size in param_grid['hidden_layer_sizes']:\n    for activation in param_grid['activation']:\n        for early_stopping in param_grid['early_stopping']:\n            for momentum in param_grid['momentum']:\n                for learning_rate in param_grid['learning_rate']:\n                    clf = MLPRegressor(hidden_layer_sizes=tuple([hidden_layer_size]*3), \n                                        activation = activation, early_stopping = early_stopping,\n                                        momentum = momentum, learning_rate = learning_rate, solver = 'sgd').fit(X_train, y_train)\n                    score = mean_squared_error(clf.predict(X_test), y_test)\n                    res = {\n                        'hidden_layer_size': hidden_layer_size,\n                        'activation': activation,\n                        'early_stopping': early_stopping,\n                        'momentum': momentum,\n                        'learning_rate': learning_rate,\n                        'squared_error': score\n                    }\n                    i+=1\n                    print(\"Model trained: {}\".format(i))\n                    reg_result_grid.append(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(reg_result_grid).head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(reg_result_grid).to_csv(\"regression_results.csv\", index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}