{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Titanic \nProblem Statement:\nThe sinking of the Titanic is one of the biggest maritime disaster in the history, killing 1502 out of 2224\npassengers and the crew. One of the reasons for such loss was that there were not enough lifeboats. Some groups of people\nwere more likely to survive than others, such as women, children, and the upper class.\nObjective:\nâ€¢\nUse logistic regression to predict the survival of a given passenger based on features, such as sex, age\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\n\nimport seaborn as sns\nsns.set(style = \"white\",color_codes = \"True\")\nsns.set(font_scale = 1.5)\n\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\n\nfrom sklearn.metrics import recall_score\n\nfrom sklearn.metrics import f1_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Importing Data Set  \n\n#df_train = pd.read.csv('E:/Harish/DataScience/Machine learning/HKnotebooks/data/mtcars.csv', delimiter = ',',engine='python')\n\ndf_train = pd.read_csv('../input/train.csv')\n## Applying the same on test data , for creating final predictions file  \n\ndf_test = pd.read_csv('../input/test.csv')\n\n\ndf_train.info()\ndf_test.info()\n\n# Observation from rain data set\n# 891 observations\n## Most null values in Cabin Column\n## some missing values in Age column\n## presence of survived column whihc will be missing in test Data \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Sex'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Embarked'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We can seecabinhas almost 80% null values , hence it does not makes sense to keep this column , \n##we will drop this column from train Data set\n## We will drop other relevant columns as well\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(['PassengerId','Name','Ticket','Fare','Cabin'],axis = 1)\ndf_test = df_test.drop(['PassengerId','Name','Ticket','Fare','Cabin'],axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plotting Age Histogram \n\nplt.hist(df_train['Age'],bins = 20,color = 'b')\nplt.xlabel('Users Age')\nplt.ylabel('No of users')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## To understand this distribution  , refer below to understand skewness o\nSo when data are skewed right, the mean is larger than the median.\n##https://www.dummies.com/education/math/statistics/how-to-identify-skew-and-symmetry-in-a-statistical-histogram/\n\nUsing the mean ,ight not give us teh correct idea , hence we will use median to impite the age \n\nFirst we will check the Average age class wise \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df_train.groupby('Pclass')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Age_firstclass = df1.get_group(1)['Age'].dropna()\nAge_secondclass = df1.get_group(2)['Age'].dropna()\nAge_thirdclass = df1.get_group(3)['Age'].dropna()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_frstClass = len(df1.get_group(1)['Age'].dropna())\ncount_secondClass = len(df1.get_group(2)['Age'].dropna())\ncount_thirdClass = len(df1.get_group(3)['Age'].dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_age_first =  Age_firstclass.sum()/count_frstClass\navg_age_second =  Age_secondclass.sum()/count_secondClass\navg_age_third = Age_thirdclass.sum()/count_thirdClass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Hence we can see average age class wise \nprint(\"Average of first class passenger \",avg_age_first)\nprint(\"Average of second class passenger \",avg_age_second)\nprint(\"Average of third class passenger \",avg_age_third)\n\n## We will asume below values for average age of three calasses -  38,30,25\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Another way to find mean is below \n\ndf_train.groupby(['Pclass']).mean()\n\ndf_test.groupby(['Pclass']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We can say the younger the person is , it is more likely to be in first class \n\ndef age_approx(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age\n    \n    \ndef age_approx_test_data(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 41\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Age'] =  df_train[['Age','Pclass']].apply(age_approx,axis =1)\n\ndf_test['Age'] =  df_test[['Age','Pclass']].apply(age_approx_test_data,axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()\n\ndf_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dropna(inplace = True)\n\ndf_test.dropna(inplace = True)\n## Now our training data set looks better , without any null values \n## we can see column sex and embarked are categoricall Data type , we will use get dummies to convert these columnd into categories \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_dummied = pd.get_dummies(df_train,columns = ['Sex'])\n\ndf_test_dummied = pd.get_dummies(df_test,columns = ['Sex'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_dummied.info()\n\ndf_test_dummied.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_dummied = pd.get_dummies(df_train_dummied,columns = ['Embarked'])\n\ndf_test_dummied = pd.get_dummies(df_test_dummied,columns = ['Embarked'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_dummied.info()\n\ndf_test_dummied.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking if variables are correlated \nsns.heatmap(df_train_dummied.corr(),cmap = 'bwr')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Strong correlation between Survived and Sex_female columns \n\n## creating model  \n\nused_features =  ['Pclass','Age','SibSp','Parch','Sex_female','Sex_male','Embarked_C','Embarked_Q','Embarked_S']\n\nX = df_train_dummied[used_features].values\n\nY = df_train_dummied['Survived']\n\nX_Final_test = df_test_dummied[used_features].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Splitting Data set into train and test data \nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size = 0.3,test_size =0.7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape\n#(266, 9)\nX_test.shape\n#(623, 9)\nY_train.shape\n# (266,0)\nY_test.shape\n#(623,0)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Now isntantiate and train Classifier \n\nLogReg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LogReg.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = LogReg.predict(X_test)\n\nY_pred_final = LogReg.predict(X_Final_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(Y_test,Y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(Y_test,Y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## This means pour model has accuracy score of 79% ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Final output is in this data frame \n\n\nY_pred_final = LogReg.predict(X_Final_test)\n\nX_Final_test =  pd.DataFrame(X_Final_test)\n\nprint(X_Final_test)\nX_Final_test.columns = used_features\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Final_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_final1  =  pd.DataFrame(Y_pred_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_name =  ['Survived']\nY_pred_final1.columns = label_name ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y_pred_final1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## pd.concat([df,df_target],axis = 1) \n\nTitanic_predictions = pd.concat([X_Final_test,Y_pred_final1],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Titanic_predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## df.to_csv(r'Path where you want to store the exported CSV file\\File Name.csv')\n\nTitanic_predictions.to_csv(r'../input/titanic_pred.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Titanic_predictions.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}