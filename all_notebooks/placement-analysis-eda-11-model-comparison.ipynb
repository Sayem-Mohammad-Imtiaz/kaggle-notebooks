{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction and Imports","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install -q dabl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nimport dabl\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import roc_auc_score\n\nplt.style.use(\"fivethirtyeight\")\norange_black = [\n    '#fdc029', '#df861d', '#FF6347', '#aa3d01', '#a30e15', '#800000', '#171820'\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA and Data Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's see what each column means:\n- sl_no: Serial Number\n- Gender\n- ssc_p: Secondary Education percentage - 10th Grade\n- ssc_b: Board of Education - Central/ Others\n- hsc_p: Higher Secondary Education percentage- 12th Grade\n- hsc_b: Board of Education- Central/ Others\n- hsc_s: Specialization in Higher Secondary Education\n- degree_p: Degree Percentage\n- degree_t: Under Graduation(Degree type)- Field of degree education\n- workex: Work Experience \n- etest_p: Employability test percentage (Conducted by college)\n- specialization: Post Graduation(MBA)- Specialization\n- mba_p: MBA percentage\n- status: Status of placement- Placed/Not placed\n- salary: Salary offered by corporate to candidates","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Let's read the data now\ndata = pd.read_csv(\"../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's Do some basic Descriptive Statitics on the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now first check for the NULL values and do something about them.\nAs we can see, the `salary` column is the only one having null values (67).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Null values are only for those candidates who haven't been placed, which is obvious. Now I will impute these to 0 just for sake of visualization. \n\nHowever, we aren't going to use the `salary` column since **it is not a cause of the `status` column, but rather an effect of `status` column**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill 0 in place of NuLL values\ndata['salary'] = data['salary'].fillna(0)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before we do viz, first drop \"sl_no\" column.\ndata = data.drop(['sl_no'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's Start the Visualization now!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Candidate Gender Chart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = data['gender'].value_counts().tolist()\nvalues = list(dict(data['gender'].value_counts()).keys())\n\nfig = px.pie(\n    values=targets, \n    names=values,\n    title='Gender Value Pie-chart',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Candidate Status (Target Variable) Chart","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = data['status'].value_counts().tolist()\nvalues = list(dict(data['status'].value_counts()).keys())\n\nfig = px.pie(\n    values=targets, \n    names=values,\n    title='Status Value Distribution',\n    color_discrete_sequence=[\"cyan\", \"blue\"]\n    \n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a solid Data Imbalance in the dataset. We will have to deal with this later.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Specialization Distribution\nLet's take a look at `Specialization` Column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = data['specialisation'].value_counts().tolist()\nvalues = list(dict(data['specialisation'].value_counts()).keys())\n\nfig = px.pie(\n    values=targets, \n    names=values,\n    title='Spec. Value Distribution',\n    color_discrete_sequence=orange_black\n    \n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there is about the same amount of candidates that have Marketing-Finance and Marketing-Human Resources Specializations.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## MBA Percent Count Plot\nLet's draw up a Count Plot to see the trends of MBA Percent Distributions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    data, x=\"mba_p\",\n    marginal=\"violin\",\n    hover_data=data.columns,\n    color_discrete_sequence=[\"maroon\"],\n    title=f\"MBA Percent Distribution [\\u03BC : ~{data['mba_p'].mean():.2f}% | \\u03C3 : ~{data['mba_p'].std():.2f} %]\",\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Candidate Percentage in MBA lies around: `62%` with a standard deviation of `6%`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Salary Distribution\nThis one will be only for students that actually got placed, since the ones not getting placed will have a salary of `0` which would affect our plot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    data[data['salary']!=0], x=\"salary\",\n    marginal=\"violin\",\n    hover_data=data.columns,\n    color_discrete_sequence=[\"magenta\"],\n    title=f\"MBA Percent Distribution [\\u03BC : ~{data['mba_p'].mean():.2f}% | \\u03C3 : ~{data['mba_p'].std():.2f} %]\",\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Work Experience Distribution\nNow analyize how work experience varies through dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = data['workex'].value_counts().tolist()\nvalues = list(dict(data['workex'].value_counts()).keys())\n\nfig = px.pie(\n    values=targets, \n    names=values,\n    title='Work Exp. Distribution',\n    color_discrete_sequence=[\"gray\", \"black\"]\n    \n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, more than `65%` of the Candidates have no work experience at all.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Performance in Employability Test\nNow we look at `etest_p` which is **Employability Test Percentage** scored by candidates.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    data, x=\"etest_p\",\n    marginal=\"box\",\n    hover_data=data.columns,\n    color_discrete_sequence=[\"red\"],\n    title=f\"Performance in Employability Test [\\u03BC : ~{data['etest_p'].mean():.2f}% | \\u03C3 : ~{data['etest_p'].std():.2f} %]\",\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An average student has scored *72%* in Employability test, where the maximum scored was *98%* and the minimum scored was *50%*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Candidate Degree Pie Chart\nNow we look at what proportion of candidates hold each degree.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = data['degree_t'].value_counts().tolist()\nvalues = list(dict(data['degree_t'].value_counts()).keys())\n\nfig = px.pie(\n    values=targets, \n    names=values,\n    title=\"Candidate's Degree Type Chart\",\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that about *67%* of candidates have a Degree in **Commerce and Management**, while *27%* of Candidates hold a degree in **Science and Technology**. Remaining *5%* hold a degree in other disciplines. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Degree Percentage Distribution\nFollowing the degree type chart, let's look at the percentage achieved by students for their respective degrees.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    data, x=\"degree_p\",\n    marginal=\"box\",\n    hover_data=data.columns,\n    color_discrete_sequence=[\"green\"],\n    title=f\"Attained Degree Percentage [\\u03BC : ~{data['degree_p'].mean():.2f}% | \\u03C3 : ~{data['degree_p'].std():.2f} %]\",\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above Distribution, we can note that only 1 student has more than *90%* in their degree. The average percentage score lies at *~67%* while the minimum score lies at *~50%*.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's also compare which degree type has more average percentage.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sci_avg_pcent = data[data['degree_t'] == 'Sci&Tech']['degree_p'].mean()\ncom_avg_pcent = data[data['degree_t'] == 'Comm&Mgmt']['degree_p'].mean()\nprint(f\"Average Percentage for Science & Technology Students is: {sci_avg_pcent:.2f}% while the average percentage of Commerce & Management Students is: {com_avg_pcent:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Higher Secondry Specialization Pie-chart\nNow we move on to Pie-chart of Higher Secondry Specialization type.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = data['hsc_s'].value_counts().tolist()\nvalues = list(dict(data['hsc_s'].value_counts()).keys())\n\nfig = px.pie(\n    values=targets, \n    names=values,\n    title=\"Higher Secondry Spec. Type Chart\",\n    color_discrete_sequence=[\"red\", \"blue\", \"green\"]\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Higher Secondry Board Type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = data['hsc_b'].value_counts().tolist()\nvalues = list(dict(data['hsc_b'].value_counts()).keys())\n\nfig = px.pie(\n    values=targets,\n    names=values,\n    title=\"Higher Secondry Board Type Chart\",\n    color_discrete_sequence=[\"orange\", \"gold\"]\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Higher Secondry Percentage\nFinally, let's look at Student Percentage in Higher Secondry Exams.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    data, x=\"ssc_p\",\n    marginal=\"box\",\n    hover_data=data.columns,\n    color_discrete_sequence=[\"blue\"],\n    title=f\"Higher Secondry Percentage [\\u03BC : ~{data['ssc_p'].mean():.2f}% | \\u03C3 : ~{data['ssc_p'].std():.2f} %]\",\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encode Categorical Data\nBefore I forget, let's encode categorical data so that the upcoming charts can be more understandable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# A few utility functions to encode categorical data\n\ndef get_category_names(df, column_name):\n    '''\n    Column passed must be categorical\n    '''\n    unique_names_dict = dict(df[column_name].value_counts())\n    unique_names = list(unique_names_dict.keys())\n    \n    _length = len(unique_names)\n    return (_length, unique_names)\n\ndef replace_small_categorical_data(df, column_name, categorical_names):\n    \"\"\"\n    Categorical Encodes a data\n    \"\"\"\n    copy_frame = df.copy(deep=True)\n    \n    copy_frame[column_name].replace(categorical_names, [x for x in range(len(categorical_names))], inplace=True)\n    \n    return copy_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_encode = [\"gender\", \"ssc_b\", \"hsc_b\", \"hsc_s\", \"degree_t\", \"workex\", \"specialisation\", \"status\"]\nencoded_data = data.copy(deep=True)\n\nfor col in to_encode:\n    _, current_category_names = get_category_names(encoded_data, col)\n    encoded_data = replace_small_categorical_data(encoded_data, col, current_category_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pairplot\nLet's draw some pair plot to see how different features affect each other.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation Heatmap\nLet's now see how all the features are correlated to each other.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 12))\nsns.heatmap(encoded_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DABL Plot\nSince we have viz. most of the columns, let's end this EDA session by a DABL plot.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First by setting `status` as target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (18, 6)\ndabl.plot(encoded_data, target_col = 'status')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And then by setting `salary` as target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (18, 6)\ndabl.plot(encoded_data, target_col = 'salary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Before we start modelling, we have to normalise and split our encoded dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, let's split the data\nsplit_pcent = 0.10\nsplit = int(split_pcent * len(encoded_data))\nencoded_data = encoded_data.sample(frac=1).reset_index(drop=True)\n\nencoded_data = encoded_data.drop(['salary'], axis=1)\n\ntest = encoded_data[:split]\ntrain = encoded_data[split:]\n\ntrainY = train['status'].values\ntrainX = train.drop(['status'], axis=1)\n\ntestY = test['status'].values\ntestX = test.drop(['status'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean Normalise the data\ntrainX = (trainX - trainX.mean()) / trainX.std()\ntestX = (testX - testX.mean()) / testX.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's start the real Classification.\nI am going to compare all the different classification techniques and then plot their corresponding testing accuracies.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are only using 11 Classifiers, you can use more if you wish.\nnames = [\"Logistic Regression\", \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"]\n\nclassifiers = [\n    LogisticRegression(),\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1, max_iter=1000),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Due to the presence of data imbalance, I am using roc-auc score instead of normal accuracy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's do the classification and store the name of the classifier and it's test score into a dictionary\n\nclf_results = {}\n\nfor name, clf in tqdm(zip(names, classifiers)):\n    # Fit on the traning data\n    clf.fit(trainX, trainY)\n    \n    # Get the test time prediction\n    preds = clf.predict(testX)\n    \n    # Calculate Test ROC_AUC\n    score = roc_auc_score(testY, preds)\n    \n    # Store the results in a dictionary\n    clf_results[name] = score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort the Model Accuracies based on the test score\nsort_clf = dict(sorted(clf_results.items(), key=lambda x: x[1], reverse=True))\n\n# Get the names and the corresponding scores\nclf_names = list(sort_clf.keys())[::-1]\nclf_scores = list(sort_clf.values())[::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the per-model performance\nfig = px.bar(\n    x=clf_scores,\n    y=clf_names,\n    color=clf_names,\n    labels={'x':'Test ROC-AUC Score', 'y':'Models'},\n    title=f\"Model Performance [ Best Model: {clf_names[-1]} | Score: {clf_scores[-1]} ]\"\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, we can cross the **90%** accuracy mark.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Thank you!\n\nPlease correct me if I’ve made any mistakes in EDA, modelling or maybe explaining some concept since I am a beginner and prone to making mistakes. \n\nPlease consider giving this notebook an upvote as it helps me work harder and publish more quality notebooks.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}