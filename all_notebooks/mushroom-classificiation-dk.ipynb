{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#To ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading File"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"mushroom = pd.read_csv('../input/mushrooms.csv')\nmushroom.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check fo dimension of dataset and values of target class"},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom['class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Models to apply - PCA, Logistic Regression, Random Forest, SVM, Naive Bayes Classifer and Decision Tree"},{"metadata":{},"cell_type":"markdown","source":"Encoding data from strings to intergers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nfor col in mushroom.columns:\n    mushroom[col] = labelencoder.fit_transform(mushroom[col])\n\nmushroom.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom['odor'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom.groupby('class').size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x='class',y='stalk-color-above-ring',data=mushroom)\nax = sns.stripplot(x='class',y='stalk-color-above-ring',data=mushroom,jitter=True,edgecolor='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separating target class from features"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = mushroom.iloc[:,1:]\nY = mushroom.iloc[:,0]\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation between different variables - only showing values > 0.4 or < -0.4"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.corr()[(X.corr() < -0.4) | (X.corr() > 0.4)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalizing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX #returns an array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking covariance\ncovarinace = pca.get_covariance()\ncovarinace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variance_explained = pca.explained_variance_\nvariance_explained","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting graph to see which component has highest explained variance\nwith plt.style.context('dark_background'):\n    plt.figure(figsize=(6,4))\n    plt.bar(range(22),variance_explained,alpha=0.5,align='center',\n            label='individual explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting graph to see the cumulative sum of covariance and decide how many components to keep\nwith plt.style.context('dark_background'):\n    plt.figure(figsize=(6,4))\n    plt.bar(range(22),variance_explained.cumsum(),alpha=0.5,align='center',\n            label='individual explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Taking only first two components now - to easliy visualize the clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = mushroom.values\npca = PCA(n_components=2)\nx = pca.fit_transform(n)\nplt.figure(figsize=(5,5))\nplt.scatter(x[:,0],x[:,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying k-means clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2,random_state=5)\nX_clustered = kmeans.fit_predict(n)\n\nLABEL_COLOR_MAP = {\n    0: 'g',\n    1: 'y'\n}\n\nlabel_color = [LABEL_COLOR_MAP[l] for l in X_clustered]\nplt.figure(figsize=(5,5))\nplt.scatter(x[:,0],x[:,1],c=label_color)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Partitioning into training and testing set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,\n                                                    random_state=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Default logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n\nLR_model = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Positive class prediction probabilities\ny_prob = LR_model.predict_proba(X_test)[:,1]\n#To derive class from the probabilities. If probability > 0.5, assign class 1 otherwise class 0\ny_pred = np.where(y_prob > 0.5, 1, 0)\nLR_model.score(X_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making confusion matrix\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Geting ROC metric - Area under the curve value\nauc_roc = metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n         label='AUC = %0.2f' % roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],linestyle = '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression (tuned)"},{"metadata":{},"cell_type":"markdown","source":"Tuned parameters include applying different learning rate (C) and different penalty types. L1(Lasso) is the first moment norm |x1-x2| (|w| for regularization case). L2(Ridge) is the second moment norm |x1-x2|^2 (|w|^2 for regularization). L2 shrinks all the coefficient by the same proportions but eliminates none, while L1 can shrink some coefficients to zero, performing variable selection. If all the features are correlateed with the target, L2 performs L1. If only a subset of the features are correlated to the target, L1 outperforms L2."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n\nLR_model = LogisticRegression()\n\ntuned_parameters = {'C': [0.001,0.01,0.1,1,10,100,1000], \n                    'penalty':['l1','l2']\n                   }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The grid search provided by GridSearchCV generates all possible candidates from a grid of parameter values specified with the tuned_parameter. The GridSearchCV instance implements the usual estimator API: when 'fitting' it on a dataset, all the possible combinations of parameter vaues are evaluated and the best combination is retained."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nLR = GridSearchCV(LR_model, tuned_parameters, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(LR.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Probability for being in positive class\ny_prob = LR.predict_proba(X_test)[:,1]\n#Getting class - if probability > 0.5, true(1) class otherwise false(0) class\ny_pred = np.where(y_prob > 0.5,1,0)\nLR.score(X_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix for the model\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Precision, Recall & f1 scores\nmeasures = metrics.classification_report(y_test,y_pred)\nmeasures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC value - Area under the curve (AUC) value\nauc_roc = metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_prob)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_ridge = LogisticRegression(penalty='l2')\nLR_ridge.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Probability for being in positive class\ny_prob = LR_ridge.predict_proba(X_test)[:,1]\n#Getting class - if probability > 0.5, true(1) class otherwise false(0) class\ny_pred = np.where(y_prob > 0.5,1,0)\nLR_ridge.score(X_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix for the model\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC value - Area under the curve (AUC) value\nauc_roc = metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_prob)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gaussian Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnaive_model = GaussianNB()\nnaive_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Probability for being in positive class\ny_prob = naive_model.predict_proba(X_test)[:,1]\n#Getting class - if probability > 0.5, true(1) class otherwise false(0) class\ny_pred = np.where(y_prob > 0.5,1,0)\nnaive_model.score(X_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of mislabel points from %d points: %d\"\n      % (X_test.shape[0], (y_test != y_pred).sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross-validating 10 times and calculating their accuracy\nscores = cross_val_score(naive_model, X, Y, cv=10, scoring='accuracy')\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix for the model\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Precision, Recall & f1 scores\nmeasures = metrics.classification_report(y_test,y_pred)\nmeasures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC value - Area under the curve (AUC) value\nauc_roc = metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_prob)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_model = SVC()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tunning SVM on 2 parameters gamma & C\ngamma parameter is the inverse of the radius of influence of samples selected by the model as support vectors. In other words, it defines how far the influence of a single training example reaches. Low gamma values means influence is far and wide whereas high gamma values means influences is near and close.\nC parameter defines tradeoff between misclassification rate and complexity of the decision surface. Low value of C means simple(smooth) decision surface and high misclassification rate whereas high value of C means low misclassification rate and complex decision surface."},{"metadata":{},"cell_type":"markdown","source":"SVM with non-polynomial kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_parameters = {\n    'C' : [1, 10, 100, 500, 1000],'kernel': ['linear','rbf'],\n    'C' : [1, 10, 100, 500, 1000],'gamma': [1, 0.1, 0.01, 0.0001], 'kernel':['rbf']\n}\ntuned_parameters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomizedSearchCV implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search: 1)A budget can be chosen independent of the number of parameters and possible values. 2)Adding parameters that do not influence the performance does not decrease efficiency.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nmodel_svm = RandomizedSearchCV(svm_model, tuned_parameters, cv = 10, \n                               scoring='accuracy', n_iter = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Might take some time"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_svm.fit(X_train, y_train)\nprint(model_svm.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model_svm.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_svm.predict(X_test)\nprint(metrics.accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix=metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.classification_report(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVM with polynomial kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_parameters = {\n 'C': [1, 10, 100,500, 1000], 'kernel': ['linear','rbf'],\n 'C': [1, 10, 100,500, 1000], 'gamma': [1,0.1,0.01,0.001, 0.0001], 'kernel': ['rbf'],\n 'degree': [2,3,4,5,6] , 'C':[1,10,100,500,1000] , 'kernel':['poly']\n}\ntuned_parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nmodel_svm = RandomizedSearchCV(svm_model, tuned_parameters, cv = 10, \n                               scoring='accuracy', n_iter = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#might take some time\nmodel_svm.fit(X_train, y_train)\nprint(model_svm.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model_svm.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model_svm.grid_scores_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_svm.predict(X_test)\nprint(metrics.accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix=metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.classification_report(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRF_model = RandomForestClassifier()\nRF_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Probabilities for positive class\ny_prob = RF_model.predict_proba(X_test)[:,1]\n#Class from probabilities\ny_pred = np.where(y_prob > 0.5, 1, 0)\nRF_model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix=metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.classification_report(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(Just for practice) Tuning Random Forest on 3 features \n1. max_features - maximum number of features Random Forest is allowed to try in individual tree - i) auto - take all features ii)sqrt - take square root of the number of features iii)log2 - take log base 2 of the number of features.\n*Higher the number of features, slower is the algorithm, better is the performance(output model)\n2. n_estimators - number of trees to build \n3. min_samples_leaf - purity of leaf node"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRFC_model = RandomForestClassifier()\ntuned_parameters = { 'min_samples_leaf': range(10,100,10),\n                   'n_estimators': range(10,100,10),\n                   'max_features': ['auto','sqrt','log2']\n                   }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nRFC_model = RandomizedSearchCV(RFC_model, tuned_parameters,cv=10, \n                              scoring='accuracy',\n                              n_iter=20, n_jobs = -1)\n#n_jobs tells the engine how many processors is it allowed to use. If -1, no restrictions, if 1, can only use 1 processor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(RFC_model.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(RFC_model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probabilities for being in positive class\ny_prob = RFC_model.predict_proba(X_test)[:,1]\n#getting class from probabilities\ny_pred = np.where(y_prob > 0.5, 1, 0)\nRFC_model.score(X_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix=metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.classification_report(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.roc_auc_score(y_test,y_pred)\nauc_roc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree_model = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probabilities for being in positive class\ny_prob = tree_model.predict_proba(X_test)[:,1]\n#getting class from probabilities\ny_pred = np.where(y_prob > 0.5, 1, 0)\ntree_model.score(X_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix=metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.classification_report(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(Just for practice) Tuning 3 parameters of Decision Tree \n1. Criterion - selection of split - gini index or entropy\n2. max-depth - maximum vertical depth of tree - to control overfitting of tree\nmax_features and min_samples_leaf - same as Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nDT_model = DecisionTreeClassifier()\n\ntuned_parameters = { 'criterion': ['gini','entropy'], \n                    'max_features': ['auto','sqrt','log2'],\n                   'min_samples_leaf': range(1,100,1),\n                   'max_depth': range(1,50,1)\n                   }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nDT_model = RandomizedSearchCV(DT_model, tuned_parameters, cv=10, scoring='accuracy',\n                             n_iter=20,n_jobs=-1,random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(DT_model.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(DT_model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probabilities for being in positive class\ny_prob = DT_model.predict_proba(X_test)[:,1]\n#getting class from probabilities\ny_pred = np.where(y_prob > 0.5, 1, 0)\nDT_model.score(X_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix=metrics.confusion_matrix(y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.classification_report(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_roc=metrics.roc_auc_score(y_test,y_pred)\nauc_roc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting values for the ROC curve and finding the best AUC value\nfrom sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred)\nroc_auc = auc(false_positive_rate,true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the roc curve\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate,color='red',\n        label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1],[0,1],linestyle= '--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}