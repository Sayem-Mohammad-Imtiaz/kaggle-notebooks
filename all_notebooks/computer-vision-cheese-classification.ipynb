{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Computer Vision Project: Cheese Classification"},{"metadata":{},"cell_type":"markdown","source":"Coded by Luna McBride"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt #plotting\n%matplotlib inline\n\nfrom PIL import Image #Image Processing\nimport os #Operating System\n\nimport tensorflow as tf #Import tensorflow in order to use Keras\nfrom keras import backend as K #Used for trying to clear memory, but I could still not clear enough RAM\n\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences #Add padding to help the Keras Sequencing\nimport tensorflow.keras.layers as L #Import the layers as L for quicker typing\nfrom tensorflow.keras.optimizers import Adam #Pull the adam optimizer for usage\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy #Loss function being used\nfrom tensorflow.keras.preprocessing import image #Add image handling, because I am looking at images\n\nfrom keras.models import Sequential #Sequential\nfrom keras.layers import Conv2D, MaxPooling2D #Load 2d layers\nfrom keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization #Load important layers\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cheese = pd.read_csv(\"../input/french-cheese-detection/fourmes_train.csv\", delimiter = \";\") #Put the cheese into a dataframe\ncheese.head() #Take a peek at the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cheeseTest = pd.read_csv(\"../input/cheese-test-csv/fourmes_test.csv\") #Put the cheese into a dataframe\ncheeseTest.head() #Take a peek at the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Check for Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cheese.isnull().any()) #Check for null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cheeseTest.isnull().any()) #Check for null values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Fix Test Set Column Names"},{"metadata":{"trusted":true},"cell_type":"code","source":"colNames = [\"filename\", \"x1\", \"y1\", \"x2\", \"y2\", \"class\"] #List to fix the names since I put spaces in my CSV\ncols = dict(zip(cheeseTest.columns, colNames)) #Zip the current names with the new list\ncheeseTest = cheeseTest.rename(columns = cols) #Rename the dataframe without the spaces\ncheeseTest.head() #Take a peek at the test dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# File Name Collecting"},{"metadata":{"trusted":true},"cell_type":"code","source":"files = cheese[\"filename\"].unique() #Get the unique file names\n\ncheese[\"filenum\"] = cheese[\"filename\"].apply(lambda x: x.split(\".\")[0]) #Put the file number in its own column\ncheese.head() #Take a peek at the dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Image Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#CropImage: Crops a Pil Image to specified corners (x1, y1) and (x2, y2)\n#Input: the image, cornerpoints (x1, y1) and (x2, y2)\n#Output: The cropped image\ndef cropImage(image, x1, y1, x2, y2):\n    return image.crop((x1, y1, x2, y2)) #Return the image cropped via (x1, y1) and (x2, y2)\n\n#Standardize: Standarizes images by resizing them to an x by y image\n#Input: The image, variables x and y to resize the image to\n#Output: The standardized image\ndef standardize(image, x, y):\n    return image.resize((x,y), Image.ANTIALIAS) #Return the resized/standardized image\n\n#PreprocessImages: Pulls image stats from the dataframe to collect, crop, and standardize images, saving them into a new repository\n#Input: The dataframe\n#Output: A list of processed images and names of their links\ndef preprocessImages(df, folder):\n    croppedImages = [] #A list to hold processed images\n    names = [] #A list to hold the link name\n    \n    directory = \"cropped_\" + folder #Give the name of the directory\n    \n    #If the cropped image directory does not exist, make it\n    if not os.path.exists(directory):\n        os.makedirs(directory) #Make the directory\n        \n    #For each row, collect the image, crop it, standardize it, and add it to the processed image list\n    for index, row in df.iterrows():\n        openImage = Image.open(\"../input/french-cheese-detection/{}/{}\".format(folder, row[\"filename\"])) #Open the image\n        openImage = cropImage(openImage, row[\"x1\"], row[\"y1\"], row[\"x2\"], row[\"y2\"]) #Crop the image (see the cropImage method)\n        stand = standardize(openImage, 60, 60) #Resize/Standardize the image (see the standardize method above)\n        croppedImages.append(np.asarray(stand)) #Append the processed image to the holder list\n        \n        #Build the file path name\n        name = \"cropped_\" + folder + \"/\" + row[\"filename\"].split(\".\")[0] + str(row[\"x1\"]) + str(row[\"y2\"]) + \".\" + row[\"filename\"].split(\".\")[1]\n        names.append(\"./\" + name) #Add the name to the names list\n        \n        #If the file does not exist, save it.\n        if not os.path.isfile(name):\n            d = stand.save(name) #Save the new cropped image\n        \n    return croppedImages, names #Return the list of processed images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesTrain, names = preprocessImages(cheese, \"fourmes_train\") #Use the preprocessImages function to process images based on the database\nplt.imshow(imagesTrain[3]) #Show a processed cheese image (the image processed, not the cheese. We are not working with American here)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A fine cheese indeed."},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesTest, namesTest = preprocessImages(cheeseTest, \"fourmes_test\") #Use the preprocessImages function to process images based on the database\nplt.imshow(imagesTest[4]) #Show a processed cheese image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Set up Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"classTrain = cheese[\"class\"] #Get the train class we are looking for\nclassTest = cheeseTest[\"class\"] #Get the test cheese type we are looking for\n\nclassTrain = pd.get_dummies(classTrain) #Get dummies for the train set\nclassTest = pd.get_dummies(classTest) #Get dummies for the test set\nprint(classTest) #Print one of the sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cheese[\"name\"] = names #Put the image names/urls into the cheese dataframe\ntrain_datagen = image.ImageDataGenerator( #Build a image generator\n        rescale=1./255, #Resize the images\n        shear_range=0.2, #Allow shearing the images\n        zoom_range=0.2, #Allow zooming\n        horizontal_flip=True) #Allow horizontal flipping\n\ntrain = train_datagen.flow_from_dataframe(cheese,  #Get the images from the cheese dataframe\n        target_size = (60, 60), #Show that image size is to be 60x60\n        batch_size = batchSize, #Set the batch size to the pre-determined size\n        class_mode = \"binary\", #Put the mode to binary since there are two labels\n        x_col = \"name\", #Get the image file names into x_col\n        y_col = \"class\") #Get the label classes into y_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = image.ImageDataGenerator(rescale=1./255) #Build a simple datagen for the test images\ncheeseTest[\"name\"] = namesTest #Add the names to the dataframe as to stream them\n\ntest = test_datagen.flow_from_dataframe(cheeseTest, #Make a flow variable for keras from the test images\n                                        class_mode = \"binary\", #Make the mode binary since there are only two tiers\n                                        x_col = \"name\", #Get the image names into the x_col\n                                        y_col = \"class\", #Get the labels (cheese type) into the y_col\n                                        batch_size = batchSize, #Set the batch size\n                                        target_size = (60, 60)) #Show that the target image size is 60x60","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train and test are already separate. Compare to train test split syntax:\n\nimageTrain, imageTest, classTrain, classTest = train_test_split(images, class, ...)"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session() #Clear any previous model building\n\nepoch = 50 #Number of runs through the data\nwidth = 60 #The width of the images\nheight = 60 #The height of the images\nchannels = 3 #The number of channels (RGB)\n\nmodel = Sequential() #Add a sequential to the model\nmodel.add(Conv2D(32, (3,3), input_shape = (width, height, channels))) #Add a convolutional image layer\nmodel.add(BatchNormalization()) #Normalize the data\nmodel.add(Activation(\"relu\")) #Make the activation relu to discourage negative units\nmodel.add(MaxPooling2D(pool_size=(2, 2))) #Max pool the data to keep the most important characteristics\n\nmodel.add(Conv2D(32, (3, 3))) #Add a convolutional image layer\nmodel.add(Activation(\"relu\")) #Make the activation relu to discourage negative units\nmodel.add(MaxPooling2D(pool_size=(2, 2))) #Max pool the data to keep the most important characteristics\n\nmodel.add(Conv2D(64, (3, 3))) #Add a bigger convolutional image layer, layering activations\nmodel.add(Activation(\"relu\")) #Make the activation relu to discourage negative units\nmodel.add(MaxPooling2D(pool_size=(2, 2))) #Max pool the data to keep the most important characteristics\n\nmodel.add(Flatten()) #Make the layers flat to apply the characteristics into one slot\nmodel.add(Dense(64)) #Add a dense layer to track activation\nmodel.add(Activation(\"relu\")) #Make the activation relu to discourage negative units\nmodel.add(Dense(1)) #Add another dense layer to finish the lot\nmodel.add(Activation(\"sigmoid\")) #Make the activation sigmoid \n\nmodel.compile(loss = \"binary_crossentropy\", #Make the loss binary to fit with the sigmoid endpoint\n              optimizer = \"rmsprop\", #Use root mean squared prop to optimize (adam came to similar results at much slower speeds)\n              metrics = [\"accuracy\"]) #Track the accuracy of the model\n\nhistory = model.fit_generator(train, epochs = epoch) #Fit the model to the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(test) #Get the loss and Accuracy based on the tests\n\n#Print the loss and accuracy\nprint(\"Test Loss: \", loss)\nprint(\"Test Accuracy: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = [\"Fourme d'Ambert\", \"Fourme de Montbrison\"] #Adding the class names\npredict = model.predict_classes(test) #Get predictions\nprint(predict) #Print the predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length = len(predict) #Get the length of the predictions\ntrue = cheeseTest[\"class\"] #Get the true names of the cheese\n\n#For each test cheese, print the cheese titled with the prediction\nfor i in range(0, length):\n    plt.figure(figsize = (6, 5)) #Get the cheese picture\n    plt.imshow(imagesTest[i]) #Show a processed cheese image\n    plt.title(\"Predicted: {} \\n True: {}\".format(classes[predict[i][0]], true[i])) #Set the title to the predicted and true cheese names","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}