{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nfrom itertools import combinations, groupby\nfrom collections import Counter\nfrom IPython.display import display\nimport os\nprint(os.listdir(\"../input\"))\n\n# Function that returns the size of an object in MB\ndef size(obj):\n    return \"{0:.2f} MB\".format(sys.getsizeof(obj) / (1000 * 1000))\n\norders = pd.read_csv('../input/dataset_group.csv')\nprint('orders -- dimensions: {0};   size: {1}'.format(orders.shape, size(orders)))\ndisplay(orders.head())\n# Any results you write to the current directory are save","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Convert from DataFrame to a Series, with order_id as index and item_id as value\norders.columns= ['datum','Transaction','Item']\norders = orders.set_index('Transaction')['Item'].rename('item_id')\ndisplay(orders.head(10))\ntype(orders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70e257ce759abdcd98e26d23aaa39221dd974b21"},"cell_type":"code","source":"print('dimensions: {0};   size: {1};   unique_orders: {2};   unique_items: {3}'\n      .format(orders.shape, size(orders), len(orders.index.unique()), len(orders.value_counts())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a110e8770785de20edd124cb11e2e1c5505ec1d"},"cell_type":"code","source":"# Returns frequency counts for items and item pairs\ndef freq(iterable):\n    if type(iterable) == pd.core.series.Series:\n        return iterable.value_counts().rename(\"freq\")\n    else: \n        return pd.Series(Counter(iterable)).rename(\"freq\")\n\n    \n# Returns number of unique orders\ndef order_count(order_item):\n    return len(set(order_item.index))\n\n\n# Returns generator that yields item pairs, one at a time\ndef get_item_pairs(order_item):\n    order_item = order_item.reset_index().as_matrix()\n    for order_id, order_object in groupby(order_item, lambda x: x[0]):\n        item_list = [item[1] for item in order_object]\n              \n        for item_pair in combinations(item_list, 2):\n            yield item_pair\n            \n\n# Returns frequency and support associated with item\ndef merge_item_stats(item_pairs, item_stats):\n    return (item_pairs\n                .merge(item_stats.rename(columns={'freq': 'freqA', 'support': 'supportA'}), left_on='item_A', right_index=True)\n                .merge(item_stats.rename(columns={'freq': 'freqB', 'support': 'supportB'}), left_on='item_B', right_index=True))\n\n\n# Returns name associated with item\ndef merge_item_name(rules, item_name):\n    columns = ['itemA','itemB','freqAB','supportAB','freqA','supportA','freqB','supportB', \n               'confidenceAtoB','confidenceBtoA','lift']\n    rules = (rules\n                .merge(item_name.rename(columns={'item_name': 'itemA'}), left_on='item_A', right_on='item_id')\n                .merge(item_name.rename(columns={'item_name': 'itemB'}), left_on='item_B', right_on='item_id'))\n    return rules[columns]   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b45b462ae1d6be05c9016403de9ed437e8c92a80"},"cell_type":"code","source":"def association_rules(order_item, min_support):\n\n    print(\"Starting order_item: {:22d}\".format(len(order_item)))\n\n\n    # Calculate item frequency and support\n    item_stats             = freq(order_item).to_frame(\"freq\")\n    item_stats['support']  = item_stats['freq'] / order_count(order_item) * 100\n\n\n    # Filter from order_item items below min support \n    qualifying_items       = item_stats[item_stats['support'] >= min_support].index\n    order_item             = order_item[order_item.isin(qualifying_items)]\n\n    print(\"Items with support >= {}: {:15d}\".format(min_support, len(qualifying_items)))\n    print(\"Remaining order_item: {:21d}\".format(len(order_item)))\n\n\n    # Filter from order_item orders with less than 2 items\n    order_size             = freq(order_item.index)\n    qualifying_orders      = order_size[order_size >= 2].index\n    order_item             = order_item[order_item.index.isin(qualifying_orders)]\n\n    print(\"Remaining orders with 2+ items: {:11d}\".format(len(qualifying_orders)))\n    print(\"Remaining order_item: {:21d}\".format(len(order_item)))\n\n\n    # Recalculate item frequency and support\n    item_stats             = freq(order_item).to_frame(\"freq\")\n    item_stats['support']  = item_stats['freq'] / order_count(order_item) * 100\n\n\n    # Get item pairs generator\n    item_pair_gen          = get_item_pairs(order_item)\n\n\n    # Calculate item pair frequency and support\n    item_pairs              = freq(item_pair_gen).to_frame(\"freqAB\")\n    item_pairs['supportAB'] = item_pairs['freqAB'] / len(qualifying_orders) * 100\n\n    print(\"Item pairs: {:31d}\".format(len(item_pairs)))\n\n\n    # Filter from item_pairs those below min support\n    item_pairs              = item_pairs[item_pairs['supportAB'] >= min_support]\n\n    print(\"Item pairs with support >= {}: {:10d}\\n\".format(min_support, len(item_pairs)))\n\n\n    # Create table of association rules and compute relevant metrics\n    item_pairs = item_pairs.reset_index().rename(columns={'level_0': 'item_A', 'level_1': 'item_B'})\n    item_pairs = merge_item_stats(item_pairs, item_stats)\n    \n    item_pairs['confidenceAtoB'] = item_pairs['supportAB'] / item_pairs['supportA']\n    item_pairs['confidenceBtoA'] = item_pairs['supportAB'] / item_pairs['supportB']\n    item_pairs['lift']           = item_pairs['supportAB'] / (item_pairs['supportA'] * item_pairs['supportB'])\n    \n    \n    # Return association rules sorted by lift in descending order\n    return item_pairs.sort_values('lift', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"556d555f6eb18752e1e50b0613553525c5b3f1c3"},"cell_type":"code","source":"%%time\nrules = association_rules(orders, 0.3)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cafce2dc934e26b067cb7a89e8e4b2c293b68902"},"cell_type":"code","source":"rules.sort_values('supportAB', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e256ec15f7dc92670676a0f71341a8b6aca4cecd"},"cell_type":"code","source":"orders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbc2c209e701e4671406deccbfe8dd36551f2299"},"cell_type":"code","source":"orders=orders.reset_index()\norders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b79b6cf746338a5035004c79f60d2d851c89d962"},"cell_type":"code","source":"from mlxtend.frequent_patterns import apriori # Data pattern exploration\nfrom mlxtend.frequent_patterns import association_rules # Association rules conversion\nfrom mlxtend.preprocessing import OnehotTransactions # Transforming dataframe for apriori\n\n#basket_sets = \norders['teller']=1.0\nbasket_sets=pd.pivot_table(orders, columns='item_id', index='Transaction', values='teller')\nbasket_sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aab747d5dbf1c7a68345f1d7768b6b5558e10f9c"},"cell_type":"code","source":"# Apriori aplication: frequent_itemsets\n# Note that min_support parameter was set to a very low value, this is the Spurious limitation, more on conclusion section\nfrequent_itemsets = apriori(basket_sets.fillna(0), min_support=0.053, use_colnames=True)\nfrequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n\n# Advanced and strategical data frequent set selection\nfrequent_itemsets[ (frequent_itemsets['length'] > 2) &\n                   (frequent_itemsets['support'] >= 0.12) ].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0ff8ee18be0df7f001980cc2e31da66d7629fa6"},"cell_type":"code","source":"# Generating the association_rules: rules\n# Selecting the important parameters for analysis\nrules2 = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\nrules2[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values('support', ascending=False).head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"214dad2e96a64220ff6a44a0fc2e38fa7cba838c"},"cell_type":"code","source":"rules2.plot.scatter(x='antecedent support',y='consequent support',c='lift',colormap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d734bccdeb13666637409d551476f085bed20730"},"cell_type":"markdown","source":"https://paginas.fe.up.pt/~ec/files_1112/week_04_Association.pdf\n\nPS (or Leverage):\n is the proportion of additional elements covered by both the\npremise and consequence above the expected if independent.\n\nConviction\n conviction of X=>Y can be interpreted as the\n ratio of the expected frequency that X occurs without Y (that is to\nsay, the frequency that the rule makes an incorrect prediction) if\nX and Y were independent\n divided by the observed frequency of incorrect predictions.\n A conviction value of 1.2 shows that the rule would be incorrect\n20% more often (1.2 times as often) if the association between X\nand Y was purely random chance."},{"metadata":{"trusted":true,"_uuid":"1207444c5c0bb193d01dbd10700c1f534f8c0c82"},"cell_type":"code","source":"rules2.sort_values('conviction', ascending=False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}