{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Intro**\n\nI've seen so many mock drafts touting combine numbers and key thresholds for various positions and I wanted to see if there was data to back any of them up. In order to do that, I am using combine data since 2000 to attempt to predict which round a player will end up in given nothing but their drill results and their positional group. I am not expecting great results from these models (especially for some positions), but I think the structure of the trees can be highly informative. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import tree\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport graphviz\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\npd.options.mode.chained_assignment = None\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**Data**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"comb_dat = pd.read_csv(\"../input/combine_data_since_2000_PROCESSED_2018-04-26.csv\")\ncomb_dat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is from combines since 2000. Unfortunately the 2018 players do not have their round labels so I am excluding them. I am treating all undrafted players as Round 8 picks to allow us to make this a regression problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"comb_dat['Round'].fillna(8.0, inplace = True)\ncomb_dat['Pick'].fillna(300.0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comb_dat.groupby('Pos').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comb_dat.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I grouped some of the positions that had smaller counts into larger groups. This is my best guess for how to categorize these into better groups. I also excluded Kickers, Punters, Fullbacks, and Long Snappers."},{"metadata":{"trusted":true},"cell_type":"code","source":"comb_dat.loc[:,'Pos']=comb_dat.Pos.replace({'C':'IOL','G':'IOL','OG':'IOL','OL':'IOL'\n                                            ,'NT':'DT',\n                                            'EDGE':'OLB',\n                                            'DB':'S','SS':'S','FS':'S',\n                                            'LB':'ILB'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comb_dat=comb_dat.loc[~comb_dat.Pos.isin(['K','P','FB','LS']),:]\ncomb_dat=comb_dat.loc[comb_dat.Year<2018,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comb_dat.groupby('Pos').count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model**"},{"metadata":{},"cell_type":"markdown","source":" If any drill had more than 50% of participants not participate, I removed the drill from the model. Otherwise, I filled null values with the median value for that drill. I also recorded the breakdown of the rounds for the players in the group. I then built position-specific decision trees to try show model performance and each drill's importance by position group. I tried to limit the trees from getting to large by putting a low max-depth (5) and high leaf fraction (0.04). These hyperparmaters could definitely be optimized for better performance but I'm more interested in easy to interpret trees. I optimized on MAE since their is considerable skewness for most positions (~40% of combine invitees go undrafted). I performed 10-fold CV and recorded the mean, median, min, and max MAEs for the 10 runs.  The summarized table is shown below."},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\npos=comb_dat.Pos.unique()\n\nfor posi in pos:\n\n    row_dict={'Pos':[np.nan],\n\n              'Count':[np.nan],\n              \n              'mean_mae':[np.nan],\n              'med_mae':[np.nan],\n              'max_mae':[np.nan],\n              'min_mae':[],\n\n              'Ht_imp':[np.nan],\n              'Wt_imp':[np.nan],\n              'Forty_imp':[np.nan],\n              'Vertical_imp':[np.nan],\n              'BenchReps_imp':[np.nan],\n              'BroadJump_imp':[np.nan],\n              'Cone_imp':[np.nan],\n              'Shuttle_imp':[np.nan],\n\n              'Ht_med':[np.nan],\n              'Wt_med':[np.nan],\n              'Forty_med':[np.nan],\n              'Vertical_med':[np.nan],\n              'BenchReps_med':[np.nan],\n              'BroadJump_med':[np.nan],\n              'Cone_med':[np.nan],\n              'Shuttle_med':[np.nan],\n\n              'Round1':[np.nan],\n              'Round2':[np.nan],\n              'Round3':[np.nan],\n              'Round4':[np.nan],\n              'Round5':[np.nan],\n              'Round6':[np.nan],\n              'Round7':[np.nan],\n              'Undrafted':[np.nan]\n             }\n\n\n\n    #posi='WR'\n    mod_vars=['Ht', 'Wt', 'Forty', 'Vertical', 'BenchReps',\n           'BroadJump', 'Cone', 'Shuttle']\n    pos_dat=comb_dat[comb_dat.Pos==posi]\n    na_sum=pos_dat.loc[:,mod_vars].isna().sum()\n\n    droppers=na_sum[na_sum>pos_dat.shape[0]/2].index\n    #print(droppers)\n    for drop in droppers:\n        #print(drop)\n        mod_vars.remove(drop)\n\n    na_fill=pos_dat[mod_vars].quantile(.5).to_dict()\n    pos_dat=pos_dat.fillna(na_fill)\n    #print(pos_dat[mod_vars].isna().sum())\n    pos_tree=tree.DecisionTreeRegressor(criterion='mae',max_depth=5,min_weight_fraction_leaf=.04,random_state=214)\n    cv_scores=abs(cross_val_score(pos_tree,pos_dat[mod_vars],pos_dat['Round'],cv=10,scoring='neg_median_absolute_error'))\n\n    round_count=pos_dat.groupby('Round').Player.count()\n    round_count=round_count/pos_dat.shape[0]\n    pos_tree=pos_tree.fit(pos_dat[mod_vars],pos_dat['Round'])\n\n    row_dict['Pos']=[posi]\n    row_dict['Count']=[pos_dat.shape[0]]\n\n    row_dict['mean_mae']=[np.mean(cv_scores)]\n    row_dict['med_mae']=[np.median(cv_scores)]\n    row_dict['min_mae']=[np.min(cv_scores)]\n    row_dict['max_mae']=[np.max(cv_scores)]\n\n    row_dict.update(dict(zip([i+'_imp' for i in mod_vars],[[i] for i in pos_tree.feature_importances_])))\n    row_dict.update(dict(zip([i+'_med' for i in mod_vars],[[i] for i in list(na_fill.values())])))\n    row_dict.update(dict(zip(['Round1','Round2','Round3','Round4','Round5','Round6','Round7','Undrafted'],[[i] for i in round_count.values])))\n\n    if i==0:\n        row_frame=pd.DataFrame.from_dict(row_dict)\n        i+=1\n    else:\n        row_frame=row_frame.append(pd.DataFrame.from_dict(row_dict),ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Results**"},{"metadata":{},"cell_type":"markdown","source":"The table below is sorted by model performance. The approach performed best on DEs and RBs. Performance declines pretty considerably from there. I was expecting QB model performance to be horrible, but somehow it performs a bit better than the DT model."},{"metadata":{"trusted":true},"cell_type":"code","source":"row_frame.sort_values('mean_mae')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos=row_frame.sort_values('mean_mae',ascending=False).Pos.values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The function below produces model summary data from above as well as the most over-drafted and under-drafted for each position. It also renders the tree."},{"metadata":{"trusted":true},"cell_type":"code","source":"def render_sum(posi):\n    print('{} Model Summary'.format(posi))\n    display(row_frame.loc[row_frame['Pos']==posi,:])\n    \n    mod_vars=['Ht', 'Wt', 'Forty', 'Vertical', 'BenchReps',\n               'BroadJump', 'Cone', 'Shuttle']\n    pos_dat_raw=comb_dat.loc[comb_dat.Pos==posi,:]\n    pos_dat=pos_dat_raw.copy()\n    na_sum=pos_dat.loc[:,mod_vars].isna().sum()\n\n    droppers=na_sum[na_sum>pos_dat.shape[0]/2].index\n        #print(droppers)\n    for drop in droppers:\n            #print(drop)\n        mod_vars.remove(drop)\n\n    na_fill=pos_dat.loc[:,mod_vars].quantile(.5).to_dict()\n    pos_dat=pos_dat.fillna(na_fill)\n\n\n    pos_tree=tree.DecisionTreeRegressor(criterion='mae',max_depth=5,min_weight_fraction_leaf=.04,random_state=214)\n    pos_tree.fit(pos_dat.loc[:,mod_vars],pos_dat.loc[:,'Round'])\n    preds=pos_tree.predict(pos_dat.loc[:,mod_vars])\n    #print(preds)\n    pos_dat_raw.loc[:,'pred_Round']=preds\n    pos_dat_raw.loc[:,'res']=pos_dat_raw.loc[:,'Round']-pos_dat_raw.loc[:,'pred_Round']\n\n    showvars=['Pos','Player','Year','Team']+mod_vars+['Round','pred_Round']\n    print('Top 10 Underdrafted {}:'.format(posi))\n    display(pos_dat_raw.sort_values(['res','Year'],ascending=[False,False])[showvars].head(10))\n    print('Top 10 Overdrafted {}:'.format(posi))\n    display(pos_dat_raw.sort_values(['res','Year'],ascending=[True,False])[showvars].head(10))\n\n\n    dot_data = tree.export_graphviz(pos_tree, out_file=None, \n                         feature_names=mod_vars,  \n                         class_names=['1','2','3','4','5','6','7','8'],\n                         filled=True, rounded=True,  \n                         special_characters=True)  \n    graph = graphviz.Source(dot_data)  \n    return(graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tree Deep Dive**"},{"metadata":{},"cell_type":"markdown","source":"**Defensive Tackles**  "},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[0])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"None of the underdrafted players jump out, it's not like there are any diamonds in the rough that were missed for this position group.\nAlso, it looks like many of the players that the model considered overdrafted are studs in the making (Jonathan Allen, Robert Nkemdiche). The tree itself seems to priortize the forty times and size. Weird that a low vertical can be an indicator of a lower pick? This model performed the worst, so it's unsurprising that the cut points seem a bit illogical. It looks like the top 40 split basically breaks the group into quick strong players and space eaters. Size becomes very important for players with bad 40 times."},{"metadata":{},"cell_type":"markdown","source":"**QB**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[1])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems absurd to draft a QB based on combine stats. Height and Vertical(???) are the most important variables. Hopefully Kyler gets rid of that quesitonable measuring stick. Also, kinda great that it lumps in Johnny Football with Aaron Rogers as the most overdrafted players in the data set. This model is a disaster (as expected)."},{"metadata":{},"cell_type":"markdown","source":"**Safety**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[2])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Forty times are huge for safeties, with the top breakpoint basically deciding the odds of a player getting drafted. A sub 4.4 seems to indicate an elite athlete for the position. For those who lack elite speed,weight and the cone drill become very important. Interestingly, Thomas Davis worked out as a Safety. Converting to a linebacker makes sense for someone with his size/speed profile."},{"metadata":{},"cell_type":"markdown","source":"**Offensive Tackles**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ng=render_sum(pos[3])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model actually corrected identified two pretty prominent busts, Jeff Otah and Luke Joeckel, but it whiffed on Sam Baker, who was a beast for Atlanta. Interestingly, it still has forty time as a key predictor along with weight. 305 is a big break pont, with players under that threshold having a hard time getting drafted (unless they run a sub 5 forty)."},{"metadata":{},"cell_type":"markdown","source":"**Inside Linebacker**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[4])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No big steals in the underdrafted department. Also it whiffed on Brandon Spikes and Luke Kuechly(Kuechly seems way faster than 4.58???). Players who ran <4.76 40 and had a >32 vertical typically heard their names called the earliest. This tree seems a bit overfit, showing that the heighest drafted players get under 26 reps on bench??. Could use some pruning"},{"metadata":{},"cell_type":"markdown","source":"**Wide Receiver**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[5])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yet again, 40 is king, this time with a way lower break point. There are actually some interesting rules here, like the idea tht you want your burner WRs(sub 4.4) to weight atleast 185. Additionally, 4.4 receivers that are 6'2 and have a 36 inch vertical are very valuable(and also freaks). When you get above 4.5 the agility drills start to get more important. Guys like Miles Austin ended up being huge steals (didn't realize he had a 40 in vertical??)."},{"metadata":{},"cell_type":"markdown","source":"**Outside Linebacker**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[6])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cameron Wake turned into a beast but plays mostly DE now. Pretty accurate about Jarvis Jones and Mingo, they seemed like replaceable athletes. The 4.725 breakpoint is a huge key in wheater someone gets drafted as an OLB. Broad Jump is also important for this group. A sub 4.72 40 who weights 250 and had a 4.3 shuttle time is more than likely a Round 1 pick."},{"metadata":{},"cell_type":"markdown","source":"**Tight End**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[7])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"40 times are big again, this time with higher thresholds. Additionally, the bench reps are pretty prominent for this group. Hunter Henery and Zach Ertz have surprisingly underwhelming combine numbers. Also I finally understand why the Cowboys drafted James Hanna, his combine numbers were absurd. "},{"metadata":{},"cell_type":"markdown","source":"**Cornerback**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[8])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"None of these names jump out. Some of the overdrafted players definitely ended up being flops. The 40 is king again, and interestingly the cone drill. Being over 200 is also important. Bigger corners have a bit more wiggle room on the 40 time, but the highest drafted guys are typically 4.4 range."},{"metadata":{},"cell_type":"markdown","source":"**Interior Offensive Linemen**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[9])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cone Drill is huge in evaluation of these bullies, along with weight. Again, 305 is a big break point for a player's draft position. \n\n"},{"metadata":{},"cell_type":"markdown","source":"**Running Backs**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[10])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Forty time, weight, and broad jump are key evaluators for the runningback group. Burners that are sub 4.45 and over 213 lbs are of high value.  For guys in the 4.5 range, broad jump becomes critical. Mark Ingram and Lesen McCoy have carved out solid careers but would probably not be a Rd. 1 player if they redid their drafts. Cedric Benson was a massive overdraft."},{"metadata":{},"cell_type":"markdown","source":"**Defensive Ends**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g=render_sum(pos[11])\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Forty and weight are again the main deciders. Justin Tuck and Jared Allen both probably belonged in their respected drafts, but it's hard to say for Tuck based on the combine since he only participated in the 40. Demarcus Lawrence had a failry underwhelming combine but has turned into a monster in the past few years. If you are 6'2\"+, 260+, and run under 4.7, congrats, you're probably going in the first round. ~4.7 seems to be the magic number for a lot of these break points."},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nObviously this model has its flaws, but it also provides some interesting cut points for the type of athlete a given player is. If the apple of your eye has similar numbers to guys that end up going undrafted, you may want to wait around to see if they fall. If you see an elite athlete sliding, maybe take a chance on their upside.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}