{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nsns.set_style(\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/car-dekho-data/car data.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num = data.select_dtypes(include=[np.float64, np.int64])\nprint(\"Columns with numerical data:\")\nfor col in df_num.columns:\n    print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat = data.select_dtypes(include = ['object'])\nprint(\"Columns with categorical data:\")\nfor col in df_cat.columns:\n    print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between numerical columns\nplt.figure(figsize = (10,8))\nsns.heatmap(data.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is strong correlation between Present Price of car and Selling Price of car which is obvious. Also there is good correlation between Year and Selling Price"},{"metadata":{},"cell_type":"markdown","source":"### Univarate data Analysis of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_bar(column):\n    plt.figure(figsize = (12,5))\n    sns.countplot(data[column])\n    plt.title(column, fontsize = 20)\n    plt.xticks(fontsize = 14)\n    plt.xlabel('')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['company','Fuel_Type','Seller_Type','Transmission']:\n    plot_bar(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hist(column):\n    plt.figure(figsize = (12,5))\n    sns.distplot(data[column])\n    plt.title(column, fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['Year','Selling_Price','Present_Price','Kms_Driven']:\n    plot_hist(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Car sold by Owner number\\n{}\".format(data[\"Owner\"].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of car sold have only one previous owner. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of cars sold through dealers: {}\".format(data.loc[data.Seller_Type == 'Dealer']['Seller_Type'].value_counts().sum()))\nprint(\"Number of cars sold without dealers: {}\".format(data.loc[data.Seller_Type == 'Individual']['Seller_Type'].value_counts().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of cars with manual transmission: {}\".format(data.loc[data.Transmission == 'Manual']['Car_Name'].value_counts().sum()))\nprint(\"Total number of cars with automatic transmission : {}\".format(data.loc[data.Transmission == 'Automatic']['Car_Name'].value_counts().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Most Popular car Companys\\n{}\".format(data[\"company\"].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Most sold cars\\n{}\".format(data[\"Car_Name\"].value_counts().nlargest(15)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bivariate Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,8))\nsns.boxplot(x = data[\"Selling_Price\"], y = data[\"Seller_Type\"])\nplt.ylabel(\"Seller_Type\",fontsize = 15)\nplt.xlabel(\"Selling_Price\", fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of Car sold by dealers generally get higher Price than sold by individuals"},{"metadata":{},"cell_type":"markdown","source":"Car are sold generally through a dealer"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.boxplot(x = data[\"Selling_Price\"], y = data[\"Fuel_Type\"])\nplt.ylabel(\"Fuel Type\",fontsize = 15)\nplt.yticks(fontsize = 14)\nplt.xlabel(\"Selling_Price\", fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is Clear from boxplot that generally Diesel Type car are sold at higher price. Mean selling Price of Diesel Price is higher than Petrol type cars . While Boxplot of CNG cars is like a line, it shows only few CNG car are sold"},{"metadata":{},"cell_type":"markdown","source":"Petrol Type car are most sold but price of diesel car is higher than others."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.boxplot(x = data[\"Selling_Price\"], y = data[\"Transmission\"])\nplt.ylabel(\"Transmission\",fontsize = 15)\nplt.yticks(fontsize = 14)\nplt.xlabel(\"Selling_Price\", fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Car with automatic transmission have a large range of sales and third quarter of it is quite big. It shows that many of cars sold falls in this range. There is in comprasion small difference between median of Manual and Automatic Cars, because some Manual Car are sold at very high Price."},{"metadata":{},"cell_type":"markdown","source":"More than 250 car sold are manual while less than 50 are Automatic"},{"metadata":{"trusted":true},"cell_type":"code","source":"keys = [year for year, df in data.groupby([\"Year\"])]\nplt.figure(figsize = (14,8))\nsns.barplot(keys, data.groupby([\"Year\"]).count()[\"Car_Name\"])\nplt.xlabel(\"Year\",fontsize = 15)\nplt.ylabel(\"Number of car sold\",fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Car_Name'].value_counts().nlargest(10).plot(kind = 'bar', figsize = (14,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,3, figsize = (18,7))\ndf = data.loc[~data.company.isin(['bajaj','hero','yamaha','tvs'])]\ndf1 = data.loc[data.company.isin(['bajaj','hero','yamaha','tvs'])]\nsns.histplot(data[\"Selling_Price\"], ax = axes[0])\nsns.histplot(df[\"Selling_Price\"], ax = axes[1])\nsns.histplot(df1[\"Selling_Price\"], ax = axes[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,7))\nsns.histplot(df[\"Selling_Price\"], color = 'blue',label = 'Cars')\nsns.histplot(df1[\"Selling_Price\"], color = 'red', label = 'Two whellers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chosing some features to train  the models on\nX = data.loc[:,[\"Year\",\"Kms_Driven\",\"Fuel_Type\",\"Seller_Type\",\"Transmission\",\"Owner\"]]\ny = data.loc[:,['Selling_Price']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Label Encoding \nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfor col in ['Fuel_Type','Seller_Type','Transmission']:\n    X_train[col] = encoder.fit_transform(X_train[col])\n    X_test[col] = encoder.transform(X_test[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data After Applying Label Encoder becomes numerical. Because Linear Regression and SVM models don't work on categorical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Standard Scaler\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train.loc[:,['Year','Kms_Driven']] = scaler.fit_transform(X_train.loc[:,['Year','Kms_Driven']])\nX_test.loc[:,['Year','Kms_Driven']] = scaler.transform(X_test.loc[:,['Year','Kms_Driven']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation\nfrom sklearn.model_selection import cross_val_score\ndef val_score(model, X, y):\n    score = -1*cross_val_score(model, X, y, cv = 5, scoring = 'neg_mean_squared_error')\n    print(\"RMSE  : {}\".format(np.sqrt(score)))\n    print(\"Average error : {}\".format(np.sqrt(score.mean())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ndef plot_learning_curves(model, X, y, ylim = None):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n    train_errors, val_errors = [], []\n    for m in range(1, len(X_train)):\n        model.fit(X_train[:m], y_train[:m])\n        y_train_predict = model.predict(X_train[:m])\n        y_val_predict = model.predict(X_val)\n        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n        val_errors.append(mean_squared_error(y_val_predict, y_val))\n    plt.figure(figsize = (10,7))\n    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n    plt.xlabel(\"Training set size\")\n    plt.ylabel(\"RMSE\")\n    plt.ylim(ylim)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing Models perfomance with their default features"},{"metadata":{},"cell_type":"markdown","source":"## 1.Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlinear_reg = LinearRegression()\nval_score(linear_reg, X_train, y_train)\nplot_learning_curves(linear_reg, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error of Decision Tree on train set and Test set\nlinear_reg.fit(X_train, y_train)\n\nprediction_train = linear_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = linear_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clearly Linear Regression model is Underfiting as train error is greater than val error"},{"metadata":{},"cell_type":"markdown","source":"## 2.SVM Linear"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVR\nlinear_svr = LinearSVR()\nval_score(linear_svr, X_train, y_train)\nplot_learning_curves(linear_svr, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.SVM Kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nsvr_reg = SVR(kernel = 'rbf')\nval_score(svr_reg, X_train, y_train)\nplot_learning_curves(svr_reg, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This Model is also underfitting, as train error and test error both are high.SVM Kernel works better when training data have more features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\nval_score(tree_reg, X_train, y_train)\nplot_learning_curves(tree_reg, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error of Decision Tree on train set and Test set\ntree_reg.fit(X_train, y_train)\n\nprediction_train = tree_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = tree_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree is too complex and overfitting. It predicts nearly perfect values for Train data but performing very poor on test data. Using more data and hyperparameters tunning  can make it better."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nval_score(rf_reg, X_train, y_train)\nplot_learning_curves(rf_reg, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Learning Curve of Random Forest model seems better. Adding more data can make it better as its curves are going down"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error of Random Forest on train set and Test set\nrf_reg.fit(X_train, y_train)\n\nprediction_train = rf_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = rf_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest seems best model according to learning curves. \n### So let's apply grid search to chose best hyperparameters for it."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = [\n{'n_estimators': [3, 10, 30, 100, 300], 'max_features': [2, 4, 6, 8,10]},\n{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n]\nforest_reg = RandomForestRegressor()\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=3,\nscoring='neg_mean_squared_error')\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best parameters\",grid_search.best_params_)\nprint(\"Best Estimators\",grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_reg = RandomForestRegressor(max_features = 2, n_estimators = 30)\nforest_reg.fit(X_train, y_train)\n\nprediction_train = forest_reg.predict(X_train)\ntrain_error = mean_squared_error(prediction_train, y_train)\n\nprediction_test = forest_reg.predict(X_test)\ntest_error = mean_squared_error(prediction_test, y_test)\n\nprint(\"Error on training set\", train_error)\nprint(\"Error on test set\",test_error )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}