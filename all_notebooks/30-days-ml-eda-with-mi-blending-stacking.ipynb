{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-31T12:54:37.84058Z","iopub.execute_input":"2021-08-31T12:54:37.841045Z","iopub.status.idle":"2021-08-31T12:54:41.020001Z","shell.execute_reply.started":"2021-08-31T12:54:37.840931Z","shell.execute_reply":"2021-08-31T12:54:41.018759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cal_mi_score(X,y):\n    X = X.copy()\n    X.drop('id', axis=1, inplace=True)\n    for col in X.select_dtypes(['object']):\n        X[col],unique = X[col].factorize()\n    discrete_features = X.dtypes == int\n    mi_scores = mutual_info_regression(X,y,discrete_features=discrete_features, random_state=42)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.figure(figsize=(10,7))\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n    \ndf_eda = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\ntarget = df_eda.pop('target')\nscores = cal_mi_score(df_eda,target)\nplot_mi_scores(scores)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:04:51.715308Z","iopub.execute_input":"2021-08-31T12:04:51.715788Z","iopub.status.idle":"2021-08-31T12:08:28.318374Z","shell.execute_reply.started":"2021-08-31T12:04:51.715754Z","shell.execute_reply":"2021-08-31T12:08:28.31731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Why using Mutual Information to find any relation between feature and target ?\nAns: Actually mutual information can predict any kind of relationship while correlation just predict the linear relation \n     between features and target\n     \n **You can see that `cont12` and `cont10` are more related to target than other features**","metadata":{}},{"cell_type":"markdown","source":"# ***Blending + Stacking***\n### - **I used 5 models with different hyperparameters and features for blending**\n>     - Ordinal encoder + standardization\n>     - Ordinal encoder + standardization (diff hyperparameters)\n>     - target encoding + standardization \n>     - one hot encoding + standardization\n>     - LGBRegressor","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nfor n in range(1,6):\n    data = pd.read_csv(f\"../input/custompreddata/train_pred_{n}.csv\")\n    df = df.merge(data, on=\"id\", how=\"left\")\n    \nall_test_df = []\nfor n in range(1,6):\n    data = pd.read_csv(f'../input/custompreddata/test_pred_{n}.csv')\n    df_test = df_test.merge(data, on=\"id\", how=\"left\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:35:22.333282Z","iopub.execute_input":"2021-08-31T12:35:22.333616Z","iopub.status.idle":"2021-08-31T12:35:28.325489Z","shell.execute_reply.started":"2021-08-31T12:35:22.333587Z","shell.execute_reply":"2021-08-31T12:35:28.324516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### - **I used 3 different models for stacking**\n>     - XGBRegressor\n>     - RandomForestRegressor\n>     - LGBRegressor","metadata":{}},{"cell_type":"code","source":"# Meta model \n\nuseful_features = [col for col in df.columns if col.startswith('pred')]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    x_train = df[df.kfold != fold].reset_index(drop=True)\n    x_valid = df[df.kfold == fold].reset_index(drop=True)\n    x_test = df_test.copy()\n    \n    valid_ids = x_valid.id.values.tolist()\n    \n    y_train = x_train.target\n    y_valid = x_valid.target\n    \n    x_train = x_train[useful_features]\n    x_valid = x_valid[useful_features]\n    params = {'learning_rate': 0.07803392035787837, \n              'reg_lambda': 1.7549293092194938e-05, \n              'reg_alpha': 20.68267919457715, \n              'subsample': 0.8031450486786944, \n              'colsample_bytree': 0.170759104940733, \n              'max_depth': 3}\n   \n    model = XGBRegressor(random_state = fold,\n#                          tree_method=\"gpu_hist\",\n#                          gpu_id=0,\n#                          predictor=\"gpu_predictor\",\n                         n_estimators=5000,\n                         n_jobs = -1,\n                         **params)\n    model.fit(x_train,\n              y_train,\n              early_stopping_rounds=300,\n              eval_set=[(x_valid, y_valid)],\n              verbose=1000,\n             )\n    \n    preds_valid = model.predict(x_valid)\n    preds_test = model.predict(x_test)\n    final_test_predictions.append(preds_test)\n    final_valid_predictions.update(dict(zip(valid_ids,preds_valid)))\n    rmse = mean_squared_error(y_valid,preds_valid, squared=False)\n    scores.append(rmse)\n    print(fold,rmse)\n    \nprint(np.mean(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\",\"pred_4\"]\nfinal_valid_predictions.to_csv(\"level1_train_pred_4.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = ['id', 'pred_4']\nsample_submission.to_csv('level1_test_pred_4.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:08:33.026563Z","iopub.execute_input":"2021-08-31T12:08:33.02687Z","iopub.status.idle":"2021-08-31T12:10:42.799924Z","shell.execute_reply.started":"2021-08-31T12:08:33.02684Z","shell.execute_reply":"2021-08-31T12:10:42.798798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# meta model 2 \n\nuseful_features = [col for col in df.columns if col.startswith('pred')]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    x_train = df[df.kfold != fold].reset_index(drop=True)\n    x_valid = df[df.kfold == fold].reset_index(drop=True)\n    x_test = df_test.copy()\n    \n    valid_ids = x_valid.id.values.tolist()\n    \n    y_train = x_train.target\n    y_valid = x_valid.target\n    \n    x_train = x_train[useful_features]\n    x_valid = x_valid[useful_features]\n    \n    model = RandomForestRegressor(n_estimators=500, max_depth=3, n_jobs=-1,random_state=42)\n    model.fit(x_train,\n              y_train,)\n    \n    preds_valid = model.predict(x_valid)\n    preds_test = model.predict(x_test)\n    final_test_predictions.append(preds_test)\n    final_valid_predictions.update(dict(zip(valid_ids,preds_valid)))\n    rmse = mean_squared_error(y_valid,preds_valid, squared=False)\n    scores.append(rmse)\n    print(fold,rmse)\n    \nprint(np.mean(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\",\"pred_5\"]\nfinal_valid_predictions.to_csv(\"level1_train_pred_5.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = ['id', 'pred_5']\nsample_submission.to_csv('level1_test_pred_5.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:10:42.801638Z","iopub.execute_input":"2021-08-31T12:10:42.801957Z","iopub.status.idle":"2021-08-31T12:17:28.510144Z","shell.execute_reply.started":"2021-08-31T12:10:42.801898Z","shell.execute_reply":"2021-08-31T12:17:28.509149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# meta model 3\n\nuseful_features = [col for col in df.columns if col.startswith('pred')]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    x_train = df[df.kfold != fold].reset_index(drop=True)\n    x_valid = df[df.kfold == fold].reset_index(drop=True)\n    x_test = df_test.copy()\n    \n    valid_ids = x_valid.id.values.tolist()\n    \n    y_train = x_train.target\n    y_valid = x_valid.target\n    \n    x_train = x_train[useful_features]\n    x_valid = x_valid[useful_features]\n    params = {\n        'max_depth':3,\n        'colsample_bytree': 0.4,  \n        'learning_rate': 0.1,  \n        'min_child_weight': 1,  \n        'reg_alpha': 10.0,  \n        'reg_lambda': 1.0,  \n        'subsample': 0.7266579209776919,\n        'random_state': 42\n    }\n    model = lgb.LGBMRegressor(**params)\n    model.fit(x_train, y_train,)\n    \n    preds_valid = model.predict(x_valid)\n    preds_test = model.predict(x_test)\n    final_test_predictions.append(preds_test)\n    final_valid_predictions.update(dict(zip(valid_ids,preds_valid)))\n    rmse = mean_squared_error(y_valid,preds_valid, squared=False)\n    scores.append(rmse)\n    print(fold,rmse)\n    \nprint(np.mean(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\",\"pred_6\"]\nfinal_valid_predictions.to_csv(\"level1_train_pred_6.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = ['id', 'pred_6']\nsample_submission.to_csv('level1_test_pred_6.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:35:31.625463Z","iopub.execute_input":"2021-08-31T12:35:31.625816Z","iopub.status.idle":"2021-08-31T12:35:37.139096Z","shell.execute_reply.started":"2021-08-31T12:35:31.625786Z","shell.execute_reply":"2021-08-31T12:35:37.138156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **I uploaded my blending + stacking data into 2 datasets**\n> **`level-data` and**\n> **`custompreddata`**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nfor n in range(1,4):\n    d = pd.read_csv(f'../input/level-data/level1_train_pred_{n}.csv')\n    df = df.merge(d, on=\"id\", how=\"left\")\n\n\nfor n in range(1,4):\n    d = pd.read_csv(f'../input/level-data/level1_test_pred_{n}.csv')\n    df_test = df_test.merge(d, on=\"id\", how=\"left\")\n    \n    \nfor n in range(4,7):\n    d = pd.read_csv(f'../input/custompreddata/level1_train_pred_{n}.csv')\n    df = df.merge(d, on=\"id\", how=\"left\")\n\n\nfor n in range(4,7):\n    d = pd.read_csv(f'../input/custompreddata/level1_test_pred_{n}.csv')\n    df_test = df_test.merge(d, on=\"id\", how=\"left\")  ","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:55:03.872511Z","iopub.execute_input":"2021-08-31T12:55:03.872874Z","iopub.status.idle":"2021-08-31T12:55:11.176127Z","shell.execute_reply.started":"2021-08-31T12:55:03.872843Z","shell.execute_reply":"2021-08-31T12:55:11.175129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [f'pred_{n}' for n in range(1,7) if n not in [5]]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    enc = preprocessing.StandardScaler()\n    df[useful_features] = enc.fit_transform(df[useful_features])\n    df_test[useful_features] = enc.transform(df_test[useful_features])\n    \n    model = LinearRegression()\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:55:13.417847Z","iopub.execute_input":"2021-08-31T12:55:13.418233Z","iopub.status.idle":"2021-08-31T12:55:16.852698Z","shell.execute_reply.started":"2021-08-31T12:55:13.418189Z","shell.execute_reply":"2021-08-31T12:55:16.851662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T12:17:40.187275Z","iopub.execute_input":"2021-08-31T12:17:40.187668Z","iopub.status.idle":"2021-08-31T12:17:40.710444Z","shell.execute_reply.started":"2021-08-31T12:17:40.187627Z","shell.execute_reply":"2021-08-31T12:17:40.70949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}