{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/gld_price_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets have a quick look of dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clearly we see there is no null value in the dataset\n#Lets study the Statistical Inferance of the dataset\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now see the correlation matrix and heatmap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncorr = df.corr()\nplt.figure(figsize = (6,5))\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            annot=True,fmt='.2f',linewidths=0.30)\nplt.title('Correlation of df Features', y = 1.05, size=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look the correlation score\nprint (corr['GLD'].sort_values(ascending=False), '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets Check our target variable\nsns.distplot(df['GLD'], color = 'blue')\nprint('Skewness: %f', df['GLD'].skew())\nprint(\"Kurtosis: %f\" % df['GLD'].kurt())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we check the relation with GLD variable\nsns.jointplot(x =df['SLV'], y = df['GLD'], color = 'deeppink')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we check the relation with GLD variable\nsns.jointplot(x =df['SPX'], y = df['GLD'], color = 'purple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now Lets create a ml model\n# Now lets take our matrix of feature and target\nx_trail = df[['SPX','USO','SLV','EUR/USD']]\nx = x_trail.iloc[:, :].values\ny = df.iloc[:, 2].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Spliting the dataset into training and test set\nfrom sklearn.model_selection import train_test_split\ntest_ratio = 0.05\nlen_train = int(len(x) * (1-test_ratio))\nx_train, x_test, y_train, y_test = x[:len_train], x[len_train:], y[:len_train], y[len_train:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now fitting the Random forest regression to the traning set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\nregressor.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now predicting the test set result\ny_pred = regressor.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now Check the error for regression\nfrom sklearn import metrics\nprint('MAE :',\" \", metrics.mean_absolute_error(y_test,y_pred))\nprint('MSE :',\" \", metrics.mean_squared_error(y_test,y_pred))\nprint('RMAE :',\" \", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now Lets Check the Training and Test set Accuracy\naccuracy_train = regressor.score(x_train, y_train)\naccuracy_test = regressor.score(x_test, y_test)\nprint(accuracy_train)\nprint(accuracy_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualising the Accuracy of Predicted result\nplt.plot(y_test, color = 'blue', label = 'Acutal')\nplt.plot(y_pred, color = 'deeppink', label = 'Predicted')\nplt.grid(0.3)\nplt.title('Acutal vs Predicted')\nplt.xlabel('Number of Oberservation')\nplt.ylabel('GLD')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}