{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n!pip install pycaret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing our dataset\ndf=pd.read_csv('../input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Toh doston,Chaliye shuru karte hain \n# Let us start our EDA\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing values\ndf.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok so we have no missing values. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us seperate our target variable from the features so that we can build a model. We will be using a Supervised learning \n# approach in this notebook by making using of different classifiers, cross-validating,among other things.\n\n\nx=df.iloc[:,:-1].values\ny=df.target\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us look at x and y\n\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us look at the correlation of different features with the target variable\n\nmatrix=df.corr()\nsns.heatmap(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(matrix['target'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see features are not highly correlated with the target varibale. The max correlation is 0.433 for the feature namely 'cp'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let us now look at individual d=features in depth by using the pandas_profiling library. See below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = pp.ProfileReport(df, title='Heart Disease Dataset Report')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Go through the above report generated using pandas-profiling to get better insight about individual features.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us look at the skew of different features \nprint(df.skew())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us plot all the features except the one with binary values or repeating values ('I am doing this to viualise the variance in \n#  variance exhibited by other fetures')\n# Creating a new dataframe and dropping all the columns that are not required in the visual\ndf1=df.drop([ 'sex', 'cp',   'fbs', 'restecg', \n       'exang',  'slope', 'ca', 'thal'],axis=1)\nsns.pairplot(df1,hue='target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can use a log tranformation on the dataset to reduce the skew and try to transform the datset as closely as possible to a normal distribution. However let us first try by using some classification models and then let us see what we shall do next.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import * \nexp = setup(data = df, target = 'target', session_id=1,\n                  normalize = True,\n                categorical_features = [ 'sex', 'cp',  'fbs', 'restecg', \n       'exang',  'slope' , 'thal', ],\n                numeric_features=['age','trestbps','chol','thalach','oldpeak','ca'],\n                categorical_imputation='mode',\n                numeric_imputation='mean',\n            remove_outliers=True,\n            outliers_threshold=0.1,\n            normalize_method='robust',\n            feature_selection=True,\n            feature_selection_threshold=0.9,\n            remove_multicollinearity=True,\n            train_size=0.8\n            \n                )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So our PyCaret setup is now successful. I have set the train size at 80 % and teest size at 20%. You can play around with these values to find the ideal ratio. Let us now comapre our models.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see the results obtained were not that great.The maximum accuracy that we obtained was around 82 % with KNN classifier and a 10 fold cross validation. Let us see what happens if we dont remove the outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import * \nexp = setup(data = df, target = 'target', session_id=1,\n                  normalize = True,\n                categorical_features = [ 'sex', 'cp',  'fbs', 'restecg', \n       'exang',  'slope' , 'thal', ],\n                numeric_features=['age','trestbps','chol','thalach','oldpeak','ca'],\n                categorical_imputation='mode',\n                numeric_imputation='mean',\n            normalize_method='robust',\n            feature_selection=True,\n            feature_selection_threshold=0.9,\n            remove_multicollinearity=True,\n            train_size=0.8\n            \n                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An instant increase of 2% in the accuracy . Let us now use only a select few features based on their correlation and see if this affects our model in anyway.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}