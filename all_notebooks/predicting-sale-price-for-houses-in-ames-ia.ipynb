{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Predicting Sale Price for Houses in Ames, IA","metadata":{}},{"cell_type":"markdown","source":"I am using the Ames, Iowa dataset containing 2930 observations and 81 features related to house sale prices in Ames, Iowa. If you'd like to browse the various features, take a look at the features [here](http://jse.amstat.org/v19n3/decock/DataDocumentation.txt).\nThe plan is to train test split the housing data. Afterwards, regression and regularization will be used to compare and analyze the model predicting house prices for Amex, IA.","metadata":{}},{"cell_type":"markdown","source":"## 1) Load relevant packages","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import cm\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter as FF\nfrom matplotlib.ticker import StrMethodFormatter as SMF\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression as lr\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:18.954301Z","iopub.execute_input":"2021-05-30T05:03:18.954967Z","iopub.status.idle":"2021-05-30T05:03:20.068387Z","shell.execute_reply.started":"2021-05-30T05:03:18.954849Z","shell.execute_reply":"2021-05-30T05:03:20.067304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Load Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/ames-housing-dataset/AmesHousing.csv')\npd.set_option(\"display.max_columns\", None)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:20.069781Z","iopub.execute_input":"2021-05-30T05:03:20.070072Z","iopub.status.idle":"2021-05-30T05:03:20.199831Z","shell.execute_reply.started":"2021-05-30T05:03:20.07004Z","shell.execute_reply":"2021-05-30T05:03:20.198907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:20.201386Z","iopub.execute_input":"2021-05-30T05:03:20.201744Z","iopub.status.idle":"2021-05-30T05:03:20.317004Z","shell.execute_reply.started":"2021-05-30T05:03:20.201702Z","shell.execute_reply":"2021-05-30T05:03:20.316307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:20.3185Z","iopub.execute_input":"2021-05-30T05:03:20.318749Z","iopub.status.idle":"2021-05-30T05:03:20.344373Z","shell.execute_reply.started":"2021-05-30T05:03:20.318723Z","shell.execute_reply":"2021-05-30T05:03:20.343541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3) Data Cleaning and Feature Engineering\nAfter browsing the various features, the initial plan is to use the columns with little to no missing values. The features with a lot of missing values don't look like variables that have a huge impact on sale price. Various variables like bedroom count, lot area, year built, overall quality, and neighborhood will be plotted against sale price.","metadata":{}},{"cell_type":"code","source":"df_na = df.isna().sum().to_frame().sort_values(by = 0, axis = 0)\ndf_na = df_na.rename(columns={0: 'NA Count'})\ndf_na.T","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:20.345387Z","iopub.execute_input":"2021-05-30T05:03:20.345627Z","iopub.status.idle":"2021-05-30T05:03:20.385549Z","shell.execute_reply.started":"2021-05-30T05:03:20.345601Z","shell.execute_reply":"2021-05-30T05:03:20.384664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_columns = df_na[df_na['NA Count'] == 0].index.to_list()\ndf_clean = df[clean_columns]\ndf_clean.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:20.386809Z","iopub.execute_input":"2021-05-30T05:03:20.387082Z","iopub.status.idle":"2021-05-30T05:03:20.409806Z","shell.execute_reply.started":"2021-05-30T05:03:20.387054Z","shell.execute_reply":"2021-05-30T05:03:20.409117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"sns.set()\n#Graph 1\ng1 = sns.lmplot(data = df_clean, x = 'Lot Area', y = 'SalePrice', hue = 'Bedroom AbvGr',\n                  palette = 'viridis_r',ci = None, height = 9, aspect = 16 / 9)\n\n#Axes.\nax = plt.gca()\n\n#Title setup.\nax.set_title('Price vs Lot Area / # of Bedrooms', fontsize = 32)\n\n#X-axis setup.\nax.set_xlabel(\"Lot Area (sq. ft.)\", fontsize = 24)\nax.set_xscale('log')\nxlabels = [2500, 5000, 10000, 20000, 40000, 80000, 160000, 320000]\nax.set_xticks(xlabels)\nax.set_xticklabels(xlabels, rotation = 45,ha = 'right')\nax.get_xaxis().set_major_formatter(FF(lambda x, p: format(int(x), ',')))\n\n#Y-axis setup.\nax.set_ylabel(\"Price\", fontsize = 24)\nax.set_ylim(0,800000)\nax.yaxis.set_major_formatter(SMF('${x:,.0f}'))\nax.tick_params(axis = 'both', which = 'major', labelsize = 16)\n\n#Legend setup.\ng1._legend.remove()\nax.legend(loc = 'upper left', title = 'Bedrooms', ncol = 2, title_fontsize = 18, fontsize = 16);\n\n#Bedroom count\nbedroom_count = df_clean['Bedroom AbvGr'].value_counts().sort_index().to_frame().rename(columns = {'Bedroom AbvGr': \"# of Houses\"})\nbedroom_count.index.name = \"Number of Bedrooms\"\nbedroom_count.T","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:20.410926Z","iopub.execute_input":"2021-05-30T05:03:20.411352Z","iopub.status.idle":"2021-05-30T05:03:21.50493Z","shell.execute_reply.started":"2021-05-30T05:03:20.411322Z","shell.execute_reply":"2021-05-30T05:03:21.503994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph 2\ng2 = sns.lmplot(data = df_clean, x = 'Year Built', y = 'SalePrice', hue = 'Overall Qual',\n                  palette = 'viridis_r', ci=None, height = 9, aspect = 16 / 9)\n\n#Axes\nax = plt.gca()\n\n#Title\nax.set_title('Price vs Year Built / Overall Quality', fontsize = 32)\n\n#X-axis\nax.set_xlabel(\"Year Built\", fontsize = 24)\nax.set_xlim(1870, 2015)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 45, ha = 'right')\n\n#Y-axis\nax.set_ylabel(\"Price\", fontsize = 24)\nax.set_ylim(0, 800000)\nax.yaxis.set_major_formatter(SMF('${x:,.0f}'))\nax.tick_params(axis = 'both', which = 'major', labelsize = 16)\n\n#Legend\ng2._legend.remove()\nax.legend(loc = 'upper left', title = 'Overall House Quality', ncol = 2, title_fontsize = 18, fontsize = 16)\n\n#Overall house quality count\nneighborhood_count = df_clean['Overall Qual'].value_counts().sort_index().to_frame().rename(columns = {'Overall Qual': \"# of Houses\"})\nneighborhood_count.index.name = \"Overall Quality\"\nneighborhood_count.T","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:21.50766Z","iopub.execute_input":"2021-05-30T05:03:21.508033Z","iopub.status.idle":"2021-05-30T05:03:22.519528Z","shell.execute_reply.started":"2021-05-30T05:03:21.507993Z","shell.execute_reply":"2021-05-30T05:03:22.51864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph 3\nxlabels = df_clean.groupby(['Neighborhood'])['SalePrice'].median().sort_values().index\ng3 = sns.boxplot(data = df_clean, x = 'Neighborhood', y = 'SalePrice', palette = 'viridis_r', order = xlabels)\nplt.gcf().set_size_inches(16, 9)\n\n#Axes\nax = plt.gca()\n\n#Title\nax.set_title('Price vs Neighborhood', fontsize = 24)\n\n#X-axis\nax.set_xlabel(\"Neighborhood\", fontsize = 24)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 45, ha = 'right')\n\n#Y-axis\nax.set_ylabel(\"Price\", fontsize = 24)\nax.set_ylim(0, 800000)\nax.yaxis.set_major_formatter(SMF('${x:,.0f}'))\nax.tick_params(axis = 'both', which = 'major', labelsize = 16)\n\n#Neighborhood count\nneighborhood_count = df_clean['Neighborhood'].value_counts().sort_index().to_frame().rename(columns = {'Neighborhood': \"# of Houses\"})\nneighborhood_count.index.name = \"Neighborhood\"\nneighborhood_count.T","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:22.521372Z","iopub.execute_input":"2021-05-30T05:03:22.52183Z","iopub.status.idle":"2021-05-30T05:03:23.163197Z","shell.execute_reply.started":"2021-05-30T05:03:22.52179Z","shell.execute_reply":"2021-05-30T05:03:23.16251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph 4\ng4 = sns.violinplot(data = df_clean, x = 'Neighborhood', y = 'SalePrice', palette = 'viridis_r', scale = 'width', order = xlabels)\nplt.gcf().set_size_inches(16, 9)\n\n#Axes\nax = plt.gca()\n\n#Title\nax.set_title('Price vs Neighborhood', fontsize = 24)\n\n#X-axis\nax.set_xlabel(\"Neighborhood\", fontsize = 24)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 45, ha = 'right')\n\n#Y-axis\nax.set_ylabel(\"Price\", fontsize = 24)\nax.set_ylim(0, 800000)\nax.yaxis.set_major_formatter(SMF('${x:,.0f}'))\nax.tick_params(axis = 'both', which = 'major', labelsize = 16)\n\n#Neighborhood count\nneighborhood_count = df_clean['Neighborhood'].value_counts().sort_index().to_frame().rename(columns = {'Neighborhood': \"# of Houses\"})\nneighborhood_count.index.name = \"Neighborhood\"\nneighborhood_count.T","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:23.164122Z","iopub.execute_input":"2021-05-30T05:03:23.16447Z","iopub.status.idle":"2021-05-30T05:03:23.952298Z","shell.execute_reply.started":"2021-05-30T05:03:23.164441Z","shell.execute_reply":"2021-05-30T05:03:23.951637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph 5\ng5 = sns.heatmap(df_clean[['Lot Area','Overall Qual','Bedroom AbvGr','Overall Cond','Full Bath','Half Bath','1st Flr SF','2nd Flr SF','Pool Area','Open Porch SF','TotRms AbvGrd','Year Built','SalePrice']].corr(),cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:23.953176Z","iopub.execute_input":"2021-05-30T05:03:23.95352Z","iopub.status.idle":"2021-05-30T05:03:24.284701Z","shell.execute_reply.started":"2021-05-30T05:03:23.953493Z","shell.execute_reply":"2021-05-30T05:03:24.283988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph 6\ng6 = sns.histplot(data=df_clean,x='SalePrice')\nplt.gcf().set_size_inches(16, 9)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:24.285649Z","iopub.execute_input":"2021-05-30T05:03:24.286042Z","iopub.status.idle":"2021-05-30T05:03:24.580594Z","shell.execute_reply.started":"2021-05-30T05:03:24.286011Z","shell.execute_reply":"2021-05-30T05:03:24.579493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Graph 7\n#Housing prices log normalized\nnp.log1p(df_clean['SalePrice'])\ng7 = sns.histplot(data=df_clean,x=np.log1p(df_clean['SalePrice']))\nplt.gcf().set_size_inches(16, 9)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:24.582007Z","iopub.execute_input":"2021-05-30T05:03:24.582553Z","iopub.status.idle":"2021-05-30T05:03:24.875653Z","shell.execute_reply.started":"2021-05-30T05:03:24.582505Z","shell.execute_reply":"2021-05-30T05:03:24.874761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) Data Modeling","metadata":{}},{"cell_type":"markdown","source":"<b>Dropped Order and PID features because they're ID variables and log transformed the SalePrice.","metadata":{}},{"cell_type":"code","source":"df_final = df_clean.drop(['Order','PID'],axis=1)\ndf_final['SalePrice']=np.log1p(df_clean['SalePrice'])\ndf_final.set_index('SalePrice',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:24.876985Z","iopub.execute_input":"2021-05-30T05:03:24.877255Z","iopub.status.idle":"2021-05-30T05:03:24.884647Z","shell.execute_reply.started":"2021-05-30T05:03:24.877213Z","shell.execute_reply":"2021-05-30T05:03:24.883894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>One-Hot encoding dummy variables","metadata":{}},{"cell_type":"code","source":"one_hot_encode_cols = df_final.dtypes[df_final.dtypes == np.object]\none_hot_encode_cols = one_hot_encode_cols.index.tolist()\n\ndf_final = pd.get_dummies(df_final, columns = one_hot_encode_cols, drop_first=True)\ndf_final.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:24.885908Z","iopub.execute_input":"2021-05-30T05:03:24.886144Z","iopub.status.idle":"2021-05-30T05:03:25.044615Z","shell.execute_reply.started":"2021-05-30T05:03:24.88612Z","shell.execute_reply":"2021-05-30T05:03:25.043628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Log transforming skew variables","metadata":{}},{"cell_type":"code","source":"float_cols = df_final.columns[df_final.dtypes == np.float]\nskew_limit = 0.75\nskew_vals = df_final[float_cols].skew()\nskew_cols = (skew_vals\n             .sort_values(ascending = False)\n             .to_frame()\n             .rename(columns = {0: 'Skew'})\n             .query('abs(Skew) > {}'.format(skew_limit)))\n#skew_cols","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:25.045658Z","iopub.execute_input":"2021-05-30T05:03:25.045921Z","iopub.status.idle":"2021-05-30T05:03:25.058751Z","shell.execute_reply.started":"2021-05-30T05:03:25.045889Z","shell.execute_reply":"2021-05-30T05:03:25.057747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Train Test Split","metadata":{}},{"cell_type":"code","source":"X = df_final.reset_index().drop('SalePrice', axis = 1)\ny = df_final.index\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:25.059793Z","iopub.execute_input":"2021-05-30T05:03:25.06008Z","iopub.status.idle":"2021-05-30T05:03:25.071214Z","shell.execute_reply.started":"2021-05-30T05:03:25.060045Z","shell.execute_reply":"2021-05-30T05:03:25.070281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train1 = X_train.copy()\ny_train1 = y_train.copy()\nX_test1 = X_test.copy()\ny_test1 = y_test.copy()\n\nlm = lr().fit(X_train1, y_train)\ny_pred = lm.predict(X_test1)\nlm.score(X_test1,y_test1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:25.072321Z","iopub.execute_input":"2021-05-30T05:03:25.072576Z","iopub.status.idle":"2021-05-30T05:03:25.162978Z","shell.execute_reply.started":"2021-05-30T05:03:25.072552Z","shell.execute_reply":"2021-05-30T05:03:25.16197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Regularized Lasso Regression\n#### K fold ","metadata":{}},{"cell_type":"code","source":"kf = KFold(shuffle = True, random_state = 42, n_splits = 5)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:25.164322Z","iopub.execute_input":"2021-05-30T05:03:25.164996Z","iopub.status.idle":"2021-05-30T05:03:25.170289Z","shell.execute_reply.started":"2021-05-30T05:03:25.164952Z","shell.execute_reply":"2021-05-30T05:03:25.169236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Optimization Function","metadata":{}},{"cell_type":"code","source":"def optimize_alpha(alphas, x, y, model, kf):\n    \n    #Scale and transform x.\n    s = StandardScaler()\n    x = s.fit_transform(x)\n    \n    #List of R2.\n    r2_scores = []\n    \n    for alpha in alphas:\n        \n        reg = model(alpha = alpha, max_iter = 500000)\n        y_pred = cross_val_predict(reg, x, y, cv = kf)\n        score = r2_score(y, y_pred)\n        r2_scores.append(score)\n    \n    return(r2_scores)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:25.172173Z","iopub.execute_input":"2021-05-30T05:03:25.172811Z","iopub.status.idle":"2021-05-30T05:03:25.185789Z","shell.execute_reply.started":"2021-05-30T05:03:25.172765Z","shell.execute_reply":"2021-05-30T05:03:25.184178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Alpha Graph","metadata":{}},{"cell_type":"code","source":"def alpha_r2_graph(alphas, R2s, xlabels, model):\n    \n    df = pd.DataFrame(data = {'alpha': alphas,'R2': R2s})\n    sns.set()\n    #Scatter Plot\n    sns.lineplot(data = df, x = 'alpha', y = 'R2', marker = 'o')\n    \n    #Size\n    plt.gcf().set_size_inches(15, 6.92)\n    paper_rc = {'lines.linewidth': 2, 'lines.markersize': 6}  \n    \n    #Axes\n    ax = plt.gca()\n    \n    #Title\n    ax.set_title(\"Hyperparameter Optimization for {} Regression\".format(model), fontsize = 24)\n\n    #X-axis\n    ax.set_xlabel(\"α\", fontsize = 22)\n    ax.set_xscale('log')\n    ax.set_xticks(xlabels)\n    ax.set_xticklabels(xlabels, rotation = 45, ha = 'right')\n    if (model == 'Ridge') :\n        ax.get_xaxis().set_major_formatter(FF(lambda x, p: format(int(x), ',')))\n\n    #Y-axis\n    ax.set_ylabel(\"R2\", fontsize = 22)\n    ylabels = [0, 0.2, 0.4, 0.6, 0.8, 1]\n    ax.set_xticks(xlabels)\n    \n    ax.tick_params(axis = 'both', which = 'major', labelsize = 16)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:25.189172Z","iopub.execute_input":"2021-05-30T05:03:25.191034Z","iopub.status.idle":"2021-05-30T05:03:25.212999Z","shell.execute_reply.started":"2021-05-30T05:03:25.190984Z","shell.execute_reply":"2021-05-30T05:03:25.211509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lasso with L1 Regularization","metadata":{}},{"cell_type":"code","source":"alphas = list(pd.core.common.flatten([[a / 2, a, 2 * a] for a in np.geomspace(1e-5, 1e1, 7)]))\nxlabels = [a for a in np.geomspace(1e-5, 1e1, 7)]\n\ns = StandardScaler()\nX_train2 = s.fit_transform(X_train)\ny_train2 = y_train.copy()\nX_test2 = s.fit_transform(X_test)\ny_test2 = y_test.copy()\n\n#R2s and graph\nr2_lasso = optimize_alpha(alphas, X_train2, y_train2, Lasso, kf)\nalpha_r2_graph(alphas, r2_lasso, xlabels, 'Lasso')\n\n#Lasso Regression\nlm_lasso = Lasso(alpha=0.005).fit(X_train2,y_train2)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:25.21647Z","iopub.execute_input":"2021-05-30T05:03:25.217775Z","iopub.status.idle":"2021-05-30T05:03:46.785101Z","shell.execute_reply.started":"2021-05-30T05:03:25.217722Z","shell.execute_reply":"2021-05-30T05:03:46.784193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ridge with L2 Regularization","metadata":{}},{"cell_type":"code","source":"alphas = list(pd.core.common.flatten([[a / 2, a, 2 * a] for a in np.geomspace(1, 1e6, 7)]))\nxlabels = [a for a in np.geomspace(1, 1e6, 7)]\n\ns = StandardScaler()\nX_train3 = s.fit_transform(X_train)\ny_train3 = y_train.copy()\nX_test3 = s.fit_transform(X_test)\ny_test3 = y_test.copy()\n\n#Determine R2s and graph.\nr2_ridge = optimize_alpha(alphas, X_train3, y_train3, Ridge, kf)\nalpha_r2_graph(alphas, r2_ridge, xlabels, 'Ridge')\n\n#Ridge Regression\nlm_ridge = Ridge(alpha=500).fit(X_train3,y_train3)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:46.789223Z","iopub.execute_input":"2021-05-30T05:03:46.789522Z","iopub.status.idle":"2021-05-30T05:03:49.325783Z","shell.execute_reply.started":"2021-05-30T05:03:46.789493Z","shell.execute_reply":"2021-05-30T05:03:49.323781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Summary Function","metadata":{}},{"cell_type":"code","source":"def summary_table(models, Xs, Y) :\n\n    index = ['Linear','Lasso', 'Ridge']\n    R2 = []\n    ADJUSTED_R2 = []\n    RMSE = []\n    MAE = []\n\n    for i in range(3):\n        y_pred = models[i].predict(Xs[i])\n        \n        #R2.\n        r2 = r2_score(Y, y_pred)\n        R2.append(r2)\n        \n        #Adj R2\n        adjusted_r2 = 1.0 - (1.0 - r2) * (len(Y) - 1.0) / (len(Y) - Xs[i].shape[1] - 1.0)\n        ADJUSTED_R2.append(adjusted_r2)\n        \n        #RMSE\n        rmse = math.sqrt(mean_squared_error(Y, y_pred))\n        RMSE.append(rmse)\n                         \n        #MAE\n        mae = mean_absolute_error(Y, y_pred)\n        MAE.append(mae)\n\n    df_summary = pd.DataFrame(data = {'R2': R2,'Adjusted R2': ADJUSTED_R2,'RMSE': RMSE,'MAE': MAE},index = index)\n    \n    return(df_summary)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:49.327249Z","iopub.execute_input":"2021-05-30T05:03:49.327509Z","iopub.status.idle":"2021-05-30T05:03:49.334256Z","shell.execute_reply.started":"2021-05-30T05:03:49.327483Z","shell.execute_reply":"2021-05-30T05:03:49.333254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train Data","metadata":{}},{"cell_type":"code","source":"linear_models = [lm, lm_lasso, lm_ridge]\nX_trains = [X_train1, X_train2, X_train3]\nsummary_table(linear_models, X_trains, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:49.335601Z","iopub.execute_input":"2021-05-30T05:03:49.335978Z","iopub.status.idle":"2021-05-30T05:03:49.370316Z","shell.execute_reply.started":"2021-05-30T05:03:49.335937Z","shell.execute_reply":"2021-05-30T05:03:49.369416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test Data","metadata":{}},{"cell_type":"code","source":"X_tests = [X_test1, X_test2, X_test3]\nsummary_table(linear_models, X_tests, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:49.371591Z","iopub.execute_input":"2021-05-30T05:03:49.3721Z","iopub.status.idle":"2021-05-30T05:03:49.405343Z","shell.execute_reply.started":"2021-05-30T05:03:49.37206Z","shell.execute_reply":"2021-05-30T05:03:49.404371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lasso Regression maintains accuracy while reducing complexity by more than half.","metadata":{}},{"cell_type":"code","source":"for i in linear_models:\n    print(len(X_train.columns[i.coef_ != 0]))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:03:49.406595Z","iopub.execute_input":"2021-05-30T05:03:49.407115Z","iopub.status.idle":"2021-05-30T05:03:49.412737Z","shell.execute_reply.started":"2021-05-30T05:03:49.407073Z","shell.execute_reply":"2021-05-30T05:03:49.411914Z"},"trusted":true},"execution_count":null,"outputs":[]}]}