{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import shapiro\nimport scipy.stats as stats\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/mobile-games-ab-testing/cookie_cats.csv'\n\ndf = pd.read_csv(path)\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(set(df['userid'])) == df.shape[0]\n\n# it seem that there is no repeatable value for user","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe([0.01,0.05, 0.10, 0.20, 0.80, 0.90, 0.95, 0.99])[['sum_gamerounds']].T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('version')['sum_gamerounds'].agg(['count','median','mean','std','max'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the max of gate_30 is 49854 gamerounds however if we check 99% confidence interval for sum_gamerounds which is 493\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['sum_gamerounds'] < df['sum_gamerounds'].max()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['sum_gamerounds'] == 0 ].shape[0]\n# 3994 users did not try to play our game app","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sum_gamerounds'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsns.lineplot(x=df['sum_gamerounds'].value_counts().index, y = df['sum_gamerounds'].value_counts().values)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('sum_gamerounds')['userid'].nunique().reset_index().head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A/B Groups & Target Summary Stats\ndf.groupby(\"version\").sum_gamerounds.agg([\"count\", \"median\", \"mean\", \"std\", \"max\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# our control and test groups have approximately same sample ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret1_count = df['retention_1'].sum()\nret7_count = df['retention_7'].sum()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['retention_1'].mean()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['retention_7'].mean()\n#18% percentage people keep continue to play game","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby([\"version\", \"retention_1\"]).sum_gamerounds.agg([\"count\", \"median\", \"mean\", \"std\", \"max\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby([\"version\", \"retention_7\"]).sum_gamerounds.agg([\"count\", \"median\", \"mean\", \"std\", \"max\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we checked that  have the control and test group same quantity for retention_1 and retention_7 ? YES!","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define A/B groups\ndf[\"version\"] = np.where(df.version == \"gate_30\", \"A\", \"B\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A/B Testing Function - Quick Solution\ndef AB_Test(dataframe, group, target):\n    \n    # Packages\n    from scipy.stats import shapiro\n    import scipy.stats as stats\n    \n    # Split A/B\n    groupA = dataframe[dataframe[group] == \"A\"][target]\n    groupB = dataframe[dataframe[group] == \"B\"][target]\n    \n    # Assumption: Normality\n    ntA = shapiro(groupA)[1] < 0.05\n    ntB = shapiro(groupB)[1] < 0.05\n    # H0: Distribution is Normal! - False\n    # H1: Distribution is not Normal! - True\n    \n    if (ntA == False) & (ntB == False): # \"H0: Normal Distribution\"\n        # Parametric Test\n        # Assumption: Homogeneity of variances\n        leveneTest = stats.levene(groupA, groupB)[1] < 0.05\n        # H0: Homogeneity: False\n        # H1: Heterogeneous: True\n        \n        if leveneTest == False:\n            # Homogeneity\n            ttest = stats.ttest_ind(groupA, groupB, equal_var=True)[1]\n            # H0: M1 == M2 - False\n            # H1: M1 != M2 - True\n        else:\n            # Heterogeneous\n            ttest = stats.ttest_ind(groupA, groupB, equal_var=False)[1]\n            # H0: M1 == M2 - False\n            # H1: M1 != M2 - True\n    else:\n        # Non-Parametric Test\n        ttest = stats.mannwhitneyu(groupA, groupB)[1] \n        # H0: M1 == M2 - False\n        # H1: M1 != M2 - True\n        \n    # Result\n    temp = pd.DataFrame({\n        \"AB Hypothesis\":[ttest < 0.05], \n        \"p-value\":[ttest]\n    })\n    temp[\"Test Type\"] = np.where((ntA == False) & (ntB == False), \"Parametric\", \"Non-Parametric\")\n    temp[\"AB Hypothesis\"] = np.where(temp[\"AB Hypothesis\"] == False, \"Fail to Reject H0\", \"Reject H0\")\n    temp[\"Comment\"] = np.where(temp[\"AB Hypothesis\"] == \"Fail to Reject H0\", \"A/B groups are similar!\", \"A/B groups are not similar!\")\n    \n    # Columns\n    if (ntA == False) & (ntB == False):\n        temp[\"Homogeneity\"] = np.where(leveneTest == False, \"Yes\", \"No\")\n        temp = temp[[\"Test Type\", \"Homogeneity\",\"AB Hypothesis\", \"p-value\", \"Comment\"]]\n    else:\n        temp = temp[[\"Test Type\",\"AB Hypothesis\", \"p-value\", \"Comment\"]]\n    \n    # Print Hypothesis\n    print(\"# A/B Testing Hypothesis\")\n    print(\"H0: A == B\")\n    print(\"H1: A != B\", \"\\n\")\n    \n    return temp\n    \n    \n    \n# Apply A/B Testing\nAB_Test(dataframe=df, group = \"version\", target = \"sum_gamerounds\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the A/B test function recejt the our H0 hypothesis so the groups are not similar to make a interpret.\n\n\ndf.groupby('version')['retention_1'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('version')['retention_7'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group A which is gate_30 has more average ratio than group b for sum_gamerounds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}