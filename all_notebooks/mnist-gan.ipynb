{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom keras.utils import np_utils # For y values\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\nimport os\nprint(os.listdir(\"../input\"))\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\n\n# For plotting\n%matplotlib inline\nimport seaborn as sns\n# For Keras\nfrom tensorflow.keras.layers import Activation, Dense, Input\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.layers import Reshape, Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.utils import plot_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"../input/mnist-in-csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\ntest = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de146ebf369e33ab93a6769c019e351f7b6e9019","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ffb977d04e7e8b13e92a5d8b1d8e18ee81cd925","trusted":true},"cell_type":"code","source":"#Remove the first column from the data, as it is the label and put the rest in X\nX_train = train.iloc[:, 1:].values#.reshape(-1,28,28,1)\n#Remove everything except the first column from the data, as it is the label and put it in y\ny_train = train.iloc[:, :1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove the first column from the data, as it is the label and put the rest in X\nX_test = test.iloc[:, 1:].values/255.#.reshape(-1,28,28,1)\n#Remove everything except the first column from the data, as it is the label and put it in y\ny_test = test.iloc[:, :1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transposed convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.\n\nWhen using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\".\n\n\nDiffernce between upsampling(keras) and decon\n\nUpSampling2D is just a simple scaling up of the image by using nearest neighbour or bilinear upsampling, so nothing smart. Advantage is it's cheap.\n\nConv2DTranspose is a convolution operation whose kernel is learnt (just like normal conv2d operation) while training your model. Using Conv2DTranspose will also upsample its input but the key difference is the model should learn what is the best upsampling for the job.\n\nhttps://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_generator(inputs, image_size): # This function builds a generator for DCGAN\n    image_resize = image_size // 4\n    kernel_size = 5\n    layer_filters = [128, 64, 32, 1]\n    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\n    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n    for filters in layer_filters:\n        if filters > layer_filters[-2]:\n            strides = 2\n        else:\n            strides = 1\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = Conv2DTranspose(filters=filters,kernel_size=kernel_size,strides=strides,padding='same')(x)\n    x = Activation('sigmoid')(x)\n    generator = Model(inputs, x, name='generator')\n    return generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_discriminator(inputs): #This function builds a discriminator\n    kernel_size = 5\n    layer_filters = [32, 64, 128, 256]\n    x = inputs\n    for filters in layer_filters:\n        if filters == layer_filters[-1]:\n            strides = 1\n        else:\n            strides = 2\n        x = LeakyReLU(alpha=0.2)(x)\n        x = Conv2D(filters=filters,\n                   kernel_size=kernel_size,\n                   strides=strides,\n                   padding='same')(x)\n\n    x = Flatten()(x)\n    x = Dense(1)(x)\n    x = Activation('sigmoid')(x)\n    discriminator = Model(inputs, x, name='discriminator')\n    return discriminator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(models, x_train, params):\n    generator, discriminator, adversarial = models \n    batch_size, latent_size, train_steps, model_name = params \n    save_interval = 500 \n    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size]) \n    train_size = x_train.shape[0] \n    for i in range(train_steps):\n        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n        real_images = x_train[rand_indexes]\n        noise = np.random.uniform(-1.0,1.0,size=[batch_size, latent_size])\n        fake_images = generator.predict(noise)\n        x = np.concatenate((real_images, fake_images))\n        y = np.ones([2 * batch_size, 1])\n        y[batch_size:, :] = 0.0\n        loss, acc = discriminator.train_on_batch(x, y)\n        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n        noise = np.random.uniform(-1.0,1.0, size=[batch_size, latent_size])\n        y = np.ones([batch_size, 1])\n        loss, acc = adversarial.train_on_batch(noise, y)\n        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n        print(log)\n        if (i + 1) % save_interval == 0:\n            plot_images(generator,noise_input=noise_input,show=False,step=(i + 1),model_name=model_name)\n        if i == 500 or (i+1) % 10000 == 0:\n            generator.save(model_name + \"_\" + str(i) + \"_\" + \".h5\")\n    generator.save(model_name + \".h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_images(generator,noise_input,show=False,step=0,model_name=\"gan\"):\n    os.makedirs(model_name, exist_ok=True)\n    filename = os.path.join(model_name, \"%05d.png\" % step)\n    images = generator.predict(noise_input)\n    plt.figure(figsize=(2.2, 2.2))\n    num_images = images.shape[0]\n    image_size = images.shape[1]\n    rows = int(math.sqrt(noise_input.shape[0]))\n    for i in range(num_images):\n        plt.subplot(rows, rows, i + 1)\n        image = np.reshape(images[i], [image_size, image_size])\n        plt.imshow(image, cmap='gray')\n        plt.axis('off')\n    plt.savefig(filename)\n    if show:\n        plt.show()\n    else:\n        plt.close('all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape data for CNN as (28, 28, 1) and normalize\nimage_size = 28\nX_train = np.reshape(X_train, [-1, 28, 28, 1])\nX_train = X_train.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = \"dcgan_mnist\"\n# network parameters\n# the latent or z vector is 100-dim\nlatent_size = 100\nbatch_size = 64\ntrain_steps = 40000\nlr = 2e-4\ndecay = 6e-8\ninput_shape = (image_size, image_size, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build discriminator model\ninputs = Input(shape=input_shape, name='discriminator_input') # Input Layer TF\ndiscriminator = build_discriminator(inputs)\noptimizer = RMSprop(lr=lr, decay=decay)\ndiscriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n#discriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(discriminator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build generator model\ninput_shape = (latent_size, )\ninputs = Input(shape=input_shape, name='z_input')\ngenerator = build_generator(inputs, image_size)\n#generator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(\n    generator.predict(np.random.uniform(-1.0,1.0,size=[1, 100])).reshape(28,28)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build adversarial model\noptimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\n# freeze the weights of discriminator during adversarial training\ndiscriminator.trainable = False\n# adversarial = generator + discriminator\nadversarial = Model(inputs, discriminator(generator(inputs)),name=model_name)\nadversarial.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n#adversarial.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(adversarial)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train discriminator and adversarial networks\nmodels = (generator, discriminator, adversarial)\nparams = (batch_size, latent_size, train_steps, model_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train(models, X_train, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_generator(generator, K):\n    noise_input = np.random.uniform(-1.0, 1.0, size=[K, 100])\n    plot_images(generator,noise_input=noise_input,show=True,model_name=\"test_outputs\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generator.load_weights('dcgan_mnist_19999_.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_generator(generator, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}