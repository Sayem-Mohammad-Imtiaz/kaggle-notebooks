{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Recommendation System based Embedding Approach \n\n## 2020-03-07 Ahn Sangho\n\n## Thanks to \n\n- [KCDC](http://www.cdc.go.kr/index.es?sid=a2)\n- [datartist\nand 9 collaborators\n](https://www.kaggle.com/kimjihoo/coronavirusdataset/data) at Kaggle\n- [Jeremy Howard](https://www.kaggle.com/jhoward) fastai\n\nThe `COVID-19` is now a global problem. \n\nAmong many countries, South Korea is doing its best to protect virus with KCDC, various medical staff and many unknown people.\n\nThis dataset is also part of this effort. KCDC is producing detailed and accurate information, and datartist at el. are refining and sharing it.\n\nThis analysis suggests a way to embed place and patient information from route of patient. Specifically, I show fastai's collaborative filtering module to embedding this information. \n\nI sincerely hope that `COVID-19` will be well prevented and finished globally as soon as possible.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\nroot_dir = Path(\"/kaggle/\")\nbase_dir = root_dir / \"input\"\n\ndata_path = base_dir / \"coronavirusdataset\"\nprint(data_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Getting the Data\n\n\nThe first step is to look at the data roughly, as you probably already know.\n\n## 1.1. Load and Head"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \n\npatient_df = pd.read_csv(data_path / \"patient.csv\")\nprint(patient_df.shape)\npatient_df.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"route_df = pd.read_csv(data_path / \"route.csv\")\nprint(route_df.shape)\nroute_df.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2. Wrangling for Rec Input\n\nTo Embedding patient and place information, some wraggling process needed. \n\nIn recommendation system, rating is common. However, this dataset does not have rating information. \n\nTherefore, I've used a trick to represent visit information as 1. As a view of matrix factorization, I expect this to work.\n\n![MF](https://miro.medium.com/max/1689/1*Zhm1NMlmVywn0G18w3exog.png)\nImage from [this website](https://medium.com/@connectwithghosh/simple-matrix-factorization-example-on-the-movielens-dataset-using-pyspark-9b7e3f567536)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \n\npatient_id = route_df[\"id\"]\nplace_id = route_df[\"city\"] + \"_\"+ route_df[\"visit\"]\none_hot = pd.Series(np.ones(patient_id.shape))\n\nroute_data = pd.DataFrame({\n    \"patient_id\": patient_id,\n    \"place_id\": place_id,\n    \"one\": one_hot\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"route_data.groupby(\"place_id\").count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Training Collab\n\nNow, We can make `learner` and train model using fastai.\n\n\nThe following steps are all common analysis process of fastai.\n\n## 2.1. Create DataBunch"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.collab import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patient, place, visit = \"patient_id\", \"place_id\", \"one\"\n\ndata = CollabDataBunch.from_df(route_data, seed=42, valid_pct=0, item_name=place) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Create Learner and Find LR"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_range = [0, 1.5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = collab_learner(data, n_factors=40, y_range=y_range, wd=1e-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot(skip_end=15, suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3. Train Learner"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, 4e-02)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Interpretation\n\nAfter Training, we finally get embedding vectors for place and patient information. \n\nIn both cases, a PCA-based dimension reduction was applied to the weights. \n\nThe results are plotting on a two-dimensional plane."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Place Embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"place_array = learn.data.train_ds[0][0].classes[\"place_id\"]\n\nplace_weight = learn.model.i_weight.weight.to(\"cpu\")\n\nplace_pca =  place_weight.pca(2)\n\nfac0, fac1 = place_pca.t()\nfac0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n\nmpl.rcParams['axes.unicode_minus'] = False\n\n# idxs = np.random.choice(len(top_itemes), 300, replace=False)\n\nX = fac0.detach().numpy()\nY = fac1.detach().numpy()\n\nplt.figure(figsize=(30,30))\nplt.scatter(X, Y)\nfor i, x, y in zip(place_array, X, Y):\n    plt.text(x,y,i, fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Patient Embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"patient_array = learn.data.train_ds[0][0].classes[\"patient_id\"]\n\npatient_weight = learn.model.u_weight.weight\n\npatient_pca =  patient_weight.pca(2)\n\nfac0, fac1 = patient_pca.t()\nfac0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n\nmpl.rcParams['axes.unicode_minus'] = False\n\n# idxs = np.random.choice(len(top_itemes), 300, replace=False)\n\nX = fac0.detach().numpy()\nY = fac1.detach().numpy()\n\nplt.figure(figsize=(30,30))\nplt.scatter(X, Y)\nfor i, x, y in zip(patient_array, X, Y):\n    plt.text(x,y,i, fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n![tree](http://t1.daumcdn.net/brunch/service/user/30eI/image/aFIiPM9FzmE3mRkE0VR_GAsS5wU.jpg)\n\n`COVID-19` has been reported to spread patient 6 to patients 10 and 11, as well as in embedding vectors. \n\nI think this information will be better represented with more data."},{"metadata":{},"cell_type":"markdown","source":"# 4. Future Work\n\nThe current dataset is still being added.\n\nBecause of the characteristic of embedding, the more data you get, the better the results, when this dataset is updated, the result will also be updated.\n\nIn addition, since it does not simply end in embedding, I will use this as input and apply it to our prediction and classification tasks."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}