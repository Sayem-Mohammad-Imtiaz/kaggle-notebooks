{"cells":[{"metadata":{"_uuid":"ac6edec448be6105bb77bcf0ffda8f5290e31c47"},"cell_type":"markdown","source":"## Introduction\nSupervised learning problems can be further grouped into \n- Regression problems and \n- Classification problems\n\nIn classification, learning algorithms takes the input data and map the output to a discrete output like True or False\nIn regression, learning algorithms maps the input data to continuous output like weight, cost, etc.\n\nIn this project I will apply regression techniques of supervised learning to predict the medical insurance costs. "},{"metadata":{"trusted":true,"_uuid":"3e967291f0df943d34ade0d355c93ff2efe817b3"},"cell_type":"code","source":"# Import libraries necessary for this project\nimport numpy as np\nimport pandas as pd\n\ndata = pd.read_csv('../input/insurance.csv')\ndata = data.dropna()\nprint (data.info())\nprint (data.head(5))\nprint ('-'*90)\nprint (\"Successfully imported Insurance data. Data has {} data points with {} variables each.\".format(*data.shape))","execution_count":5,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"notes"},"_uuid":"611bb518f6d6d4d2ad2462bd25e5df3f2afe9559"},"cell_type":"markdown","source":"## Data Exploration\nDataset consists of 1338 records. Each record contains the below data for specific person.\n- age – Age of the person\n- sex – Sex of the person\n- bmi – Body Mass Index(BMI) of the person\n- children – Number of children for the person\n- smoker – Smoking status of the person\n- region – Region of the person in US\n- charges – Medical Insurance costs per year for the person\n"},{"metadata":{"trusted":true,"_uuid":"c7a223f92842fd4bab4558a431403b51184b4f74"},"cell_type":"code","source":"def bmi_category(bmi):\n    if bmi < 18.5:\n        return 'under-weight'\n    elif bmi >= 18.5 and bmi <= 24.9:\n        return 'normal-weight'\n    elif bmi >= 24 and bmi <= 29.9:\n        return 'over-weight'\n    elif bmi > 30.0:\n        return \"obese\"\n    \ndef age_category(age):\n    age_dict = {\n        0: '0-9',\n        1: '10-19',\n        2: '20-29',\n        3: '30-39',\n        4: '40-49',\n        5: '50-59',\n        6: '60-69',\n        7: '70-79',\n        8: '80-89',\n        9: '90-99',\n        10: '100-200'\n    }\n    return age_dict[age//10]\n    \ndata['cbmi'] = data['bmi'].apply(lambda x: \"none\")\ndata['cage'] = data['age'].apply(lambda x: \"none\")\n\nfor idx, row in data.iterrows():\n    data.at[idx, 'cage'] = age_category(row['age'])\n    data.at[idx, 'cbmi'] = bmi_category(row['bmi'])\n    \nby_age = data.groupby(by='cage').size()\nprint (by_age)\nprint ('-'*80)\n\nby_sex = data.groupby(by='sex').size()\nprint (by_sex)\nprint ('-'*80)\n\nby_smoker = data.groupby(by='smoker').size()\nprint (by_smoker)\nprint ('-'*80)\n\nby_region = data.groupby(by='region').size()\nprint (by_region)\nprint ('-'*80)\n\nby_children = data.groupby(by='children').size()\nprint (by_children)\nprint ('-'*80)\n\nby_bmi = data.groupby(by='cbmi').size()\nprint (by_bmi)\nprint ('-'*80)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"1cd0c047ffd24bd2babf325b131cdefff395293d"},"cell_type":"markdown","source":"To understand correlation between the input or the independent variables, I classified the ages and BMI into specific categories. \nThe above analysis shows the stats like number of male and female, smokers and non-smokers, etc. from the input data.  \nTaking the BMI ranges from Medline Plus, I categorized the input samples into `below-weight`, `normal-weight`, `over-weight` and `obese`.\n\nFrom the above data we can observe below\n- Input data contains an even distribution of male and female samples\n- Majority of them are non-smokers with 1064 samples\n- Majority of the samples are in age groups 20-29 and 40- 49 with the numbers 280 and 279 respectively.\n- A major sample of input data contains persons with no children with 574.\n- The data is evenly distributed across 4 regions with the region of `southeast` having slightly more samples.\n- Majority the sample fall under the category of `obese`"},{"metadata":{"trusted":true,"_uuid":"0b3ed2d337afa0ded87857b63a12439149979c63"},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nvariables = ['sex','smoker','region','cage','cbmi','children']\n\n# data distribution analysys\nprint('Data distribution analysys')\nfor v in variables:\n    data = data.sort_values(by=[v])\n    data[v].value_counts().plot(kind = 'bar')\n    plt.title(v)\n    plt.show()","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3675cbf8c938ed3e7b3958da3bd29b43eb0977cb"},"cell_type":"code","source":"print('Mean cost analysys:')\nfor v in variables:\n    group_df = data.groupby(pd.Grouper(key=v)).mean()\n    group_df = group_df.sort_index()\n    group_df.plot(y = ['charges'],kind = 'bar')\n    plt.show()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"cbc984a6c1ad6fb05c3b82fc3d0564e4968438f3"},"cell_type":"markdown","source":"From the above bar graphs, we can deduce the below facts.\n- Insurance costs are higher among male population\n- Insurance costs are highest among the population of age groups 60-69.\n- Insurance costs increases among the smokers\n- Insurance costs increases among the obese population\n- Insurance costs are higher among the population in southwest region\n- Surprisingly, insurance costs are higher among the individuals with 2 or 3 children rather than with individuals with 4 or 5 children.\n"},{"metadata":{"trusted":true,"_uuid":"7e0fd546afd60c83b40de708d597781c4f310073"},"cell_type":"code","source":"sns.violinplot(x='sex', y='charges',data=data)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16a8a3e56ce44bd2dde90b139415244971d59064"},"cell_type":"code","source":"sns.violinplot(x='smoker', y='charges',data=data)","execution_count":12,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"632ca49f0ef63000c4bdb33feeb5074b5463ea40"},"cell_type":"code","source":"sns.violinplot(x='region', y='charges',data=data)","execution_count":24,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b6d39e1c9980aa78c03f78abf201db6c382bd5c4"},"cell_type":"code","source":"sns.boxplot(x='sex', y='charges',data=data)","execution_count":25,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"97b0b97b1947cd5c35df2bb2424409d44d34302f"},"cell_type":"code","source":"sns.boxplot(x='cage', y='charges',data=data)","execution_count":26,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e5903c7d8c9858e1e4525aab71bbf93d03513e97"},"cell_type":"code","source":"sns.boxplot(x='cbmi', y='charges',data=data)","execution_count":27,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6d703a06ed9a39faca8001ec3c422402b2268906"},"cell_type":"code","source":"sns.boxplot(x='smoker', y='charges',data=data)","execution_count":28,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"03bd6181bdba5c6caa89bd12e639f77d9f1b24f5"},"cell_type":"code","source":"sns.boxplot(x='children', y='charges',data=data)","execution_count":29,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4f0a62fc76de494010b94288a877219686d97cb5"},"cell_type":"code","source":"sns.boxplot(x='region', y='charges',data=data)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c8aa127d41e62e647783bbcfab0829f23ff83cb"},"cell_type":"code","source":"sns.pairplot(data, size=2)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"d6d10281716afede1e1a283f036da8e1ab758ae2"},"cell_type":"markdown","source":"### Implementation: Calculate Statistics\nI explored the descriptive statistics about the insurance costs."},{"metadata":{"trusted":true,"_uuid":"12302bdda255ff1511189df85555afc152d4d9a5"},"cell_type":"code","source":"target = data['charges']\nfeatures = data.drop(['age', 'bmi', 'charges'], axis=1)\nmin_cost = np.min(target)\nmax_cost = np.max(target)\nmean_cost = np.mean(target)\nmedian_cost = np.median(target)\nstd_cost = np.std(target)\n\nprint (target.describe())\nprint ('-'*90)\n# calculated statistics\nprint (\"Statistics for Medical Insurance dataset:\\n\")\nprint (\"Minimum insurance cost: ${:,.2f}\".format(min_cost))\nprint (\"Maximum insurance acost: ${:,.2f}\".format(max_cost))\nprint (\"Mean insurance cost: ${:,.2f}\".format(mean_cost))\nprint (\"Median insurance cost ${:,.2f}\".format(median_cost))\nprint (\"Standard deviation of insurance costs: ${:,.2f}\".format(std_cost))","execution_count":15,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2524f06674c2f3ffb0e4c91bd35b4183dd69c347"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdef1a47512bfe266d19ab2f7d81fe3fc9b408e5"},"cell_type":"code","source":"output = pd.DataFrame(index=features.index)\n\nfor col, col_data in features.iteritems():\n    if object == col_data.dtype:\n        col_data = col_data.replace(['yes', 'no'], [1, 0])\n        \n    if object == col_data.dtype:\n        col_data = pd.get_dummies(col_data, prefix = col)\n    output = output.join(col_data)\n\nfeatures = output\nprint (\"Processed feature columns ({} total features):\\n{}\".format(len(features.columns), list(features.columns)))\n#print features.head(5)","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"b6f3c813475e0adf2ba87573bef559022940a2ab"},"cell_type":"markdown","source":"----\n\n## Developing a Model\n"},{"metadata":{"_uuid":"a813bad321ec75293f5b94eb04aed5bdea478fa7"},"cell_type":"markdown","source":"### Implementation: Define a Performance Metric\nI opted for below two metrics.\n- Coefficient of determination\nThis metric is denoted by R^2 and also called are “R squared”. R-squared is a statistical measure of how close the data are to the fitted regression line. This metric calculates the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\nBest possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n\n- Explained variance score\nWhile determining the dependent variable, first we need to understand how much variance is observed in it. This metric explains the fluctuation (or variance) of the dependent variable by using the independent variables. This measures how far a set of numbers are spread out from their mean value. Best possible score is 1.0, lower values are worse."},{"metadata":{"_uuid":"65f4f138c51925e2800d1ebcc3c10516958b543d"},"cell_type":"markdown","source":"### Training and Testing\n\n1. Splitting the data set into training and testing subsets helps to assess the performance of the model over an\n   independent data set. Typlically, we train the model using training data subset and then evaluate the model's \n   performance using the testing data subset, which is independent of the training data subset.\n   \n2. Splitting the data set also helps in having a check on model's overfitting.   "},{"metadata":{"trusted":true,"_uuid":"7181ae4fff4e381c119ba2611a56bb8bc08a258c"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, \n                                                    target,\n                                                    test_size=0.20, \n                                                    random_state=0)\nprint (\"Training and testing split was successful.\")","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0202e464efbdbe2e7ad5e25938aed37c0f0a8181"},"cell_type":"code","source":"from time import time\nfrom sklearn.metrics import r2_score, explained_variance_score\ndef train_predict_model(clf, X_train, y_train, X_test, y_test):\n    ''' Fits a classifier to the training data. '''\n    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n    # Start the clock, train the classifier, then stop the clock\n    start = time()\n    clf.fit(X_train, y_train)\n    end = time()\n    # Print the results\n    print (\"Trained model in {:.4f} seconds\".format(end - start))\n    print ('#'*50)\n    # Start the clock, make predictions, then stop the clock\n    print (\"Predictions for training data:\")\n    start = time()\n    y_pred = clf.predict(X_train)\n    end = time()\n    print (\"Made predictions for training data in {:.4f} seconds.\".format(end - start))\n    print (\"R^2 score for training set: {:4f}\".format(r2_score(y_train.values, y_pred)))\n    print (\"explained-variance score for training set: {:4f}\".format(explained_variance_score(y_train.values, y_pred)))\n    print ('#'*50)\n    print (\"Predictions for testing data:\")\n    start = time()\n    y_pred = clf.predict(X_test)\n    end = time()\n    print (\"Made predictions for testing data in {:.4f} seconds.\".format(end - start))\n    print (\"R^2 score for testing set: {:4f}\".format(r2_score(y_test.values, y_pred)))\n    print (\"explained-variance score for testing set: {:4f}\".format(explained_variance_score(y_test.values, y_pred)))","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"a1a25a6002714a2a93865ef8e464afa32e793672"},"cell_type":"markdown","source":"As part of evaluation, I considered multiple regression algorithms like decision trees, Support Vector Machines for regression, etc. Based on the metrics, I choose to use decision tree technique for this project\n\nThe goal of decision tree is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. For instance, in the example below, decision trees learn from data to approximate a sine curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.\n"},{"metadata":{"trusted":true,"_uuid":"372932dbe536fee5889559cbd63f46b45964a557"},"cell_type":"code","source":"from sklearn.svm import SVR, LinearSVR, NuSVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nclf_a = DecisionTreeRegressor(random_state=1)\nclf_b = SVR()\nclf_c = KNeighborsRegressor()\nclf_d = NuSVR()\nfor clf in (clf_a, clf_b, clf_c, clf_d):\n    for size in (300, 600, 900):\n        train_predict_model(clf, X_train[:size], y_train[:size], X_test, y_test)\n        print('-'* 80)\n    print ('+'*80)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"316d6932356653ab73d417b57105e57d03e1ef15"},"cell_type":"markdown","source":"Once after deciding the model, I used a random permutation cross-validator to split the features into multiple data-sets. \nI used grid-search technique to fit the model against various parameters of the DT algorithm like\n- criterion: This parameter measures the quality of split with supported values of `mse`, `friedman_mse` and `mae`\n- splitter: This parameter is used to choose the strategy of split at each node with values of `best` and `random`\n- max_depth: This parameter defines the maximum depth of the decision tree. I used values from 1 thru 10.  "},{"metadata":{"trusted":true,"_uuid":"bb05f2e26072212c4a8a193004dd8b9ee9e5c00c"},"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit, GridSearchCV\nfrom sklearn.metrics import make_scorer\ndef fit_model(X, y):\n    rs = ShuffleSplit(n_splits=16, test_size=0.20, random_state=1)\n    cv_sets = rs.split(X)\n    reg = DecisionTreeRegressor(random_state=0)\n    params = {\n        'criterion': ['mse', 'friedman_mse', 'mae'],\n        'splitter': ['best', 'random'],\n        'max_depth': range(1,11),\n    }\n    scoring_fnc = make_scorer(r2_score)\n    grid = GridSearchCV(estimator=reg, \n                        param_grid=params, \n                        scoring=scoring_fnc,\n                        cv=cv_sets)\n    grid = grid.fit(features, target)\n    return grid.best_estimator_\n\nbest_reg = fit_model(X_train, y_train)\nprint ('Model Parameters:')\nprint (\"Parameter 'criterion' is {} for the optimal model.\".format(best_reg.get_params()['criterion']))\nprint (\"Parameter 'splitter' is {} for the optimal model.\".format(best_reg.get_params()['splitter']))\nprint (\"Parameter 'max_depth' is {} for the optimal model.\".format(best_reg.get_params()['max_depth']))\ntrain_predict_model(best_reg, X_train, y_train, X_test, y_test)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90d86ac9048bbcf862261a11f4abbd190cb073e4"},"cell_type":"code","source":"client_data = [\n    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n    [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n    [1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n    [1, 0, 3, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n    [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n    [0, 1, 2, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n ]\n#0      19  female  27.900         0    yes  southwest  16884.92400\n#1      18    male  33.770         1     no  southeast   1725.55230\n#1313   19  female  34.700         2    yes  southwest  36397.57600\n#1314   30  female  23.655         3    yes  northwest  18765.87545\n#15     19    male  24.600         1     no  southwest   1837.23700\n#29     31    male  36.300         2    yes  southwest  38711.00000\n\n#'children', 'smoker', 'region_northeast', 'region_northwest', 'region_southeast', 'region_southwest']\n#      age  sex_female  sex_male    bmi  children  smoker  region_northeast  \\\nbest_reg.predict(client_data)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"10416a19aadb6dd4f68f7b4e2a515c4d5647e259"},"cell_type":"markdown","source":"As seen from the above results, selected DT model seems to be predicting the costs accurately at the higher end of the costs scale. \nFrom the above data, for records 1, 3, 4 and 6, the margin between the actual and predicted cost significantly less compared to the records 2 and 5. \nFor records 2 and 5, the actual insurance cost is less than 2000 USD and the model predicted the values to be above 2000 USD. \nIn case of other records, the actual insurance cost is more than 2000 USD and the model has predicted the values more accurately. "}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.14"}},"nbformat":4,"nbformat_minor":1}