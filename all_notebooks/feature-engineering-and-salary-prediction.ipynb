{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Feature engineering\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/nba2k20-player-dataset/nba2k20-full.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First of all, I think it is useless to pass \"full_name\" to the model, so I drop this column.      \nOther columns I think maybe useful for the model.     \nAt first sight, it seems like column \"jersey\" is useless, but if you take a look at the distribution of jersey, you notice that \"#0\" repeats three times more often than other numbers, so I leave it, maybe it has a sense for the model.\nI also leave the column \"college\", because there are a lot of basketball players who graduated from definition colleges, so I think this information may be useful.         \nI think other columns do not make you doubt their usefulness.    \n\nFrom the column \"b_day\" I leave the only year.   \nFrom column \"height\" I leave only height in meters.   \nfrom column \"weight\" I leave only weight in kilograms.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, such column as:  jersey, b_day, height, weight, salary, draft_round, and draft_peak we must turn to numeric dtype."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(\"full_name\", axis=1)\ndata[\"jersey\"] = data[\"jersey\"].str[1:].astype(\"int8\")\ndata[\"b_day\"] = pd.to_datetime(data[\"b_day\"]).dt.year\ndata[\"height\"] = data[\"height\"].str.split(\"/\").str[1].astype(\"float\")\ndata[\"weight\"] = data[\"weight\"].str.split(\"/\").str[1].str[0:-3].astype(\"float\")\ndata[\"salary\"] = data[\"salary\"].str[1:].astype(\"int64\")\ndata[\"draft_round\"] = data[\"draft_round\"].replace({\"Undrafted\": 0}).astype(\"int8\")\ndata[\"draft_peak\"] = data[\"draft_peak\"].replace({\"Undrafted\": 0}).astype(\"int8\")\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will replace all categorical values for one-hot encoding vectors. But first let's fill \"null\" values in dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['team'] = data['team'].fillna('No team')\ndata['college'] = data['college'].fillna('No college')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in ['team', 'position', 'country', 'college']:\n    encoded_columns = pd.get_dummies(data[column], prefix=column)\n    data = data.join(encoded_columns).drop(column, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data[\"salary\"]\nX = data.drop(\"salary\", axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.StandardScaler().fit(X_train)  \nX_train_normalized = scaler.transform(X_train)      \nX_test_normalized = scaler.transform(X_test)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Salary prediction"},{"metadata":{},"cell_type":"markdown","source":"I decided to use the Random Forest Regressor model. I also use GridSearchCV in searching for the best hyperparameters.   \n\nEarlier we normalized data, but we did not normalize target data (y_test, y_train), there are big numbers in target data, so I will be use np.log() to decrease values in target data. This will not affect the result, but it will be easier for the model to work with smaller numbers and it will be more convenient for us to evaluate the result. \n\nLater, if we want to receive a real salary, we must use np.exp() for the predicted value."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RF = RandomForestRegressor(random_state=7)\nparams_RF = {\n    \"n_estimators\": [200, 150] ,\n    \"max_depth\": [15, 10],\n    \"min_samples_split\": [2, 4, 8],\n    \"max_features\": [\"sqrt\", \"log2\"]\n}\nmodel_RF = GridSearchCV(model_RF, params_RF, scoring=\"neg_mean_squared_error\" )\nmodel_RF.fit(X_train_normalized, np.log(y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best parameters from GridSearchCV."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RF.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best cross-validation score."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RF.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Why score is negative?\n\nGridSearchCV tries to maximize the model's score, that's why we use \"neg_mean_squared_error\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_RF = model_RF.predict(X_test_normalized)\nmse = mean_squared_error(np.log(y_test), y_pred_RF)\nprint(\"Test mean squered error:\", mse)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}