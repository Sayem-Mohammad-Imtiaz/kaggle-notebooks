{"cells":[{"metadata":{"trusted":false,"_uuid":"a959ae71cd3e58015c8e98c620d83c1e519d971d"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.preprocessing import *\nfrom sklearn.metrics import *\nfrom sklearn.ensemble import *\nfrom sklearn.linear_model import *\nfrom sklearn.svm import * \nfrom sklearn.model_selection import *\nfrom imblearn.over_sampling import *\nfrom sklearn.neighbors import *\nfrom sklearn.neural_network import *\nfrom scipy.stats import t\nfrom collections import defaultdict\nimport copy\nimport csv","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d7de3c4f5cedf295d44b2e646de6a19cfabfe63"},"cell_type":"markdown","source":"# Data\n\n## Preprocess\nThe German Risk data has 10 features, the features of the data are Age, Sex, Job, Housing, Saving accounts, Checking account, Credit amount, Duration and Purpose and the label of the data is called Risk. Since the features of the data are a mix of numerical and categorical values, it was necessary to transform the numerical values into a categorical one. First of all, age was transformed into a categorical variable by discriminating if an applicant is in retirement age or not. Second, credit amount of the loan was transformed into a categorical data by discriminating the continuous values by using quantiles. All values up to the 1st quantile are considered low, values in the interquartile range is considered medium, and values greater than the 3rd quantile to be considered high. Third, duration of the loan was transformed from a discrete numericla value into a categorical value by grouping all loans less than 12 months to be a short term loan, and anything greater than or equal to 12 months to be a long term loan. After transforming all the variables into a categorical variable, it was then possible to use dummy variables to model the levels of the categories. By encoding the cateogrical variable using the one hot encoding (dummy variable) method, the features grew from 9 columns up to 31 columns to encode all the possible combinations of the categorical variables. Subsequently, the data set was split into a 80% training and 20% testing set by simple random sample. This was employed to make sure that the test risk is an unbiased estimate of true risk. After the split it was found that the training set was imbalanced. In order to combat this, Synthetic Minority Over-sampling Technique (SMOTE) would be employed such that it would both oversample and undersample the training data in order to create a 50:50 balance. This would both exaggerate the minority and majority population of the training set and reduce estimation error due to bias."},{"metadata":{"trusted":false,"_uuid":"2a94bc44c237fe9d36730b2f3535c40d94c1ebb2"},"cell_type":"code","source":"filename='german_credit_data.csv'\ndf = pd.read_csv(filename,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"63870e7f2a960096d62710874791b6d8ec464c3e"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"055acf919d58be5fdd11c072f3707a6a3f1beddb"},"cell_type":"code","source":"# pension age based on gender\npension = (df['Age'] >= 65) & (df['Sex'] == ('female')) | (df['Age'] >= 65) & (df['Sex'] == ('male'))\n\n# discriminate based on quantiles of credit amount\ndf['Credit amount'].quantile([.25,.75])\n\ncredit = []\nfor i in df['Credit amount']:\n    if i < df['Credit amount'].quantile(.25):\n        credit.append('low')\n    elif i < df['Credit amount'].quantile(.75):\n        credit.append('med')\n    else:\n        credit.append('high')\n# discriminate based on duration of loans in month if less than 12 then it's a short term loan, long term otherwise.\n\nduration = []\nfor i in df['Duration']:\n    if i < 12:\n        duration.append('short')\n    else:\n        duration.append('long')\n\n# clean whitespace on column names to not fuck shit up\ndf.columns = df.columns.str.replace(' ', '')\n# create new dataframe\ndf_clean = pd.DataFrame(columns=['sex','housing','job','purpose','sav','chq','amt','duration','pension'])\ndf_clean = df_clean.fillna(0)\n\n# factorize all categorical variables, take the log of credit amount because it's better to work in the log scale for money\ndf_clean['sex'] = pd.factorize(df.Sex)[0]\ndf_clean['housing'] = pd.factorize(df.Housing)[0]\ndf_clean['job'] = pd.factorize(df.Job)[0]\ndf_clean['purpose'] = pd.factorize(df.Purpose)[0]\ndf_clean['sav'] = pd.factorize(df.Savingaccounts)[0] + 1\ndf_clean['chq'] = pd.factorize(df.Checkingaccount)[0] + 1\ndf_clean['pension'] = pd.factorize(pension)[0]\ndf_clean['amt'] = pd.factorize(credit)[0]\ndf_clean['duration'] = pd.factorize(duration)[0]\n\n# good risk = 0, bad risk = 1\nlabel = pd.factorize(df[\"Risk\"].values)[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5880a5e8f85c165bbba2be4412b3e398b7f9c571"},"cell_type":"code","source":"df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"0ea6351df8f0a77cd7e2a8bf975241d80ce223f6"},"cell_type":"code","source":"# in order to replicate the experiment\nseed = 1992\n# split data for training and holdout test set\ndata_train, data_test, label_train, label_test = train_test_split(df_clean, label, test_size = 0.20, random_state=seed)\n\n# SMOTE to oversample and undersample\nsm = SMOTE(random_state=seed)\ndata_train, label_train = sm.fit_resample(data_train, label_train)\n\n# using stratified k fold in order to get equal proportion of data\nskf = StratifiedKFold(n_splits=4, random_state=seed, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b9b2f0a94a9e94fd13c7ab19b85966c35364919"},"cell_type":"markdown","source":"# Training\n## Methods\nThese five following classifiers are chosen to solve the task of binary classification: \n\n$h_1$: Logistic regression with a regularization parameter of 0.8 and the rest of the parameters are chosen as default. \n\n\n$h_2$: Support vector machines with a polynomial kernel of degree 2, the rest of the parameters are chosen by default.\n\n\n$h_4$: Random forest with 6 trees with maximum depth equal to the number of features after adding the dummy variables were chosen as parameters of this algorithm. The maximum depth was chosen because the data was transformed to a purely categorical one, and the maximum depth of the tree will enable all permutations of the categorical variables to work. The rest of the parameters are chosen as default.\n\n\n$h_5$: K Nearest Neighbor with $k=7$ and with default parameters for the rest.\n\n\n$h_6$: Artifiicial Neural Network with a hidden layer, sigmoid activation function and Stochastic Gradient Descent to tune its weights as parameters. The rest of the hyper parameters are default values from the function itself.\n\n## Crossvalidation\n\nAfter preprocessing the data and finally achieving a train and test split, it is then possible to employ cross validation on the training set. Stratified k-fold is chosen in order to preserve the 50:50 balance of the training data. In this data, four folds were chosen and all the algorithms were run through each permutation of the folds of the data once. The best classifier score out of the four folds will determine the best model of each algorithm which will then be used on the testing set."},{"metadata":{"trusted":false,"_uuid":"bf999434a5c2c0b1c8fa35638dd04f466bcc3e43"},"cell_type":"code","source":"# ml models\nl = LogisticRegression(C=0.8, random_state = seed, solver='liblinear')\nr = RandomForestClassifier(n_estimators=6,max_depth=31, random_state= seed)\ns = SVC(kernel='poly', degree=3, gamma=2, probability=True, random_state = seed)\nk = KNeighborsClassifier(n_neighbors=7)\na = MLPClassifier(solver='sgd', activation='relu', alpha=1e-5,hidden_layer_sizes=(9,), random_state=seed)\n\n# One hot encoding (dummy variables)\nenc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(data_train)\nX_train_one_hot = enc.transform(data_train)\nX_test_one_hot = enc.transform(data_test)\n\nX_train = []\nX_test = []\ny_train = []\ny_test = []\n\n# Stratified K-fold\nfor train_index, test_index in skf.split(X_train_one_hot, label_train):\n    train_data, test_data = X_train_one_hot[train_index], X_train_one_hot[test_index]\n    X_train.append(train_data)\n    X_test.append(test_data)\n    \n    train_label, test_label = label_train[train_index], label_train[test_index]\n    y_train.append(train_label)\n    y_test.append(test_label)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"57a32b9e93dd9df7848095847915aa5cf46bc1a7"},"cell_type":"code","source":"# testing 0 1 loss\nl_test_error = [];\ns_test_error = [];\nr_test_error = [];\nk_test_error = [];\na_test_error = [];\nl_pred = []\ns_pred = []\nr_pred = []\nk_pred = []\na_pred = []\n\n\nfor i in range(4):\n    l.fit(X_train[i],y_train[i])\n    s.fit(X_train[i],y_train[i])\n    r.fit(X_train[i],y_train[i])\n    k.fit(X_train[i],y_train[i])   \n    a.fit(X_train[i],y_train[i])  \n\n    l_pred.append(l.predict(X_test[i]))\n    l_test_error.append(balanced_accuracy_score(y_test[i],l_pred[i]))\n    s_pred.append(s.predict(X_test[i])) \n    s_test_error.append(balanced_accuracy_score(y_test[i],s_pred[i]))\n    \n    r_pred.append(r.predict(X_test[i]))\n    r_test_error.append(balanced_accuracy_score(y_test[i],r_pred[i]))    \n    k_pred.append(k.predict(X_test[i]))\n    k_test_error.append(balanced_accuracy_score(y_test[i],k_pred[i]))  \n    a_pred.append(a.predict(X_test[i]))\n    a_test_error.append(balanced_accuracy_score(y_test[i],a_pred[i]))\n\nindex = []\nindex.append(l_test_error.index(max(l_test_error)))\nindex.append(s_test_error.index(max(s_test_error)))\nindex.append(r_test_error.index(max(r_test_error)))\nindex.append(k_test_error.index(max(k_test_error)))\nindex.append(a_test_error.index(max(a_test_error)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"511b9d4b976783da24c326983e834bc50192ddef"},"cell_type":"markdown","source":""},{"metadata":{"trusted":false,"_uuid":"e2d6ac1915d34f3f520254f1b6326052e48be7a5"},"cell_type":"code","source":"l.fit(X_train[index[0]],y_train[index[0]])\ns.fit(X_train[index[1]],y_train[index[1]])\nr.fit(X_train[index[2]],y_train[index[2]])\nk.fit(X_train[index[3]],y_train[index[3]])   \na.fit(X_train[index[4]],y_train[index[4]])  \n\nl_test_pred = l.predict(X_test_one_hot)\ns_test_pred = s.predict(X_test_one_hot)\nr_test_pred = r.predict(X_test_one_hot)\nk_test_pred = k.predict(X_test_one_hot)\na_test_pred = a.predict(X_test_one_hot)\n\nempirical_risk = []\n\nempirical_risk.append(zero_one_loss(label_test,l_test_pred))\nempirical_risk.append(zero_one_loss(label_test,s_test_pred))\nempirical_risk.append(zero_one_loss(label_test,r_test_pred))\nempirical_risk.append(zero_one_loss(label_test,k_test_pred))\nempirical_risk.append(zero_one_loss(label_test,a_test_pred))\n\n\nm = X_test_one_hot.shape[0]\n\nprint(empirical_risk)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f25c360a5bf4c4164c3328305ae34d10f780cab1"},"cell_type":"markdown","source":"# Analysis\n\n## Empirical Risk\nThe empirical risk of each classifier were found to be as follows:\n$L_S(h_1) = 0.275$  \n$L_S(h_2) = 0.345$  \n$L_S(h_3) = 0.320$  \n$L_S(h_4) = 0.345$  \n$L_S(h_5) = 0.300$  \n\n## Hoeffding's Bound on Empirical Risk with a zero-one loss function\nThe Hoeffding's bounds were chosen because they offer a tighter bound compared to the usual methods. The confidence intervals were computed as follows:  \n\n$P(|L_{S_{test}}(h_i) - L_S(h_i)|) \\geq \\sqrt{\\frac{\\log 2/\\delta}{2m}}$ for  $i \\in 1,2,3,5,4,6$\n\n\nWhere $m = 200$, or size of testing set.\n\nBased on the one-at-time 95% and 99% confidence intervals, logistic regression was the classifier with the tightest upper bound on the empirical risk. However, based on both te 95% and 99% simultaneous confidence intervals, with equal weights given to each classifer, it is possible to conclude that there are no statistically significant difference between each classifier's empirical risk."},{"metadata":{"trusted":false,"_uuid":"5e4bc10135ca1d6f280c6a11f41e7a3b124a4059"},"cell_type":"code","source":"delta = 0.05\nhoeffding = np.sqrt(float(np.log(2/delta))/(float(2)*m))\nlower = empirical_risk - hoeffding\nupper = empirical_risk + hoeffding\nhoeffding_ci = [lower,upper]\n\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], empirical_risk, yerr=hoeffding, linestyle='',fmt=\"o\")\nplt.title(\"Hoeffding's 95% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0,0.6])\nplt.xlabel('Classifier')\nplt.ylabel('Empirical Risk')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c7f30951d426b6d14a2d6af846557d73b940a4d"},"cell_type":"markdown","source":"\ndelta = 0.01\nhoeffding = np.sqrt(float(np.log(2/delta))/(float(2)*m))\nlower = empirical_risk - hoeffding\nupper = empirical_risk + hoeffding\nhoeffding_ci = [lower,upper]\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], empirical_risk, yerr=hoeffding, linestyle='',fmt=\"o\")\nplt.title(\"Hoeffding's 99% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0,0.6])\nplt.xlabel('Classifier')\nplt.ylabel('Empirical Risk')\nplt.show()"},{"metadata":{"trusted":false,"_uuid":"fb96b69d82518c09de62b9353360a9a9c854d3f3"},"cell_type":"code","source":"delta = 0.05/5\nhoeffding = np.sqrt(float(np.log(2/delta))/(float(2)*m))\nlower = empirical_risk - hoeffding\nupper = empirical_risk + hoeffding\nhoeffding_ci = [lower,upper]\n\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], empirical_risk, yerr=hoeffding, linestyle='',fmt=\"o\")\nplt.title(\"Hoeffding's Simultaneous 95% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0,0.6])\nplt.xlabel('Classifier')\nplt.ylabel('Empirical Risk')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"f7eb846b16d624f9e173ea3089da1f1a33decd3f"},"cell_type":"code","source":"delta = 0.01/5\nhoeffding = np.sqrt(float(np.log(2/delta))/(float(2)*m))\nlower = empirical_risk - hoeffding\nupper = empirical_risk + hoeffding\nhoeffding_ci = [lower,upper]\n\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], empirical_risk, yerr=hoeffding, linestyle='',fmt=\"o\")\nplt.title(\"Hoeffding's Simultaneous 99% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0,0.5])\nplt.xlabel('Classifier')\nplt.ylabel('Empirical Risk')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f5922e9de4e72243294751374ecb9f919cd40665"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5493423c153212ee9f37bf5cf78beae37e11a707"},"cell_type":"code","source":"print(avg_prec)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c655055a9897cbb1a70f1bc4639078807e95c3b"},"cell_type":"markdown","source":"## Average Precision Score\nPrecision and recall curve measures the ratio of true positives over the sum of true and negative\npositives. However, the difficulty of assessing the curve itself has lend a way to using it's Average Precision Score. The higher the average precision score of a classifier, the better the classifier is at minimizing false positives. The average precision score of classifier $h_i$ will denoted as $APS(h_i)$.\n\nThe average precision score of each classifier are:\n$APS(h_1) = 0.649$\n$APS(h_2) = 0.487$\n$APS(h_3) = 0.517$\n$APS(h_4) = 0.530$\n$APS(h_5) = 0.684$\n\n\n## Bootstrap bounds on Average Precision Score\n\nSince, the precision scores are unique according to each testing set. A method (Evans & Rosenthal, p. 355) devised to find the standard error by resampling from an empirical cumulative distribution function. Resamples are drawn with replacement on the testing data and then its average precision score is calculated. This process is repeated for $10^4$ times in order to generate an empirical distribution function and which in turn will generate a standard error. Then a studentized $\\gamma$-confidence interval of the average precision score can be computed as follows:\n\n$APS(h_i) \\pm t_{(1+\\gamma)/2}(n-1) \\cdot \\sqrt{Var(APS(h_i))}$ for $i = 1,2,3,4,5$\n\nBased on the 95% and 99% confidence intervals, the neural network has the tightest lower bound on the average precision score. While on the simultaneous 95% confidence intervals, there is a clear separation between the average precision score of the single layer neural network and the support vector machine with polynomial kernel. However, at the simultaneous 99% confidence interval all the classifier's average precision score overlaps again."},{"metadata":{"trusted":false,"_uuid":"4f4d4e246377c35683fc0f843743969d75c3d3ac"},"cell_type":"code","source":"\navg_prec = []\navg_prec.append(average_precision_score(label_test,l.predict_proba(X_test_one_hot)[:,1]))\navg_prec.append(average_precision_score(label_test,s.predict_proba(X_test_one_hot)[:,1]))\navg_prec.append(average_precision_score(label_test,r.predict_proba(X_test_one_hot)[:,1]))\navg_prec.append(average_precision_score(label_test,k.predict_proba(X_test_one_hot)[:,1]))\navg_prec.append(average_precision_score(label_test,a.predict_proba(X_test_one_hot)[:,1]))\n\n\n## bootstrap for confidence interval\nn_bootstraps = 10000\nbootstrap_prec = []\nfor i in range(5):\n    bootstrap_prec.append([])\n\nrng = np.random.RandomState(seed)\nfor i in range(n_bootstraps):\n    indices = rng.randint(0, len(label_test) - 1, len(label_test))\n    bootstrap_prec[0].append(average_precision_score(label_test[indices],l.predict_proba(X_test_one_hot[indices,])[:,1], pos_label = 0))\n    bootstrap_prec[1].append(average_precision_score(label_test[indices],s.predict_proba(X_test_one_hot[indices,])[:,1], pos_label = 0))\n    bootstrap_prec[2].append(average_precision_score(label_test[indices],r.predict_proba(X_test_one_hot[indices,])[:,1], pos_label = 0))\n    bootstrap_prec[3].append(average_precision_score(label_test[indices],k.predict_proba(X_test_one_hot[indices,])[:,1], pos_label = 0))\n    bootstrap_prec[4].append(average_precision_score(label_test[indices],a.predict_proba(X_test_one_hot[indices,])[:,1], pos_label = 0))\n\n# get standard errors to build the t student confidence interval via bootstrapping\nstd_error = []\nfor i in range(5):\n    std_error.append(np.sqrt(np.var(bootstrap_prec[i])))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7208afbdafcc134f6fff9298fb09e3de89be0ad3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"32b644cad9b59abbd5671dc6c5feb7d6d7f756e2"},"cell_type":"code","source":"alpha = 0.05\nt_stat = t.ppf((1-alpha+1)/2, df = n_bootstraps - 1)\nupper_lower_bound = t_stat*std_error[0]\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], avg_prec, yerr=upper_lower_bound, linestyle='',fmt=\"o\")\nplt.title(\"Average Precision Score 95% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0.3,0.8])\nplt.xlabel('Classifier')\nplt.ylabel('Average Precision Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"25f6bf056da5254b47a89a1ff2381bb4ebda3216"},"cell_type":"code","source":"alpha = 0.01\nt_stat = t.ppf((1-alpha+1)/2, df = n_bootstraps - 1)\nupper_lower_bound = t_stat*std_error[0]\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], avg_prec, yerr=upper_lower_bound, linestyle='',fmt=\"o\")\nplt.title(\"Average Precision Score 99% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0.3,0.8])\nplt.xlabel('Classifier')\nplt.ylabel('Average Precision Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a6d88bcc174b09ba2e6c895d736f996744a31fec"},"cell_type":"code","source":"alpha = 0.05/5\nt_stat = t.ppf((1-alpha+1)/2, df = n_bootstraps - 1)\nupper_lower_bound = t_stat*std_error[0]\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], avg_prec, yerr=upper_lower_bound, linestyle='',fmt=\"o\")\nplt.title(\"Average Precision Score Simultaneous 95% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0.3,0.9])\nplt.xlabel('Classifier')\nplt.ylabel('Average Precision Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bb2f510d753f0b34712d006f120eb22e3d9b09f5"},"cell_type":"code","source":"alpha = 0.01/5\nt_stat = t.ppf((1-alpha+1)/2, df = n_bootstraps - 1)\nupper_lower_bound = t_stat*std_error[0]\n\nplt.errorbar([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\"], avg_prec, yerr=upper_lower_bound, linestyle='',fmt=\"o\")\nplt.title(\"Average Precision Score Simultaneous 99% Confidence Interval\")\naxes = plt.gca()\naxes.set_ylim([0.3,0.9])\nplt.xlabel('Classifier')\nplt.ylabel('Average Precision Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4fd8bbe39208b895097fd61061bc8c88e2ece39e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93a60c38448e6a58190b7d0760d9455172dcf444"},"cell_type":"markdown","source":"\n\n# Improvements\nThe biggest omission of this experiment is hyper parameter tuning. Since, all the parameters were chosen by inspecting the training errors directly, it may have been that the final parameters chosen are not optimal. For future runs of this experiment this can be implemented. However, all results of this experiment can be replicated by using the same seed on the supplementary code.\n\n# Conclusion\nBased on the zero one loss metric, it was discovered that there perhaps may not be a better classifier out of the five since the simultaneous confidence interval overlaps with each classifiers empirical risk. Also based on the average precision score, it was also discovered that at the boot-strap simultaneous 99% confidence interval there are no better classifier.  However, based on the tightest upper bound of the empirical risk, the logistic regression will be the classifier of choice for this run of the experiment.  While, based on the tightest lower bound of the average precision score, the single layer neural network will be the classifier of choice for this run of the experiment."},{"metadata":{"trusted":false,"_uuid":"927c33ff2d7061996ad81e3edd54c0652ea1e26b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}