{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import packages\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read data\ntraining_features_data = pd.read_csv(\"../input/flu-shot-learning-h1n1-seasonal-flu-vaccines/training_set_features.csv\",\n                    sep=',')\n\n\ntraining_set_labels = pd.read_csv(\"../input/flu-shot-learning-h1n1-seasonal-flu-vaccines/training_set_labels.csv\",\n                    sep=',')\n\n\ntest_features_data = pd.read_csv(\"../input/flu-shot-learning-h1n1-seasonal-flu-vaccines/test_set_features.csv\",\n                    sep=',')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_features_data.shape)  \nprint(training_set_labels.shape) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **here is preprocessing for train dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#eliminate null values\n\n#for float types\ntraining_features_data=training_features_data.fillna(training_features_data.mean())\n\n#for string types\ntraining_features_data=training_features_data.fillna('out-of-category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check no missing values are left \ntraining_features_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoding categorical features (str-->float)\nenc = OrdinalEncoder()\n\nenc.fit(training_features_data)\ntraining_features_data_arr=enc.transform(training_features_data)\n\ncol_names_list=training_features_data.columns\nencoded_categorical_df=pd.DataFrame(training_features_data_arr, columns=col_names_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalization(make all values bet. 0-1)\nscaler = StandardScaler()\nscaler.fit(encoded_categorical_df)\nnormalized_arr=scaler.transform(encoded_categorical_df)\n\nnormalized_df=pd.DataFrame(normalized_arr, columns=col_names_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check if data types are correct or not \nnormalized_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **test dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check types of test dataset\ntest_features_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#eliminate null values\n\n#for float types\ntest_features_data=test_features_data.fillna(test_features_data.mean())\n\n#for string types\ntest_features_data=test_features_data.fillna('out-of-category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check no missing values are left \ntest_features_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoding categorical features  (str-->float)\nenc = OrdinalEncoder()\nenc.fit(test_features_data)\ntest_features_data_arr=enc.transform(test_features_data)\n\ncol_names_list=test_features_data.columns\ntest_encoded_categorical_df=pd.DataFrame(test_features_data_arr, columns=col_names_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check data types\ntest_encoded_categorical_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalization(bet. 0-1)\n\n#using minmax scaler(look up)\ntest_normalized_arr=scaler.transform(test_encoded_categorical_df)\ntest_normalized_df=pd.DataFrame(test_normalized_arr, columns=col_names_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import sklearn methods \nfrom sklearn.metrics import roc_curve, classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split df to X and Y\ny = training_set_labels.loc[:, 'h1n1_vaccine'].values\nX = normalized_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into 80-20 for training set / test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n\n# cross-validation with 5 splits\ncv = StratifiedShuffleSplit(n_splits=5, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display test scores and return result string and indexes of false samples\ndef display_test_scores(test, pred):\n    str_out = \"\"\n    str_out += (\"TEST SCORES\\n\")\n    str_out += (\"\\n\")\n\n    #print AUC score\n    auc = roc_auc_score(test, pred)\n    str_out += (\"AUC: {:.4f}\\n\".format(auc))\n    str_out += (\"\\n\")\n    \n    false_indexes = np.where(test != pred)\n    return str_out, false_indexes\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regressor-1: Decision Tree regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"#decision tree regressor\nregressor = DecisionTreeRegressor(random_state = 0)\n\n# parameters \nparameters = {\n                \"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n                \"splitter\": [\"best\",\"random\"],\n                }\n\n# grid search for parameters\ngrid1 = GridSearchCV(estimator=regressor, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid1.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid1.best_params_, grid1.best_score_))\n\n# detailed dataframe of gridsearch\ndetailed_grid_results1 = pd.DataFrame(grid1.cv_results_)\ndetailed_grid_results1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction results\ny_pred1 = grid1.predict(X_test)\n\n# print accuracy metrics\nresults1, false1 = display_test_scores(y_test, y_pred1)\nprint(results1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regressor-2: Bayesian-Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bayesian Ridge for regression \n\nclf_ridge = linear_model.BayesianRidge()\n\n\n# parameters \nparameters = {\n                'alpha_init': [None, 1],\n                'lambda_init': [1, 1e-3],\n            }\n\n\n# grid search for parameters\ngrid2 = GridSearchCV(estimator=clf_ridge, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid2.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid2.best_params_, grid2.best_score_))\n\n# prediction results\ny_pred2 = grid2.predict(X_test)\n\n\n# print accuracy metrics\nresults2, false2 = display_test_scores(y_test, y_pred2)\nprint(results2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regressor-3: SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"regr = SVR(C=1.0, epsilon=0.2)\n\n# parameters \nparameters = {\n                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                'C': [0.01,0.1,1,10,100],\n                'max_iter': [100,1000],\n            }\n\n# grid search for parameters\ngrid3 = GridSearchCV(estimator=regr, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid3.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid3.best_params_, grid3.best_score_))\n\n# prediction results\ny_pred3 = grid3.predict(X_test)\n\n# print accuracy metrics\nresults3, false3 = display_test_scores(y_test, y_pred3)\nprint(results3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regressor-4: SGDRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = SGDRegressor( tol=1e-3)\n\n\n# parameters \nparameters = {\n                'alpha': [0.0001, 0.001, 0.01, 1],\n                'max_iter': [10,100,1000],\n                'learning_rate': ['invscaling', 'optimal', 'adaptive'],\n            }\n\n# grid search for parameters\ngrid4 = GridSearchCV(estimator=reg, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid4.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid4.best_params_, grid4.best_score_))\n\n\n# prediction results\ny_pred4 = grid.4predict(X_test)\n\n# print accuracy metrics\nresults4, false4 = display_test_scores(y_test, y_pred4)\nprint(results4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regressor-5: RandomForestRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr = RandomForestRegressor(random_state=0)\n\n# parameters \nparameters = {\n                'n_estimators': [20, 50, 100],\n            }\n\n# grid search for parameters\ngrid5 = GridSearchCV(estimator=rfr, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid5.fit(X_train, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid5.best_params_, grid5.best_score_))\n\n\n\n# prediction results\ny_pred5 = grid5.predict(X_test)\n\n# print accuracy metrics\nresults5, false5 = display_test_scores(y_test, y_pred5)\nprint(results5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# t-test"},{"metadata":{},"cell_type":"markdown","source":">  if p-value<=0.05 --> difference of two model is significant(yani iki modelin farkı belirgin, yani iki model farklı)\n\n>  if p-value>0.05 --> difference of two model is NOT significant(yani iki model çok farklı değil)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import mean_absolute_error\nfrom scipy import stats\n\n#test_size=%20\nn_splits = 5\n\n#test_size_list=[0.50, .30, .10]\n\n#for i in test_size_list:\n\nsss = StratifiedShuffleSplit(n_splits=n_splits, random_state=42, test_size=0.2)\n\nmodel_1 = RandomForestRegressor(random_state=0, n_estimators=100)\nmodel_2 = SGDRegressor(alpha= 0.001, learning_rate='adaptive', max_iter=100)\nmodel_3 = linear_model.BayesianRidge(alpha_init=None, lambda_init= 0.001)\n\n\ncv_mae_1 = []\ncv_mae_2 = []\ncv_mae_3 = []\n\n\n\nfor X_train_list, X_test_list in sss.split(X,y):\n    model_1.fit(X.loc[X_train_list], y[X_train_list])\n    pred_1 = model_1.predict(X.loc[X_test_list])\n    err_1 = mean_absolute_error(y[X_test_list], pred_1)\n    cv_mae_1.append(err_1)\n\n\n    model_2.fit(X.loc[X_train_list], y[X_train_list])\n    pred_2 = model_2.predict(X.loc[X_test_list])\n    err_2 = mean_absolute_error(y[X_test_list], pred_2)\n    cv_mae_2.append(err_2)\n\n    model_3.fit(X.loc[X_train_list], y[X_train_list])\n    pred_3 = model_3.predict(X.loc[X_test_list])\n    err_3 = mean_absolute_error(y[X_test_list], pred_3)\n    cv_mae_3.append(err_3)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nprint(stats.ttest_rel(cv_mae_1,cv_mae_2))\nprint(stats.ttest_rel(cv_mae_3,cv_mae_2))\nprint(stats.ttest_rel(cv_mae_3,cv_mae_1))\n\n#üç modeli karşılaştırdık; hepsi significant çıktı, en büyük olan modeli seçiyoruz, eyv:dd\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bayesian Ridge for regression \n\n#clf_ridge = linear_model.BayesianRidge(alpha_init=None, lambda_init=0.001)\n#clf_ridge.fit(X,y)\n\n# prediction results\n#y_pred = clf_ridge.predict(test_normalized_df)\n\n#y_pred = 1/(1+np.exp(-y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random forest regressor\n\nrfr = RandomForestRegressor(random_state=0, n_estimators=100)\nrfr.fit(X,y)\n\n# prediction results\ny_pred = rfr.predict(test_normalized_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(np.logical_or(np.array(y_pred) > 1, np.array(y_pred) < 0), axis=0)\n\ny_pred[:10]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}