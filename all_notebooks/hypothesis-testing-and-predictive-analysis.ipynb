{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2e392be2-f09d-7083-84c3-87877ead3963"},"source":"This report aims at understanding and applying **Hypothesis testing** methods such as <br>\n1.  **Normal Distribution**<br>\n2. **Student t Distribution**<br>\n3. **ANOVA**<br>\n\nSome **Machine learning** tecniques such as <br>\n1. **Random Forests** <br>\n2. **Linear Regressor**<br>\nare also used to do **predictive analysis** \n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ef82d69-83cd-8ce5-49da-98d3760ba1f3"},"outputs":[],"source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport statistics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import KFold   #For K-fold cross validation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn import metrics"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaa9b895-2309-9dd4-121b-05e2278187bd"},"outputs":[],"source":"payroll = pd.read_csv(\"../input/data.csv\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"22cbceb4-cca4-9fe1-82e9-667a35f7b655"},"source":"**Data Cleansing**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c8a29ff-6f6b-6156-8cbc-32ab3ca32ad5"},"outputs":[],"source":"payroll = payroll[pd.notnull(payroll['Payroll Department'])]\npayroll.rename(columns={'Projected Annual Salary' : 'Annual_sal'}, inplace = True)\npayroll.rename(columns={'Job Class Title' : 'Job_title'}, inplace = True)\npayroll.rename(columns={'Base Pay' : 'Base_Pay'}, inplace = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14c499e4-c66b-d358-1c78-c40e5ef5948b"},"outputs":[],"source":"for i in ['Annual_sal','Q1 Payments','Q2 Payments','Q3 Payments','Q4 Payments','Payments Over Base Pay',\n          'Total Payments','Base_Pay','Permanent Bonus Pay','Longevity Bonus Pay','Temporary Bonus Pay','Overtime Pay',\n          'Other Pay & Adjustments','Other Pay (Payroll Explorer)','Average Health Cost','Average Dental Cost',\n          'Average Basic Life','Average Benefit Cost']:\n    payroll[i] = payroll[i].str.replace('$','')"},{"cell_type":"markdown","metadata":{"_cell_guid":"c6862512-0f12-d11f-9dfb-5ed1b6b5350d"},"source":"**Outlier removal**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af8308fc-8a70-a7be-92c5-c16f1a2f30cf"},"outputs":[],"source":"payroll = payroll[payroll.Annual_sal != 0]  \npayroll = payroll[payroll.Base_Pay != 0]\npayroll.Annual_sal = payroll.Annual_sal.astype(float)\npayroll.Base_Pay = payroll.Base_Pay.astype(float)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d21c2cb-5cd0-6029-c73c-16d81168c93b"},"outputs":[],"source":"plt.figure(figsize = (12,6))\nsns.distplot(payroll.Annual_sal,color = 'darkgreen')"},{"cell_type":"markdown","metadata":{"_cell_guid":"641b8314-8549-4161-d70c-8929d0ff1028"},"source":"**Creating different Sample  from the population**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c5a578a-06c6-9db9-30db-95a9ad7d7c55"},"outputs":[],"source":"payroll_2015 = payroll[payroll.Year ==2015]\npayroll_2016 = payroll[payroll.Year ==2016]"},{"cell_type":"markdown","metadata":{"_cell_guid":"7e402c97-0a74-fad3-7343-cd64719400a4"},"source":"**Calculating the Population Parameters**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78af4e8c-b491-1802-26e9-f28fd8218fe1"},"outputs":[],"source":"pop_mean_2015 = payroll_2015['Annual_sal'].mean()\npop_std_2015 = statistics.stdev(payroll_2015.Annual_sal)\nprint(\"Population Mean: \"+str(pop_mean_2015))\nprint(\"Population Standard Deviation: \"+str(pop_std_2015))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f7fc0bb7-c6b2-ec72-e56c-e9428fa67f8f"},"source":"**Calculating the Sample Parameters**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59bd0435-89ef-e041-343b-8b64d2d82c3c"},"outputs":[],"source":"print(\"Population Mean: \"+str(payroll_2016['Annual_sal'].mean()))\npayroll_2016_sample = payroll_2016.sample(frac=0.10)\nsample_mean_2016 = payroll_2016_sample['Annual_sal'].mean()\nprint(\"Sample Mean: \"+str(sample_mean_2016))\nsample_std_2016 = statistics.stdev(payroll_2016_sample.Annual_sal)\nprint(\"Sample Standard Deviation: \"+str(sample_std_2016))"},{"cell_type":"markdown","metadata":{"_cell_guid":"128407af-dcf5-5092-1529-41fdc4859db9"},"source":"**Hypothesis Testing**"},{"cell_type":"markdown","metadata":{"_cell_guid":"6e981fd5-2b23-a17a-a4cb-edbdb9f5fefd"},"source":"<b>Normal distribution</b><br><br>\n<b>Null Hypothesis</b> : Pay does not increase in 2016<br>\n<b>Alternate Hypothesis</b>: It increases<br>\n<b>Population parameters</b>: Mean = pop_mean_2015, standard deviation = pop_std_2015<br>\n<b>Sample parameters</b> :   Mean = sample_mean_2016, standard deviation = sample_std_2016<br>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b09beb1-4545-3921-ffdb-1e02108cbf84"},"outputs":[],"source":"import math\n# Confidence Level 95 %  for one sided Normal curve\nzscore_critical = 1.65 \n# Calculate the test statistics \nzscore_test_stat = ((sample_mean_2016 - pop_mean_2015)*math.sqrt(8916))/sample_std_2016\nprint(zscore_test_stat)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c1172db8-c85a-481d-8239-540955253c68"},"source":"<b>Conclusion</b>: As the test statistics fall into the rejection region the null hypothesis is rejected<br>\nand it can be concluded that the Annual salaries increase in 2016.<br>\nHowever, we will first check for the <b>Type 1</b> and <b>Type 2 </b>Errors"},{"cell_type":"markdown","metadata":{"_cell_guid":"b95bd9c7-51fd-175e-c14f-1ea22adedfaf"},"source":"**Type 1 type 2 hypothesis error**<br>\nIn statistical hypothesis testing, a type I error is the incorrect rejection of a true null hypothesis (a \"false positive\"), while a type II error is incorrectly retaining a false null hypothesis (a \"false negative\")."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d0e2a9b-0305-7451-923a-45f7a2a7a56a"},"outputs":[],"source":"# we are basically checking the true value of the population characteristics\npop_mean_2016 = payroll_2016['Annual_sal'].mean()\npop_std_2016 = statistics.stdev(payroll_2016.Annual_sal)\n\nzscore_error = ((pop_mean_2016 - pop_mean_2015)/pop_std_2016)\nprint(zscore_error)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f052b395-0e00-51b0-12ed-466474c59963"},"source":"We can clearly see that we encountered a Type 1 error as the population mean is well within acceptable region"},{"cell_type":"markdown","metadata":{"_cell_guid":"3d8a94fb-41f1-08ad-9ad4-3ba03f2f14ba"},"source":"**Student T-distribution**<br>\n**Null Hypothesis**: pay does not increase in 2016<br>\n**Alternate Hypothesis**: it increases<br>\n**Population parameters**: Mean = pop_mean_2015, standard deviation = pop_std_2015<br>\n**Sample parameters** : Mean = sample_mean_2016, standard deviation = sample_std_2016<br>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30cec429-224a-6591-fb91-45fa911890fc"},"outputs":[],"source":"#Calculating the Sample Parameters**\npayroll_2014 = payroll[payroll.Year ==2014]\npayroll_2015 = payroll[payroll.Year ==2015]\n# Creating Sample distribution for T statistics\npayroll_t_2015_sample = payroll_2015.sample(frac=0.00062)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4159db7-02aa-a0f3-37c0-f6c632decf0a"},"outputs":[],"source":"payroll_t_2015_sample = payroll_2015.sample(frac=0.00062)\nN = len(payroll_t_2015_sample)\nsample_mean_2015 = payroll_t_2015_sample['Annual_sal'].mean()\nsample_std_2015 = statistics.stdev(payroll_t_2015_sample.Annual_sal)\npop_std_2014  = statistics.stdev(payroll_2014.Annual_sal)\npop_mean_2014 = payroll_2014['Annual_sal'].mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4505916-91db-2189-4097-43f567b5c583"},"outputs":[],"source":"# Confidence Level 95 %  for one sided T curve\nt_critical = 1.311\n\n# Calculate the test statistics \ntscore_test_stat = ((sample_mean_2015 - pop_mean_2014)*math.sqrt(N))/sample_std_2015\n\nprint(tscore_test_stat)"},{"cell_type":"markdown","metadata":{"_cell_guid":"04e74bc0-16a9-d53e-2dbf-938f7a988a42"},"source":"Depending on the Test score , we can accept/Reject the Null"},{"cell_type":"markdown","metadata":{"_cell_guid":"0fba82e3-0385-ba19-15a1-8287a02521c1"},"source":"**** F Distribution and ANOVA**"},{"cell_type":"markdown","metadata":{"_cell_guid":"0daafdb7-aeba-e8c1-0e51-4e751cf05dac"},"source":"The means from three different samples are compared using ANOVA<br>\nIt is similar to applying t-tests over multiple sample\nANOVA : https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide.php"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1ad5c0f-1081-aaf0-c2a4-440c6b7320e0"},"outputs":[],"source":"payroll_2014 = payroll[payroll.Year ==2014]\npayroll_2014_elec = payroll_2014[payroll_2014.Job_title == 'Electrician']\npayroll_2015_elec = payroll_2015[payroll_2015.Job_title == 'Electrician']\npayroll_2016_elec = payroll_2016[payroll_2016.Job_title == 'Electrician']\nsample_elec_2014 = payroll_2014_elec.sample(frac=0.47)\nsample_elec_mean_2014 = sample_elec_2014['Base_Pay'].mean()\nprint(\"Sample Mean 2014 \"+str(sample_elec_mean_2014))\nsample_elec_2015 = payroll_2015_elec.sample(frac=0.41)\nsample_elec_mean_2015 = sample_elec_2015['Base_Pay'].mean()\nprint(\"Sample Mean 2015 \"+str(sample_elec_mean_2015))\nsample_elec_2016 = payroll_2016_elec.sample(frac=0.22)\nsample_elec_mean_2016 = sample_elec_2016['Base_Pay'].mean()\nprint(\"Sample Mean 2016 \"+str(sample_elec_mean_2016))\n# Creating the Samples of the base pays over three years\nsam_1 = sample_elec_2014.Base_Pay\nsam_2 = sample_elec_2015.Base_Pay\nsam_3 = sample_elec_2016.Base_Pay"},{"cell_type":"markdown","metadata":{"_cell_guid":"6c0f7e3e-d2eb-18cb-d14d-c8b45ef950ec"},"source":"**Calculating the test statistics**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d10bc03b-262c-7774-706e-f48e71e4da10"},"outputs":[],"source":"f, p = stats.f_oneway(sam_1, sam_2, sam_3 )\nprint ('F value:', f)\nprint ('P value:', p, '\\n')"},{"cell_type":"markdown","metadata":{"_cell_guid":"1d785156-ace9-6d45-96fa-d8e2b61b7f77"},"source":"P value is very low, hence null hypothesis is rejected"},{"cell_type":"markdown","metadata":{"_cell_guid":"1270aa06-a166-8ab6-d475-d8e03db12b9d"},"source":"**Predictive Analysis using Machine Learning**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80b1f9de-5bd2-4513-0017-2f1fd4d29835"},"outputs":[],"source":"# Transform the qualitative data into vectors\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer(stop_words = 'english')\ndtm = vect.fit_transform(payroll.Job_title)"},{"cell_type":"markdown","metadata":{"_cell_guid":"73f0c9b7-44f4-2bcb-6e2a-4fba98f697d6"},"source":"**Split the data into training and testing datasets**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3f4951b-c078-680d-44db-c52ad6619b26"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split\n\nX = dtm\ny = payroll.Annual_sal\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 100)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f4c48fec-8da9-5caf-4a91-d81ad811393e"},"source":"<b>Random Forest Regressor</b> : It is a form of ensemble learning, it uses many randomized decision trees to<br>\npredict the outcome, hence the name.\n\n<b>Regression</b> is used to predict continous variables whereas <b>Classification</b> is used for predicting<br>\ndiscrete values\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71ae7f0b-a28c-2d66-d8a3-0eede6ba255c"},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\n\nclf = RandomForestRegressor()\nclf.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bcbda5bb-f0cc-7ef0-1345-ebe34bdf9524"},"outputs":[],"source":"from sklearn.metrics import r2_score, mean_squared_error\n\npred_train = clf.predict(X_train)\npred_test = clf.predict(X_test)\n\nprint('Root mean Score Training: {}'.format(r2_score(y_train, pred_train)))\nprint('Root mean Score Testing: {}'.format(r2_score(y_test, pred_test)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"11b4f4f1-9944-94f3-c95a-177aa1272ee5"},"source":"**Visualization for training and testing data prediction accuracy**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68c0c9f0-0320-941e-f44f-677d4c8ad3bb"},"outputs":[],"source":"plt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.plot(np.arange(len(pred_train)), y_train - pred_train,'o')\nplt.axhline(0)\nplt.subplot(1,2,2)\nplt.plot(np.arange(len(pred_test)), y_test - pred_test,'o')\nplt.axhline(0)\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a0d7e348-ccde-5a5f-2cad-e90c4ea8adf2"},"source":"**Linear Regression**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"736f522a-7cf5-3107-2e7e-5ce4cd8660b9"},"outputs":[],"source":"# Selecting the features and creating train test split\ny = payroll[\"Average Benefit Cost\"]\nX = payroll[['Annual_sal','Q1 Payments','Q2 Payments','Q3 Payments','Q4 Payments']].copy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f7e3e11f-1276-206d-40c3-7bc9fe2abee3"},"source":"**Training the model**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7393b81-e542-1c3b-f5b2-a9e3bc09d3b4"},"outputs":[],"source":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nlm.fit(X_train,y_train)\nprint(lm.intercept_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a420e2c-0a89-3777-420d-ad38ea9ba32f"},"outputs":[],"source":"coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])\nranked_suburbs = coeff_df.sort_values(\"Coefficient\", ascending = False)\nprint(ranked_suburbs)"},{"cell_type":"markdown","metadata":{"_cell_guid":"70133ebe-11aa-450a-08d2-c190cf99587e"},"source":"**The coefficient suggests that it has a poor coorelation with the target, hence a poor model is expected**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"228e2c63-7b2f-645a-b9e4-390f3d7cc759"},"outputs":[],"source":"pred_train = lm.predict(X_train)\npred_test = lm.predict(X_test)\nprint('Root mean Score Training: {}'.format(r2_score(y_train, pred_train)))\nprint('Root mean Score Testing: {}'.format(r2_score(y_test, pred_test)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"af949c59-4101-a2df-949a-3112633ffac3"},"source":"**Processing for creating Best Fit Line**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd48871b-2bc6-fee5-69a1-13dee7e4d44b"},"outputs":[],"source":"new = pd.Series(list(y_test)).values\nnew_list =[]\nfor i in range(len(new)):\n    new_list.insert(i,new[i])\nnew_list = [float(q) for q in new_list]\nnew_list = [round(q) for q in new_list]\npred_test = [float(q) for q in pred_test]\npred_test = [round(q) for q in pred_test]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc9760ba-c923-9d72-3a3b-55f439cc721a"},"outputs":[],"source":"# Logic for finding the line of best split\ndef best_fit(X, Y):\n\n    xbar = sum(X)/len(X)\n    ybar = sum(Y)/len(Y)\n    n = len(X) # or len(Y)\n\n    numer = sum([xi*yi for xi,yi in zip(X, Y)]) - n * xbar * ybar\n    denum = sum([xi**2 for xi in X]) - n * xbar**2\n    b = numer/denum\n    a = ybar - b * xbar\n    print('best fit line:\\ny = {:.2f} + {:.2f}x'.format(a, b))\n    return(a,b)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaae03ac-8897-aead-ab4d-4a4782d44108"},"outputs":[],"source":"a, b = best_fit(new_list, pred_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bb2ecf71-c9d2-8a64-2526-79508d3f537b"},"source":"**Visualizing the Best fit line**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2db800b3-74c7-04b5-1cd3-283bf89d54b4"},"outputs":[],"source":"plt.scatter(new_list, pred_test)\nyfit = [a + b * xi for xi in new_list]\nplt.plot(new_list, yfit)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3f16fb0-75c6-e49c-4c90-31ee0f8e97be","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}