{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi all, \n    my name is Jacopo Pierotti and this is my first attempt to analyze some data distribution.\nIn the following notebook, we will analyze the data distribution of the shooting from the police in the U.S.A. during the time period 2015 to mid 2020.\nMOst of this work is based on the very clear notebook by Mrinal (https://www.kaggle.com/mrinaal007/police-shootouts) which I invite you to check.\nMy main extra points with respect to his work are the normalization of the people based on the U.S.A. demographic.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First of all, we import some useful libraries needed for our analyses","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px # data visualization tool\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we load our data and we take a look at the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/data-police-shootings/fatal-police-shootings-data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, we have plenty of useful information but also unuseful one. Hence, we remove the unuseful coloum (id) from the dataset. Then, we transform the data in a more convenient format.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('id', 1)\ndf['month'] = pd.to_datetime(df['date']).dt.month\ndf['year'] = pd.to_datetime(df['date']).dt.year","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We check if the dataframe is missing some information (i.e. some entries are empty).<bf>\nWe compute the percentages of missing data for each coloumn.\nAs we will see, the coloumn with the most unavailable data doesn't have values for about 10% of its entries.\nWe decide that about 90% of the 5000+ rows of the dataframe is still an very good amount of data to consider, so we drop entries without complete information.   \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"uncomplete_data = df.isna().sum()*100/df.shape[0]\nprint(uncomplete_data)\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we check how many different value each coloumn can take and, to ease the reading, we change the string values some entries.\n<br> Trick for non-U.S. citizen not famliar with foreing geography (such as myself), the caridnality of the state coloumn is 51 because there are 50 state + washinton dc which does not belong to any state.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cardinality ={}\nfor col in df.columns:\n    cardinality[col] = df[col].nunique()\n#print(cardinality)\nd = {'A':'Asian','B':'Black','H':'Hispanic', 'N':'Native','O':'Other','W':'White'}\ndf['race'] = df['race'].replace(d)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we start actually analyzing some data. For starter, we display how many shooting -in absolute terms- happend over all the years. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yearly_shootouts = df['year'].value_counts()\nyearly_shootouts = pd.DataFrame(yearly_shootouts)\nyearly_shootouts= yearly_shootouts.reset_index()\nyearly_shootouts=yearly_shootouts.rename(columns={'index':'year','year':'Shootouts'})\nfig = px.bar(yearly_shootouts, y='Shootouts', x='year', barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The trend seems to be decreasing (note that the data for 2020 is incomplete). To have a more accurate idea, we normalize the above figure with respect to the u.s.a. population for those years (data taken form wikipedia). <br>\n*for the data analyst out there, how do you divide a column of a dataframe by a dictionary (where the keys of the dictionary are the row of the dataframe)?*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#yearly_population = {'2015':320.7,'2016':323.1,'2017':325.1,'2018':327.2 ,'2019':328.2,'2020':331.0}\n\nyearly_population_array = [320.7,323.1,325.1,327.2 ,328.2,331.0]\nyearly_shootouts['Shootouts_normalized'] = yearly_shootouts['Shootouts'].div(yearly_population_array).multiply(yearly_population_array[-1])\nfig = px.bar(yearly_shootouts, y='Shootouts_normalized', x='year', barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The previous two barplot show the first main point of this analysys.<br>\n# 1) Police shooting (in absolute and relative terms) have been decreasing in the past 6 years \n<br>\nNote that this is just an observation based on 6 years, which might not be enough to extract a general trend. <br>\nNow we look at other features, such as age distribution, usage of body cams, gender and etnicity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.figure_factory as ff\nfor etn in df['race'].unique():\n    x = df[df['race']==etn]['age']\n    hist_data = [x]\n    group_labels = ['Age_'+str(etn)]\n    fig = ff.create_distplot(hist_data, group_labels)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown from the graph above, most victims are between their twenties and thirties, independently of their etnicity.\nNow we analyze the usage of body cams.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bc_shootout = df['body_camera']\nprint(bc_shootout.value_counts())\nprint(bc_shootout.value_counts()[0]/bc_shootout.value_counts()[1])\nfig = px.histogram(bc_shootout,x='body_camera',color='body_camera')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph above lead to the following main consideration: <br>\n# 2) Police officers are 7.3 times more likely to shoot when their body cameras are deactivated.<br>\nOne small note about this, our data don't tell us if all the police officers had the option to have and wear a body camera. If they didn't the previous point would not be correct.\n\n<br>Hereafter, we analize the gender inequality in police shootings.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for etn in df['race'].unique():\n    gender_per_etn = df[df['race']==etn]['gender']\n    fig = px.histogram(gender_per_etn,x='gender',color='gender',labels={'gender':'gender_'+str(etn)})\n    fig.show()   \ngender_shootout = df['gender']\nprint(gender_shootout.value_counts())\nprint(gender_shootout.value_counts()[0]/gender_shootout.value_counts()[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The previous histograms show us a huge gap between the genders (given the structur of the dataframe, just male and female have been considered).\n# 3) Males are 21.33 times more likely to get shot then females.<br>\nNext, we confront shooting by etnicity, first in absolte terms, then in relative terms.\nAgain, the missing data are taken from wikipedia and refers to the year 2017.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"etn_shootout = df['race']\nprint(etn_shootout.value_counts())\nfig = px.histogram(etn_shootout,x='race',color='race')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's clear that, in absolute term, white people are shot more than anybody else. But white people constitute around 61.5% of the overall population. Let's normalize and see what happen.\n<br>\nAgain, the missing data are taken from wikipedia and refers to the year 2017, due to some small approxiamtion errors (most likely), the sum of the percentage adds up to 100.2, but this small error won't stir the overall trends.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"etn_population_array = [61.5,12.7,17.3, 5.3,0.9,2.5] # unelegant - to correct later\netn_shootouts_norm = pd.DataFrame()\netn_shootouts_norm['etn_shootouts_norm'] = df['race'].value_counts().divide(etn_population_array)\n\nprint(etn_shootouts_norm.head())\nfig = px.bar(etn_shootouts_norm,y='etn_shootouts_norm',color='etn_shootouts_norm', barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These results are probably the most interesting of the all discussion.\n# 4) The trends clearly shows that black and native people are more likely to be shot, followed by hispanic and white people while asian and other nationality are the least likely.\n\n<br> Among the many other things we could still analyze, we decide to focus on the shooting against disarmed and not fleeing people who also don't show any sign of mental illness per etnicity. In some sense, these shooting can be seen as the most unjustified ones. To make a fair comparison, we normalize these shooting with respect to the total count of shooting per etnicity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"innocent_people = df[(df.signs_of_mental_illness==False) & (df.armed =='unarmed') & (df.flee=='Not fleeing')]\nlista= pd.DataFrame()\nlista['count'] = innocent_people['race'].value_counts().divide(df['race'].value_counts())\n\nfig = px.bar(lista, y='count', barmode='group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that:<br>\n# 5) the ratio of very unjustified shooting over total shooting per etnicity is quite constant among all the etnicities.<br>\n(Native and Other present different result because of the small amount of sample) ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This was my analisys on the dataset '/kaggle/input/data-police-shootings/fatal-police-shootings-data.csv' and it is also my first real data analisys. Don't be shy, constructive feedback and comments are very welcome :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}