{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Internet news: Topic Modeling and Search with Top2Vec\n\n[Top2Vec](https://github.com/ddangelov/Top2Vec) is an algorithm for **topic modelling** and **semantic search**. It **automatically** detects topics present in text and generates jointly embedded topic, document and word vectors. Once you train the Top2Vec model you can:\n* Get number of detected topics.\n* Get topics.\n* Search topics by keywords.\n* Search documents by topic.\n* Find similar words.\n* Find similar documents.\n\nThis notebook preprocesses the [Kaggle Internet news data with readers engagement](https://www.kaggle.com/szymonjanowski/internet-articles-data-with-users-engagement), it treats each section of every paper as a distinct document. A Top2Vec model is trained on those documents. \n\nOnce the model is trained you can do **semantic** search for documents by topic, searching for documents with keywords, searching for topics with keywords, and for finding similar words. These methods all leverage the joint topic, document, word embeddings distances, which represent semantic similarity. \n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Import and Setup "},{"metadata":{},"cell_type":"markdown","source":"### 1. Install the [Top2Vec](https://github.com/ddangelov/Top2Vec) library"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install top2vec==1.0.6","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json\nimport os\nfrom top2vec import Top2Vec","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/internet-articles-data-with-users-engagement/articles_data.csv\",\n                usecols = [\"content\"])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hotel_reviews = hotel_reviews_df.Review.values.tolist()\ndf1 = df1.content.values.tolist()\ntype(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[:1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Top2Vec Model\n\n\n\nParameters:\n\n* documents: Input corpus, should be a list of strings.\n* speed: This parameter will determine how fast the model takes to train. The 'fast-learn' option is the fastest and will generate the lowest quality vectors. The 'learn' option will learn better quality vectors but take a longer time to train. The 'deep-learn' option will learn the best quality vectors but will take significant time to train.\n* workers: The amount of worker threads to be used in training the model. Larger amount will lead to faster training.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Top2Vec(documents=df1, speed=\"learn\", workers=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Top2Vec Discovered Topics"},{"metadata":{},"cell_type":"markdown","source":"## 1.Get Number of Topics\n> \nThis will return the number of topics that Top2Vec has found in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_num_topics()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.Get Topics\n\nThis will return the topics in decreasing size."},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_words, word_scores, topic_nums = model.get_topics(82)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Generate Word Clouds\n\nUsing a topic number you can generate a word cloud. We will generate word clouds for topics 70 through 75."},{"metadata":{"trusted":true},"cell_type":"code","source":"for topic in topic_nums[70:75]:\n    model.generate_topic_wordcloud(topic, background_color=\"black\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Search Papers by Topic"},{"metadata":{},"cell_type":"markdown","source":"We are going to search by topic 40"},{"metadata":{"trusted":true},"cell_type":"code","source":"documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=40, num_docs=2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Returns:\n\n*     documents: The documents in a list, the most similar are first.\n\n*     doc_scores: Semantic similarity of document to topic. The cosine similarity of the document and topic vector.\n\n*     doc_ids: Unique ids of documents. If ids were not given, the index of document in the original corpus.\n"},{"metadata":{},"cell_type":"markdown","source":"For each of the returned documents we are going to print its content, score and document number."},{"metadata":{"trusted":true},"cell_type":"code","source":"documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=40, num_docs=2)\nfor doc, score, doc_id in zip(documents, document_scores, document_ids):\n    print(f\"Document: {doc_id}, Score: {score}\")\n    print(\"-----------\")\n    print(doc)\n    print(\"-----------\")\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Similar Keywords\n\nSearch for similar words to football."},{"metadata":{"trusted":true},"cell_type":"code","source":"words, word_scores = model.similar_words(keywords=[\"football\"], keywords_neg=[], num_words=10)\nfor word, score in zip(words, word_scores):\n    print(f\"{word} {score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Search Papers by Keywords\n\nSearch documents for content semantically similar to **games** and **players**."},{"metadata":{"trusted":true},"cell_type":"code","source":"documents, document_scores, document_nums = model.search_documents_by_keyword(keywords=[\"games\", \"players\"], num_docs=4)\nfor doc, score, doc_id in zip(documents, document_scores, document_ids):\n    print(f\"Document: {doc_id}, Score: {score}\")\n    print(\"-----------\")\n    print(doc)\n    print(\"-----------\")\n    print()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}