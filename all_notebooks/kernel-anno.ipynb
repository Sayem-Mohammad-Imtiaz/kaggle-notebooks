{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd \nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nnp.set_printoptions(threshold=np.inf)\n\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\n\n# One great way to analyze the accuracy is by plotting a confusion matrix. First, we declare a custom plotting function.\ndef plotCf(a,b,t):\n    cf =confusion_matrix(a,b)\n    plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')\n    plt.colorbar()\n    plt.title(t)\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    tick_marks = np.arange(len(set(a))) # length of classes\n    class_labels = ['0','1']\n    plt.xticks(tick_marks,class_labels)\n    plt.yticks(tick_marks,class_labels)\n    thresh = cf.max() / 2.\n    for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n        plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n    plt.show();\n\ndef Sigmoid(Z):\n    return 1/(1+np.exp(-Z))\n\ndef Relu(Z):\n    return np.maximum(0,Z)\n\ndef dRelu2(dZ, Z):    \n    dZ[Z <= 0] = 0    \n    return dZ\n\ndef dRelu(x):\n    x[x<=0] = 0\n    x[x>0] = 1\n    return x\n\ndef dSigmoid(Z):\n    s = 1/(1+np.exp(-Z))\n    dZ = s * (1-s)\n    return dZ\n\nclass dlnet:\n    def __init__(self, x, y):\n        self.debug = 0;\n        self.X=x\n        self.Y=y\n        self.Yh=np.zeros((1,self.Y.shape[1])) \n        self.L=2\n        self.dims = [9, 15, 1] \n        self.param = {}\n        self.ch = {}\n        self.grad = {}\n        self.loss = []\n        self.lr=0.003\n        self.sam = self.Y.shape[1]\n        self.threshold=0.5\n        \n    def nInit(self):    \n        np.random.seed(1)\n        self.param['W1'] = np.random.randn(self.dims[1], self.dims[0]) / np.sqrt(self.dims[0]) \n        self.param['b1'] = np.zeros((self.dims[1], 1))        \n        self.param['W2'] = np.random.randn(self.dims[2], self.dims[1]) / np.sqrt(self.dims[1]) \n        self.param['b2'] = np.zeros((self.dims[2], 1))                \n        return \n\n    def forward(self):    \n        Z1 = self.param['W1'].dot(self.X) + self.param['b1'] \n        A1 = Relu(Z1)\n        self.ch['Z1'],self.ch['A1']=Z1,A1\n        \n        Z2 = self.param['W2'].dot(A1) + self.param['b2']  \n        A2 = Sigmoid(Z2)\n        self.ch['Z2'],self.ch['A2']=Z2,A2\n\n        self.Yh=A2\n        loss=self.nloss(A2)\n        return self.Yh, loss\n\n    def nloss(self,Yh):\n        loss = (1./self.sam) * (-np.dot(self.Y,np.log(Yh).T) - np.dot(1-self.Y, np.log(1-Yh).T))    \n        return loss\n\n    def backward(self):\n        dLoss_Yh = - (np.divide(self.Y, self.Yh ) - np.divide(1 - self.Y, 1 - self.Yh))    \n        \n        dLoss_Z2 = dLoss_Yh * dSigmoid(self.ch['Z2'])    \n        dLoss_A1 = np.dot(self.param[\"W2\"].T,dLoss_Z2)\n        dLoss_W2 = 1./self.ch['A1'].shape[1] * np.dot(dLoss_Z2,self.ch['A1'].T)\n        dLoss_b2 = 1./self.ch['A1'].shape[1] * np.dot(dLoss_Z2, np.ones([dLoss_Z2.shape[1],1])) \n                            \n        dLoss_Z1 = dLoss_A1 * dRelu(self.ch['Z1'])        \n        dLoss_A0 = np.dot(self.param[\"W1\"].T,dLoss_Z1)\n        dLoss_W1 = 1./self.X.shape[1] * np.dot(dLoss_Z1,self.X.T)\n        dLoss_b1 = 1./self.X.shape[1] * np.dot(dLoss_Z1, np.ones([dLoss_Z1.shape[1],1]))  \n        \n        self.param[\"W1\"] = self.param[\"W1\"] - self.lr * dLoss_W1\n        self.param[\"b1\"] = self.param[\"b1\"] - self.lr * dLoss_b1\n        self.param[\"W2\"] = self.param[\"W2\"] - self.lr * dLoss_W2\n        self.param[\"b2\"] = self.param[\"b2\"] - self.lr * dLoss_b2\n        \n        return\n\n\n    def pred(self,x, y):  \n        self.X=x\n        self.Y=y\n        comp = np.zeros((1,x.shape[1]))\n        pred, loss= self.forward()    \n    \n        for i in range(0, pred.shape[1]):\n            if pred[0,i] > self.threshold: comp[0,i] = 1\n            else: comp[0,i] = 0\n    \n        print(\"Acc: \" + str(np.sum((comp == y)/x.shape[1])))\n        \n        return comp\n    \n    def gd(self,X, Y, iter = 3000):\n        np.random.seed(1)                         \n    \n        self.nInit()\n    \n        for i in range(0, iter):\n            Yh, loss=self.forward()\n            self.backward()\n        \n            if i % 500 == 0:\n                print (\"Cost after iteration %i: %f\" %(i, loss))\n                self.loss.append(loss)\n\n        plt.plot(np.squeeze(self.loss))\n        plt.ylabel('Loss')\n        plt.xlabel('Iter')\n        plt.title(\"Lr =\" + str(self.lr))\n        plt.show()\n    \n        return\n    \ndf = pd.read_csv('../input/dataset2/wisconsin-cancer-dataset.csv',header=None)\n# Then we proceed to eliminate all rows that hold missing values (represented by the ? character), \n# which we have identified as the column that holds them.\ndf = df[~df[6].isin(['?'])]\n# The ‘?’ character causes Python to interpret columns as made of strings. Other columns are made of integers. \n# We set the entire dataframe to be interpreted as made of float numbers. This helps our network perform complex computations.\ndf = df.astype(float)\n# We proceed to do these changes. First, we change the class values (at the column number 10) from 2 to 0 and from 4 to 1\ndf.iloc[:,10].replace(2, 0,inplace=True)\ndf.iloc[:,10].replace(4, 1,inplace=True)\n\ndf.head(3)\nscaled_df=df\n\n\n# we apply min-max normalization using the sklearn library:\nnames = df.columns[0:10]\nscaler = MinMaxScaler() \nscaled_df = scaler.fit_transform(df.iloc[:,0:10]) \nscaled_df = pd.DataFrame(scaled_df, columns=names)\n\n# After the training, we will validate the quality of our network by running the process again through the validation set.\nx=scaled_df.iloc[0:500,1:10].values.transpose()\ny=df.iloc[0:500,10:].values.transpose()\n\nxval=scaled_df.iloc[501:683,1:10].values.transpose()\nyval=df.iloc[501:683,10:].values.transpose()\n\nprint(df.shape, x.shape, y.shape, xval.shape, yval.shape)\n\n# We will first train the network with the  rows of our x,y training set. \n# Afterwards, we will test the trained network with the  rows of our xval,yval validation set, \n# to see how well the network generalizes to data it has never seen before\nnn = dlnet(x,y)\nnn.lr=0.07\nnn.dims = [9, 15, 1]\nnn.gd(x, y, iter = 67000)\n\n# compare the accuracy of the network when using the training and validation sets, by calling the pred function twice, \n# once with our training set, and another time with our validation set.\npred_train = nn.pred(x, y)\npred_test = nn.pred(xval, yval)\nnn.threshold=0.5\n\nnn.X,nn.Y=x, y \ntarget=np.around(np.squeeze(y), decimals=0).astype(np.int)\npredicted=np.around(np.squeeze(nn.pred(x,y)), decimals=0).astype(np.int)\nplotCf(target,predicted,'Cf Training Set')\n\n\nnn.X,nn.Y=xval, yval \ntarget=np.around(np.squeeze(yval), decimals=0).astype(np.int)\npredicted=np.around(np.squeeze(nn.pred(xval,yval)), decimals=0).astype(np.int)\nplotCf(target,predicted,'Cf Validation Set')\n\nnn.threshold=0.9\n\nnn.X,nn.Y=x, y \ntarget=np.around(np.squeeze(y), decimals=0).astype(np.int)\npredicted=np.around(np.squeeze(nn.pred(x,y)), decimals=0).astype(np.int)\nplotCf(target,predicted,'Cf Training Set')\n\nnn.X,nn.Y=xval, yval \ntarget=np.around(np.squeeze(yval), decimals=0).astype(np.int)\npredicted=np.around(np.squeeze(nn.pred(xval,yval)), decimals=0).astype(np.int)\nplotCf(target,predicted,'Cf Validation Set')\n\n# We can now use the nn.forward() function to compare directly the first few values of the validation \n# set output in relation to the target output:\nnn.X,nn.Y=xval, yval \nyvalh, loss = nn.forward()\nprint(\"\\ny\",np.around(yval[:,0:50,], decimals=0).astype(np.int))       \nprint(\"\\nyh\",np.around(yvalh[:,0:50,], decimals=0).astype(np.int),\"\\n\")\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}