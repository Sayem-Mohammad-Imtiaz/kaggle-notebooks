{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/amazon-stocks-lifetime-dataset/AMZN.csv\")\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us convert the string dates to datetime objects."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'],format='%Y-%m-%d')\ndf.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are trying to focus on the closing price of the stocks everyday after lets say 2016."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame({'Date':df['Date'],'Closing Price':df['Close']})\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.index = data.Date\ndata = data.drop('Date',axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[\"2016\":]\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Data Visualisation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(data.index,data['Closing Price'])\nplt.xlabel(\"date\")\nplt.ylabel(\"closing price\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see that this data is not stationary as it has increasing mean.Let us visualize the trends and seasonality."},{"metadata":{"trusted":true},"cell_type":"code","source":"def myplot(series):\n    plt.figure(figsize=(10,10))\n    plt.plot(data.index,series)\n    plt.xlabel(\"date\")\n    plt.ylabel(\"closing price\")\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nresult = seasonal_decompose(data ,model = 'additive',period = 20)\nSeasonal = result.seasonal.to_numpy()\nTrend = result.trend.to_numpy()\ndata_original = data.to_numpy()\nmyplot(result.trend)\nmyplot(result.seasonal)\nmyplot(result.resid)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see this is an additive model as the seasonality is alomost periodic in nature,Also the trend here is increasing one.We will move forward with the residual (removing the trend and seasonality)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_series = result.resid\ndata_series.replace([np.inf, -np.inf], np.nan, inplace=True) \ndata_series = data_series.fillna(0)\nmyplot(data_series)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have the residual here and the values seem to hetereoscedastic(have varying variance).\nTo remove this problem we will use log transform."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_series = np.log(300 + data_series)\nmyplot(data_series)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us see the adfuller test for auto correlation dependance."},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ndata_series = data_series.fillna(0)\nresult = adfuller(data_series)\nprint(\"The p-value is \" + str(result[1]))\nif result[1] < 0.05:\n    print(\"data-series is stationary\")\nelse:\n    print(\"data-series is not stationary\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have our stationary dataset."},{"metadata":{},"cell_type":"markdown","source":"Now we are going to forecast using our time series data.First we will create our test and train datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_array = data_series.to_numpy()\ndata_array = data_array\ntrain = data_array[0: 900]\ntest = data_array[900:976]\nx = []\nval = 0\nfor c in test:\n    x.append(val+900)\n    val = val + 1\n    \nplt.plot(train,label = \"train\")\nplt.plot(x,test,label = \"test\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will start by using our simple and exponential moving average."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Simple moving Average\ndf_sma = data_series.rolling(window = 5).mean()\nplt.plot(df_sma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_sma = df_sma.to_numpy()\ndata_sma = data_sma[900:]\nerror = mean_squared_error(test,data_sma)\nprint(\"The error for exponential moving average is \" + str(error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(data_series.index[900:],test,label=\"test\")\nplt.plot(data_series.index[900:],data_sma,label= \"predictions\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Exponential moving average\ndf_ema = data_series.ewm(span = 5,adjust = False).mean()\nplt.plot(df_ema)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ema = df_ema.to_numpy()\ndata_ema = data_ema[900:]\nerror = mean_squared_error(test,data_ema)\nprint(\"The error for exponential moving average is \"+ str(error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.plot(data_series.index[900:],test,label=\"test\")\nplt.plot(data_series.index[900:],data_ema,label= \"predictions\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now be using an arima model here.\nWe have to determine the p and q parameters,we will leave the d = 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\nplt.plot(acf(train[:50]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use the p value for the auto regressive model to be around 2 or 3."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pacf(train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will keep the q value to be 1 here.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\n\npredictions = []\ninput = []\nfor x in train:\n    input.append(x)\nfor x in test:\n    model = ARIMA(input,order=(2,0,1))\n    output = model.fit(disp=0).forecast()\n    predictions.append(output[0])\n    input.append(output[0])\nerror = mean_squared_error(test,predictions)\nprint(\"The mean squared error is given as \" + str(error))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us visualise our output."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))    \nplt.plot(data_series.index[900:],test,label=\"test\")\nplt.plot(data_series.index[900:],predictions,label= \"predictions\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nX = []\nA = []\nE = []\nS = []\nfrom math import exp\nfor i in range(len(test)):\n    A.append(exp(predictions[i]) + Seasonal[i+900] + Trend[i+900])\n    X.append(exp(test[i]) + Seasonal[i+900] + Trend[i+900])\n    E.append(exp(data_ema[i]) + Seasonal[i+900] + Trend[i+900])\n    S.append(exp(data_sma[i]) + Seasonal[i+900] + Trend[i+900])\n    \nplt.plot(data_series.index[900:],X,label=\"test\")\nplt.plot(data_series.index[900:],A,label= \"Arima_predictions\")\nplt.plot(data_series.index[900:],E,label= \"exponentialMA_predictions\")\nplt.plot(data_series.index[900:],S,label= \"SimpleMA_predictions\")\nplt.title(\"Stock price forecasting using different approaches.\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here We can see that Exponential moving average and simple moving average work better than the Arima model,We can improve upon the arima model by using grid search for the parameters.Finally we have plotted the forecasts with all our techniques."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}