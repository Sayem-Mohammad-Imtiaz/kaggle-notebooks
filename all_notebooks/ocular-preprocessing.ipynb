{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Ocular Disease Recognition - Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install openpyxl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/data.xlsx'\nIMG_DIR = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df = pd.read_excel(DATA_PATH)\nprint(main_df.shape)\nmain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I intend to feed the network 2 images at a time - left and right eye together. This would make more sense from the medical point of view, but also this way i will be able to use labeled columns directly (they do not specify which eye was affected). <br>\nIf i wanted to use one image at a time, i would have to search \"Left-Diagnostic Keywords\" and \"Right-Diagnostic Keywords\" columns for specific keywords. In some cases this wouldn't be a problem: e.g. cataract is always a \"cataract\", but complex diseases like diabetes could manifest differently, different terms could be used to describe the same thing, or even the same term could be written differently by different doctors: e.g. \"nonproliferative\" and \"non proliferative\".<br><br>\n\nIn this dataset, we have a significant dispersion of image sizes (height: 188 - 3456, width: 250 - 5184) with something like 150 images under 1000px size and 10 images under 200px. Most of the images are horizontal or square, but there are also 114 images that are vertical<br>\n(these numbers come from my notebook on file structure exploration: https://www.kaggle.com/annaszal/ocular-files)<br><br>\n\nSince small images make a rather small fraction of the whole set, i am going to choose size as to better preserve information, the small ones will get upscaled. I'm also going to remove black borders and crop all images to a square, then concatenate left and right images into one. I suppose i could stack the two images in channel dimension instead of dealing with non-square input, or create a new dimension, but i can still do that after i load the concatenated images, so it is more of a personal preference at this point."},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop(image): \n    # Remove vertical black borders (the image must be already normalized)\n    sums = image.sum(axis=0)\n    sums = sums.sum(axis=1)\n    filter_arr = []\n    for s in sums:\n        if s == 0:\n            filter_arr.append(False)\n        else:\n            filter_arr.append(True)\n    image = image[:, filter_arr]\n    \n    # Crop to a square shape\n    h = image.shape[0]\n    w = image.shape[1]    \n    \n    if h < w:\n        x = (w - h)//2\n        image = image[:, x:x+h, :]        \n    elif h > w:\n        x = (h - w)//2\n        image = image[x:x+w, :, :]           \n    else:\n        pass\n    \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(file_name):\n    image = cv2.imread(os.path.join(IMG_DIR, file_name))\n    \n    norm_img = np.zeros(image.shape)\n    norm_img = cv2.normalize(image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    \n    image = crop(norm_img)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    \n    return image\n\ndef preprocess_patient(patient_id):\n    left_eye_file = str(patient_id) + '_left.jpg'\n    right_eye_file = str(patient_id) + '_right.jpg'\n    image = cv2.hconcat([preprocess_image(left_eye_file), preprocess_image(right_eye_file)]) \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# example\npatient_id = main_df.iloc[7]['ID']\nimage = preprocess_patient(patient_id)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create image files"},{"metadata":{"trusted":true},"cell_type":"code","source":"images = {}\nfor i in tqdm(range(main_df.shape[0])):\n    patient_id = main_df.iloc[i]['ID']\n    image = preprocess_patient(patient_id)\n    images[patient_id] = image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_dir = \"ocular\"\nimg_dir = os.path.join(output_dir, 'images')\nos.makedirs(output_dir)\nos.makedirs(img_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in tqdm(images.keys()):\n    out_file_path = os.path.join(img_dir, str(i)+'.jpg')\n    cv2.imwrite(out_file_path, images[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_files = 0\nfor base, dirs, files in os.walk(img_dir):\n    for Files in files:\n        total_files += 1\n\ntotal_files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# example\npatient_id = 0\nimage = cv2.imread(os.path.join(img_dir, str(patient_id)+'.jpg'))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix the comma-like symbol\nfor i in range(main_df.shape[0]):\n    corrected_l = main_df.iloc[i]['Left-Diagnostic Keywords'].replace('，', ', ')  \n    main_df.loc[i, 'Left-Diagnostic Keywords'] = corrected_l\n    corrected_r = main_df.iloc[i]['Right-Diagnostic Keywords'].replace('，', ', ')  \n    main_df.loc[i, 'Right-Diagnostic Keywords'] = corrected_r\n\nmain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_df.to_csv(os.path.join(output_dir, 'data.csv'), index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(output_dir, 'data.csv'))\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!zip -r ocular_512x1024.zip ./ocular","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -R ocular","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}