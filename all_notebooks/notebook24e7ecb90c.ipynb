{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #\n# #\n# # Objectives:\n# #\n# # Which variables are significant in predicting the price of a car\n# # How well those variables describe the price of a car\n# #\n# # Goal:\n# #\n# # We are required to model the price of cars with the available independent variables.\n# # It will be used by the management to understand how exactly the prices vary with the independent variables.\n#\n# # Below has positive correlation\n# # Wheel Base\n# # Car length\n# # Car width\n# # Curb Weight\n# # Engine Size\n# # Bore Ratio\n# # Horse-power\n# #\n# # MPG has a negative correlation\n#\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sns\nimport pandas as pd\nf=pd.read_csv(\"/Users/kushagra/Downloads/CarPrice_Assignment.csv.xls\")\n# print(f)\n# print(f.info())\n# # print(f['symboling'])\n#\n# # ar_sym=f['symboling']\n# # print(ar_sym.max())\n# # print(ar_sym.min())\n# #\n# r=[]\n# s=[]\n# hr=0\n# sr=0\n# for i in range(0,205):\n#     if (f['symboling'][i]>=0):\n#         # print(f['CarName'][i]+': Risky Vehicle')\n#         r.append(f['CarName'][i]+': Risky Vehicle')\n#         hr=hr+1\n#     else:\n#         # print(f['CarName'][i]+\": Safe vehicle\")\n#         s.append(f['CarName'][i]+': Safe Vehicle')\n#         sr=sr+1\n# #\n# # print(\"There are\",  hr , \"risky vehicles. \")\n# # print(\"There are\" , sr,   \"safe vehicles. \" )\n# arr1=pd.Series(r)\n# arr2=pd.Series(s)\n# # print('List of Safe Vehicles:\\n',arr2)\n# # print('List of Risky Vehicles:\\n',arr1)\n# # print(arr1[])\n# # labels=[\"Risky Vehicles\" , \"Safe Vehicles\"]\n# # values=[hr,sr]\n# # plt.bar(labels,values)\n# # plt.ylabel(\"Number of Vehicles\")\n# # plt.title('Kind of Vehicle Lot')\n# #\n# # sns.regplot(x='symboling',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# g=[]\n# for i in range (0,205):\n#     if(f['fueltype'][i]=='gas'):\n#         g.append(1)\n#     else:\n#         g.append(2)\n# #\n# # arr3=pd.DataFrame(g)\n# # arr3.columns=['Fuel_Type']\n# # # print(arr3)\n# #\n# # f=f.join(arr3)\n# h=pd.get_dummies(f['aspiration'])\n# # print(h)\n# i=h['std'].value_counts()\n# # print(i)\n#\n# f_grp=f.groupby(['fueltype'],as_index=False)\n# # print(f_grp.get_group('diesel'))\n# # f.iloc[0,26]=\"Fuel Type\"\n# # print(f.iloc[0,26])\n# f_grp1=f.groupby(['aspiration'],as_index=False)\n# # print(f_grp1.get_group('turbo'))\n#\n# #\n# # sns.regplot(x='Fuel_Type',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# # The above graph shows there are more options in Gas Variant and their prices vary in the whole range.\n# # Diesel cars are less and are comparitively cheaper.\n# # f.drop('Fuel_Type', axis=1,inplace=True)\n# #\n# # print(f)\n# # sns.regplot(x='wheelbase',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# # Wheel base has a positive correlation with the price\n# # sns.regplot(x='carlength',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# #car length also has a positive correlation\n#\n# # sns.regplot(x='carwidth',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# #car width also has a positive correlation with the price\n#\n# # sns.regplot(x='carheight',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# # car height has no correlation with the price\n#\n# # sns.regplot(x='curbweight',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# # curb weight postive correlation\n# #\n# # sns.regplot(x='enginesize',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# # #engine size postive coorelation\n# #\n# # sns.regplot(x='boreratio',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# #bore ration positive correlation\n#\n# #\n# # sns.regplot(x='stroke',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# #no correlation\n#\n# # sns.regplot(x='compressionratio',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# # no correlation\n# #\n# # sns.regplot(x='horsepower',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# #positive correlation\n# #\n# # sns.regplot(x='peakrpm',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# #no correlation\n# #\n# # sns.regplot(x='citympg',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n# #negative coreelation\n# #\n# # sns.regplot(x='highwaympg',y='price',data=f)\n# # plt.ylim(0,)\n# # plt.show()\n#\n# # negative correlation\n#\n#\n#\n# np1=f[['wheelbase']]\n# np2=f['price']\n# lm=LinearRegression()\n# # print(np1.shape)\n# # print(np2.shape)\n# #\n# # print(np1)\n# np3=[[40,26]]\n# lm.fit(np1,np2)\n# y=lm.predict(np1)\n# # # print(lm.intercept_)\n# # # print(lm.coef_)\n# # #\n# # hx=10\n# # ez=110\n# # price=2156.7338-(225.9817*hx)+(142.3809*ez)\n# # print(price)\n# #above function bases a model between the values of highwaympg and price and then predicts the value of any car\n# # with the mentioned highwaympg\n# #\n# # axl=sns.distplot(f['price'], hist=False, color='r', label='Actual Value')\n# # sns.distplot(y, hist=False, color='b', label='Fitted Values' , ax=axl)\n# # plt.show()\n# #\n#\n#\n# # Curvilinear Regression Model\n# # from sklearn.linear_model import LinearRegression\n# # from sklearn.preprocessing import StandardScaler\n# # from sklearn.preprocessing import PolynomialFeatures\n# # from sklearn.pipeline import Pipeline\n# #\n# # Input=[('Scale' , StandardScaler()) , ('Polynomial' , PolynomialFeatures (degree=3)) , ('model' , LinearRegression()) ]\n# #\n# # pipe=Pipeline(Input)\n# #\n# #\n# # # Training the Pipeline\n# #\n# # pipe.fit(f[['horsepower','enginesize']], f['price'] )\n# # yhat=pipe.predict(f[['horsepower', 'enginesize']])\n# # print(yhat)\n#\n# w=f.loc[f['fueltype']== 'gas']['doornumber']\n# # print(w)\n# fstr=[]\n# for i in range (0,205):\n#     if str(f['CarName'][i]).startswith('bmw'):\n#         fstr.append(f.iloc[i])\n# # print(pd.DataFrame(fstr))\n#\n# bmw=pd.DataFrame(fstr)\n# # bmw.info()\n#\n# bmwp=sum(bmw.loc[bmw['doornumber']=='two']['price'])/3\n# bmwp1=(bmw.loc[bmw['doornumber']=='four']['price'])\n#\n# q=0\n# for _ in bmwp1:\n#     q=q+1\n#\n# sumbmwp1=sum(bmw.loc[bmw['doornumber']=='four']['price'])/q\n# # print(sumbmwp1)\n# # print(bmwp)\n#\n#\n\n\n\n# Practice\nar=np.arange(10,30)\narr=ar.reshape(2,10)\ng=f.groupby('drivewheel')\n#\n# for drivehweel, drivewheel_f  in g:\n# \t# print( drivehweel)\n# \t# print(drivewheel_f)\n#\n\n\nh=f.head()\n# print(h)\nf_pivot= h.pivot(index='CarName', columns= 'fueltype', values='wheelbase')\n# print(f_pivot)\n\nw=f.loc[f['fueltype']== 'gas']['doornumber']\n# print(w)\n# print(f.iloc[[20,30],[20,25]])\ng=f.drop_duplicates(subset='fueltype')\n# print(f.sample())","metadata":{},"execution_count":null,"outputs":[]}]}