{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import những thư viện và module cần dùng","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, plot_confusion_matrix, accuracy_score, f1_score\nfrom wordcloud import WordCloud,STOPWORDS\nimport re\nimport os\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\nnltk.download('wordnet')\nnltk.download('stopwords')\nfrom sklearn.feature_extraction.text  import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB, MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D, Bidirectional, Input,GlobalMaxPool1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import plot_model\nimport torch\nfrom transformers import DistilBertTokenizer, DistilBertConfig, DistilBertModel, TFDistilBertModel\nfrom tqdm import tqdm\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Đọc dữ liệu từ file csv","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"TRAIN_FILE_PATH = '/kaggle/input/ag-news-classification-dataset/train.csv'\nTEST_FILE_PATH = '/kaggle/input/ag-news-classification-dataset/test.csv'\ndata = pd.read_csv(TRAIN_FILE_PATH)\ntestdata = pd.read_csv(TEST_FILE_PATH)\n\ntrain = data['Title'] + \" \" + data['Description'] # Combine title and description (better accuracy than using them as separate features)\ny_train = data['Class Index'].apply(lambda x: x-1).values # Class labels need to begin from 0\n\ntest = testdata['Title'] + \" \" + testdata['Description'] # Combine title and description (better accuracy than using them as separate features)\ny_test = testdata['Class Index'].apply(lambda x: x-1).values # Class labels need to begin from 0\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thăm dò và trực quang hóa dữ liệu","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Thống kê số nhãn có trên tập train và tập test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Có thể thấy số nhãn trên cả 2 tập data khá đồng đều. Sử dụng Word Cloud để Visualize một số từ xuất hiện nhiều trong 2 tập này để xem xu hướng của 2 tập:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## World News Wordcloud ##","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thêm một số stopwords tồn tại trong dữ liệu\nstopwordset= set(STOPWORDS)\nmorestop={'lt','gt','href','HREF','quot','aspx', 'wa', 'hi', 'AP'}\nstopwordset= stopwordset.union(morestop)\n# lấy ra các tin tức chủ đề World\nworld = data[data['Class Index']==1]\n# Vẽ biểu đồ wordcloud cho chủ đề word\nplt.figure(figsize = (20,12))\nwordcloud = WordCloud(max_words = 500 ,background_color=\"white\", stopwords=stopwordset).generate(' '.join(world.Description))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sports News Wordcloud##","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sports = data[data['Class Index']==2]\n# Visualize with word cloud\nplt.figure(figsize = (20,12))\nwordcloud = WordCloud(max_words = 500 ,background_color=\"white\", stopwords=stopwordset).generate(' '.join(sports.Description))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Business News Wordcloud ##","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"business = data[data['Class Index']==3]\n# Visualize with word cloud\nplt.figure(figsize = (20,12))\nwordcloud = WordCloud(max_words = 500 ,background_color=\"white\", stopwords=stopwordset).generate(' '.join(business.Description))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Science and Technology News Wordcloud ##","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SnT = data[data['Class Index']==4]\n# Visualize with word cloud\nplt.figure(figsize = (20,12))\nwordcloud = WordCloud(max_words = 500 ,background_color=\"white\", stopwords=stopwordset).generate(' '.join(SnT.Description))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tiền xử lí dữ liệu #","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sử dụng Regular Expression lọc các url tồn tại trong dataset\ndef remove_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\nX_train = train.apply(remove_urls)\nX_test = test.apply(remove_urls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sử dụng Regular Expression lọc các thẻ html tồn tại trong dataset\ndef remove_html(text):\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)\n\nX_train = X_train.apply(remove_html)\nX_test = X_test.apply(remove_html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tách các phần tử trong câu ra thành từng phần riêng biệt\ndef word_tokenize(txt):\n    tokens = re.findall(\"[\\w']+\", txt)\n    return tokens\nX_train = X_train.apply(word_tokenize)\nX_test = X_test.apply(word_tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chuyển tất cả các từ trong dataset về dạng viết thường\ndef lowercasing(lst):\n    new_lst=[]\n    for  i in  lst:\n        i=i.lower()\n        new_lst.append(i) \n    return new_lst\nX_train = X_train.apply(lowercasing)\nX_test = X_test.apply(lowercasing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tiến hành lọc bỏ các từ không có nhiều ý nghĩa trong tiếng Anh (stopwords) như a, an, the, and, but, ...\ndef remove_stopwords(lst):\n    stop=stopwords.words('english')\n    new_lst=[]\n    for i in lst:\n        if i not in stop:\n            new_lst.append(i)\n    return new_lst\n\nX_train=X_train.apply(remove_stopwords)\nX_test=X_test.apply(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loại bỏ các kí tự đặc biệt trong văn bản\ndef remove_punctuations(lst):\n    new_lst=[]\n    for i in lst:\n        for j in  string.punctuation:\n            i=i.replace(j,'')\n        new_lst.append(i)\n    return new_lst\nX_train = X_train.apply(remove_punctuations) \nX_test = X_test.apply(remove_punctuations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loại bỏ các tiền tố hậu tố trong văn bản\n# Ex: Playing -> play\n#     Played -> play\ndef stemming(text):\n    porter_stemmer = PorterStemmer()\n    roots = [porter_stemmer.stem(each) for each in text]\n    return (roots)\n\nX_train=X_train.apply(stemming)\nX_test=X_test.apply(stemming)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chuyển các từ đặc biệt về dạng nguyên mẫu\n#Ex: are/is/am -> be\nlemmatizer=WordNetLemmatizer()\ndef lemmatzation(lst):\n    new_lst=[]\n    for i in lst:\n        i=lemmatizer.lemmatize(i)\n        new_lst.append(i)\n    return new_lst\nX_train=X_train.apply(lemmatzation)\nX_test=X_test.apply(lemmatzation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lọc thêm một số stopword chỉ xuất hiện trong dataset\ndef remove_extrawords(lst):\n    stop=['href','lt','gt','ii','iii','ie','quot','com']\n    new_lst=[]\n    for i in lst:\n        if i not in stop:\n            new_lst.append(i)\n    return new_lst\n\nX_train=X_train.apply(remove_extrawords)\nX_test=X_test.apply(remove_extrawords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gộp các tokens lại thành một câu\nX_train=X_train.apply(lambda x: ''.join(i+' ' for i in x))\nX_test=X_test.apply(lambda x: ''.join(i+' '  for i in x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Biến đổi dữ liệu từ text sang vector","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Sử dụng Tf-idf để tính toán vectorize dữ liệu (RAW). Vì dữ liệu tương đối lớn nên để giới hạn số cột và thông tin, \nta giới hạn số feature tối đa là 1000 và không onehot dữ liệu như thông thường mà chuyển về miền dữ liệu \"\"\" \ntfidf=TfidfVectorizer(max_features=1000,min_df=6)\nX_raw_train_arr=tfidf.fit_transform(train)\nX_raw_test_arr=tfidf.transform(test)\nprint(len(tfidf.get_feature_names()))\nX_raw_train_arr=X_raw_train_arr.toarray()\nX_raw_test_arr=X_raw_test_arr.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Sử dụng Tf-idf để tính toán vectorize dữ liệu (đã được xử lí). Vì dữ liệu tương đối lớn nên để giới hạn số cột và thông tin, \nta giới hạn số feature tối đa là 1000 và không onehot dữ liệu như thông thường mà chuyển về miền dữ liệu \"\"\" \ntfidf=TfidfVectorizer(max_features=1000,min_df=6)\nX_train_arr=tfidf.fit_transform(X_train)\nX_test_arr=tfidf.transform(X_test)\nprint(len(tfidf.get_feature_names()))\nX_train_arr=X_train_arr.toarray()\nX_test_arr=X_test_arr.toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sử dụng mô hình Machine Learning ( mặc định ) và sử dụng dữ liệu thô (RAW Data)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hàm dùng để trực quang confusion matrix\ndef confusion_mat(color):\n    cof=confusion_matrix(y_test, y_pred)\n    cof=pd.DataFrame(cof, index=[i for i in range(1,5)], columns=[i for i in range(1,5)])\n    sns.set(font_scale=1.5)\n    plt.figure(figsize=(8,8));\n\n    sns.heatmap(cof, cmap=color,linewidths=1, annot=True,square=True, fmt='d', cbar=False,xticklabels=['World','Sports','Business','Science'],yticklabels=['World','Sports','Business','Science']);\n    plt.xlabel(\"Predicted Classes\");\n    plt.ylabel(\"Actual Classes\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sử dụng mô hình Gaussian Naive Bayes để train dữ liệu\nmodel = GaussianNB()\nmodel.fit(X_raw_train_arr, y_train)\n# Kết quả đánh giá mô hình trên tập test\ny_pred = model.predict(X_raw_test_arr)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,model.predict(X_raw_train_arr)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sử dụng mô hình Multinomial Naive Bayes để train dữ liệu\nmodel = MultinomialNB()\nmodel.fit(X_raw_train_arr, y_train)\n# Kết quả đánh giá mô hình trên tập test\ny_pred = model.predict(X_raw_test_arr)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,model.predict(X_raw_train_arr)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sử dụng mô hình Machine Learning ( hyperparameter tuning ) và sử dụng dữ liệu đã được xử lí","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sử dụng mô hình Gaussian Naive Bayes để train dữ liệu (th)\nmodel = GaussianNB(var_smoothing=0.06)\nmodel.fit(X_train_arr, y_train)\n# Kết quả đánh giá mô hình trên tập test\ny_pred = model.predict(X_test_arr)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,model.predict(X_train_arr)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thay đổi tham số **var_smoothing** từ 1e-9 tăng lên 0.06 và tiền xử lí dữ liệu -> Accuracy trên tập test tăng từ 81.32% lên 84.05%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sử dụng mô hình Multinomial Naive Bayes để train dữ liệu\nmodel = MultinomialNB(alpha=5.7)\nmodel.fit(X_train_arr, y_train)\n# Kết quả đánh giá mô hình trên tập test\ny_pred = model.predict(X_test_arr)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,model.predict(X_train_arr)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thay đổi tham số **alpha** từ 1 tăng lên 5.7 và tiền xử lí dữ liệu -> Accuracy trên tập test tăng từ 84.47% lên 85.47%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Sử dụng Pre-trained model BERT để tokenize và Fine-tuning cho bài toán Text Classification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Sử dụng Distil BERT Tokenizer để tokenize dữ liệu","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sử dụng DistilBERT Pre-trained model để tokenize data\nmaxlen = train.map(lambda x: len(x.split())).max()\ndistil_bert = 'distilbert-base-uncased'\n\ntokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n                                                max_length=maxlen, pad_to_max_length=True, truncation=True)\n\ndef tokenize(sentences, tokenizer, maxlen):\n    input_ids, input_masks, input_segments = [],[],[]\n    for sentence in tqdm(sentences):\n        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=maxlen, pad_to_max_length=True, \n                                             return_attention_mask=True, return_token_type_ids=True)\n        input_ids.append(inputs['input_ids'])\n        input_masks.append(inputs['attention_mask'])\n        input_segments.append(inputs['token_type_ids'])        \n        \n    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tokenize dữ liệu chưa được xử lí với Distil BERT tokenizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_raw_train = tokenize(train, tokenizer, maxlen)\nX_raw_test = tokenize(test, tokenizer, maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(X_raw_train).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tpu_strategy.scope():\n    config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n    config.output_hidden_states = False\n    transformer_model = TFDistilBertModel.from_pretrained(distil_bert, config=config)\n\n    input_ids_in = Input(shape=(maxlen,), name='input_token', dtype='int32')\n    input_masks_in = Input(shape=(maxlen,), name='masked_token', dtype='int32') \n\n    embedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\n    X = Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(embedding_layer)\n    X = GlobalMaxPool1D()(X)\n    X = Dense(64, activation='relu')(X)\n    X = Dropout(0.2)(X)\n    X = Dense(4, activation='sigmoid')(X)\n    model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n\n    for layer in model.layers[:3]:\n        layer.trainable = False\n\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n#     EarlyStopping(\n#         monitor='val_accuracy',\n#         min_delta=1e-4,\n#         patience=4,\n#         verbose=1\n#     ),\n    ModelCheckpoint(\n        filepath='DistilBERT_RAW.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_raw_train, y_train, batch_size=64 * tpu_strategy.num_replicas_in_sync, validation_data=(X_raw_test, y_test), epochs=20, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('DistilBERT_RAW.h5')\ny_pred = np.argmax(model.predict(X_raw_test), axis=1)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,np.argmax(model.predict(X_raw_train), axis=1)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('Greens')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thực hiện tokenize và train với dữ liệu đã xử lí để so sánh ( cùng số batch size, epochs )","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = X_train.map(lambda x: len(x.split())).max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = tokenize(X_train, tokenizer, maxlen)\nX_test = tokenize(X_test, tokenizer, maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(X_train).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n#     EarlyStopping(\n#         monitor='val_accuracy',\n#         min_delta=1e-4,\n#         patience=4,\n#         verbose=1\n#     ),\n    ModelCheckpoint(\n        filepath='DistilBERT_PRP.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size=64 * tpu_strategy.num_replicas_in_sync, validation_data=(X_test, y_test), epochs=20, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('DistilBERT_PRP.h5')\ny_pred = np.argmax(model.predict(X_test), axis=1)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,np.argmax(model.predict(X_train), axis=1)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('Greens')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thực nghiệm đối với Pre-trained model BERT lên 2 tập dữ liệu ta lại thấy kết quả khác là kết quả đánh giá mô hình dự đoán trên dữ liệu đã được xử lí thấp hơn đối với dữ liệu chưa được xử lí cũng là một kết quả dễ hiểu vì theo [1] thì BERT được pre-training trên dữ liệu English Wikipedia và BookCorpus, đây là những dữ liệu văn bản dưới dạng văn bản chính quy mà dữ liệu của chúng ta không phải dạng là dữ liệu này nên bước tiền xử lí có thể đã làm một số thông tin sai lệch đi ảnh hưởng đến chất lượng của dữ liệu.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Tokenize data với DistilBERT Tokenizer và sử dụng mô hình Bi-LSTM ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Khởi tạo tham số Embedding layer cho dữ liệu tokenize bởi DistilBERT","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bert_embed_matrix():\n    model = DistilBertModel.from_pretrained(distil_bert)\n    bert_embeddings = list(model.children())[0]\n    bert_word_embeddings = list(bert_embeddings.children())[0]\n    mat = bert_word_embeddings.weight.data.numpy()\n    return mat\nembedding_matrix = get_bert_embed_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Xây dựng kiến trúc Bi-LSTM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with tpu_strategy.scope():    \n    model = Sequential()\n    model.add(Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1], input_length=maxlen))\n    model.add(Bidirectional(LSTM(128, return_sequences=True))) # bidirectional LSTMs since this isn't a timeseries problem\n    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n    model.add(GlobalMaxPooling1D())\n    model.add(Dense(1024))\n    model.add(Dropout(0.25))\n    model.add(Dense(512))\n    model.add(Dropout(0.25))\n    model.add(Dense(256))\n    model.add(Dropout(0.25))\n    model.add(Dense(4, activation='softmax'))\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=1e-4,\n        patience=5,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        filepath='weights_RAW.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # sparse categorical crossentropy loss because data is not one-hot encoded\nhistory = model.fit(X_raw_train, y_train, batch_size=64 * tpu_strategy.num_replicas_in_sync, validation_data=(X_raw_test, y_test), epochs=20, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('weights_RAW.h5')\ny_pred = np.argmax(model.predict(X_raw_test), axis=1)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,np.argmax(model.predict(X_raw_train), axis=1)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=1e-4,\n        patience=5,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        filepath='weights_PRP.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # sparse categorical crossentropy loss because data is not one-hot encoded\nhistory = model.fit(X_train, y_train, batch_size=64 * tpu_strategy.num_replicas_in_sync, validation_data=(X_test, y_test), epochs=20, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('weights_PRP.h5')\ny_pred = np.argmax(model.predict(X_test), axis=1)\nprint('Accuracy on Train set: ', round(accuracy_score(y_train,np.argmax(model.predict(X_train), axis=1)),4)*100,'%')\nprint('Accuracy on Test set: ', round(accuracy_score(y_test,y_pred),4)*100,'%')\nprint('F1: ', f1_score(y_test,y_pred,average='micro'))\n\nconfusion_mat('Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}