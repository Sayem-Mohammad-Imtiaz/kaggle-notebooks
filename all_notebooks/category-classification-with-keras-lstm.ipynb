{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.core import Activation, Dense, Dropout, SpatialDropout1D\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nfrom keras.preprocessing import sequence\nfrom sklearn.model_selection import train_test_split\nimport collections\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.corpus import stopwords\nimport numpy as np\nimport pandas as pd\nfrom keras.utils.np_utils import to_categorical\nfrom keras_tqdm import TQDMNotebookCallback\n#nltk.download('punkt')\n#nltk.download('stopwords')\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file = \"../input/news-aggregator-dataset/uci-news-aggregator.csv\"\n\ndata = pd.read_csv(file, usecols=[\"CATEGORY\", \"TITLE\"])\n#Converter categoria string para numÃ©rico\ndata.CATEGORY = pd.Categorical(data.CATEGORY)\ndata['CATEGORY'] = data.CATEGORY.cat.codes\n\nROWS = 8000\nROWS_PER_CATEGORY = int(ROWS/4) \n\n#Seleciona 8000 linhas balanceadas nas quatro categorias\ndata = data[data[\"CATEGORY\"] == 0].head(ROWS_PER_CATEGORY) \\\n                                       .append(data[data[\"CATEGORY\"] == 1].head(ROWS_PER_CATEGORY)) \\\n                                       .append(data[data[\"CATEGORY\"] == 2].head(ROWS_PER_CATEGORY)) \\\n                                       .append(data[data[\"CATEGORY\"] == 3].head(ROWS_PER_CATEGORY))\nmaxlen = 0\nword_freqs = collections.Counter()\nnum_recs = 0\nstop_words = set(stopwords.words('english'))\nsnow_stem = nltk.stem.SnowballStemmer('english')\n\nfor sentence in data[\"TITLE\"]:\n    words = nltk.word_tokenize(sentence.lower())\n    if len(words) > maxlen:\n        maxlen = len(words)\n    for word in words:\n        if word in stop_words:\n            continue;\n        word = snow_stem.stem(word)\n        word_freqs[word] += 1\n    num_recs += 1\n\nprint(\"maxlen :\", maxlen)\nprint(\"len(word_freqs) :\", len(word_freqs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_VOCAB= 2000\nMAX_TITLE_LENGTH = 20\n\nvocab_size = min(MAX_VOCAB, len(word_freqs)) + 1#Somado 1 por causa do UNK\nword2index = {x[0]: i+1 for i, x in enumerate(word_freqs.most_common(MAX_VOCAB))}\nword2index[\"UNK\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\ny = []\n\ni = 0\n\nfor sentence in data[\"TITLE\"]:\n    words = nltk.word_tokenize\n    words = nltk.word_tokenize(sentence.lower())\n    seqs = []\n    for word in words:\n        if word in stop_words:\n            continue\n        word = snow_stem.stem(word)\n        if word in word2index:\n            seqs.append(word2index[word])\n        else:\n            seqs.append(word2index[\"UNK\"])\n    X.append(seqs)\nfor category in data[\"CATEGORY\"]:\n    y.append(category)\nX = sequence.pad_sequences(X, maxlen=MAX_TITLE_LENGTH)\ny = to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBEDDING_SIZE= 128\nHIDDEN_LAYER_SIZE = 256\nBATCH_SIZE = 32\nNUM_EPOCH = 5\n\n# Define Model\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, EMBEDDING_SIZE, input_length=MAX_TITLE_LENGTH))\nmodel.add(LSTM(HIDDEN_LAYER_SIZE, dropout=0.4, recurrent_dropout=0.2))\nmodel.add(Dense(4))\nmodel.add(Activation(\"softmax\"))\n\nmodel_adam = model\n\nmodel.summary()\n\nmodel_adam.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_adam = model_adam.fit(Xtrain, ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, \n                    validation_data=(Xtest, ytest), verbose=2, callbacks=[TQDMNotebookCallback()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplot(211)\nplt.title(\"Accuracy\")\nplt.plot(history_adam.history[\"accuracy\"], color=\"g\", label=\"Train\")\nplt.plot(history_adam.history[\"val_accuracy\"], color=\"b\", label=\"Validation\")\nplt.legend(loc=\"best\")\n\nplt.subplot(212)\nplt.title(\"Loss\")\nplt.plot(history_adam.history[\"loss\"], color=\"g\", label=\"Train\")\nplt.plot(history_adam.history[\"val_loss\"], color=\"b\", label=\"Validation\")\nplt.legend(loc=\"best\")\nplt.savefig(\"grafico\")\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score, acc = model.evaluate(Xtest, ytest, batch_size=BATCH_SIZE, verbose=0)\nprint(\"Test score: %.3f, accuracy: %.3f\" % (score,acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}