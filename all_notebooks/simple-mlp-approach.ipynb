{"cells":[{"metadata":{},"cell_type":"markdown","source":"- five minute mlp\n- 84%--87% roc/auc\n- anyone got pro-tips?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom keras import backend as K\nfrom keras import layers as L\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom keras.regularizers import l1_l2\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/machine-learning-for-diabetes-with-python/diabetes_data.csv')\nscaler = MinMaxScaler()\n\ny = data.pop('Outcome')\nX = pd.DataFrame(scaler.fit_transform(data))\n\nX_test = X[-80:]\ny_test = y[-80:]\n\nX = X.drop(X.index[-80:])\ny = y.drop(y.index[-80:])\n\ndisplay(len(X))\ndisplay(X.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf = RandomForestClassifier(n_estimators = 200, max_depth=16)\nrf_clf.fit(data[data.columns[:-1]], data[data.columns[-1]])\npd.Series(rf_clf.feature_importances_, index = data.columns[:-1]).nlargest(12).plot(kind='barh',figsize=(10,10),title = 'Feature importance').invert_yaxis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session()\nreduce_lr = ReduceLROnPlateau(patience=5,verbose=False)\nmodel_ckpt = ModelCheckpoint('DiabetesNet.h5',save_best_only=True,verbose=False)\nearly_stop = EarlyStopping(patience=8,verbose=False)\n\nentry = L.Input(shape=(len(X.columns),))\nx = L.GaussianNoise(0.2)(entry)\nx = L.Dense(69,activation='linear')(x)\nx = L.LeakyReLU(0.4)(x)\nx = L.Dense(42,activation='linear')(x)\nx = L.LeakyReLU(0.4)(x)\nx = L.Dense(9,activation='linear',kernel_regularizer=l1_l2(2e-4))(x)\nx = L.LeakyReLU(0.3)(x)\nx = L.Dense(1,activation='hard_sigmoid')(x)\n\nmodel = Model(entry,x)\nmodel.compile(loss='mse',optimizer=Adam(lr=1e-4),metrics=['accuracy'])\nhistory = model.fit(X,y,epochs=666,verbose=0,callbacks=[reduce_lr,model_ckpt,early_stop],steps_per_epoch=200,validation_steps=50,validation_split=0.3)\nprint('roc/auc: {}'.format(roc_auc_score(y_test,model.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}