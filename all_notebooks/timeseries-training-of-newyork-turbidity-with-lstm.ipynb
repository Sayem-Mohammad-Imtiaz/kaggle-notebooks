{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from math import sqrt\nfrom numpy import concatenate\nfrom numpy import datetime64\nfrom numpy import timedelta64\nimport numpy as np\nimport pandas as pd\nfrom pandas import read_csv\nfrom pandas import merge\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom pandas import to_datetime\nfrom pandas import DateOffset\nfrom datetime import datetime\nfrom matplotlib import pyplot\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras.layers import LSTM\nfrom tensorflow.python.keras.preprocessing.sequence import TimeseriesGenerator\n\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"207d3ce97c58eb5fcd548820074dab8cf59e8d4f"},"cell_type":"code","source":"dataset = read_csv('../input/watershed-water-quality-data.csv')\ndataset.head()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef16f58bdb880df3275dfd2d80acdf15d37ee042"},"cell_type":"markdown","source":"<font size=5>Taking each row and making new rows for each 4 hour time value</font>\n\n* Since the Turbidity values are taken every 4 hours, we can turn this dataset into 4 hour segments as opposed to rows that are split by Days."},{"metadata":{"trusted":true,"_uuid":"2a0189dbcfafab17081553f6c8a6d30bcdec3dc8"},"cell_type":"code","source":"\ntwelve_am_data_set = dataset[['Date','Turbidity(NTU) at 12AM','Coliform, Fecal(fc/100mL)']]\nfour_am_data_set = dataset[['Date','Turbidity(NTU) at 4AM','Coliform, Fecal(fc/100mL)']]\neight_am_data_set = dataset[['Date','Turbidity(NTU) at 8AM','Coliform, Fecal(fc/100mL)']]\ntwelve_pm_data_set = dataset[['Date','Turbidity(NTU) at 12PM','Coliform, Fecal(fc/100mL)']]\nfour_pm_data_set = dataset[['Date','Turbidity(NTU) at 4PM','Coliform, Fecal(fc/100mL)']]\neight_pm_data_set = dataset[['Date','Turbidity(NTU) at 8PM','Coliform, Fecal(fc/100mL)']]\n\n#Change Date by adding hour of measurement\n\ntwelve_am_data_set['Date'] = to_datetime(twelve_am_data_set['Date'])\n\nfour_am_data_set['Date'] = to_datetime(four_am_data_set['Date'])\nfour_am_data_set['Date'] = four_am_data_set['Date'] + DateOffset(hours=4)\n\neight_am_data_set['Date'] = to_datetime(eight_am_data_set['Date'])\neight_am_data_set['Date'] = eight_am_data_set['Date'] + DateOffset(hours=8)\n\ntwelve_pm_data_set['Date'] = to_datetime(twelve_pm_data_set['Date'])\ntwelve_pm_data_set['Date'] = twelve_pm_data_set['Date'] + DateOffset(hours=12)\n\nfour_pm_data_set['Date'] = to_datetime(four_pm_data_set['Date'])\nfour_pm_data_set['Date'] = four_pm_data_set['Date'] + DateOffset(hours=16)\n\neight_pm_data_set['Date'] = to_datetime(eight_pm_data_set['Date'])\neight_pm_data_set['Date'] = eight_pm_data_set['Date'] + DateOffset(hours=20)\n\ntwelve_am_data_set.columns = [\"Date\", \"Turbidity\",'Fecal']\nfour_am_data_set.columns = [\"Date\", \"Turbidity\",'Fecal']\neight_am_data_set.columns = [\"Date\", \"Turbidity\",'Fecal']\ntwelve_pm_data_set.columns = [\"Date\", \"Turbidity\",'Fecal']\nfour_pm_data_set.columns = [\"Date\", \"Turbidity\",'Fecal']\neight_pm_data_set.columns = [\"Date\", \"Turbidity\",'Fecal']\n\ncomplete_data_set= concat([twelve_am_data_set,four_am_data_set, eight_am_data_set,twelve_pm_data_set,four_pm_data_set,eight_pm_data_set], axis=0, join='outer', ignore_index=False)\n\ncomplete_data_set = complete_data_set.sort_values(by=['Date'])\ncomplete_data_set.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b104cb0535edd5d952ee030f5bc093c49f47ec4"},"cell_type":"code","source":"complete_data_set.Turbidity.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c8aaf876e21e3ba7b611a047f10454423d38afd"},"cell_type":"code","source":"complete_data_set.Fecal.unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d7a33055c6768e4ebae4bb390c09bf88010dc98"},"cell_type":"markdown","source":"\nSince the Fecal column has values that are not numbers, such as 'E1' 'E2' etc., We can't pass it to the LSTM unless we do something such as one-hot coding.\nHowever, this wouldn't make much sense as the number values are measurements. The E values are either Errors or they mean something field-specific.\nWe could omit them in training if they do not amount to much in the total dataset:"},{"metadata":{"trusted":true,"_uuid":"1277ba6c042c17f41b74cd1739bc46b31b2b06d8"},"cell_type":"code","source":"pd.value_counts(complete_data_set['Fecal']).plot.bar(figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28feef2ae6f9e217dd95f0c344b8727f8e781a2c"},"cell_type":"markdown","source":"Since the vast majority of the values are not numbers, we will omit this data for the rest of the project."},{"metadata":{"trusted":true,"_uuid":"9f03366218b3bb24e47f5f8f60ac3853c926e98a"},"cell_type":"code","source":"\ncomplete_data_set = complete_data_set.drop(['Fecal'], axis=1)\ncomplete_data_set.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0d401fdd4da7a5431c977824b7b01df2b360a3"},"cell_type":"code","source":"complete_data_set['Turbidity'].plot.hist(bins=50,figsize = (10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01c1afa2b9f510ba3f336dd3d56683116b97d5c4"},"cell_type":"code","source":"df = complete_data_set.set_index('Date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01c1afa2b9f510ba3f336dd3d56683116b97d5c4"},"cell_type":"code","source":"df['Turbidity'].plot(figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9cfaa2d97516287f9c93cda30e91735bac22a0c"},"cell_type":"markdown","source":"<font size=5>Lets take a closer look of the first month </font>"},{"metadata":{"trusted":true,"_uuid":"01c1afa2b9f510ba3f336dd3d56683116b97d5c4"},"cell_type":"code","source":"df[:180]['Turbidity'].plot(figsize = (20,10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c93a43b94f4e339a89846a5f086bfc622c9eb6d"},"cell_type":"markdown","source":"<font size=5>Check for Null Values and replace them with previous result</font>"},{"metadata":{"trusted":true,"_uuid":"207d3ce97c58eb5fcd548820074dab8cf59e8d4f"},"cell_type":"code","source":"\nnan_rows = df[df['Turbidity'].isnull()]\nnan_rows","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df= df.fillna(method='ffill')\ndf.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51b6569029d4ef44838fb5b118902e4b87143511"},"cell_type":"code","source":"#remove first row which is also null\ndf = df.iloc[1:]\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"486ffe83b776f137c3d4d4523ecb51d7138d1da3"},"cell_type":"markdown","source":"<font size=5>Preparing Data For Keras LSTM Network</font>"},{"metadata":{"trusted":true,"_uuid":"e64ca70495a89b1e25586fbb3da405c0adc2036b"},"cell_type":"code","source":"values = df.values\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(values)\n\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09fdddabfba00f545ec9d0e377edfa50c206e4e2"},"cell_type":"code","source":"train_data_gen = TimeseriesGenerator(train, train,\n\tlength=2, sampling_rate=1,stride=1,\n    batch_size=3)\ntest_data_gen = TimeseriesGenerator(test, test,\n\tlength=2, sampling_rate=1,stride=1,\n\tbatch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2752716f59811a17d42b34e32d8119b5faa863b4"},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(4, input_shape=(2, 1)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory = model.fit_generator(train_data_gen, epochs=50).history","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"baa99b091041a8482e714c2c57bd186121db6ac2"},"cell_type":"markdown","source":"<font size=5>Testing The Model</font>"},{"metadata":{"trusted":true,"_uuid":"7c61592b14f57591127b2c3a3fb4ca9e694d222f"},"cell_type":"code","source":"model.evaluate_generator(test_data_gen)\ntrainPredict = model.predict_generator(train_data_gen)\ntrainPredict.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c61592b14f57591127b2c3a3fb4ca9e694d222f"},"cell_type":"code","source":"testPredict = model.predict_generator(test_data_gen)\ntestPredict.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de087c625aebc79bfb9f505d7a43adcf62aa3efb"},"cell_type":"markdown","source":"<font size=5>Plotting The Results</font>"},{"metadata":{"trusted":true,"_uuid":"18582ff308f712122adcd7351d08ef9e7ea06905"},"cell_type":"code","source":"\n#return values to their pre-normalized form\ninv_trainPredict = scaler.inverse_transform(trainPredict)\ninv_testPredict= scaler.inverse_transform(testPredict)\n\n\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[2:len(trainPredict)+2, :] = inv_trainPredict\n\n\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(2*2):len(dataset), :] = inv_testPredict\n\npyplot.figure(figsize = (20, 10))\npyplot.plot(trainPredictPlot, label=\"trainPredict\")\npyplot.plot(testPredictPlot,label=\"testPredict\")\npyplot.plot(df['Turbidity'].values, label=\"real\")\npyplot.xlabel(\"Date\")\npyplot.ylabel(\"Turbidity\")\npyplot.title(\"Comparison \")\npyplot.legend()\npyplot.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e2ee675d9fd5ffa4d95d51a7e6af6c1441e17e0"},"cell_type":"code","source":"\npyplot.figure(figsize = (20, 10))\npyplot.plot(trainPredictPlot[6600:6630], label=\"trainPredict\")\npyplot.plot(testPredictPlot[6600:6630],label=\"testPredict\")\npyplot.plot(df[6600:6630]['Turbidity'].values, label=\"real\")\npyplot.xlabel(\"4-hour measurements\")\npyplot.ylabel(\"Turbidity\")\npyplot.title(\"Comparison \")\npyplot.legend()\npyplot.grid(True,which='both')\npyplot.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2668fe812355d3028642c8092cec165b3a2cbfb9"},"cell_type":"markdown","source":"<font size=5>Analysis<font>\n1. The model works but could use much more fine-tuning. This model looks back 8 hours in the past to predict the present turbidity.  Looking back 4 hours would probably lead to a better result if we had measurements taken every hour as opposed to in 4 hour increments.\n2. More Data is needed as well as longer training time and \n3. The Fecal Coliform Data would also help in finding patterns that the lstm is missing\n   "},{"metadata":{"trusted":true,"_uuid":"84933b36fbc54428cf06aed6727d15a455abf49d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}