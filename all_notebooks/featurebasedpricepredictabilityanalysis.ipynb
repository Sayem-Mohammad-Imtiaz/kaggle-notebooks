{"cells":[{"metadata":{"trusted":true,"_uuid":"3903c02b3ab4e036b26318730671d82f1373f0b3"},"cell_type":"code","source":"# Import required libraries\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nimport seaborn as sns\nimport time\nfrom geopy.distance import great_circle\n\nfrom collections import Counter\nimport re\nimport xgboost as xgb\n\nfrom sklearn.linear_model import LinearRegression as lg\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.tree import DecisionTreeRegressor\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f29bd23b16c6eb940c158649f1fd5a12c1c895b7"},"cell_type":"code","source":"# Load the dataset\ndata_initial = pd.read_csv('../input/listings_summary.csv')\n# Print the columns of Initial Dataset loaded\ndata_initial.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94422be34e810c1b0ca689eca44f16692508ffb7"},"cell_type":"code","source":"# Move the selected Features for analysis into a variable\nfeatures_to_keep = ['id', 'space', 'description', 'host_has_profile_pic',\n                    'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',  \n                   'bedrooms', 'bed_type', 'amenities', 'square_feet', 'price', 'cleaning_fee', \n                   'security_deposit', 'extra_people', 'guests_included', 'minimum_nights',  \n                   'instant_bookable', 'cancellation_policy', 'experiences_offered', \n                    'neighborhood_overview','access', 'house_rules']\n\n# Load the Features into a dataset variable\ndata_raw = data_initial[features_to_keep].set_index('id')\n# Check the Shape of the Dataset\nprint(\"The dataset with selected features has {} rows and {} columns.\".format(*data_raw.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean, Normalize and Standardize the Features"},{"metadata":{"trusted":true,"_uuid":"a8cffbd6b177ab92078813369968b8c28547db8e"},"cell_type":"code","source":"# Normalizing the 'room_type' feature\ndata_raw.room_type.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"f007687907a984acb4d6bacae5d24be814e13785"},"cell_type":"code","source":"# Normalizing the 'property_type' feature\ndata_raw.property_type.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c80544e5eb95a404506b23cdb713f17bd2104f0b"},"cell_type":"code","source":"#Print First 3 rows of the selected features\ndata_raw[['price', 'cleaning_fee', 'extra_people', 'security_deposit']].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16c46d134999167f52c2b8882201647757414ca9"},"cell_type":"code","source":"# Checking for Nan's in 'price' column\ndata_raw.price.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"825b5cf5dce2b8a897d32caffb4fd716a4a199cf"},"cell_type":"code","source":"# Checking for Nan's in 'cleaning_fee' column\ndata_raw.cleaning_fee.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"038321b0bdc33aa48fdd0e6bf8017d6d8db3ed54"},"cell_type":"code","source":"#Replace Nan's with $0.00 for 'cleaning_fee'\ndata_raw.cleaning_fee.fillna('$0.00', inplace=True)\ndata_raw.cleaning_fee.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2c98e0c789b4e42096c7d729092b0b676b3dccf"},"cell_type":"code","source":"# Checking for Nan's in 'security_deposit' column\ndata_raw.security_deposit.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2deda6da721faa0c25db24eadb000bd58da24890"},"cell_type":"code","source":"#Replace Nan's with $0.00 for 'security_deposit'\ndata_raw.security_deposit.fillna('$0.00', inplace=True)\ndata_raw.security_deposit.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6210700b9fcac89834a910ea65c92fcf72b1bd15"},"cell_type":"code","source":"# Checking for Nan's in 'extra_people' column\ndata_raw.extra_people.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98f99f9d3bb94415650dd153993c8cc1efd31eec"},"cell_type":"code","source":"# Cleaning up the features using method chaining\ndata_raw.price = data_raw.price.str.replace('$', '').str.replace(',', '').astype(float)\ndata_raw.cleaning_fee = data_raw.cleaning_fee.str.replace('$', '').str.replace(',', '').astype(float)\ndata_raw.security_deposit = data_raw.security_deposit.str.replace('$', '').str.replace(',', '').astype(float)\ndata_raw.extra_people = data_raw.extra_people.str.replace('$', '').str.replace(',', '').astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bcc18faf3ad33549171885ba9e316c854fe370f"},"cell_type":"code","source":"# Analyzing the 'price' feature\ndata_raw['price'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0779a26846f6e8cda56160f4e83b94c8820771d3"},"cell_type":"code","source":"green_square = dict(markerfacecolor='g', markeredgecolor='g', marker='.')\ndata_raw['price'].plot(kind='box', xlim=(0, 1000), vert=False, flierprops=green_square, figsize=(16,3));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf28be9596521c708712eda83c921e1d7e181d10"},"cell_type":"code","source":"# Based on the plot, to improve the dataset quality removed listings with prices above 400 and 0.00 \ndata_raw.drop(data_raw[ (data_raw.price > 400) | (data_raw.price == 0) ].index, axis=0, inplace=True)\ndata_raw['price'].describe()\nprint(\"The dataset after price-wise preprocessed has {} rows and {} columns.\".format(*data_raw.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dafb873ecf5c408f22650b5c6a8296ac8716de54"},"cell_type":"code","source":"# Viewing all the dataset features for Nan's and Missing Values\ndata_raw.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fd60a373edd9ba5f441fe7766ebaa0b2161c378"},"cell_type":"code","source":"# Droping features with too many Nan's\ndata_raw.drop(columns=['square_feet', 'space','neighborhood_overview','access', 'house_rules'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d3f0e92c63d6f8837a2a1f58a72ec2038aec06d"},"cell_type":"code","source":"# Droping rows with Nan's in features 'bathrooms', 'bedrooms'\ndata_raw.dropna(subset=['bathrooms', 'bedrooms', ], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f236202db45057a75eee92de79ffb1830aeee306"},"cell_type":"code","source":"# Replacing Nan's with no for 'host_has_profile_pic' \ndata_raw.host_has_profile_pic.fillna(value='f', inplace=True)\ndata_raw.host_has_profile_pic.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcf8f55cfd5340e2602af264576ec49206b48be1"},"cell_type":"code","source":"# Checking the dataset features after dropping features with higher Nan's\ndata_raw.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'description' has lot of Nan's yet there might be useful information regading size\n# Trying to extract size by identyfying numbers followed by text like 'sm' or 'm' and \n# transform it into a new feature 'size'\n# Extract numbers from 'description' feature\ndata_raw['size'] = data_raw['description'].str.extract('(\\d{2,3}\\s?[smSM])', expand=True)\ndata_raw['size'] = data_raw['size'].str.replace(\"\\D\", \"\")\n\n# Now change datatype of size into float\ndata_raw['size'] = data_raw['size'].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping 'description' feature\ndata_raw.drop(['description'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding a new feature 'distance' to the dataset as location is most important in determining the price\ndef distance_from_midberlin(lat, lon):\n    berlin_centre = (52.5027778, 13.404166666666667)\n    record = (lat, lon)\n    return great_circle(berlin_centre, record).km\n\ndata_raw['distance'] = data_raw.apply(lambda x: distance_from_midberlin(x.latitude, x.longitude), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ef583ae18300fc053ebada9b0d71099f97aaa12"},"cell_type":"code","source":"print(\"After preprocessing for missing values and adding new features the dataset has {} rows and {} columns.\".format(*data_raw.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Linear Regressor Model for Training the data to predict missing values for 'size'"},{"metadata":{"trusted":true,"_uuid":"095983ecd3c257a7e5b6b992b165646e7b67f1c4"},"cell_type":"code","source":"# Filtering out sub_data to detrmine missing values in 'size' based on related independent features\nsub_data = data_raw[['accommodates', 'bathrooms', 'bedrooms',  'price', 'cleaning_fee', \n                 'security_deposit', 'extra_people', 'guests_included', 'distance', 'size']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7dbbca5f805af001a9b1f7e79c2e4aec24cff6b"},"cell_type":"code","source":"# Split datasets into train and test\ntrain_data = sub_data[sub_data['size'].notnull()]\ntest_data  = sub_data[sub_data['size'].isnull()]\n\n# Define X\nX_train = train_data.drop('size', axis=1)\nX_test  = test_data.drop('size', axis=1)\n\n# Define y\ny_train = train_data['size']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a741aeb9d1d92df1509b6c149ddf1bd0dbd86b8"},"cell_type":"code","source":"# Describe train_data, test_data, X_train, x_test and y_train data sets \nprint(\"Shape of Train Data:    \",train_data.shape)\nprint(\"Shape of Test Data:    \",test_data.shape)\nprint(\"\\nShape of X_train:\", X_train.shape)\nprint(\"Shape of X_test:\", X_test.shape)\nprint(\"\\nShape of y_train:\", y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e320edfda01defc46e775370bb7ab9dbf69c23bc"},"cell_type":"code","source":"\n# instantiate the Linear Regression Model\nlinreg = lg()\n\n# Fit Linear regression model to training data\nlinreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a93238b163cf5f1134cc99de6ad80d0ecb45dc20"},"cell_type":"code","source":"# Make predictions using the model\ny_test = linreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d9246e971184f96f1634b900d2fa2dc275ae24b"},"cell_type":"code","source":"# Add the new predicted values to the dataframe 'size' feature\ny_test = pd.DataFrame(y_test)\ny_test.columns = ['size']\nprint(y_test.shape)\ny_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"319521b104f0ae928661c70c49e3043ad1f7ebc2"},"cell_type":"code","source":"print(X_test.shape)\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8f50b3977c85bb99fcc5da05608f84cb3ed5523"},"cell_type":"code","source":"# Add the index of X_test to an own dataframe\nprelim_index = pd.DataFrame(X_test.index)\nprelim_index.columns = ['prelim']\n\n# Concat this dataframe with y_test to form our new test dataset\ny_test = pd.concat([y_test, prelim_index], axis=1)\ny_test.set_index(['prelim'], inplace=True)\ny_test.head()\nnew_test_data = pd.concat([X_test, y_test], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"638648b59f021298b350f663fe02ce9269ac653d"},"cell_type":"code","source":"# check the new test dataset for Nan's in 'size' feature\nprint(new_test_data.shape)\nnew_test_data['size'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4203809ece3a7d2cdf32923993c04f8a30105b1f"},"cell_type":"code","source":"# concant train and test data to a new sub dataset\nsub_data_new = pd.concat([new_test_data, train_data], axis=0)\n\nprint(sub_data_new.shape)\nsub_data_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eabd1d8e3140505feca328e3b153b77c49bf1118"},"cell_type":"code","source":"# check if the new sub dataset had Nan's in 'size' column\nsub_data_new['size'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ee5305165f18ffcdf51be6031206e87f98463e7"},"cell_type":"code","source":"# prepare the features before concatening\ndata_raw.drop(['accommodates', 'bathrooms', 'bedrooms', 'price', 'cleaning_fee', \n             'security_deposit', 'extra_people', 'guests_included', 'distance', 'size'], \n            axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97a09713d94be9863b54b54ccd097899efab8b7b"},"cell_type":"code","source":"# concate the dataset output from linear regression model to complete original dataframe\ndf = pd.concat([sub_data_new, data_raw], axis=1)\n\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca83d7bf9b6df07c2715b683d2a520daf66baa1a"},"cell_type":"code","source":"# analyze 'size' feature to improve quality of the data\ngreen_square = dict(markerfacecolor='g', markeredgecolor='g', marker='.')\ndf['size'].plot(kind='box', xlim=(0, 1000), vert=False, flierprops=green_square, figsize=(16,4));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee27340a0ab8245d7df4139e73549fdade8bea96"},"cell_type":"code","source":"# drop the rows with 'size' column values 0 and greater than 400 as they are only few \ndf.drop(df[ (df['size'] == 0.) | (df['size'] > 400.) ].index, axis=0, inplace=True)\nprint(\"The dataset after preprocessing 'size' feature has {} rows and {} columns.\".format(*df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"872df3f9ab4f458eb15f2d5ebe169f6d5517550c"},"cell_type":"code","source":"# Analyzing another important feature 'ameneties' \nresults = Counter()\ndf['amenities'].str.strip('{}')\\\n               .str.replace('\"', '')\\\n               .str.lstrip('\\\"')\\\n               .str.rstrip('\\\"')\\\n               .str.split(',')\\\n               .apply(results.update)\n\nresults.most_common(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9880fc5e526410d53c0d5a0a7a1111e1f3ec3f2"},"cell_type":"code","source":"# create a new sub dataframe with 'amenity' and 'count'\nsub_df = pd.DataFrame(results.most_common(30), columns=['amenity', 'count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0f740af02fdf197f7c168229f31d3edb2ed9c78"},"cell_type":"code","source":"# ploting the top 20 amenities \nsub_df.sort_values(by=['count'], ascending=True).plot(kind='barh', x='amenity', y='count',  \n                                                      figsize=(10,10), legend=False, color='green',\n                                                      title='Feature_Amenities')\nplt.xlabel('Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35db4194998042000e957b6f511b195105962236"},"cell_type":"code","source":"# adding new features using 'amenities'\ndf['Laptop_friendly_workspace'] = df['amenities'].str.contains('Laptop friendly workspace')\ndf['TV'] = df['amenities'].str.contains('TV')\ndf['Family_kid_friendly'] = df['amenities'].str.contains('Family/kid friendly')\ndf['Host_greets_you'] = df['amenities'].str.contains('Host greets you')\ndf['Smoking_allowed'] = df['amenities'].str.contains('Smoking allowed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4491af81d649943b18c5b91df1f9610a5b0e3b78"},"cell_type":"code","source":"# after adding new features drop redundant 'amenities' column \ndf.drop(['amenities'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f8c67fdd393ba4cbcd03b2d9ee2a350ec611a47"},"cell_type":"code","source":"# Check the exisiting columns on the dataset\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"162ffe3c48afff7f7082657cccdddcf02cf5ba75"},"cell_type":"code","source":"# print information of the dataset \ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e13cd8f0aa7e1e6f12fa3192b0cac654818389f"},"cell_type":"code","source":"# drop the unhelpful columns\ndf.drop(['latitude', 'longitude', 'property_type'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3372d9c15237f705fa5a959ab4bf96733e9ec2c"},"cell_type":"code","source":"# convert all string columns into categorical features\nfor col in ['host_has_profile_pic', 'room_type', 'bed_type', 'instant_bookable', \n            'cancellation_policy']:\n    df[col] = df[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db32f594aedc3ffbed9c79209711d01d3a6a156a"},"cell_type":"code","source":"# define target\ntarget = df[[\"price\"]]\n\n# define features \nfeatures = df.drop([\"price\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83eef52f4afd65edaf2b798aea12b021d3813498"},"cell_type":"code","source":"# identify neumerical features\nnum_fea = features.select_dtypes(include=['float64', 'int64', 'bool']).copy()\n\n# one-hot encoding of categorical features\ncat_fea = features.select_dtypes(include=['category']).copy()\ncat_fea = pd.get_dummies(cat_fea)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c919724f12ebcbab1bb67d86c9d8a41aa212bf3"},"cell_type":"code","source":"# concat numerical and categorical features\nfeatures_recoded = pd.concat([num_fea, cat_fea], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cde0fb453af5d66164ca16e079bfa3b842a9a68"},"cell_type":"code","source":"print(features_recoded.shape)\nfeatures_recoded.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XGBoost Regressor**"},{"metadata":{"trusted":true,"_uuid":"d02b729157e675c68fbdebc4ea99cdd69150c08f"},"cell_type":"code","source":"# split dataset into training and test datasets\nX_train, X_test, y_train, y_test = train_test_split(features_recoded, target, test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a637fb845ee679e98d197fb8c287e34207d2564"},"cell_type":"code","source":"# Instantiating XGB Regressor\n\nbooster_start = time.time()\n\nbooster = xgb.XGBRegressor()\n\n# create Grid\n                \nparam_grid = {'n_estimators': [200, 300, 400],\n              'learning_rate': [.03, 0.05, .07], \n              'max_depth': [3, 4, 5],\n              'min_child_weight': [4],\n              'colsample_bytree': [0.7, 0.8, 1],\n              'gamma': [0.0, 0.1, 0.2]}\n\n# instantiate the tuned random forest\nbooster_grid_search = GridSearchCV(booster, param_grid, cv=3, n_jobs=-1)\n\n# train the tuned random forest\nbooster_grid_search.fit(X_train, y_train)\n\n# print best estimator parameters found during the grid search\nprint(booster_grid_search.best_params_)\n\nbooster = xgb.XGBRegressor(colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, \n                           max_depth=6, n_estimators=200)\nbooster.fit(X_train, y_train)\ntraining_preds_booster = booster.predict(X_train)\nval_preds_booster = booster.predict(X_test)\n\nbooster_end = time.time()\n\n# Printing the results\n\nprint(\"\\nTraining RMSE:\", round(np.sqrt(mean_squared_error(y_train, training_preds_booster)),4))\nprint(\"Validation RMSE:\", round(np.sqrt(mean_squared_error(y_test, val_preds_booster)),4))\nprint(\"\\nTraining r2:\", round(r2_score(y_train, training_preds_booster),4))\nprint(\"Validation r2:\", round(r2_score(y_test, val_preds_booster),4))\nprint(f\"Time taken to run: {round((booster_end - booster_start)/60,1)} minutes\")\n\n# Producing a dataframe of feature importances\nft_weights_booster = pd.DataFrame(booster.feature_importances_, columns=['weight'], index=features_recoded.columns)\nft_weights_booster.sort_values('weight', inplace=True)\nft_weights_booster\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting feature importances\nplt.figure(figsize=(8,20))\nplt.barh(ft_weights_booster.index, ft_weights_booster.weight, align='center') \nplt.title(\"Feature importances in the XGBoost model\", fontsize=14)\nplt.xlabel(\"Feature importance\")\nplt.margins(y=0.01)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Cross Validation with 10 fold \nxg_train = xgb.DMatrix(data=X_train, label=y_train)\n\nparams = {'colsample_bytree': 0.3,'learning_rate': 0.2,\n                'max_depth': 5, 'alpha': 10}\n\ncv_results = xgb.cv(dtrain=xg_train, params=params, nfold=10,\n                    num_boost_round=200,early_stopping_rounds=5,metrics=\"rmse\", as_pandas=True, seed=123)\n\nprint((cv_results[\"test-rmse-mean\"]).tail(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the important features needed for Simple Model\nfeat_importances = pd.Series(booster.feature_importances_, index=features_recoded.columns)\nfeat_importances.nlargest(10).sort_values().plot(kind='barh', color='green', figsize=(10,5))\nplt.xlabel('Relative Feature Importance with XGBoost');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the columns of original dataset\nfeatures_recoded.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define Simple Model Dataset with 10 features\nsimplefeatures_to_keep = ['accommodates', 'bathrooms', 'bedrooms', 'extra_people', 'guests_included', 'size',\n                          'room_type_Private room','room_type_Entire home/apt','room_type_Shared room', \n                          'cancellation_policy_super_strict_60']\nsimplefeatures = features_recoded[simplefeatures_to_keep]\n\n# Check the Shape of the Dataset with important features for Simple Model\nprint(\"The dataset with selected features has {} rows and {} columns.\".format(*simplefeatures.shape))\n\n# split dataset into training and test datasets\nSimpleX_train, SimpleX_test, Simpley_train, Simpley_test = train_test_split(simplefeatures, target, test_size=0.2)\n\n# Instantiating XGB Regressor for training Simple model\n\nsimplebooster_start = time.time()\n\nsimplebooster = xgb.XGBRegressor()\n\nsimplebooster = xgb.XGBRegressor(colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, \n                           max_depth=6, n_estimators=200, random_state=4)\nsimplebooster.fit(SimpleX_train, Simpley_train)\ntraining_preds_simplebooster = simplebooster.predict(SimpleX_train)\nval_preds_simplebooster = simplebooster.predict(SimpleX_test)\n\nsimplebooster_end = time.time()\n\n\n# Printing the results for Simple Model\n\nprint(\"\\nTraining RMSE:\", round(np.sqrt(mean_squared_error(Simpley_train, training_preds_simplebooster)),4))\nprint(\"Validation RMSE:\", round(np.sqrt(mean_squared_error(Simpley_test, val_preds_simplebooster)),4))\nprint(\"\\nTraining r2:\", round(r2_score(Simpley_train, training_preds_simplebooster),4))\nprint(\"Validation r2:\", round(r2_score(Simpley_test, val_preds_simplebooster),4))\nprint(f\"Time taken to run: {round((simplebooster_end - simplebooster_start)/60,1)} minutes\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree Regressor Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# split test and train datasets \nX = features_recoded\ny = df[\"price\"]\n\nX_treetrain, X_treetest, y_treetrain, y_treetest = train_test_split(X, y, test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate Decision Tree Regression Model\n\ntree_start = time.time()\n\nregr_tree = DecisionTreeRegressor()\n# fit and train model\nregr_tree.fit(X_treetrain, y_treetrain)\n\nval_pred_decisiontree = regr_tree.predict(X_treetest)\n\ntree_end = time.time()\n\n# Printing the results for Decision Tree Regression Model\n\nprint(\"Validation RMSE:\", round(np.sqrt(mean_squared_error(y_treetest, val_pred_decisiontree)),4))\nprint(f\"Time taken to run: {round((tree_end - tree_start),1)} seconds\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}