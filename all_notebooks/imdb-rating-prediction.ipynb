{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading the data\ndf= pd.read_csv('/kaggle/input/imdb-5000-movie-dataset/movie_metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing all the necessary libraries\nimport matplotlib.pyplot as plt\nimport seaborn           as sns\nimport statsmodels.api   as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nimport scipy.stats as stats\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom statsmodels.formula.api import ols\n\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns=None\n\npd.options.display.max_rows=None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf.profile_report()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that most of movies are released in USA and are in English language.\n\nAlmost all columns are skewed. So, we need to apply transforamtion.\n\nThere are some missing values in some columns. So, we need to treat them as well.\n\nThere's very low correlation between all independent variables and the dependent variable. \n\nSo, we can infer that linear regression will not give good accuracy.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping all the un-necessary columns\ndf = df.drop(['color', 'movie_imdb_link', 'movie_title', 'plot_keywords', 'director_name','actor_1_name', 'actor_2_name', 'actor_3_name', 'country','language', 'genres', 'title_year'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#content_rating is a categorical column so let's replace missing value for this column with its' mode.\n\ncontent_rating_mode= df['content_rating'].mode()\ndf.content_rating.fillna(content_rating_mode[0],inplace=True)\n\n\n\n# For All numerical columns, we will replace the missing values with their medians.\n\nmedianlist=['actor_2_facebook_likes','actor_1_facebook_likes','num_user_for_reviews','director_facebook_likes',\n            'gross','duration', 'num_critic_for_reviews','budget','actor_3_facebook_likes',\n            'num_critic_for_reviews','aspect_ratio','facenumber_in_poster']\n\n\ndef median(i):\n    median= df[i].median()\n    i = df[i].fillna(median)\n    return i\n\n\n\nfor i in medianlist:\n    df[i]= median(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dummies for content_rating.\ntop_10_CR=[x for x in df.content_rating.value_counts().sort_values(ascending=False).head(10).index]\n\nfor label in top_10_CR:\n    df[\"content_rating\"+\"_\"+label]=np.where(label==df[\"content_rating\"],1,0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the original column after \ndf= df.drop('content_rating',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1= df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df:\n    df[i] = df[i].map(lambda i: np.log1p(i) ) \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.drop('imdb_score', axis=1)\nY=df['imdb_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc= StandardScaler()\npd.DataFrame()\nX= pd.DataFrame(sc.fit_transform(x), columns=x.columns)\nX.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# train test split\nx_train,x_test,y_train,y_test = train_test_split(X ,Y,test_size = 0.3,random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter Tuning\n\n### Random forest Grid search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc= RandomForestRegressor(random_state=1)\nhyper={'n_estimators': np.arange(1,50)}\n\nrfc_grid=GridSearchCV(estimator= rfc, param_grid=hyper, verbose=True)\n\nrfc_grid.fit(x_train,y_train)\n\nrfc_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN gridsearch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_param= {'n_neighbors': np.arange(3,30), 'weights':['uniform', 'distance']}\nknn = KNeighborsRegressor()\nknn_grid= GridSearchCV(knn, knn_param, cv=5, scoring='neg_mean_squared_error')\nknn_grid.fit(x_train, y_train)\n\nknn_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision tree Grid Search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt= DecisionTreeRegressor(random_state=1)\ndt_params= {'max_depth': np.arange(1,50), 'min_samples_leaf': np.arange(2,15)} #2,15 not too high, not too low\n\nGS_dt= GridSearchCV(dt, dt_params, cv=5, scoring='neg_mean_squared_error')\n\nGS_dt.fit(x_train, y_train)\n\nGS_dt.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ada-boost RF Grid Search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nRF= RandomForestRegressor(**rfc_grid.best_params_, random_state=1)\nensemble_params= {'n_estimators': np.arange(1,20)} \nAB_RF= ensemble.AdaBoostRegressor(base_estimator=RF ,random_state=1)\n\nGS_AB_RF = GridSearchCV(AB_RF, ensemble_params, cv=5, scoring='neg_mean_squared_error')\n\nGS_AB_RF.fit(x_train, y_train)\nGS_AB_RF.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Calculate accuracy for each model after applying grid SearchÂ¶\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#declare the models\nlr  = LinearRegression()\nRF  = RandomForestRegressor(n_estimators= 48, random_state=1)\nknn = KNeighborsRegressor(n_neighbors= 10, weights= 'distance')\ndt  = DecisionTreeRegressor(max_depth= 6, min_samples_leaf= 13)\nbgc =ensemble.BaggingRegressor(base_estimator=lr)\nAB_RF= ensemble.AdaBoostRegressor(**GS_AB_RF.best_params_, base_estimator=RF, random_state=1)\ngb  =ensemble.GradientBoostingRegressor()\n\n#create a list of models\nmodels=[lr,RF ,knn, dt, bgc,AB_RF, gb]\n\ndef score_model(xtrain,ytrain,xtest,ytest):\n    mod_columns=[]\n    mod=pd.DataFrame(columns=mod_columns)\n    i=0\n    #read model one by one\n    for model in models:\n        model.fit(xtrain,ytrain)\n        y_pred=model.predict(xtest)\n        \n        \n        \n        \n        #compute metrics\n        train_accuracy=model.score(xtrain,ytrain)\n        test_accuracy=model.score(xtest,ytest)\n        \n        #insert in dataframe\n        mod.loc[i,\"Model_Name\"]=model.__class__.__name__\n        mod.loc[i,\"Train_Accuracy\"]=round(train_accuracy,2)\n        mod.loc[i,\"Test_Accuracy\"]=round(test_accuracy,2)\n        \n        i+=1\n\n    \n    return(mod)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report=score_model(x_train,y_train,x_test,y_test)\nreport","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we had inferred above, we can see that linear regression is not giving good results.\n# We can conclude that gradient boosting Regressor is the best model as it has good train and test accuracies as compared to other models.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}