{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom imblearn.over_sampling import RandomOverSampler,SMOTEN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom keras.models import Model\nimport kerastuner as kt\nfrom keras.applications.mobilenet import preprocess_input\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Dense\nfrom keras.layers.merge import concatenate\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T08:41:12.882979Z","iopub.execute_input":"2021-06-29T08:41:12.883316Z","iopub.status.idle":"2021-06-29T08:41:19.914284Z","shell.execute_reply.started":"2021-06-29T08:41:12.883286Z","shell.execute_reply":"2021-06-29T08:41:19.913208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We will import the datasets from fer2013.csv dataset from Kaggle.**","metadata":{}},{"cell_type":"code","source":"expression=pd.read_csv('../input/facialexpressionrecognition/fer2013.csv')\nexpression","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:19.915947Z","iopub.execute_input":"2021-06-29T08:41:19.916388Z","iopub.status.idle":"2021-06-29T08:41:26.7446Z","shell.execute_reply.started":"2021-06-29T08:41:19.916345Z","shell.execute_reply":"2021-06-29T08:41:26.743492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"expression.emotion.unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:26.74629Z","iopub.execute_input":"2021-06-29T08:41:26.746698Z","iopub.status.idle":"2021-06-29T08:41:26.756122Z","shell.execute_reply.started":"2021-06-29T08:41:26.746657Z","shell.execute_reply":"2021-06-29T08:41:26.755169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Each pixel row has 2304 values which can be broken down into 48*48 images**","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:44:59.10409Z","iopub.execute_input":"2021-06-29T05:44:59.104474Z","iopub.status.idle":"2021-06-29T05:44:59.11347Z","shell.execute_reply.started":"2021-06-29T05:44:59.104437Z","shell.execute_reply":"2021-06-29T05:44:59.11169Z"}}},{"cell_type":"code","source":"len(expression['pixels'][0].split())","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:26.897438Z","iopub.execute_input":"2021-06-29T08:41:26.897921Z","iopub.status.idle":"2021-06-29T08:41:26.903153Z","shell.execute_reply.started":"2021-06-29T08:41:26.897879Z","shell.execute_reply":"2021-06-29T08:41:26.902159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The data is distributed across training,testing and validation sets. Thus, we will seperate that data.**","metadata":{}},{"cell_type":"code","source":"emot_training=expression.loc[expression['Usage']=='Training']\nemot_test=expression.loc[expression['Usage']=='PrivateTest']\nemot_valid=expression.loc[expression['Usage']=='PublicTest']","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:30.470219Z","iopub.execute_input":"2021-06-29T08:41:30.470774Z","iopub.status.idle":"2021-06-29T08:41:30.488589Z","shell.execute_reply.started":"2021-06-29T08:41:30.470727Z","shell.execute_reply":"2021-06-29T08:41:30.487563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We will now look at the data different distribution of data for test,validation and training data for each category of image.**","metadata":{}},{"cell_type":"code","source":"pd.concat([emot_training['emotion'].value_counts(),emot_valid['emotion'].value_counts(),emot_test['emotion'].value_counts()],axis=1,keys=['Training','Validation','Testing'])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:36.27335Z","iopub.execute_input":"2021-06-29T08:41:36.273706Z","iopub.status.idle":"2021-06-29T08:41:36.29266Z","shell.execute_reply.started":"2021-06-29T08:41:36.273675Z","shell.execute_reply":"2021-06-29T08:41:36.291744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since the data for each category is not evenly distributed, we will do some random sampling to increase the size of data for certain caetgories using imblearn library.**","metadata":{}},{"cell_type":"code","source":"dup_emo=emot_training['emotion']\ndup_train=emot_training.drop('emotion',axis=1)\n\ndup_emo_valid=emot_valid['emotion']\ndup_valid=emot_valid.drop('emotion',axis=1)\n\nsampling_dict_1={0:3995,1:1500,2:4097,3:7215,4:4830,5:3171,6:4965}\n# sampling_dict_2={0:3995,1:1500,2:4097,3:4000,4:4000,5:3171,6:4000}\nover_sample=SMOTEN(sampling_strategy=sampling_dict_1,random_state=101)\ndup_train,dup_emo=over_sample.fit_resample(dup_train.values,dup_emo.values)\n\nsampling_dict_2={0:467,1:200,2:496,3:895,4:653,5:415,6:607}\nover_sample_2=SMOTEN(sampling_strategy=sampling_dict_2,random_state=101)\ndup_valid,dup_emo_valid=over_sample_2.fit_resample(dup_valid.values,dup_emo_valid.values)\n# under_sample=RandomUnderSampler(sampling_strategy=sampling_dict_2,random_state=101)\n# steps=[('over',over_sample),('under',under_sample)]\n# pipe=Pipeline(steps)\n# dup,dup_emo=pipe.fit_resample(dup.values,dup_emo.values)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:39.615105Z","iopub.execute_input":"2021-06-29T08:41:39.615449Z","iopub.status.idle":"2021-06-29T08:41:40.081459Z","shell.execute_reply.started":"2021-06-29T08:41:39.615405Z","shell.execute_reply":"2021-06-29T08:41:40.080467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emot_training=pd.DataFrame(dup_train,columns=['pixels','Usage'])\nemot_training['emotion']=dup_emo\n\nemot_valid=pd.DataFrame(dup_valid,columns=['pixels','Usage'])\nemot_valid['emotion']=dup_emo_valid","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:44.310987Z","iopub.execute_input":"2021-06-29T08:41:44.311338Z","iopub.status.idle":"2021-06-29T08:41:44.321807Z","shell.execute_reply.started":"2021-06-29T08:41:44.3113Z","shell.execute_reply":"2021-06-29T08:41:44.320892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat([emot_training['emotion'].value_counts(),emot_valid['emotion'].value_counts()],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:45.220868Z","iopub.execute_input":"2021-06-29T08:41:45.221345Z","iopub.status.idle":"2021-06-29T08:41:45.235149Z","shell.execute_reply.started":"2021-06-29T08:41:45.221312Z","shell.execute_reply":"2021-06-29T08:41:45.23406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nfor each_image in range(1,10):\n    temp=emot_training['pixels'][each_image].split()\n    for i in range(len(temp)):\n        temp[i]=int(temp[i])\n    plt.subplot(3,3,each_image)\n    plt.imshow(np.array(temp).reshape(48,48))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:47.876456Z","iopub.execute_input":"2021-06-29T08:41:47.876794Z","iopub.status.idle":"2021-06-29T08:41:48.61865Z","shell.execute_reply.started":"2021-06-29T08:41:47.876765Z","shell.execute_reply":"2021-06-29T08:41:48.617955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_emotions=emot_training['emotion']\ntrain_emotions=keras.utils.to_categorical(train_emotions)\n\ntest_emotions=emot_test['emotion']\ntest_emotions=keras.utils.to_categorical(test_emotions)\n\nvalid_emotions=emot_valid['emotion']\nvalid_emotions=keras.utils.to_categorical(valid_emotions)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:48.791927Z","iopub.execute_input":"2021-06-29T08:41:48.792409Z","iopub.status.idle":"2021-06-29T08:41:48.798717Z","shell.execute_reply.started":"2021-06-29T08:41:48.792378Z","shell.execute_reply":"2021-06-29T08:41:48.797724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images=np.uint8(emot_training['pixels'].str.split().tolist())\ntrain_images=train_images.reshape((emot_training.shape[0],48,48,1))\ntrain_images=train_images.astype('float32')/255\n\ntest_images=np.uint8(emot_test['pixels'].str.split().tolist())\ntest_images=test_images.reshape((emot_test.shape[0],48,48,1))\ntest_images=test_images.astype('float32')/255\n\nvalid_images=np.uint8(emot_valid['pixels'].str.split().tolist())\nvalid_images=valid_images.reshape((emot_valid.shape[0],48,48,1))\nvalid_images=valid_images.astype('float32')/255\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:49.75479Z","iopub.execute_input":"2021-06-29T08:41:49.755123Z","iopub.status.idle":"2021-06-29T08:42:10.904896Z","shell.execute_reply.started":"2021-06-29T08:41:49.755092Z","shell.execute_reply":"2021-06-29T08:42:10.9041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test_images[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:42:10.906021Z","iopub.execute_input":"2021-06-29T08:42:10.906409Z","iopub.status.idle":"2021-06-29T08:42:11.014486Z","shell.execute_reply.started":"2021-06-29T08:42:10.906379Z","shell.execute_reply":"2021-06-29T08:42:11.013343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We use stacked models for prediction of our data.\nI have used 3 different neural models an stacked them up on another neural network.**","metadata":{}},{"cell_type":"code","source":"model_1=keras.Sequential([\n    keras.Input(train_images.shape[1:]),\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.Flatten(),\n\n    layers.Dense(units=192,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(192,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(7,activation='softmax')\n])\n\nopt=keras.optimizers.Adam(\n    learning_rate=0.01,\n#     beta_1=0.91\n)  \n\nmodel_1.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n    \n    \nmodel_2=keras.Sequential([\n    keras.Input(train_images.shape[1:]),\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.Flatten(),\n\n    layers.Dense(units=128,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(128,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(7,activation='softmax')\n])\n\nopt=keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.91\n)  \n\nmodel_2.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)    \n\n\nmodel_3=keras.Sequential([\n    keras.Input(train_images.shape[1:]),\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n#     layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.Flatten(),\n\n    layers.Dense(units=32,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(32,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(7,activation='softmax')\n])\n\nopt=keras.optimizers.Adam(\n    learning_rate=0.01,\n    beta_1=0.95\n)  \n\nmodel_3.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n    \nmodels=[model_1,model_2,model_3]\nepochs_list=[25,25,25]","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:42:11.016571Z","iopub.execute_input":"2021-06-29T08:42:11.016996Z","iopub.status.idle":"2021-06-29T08:42:11.644588Z","shell.execute_reply.started":"2021-06-29T08:42:11.016953Z","shell.execute_reply":"2021-06-29T08:42:11.643617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def fit_model(train_x,train_y,i):\n#     model=models[i]\n    \n#     history=model.fit(train_x,train_y,epochs=epochs_list[i],verbose=0)\n    \n#     return model\n\n# for i in range(3):\n#     model=fit_model(train_images,train_emotions,i)\n    \n#     filename='model/model_' + str(i+4) + '.h5'\n    \n#     model.save(filename)\n    \n#     print('Saved' + filename)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:41:05.432022Z","iopub.execute_input":"2021-06-29T08:41:05.432404Z","iopub.status.idle":"2021-06-29T08:41:05.498014Z","shell.execute_reply.started":"2021-06-29T08:41:05.432323Z","shell.execute_reply":"2021-06-29T08:41:05.496765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_all_models(n_models):\n    all_models=[]\n    for i in range(3):\n        filename='../input/ensemble-models/model_' + str(i+4) + '.h5'\n        model=load_model(filename)\n        all_models.append(model)\n        print(filename + 'loaded')\n        \n    return all_models\n\ndef stacked_model(members):\n    for i in range(len(members)):\n        model=members[i]\n        for layer in model.layers:\n            layer.trainable=False\n            layer._name = 'ensemble_' + str(i+4) + '_' + layer.name\n            \n    ensemble_input=[model.input for model in members]\n    ensemble_output=[model.output for model in members]\n\n    merge=concatenate(ensemble_output)\n    hidden=Dense(units=128,activation='relu')(merge)\n    hidden=Dense(units=128,activation='relu')(hidden)\n    hidden=Dense(units=128,activation='relu')(hidden)\n    output=Dense(units=7,activation='softmax')(hidden)\n\n    model=Model(inputs=ensemble_input,outputs=output)\n    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n    \n    return model\n\ndef fit_stacked_model(model,inputX,inputY):\n    X=[inputX for _ in range(len(model.input))]\n#     inputy_enc=to_categorical(inputY)\n    \n    model.fit(X,inputY,epochs=25,verbose=0)\n    \ndef predict_stacked_model(model,inputx):\n    X=[inputx for _ in range(len(model.input))]\n    return model.predict(X,verbose=0)\n\nmembers=load_all_models(3)\nstacked_models=stacked_model(members)\n\nfit_stacked_model(stacked_models,valid_images,valid_emotions)\n\nyhat=predict_stacked_model(stacked_models,valid_images)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T08:42:15.653019Z","iopub.execute_input":"2021-06-29T08:42:15.653347Z","iopub.status.idle":"2021-06-29T09:07:39.202201Z","shell.execute_reply.started":"2021-06-29T08:42:15.653317Z","shell.execute_reply":"2021-06-29T09:07:39.200991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacked_models.input","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:11:12.244217Z","iopub.execute_input":"2021-06-29T09:11:12.244634Z","iopub.status.idle":"2021-06-29T09:11:12.251247Z","shell.execute_reply.started":"2021-06-29T09:11:12.244584Z","shell.execute_reply":"2021-06-29T09:11:12.250379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat2=np.argmax(yhat,axis=1)\nacc=accuracy_score(np.argmax(valid_emotions,axis=1),yhat2)\nacc","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:11:15.320866Z","iopub.execute_input":"2021-06-29T09:11:15.32127Z","iopub.status.idle":"2021-06-29T09:11:15.328587Z","shell.execute_reply.started":"2021-06-29T09:11:15.321231Z","shell.execute_reply":"2021-06-29T09:11:15.327722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have a test accuracy of 64%+**","metadata":{}},{"cell_type":"code","source":"yhat3=predict_stacked_model(stacked_models,test_images)\nacc=accuracy_score(np.argmax(test_emotions,axis=1),np.argmax(yhat3,axis=1))\nacc","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:11:18.946017Z","iopub.execute_input":"2021-06-29T09:11:18.946332Z","iopub.status.idle":"2021-06-29T09:12:15.23432Z","shell.execute_reply.started":"2021-06-29T09:11:18.946303Z","shell.execute_reply":"2021-06-29T09:12:15.233325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat4=predict_stacked_model(stacked_models,train_images)\nprint(classification_report(test_emotions,to_categorical(np.argmax(yhat3,axis=1))))\nprint(classification_report(train_emotions,to_categorical(np.argmax(yhat4,axis=1))))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T09:12:15.236046Z","iopub.execute_input":"2021-06-29T09:12:15.236454Z","iopub.status.idle":"2021-06-29T09:20:00.37055Z","shell.execute_reply.started":"2021-06-29T09:12:15.236391Z","shell.execute_reply":"2021-06-29T09:20:00.369709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_emo(n):\n    emotions_list = {0:'angry',1:'disgust',2:'fear',3:'happy',4:'sad',5:'surprise',6:'neutral'}\n    return emotions_list[n]\n\n\ndef pred(image):\n    inp=image.reshape(1,48,48,1)\n    \n    img=[inp for _ in stacked_models.input]\n    \n    print(map_emo(np.argmax(stacked_models.predict(img))))\n    \n    plt.imshow(image)\n\npred(train_images[3897])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T10:29:07.352112Z","iopub.execute_input":"2021-06-29T10:29:07.352488Z","iopub.status.idle":"2021-06-29T10:29:07.523853Z","shell.execute_reply.started":"2021-06-29T10:29:07.352457Z","shell.execute_reply":"2021-06-29T10:29:07.522995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}