{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.columns:\n    if df[col].dtypes == object:\n        print('------')\n        print(df[col].describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_less_5 = []\nprint(\"Less than 5% missing values:\\n\")\nfor col in df.columns:\n    percen_NaN = df[col].isnull().sum()/df.shape[0]*100   \n    # Columns with more than 5% of NaN \n    if percen_NaN < 5:\n        print(f'{col} : {df[col].isnull().sum()/df.shape[0]*100}%')\n        col_less_5.append(col)\nprint(\"-------------\")\nprint(\"\\nMore than 5% missing values:\\n\")\nfor col in df.columns:\n    percen_NaN = df[col].isnull().sum()/df.shape[0]*100   \n    # Columns with more than 5% of NaN \n    if percen_NaN >= 5:\n        print(f'{col} : {df[col].isnull().sum()/df.shape[0]*100}%')\n        pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[[\"Cloud9am\",\"Cloud3pm\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First with NaN < 5% ","metadata":{}},{"cell_type":"code","source":"df_2 = df[col_less_5].dropna()\ndf_2[col_less_5].isna().sum(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'{round((df_2[col_less_5].dropna().shape[0] - df[col_less_5].shape[0]) / df[col_less_5].shape[0] * 100,2)}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On a perdu 7.47% de l'information total mais toutes nos valeurs sont goods normalement","metadata":{}},{"cell_type":"code","source":"df_2[col_less_5].info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_2[['RainToday','RainTomorrow']].value_counts()\ndf_2['RainToday'] = df_2['RainToday'].map(lambda x : 0 if x == \"No\" else 1)\ndf_2['RainTomorrow'] = df_2['RainTomorrow'].map(lambda x : 0 if x == \"No\" else 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2.drop(['WindDir3pm'], axis = 1,inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = df_2[df_2.columns[2:-1]].copy()\ndf_cr = (X - X.mean())/X.std()\ndf_cr['RainToday'] = df_2['RainToday']\ndf_cr['RainTomorrow'] = df_2['RainTomorrow']\ndf_cr = df_cr.reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cr.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_interesting = [\"MinTemp\",\"MaxTemp\",\"Humidity9am\",\"Humidity3pm\",\"Temp9am\",\"Temp3pm\",\"RainTomorrow\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cr[[\"RainToday\",\"RainTomorrow\"]].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(df_cr[col_interesting], hue=\"RainTomorrow\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-NN","metadata":{}},{"cell_type":"markdown","source":"'Humidity3pm','MinTemp', 'MaxTemp'","metadata":{}},{"cell_type":"code","source":"y = df_cr[\"RainTomorrow\"]\ncol_features = [\"MinTemp\",\"MaxTemp\",\"Humidity9am\",\"Humidity3pm\",\"Temp9am\",\"Temp3pm\",\"RainToday\"]\nX = df_cr[col_features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=6)\nknn.fit(X_train, y_train)\nprediction = knn.predict(X_test)\nknn.score(X_train,y_train)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Précision \nsum(prediction == y_test)/len(y_test)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test du best n_neighbors","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nn_neighbors_list = range(1,21)\nTesting_Accuracy = []\nTraining_Accuracy = []\nfor n_i in n_neighbors_list:\n    knn = KNeighborsClassifier(n_neighbors= n_i)\n    knn.fit(X_train, y_train)\n    prediction = knn.predict(X_test)\n    print(f'--\\n{n_i} neighbors')\n    print(confusion_matrix(y_test,prediction)/len(y_test)*100)\n    Training_Accuracy.append(knn.score(X_train,y_train)*100)\n    Testing_Accuracy.append(sum(prediction == y_test)/len(y_test)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Training_Accuracy)\nprint('---')\nprint(Testing_Accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()[1]/y_train.value_counts()[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Result_knn = pd.DataFrame({'n' : n_neighbors_list,'Training_Accuracy' : Training_Accuracy,'Testing_Accuracy' : Testing_Accuracy})\nsns.lineplot(x = \"n\", \n             y = \"Training_Accuracy\",\n             palette = \"Set2\",\n             label = \"Training\",\n             linewidth = 3,\n             data = Result_knn)\nsns.lineplot(x = \"n\", \n             y = \"Testing_Accuracy\", \n             palette = \"Set2\",\n             label = \"Testing\",\n             linewidth = 3,\n             data = Result_knn)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ACP","metadata":{}},{"cell_type":"code","source":"df_acp = df_2[df_2.columns[2:-1]]\ndf_acp.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nZ_acp = sc.fit_transform(df_acp)\n#moyenne\nprint(np.mean(Z_acp,axis=0))\n#écart-type\nprint(np.std(Z_acp,axis=0,ddof=0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nacp = PCA(svd_solver='full')\n#calculs\ncoord = acp.fit_transform(Z_acp)\nn = acp.n_components_\nprint(acp.n_components_) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#valeur corrigée\neigval = (Z_acp.shape[0]-1)/Z_acp.shape[0]*acp.explained_variance_\nprint(eigval)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#proportion de variance expliquée\nprint(acp.explained_variance_ratio_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n#scree plot\nplt.plot(np.arange(1,Z_acp.shape[1]+1),eigval)\nplt.title(\"Scree plot\")\nplt.ylabel(\"Eigen values\")\nplt.xlabel(\"Factor number\")\nplt.arrow(x=4,y=3,dx=-1.75,dy=-0.88,width=0.04,head_starts_at_zero=True,color = 'red')\nplt.arrow(x=6,y=2,dx=-1.75,dy=-0.88,width=0.04,head_starts_at_zero=True,color = 'green')\nplt.text(4,3,'Elbow 1',color='red')\nplt.text(6,2,'Elbow 2',color='green')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cumul de variance expliquée\nplt.plot(np.arange(1,Z_acp.shape[1]+1),np.cumsum(acp.explained_variance_ratio_))\nplt.title(\"Explained variance vs. # of factors\")\nplt.ylabel(\"Cumsum explained variance ratio\")\nplt.xlabel(\"Factor number\")\nplt.axvline(4,color='red')\nplt.axhline(0.86,color='red')\nplt.text(1,0.88,'86%',color='red')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On va prend k = 4  \nk étant le nombre d'axes ","metadata":{}},{"cell_type":"code","source":"ratio = Z_acp.shape[0]/Z_acp.shape[1]\n#Une bonne ACP est si ratio > 3, alors c'est plutôt une bonne ACP \nprint(ratio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seuils pour test des bâtons brisés\nbs = 1/np.arange(Z_acp.shape[1],0,-1)\nbs = np.cumsum(bs)\nbs = bs[::-1]\n\n#test des bâtons brisés\nprint(pd.DataFrame({'Val.Propre':eigval,'Seuils':bs}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acp_test_color = df_2[df_2.columns[2:]]\nacp_test_color\n#modalités de la variable qualitative\nmodalites = np.unique(acp_test_color[\"RainTomorrow\"])\nprint(modalites)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in range(len(modalites)):\n    print(c)\n    print(len(acp_test_color.query(f\"(RainTomorrow  ==  {modalites[c]})\")))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n#pour chaque modalité de la var. illustrative\nfor c in range(len(modalites)):\n    #numéro des individus concernés\n    numero = acp_test_color.query(f\"(RainToday  ==  {modalites[c]})\")\n\ntest2 = pd.DataFrame({'X':coord[:,0],'Y':coord[:,1],'RainToday': df_2[\"RainToday\"]})\n\nplt.subplots(figsize=(12,12))\nsns.scatterplot(x = 'X', y = 'Y',hue=\"RainToday\",alpha=0.3,\n                data = test2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n#pour chaque modalité de la var. illustrative\nfor c in range(len(modalites)):\n    #numéro des individus concernés\n    numero = acp_test_color.query(f\"(RainTomorrow  ==  {modalites[c]})\")\n\ntest = pd.DataFrame({'X':coord[:,0],'Y':coord[:,1],'RainTomorrow': acp_test_color[\"RainTomorrow\"]})\n\nplt.subplots(figsize=(12,12))\nsns.scatterplot(x = 'X', y = 'Y',hue=\"RainTomorrow\",alpha=0.3,\n                data = test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\ntest_3D = pd.DataFrame({'X':coord[:,0],'Y':coord[:,1],'Z':coord[:,2],'RainTomorrow': acp_test_color[\"RainTomorrow\"]})\nfig = px.scatter_3d(test_3D, x='X', y='Y', z='Z',color = 'RainTomorrow')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Séparation trop marqué, donc trop grosse importance de la variable Rain Today**","metadata":{}},{"cell_type":"code","source":"# Question 1.iii\nfig, ax = plt.subplots(1,2, figsize=[20,5])\nRain_0 = test2[test2[\"RainToday\"]  ==  0]\nRain_1 = test2[test2[\"RainToday\"]  ==  1]\n\nsns.scatterplot(ax = ax[0],x = 'X',\n                y = 'Y',\n                data = Rain_0)\nsns.scatterplot(ax = ax[1],x = 'X',\n                y = 'Y', \n                data = Rain_1,color='red')\n\nax[0].set_xlim(-10,10)\nax[0].set_ylim(-3,25)\n\nax[1].set_xlim(-10,10)\nax[1].set_ylim(-3,25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#contribution des individus dans l'inertie totale\ndi = np.sum(Z_acp**2,axis=1)\nprint(pd.DataFrame({'d_i':di}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#qualité de représentation des individus - COS2\ncos2 = coord**2\nfor j in range(Z_acp.shape[1]):\n    cos2[:,j] = cos2[:,j]/di\nprint(pd.DataFrame({'COS2_1':cos2[:,0],'COS2_2':cos2[:,1]}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vérifions la théorie - somme en ligne des cos2 = 1\nprint(np.sum(cos2,axis=1).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Représentation des variables","metadata":{}},{"cell_type":"code","source":"#racine carrée des valeurs propres\nsqrt_eigval = np.sqrt(eigval)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#corrélation des variables avec les axes\np = Z_acp.shape[1]\nk = 4\ncorvar = np.zeros((p,p))\nfor k in range(p):\n    corvar[:,k] = acp.components_[k,:] * sqrt_eigval[k]\n\n#afficher la matrice des corrélations variables x facteurs \nprint(corvar)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#on affiche pour les deux premiers axes\npd.DataFrame({'COR_1':corvar[:,0],'COR_2':corvar[:,1]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cercle des corrélations\nfig, axes = plt.subplots(figsize=(8,8))\naxes.set_xlim(-1,1)\naxes.set_ylim(-1,1)\n#affichage des étiquettes (noms des variables)\nfor j in range(p):\n    plt.annotate(df_2[df_2.columns[2:-1]].columns[j],(corvar[j,0],corvar[j,1]))\n    plt.scatter(corvar[j,0],corvar[j,1],color='blue')\n\n# ajouter les axes\nplt.plot([-1,1],[0,0],color='silver',linestyle='-',linewidth=1)\nplt.plot([0,0],[-1,1],color='silver',linestyle='-',linewidth=1)\n\n#ajouter un cercle\ncercle = plt.Circle((0,0),1,color='blue',fill=False)\naxes.add_artist(cercle)\n#affichage\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}