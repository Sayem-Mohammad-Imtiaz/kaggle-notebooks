{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style(\"darkgrid\")\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n!pip install -q tensorflow==2.0.0-alpha0\nimport tensorflow as tf\n# Load the TensorBoard notebook extension\n%load_ext tensorboard.notebook\n\n# Imports for the HParams plugin\nfrom tensorboard.plugins.hparams import api_pb2\nfrom tensorboard.plugins.hparams import summary as hparams_summary\nfrom google.protobuf import struct_pb2\n\n# Clear any logs from previous runs\n!rm -rf ./logs/ \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42bd769dfc59b208a72331cf81f7405ded932e35"},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"218b6701e2f08ae6d9f4c415e8774e63f8e5e175"},"cell_type":"markdown","source":"# Reading and analyzing the data"},{"metadata":{"trusted":true,"_uuid":"3af3beac48866c91b295f78009e898a6fcc27f99"},"cell_type":"code","source":"data=pd.read_csv(\"../input/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc34bf5573822effdefda73030caf35cb9e72c44"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d708194e043efeac1c98bb2f0c12bf06df90245"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8f34bf2b2d021cb71c5e403d10431821f66ac37"},"cell_type":"markdown","source":"All the feature columns are in numeric format. This is not the case in real world scenarios. Let's look at the statistics for each feature."},{"metadata":{"trusted":true,"_uuid":"62acaa84bf596611b3e61d3797b741b920166209"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97bfab5f4f4921b4107039f05ad6b92563292d73"},"cell_type":"code","source":"# Just to see the correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(data.corr(method='pearson'),annot=True,cmap='YlGnBu',fmt='.2f',linewidths=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f905ca5bc128cebf25380fd06a6072838a109835"},"cell_type":"code","source":"# A utility method to create a tf.data dataset from a Pandas Dataframe\ndef df_to_dataset(dataframe, shuffle=True, batch_size=32):\n  dataframe = dataframe.copy()\n  labels = dataframe.pop('target')\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa8604707f538f91b0c448fb6d86f1a66da1485e"},"cell_type":"markdown","source":"## Define Feature columns for tensorflow\nExamples of each column type"},{"metadata":{"trusted":true,"_uuid":"f7a370e06252e1fcfdadec4f4cdedd69cf1e0b7c"},"cell_type":"code","source":"feature_columns = []\n\n# numeric cols\nfor header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']:\n  feature_columns.append(tf.feature_column.numeric_column(header))\n\n# bucketized cols\nage = tf.feature_column.numeric_column(\"age\")\nage_buckets = tf.feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\nfeature_columns.append(age_buckets)\n\n# indicator cols\ndata[\"thal\"] = data[\"thal\"].apply(lambda x: str(x))\nthal = tf.feature_column.categorical_column_with_vocabulary_list(\n      'thal', ['3', '6', '7'])\nthal_one_hot = tf.feature_column.indicator_column(thal)\nfeature_columns.append(thal_one_hot)\n\ndata[\"sex\"] = data[\"sex\"].apply(str)\nsex = tf.feature_column.categorical_column_with_vocabulary_list(\n      'sex', ['0', '1'])\nsex_one_hot = tf.feature_column.indicator_column(sex)\nfeature_columns.append(sex_one_hot)\n\ndata[\"cp\"] = data[\"cp\"].apply(lambda x: str(x))\ncp = tf.feature_column.categorical_column_with_vocabulary_list(\n      'cp', ['0', '1', '2', '3'])\ncp_one_hot = tf.feature_column.indicator_column(cp)\nfeature_columns.append(cp_one_hot)\n\ndata[\"slope\"] = data[\"slope\"].apply(str)\nslope = tf.feature_column.categorical_column_with_vocabulary_list(\n      'slope', ['0', '1', '2'])\nslope_one_hot = tf.feature_column.indicator_column(slope)\nfeature_columns.append(slope_one_hot)\n\n# embedding cols\nthal_embedding = tf.feature_column.embedding_column(thal, dimension=8)\nfeature_columns.append(thal_embedding)\n\n# crossed cols\nage_thal_crossed = tf.feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\nage_thal_crossed = tf.feature_column.indicator_column(age_thal_crossed)\nfeature_columns.append(age_thal_crossed)\n\ncp_slope_crossed = tf.feature_column.crossed_column([cp, slope], hash_bucket_size=1000)\ncp_slope_crossed = tf.feature_column.indicator_column(cp_slope_crossed)\nfeature_columns.append(cp_slope_crossed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f067b02107379759633366c096de2dbf971905c"},"cell_type":"code","source":"train, test = train_test_split(data, test_size=0.2)\ntrain, val = train_test_split(train, test_size=0.2)\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')\nprint(len(test), 'test examples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37098a5b11c4ba7b817120c96dca82faaf2ed1ab"},"cell_type":"code","source":"batch_size = 32\ntrain_ds = df_to_dataset(train, batch_size=batch_size)\nval_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\ntest_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c181a9c957e661fd21c99bd837edcbc31fd3912b"},"cell_type":"markdown","source":"## Hyperparameter tuning"},{"metadata":{"trusted":true,"_uuid":"4dc7161db2c90bbe7d2fc8b8f9496746f1d96f39"},"cell_type":"code","source":"num_units_list = [128, 256]\ndropout_rate_list = [0.2, 0.5] \noptimizer_list = ['adam', 'sgd'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d9b9a0169af220a26ac68dcbbcd99afa79ede2d"},"cell_type":"code","source":"# Utility method to create summary for tensorboard\ndef create_experiment_summary(num_units_list, dropout_rate_list, optimizer_list):\n  num_units_list_val = struct_pb2.ListValue()\n  num_units_list_val.extend(num_units_list)\n  dropout_rate_list_val = struct_pb2.ListValue()\n  dropout_rate_list_val.extend(dropout_rate_list)\n  optimizer_list_val = struct_pb2.ListValue()\n  optimizer_list_val.extend(optimizer_list)\n  return hparams_summary.experiment_pb(\n      # The hyperparameters being changed\n      hparam_infos=[\n          api_pb2.HParamInfo(name='num_units',\n                             display_name='Number of units',\n                             type=api_pb2.DATA_TYPE_FLOAT64,\n                             domain_discrete=num_units_list_val),\n          api_pb2.HParamInfo(name='dropout_rate',\n                             display_name='Dropout rate',\n                             type=api_pb2.DATA_TYPE_FLOAT64,\n                             domain_discrete=dropout_rate_list_val),\n          api_pb2.HParamInfo(name='optimizer',\n                             display_name='Optimizer',\n                             type=api_pb2.DATA_TYPE_STRING,\n                             domain_discrete=optimizer_list_val)\n      ],\n      # The metrics being tracked\n      metric_infos=[\n          api_pb2.MetricInfo(\n              name=api_pb2.MetricName(\n                  tag='accuracy'),\n              display_name='Accuracy'),\n      ]\n  )\n\nexp_summary = create_experiment_summary(num_units_list, dropout_rate_list, optimizer_list)\nroot_logdir_writer = tf.summary.create_file_writer(\"logs/hparam_tuning\")\nwith root_logdir_writer.as_default():\n  tf.summary.import_event(tf.compat.v1.Event(summary=exp_summary).SerializeToString())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"419cd0e556391f1190fdf354f17e4057b06ecac4"},"cell_type":"code","source":"# Model compiler\ndef train_test_model(hparams):\n\n  model = tf.keras.models.Sequential([\n    tf.keras.layers.DenseFeatures(feature_columns),\n    tf.keras.layers.Dense(hparams['num_units'], activation='relu'),\n    tf.keras.layers.Dropout(hparams['dropout_rate']),\n      tf.keras.layers.Dense(hparams['num_units'], activation='relu'),\n    tf.keras.layers.Dense(2, activation='sigmoid')\n  ])\n  model.compile(optimizer=hparams['optimizer'],\n                loss='binary_crossentropy',\n                metrics=['accuracy'])\n\n  model.fit(train_ds, \n            validation_data=val_ds, \n            epochs=50,\n            use_multiprocessing=True,)\n  _, accuracy = model.evaluate(test_ds)\n  return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fab5c9d27442abeee64e0024983055337101815d"},"cell_type":"code","source":"# Model runner\ndef run(run_dir, hparams):\n  writer = tf.summary.create_file_writer(run_dir)\n  summary_start = hparams_summary.session_start_pb(hparams=hparams)\n\n  with writer.as_default():\n    accuracy = train_test_model(hparams)\n    summary_end = hparams_summary.session_end_pb(api_pb2.STATUS_SUCCESS)\n      \n    tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")\n    tf.summary.import_event(tf.compat.v1.Event(summary=summary_start).SerializeToString())\n    tf.summary.import_event(tf.compat.v1.Event(summary=summary_end).SerializeToString())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b691525b38d7e47d7a9149bb6f565b4ee66a1fa"},"cell_type":"code","source":"session_num = 0\n\nfor num_units in num_units_list:\n  for dropout_rate in dropout_rate_list:\n    for optimizer in optimizer_list:\n      hparams = {'num_units': num_units, 'dropout_rate': dropout_rate, 'optimizer': optimizer}\n      print('--- Running training session %d' % (session_num + 1))\n      print(hparams)\n      run_name = \"run-%d\" % session_num\n      run(\"logs/hparam_tuning/\" + run_name, hparams)\n      session_num += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0611fc92f4941c4c46189c75825b51ae6613e92"},"cell_type":"markdown","source":"# In TnesorFlow 2.0 they included the capabiluity to run tensorboard directly inside notebooks. This is working on local jupyter but not here. Hope kaggle fixes this and update"},{"metadata":{"trusted":true,"_uuid":"5f778ea9f6d0ea090fd414fb1c417b27ea475afb"},"cell_type":"code","source":"# %tensorboard --logdir logs/hparam_tuning","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}