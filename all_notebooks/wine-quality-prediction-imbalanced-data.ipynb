{"cells":[{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Necessary Libraries</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.transforms as transforms\nimport seaborn as sns\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Data Analysis and Visualizations*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Let's check if there are null values or not.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">There is no any null value.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.countplot(df[\"quality\"], palette=\"Oranges\")\nplt.title(\"Distribution of Wine Qualities\", size=28, fontweight=\"bold\")\nplt.xlabel(\"Quality\", size=18, fontweight=\"bold\")\nplt.ylabel(\"Count\", size=18, fontweight=\"bold\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.distplot(df['quality'], color=\"red\")\nplt.xlabel(\"Quality\", size=18, fontweight=\"bold\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_alcohol_list = []\nmean_ph_list = []\nmean_density_list = []\nmean_residual_sugar_list = []\n\nquality_list = df.quality.unique()\nquality_list.sort()\nfor i in quality_list:\n    df_quality = df[df[\"quality\"]==int(i)]\n    mean_alcohol = df_quality[\"alcohol\"].mean()\n    mean_ph = df_quality[\"pH\"].mean()\n    mean_density = df_quality[\"density\"].mean()\n    mean_residual_sugar = df_quality[\"residual sugar\"].mean()\n    \n    mean_alcohol_list.append(mean_alcohol)\n    mean_ph_list.append(mean_ph)\n    mean_density_list.append(mean_density)\n    mean_residual_sugar_list.append(mean_residual_sugar)\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(26,12))\nax1.bar(quality_list, mean_alcohol_list, color = \"#ECC679\")\nax1.set_title(\"Average Alcohol Values of Qualities \", size=20)\nax1.set_xlabel(\"Quality\", size=13)\nax1.set_ylabel(\"Alcohol\", size=13)\nax2.bar(quality_list, mean_ph_list, color = \"skyblue\")\nax2.set_title(\"Average pH Values of Qualities \", size=20)\nax2.set_xlabel(\"Quality\", size=13)\nax2.set_ylabel(\"pH\", size=13)\nax2.set_ylim([3,3.5])\nax3.bar(quality_list, mean_density_list, color = \"green\")\nax3.set_title(\"Average Density Values of Qualities \", size=20)\nax3.set_xlabel(\"Quality\", size=13)\nax3.set_ylabel(\"Density\", size=13)\nax3.set_ylim([0.99,1.0])\nax4.bar(quality_list, mean_residual_sugar_list, color = \"gray\")\nax4.set_title(\"Average Residual Sugar Values of Qualities \", size=20)\nax4.set_xlabel(\"Quality\", size=13)\nax4.set_ylabel(\"Residual Sugar\", size=13)\nax4.set_ylim([1.5,3])\nplt.tight_layout(pad=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Correlation Matrix*"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Let's take a glance at the correlation matrix to understand the relations between feature columns and target column.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ndf_corr = df.corr()\nsns.heatmap(df_corr, annot=True, cmap=\"GnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:DodgerBlue;\"><u><b>Some Positive Correlations</b></u> <p>\n<p style=\"color:Tomato;\">1-Fixed Acidity and Citric Acid</p>\n<p style=\"color:Tomato;\">2-Fixed Acidity and Density</p>\n<p style=\"color:Tomato;\">3-Total Sulfur Dioxide and Free Sulfur Dioxide</p>\n\n<p style=\"color:DodgerBlue;\"><u><b>Some Negative Correlations</b></u> <p>\n<p style=\"color:Tomato;\">1-pH and Fixed Acidity</p>\n<p style=\"color:Tomato;\">2-pH and Citric Acid</p>\n<p style=\"color:Tomato;\">3-Citric Acid and Volatile Acidity</p>\n<p style=\"color:Tomato;\">4-Alcohol and Density</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"for quality in df.quality:\n    if quality < 6.5:\n        df['quality'] = df['quality'].replace([int(quality)],'Bad')\n    else:\n        df['quality'] = df['quality'].replace([int(quality)],'Good')\nplt.figure(figsize = (16,8))\nlabels = df[\"quality\"].unique().tolist()\nsizes = df[\"quality\"].value_counts().tolist()\ncolors = [\"#59CBC0\", \"#BFD7D4\"]\nexplode = (0, 0)\nplt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90, textprops={'fontsize': 14, \"fontweight\" : \"bold\"}, colors=colors)\nplt.title(\"Distribution of Wines\", size=28, fontweight=\"bold\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">As it is seen on the pie chart. We have 86.4% bad quality wines and 13.6% good quality wines which is highly imbalanced. It may affect performances of our models.</p>\n<p style=\"color:Tomato;\">Let's arrange the data!</p>"},{"metadata":{},"cell_type":"markdown","source":"# *Data Preparation*"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Encoding and Normalization</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"recall_score_dict = {}\nacc_score_dict = {}\nprecision_score_dict = {}\n\nle = LabelEncoder()\ndf[\"quality\"] = le.fit_transform(df[\"quality\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.drop(\"quality\", axis=1)\ny = df[\"quality\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = StandardScaler()\nx = ss.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Splitting dataset</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Classification*"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">We know that we are dealing with an imbalanced dataset. But, before applying a method to handle with imbalanced dataset, let's see a bad model at first.</p>"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:DodgerBlue;\">Logistic Regression</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_lr = lr.predict(X_test)\nprint(\"Accuracy Score :\",lr.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Score is 86.45%. Not bad! But, only the accuracy score makes a model nice?</p>\n<p style=\"color:Tomato;\">Let's take a look at the confusion matrix!</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_lr = confusion_matrix(y_test, y_predict_lr)\nplt.figure(figsize=(10,6))\nsns.heatmap(cm_lr, annot=True, cmap=\"Blues\", fmt=\".1f\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Even though, the accuracy score is high, the model is very bad at identifying of \"1\" values which are good quality wines.</p>\n<p style=\"color:Tomato;\">Let's check recall.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_predict_lr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">As we expected, recall score is very low at identifying good quality wines.</p>\n<p style=\"color:Tomato;\">That's not a good model due to imbalanced target values. Let's try to improve it!</p>"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Apply SMOTE method to handle with imbalanced target values.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=42)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train)\nprint(\"Quality Distribution Before SMOTE Operation : \\n\", y_train.value_counts(), \"\\n\")\nprint(\"Quality Distribution After SMOTE Operation : \\n\" ,y_train_res.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ncolors = [\"#59CBC0\", \"#BFD7D4\"]\nlabels = [\"Bad\", \"Good\"]\ny_train_res.value_counts().plot(kind=\"pie\",shadow=True, autopct='%1.1f%%', \n                                textprops={'fontsize': 14, \"fontweight\" : \"bold\"},\n                                colors = colors, labels=labels)\nplt.title(\"Distribution of Wine Qualities After SMOTE\", size=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">We have increased the number of good wine samples in the data. </p>\n<p style=\"color:Tomato;\">Let's apply the Logistic Regression again. </p>"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:DodgerBlue;\">Logistic Regression with SMOTE</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr2 = LogisticRegression()\nlr2.fit(X_train_res, y_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_lr2 = lr2.predict(X_test)\nacc_score_dict[\"LR\"] = lr2.score(X_test, y_test)\nrecall_score_dict[\"LR\"] =recall_score(y_test, y_predict_lr2)\nprecision_score_dict[\"LR\"] = precision_score(y_test, y_predict_lr2)\nprint(\"Accuracy Score :\",lr2.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_lr2 = confusion_matrix(y_test, y_predict_lr2)\nplt.figure(figsize=(10,6))\nsns.heatmap(cm_lr2, annot=True, cmap=\"Blues\", fmt=\".1f\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_predict_lr2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Accuracy score has been decreased from 86.45% to 80.41% but, the model is better at identifying good quality wines. </p>"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Let's check CV score as well.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV Score : \", cross_val_score(estimator=lr2, X = X_train_res, y = y_train_res, cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Now, let's try other machine learning algorithms with SMOTE to compare results. </p>"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:DodgerBlue;\">Decision Tree Classifier</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc = DecisionTreeClassifier(criterion = 'gini', min_samples_split = 10, random_state=42)\ndtc.fit(X_train_res, y_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_dtc = dtc.predict(X_test)\nacc_score_dict[\"DTC\"] = dtc.score(X_test, y_test)\nrecall_score_dict[\"DTC\"] = recall_score(y_test, y_predict_dtc)\nprecision_score_dict[\"DTC\"] = precision_score(y_test, y_predict_dtc)\nprint(\"Accuracy Score :\",dtc.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_dtc = confusion_matrix(y_test, y_predict_dtc)\nplt.figure(figsize=(10,6))\nsns.heatmap(cm_dtc, annot=True, cmap=\"Blues\", fmt=\".1f\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_predict_dtc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV Score : \", cross_val_score(estimator=dtc, X = X_train_res, y = y_train_res, cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:DodgerBlue;\">Random Forest Classifier</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=10)\nrfc.fit(X_train_res, y_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_rfc = rfc.predict(X_test)\nacc_score_dict[\"RFC\"] = rfc.score(X_test, y_test)\nrecall_score_dict[\"RFC\"] =recall_score(y_test, y_predict_rfc)\nprecision_score_dict[\"RFC\"] = precision_score(y_test, y_predict_rfc)\nprint(\"Accuracy Score :\",rfc.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_rfc = confusion_matrix(y_test, y_predict_rfc)\nplt.figure(figsize=(10,6))\nsns.heatmap(cm_rfc, annot=True, cmap=\"Blues\",fmt=\".1f\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_predict_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV Score : \", cross_val_score(estimator=rfc, X = X_train_res, y = y_train_res, cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:DodgerBlue;\">SVM</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(probability=True)\nsvm.fit(X_train_res, y_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_svm = svm.predict(X_test)\nacc_score_dict[\"SVM\"] = svm.score(X_test, y_test)\nrecall_score_dict[\"SVM\"] =recall_score(y_test, y_predict_svm)\nprecision_score_dict[\"SVM\"] = precision_score(y_test, y_predict_svm)\nprint(\"Accuracy Score :\",svm.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_svm = confusion_matrix(y_test, y_predict_svm)\nplt.figure(figsize=(10,6))\nsns.heatmap(cm_svm, annot=True, cmap=\"Blues\",fmt=\".1f\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_predict_svm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV Score : \", cross_val_score(estimator=svm, X = X_train_res, y = y_train_res, cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Comparison*"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Let's visualize the accuracy and recall scores to distinguish better. </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Scores for Each Model After SMOTE: \",acc_score_dict)\nprint(\"Recall Scores for Each Model After SMOTE: \",recall_score_dict)\nprint(\"Precision Scores for Each Model After SMOTE: \",precision_score_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = acc_score_dict.keys()\nacc_scores = acc_score_dict.values()\nrecall_scores = recall_score_dict.values()\nprecision_scores = precision_score_dict.values()\n\nx = np.arange(len(labels))\nwidth = 0.30\n\nfig, ax = plt.subplots(figsize=(16,8))\nrects1 = ax.bar(x - width, acc_scores, width, label='Accuracy', color=\"#056937\")\nrects2 = ax.bar(x, recall_scores, width, label='Recall', color=\"#062D5F\")\nrects3 = ax.bar(x + width, precision_scores, width, label='Precision', color=\"#AE4D4D\")\n\nax.set_xlabel('Model', fontsize=15)\nax.set_ylabel('Score', fontsize=15)\nax.set_title('Comparison of Accuracy, Recall and Precision Scores of Models', fontsize=22, fontweight=\"bold\", fontstyle=\"italic\")\nax.set_xticks(x)\nax.set_xticklabels(labels)\nplt.ylim([0,1])\nplt.xticks(fontsize=16)\nlegend = ax.legend(bbox_to_anchor=(1, 1), loc='upper left',prop={\"size\":18})\nlegend.set_title('Score',prop={'size':20})\n\nfor i, v in enumerate(acc_score_dict.values()):\n    plt.text(i-0.43, v+0.025, \"{:.4f}\".format(v), color='#056937', va='center', fontweight='bold', size=14)\nfor i, v in enumerate(recall_score_dict.values()):\n    plt.text(i-0.12, v+0.025, \"{:.4f}\".format(v), color='#062D5F', va='center', fontweight='bold',size=14)\nfor i, v in enumerate(precision_score_dict.values()):\n    plt.text(i+0.17, v+0.025, \"{:.4f}\".format(v), color='#AE4D4D', va='center', fontweight='bold',size=14)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"color:DodgerBlue;\">ROC Curves and AUCs</h2>"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"color:Tomato;\">Let's check the ROC curves and AUCs for each model. Higher the AUC, better the model is at predicting good wines as good wines and bad wines as bad wines. </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_lr = lr2.predict_proba(X_test)[:,1]\nprob_dtc = dtc.predict_proba(X_test)[:,1]\nprob_rfc = rfc.predict_proba(X_test)[:,1]\nprob_svm = svm.predict_proba(X_test)[:,1]\n\nprob_dict = {\"ROC LR\": prob_lr, \"ROC DTC\": prob_dtc, \"ROC RFC\": prob_rfc, \"ROC SVM\": prob_svm}\n\nfor model, prob in prob_dict.items():\n    fpr, tpr, threshold = metrics.roc_curve(y_test, prob)\n    roc_auc = metrics.auc(fpr, tpr)\n    plt.figure(figsize=(10,6))\n    plt.plot(fpr, tpr, color = \"b\", label = \"AUC = %0.2f\" %roc_auc)\n    plt.legend(loc=\"lower right\", prop={\"size\":15})\n    plt.xlabel(\"False Positive Rate\", size=12)\n    plt.ylabel(\"True Positive Rate\", size=12)\n    plt.plot([0,1], [0,1], \"r--\")\n    plt.title(str(model), size=20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}