{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import required libraries\n\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns # data visualization\n\nimport warnings # Warnings\nwarnings.filterwarnings('ignore') # Ignore warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Embed static images in notebook\n%matplotlib inline\n\n# Show upto 150 rows and columns in a DataFrame\npd.set_option('display.max_columns', 150)\npd.set_option('display.max_rows', 150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read the Data files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detecting the encoding of the files to be imported\n\nimport chardet\n\ndef find_encoding(fname):\n    r_file = open(fname, 'rb').read()\n    result = chardet.detect(r_file)\n    charenc = result['encoding']\n    return charenc\n\nprint(\"Encoding of the application_data file: \" + find_encoding('/kaggle/input/bank-loans-dataset/application_data.csv'))\nprint(\"Encoding of the previous_application file: \" + find_encoding('/kaggle/input/bank-loans-dataset/previous_application.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, both the files are encoded as 'ascii'. Let's import the files now."},{"metadata":{},"cell_type":"markdown","source":"Most of the times, you will not need to check the encoding of the data files. But, it is a good practice to check it to avoid any errors due to reading the files with the wrong encoding."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Time to read the files\n\napplication_data = pd.read_csv('/kaggle/input/bank-loans-dataset/application_data.csv', encoding = 'ascii')\nprev_application = pd.read_csv('/kaggle/input/bank-loans-dataset/previous_application.csv', encoding = 'ascii')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Application Data contains the information about the loan and applicant at the time of the application of the loan. <br>\nPrevious Application Data contains the Application Data for the client's previous loan application. It has one row per previous application."},{"metadata":{},"cell_type":"markdown","source":"## Data Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shape of the dataframes\n\nprint('Application Data: ', application_data.shape)\nprint('Previous Application Data: ', prev_application.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Snapshots of the datasets\n\napplication_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev_application.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical summary of application data\n\napplication_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".describe gives us the statistical summary of the numerical variables only. However, if we want to also include the categorical variables, we can set the parameter include = 'all'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical summary of application data\n\napplication_data.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical summary of Previous Application Data\n\nprev_application.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treating missing values and removing irrelevant variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get percentage of missing data for each column and save it in another DataFrame\n\napp_data_missing = pd.DataFrame(100*application_data.isnull().sum()/application_data.shape[0]).reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we have a large number of variables, let's first visualize the missing values in a chart."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a chart for missing values\n\nplt.figure(figsize = (20,5))\nplt.plot(app_data_missing['index'], app_data_missing[0])\nplt.xticks(rotation = 90, fontsize = 8)\nplt.title('Percentage of missing values in each column of Application Data', fontsize = 14)\nplt.xlabel('Columns / Variables', fontsize = 10)\nplt.ylabel('Percentage Missing', fontsize = 10)\nplt.grid(b = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that many of the variables have a high percentage of missing values."},{"metadata":{},"cell_type":"markdown","source":"Let us create a DataFrame of the columns that have more than 45% values as missing."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Storing the variables having >45% missing values in a list\n\nmiss_cols = list(app_data_missing.loc[app_data_missing[0] > 45, 'index'])\nlen(miss_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can remove these 49 columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the high missing columns\n\napplication_data.drop(miss_cols, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the shape of application data again\n\napplication_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's start by first identifying the unnecessary columns based on our understanding from the columns_description file.<br>\n\nThe columns *FLAG_WORK_PHONE* and *FLAG_PHONE* both contain the information on whether the client provided home phone or not. Since, work phone information is captured in the *FLAG_EMP_PHONE* variable, we can remove the *FLAG_WORK_PHONE* variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping FLAG_WORK_PHONE variable\n\napplication_data.drop('FLAG_WORK_PHONE', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we also do not have any context on what the variables *EXT_SOURCE_2* and *EXT_SOURCE_3* mean and how they relate to whether the client is more probable to default or not, we can remove these columns too."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping EXT_SOURCE_2, EXT_SOURCE_3 variables\n\napplication_data.drop(['EXT_SOURCE_2', 'EXT_SOURCE_3'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The column *NAME_TYPE_SUITE* which indicates who was accompanying the client while applying for the loan has no relation with whether the client will default or not, we can remove this column too. <br>\nSimilarly, the columns *WEEKDAY_APPR_PROCESS_START*, *HOUR_APPR_PROCESS_START*, *REG_REGION_NOT_LIVE_REGION*, *REG_REGION_NOT_WORK_REGION*, *LIVE_REGION_NOT_WORK_REGION*, *REG_CITY_NOT_LIVE_CITY*, *REG_CITY_NOT_WORK_CITY*, *LIVE_CITY_NOT_WORK_CITY* can also be removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing unnecessary columns\n\napplication_data.drop(['NAME_TYPE_SUITE', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, the columns of document flags are not individually important as we have no information about which document is being referred to. But, they can be a good indicator at an **aggregate** level. So, we can create another column *NUM_DOCS_ADDED* as the number of documents submitted."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the NUM_DOCS_ADDED Column\n\napplication_data['NUM_DOCS_ADDED'] = application_data['FLAG_DOCUMENT_2'] + application_data['FLAG_DOCUMENT_3'] + application_data['FLAG_DOCUMENT_4'] + application_data['FLAG_DOCUMENT_5'] + application_data['FLAG_DOCUMENT_6'] + application_data['FLAG_DOCUMENT_7'] + application_data['FLAG_DOCUMENT_8'] + application_data['FLAG_DOCUMENT_9'] + application_data['FLAG_DOCUMENT_10'] + application_data['FLAG_DOCUMENT_11'] + application_data['FLAG_DOCUMENT_12'] + application_data['FLAG_DOCUMENT_13'] + application_data['FLAG_DOCUMENT_14'] + application_data['FLAG_DOCUMENT_15'] + application_data['FLAG_DOCUMENT_16'] + application_data['FLAG_DOCUMENT_17'] + application_data['FLAG_DOCUMENT_18'] + application_data['FLAG_DOCUMENT_19'] + application_data['FLAG_DOCUMENT_20'] + application_data['FLAG_DOCUMENT_21']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can **remove the Document flag variables**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing Document flag variables\n\napplication_data.drop(['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Updated shape of Application Data\n\napplication_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We only have 42 columns now."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print percentage missing values of each column\n\nprint(100*application_data.isnull().sum()/application_data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The percentage of missing values for columns *AMT_ANNUITY*, *AMT_GOODS_PRICE*, *OBS_30_CNT_SOCIAL_CIRCLE*, *DEF_30_CNT_SOCIAL_CIRCLE*, *OBS_60_CNT_SOCIAL_CIRCLE*, *DEF_60_CNT_SOCIAL_CIRCLE*, *DAYS_LAST_PHONE_CHANGE* is very less. So, we can **remove these missing rows**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing missing values for AMT_ANNUITY\napp_data_1 = application_data[~application_data['AMT_ANNUITY'].isnull()].copy()\n\n# Removing missing values for AMT_GOODS_PRICE\napp_data_2 = app_data_1[~app_data_1['AMT_GOODS_PRICE'].isnull()].copy()\n\n# Removing missing values for OBS_30_CNT_SOCIAL_CIRCLE\napp_data_3 = app_data_2[~app_data_2['OBS_30_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for DEF_30_CNT_SOCIAL_CIRCLE\napp_data_4 = app_data_3[~app_data_3['DEF_30_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for OBS_60_CNT_SOCIAL_CIRCLE\napp_data_5 = app_data_4[~app_data_4['OBS_60_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for DEF_60_CNT_SOCIAL_CIRCLE\napp_data_6 = app_data_5[~app_data_5['DEF_60_CNT_SOCIAL_CIRCLE'].isnull()].copy()\n\n# Removing missing values for DAYS_LAST_PHONE_CHANGE\napp_data_7 = app_data_6[~app_data_6['DAYS_LAST_PHONE_CHANGE'].isnull()].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shape of updated DataFrame\n\napp_data_7.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have 306199 rows in the data now, ehich is around **99.57% of the original data**. So, we are good to go with this data."},{"metadata":{},"cell_type":"markdown","source":"*OCCUPATION_TYPE* column is a categorical variable, let's look at the composition of the variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of each instance of OCCUPATION_TYPE\n\n100*app_data_7['OCCUPATION_TYPE'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although Laborers make up a large percent of our data, it is not so high that we replace our missing values with it. So, let us **impute the missing values in this column with 'Unknown'**. In the machine learning model, this column, combined with *'NAME_INCOME_TYPE'* could indicate towards a person's occupation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing missing values in OCCUPATION_TYPE with 'Unknown'\n\napp_data_7['OCCUPATION_TYPE'].fillna('Unknown', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's look at *AMT_REQ_CREDIT_BUREAU* columns and how we can impute their missing values. <br>\n\nSince these columns are numeric and represent the number of queries in the Credit Bureau about the client in the specified time period, we can **use the median of each column to impute the values**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing missing values in AMT_REQ_CREDIT_BUREAU variables with the median of each column\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_HOUR'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_HOUR'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_DAY'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_DAY'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_WEEK'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_WEEK'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_MON'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_MON'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_QRT'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_QRT'].median(), inplace = True)\n\napp_data_7['AMT_REQ_CREDIT_BUREAU_YEAR'].fillna(app_data_7['AMT_REQ_CREDIT_BUREAU_YEAR'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verifying whether all missing values are treated\n\nprint(100*app_data_7.isnull().sum()/app_data_7.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All missing values of the application dataset are cealned."},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the Data types"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the dataset again\n\napp_data_7.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the columns *DAYS_BIRTH*, *DAYS_EMPLOYED*, *DAYS_REGISTRATION*, *DAYS_PUBLISH* are negative. These should be in positive years or months. Let's **convert these to years**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Negative Days to Positive Years\n\napp_data_7['DAYS_BIRTH_YRS'] = app_data_7['DAYS_BIRTH'].apply(lambda x : (-1.0)*x/365)\n\napp_data_7['DAYS_EMPLOYED_YRS'] = app_data_7['DAYS_EMPLOYED'].apply(lambda x: (-1.0)*x/365)\n\napp_data_7['DAYS_REGISTRATION_YRS'] = app_data_7['DAYS_REGISTRATION'].apply(lambda x : (-1.0)*x/365)\n\napp_data_7['DAYS_ID_PUBLISH_YRS'] = app_data_7['DAYS_ID_PUBLISH'].apply(lambda x : (-1.0)*x/365)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to drop the older Days columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop negative days columns\n\napp_data_7.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, there are no columns that are of date type in this DataFrame. We only have the age/time since documents were changed which are recorded as float. We should not convert these to DateTime type."},{"metadata":{},"cell_type":"markdown","source":"Now, let's look at some variables where the DataType is not stored correctly. <br>\nLet's look at CNT_FAM_MEMBERS which is stored as float. It should be stored as integer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert CNT_FAM_MEMBERS to int\n\napp_data_7['CNT_FAM_MEMBERS'] = app_data_7.loc[:,'CNT_FAM_MEMBERS'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Social Circle variables to int\n\napp_data_7['OBS_30_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'OBS_30_CNT_SOCIAL_CIRCLE'].astype(int)\n\napp_data_7['DEF_30_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'DEF_30_CNT_SOCIAL_CIRCLE'].astype(int)\n\napp_data_7['OBS_60_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'OBS_60_CNT_SOCIAL_CIRCLE'].astype(int)\n\napp_data_7['DEF_60_CNT_SOCIAL_CIRCLE'] = app_data_7.loc[:,'DEF_60_CNT_SOCIAL_CIRCLE'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling Outliers and Binning"},{"metadata":{},"cell_type":"markdown","source":"Now, we need to identify the outliers in our continuous variables. <br>\nFor this, we first need to identify the continuous variables in our dataset. So, let's look at the number of unique values in each variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values in each variable\n\napp_data_7.nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see here that the variables REGION_POPULATION_RELATIVE, AMT_GOODS_PRICE, AMT_INCOME_TOTAL, DAYS_LAST_PHONE_CHANGE, AMT_CREDIT, DAYS_ID_PUBLISH_YRS, DAYS_EMPLOYED_YRS, AMT_ANNUITY, DAYS_REGISTRATION_YRS and DAYS_BIRTH_YRS are continuous variables since their number of unique values is large. "},{"metadata":{},"cell_type":"markdown","source":"Let's try to find outliers in variables AMT_INCOME_TOTAL, AMT_CREDIT, DAYS_BIRTH_YRS."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plot for AMT_INCOME_TOTAL\n\nplt.figure(figsize = (18,5))\nsns.boxplot(app_data_7['AMT_INCOME_TOTAL'])\nplt.title('Box plot of AMT_INCOME_TOTAL')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical summary of AMT_INCOME_TOTAL\n\napp_data_7['AMT_INCOME_TOTAL'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that one value is way higher than all other values. We can delete this value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the outlier observation\n\napp_data_7 = app_data_7[app_data_7['AMT_INCOME_TOTAL']< app_data_7['AMT_INCOME_TOTAL'].max()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plot for AMT_INCOME_TOTAL after removing the outlier\n\nplt.figure(figsize = (18,5))\nsns.boxplot(app_data_7['AMT_INCOME_TOTAL'])\nplt.title('Box plot of AMT_INCOME_TOTAL')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can bin these values. For that, we first need to look at the distribution of the variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Applicant's income\n\nplt.figure(figsize = (18,6))\nplt.hist(app_data_7['AMT_INCOME_TOTAL'])\nplt.yscale('log')\nplt.xlabel(\"Applicant's Income\",fontsize=12)\nplt.title('Distribution of AMT_INCOME_TOTAL')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To know more, we can look at the percentile values of the Income variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Different percentiles of Income variable\n\napp_data_7['AMT_INCOME_TOTAL'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our median is just around 1.5 lakh. So, our bins have to be more dense below 1.5 lakh and sparse beyond that. Let's create these bins."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating bins for Income variable\n\napp_data_7['APPLICANT_INCOME'] = pd.cut(x=app_data_7['AMT_INCOME_TOTAL'],\n                                    bins=[0, 50000, 100000, 150000, 300000, 500000, 1000000, 2000000, 100000000],\n                                    labels=['<50k', '50k - 1lac', '1lac - 1.5lac', '1.5lac - 3lac', '3lac - 5lac', '5lac - 10lac', '10lac - 20lac', '>20lac'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the composition of our new variable APPLICANT_INCOME."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Value Counts of APPLICANT_INCOME\n\napp_data_7['APPLICANT_INCOME'].value_counts(normalize = True, sort = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's see how our DAYS_BIRTH_YRS, which represents the age of the applicant, is distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of Applicant's age\n\nplt.figure(figsize = (18,6))\nplt.hist(app_data_7['DAYS_BIRTH_YRS'])\nplt.xlabel(\"Age of Applicant\",fontsize=12)\nplt.title('Distribution of AMT_INCOME_TOTAL')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plot of DAYS_BIRTH_YRS\n\nplt.figure(figsize = (18,4))\nsns.boxplot(app_data_7['DAYS_BIRTH_YRS'])\nplt.title('Box plot of DAYS_BIRTH_YRS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, there are no outliers in the DAYS_BIRTH_YRS variable. But, we can still bin this variable as people of an age group tend to behave in a similar manner."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating bins for Applicant's age\n\napp_data_7['APPLICANT_AGE'] = pd.cut(x=app_data_7['DAYS_BIRTH_YRS'],\n                                    bins=[0, 25, 40, 60, 80],\n                                    labels=['<25 yrs', '25-40 yrs', '40-60 yrs', '>60 yrs'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the composition of the APPLICANT_AGE variable\n\n100*app_data_7['APPLICANT_AGE'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plot of AMT_CREDIT\n\nplt.figure(figsize = (18,5))\nsns.boxplot(app_data_7['AMT_CREDIT'])\nplt.title('Box plot of AMT_CREDIT')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Different percentiles of the AMT_CREDIT variable\n\napp_data_7['AMT_CREDIT'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating bins for AMT_CREDIT\n\napp_data_7['LOAN_AMOUNT'] = pd.cut(x=app_data_7['AMT_CREDIT'],\n                                    bins=[0, 250000, 500000, 750000, 1000000, 1500000, 2000000, 5000000],\n                                    labels=['<2.5lac', '2.5lac - 5lac', '5lac - 7.5lac', '7.5lac - 10lac', '10lac - 15lac', '15lac - 20lac', '>20lac'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the composition of LOAN_AMOUNT variable\n\napp_data_7['LOAN_AMOUNT'].value_counts(normalize = True, sort = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Class Imbalance"},{"metadata":{},"cell_type":"markdown","source":"We start our analysis by checking the imbalance in the data. Imbalance is the ratio of one value of Target variable vs the other."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting number of rows for TARGET values of 1 and 0\n\nprint(app_data_7['TARGET'].value_counts(normalize = True))\n\nprint(app_data_7['TARGET'].value_counts(normalize = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, imbalance for TARGET = 1 is 91.9114% and for TARGET = 0 is 8.0886%."},{"metadata":{},"cell_type":"markdown","source":"## Dividing dataset into 1 and 0"},{"metadata":{},"cell_type":"markdown","source":"Now, we will divide the dataset into two parts - One with TARGET = 0 and one with TARGET = 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating DataFrame with TARGET = 1\n\napp_data_target_1 = app_data_7.loc[app_data_7['TARGET'] == 1]\napp_data_target_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creting DataFrame with TARGET = 0\n\napp_data_target_0 = app_data_7.loc[app_data_7['TARGET'] == 0]\napp_data_target_0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confirming whether the new DataFrames have correct row counts\n\nprint(app_data_7['TARGET'].value_counts(),\"\\n\",app_data_target_0.shape[0],\"\\n\",app_data_target_1.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can confirm that the two new dataframes have correct respective TARGET value and right row count."},{"metadata":{},"cell_type":"markdown","source":"## Univariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Categorical Unordered Univariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Types\n\napp_data_target_0.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, our unordered categorical variables are NAME_CONTRACT_TYPE, CODE_GENDER, NAME_INCOME_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, OCCUPATION_TYPE, ORGANIZATION_TYPE."},{"metadata":{},"cell_type":"markdown","source":"Let's look at these one by one for both Target = 0 an Target = 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the CODE_GENDER variable\n\nplt.figure(figsize = (18,6))\nplt.title('Applicant Gender')\n\nplt.subplot(121)\nplt.title('Percentage of Male/Female for Target = 0', fontsize = 10)\nplt.xlabel('Target = 0')\nplt.ylabel('Percentage')\n(100*app_data_target_0['CODE_GENDER'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(122)\nplt.title('Percentage of Male/Female for Target = 1', fontsize = 10)\nplt.xlabel('Target = 1')\nplt.ylabel('Percentage')\n(100*app_data_target_1['CODE_GENDER'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_data_target_0['CODE_GENDER'].value_counts(normalize = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing rows with Gender as 'XNA'\n\napp_data_target_0 = app_data_target_0[~(app_data_target_0['CODE_GENDER'] == 'XNA')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the chart again\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Applicant Gender')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['CODE_GENDER'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['CODE_GENDER'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we can see that Males are more likely to default on a loan."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual values\nprint(app_data_target_0['CODE_GENDER'].value_counts(normalize = True))\nprint(app_data_target_1['CODE_GENDER'].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the NAME_CONTRACT_TYPE variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Loan Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_CONTRACT_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_CONTRACT_TYPE'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, Revolving loans are less likely to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual values\nprint(app_data_target_0['NAME_CONTRACT_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_CONTRACT_TYPE'].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting NAME_INCOME_TYPE variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Income Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_INCOME_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_INCOME_TYPE'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual values\nprint(app_data_target_0['NAME_INCOME_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_INCOME_TYPE'].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting NAME_FAMILY_STATUS variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Family Status')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_FAMILY_STATUS'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_FAMILY_STATUS'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Married people are less likely to default while Single and Civil married people are more likely to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual values\nprint(app_data_target_0['NAME_FAMILY_STATUS'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_FAMILY_STATUS'].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting NAME_HOUSING_TYPE variable\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Housing Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['NAME_HOUSING_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_HOUSING_TYPE'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People living with parents or in a rented apartment are more likely to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual values\nprint(app_data_target_0['NAME_HOUSING_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['NAME_HOUSING_TYPE'].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting OCCUPATION_TYPE variable\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('Occupation Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\n(100*app_data_target_0['OCCUPATION_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['OCCUPATION_TYPE'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Laborers, Sales staff, Drivers are more likely to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual values\nprint(app_data_target_0['OCCUPATION_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['OCCUPATION_TYPE'].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting ORGANIZATION_TYPE variable\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('Income Type')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\nplt.ylabel('Percent')\nplt.xticks(fontsize = 7)\n(100*app_data_target_0['ORGANIZATION_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\nplt.xticks(fontsize = 7)\n(100*app_data_target_1['ORGANIZATION_TYPE'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual values\nprint(app_data_target_0['ORGANIZATION_TYPE'].value_counts(normalize = True))\nprint(app_data_target_1['ORGANIZATION_TYPE'].value_counts(normalize = True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Ordered Univariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"Let's first identify the Ordered Categorical variables in our dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"app_data_target_0.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variables FLAG_OWN_CAR, FLAG_OWN_REALTY, NAME_EDUCATION_TYPE, APPLICANT_INCOME, APPLICANT_AGE, LOAN_AMOUNT are all Ordered Categorical variables. Let's look at these one by one."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the FLAG_OWN_CAR\n\nfig = plt.figure(figsize = (18,5))\nfig.suptitle('Does the Applicant own a Car?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['FLAG_OWN_CAR'].value_counts(normalize = True)).plot.pie()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['FLAG_OWN_CAR'].value_counts(normalize = True)).plot.pie()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People who do not own a car are more likely to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the FLAG_OWN_REALTY\n\nfig = plt.figure(figsize = (18,6))\nfig.suptitle('Does the Applicant own a House?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['FLAG_OWN_REALTY'].value_counts(normalize = True)).plot.pie()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['FLAG_OWN_REALTY'].value_counts(normalize = True)).plot.pie()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People who do not own a house are more likely to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the NAME_EDUCATION_TYPE\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('Education level of Applicant')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['NAME_EDUCATION_TYPE'].value_counts(normalize = True)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['NAME_EDUCATION_TYPE'].value_counts(normalize = True)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People with a higher level of education are less likely to default."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the APPLICANT_INCOME\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('What is the income of the Applicant?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['APPLICANT_INCOME'].value_counts(normalize = True, sort = False)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['APPLICANT_INCOME'].value_counts(normalize = True, sort = False)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the APPLICANT_AGE\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('What is the age of the Applicant?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['APPLICANT_AGE'].value_counts(normalize = True, sort = False)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['APPLICANT_AGE'].value_counts(normalize = True, sort = False)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the LOAN_AMOUNT\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle('What is the loan amount?')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\n(100*app_data_target_0['LOAN_AMOUNT'].value_counts(normalize = True, sort = False)).plot.bar()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\n(100*app_data_target_1['LOAN_AMOUNT'].value_counts(normalize = True, sort = False)).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numerical variables"},{"metadata":{},"cell_type":"markdown","source":"Let's see the statistical summary of our DataFrames. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical summary of Target = 0\n\napp_data_target_0.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical summary of Target = 1\n\napp_data_target_1.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's plot the box plots of the variables CNT_CHILDREN, CNT_FAM_MEMBERS, REGION_RATING_CLIENT, DEF_30_CNT_SOCIAL_CIRCLE, DEF_60_CNT_SOCIAL_CIRCLE, NUM_DOCS_ADDED, DAYS_LAST_PHONE_CHANGE."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plots of CNT_CHILDREN\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Number of Children')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['CNT_CHILDREN'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['CNT_CHILDREN'].plot.box()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plots of CNT_FAM_MEMBERS\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Number of Family Members')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['CNT_FAM_MEMBERS'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['CNT_FAM_MEMBERS'].plot.box()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plots of REGION_RATING_CLIENT\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Rating of Applicant\\'s Region')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['REGION_RATING_CLIENT'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['REGION_RATING_CLIENT'].plot.box()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plots of FLAG_OWN_CAR vs AMT_ANNUITY\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\n#plt.xlabel('Target = 0')\nsns.boxplot(x='FLAG_OWN_CAR', y='AMT_ANNUITY', data=app_data_target_0)\nplt.yscale('log')\n\nplt.subplot(ax2)\n#plt.xlabel('Target = 1')\nsns.boxplot(x='FLAG_OWN_CAR', y='AMT_ANNUITY', data=app_data_target_1)\nplt.yscale('log')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plots of APPLICANT_INCOME vs AMT_ANNUITY\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\n#plt.xlabel('Target = 0')\nsns.boxplot(x=\"APPLICANT_INCOME\", y='AMT_ANNUITY', data=app_data_target_0)\nplt.yscale('log')\n\nplt.subplot(ax2)\n#plt.xlabel('Target = 1')\nsns.boxplot(x=\"APPLICANT_INCOME\", y='AMT_ANNUITY', data=app_data_target_1)\nplt.yscale('log')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Strip Plots of AMT_GOODS PRICE vs LOAN AMOUNT\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nsns.stripplot(x='AMT_GOODS_PRICE', y=\"LOAN_AMOUNT\", data=app_data_target_0)\n\nplt.subplot(ax2)\nsns.stripplot(x='AMT_GOODS_PRICE', y=\"LOAN_AMOUNT\", data=app_data_target_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Strip plot for AMT_GOODS_PRICE vs APLICANT_INCOME\n\nfig = plt.figure(1, figsize = (18,6))\nfig.suptitle(\"Target=0 vs Target=1\")\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nsns.stripplot(x='AMT_GOODS_PRICE', y=\"APPLICANT_INCOME\", data=app_data_target_0)\n\nplt.subplot(ax2)\nsns.stripplot(x=\"AMT_GOODS_PRICE\", y=\"APPLICANT_INCOME\", data=app_data_target_1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plots of DAYS_LAST_PHONE_CHANGE\n\nfig = plt.figure(1, figsize = (18,8))\nfig.suptitle('Number of Defaults in Applicant\\'s social surroundings')\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, sharey = ax1)\n\nplt.subplot(ax1)\nplt.xlabel('Target = 0')\napp_data_target_0['DAYS_LAST_PHONE_CHANGE'].plot.box()\n\nplt.subplot(ax2)\nplt.xlabel('Target = 1')\napp_data_target_1['DAYS_LAST_PHONE_CHANGE'].plot.box()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Numeric - Numeric Analysis"},{"metadata":{},"cell_type":"markdown","source":"Let's first see which numerical columns we have."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking dtypes again\n\napp_data_target_0.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, the numerical columns are AMT_INCOME_TOTAL, AMT_CREDIT, AMT_ANNUITY, AMT_GOODS_PRICE, REGION_POPULATION_RELATIVE, AMT_REQ_CREDIT_BUREAU_WEEK, AMT_REQ_CREDIT_BUREAU_MON, AMT_REQ_CREDIT_BUREAU_YEAR, DAYS_BIRTH_YRS, DAYS_EMPLOYED_YRS, DAYS_REGISTRATION_YRS."},{"metadata":{},"cell_type":"markdown","source":"Let's look at the relation between Income and Loan amount."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data = app_data_target_0, vars = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_YEAR'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the same variables for Target = 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data = app_data_target_0, vars = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_YEAR'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data = app_data_target_1, vars = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_YEAR'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the correlation between AMT_CREDIT, AMT_ANNUITY, AMT_INCOME_TOTAL, CNT_CHILDREN, DAYS_EMPLOYED_YRS, DAYS_BIRTH_YRS"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the Correlation Matrix for Target = 0\n\ncurr_0 = app_data_target_0[['AMT_CREDIT', 'AMT_ANNUITY', 'AMT_INCOME_TOTAL', 'CNT_CHILDREN', 'DAYS_EMPLOYED_YRS', 'DAYS_BIRTH_YRS']]\n\ncor_0 = curr_0.corr()\n\nsns.heatmap(cor_0, cmap = \"YlGnBu\", annot = True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the Correlation Matrix for Target = 0\n\ncurr_1 = app_data_target_1[['AMT_CREDIT', 'AMT_ANNUITY', 'AMT_INCOME_TOTAL', 'CNT_CHILDREN', 'DAYS_EMPLOYED_YRS', 'DAYS_BIRTH_YRS']]\n\ncor_1 = curr_1.corr()\n\nsns.heatmap(cor_1, cmap = \"YlGnBu\", annot = True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA on Previous Application Data"},{"metadata":{},"cell_type":"markdown","source":"Let's repeat all the processes done with the Application Data file."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get percentage of missing data for each column and save it in another DataFrame\n\nprev_app_data_missing = pd.DataFrame(100*prev_application.isnull().sum()/prev_application.shape[0]).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating chart for missing values \n\nplt.figure(figsize = (18,5))\nplt.plot(prev_app_data_missing['index'], prev_app_data_missing[0])\nplt.xticks(rotation = 90, fontsize = 7)\nplt.title('Percentage of Missing Values in each column of Previous Application Data', fontsize = 14)\nplt.xlabel('Columns', fontsize = 10)\nplt.ylabel('Percentage Missing', fontsize = 10)\nplt.figure()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the Missing percentage values as a DataFrame\n\nprev_app_data_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the list of columns with > 45% data as missing\n\nmiss_cols_prev_app_data = list(prev_app_data_missing.loc[prev_app_data_missing[0] > 45, 'index'])\nprint(len(miss_cols_prev_app_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the columns from Application Data\n\nprev_application.drop(miss_cols_prev_app_data, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print percentage missing values of each column\n\nprint(100*prev_application.isnull().sum()/prev_application.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing missing values for PRODUCT_COMBINATION\n\nprev_app_data_1 = prev_application[~prev_application['PRODUCT_COMBINATION'].isnull()].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev_app_data_1.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This represents 99.97% of the original data."},{"metadata":{"trusted":true},"cell_type":"code","source":"prev_app_data_1['DAYS_LAST_DUE'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing missing values with median\n\nprev_app_data_1['AMT_ANNUITY'].fillna(prev_app_data_1['AMT_ANNUITY'].median(), inplace = True)\n\nprev_app_data_1['AMT_GOODS_PRICE'].fillna(prev_app_data_1['AMT_GOODS_PRICE'].median(), inplace = True)\n\nprev_app_data_1['CNT_PAYMENT'].fillna(prev_app_data_1['CNT_PAYMENT'].median(), inplace = True)\n\nprev_app_data_1['DAYS_FIRST_DRAWING'].fillna(prev_app_data_1['DAYS_FIRST_DRAWING'].median(), inplace = True)\n\nprev_app_data_1['DAYS_FIRST_DUE'].fillna(prev_app_data_1['DAYS_FIRST_DUE'].median(), inplace = True)\n\nprev_app_data_1['DAYS_LAST_DUE_1ST_VERSION'].fillna(prev_app_data_1['DAYS_LAST_DUE_1ST_VERSION'].median(), inplace = True)\n\nprev_app_data_1['DAYS_LAST_DUE'].fillna(prev_app_data_1['DAYS_LAST_DUE'].median(), inplace = True)\n\nprev_app_data_1['DAYS_TERMINATION'].fillna(prev_app_data_1['DAYS_TERMINATION'].median(), inplace = True)\n\nprev_app_data_1['NFLAG_INSURED_ON_APPROVAL'].fillna(prev_app_data_1['NFLAG_INSURED_ON_APPROVAL'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print percentage missing values of each column\n\nprint(100*prev_app_data_1.isnull().sum()/prev_app_data_1.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All missing values have been imputed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the DAYS_FIRST_DUE variable to positive years\n\nprev_app_data_1['DAYS_FIRST_DUE'] = prev_app_data_1['DAYS_FIRST_DUE'].apply(lambda x : (-1.0)*x/365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking DataTypes of Previous Application Data\n\nprev_app_data_1.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing irrelevant columns\n\nprev_app_data_1.drop(['WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'FLAG_LAST_APPL_PER_CONTRACT', 'NFLAG_LAST_APPL_IN_DAY'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Data Types of all remaining variables are correct."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values in each variable\n\nprev_app_data_1.nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plot for AMT_ANNUITY\n\nplt.figure(figsize = (18, 4))\nsns.boxplot(prev_app_data_1['AMT_ANNUITY'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Different percentiles of the AMT_ANNUITY variable\n\nprev_app_data_1['AMT_ANNUITY'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating bins for AMT_ANNUITY\n\nprev_app_data_1['LOAN_INSTALMENT'] = pd.cut(x=prev_app_data_1['AMT_ANNUITY'],\n                                    bins=[0, 5000, 10000, 20000, 30000, 40000, 50000, 500000],\n                                    labels=['<5k', '5k - 10k', '10k - 20k', '20k - 30k', '30k - 40k', '40k - 50k', '>50k'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev_app_data_1.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.stripplot(x='DAYS_TERMINATION', y=\"NAME_CONTRACT_STATUS\", data=prev_app_data_1)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.suptitle(\"Amount of Loan asked Vs Contract Status\")\nsns.stripplot(x='AMT_APPLICATION', y=\"NAME_CONTRACT_STATUS\", data=prev_app_data_1)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.suptitle(\"when was the decision about previous application made Vs Contract Status\")\nsns.stripplot(x= \"DAYS_DECISION\", y=\"NAME_CONTRACT_STATUS\", data=prev_app_data_1)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev_app_data_1.NAME_CONTRACT_STATUS.value_counts(normalize=True).plot.barh()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev_app_data_1.NAME_PORTFOLIO.value_counts(normalize=True).plot.barh()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}