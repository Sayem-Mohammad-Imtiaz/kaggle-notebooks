{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n<p>Welcome! In this notebook i'm going to analyze credit card's customers data and implement a Machine Learning Classfier to predict the attrition probabilty of customers</p>\n<h3>My main objectives on this project are:</h3>   \n<ul>\n    <li>Applying exploratory data analysis and trying to get some insights about our dataset</li>\n    <li>Getting data in better shape by transforming and feature engineering to help us in building better models</li>\n    <li>Building and tuning different ML algorithms to get some results on predicting Attrition</li>\n</ul>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Importing Libraries</h2>\n<p>Lets start by importing some packages we are going to need</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Meeting the data\n<p>Lets open the data and see what we have</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Opening the data\ndata = pd.read_csv('../input/credit-card-customers/BankChurners.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see the shapes of the data so we know what we are dealing with\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets observe some of his elements\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets delete the last two columns as they are irrelevant\ndata.drop(columns=[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\",\n                  \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"],\n         inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividing the label and features columns in X, y and then eliminating ids as they are irrelevants for the analysis and modeling\nX = data.copy()\nX.drop(columns=['CLIENTNUM', 'Attrition_Flag'], inplace=True)\ny = data['Attrition_Flag']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using a label binarizer to convert y label into 1's and 0's\nlabelBinarizer = LabelBinarizer()\ny = labelBinarizer.fit_transform(y)\ny = np.reshape(y, -1)\ny = pd.Series(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n<p>Exploratory Data Analysis</p>\n\n<p>Lets create a heatmap graphic here. With this graphic we can see the correlation between different features</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For this purpose, i'll concatenate y and X\nanalysisData = X.copy()\nanalysisData['Attrition_Flag'] = y\ncorrelation = analysisData.corr()\n\nf, ax = plt.subplots(figsize=(14,12))\nplt.title('Correlation of numerical attributes', size=16)\nsns.heatmap(correlation)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Observations</h4>\n<li>Let's focus on the lighter parts of the graph</li>\n<ol>\n    <li>Customer age and Months on book have a high correlation because these customers just got the possibility of getting a credit card</li>\n    <li>Avg_Open_To_Buy and Credit_Limit have a high correlation because they are telling the \"same thing\"</li>\n    <li>Total Transaction Amount is high correlated with Total Transacion Count because usually the amount tends to get higher as the count of transactions grow</li>\n</ol>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To be clearer, let's take a look at a simple plot Total_Trans_Amt in function of Total_Trans_Ct\n\namount = analysisData['Total_Trans_Amt']\ncount = analysisData['Total_Trans_Ct']\n\nfig, ax = plt.subplots()\nax.plot(count, amount)\n\nax.set(xlabel='Number of transactions', ylabel='Total amount of transactions',\n       title='Transactions total amount in function of the number of transactions')\nax.grid()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see the variability and some other statistics of categorical columns\ncat_columns = X.select_dtypes(include=['object']).columns\nfor col in cat_columns:\n    print(X[col].value_counts(ascending=True, normalize=True))\n    print(X[col].describe())\n    print(\"---------------------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Data\n<ul>\n    <li>Lets see if there any missing values and visualize them</li>\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<li>Luckily we don't have any missing values, so we can proceed with modeling</li>"},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing + Pipeline\n<li>First, lets split the data into train and test dataframes</li>\n<p>Pipeline Steps:</p>\n<ol>\n    <li>One Hot Encoding</li>\n    <li>Quantile Proccesing</li>\n    <li>Fit the model</li>\n</ol>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier(colsample_bytree= 0.7, learning_rate= 0.07, max_depth=7, min_child_weight=4,\n                  n_estimators = 500, nthread=4, objective= 'reg:linear', subsample= 0.7, tree_method='gpu_hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import QuantileTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catTransformer = ColumnTransformer([('encoder', OneHotEncoder(), cat_columns)], remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\nmodel_pipeline = Pipeline(steps=[\n                                ('One Hot Encoding', catTransformer),\n                                ('Quantile_Proccesing', QuantileTransformer(n_quantiles=10, random_state=0)),\n                                ('XGBoost', xgb)\n                                ])\nmodel_pipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy Metrics\nfrom sklearn.metrics import accuracy_score\n\ny_pred = model_pipeline.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# End\n<p>Thanks for going all the way down through my notebook! I hope you were able to get something usefull from this. Feel free to ask your questions and use my code</p>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}