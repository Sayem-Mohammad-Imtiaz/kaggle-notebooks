{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Building Machine Learning Pipelines: Data Analysis Phase"},{"metadata":{},"cell_type":"markdown","source":"## Kaggle Project: House Prices: Advanced Regression Techniques\n\nThe main aim of this project is to predict the house price based on various features which we will discuss as we go ahead\n\nYou can have a look at the project description and the data from below link\n\nhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques"},{"metadata":{},"cell_type":"markdown","source":"## Lifecycle or a Pipeline of a Data Science Projects\n1. Data Analysis\n2. Feature Engineering\n3. Feature Selection\n4. Model Building\n5. Model Deployment"},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis\n\nIn this part 1 of the notebook, we will look at the various steps invloved in Data Analysis Phase where we involve more with the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n## Display all the columns of the dataframe\npd.pandas.set_option('display.max_columns',None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv('../input/advance-house-price-predicitons/train.csv')\n\n## print shape of dataset with rows and columns\nprint(df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## print the top5 records\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### In Data Analysis involves finding out the below steps and analysing them\n1. Missing Values\n2. All The Numerical Variables\n3. Distribution of the Numerical Variables\n4. Categorical Variables\n5. Cardinality of Categorical Variables\n6. Outliers\n7. Relationship between independent and dependent feature(SalePrice)\n"},{"metadata":{},"cell_type":"markdown","source":"## Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we will check the percentage of nan values present in each feature\n# 1. Get the list of features which has missing values\nnull_features = [ features \n                  for features in df_train.columns \n                      if df_train[features].isnull().sum()>1 ]\n\n# 2. Print the feature name and the percentage of missing values\ndf_train_missing = pd.DataFrame(np.round(df_train[null_features].isnull().mean(), 4),\n                                columns=['% missing values'])\ndf_train_missing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation:\n\nThe columns Alley,PoolQC,Fence and MiscFeature have more than 80% of missing values,Now lets see whether there is a relationship between missing values and the target feature(SalesPrice) by plotting them"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in null_features:\n    df_train_tmp = df_train.copy()\n    \n    # let's convert all the Nan values to 1, otherwise zero for easy plotting the relationship with the SalesPrice\n    df_train_tmp[feature] = np.where(df_train_tmp[feature].isnull(), 1, 0)\n    \n    # let's calculate the mean SalePrice where the information is missing or present\n    df_train_tmp.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation\nHere With  the relation between the missing values and the dependent variable is clearly evident.We cannot remove these rows where NaN values are present as there is a dependency, so we have to replace these NaN values with something meaningful which we will do in the Feature Engineering section"},{"metadata":{},"cell_type":"markdown","source":"### Styling using pandas\n\nhttps://kanoki.org/2019/01/02/pandas-trick-for-the-day-color-code-columns-rows-cells-of-dataframe/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Highlight the entire row in Yellow where Column B value is greater than 1\n# np.random.seed(24)\n# df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n \n# df = pd.concat([df, pd.DataFrame(np.random.randn(10, 4), columns=list('BCDE'))],\n#                axis=1)\n# df.iloc[0, 2] = np.nan\n \n# def highlight_greaterthan(s,column):\n#     is_max = pd.Series(data=False, index=s.index)\n#     is_max[column] = s.loc[column] >= 1\n#     return ['background-color: red' if is_max.any() else '' for v in is_max]\n \n# def highlight_greaterthan_1(s):\n#     if s.B > 1.0:\n#         return ['background-color: yellow']*5\n#     else:\n#         return ['background-color: white']*5\n \n # df.style.apply(highlight_greaterthan_1, axis=1)\n\n\n# # Color code the text having values less than zero in a row\n# def color_negative_red(val):\n#     color = 'red' if val &lt; 0 else 'black'  # here &lt corresponds to '<' and &gt for '>' is used html\n#     return 'color: %s' % color\n\n# df.style.applymap(color_negative_red)\n\n\n# # Highlight the Specific Values or Cells\n# import pandas as pd\n# import numpy as np\n\n# def highlight_max(s):    \n#     is_max = s == s.max()\n#     return ['background-color: red' if v else '' for v in is_max]\n\n# df.style.apply(highlight_max)\n\n\n# # Highlight all Nulls in My data\n# df.style.highlight_null(null_color='green')\n\n# # Styler.set_properties\n# df.style.set_properties(**{'background-color': 'black',\n#                             'color': 'lawngreen',\n#                             'border-color': 'white'})\n\n# # Bar charts in DataFrame\n# df.style.bar(subset=['A', 'B'], color='#d65f5f')\n\n# # Table style\n# from IPython.display import HTML\n\n# def hover(hover_color=\"#ffff99\"):\n#     return dict(selector=\"tr:hover\",\n#                 props=[(\"background-color\", \"%s\" % hover_color)])\n\n# styles = [\n#     hover(),\n#     dict(selector=\"th\", props=[(\"font-size\", \"150%\"),\n#                                (\"text-align\", \"center\")]),\n#     dict(selector=\"caption\", props=[(\"caption-side\", \"bottom\")])\n# ]\n# html = (df.style.set_table_styles(styles)\n#           .set_caption(\"Hover to highlight.\"))\n# html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_html = df_train.head().copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\n\ndef hover(hover_color=\"#ffff99\"):\n    return dict(selector=\"tr:hover\",\n                props=[(\"background-color\", \"%s\" % hover_color)])\n\nstyles = [\n    hover(),\n    dict(selector=\"th\", props=[(\"font-size\", \"150%\"),\n                               (\"text-align\", \"center\")]),\n    dict(selector=\"caption\", props=[(\"caption-side\", \"bottom\")])\n]\nhtml = (df_train_html.style.set_table_styles(styles)\n          .set_caption(\"Hover to highlight.\"))\nhtml","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numerical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see the data types present in our dataset\ndf_train.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here data type 'O' represents Object which includes categorical variables,\n# Get the list of numerical variables\nnumerical_features = [feature \n                          for feature in df_train.columns \n                              if df_train[feature].dtypes != 'O']\n\nprint('Number of numerical variables: ', len(numerical_features))\n\n# visualise the numerical variables\ndf_train[numerical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def color_negative_red(col):\n    col1 = col\n    color = 'green' if 'Yr' in col1 or 'Year'in col1 else 'black'  # here &lt corresponds to '<' and &gt for '>' is used html\n    return 'color: %s' % color\n\npd.DataFrame(df_train.columns).style.applymap(color_negative_red)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that there are columns(marked in ***green***) which consists of date, lets convert those columns to date data type"},{"metadata":{},"cell_type":"markdown","source":"#### Temporal Variables(Eg: Datetime Variables)\n\nFrom the Dataset we have 4 year variables. We have to extract information from the datetime variables like no of years or no of days. One example in this specific scenario can be difference in years between the year the house was built and the year the house was sold. We will be performing this analysis in the Feature Engineering."},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of variables that contain year information\nyear_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's explore the content of these year variables\nfor feature in year_feature:\n    print(feature, df_train[feature].unique(),end = '\\n\\n',sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[year_feature].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets analyze the Temporal Datetime Variables\n# We will check the relationship between these year features and SalesPrice \n# and see how price is changing over the years\n# Here mean and median are almost same, for a safer side lets do analysis by taking a median\nfor yr_feature in year_feature:\n    df_train.groupby(yr_feature)['SalePrice'].median().plot()\n    plt.xlabel(yr_feature)\n    plt.ylabel('Median House Price')\n    plt.title(\"House Price vs {}\".format(yr_feature))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Oberservation\n\n1. There is increase in price, if the year of built is in the period 1940-2000. But there is almost same price(though there are spikes in some years) in the period 1880-1940.\n2. There is an increase in price if the house is modified recently\n3. Over the period of 1950-2000 there is demand for garage,if the garage is present then the house price increased over the years"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Here we will compare the difference between All years feature and year sold with SalePrice\n\ndata=df_train.copy()\nfor feature in year_feature:\n    if feature!='YrSold':\n        ## We will capture the difference between year variable and year the house was sold for\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation\n\n1. we can see that as the difference between the year features and the year sold increases then the house price decreases exponentially\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_features=[feature for feature in numerical_features if len(data[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Total Discrete Variables: {}\".format(len(discrete_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discrete_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[discrete_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[discrete_features].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets Find the realtionship between discrete variables and SalePice\n\nfor feature in discrete_features:\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation\n\n1. we can see from the plots above that Some discrete variables have relationship with the SalesPrice and some seems to be constant with the SalesPrice"},{"metadata":{},"cell_type":"markdown","source":"#### Continuous Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_feature=[feature for feature in numerical_features if feature not in discrete_features+year_feature+['Id']]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets analyse the continuous values by creating histograms to understand the distribution\n\nfor feature in continuous_feature:\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[continuous_feature].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We will be using logarithmic transformation\n\ndata = df_train.copy()\nfor feature in continuous_feature:\n# Here we skip the feature if it has unique value 0 as the log(0) is undefined\n    if 0 in data[feature].unique() or feature in ['SalePrice']: \n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data['SalePrice']=np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalesPrice')\n        plt.title(feature)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=df_train.copy()\nfor feature in continuous_feature:\n    if 0 in data[feature].unique(): # here we pass if the unique values\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [feature for feature in df_train.columns if data[feature].dtypes=='O']\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[categorical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_count = []\nfor feature in categorical_features:\n    cat_count.append(len(df_train[feature].unique()))\n\ndata_cat = {'Feature':categorical_features, 'No of Categories':cat_count} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat = pd.DataFrame(data_cat) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets see the relationship between categorical variable and dependent feature SalesPrice\ndata=df_train.copy()\nfor feature in categorical_features:\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}