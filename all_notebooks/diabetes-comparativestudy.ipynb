{"cells":[{"metadata":{},"cell_type":"markdown","source":"**The Pima Indian Diabetes dataset consists of women who are diagnosed with and without diabetes along with various features represented as columns that play an important role in the diagnosis. This notebook shows a comparative study between various classifier models used to perform Binary Classification on this data set. In the end we conclude which classifier model gives us the best result."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing all the necessary libraries and data set\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the data\ndata = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#checking 'NaN' values in the data\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#describing data to view various statstical variables\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot a count plot\nsns.countplot(data = data, x = \"Outcome\",hue = \"Outcome\")\nplt.title(\"WomenDiabetesData\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Box plot\nfig, ax = plt.subplots(figsize = (5,5))\nsns.boxplot(data = data, y = \"Pregnancies\", x = \"Outcome\", hue = \"Outcome\")\nplt.title(\"Pregnancies\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot a line plot\nsns.lineplot(data = data, x = 'Age', y = 'BloodPressure', hue = 'Age')\nplt.title(\"Age and BP\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting histograms for all features in the data set\nfor i in data.columns:\n    plt.figsize=(5,5)\n    plt.hist(data[i])\n    plt.title(i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot scatter plot for all features in the data set\nsns.pairplot(data = data, hue = \"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation of each features"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot heatmap and show case correlation of each features\ncorr_mat = data.corr()\nplt.figure(figsize=(12,10))\nsns.heatmap(corr_mat, annot = True, cmap = \"coolwarm\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standard Scaling\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assigning X and Y\nX = data[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\nY = data.Outcome","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assigning training and test data\nfrom sklearn.model_selection import train_test_split\nX_train_orig, X_test, Y_train,Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X_train_orig)\nX_train = sc.transform(X_train_orig)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr_classifier = LogisticRegression()\nlr_classifier.fit(X_train, Y_train)\nY_pred = lr_classifier.predict(X_test)\nprint(\"Accuracy of the model:\",accuracy_score(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb_classifier = GaussianNB()\ngnb_classifier.fit(X_train, Y_train)\nY_pred = gnb_classifier.predict(X_test)\nprint(\"Accuracy of the model:\",accuracy_score(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier()\nrf_classifier.fit(X_train, Y_train)\nY_pred = rf_classifier.predict(X_test)\nprint(\"Accuracy of the model:\",accuracy_score(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_classifier = SVC()\nsvm_classifier.fit(X_train, Y_train)\nY_pred = svm_classifier.predict(X_test)\nprint(\"Accuracy of the model:\",accuracy_score(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf \nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n#define keras model\nmodel = Sequential()\nmodel.add(Dense(12, input_dim = 8, activation = 'relu'))\nmodel.add(Dense(8, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n#compile the keras model\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\n\n#fit the model\nmodel.summary()\nmodel.fit(X_train, Y_train, epochs = 150, batch_size = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict the model\n_, accuracy = model.evaluate(X_train, Y_train, verbose = 0)\nprint(\"Accuracy of the model:\", accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can conclude that SVM and Logistic Regression model give the best results in terms of recall. \nIn any sort of medical diagnosis it is important to consider recall value and from the above results we conclude the same.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}