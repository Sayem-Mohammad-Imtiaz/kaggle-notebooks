{"cells":[{"metadata":{},"cell_type":"markdown","source":"Let's install `h2o4gpu`"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!apt-get install -y libopenblas-dev pbzip2\n!pip install -U tabulate==0.8.2\n!pip install h2o4gpu\nimport h2o4gpu","execution_count":1,"outputs":[{"output_type":"stream","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nlibopenblas-dev is already the newest version (0.2.19-3).\npbzip2 is already the newest version (1.1.9-1+b1).\n0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\nRequirement already up-to-date: tabulate==0.8.2 in /opt/conda/lib/python3.6/site-packages (0.8.2)\nRequirement already satisfied: h2o4gpu in /opt/conda/lib/python3.6/site-packages (0.3.1.10000)\nRequirement already satisfied: pandas==0.24.1 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (0.24.1)\nRequirement already satisfied: pytest==3.10.1 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (3.10.1)\nRequirement already satisfied: pytest-xdist==1.22.2 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (1.22.2)\nRequirement already satisfied: pytz==2018.4 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (2018.4)\nRequirement already satisfied: future==0.16.0 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (0.16.0)\nRequirement already satisfied: pytest-forked==0.2 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (0.2)\nRequirement already satisfied: pytest-cov==2.5.1 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (2.5.1)\nRequirement already satisfied: scipy==1.2.1 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (1.2.1)\nRequirement already satisfied: pylint==1.8.4 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (1.8.4)\nRequirement already satisfied: numpy==1.16.1 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (1.16.1)\nRequirement already satisfied: tabulate==0.8.2 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (0.8.2)\nRequirement already satisfied: scikit-learn==0.20.2 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (0.20.2)\nRequirement already satisfied: psutil==5.4.5 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (5.4.5)\nRequirement already satisfied: python-dateutil==2.7.2 in /opt/conda/lib/python3.6/site-packages (from h2o4gpu) (2.7.2)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (18.1.0)\nRequirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (4.1.0)\nRequirement already satisfied: atomicwrites>=1.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (1.3.0)\nRequirement already satisfied: pluggy>=0.7 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (0.9.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (1.12.0)\nRequirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (1.5.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from pytest==3.10.1->h2o4gpu) (39.1.0)\nRequirement already satisfied: execnet>=1.1 in /opt/conda/lib/python3.6/site-packages (from pytest-xdist==1.22.2->h2o4gpu) (1.5.0)\nRequirement already satisfied: coverage>=3.7.1 in /opt/conda/lib/python3.6/site-packages (from pytest-cov==2.5.1->h2o4gpu) (4.5.3)\nRequirement already satisfied: astroid<2.0,>=1.6 in /opt/conda/lib/python3.6/site-packages (from pylint==1.8.4->h2o4gpu) (1.6.3)\nRequirement already satisfied: isort>=4.2.5 in /opt/conda/lib/python3.6/site-packages (from pylint==1.8.4->h2o4gpu) (4.3.4)\nRequirement already satisfied: mccabe in /opt/conda/lib/python3.6/site-packages (from pylint==1.8.4->h2o4gpu) (0.6.1)\nRequirement already satisfied: apipkg>=1.4 in /opt/conda/lib/python3.6/site-packages (from execnet>=1.1->pytest-xdist==1.22.2->h2o4gpu) (1.5)\nRequirement already satisfied: lazy_object_proxy in /opt/conda/lib/python3.6/site-packages (from astroid<2.0,>=1.6->pylint==1.8.4->h2o4gpu) (1.3.1)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.6/site-packages (from astroid<2.0,>=1.6->pylint==1.8.4->h2o4gpu) (1.10.11)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Read and process netflix dataset to scipy sparse matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport numpy as np\nimport scipy\nfrom sklearn.model_selection import train_test_split\n\nfiles = [\n    '../input/combined_data_1.txt',\n    '../input/combined_data_2.txt',\n    '../input/combined_data_3.txt',\n    '../input/combined_data_4.txt',\n]\n\ncoo_row = []\ncoo_col = []\ncoo_val = []\n\nfor file_name in files:\n    print('processing {0}'.format(file_name))\n    with open(file_name, \"r\") as f:\n        movie = -1\n        for line in f:\n            if line.endswith(':\\n'):\n                movie = int(line[:-2]) - 1\n                continue\n            assert movie >= 0\n            splitted = line.split(',')\n            user = int(splitted[0])\n            rating = float(splitted[1])\n            coo_row.append(user)\n            coo_col.append(movie)\n            coo_val.append(rating)\n    gc.collect()\n\nprint('transformation...')\n\ncoo_val = np.array(coo_val, dtype=np.float32)\ncoo_col = np.array(coo_col, dtype=np.int32)\ncoo_row = np.array(coo_row)\nuser, indices = np.unique(coo_row, return_inverse=True)\nuser = user.astype(np.int32)\n\ngc.collect()\n\ncoo_matrix = scipy.sparse.coo_matrix((coo_val, (indices, coo_col)))\nshape = coo_matrix.shape\nprint('R matrix size', shape)\n\ngc.collect()\n\nprint('splitting into training and validation set')\ntrain_row, test_row, train_col, test_col, train_data, test_data = train_test_split(\n    coo_matrix.row, coo_matrix.col, coo_matrix.data, test_size=0.2, random_state=42)\n\ntrain = scipy.sparse.coo_matrix(\n    (train_data, (train_row, train_col)), shape=shape)\ntest = scipy.sparse.coo_matrix(\n    (test_data, (test_row, test_col)), shape=shape)\n","execution_count":2,"outputs":[{"output_type":"stream","text":"processing ../input/combined_data_1.txt\nprocessing ../input/combined_data_2.txt\nprocessing ../input/combined_data_3.txt\nprocessing ../input/combined_data_4.txt\ntransformation...\nR matrix size (480189, 17770)\nsplitting into training and validation set\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Let's factorize matrix R "},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = 40\n_lambda = 0.01\n# increase it in case out-of GPU memory, but n_components / BATCHES has to be a multiple of 10\nBATCHES=1\n\n\n\nscores = []\nfactorization = h2o4gpu.solvers.FactorizationH2O(\n    n_components, _lambda, max_iter=100)\nfactorization.fit(train, X_test=test, X_BATCHES=BATCHES,\n                      THETA_BATCHES=BATCHES, scores=scores, verbose=True, early_stopping_rounds=5)\nprint('best iteration:',factorization.best_iteration)","execution_count":6,"outputs":[{"output_type":"stream","text":"iteration 0 train: 0.831149160861969 cv: 0.9896033406257629\niteration 1 train: 0.7535563111305237 cv: 0.9313276410102844\niteration 2 train: 0.7214264869689941 cv: 0.9011292457580566\niteration 3 train: 0.7067406177520752 cv: 0.8872774243354797\niteration 4 train: 0.6985356211662292 cv: 0.8795573711395264\niteration 5 train: 0.6933938264846802 cv: 0.8747438192367554\niteration 6 train: 0.6899409294128418 cv: 0.8715165853500366\niteration 7 train: 0.6874918937683105 cv: 0.8692240715026855\niteration 8 train: 0.685676634311676 cv: 0.8675171732902527\niteration 9 train: 0.6842845678329468 cv: 0.8662049174308777\niteration 10 train: 0.6831879019737244 cv: 0.8651642203330994\niteration 11 train: 0.6823055148124695 cv: 0.8643186092376709\niteration 12 train: 0.6815824508666992 cv: 0.8636147975921631\niteration 13 train: 0.6809810400009155 cv: 0.8630224466323853\niteration 14 train: 0.6804736256599426 cv: 0.8625165820121765\niteration 15 train: 0.6800405383110046 cv: 0.8620761632919312\niteration 16 train: 0.6796668171882629 cv: 0.8616912364959717\niteration 17 train: 0.6793415546417236 cv: 0.8613538146018982\niteration 18 train: 0.6790557503700256 cv: 0.8610517382621765\niteration 19 train: 0.678803026676178 cv: 0.8607834577560425\niteration 20 train: 0.6785783767700195 cv: 0.8605425357818604\niteration 21 train: 0.6783772706985474 cv: 0.8603273034095764\niteration 22 train: 0.6781967282295227 cv: 0.8601323366165161\niteration 23 train: 0.6780338883399963 cv: 0.8599585294723511\niteration 24 train: 0.6778865456581116 cv: 0.859798789024353\niteration 25 train: 0.6777527928352356 cv: 0.8596529960632324\niteration 26 train: 0.6776309609413147 cv: 0.8595209121704102\niteration 27 train: 0.6775198578834534 cv: 0.8593988418579102\niteration 28 train: 0.6774181127548218 cv: 0.8592854738235474\niteration 29 train: 0.6773248910903931 cv: 0.8591821193695068\niteration 30 train: 0.6772391200065613 cv: 0.8590856790542603\niteration 31 train: 0.6771601438522339 cv: 0.858997106552124\niteration 32 train: 0.6770873665809631 cv: 0.8589134812355042\niteration 33 train: 0.6770200133323669 cv: 0.858837366104126\niteration 34 train: 0.6769576072692871 cv: 0.858765184879303\niteration 35 train: 0.6768998503684998 cv: 0.8586984872817993\niteration 36 train: 0.6768459677696228 cv: 0.8586359620094299\niteration 37 train: 0.676796019077301 cv: 0.8585779070854187\niteration 38 train: 0.6767492890357971 cv: 0.858522891998291\niteration 39 train: 0.6767058372497559 cv: 0.8584725260734558\niteration 40 train: 0.6766651272773743 cv: 0.8584250211715698\niteration 41 train: 0.6766270995140076 cv: 0.8583807945251465\niteration 42 train: 0.6765915155410767 cv: 0.8583387136459351\niteration 43 train: 0.6765580773353577 cv: 0.8582994341850281\niteration 44 train: 0.6765268445014954 cv: 0.8582614064216614\niteration 45 train: 0.676497220993042 cv: 0.8582269549369812\niteration 46 train: 0.6764695048332214 cv: 0.8581939935684204\niteration 47 train: 0.6764433979988098 cv: 0.8581629991531372\niteration 48 train: 0.6764188408851624 cv: 0.8581328392028809\niteration 49 train: 0.6763955950737 cv: 0.8581055402755737\niteration 50 train: 0.6763736605644226 cv: 0.8580787181854248\niteration 51 train: 0.6763529181480408 cv: 0.8580535650253296\niteration 52 train: 0.6763333082199097 cv: 0.8580296635627747\niteration 53 train: 0.676314651966095 cv: 0.8580067753791809\niteration 54 train: 0.6762968897819519 cv: 0.8579844832420349\niteration 55 train: 0.6762802600860596 cv: 0.8579631447792053\niteration 56 train: 0.6762643456459045 cv: 0.8579422831535339\niteration 57 train: 0.6762491464614868 cv: 0.8579230308532715\niteration 58 train: 0.6762347221374512 cv: 0.8579039573669434\niteration 59 train: 0.6762208938598633 cv: 0.8578851819038391\niteration 60 train: 0.6762079000473022 cv: 0.857867956161499\niteration 61 train: 0.6761953234672546 cv: 0.8578507304191589\niteration 62 train: 0.6761834025382996 cv: 0.8578347563743591\niteration 63 train: 0.6761720180511475 cv: 0.8578187823295593\niteration 64 train: 0.6761611104011536 cv: 0.857803463935852\niteration 65 train: 0.6761507391929626 cv: 0.857789158821106\niteration 66 train: 0.6761407256126404 cv: 0.8577753305435181\niteration 67 train: 0.6761311292648315 cv: 0.857761800289154\niteration 68 train: 0.6761221289634705 cv: 0.8577486276626587\niteration 69 train: 0.6761133074760437 cv: 0.857735812664032\niteration 70 train: 0.6761048436164856 cv: 0.8577237129211426\niteration 71 train: 0.6760967373847961 cv: 0.8577119708061218\niteration 72 train: 0.6760889887809753 cv: 0.8577004671096802\niteration 73 train: 0.6760814785957336 cv: 0.8576897382736206\niteration 74 train: 0.6760744452476501 cv: 0.8576786518096924\niteration 75 train: 0.6760675311088562 cv: 0.8576686382293701\niteration 76 train: 0.6760610342025757 cv: 0.857658863067627\niteration 77 train: 0.6760545969009399 cv: 0.857649564743042\niteration 78 train: 0.6760483980178833 cv: 0.8576402068138123\niteration 79 train: 0.6760425567626953 cv: 0.8576319217681885\niteration 80 train: 0.6760368347167969 cv: 0.8576230406761169\niteration 81 train: 0.6760313510894775 cv: 0.8576157689094543\niteration 82 train: 0.6760260462760925 cv: 0.8576078414916992\niteration 83 train: 0.6760209798812866 cv: 0.8575997352600098\niteration 84 train: 0.6760161519050598 cv: 0.857591986656189\niteration 85 train: 0.6760113835334778 cv: 0.8575846552848816\niteration 86 train: 0.6760067939758301 cv: 0.8575774431228638\niteration 87 train: 0.6760023236274719 cv: 0.8575709462165833\niteration 88 train: 0.6759980916976929 cv: 0.8575644493103027\niteration 89 train: 0.6759939789772034 cv: 0.8575579524040222\niteration 90 train: 0.6759899854660034 cv: 0.8575524091720581\niteration 91 train: 0.675986111164093 cv: 0.8575469851493835\niteration 92 train: 0.6759823560714722 cv: 0.8575410842895508\niteration 93 train: 0.6759787797927856 cv: 0.8575369715690613\niteration 94 train: 0.6759752631187439 cv: 0.8575314879417419\niteration 95 train: 0.6759718656539917 cv: 0.8575273752212524\niteration 96 train: 0.6759686470031738 cv: 0.8575222492218018\niteration 97 train: 0.6759653687477112 cv: 0.8575182557106018\niteration 98 train: 0.6759623289108276 cv: 0.8575137853622437\niteration 99 train: 0.6759594082832336 cv: 0.8575090169906616\nbest iteration: 99\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"And now `factorization.XT` and `factorization.thetaT` contain dense representation of users and movies respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X shape:', factorization.XT.shape)\nprint('ThetaT shape:', factorization.thetaT.shape)\n","execution_count":12,"outputs":[{"output_type":"stream","text":"X shape: (480189, 40)\nThetaT shape: (17770, 40)\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}