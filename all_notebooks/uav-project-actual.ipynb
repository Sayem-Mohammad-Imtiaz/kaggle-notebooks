{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Used to change filepaths\nfrom pathlib import Path\n\n# We set up matplotlib, pandas, and the display function\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nimport pandas as pd\n\n# import numpy to use in this cell\n# ... YOUR CODE FOR TASK 1 ...\nimport numpy as np\n# import Image from PIL so we can use it later\n# ... YOUR CODE FOR TASK 1 ...\nfrom PIL import Image\n# generate test_data\n# ... YOUR CODE FOR TASK 1 ...\ntest_data = np.random.beta(1,1,size=(100, 100, 3))\n# display the test_data\n# ... YOUR CODE FOR TASK 1 ...\nplt.imshow(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# open the image\nimg = Image.open('../input/bee_imgs/bee_imgs/001_043.png')\n\n# Get the image size\nimg_size = img.size\n\nprint(\"The image size is: {}\".format(img_size))\n\n# Just having the image as the last line in the cell will display it in the notebook\nimg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Image Manipulation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Crop the image to 25, 25, 75, 75\nimg_cropped = img.crop([25, 25, 75, 75])\ndisplay(img_cropped)\n\n# rotate the image by 45 degrees\nimg_rotated = img.rotate(45,expand=25)\ndisplay(img_rotated)\n\n# flip the image left to right\nimg_flipped = img.transpose(Image.FLIP_LEFT_RIGHT)\ndisplay(img_flipped)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Images in the form of array being plotted as Red, Green and Blue Channels**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn our image object into a NumPy array\nimg_data = np.array(img)\n\n# get the shape of the resulting array\nimg_data_shape = img_data.shape\n\nprint(\"Our NumPy array has the shape: {}\".format(img_data_shape))\n\n# plot the data with `imshow`\nplt.imshow(img_data)\nplt.show()\n\n# plot the red channel\nplt.imshow(img_data[:, :, 0], cmap=plt.cm.Reds_r)\nplt.show()\n\n# plot the green channel\nplt.imshow(img_data[:, :, 1], cmap=plt.cm.Greens_r)\nplt.show()\n\n# plot the blue channel\nplt.imshow(img_data[:, :, 2], cmap=plt.cm.Blues_r)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Exploring The Color Channels**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_kde(channel, color):\n    \"\"\" Plots a kernel density estimate for the given data.\n        \n        `channel` must be a 2d array\n        `color` must be a color string, e.g. 'r', 'g', or 'b'\n    \"\"\"\n    data = channel.flatten()\n    return pd.Series(data).plot.density(c=color)\n\n# create the list of channels\nchannels = ['r', 'g', 'b']\n    \ndef plot_rgb(image_data):\n    # use enumerate to loop over colors and indexes\n    for ix, color in enumerate(channels):\n        plot_kde(image_data[:, :, ix], color)\n        \n    plt.show()\n\nplot_rgb(img_data)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **#Honey bees RGB**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load bee_12.jpg as honey\nhoney = Image.open('../input/bee_imgs/bee_imgs//001_134.png')\n\n# display the honey bee image\ndisplay(honey)\n\n# NumPy array of the honey bee image data\nhoney_data = np.array(honey)\n\n# plot the rgb densities for the honey bee image\nplot_rgb(honey_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Bumble bee RGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load bee_3.jpg as bumble\nbumble = Image.open('../input/bee_imgs/bee_imgs//001_140.png')\n\n# display the bumble bee image\ndisplay(bumble)\n\n# NumPy array of the bumble bee image data\nbumble_data = np.array(bumble)\n\n# plot the rgb densities for the bumble bee image\nplot_rgb(bumble_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#CNN for Honey bee health Classification**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#to import images\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"directory = \"../input/bee_imgs/bee_imgs/\"\n#64x64 for faster training.\npicture3 = image.load_img(directory+\"041_073.png\", target_size=(64,64))\npicture3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/bee_data.csv\")\n#create a list to hold the 4d image tensors data\nX_pics = [image.load_img(directory+img_name,target_size=(64,64)) for img_name in df[\"file\"]]\n\n#a list of np tensors\nX = [np.array(image.img_to_array(i)) for i in X_pics]\n#rescale for training, using minmax scaling\nX = [i/255.0 for i in X]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#verified to be in order. Should be identical to the picture above\nX_pics[2] #third picture","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summary of the target/labels\nprint(df.health.value_counts())\ntarget_ids = []\nfor i in df.health:\n    if i not in target_ids:\n        target_ids.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing images into different health classes\n    \ny_keys = {\"healthy\":np.array([1,0,0,0,0,0]),\n         \"few varrao, hive beetles\":np.array([0,1,0,0,0,0]),\n         \"Varroa, Small Hive Beetles\":np.array([0,0,1,0,0,0]),\n         \"ant problems\":np.array([0,0,0,1,0,0]),\n         \"hive being robbed\":np.array([0,0,0,0,1,0]),\n         \"missing queen\":np.array([0,0,0,0,0,1])}\ny = [y_keys[i] for i in df.health]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#helper function\n#input as 1 type of target only, return some random indices for image showing\ndef random_imgs(df,num_images,X_pics):\n    index_lst = df[\"file\"].sample(n=num_images,random_state=1).index\n    image_lst = []\n    for i in index_lst:\n        image_lst.append(X_pics[i])\n    return image_lst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healthy = random_imgs(df[df[\"health\"]==\"healthy\"],4,X_pics)\nhive_beetles = random_imgs(df[df[\"health\"] == \"few varrao, hive beetles\"],4,X_pics)\nant_probs = random_imgs(df[df[\"health\"] == \"ant problems\"],4,X_pics)\nhive_robbed = random_imgs(df[df[\"health\"] == \"hive being robbed\"],4,X_pics)\nvarroa = random_imgs(df[df[\"health\"] == \"Varroa, Small Hive Beetles\"],4,X_pics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#only plot 2x2 images. Helper function. One can always generalize the function if neccessary\ndef plot_bees(img_lst,title):\n    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(8,8))\n    ax[0].imshow(img_lst[0])\n    ax[0].set_title(title)\n    ax[1].imshow(img_lst[1])\n    #ax[1].set_title(title)\n    ax[2].imshow(img_lst[2])\n    #ax[2].set_title(title)\n    ax[3].imshow(img_lst[3])\n    #ax[3].set_title(title)\n    \n    plt.show()\n    \n#plot_bees(healthy,\"healthy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bees(healthy,\"healthy\")\nplot_bees(hive_beetles,\"few varrao, hive beetles\")\nplot_bees(ant_probs,\"ant problems\")\nplot_bees(hive_robbed,\"hive being robbed\")\nplot_bees(varroa,\"Varroa, Small Hive Beetles\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convolution Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keras CNN\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Activation\nfrom keras.layers import BatchNormalization\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import callbacks\n\n\nfrom sklearn.model_selection import train_test_split\nhistory = callbacks.History() #need to be defined first","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LeNet's conv->pool->conv patterns\ndef train_cnn():\n    #to combat overfitting, better optimization for CNN, we'll be using Batch normalization PRIOR to activation.\n    #There has been a debate on where to use it, but the consensus has been to use it prior/after non-linearity (activation)\n    model = Sequential()\n\n    #3x3 matrix with 11 feature maps in total, conventional. 3d array for colored img, RGB. 255 in term of intensity max/min\n    model.add(Convolution2D(11,3,3, input_shape=(64,64,3)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),padding=\"SAME\"))\n    \n\n    model.add(Convolution2D(21,3,3, activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),padding=\"SAME\"))\n\n    #third convo layer with more feature filter size, 41 for better detection.\n    model.add(Convolution2D(41,3,3, activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2,2),padding=\"SAME\"))\n\n    #Flattening to input the fully connected layers\n    model.add(Flatten())\n\n    #dense layer section with after flattening\n    #hidden layer, 200\n    model.add(Dense(200, activation=\"relu\"))\n    model.add(Dropout(0.2))\n    model.add(Dense(6, activation=\"softmax\"))\n    \n    #smaller learning rate to optimize better. Default has periodic dips\n    model.compile(optimizer=optimizers.rmsprop(lr=0.0001), loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting into train,test, val datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y,random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#uncomment for training\nmodel1 = train_cnn()\nhistory1 = model1.fit(np.array(X_train),np.array(y_train),validation_data=(np.array(X_val),np.array(y_val)),\n                      verbose=True,shuffle=True,epochs=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_plot(history,epochs,title,y_range=[0.5,1.0],save=0 ):\n    train_losses = history.history[\"loss\"]\n    val_losses = history.history[\"val_loss\"]\n    plt.plot([i for i in range(0,epochs)],train_losses,val_losses)\n    plt.legend([\"Train Loss\",\"Val Loss\"])\n    plt.title(title)\n    \n    if save == 1:\n        plt.savefig(title+\"_Losses.jpg\")\n    plt.show()\n    \n    \n    train_losses = history.history[\"acc\"]\n    val_losses = history.history[\"val_acc\"]\n    plt.plot([i for i in range(0,epochs)],train_losses,val_losses)\n    plt.legend([\"Train_acc\",\"Val_acc\"])\n    plt.title(title)\n    plt.ylim(y_range)\n    \n    if save == 1:\n        plt.savefig(title+\"_Accuracy.jpg\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_plot(history1,epochs=len(history1.epoch),title=\"baseline_cnn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}