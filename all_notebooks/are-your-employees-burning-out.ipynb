{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nsns.set(color_codes=True)\nplt.figure(figsize=(12,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/hackerearth-employee-burnout-challenge/train.csv')\ntest = pd.read_csv('../input/hackerearth-employee-burnout-challenge/test.csv')\nsample = pd.read_csv('../input/hackerearth-employee-burnout-challenge/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date of Joining'] = pd.to_datetime(train['Date of Joining'],errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train.columns:\n    print(\"Unique Values in Column {} are {}\".format(i,len(train[i].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('Employee ID' ,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.get_dummies(train,columns=['Gender', 'Company Type', 'WFH Setup Available',\n       'Designation', 'Resource Allocation'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(axis = 0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train.corr()\ncorr_matrix['Burn Rate'].sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['Burn Rate'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\ntrain['Date_of_Joining_year'] = train['Date of Joining'].dt.year\ntrain['Date_of_Joining_month'] = train['Date of Joining'].dt.month\ntrain['Date_of_Joining_week'] = train['Date of Joining'].dt.week\ntrain['Date_of_Joining_day'] = train['Date of Joining'].dt.day\ntrain['Date_of_Joining_dayofweek'] = train['Date of Joining'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('Date of Joining',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop('Burn Rate',axis=1)\nY = train['Burn Rate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(np.array(X),np.array(Y),test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape,X_test.shape,Y_train.shape,Y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression,Lasso,ElasticNet,Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score\nfrom mlxtend.regressor import StackingCVRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train,Y_train)\npred = lr.predict(X_test)\ns1 = r2_score(Y_test,pred)\ns1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls = Lasso(alpha=1)\nls.fit(X_train,Y_train)\npred_ls = ls.predict(X_test)\ns2 = r2_score(Y_test,pred_ls)\ns2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rd = Ridge(alpha=1)\nrd.fit(X_train,Y_train)\npred_rd = rd.predict(X_test)\ns3 = r2_score(Y_test,pred_rd)\ns3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"en = ElasticNet(alpha=1)\nen.fit(X_train,Y_train)\npred_en = en.predict(X_test)\ns4 = r2_score(Y_test,pred_en)\ns4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr = DecisionTreeRegressor()\ndtr.fit(X_train,Y_train)\npred_dt = (dtr.predict(X_test))\ns5 = r2_score(Y_test,pred_dt)\ns5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = CatBoostRegressor(iterations=500,loss_function='MAE',eval_metric='RMSE',task_type='GPU')\ncat.fit(X_train,Y_train,verbose=True)\npred_cat = cat.predict(X_test)\ns6 = r2_score(Y_test,pred_cat)\ns6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=800)\nrf.fit(X_train,Y_train)\npred_rf = rf.predict(X_test)\ns7 = r2_score(Y_test,pred_rf)\ns7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'n_estimators': 1000,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}\ngd =GradientBoostingRegressor(**params)\ngd.fit(X_train,Y_train)\npred_gd = gd.predict(X_test)\ns8 = r2_score(Y_test,pred_gd)\ns8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\nfor i, y_pred in enumerate(gd.staged_predict(X_test)):\n    test_score[i] = gd.loss_(Y_test, y_pred)\n\nfig = plt.figure(figsize=(6, 6))\nplt.subplot(1, 1, 1)\nplt.title('Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, gd.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = XGBRegressor(n_estimators = 3000,learning_rate=0.01)\nxg.fit(X_train,Y_train)\npred_xg = xg.predict(X_test)\ns9 = r2_score(Y_test,pred_xg)\ns9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'learning_rate': 0.001,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.7,\n    'bagging_freq': 10,\n    'verbose': 0,\n    \"max_depth\": 8,\n    \"num_leaves\": 128,  \n    \"max_bin\": 512,\n    \"num_iterations\": 1000,\n    \"n_estimators\": 3000\n}\nlgb = LGBMRegressor()\nlgb.fit(X_train,Y_train,eval_set = (X_test,Y_test),early_stopping_rounds=1000)\npred_lgb = lgb.predict(X_test)\ns10 = r2_score(Y_test,pred_lgb)\ns10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]\n\n\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\n\n\n\nrf_random = RandomizedSearchCV(estimator=rf,param_distributions=random_grid,\n                               scoring='neg_mean_squared_error',\n                              n_iter=10,cv=5,verbose=2,random_state=42,n_jobs=1)\n\nrf_random.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rf_random.predict(X_test)\ns11 = r2_score(Y_test,predictions)\ns11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/hackerearth-employee-burnout-challenge/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date of Joining'] = pd.to_datetime(test['Date of Joining'],errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop('Employee ID' ,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.get_dummies(test,columns=['Gender', 'Company Type', 'WFH Setup Available',\n       'Designation', 'Resource Allocation'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\ntest['Date_of_Joining_year'] = test['Date of Joining'].dt.year\ntest['Date_of_Joining_month'] = test['Date of Joining'].dt.month\ntest['Date_of_Joining_week'] = test['Date of Joining'].dt.week\ntest['Date_of_Joining_day'] = test['Date of Joining'].dt.day\ntest['Date_of_Joining_dayofweek'] = test['Date of Joining'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop('Date of Joining',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = sc.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg = StackingCVRegressor(regressors=(lgb,rf,gd),meta_regressor=lgb,use_features_in_secondary=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg.fit(X_train,Y_train)\ntest_stack = avg.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_random_rf = rf_random.predict(test)\ntest_lg = lgb.predict(test)\ntest_rf = rf.predict(test)\ntest_xg = xg.predict(test)\ntest_gd = gd.predict(test)\nfinal_test = (test_lg*0.6 + test_random_rf*0.1 + test_rf*0.1 + test_xg*0.1 + test_gd*0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/hackerearth-employee-burnout-challenge/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame()\nsubmit['Employee ID'] = test['Employee ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit['Burn Rate'] = final_test.round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submit.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}