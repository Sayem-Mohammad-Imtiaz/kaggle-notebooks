{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import namedtuple, OrderedDict\nimport tensorflow as tf\nfrom os import listdir\nfrom os.path import isfile, join\nimport numpy as np\nfrom PIL import Image\nimport io\nimport pandas as pd\nfrom io import BytesIO","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read CSV with strategies. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_path = '../input/strategies/train_annotations_strategies.csv'\ndf_strategies = pd.read_csv(main_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select Strategy\nSTRATEGY = 'C_wbf'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pathlib\nimport tarfile\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tf_slim\n!pip install pycocotools\n!pip install lvis\n!pip install numba \n\nif \"models\" in pathlib.Path.cwd().parts:\n    while \"models\" in pathlib.Path.cwd().parts:\n        os.chdir('..')\nelif not pathlib.Path('models').exists():\n    !git clone --depth 1 https://github.com/tensorflow/models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd models/research\n\n# Compile protos.\nprotoc object_detection/protos/*.proto --python_out=.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Environment variables\nos.environ['PYTHONPATH'] += \":/kaggle/working/models:/kaggle/working/models/research/slim/:/kaggle/working/models/research:\"\n\nimport sys\nsys.path.append(\"/kaggle/working/models\")\nsys.path.append(\"/kaggle/working/models/research\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from object_detection.utils import label_map_util\nfrom object_detection.utils import dataset_util","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_with_findings = df_strategies[df_strategies['strategy'] == STRATEGY].copy()\n\n# Read the Label Map\nlabel_map = '../input/labelmap/label_map.pbtxt'\nlabel_dict = label_map_util.get_label_map_dict(label_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split(df, group):\n    data = namedtuple('data', ['image_id', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\n\ndef create_tf_example(group, path, label_dict):\n    \n    # Read the file (dicom)\n    data = tf.io.read_file(os.path.join(path, '{}.jpg'.format(group.image_id)))\n    image = tf.io.decode_jpeg(data)\n    height, width, length = image.shape\n    \n    # Read the file (jpg)\n    #with tf.gfile.GFile(os.path.join(path, '{}.jpg'.format(group.image_id)), 'rb') as fid:\n    #    encoded_jpg = fid.read()\n        \n    #encoded_jpg_io = io.BytesIO(encoded_jpg)\n    #image = Image.open(encoded_jpg_io)\n    #width, height = image.size\n    \n    filename = group.image_id.encode('utf8')\n    image_format = b'jpeg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    for index, row in group.object.iterrows():\n        xmins.append(row['x_min'] / width)\n        xmaxs.append(row['x_max'] / width)\n        ymins.append(row['y_min'] / height)\n        ymaxs.append(row['y_max'] / height)\n        classes_text.append(row['class_name'].encode('utf8'))\n        # Changed to map the Label map file\n        # row['class'] contains other label as the labelmap (+ 1)\n        classes.append(label_dict[row['class_name']])\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': dataset_util.int64_feature(height),\n        'image/width': dataset_util.int64_feature(width),\n        'image/filename': dataset_util.bytes_feature(filename),\n        'image/source_id': dataset_util.bytes_feature(filename),\n        'image/encoded': dataset_util.bytes_feature(data.numpy()),\n        'image/format': dataset_util.bytes_feature(image_format),\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\n    }))\n\n    return tf_example","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = split(train_with_findings, 'image_id')\nsplitfactor_train_val = 0.8 # splitfactor_train_val train_share; 1-splitfactor_train_val=val_share\n\ngrouped_train = grouped[:int(len(grouped) * splitfactor_train_val)]\ngrouped_val = grouped[int(len(grouped) * splitfactor_train_val):]\nassert len(grouped_val) + len(grouped_train) == len(grouped)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Path of the TF Records\ntfrecords_train_path = './tfrecords/{strategy}/train'.format(strategy=STRATEGY)\ntfrecords_val_path = './tfrecords/{strategy}/val'.format(strategy=STRATEGY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists(tfrecords_train_path):\n    os.makedirs(tfrecords_train_path)\nif not os.path.exists(tfrecords_val_path):\n    os.makedirs(tfrecords_val_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating TRAINING TF Records\nfilename = '{path}/train.tfrecord'.format(path = tfrecords_train_path)\nwriter = tf.io.TFRecordWriter(filename)\n\nfor group in grouped_train:    \n    tf_example = create_tf_example(group, '../input/vinbigdata-original-image-dataset/vinbigdata/train/', label_dict)\n    writer.write(tf_example.SerializeToString())\nwriter.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating TRAINING TF Records\nfilename = '{path}/val.tfrecord'.format(path = tfrecords_val_path)\nwriter = tf.io.TFRecordWriter(filename)\n\nfor group in grouped_val:    \n    tf_example = create_tf_example(group, '../input/vinbigdata-original-image-dataset/vinbigdata/train/', label_dict)\n    writer.write(tf_example.SerializeToString())\nwriter.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}