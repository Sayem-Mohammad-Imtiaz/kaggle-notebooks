{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport sys\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nmatplotlib.style.use(\"Solarize_Light2\")\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def check_null(df):\n    \"\"\"\n    Returns percentage of rows containing missing data\n    \"\"\"\n    return df.isna().sum() * 100/len(df)\n\n\ndef get_missing_dates(series, start_date, end_date, freq=\"D\"):\n    \"\"\"\n    Returns the dates which are missing in the series\n    date_sr between the start_date and end_date\n    \n    series: Series consisting of date\n    start_date: Start date in String format\n    end_date: End date in String format\n    \"\"\"\n    return pd.date_range(\n        start=start_date, end=end_date, freq=freq).difference(series)\n\n\ndef check_duplicate(df, subset):\n    \"\"\"\n    Returns if there are any duplicate rows in the DataFrame.\n    \n    df: DataFrame under consideration\n    subset: Optional List of feature names based on which \n            duplicate rows are being identified. \n    \"\"\"\n    if subset is not None: \n        return df.duplicated(subset=subset, keep=False).sum()\n    else:\n        return df.duplicated(keep=False).sum()\n\n\ndef create_date_features(source_df, target_df, feature_name):\n    '''\n    Create new features related to dates\n    \n    source_df : DataFrame consisting of the timestamp related feature\n    target_df : DataFrame where new features will be added\n    feature_name : Name of the feature of date type which needs to be decomposed.\n    '''\n    target_df.loc[:, 'year'] = source_df.loc[:, feature_name].dt.year.astype('uint16')\n    target_df.loc[:, 'month'] = source_df.loc[:, feature_name].dt.month.astype('uint8')\n    target_df.loc[:, 'quarter'] = source_df.loc[:, feature_name].dt.quarter.astype('uint8')\n    target_df.loc[:, 'weekofyear'] = source_df.loc[:, feature_name].dt.isocalendar().week.astype('uint8')\n    \n    target_df.loc[:, 'hour'] = source_df.loc[:, feature_name].dt.hour.astype('uint8')\n    \n    target_df.loc[:, 'day'] = source_df.loc[:, feature_name].dt.day.astype('uint8')\n    target_df.loc[:, 'dayofweek'] = source_df.loc[:, feature_name].dt.dayofweek.astype('uint8')\n    target_df.loc[:, 'dayofyear'] = source_df.loc[:, feature_name].dt.dayofyear.astype('uint8')\n    target_df.loc[:, 'is_month_start'] = source_df.loc[:, feature_name].dt.is_month_start\n    target_df.loc[:, 'is_month_end'] = source_df.loc[:, feature_name].dt.is_month_end\n    target_df.loc[:, 'is_quarter_start']= source_df.loc[:, feature_name].dt.is_quarter_start\n    target_df.loc[:, 'is_quarter_end'] = source_df.loc[:, feature_name].dt.is_quarter_end\n    target_df.loc[:, 'is_year_start'] = source_df.loc[:, feature_name].dt.is_year_start\n    target_df.loc[:, 'is_year_end'] = source_df.loc[:, feature_name].dt.is_year_end\n    \n    # This is of type object\n    target_df.loc[:, 'month_year'] = source_df.loc[:, feature_name].dt.to_period('M')\n    \n    return target_df\n\n\ndef plot_boxh_groupby(df, feature_name, by):\n    \"\"\"\n    Box plot with groupby\n    \n    df: DataFrame\n    feature_name: Name of the feature to be plotted\n    by: Name of the feature based on which groups are created\n    \"\"\"\n    df.boxplot(column=feature_name, by=by, vert=False, \n                              figsize=(10, 6))\n    plt.title(f'Distribution of {feature_name} by {by}')\n    plt.show()\n    \n\ndef plot_hist(df, feature_name, kind='hist', bins=100, log=True):\n    \"\"\"\n    Plot histogram.\n    \n    df: DataFrame\n    feature_name: Name of the feature to be plotted.\n    \"\"\"\n    if log:\n        df[feature_name].apply(np.log1p).plot(kind='hist', \n                                              bins=bins, \n                                              figsize=(15, 5), \n                                              title=f'Distribution of log1p[{feature_name}]')\n    else:\n        df[feature_name].plot(kind='hist', \n                              bins=bins, \n                              figsize=(15, 5), \n                              title=f'Distribution of {feature_name}')\n    plt.show()\n\n\ndef plot_ts(series, figsize=(20, 6), title=None, xlabel=\"\", ylabel=\"\"):\n    \"\"\"\n    Plot Time Series data. The series object should have date or time as index.\n    \n    series: Series object to be plotted.\n    \"\"\"\n    series.plot(figsize=figsize, title=title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()\n\n\ndef plot_barh(df, feature_name, normalize=True, \n              kind='barh', figsize=(15,5), sort_index=False, title=None):\n    \"\"\"\n    Plot barh for a particular feature\n    \n    kind : Type of the plot\n    \n    \"\"\"\n    if sort_index==True:\n        df[feature_name].value_counts(\n                normalize=normalize, dropna=False).sort_index().plot(\n                kind=kind, figsize=figsize, grid=True,\n                title=title)\n    else:   \n        df[feature_name].value_counts(\n                normalize=normalize, dropna=False).sort_values().plot(\n                kind=kind, figsize=figsize, grid=True,\n                title=title)\n    \n    plt.legend()\n    plt.show()\n\n\ndef plot_boxh(df, feature_name, kind='box', log=True):\n    \"\"\"\n    Box plot\n    \"\"\"\n    if log:\n        df[feature_name].apply(np.log1p).plot(kind='box', vert=False, \n                                                  figsize=(10, 6), \n                                                  title=f'Distribution of log1p[{feature_name}]')\n    else:\n        df[feature_name].plot(kind='box', vert=False, \n                              figsize=(10, 6), \n                              title=f'Distribution of {feature_name}')\n    plt.show()\n    \n\ndef plot_scatter(df, feature_x, feature_y, figsize=(10,10), \n                 title=None, xlabel=None, ylabel=None):\n    \"\"\"\n    Plot satter     \n    \"\"\"\n    df.plot.scatter(feature_x, feature_y, \n                    figsize=(8, 6), title=title, \n                    legend=None)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis for Predictive Maintenance (PdM)\n\n\n### This notebook explores the data related to Predictive Maintenance ([link](https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance)) provided by Microsoft Azure.\n\n\n# What is Predictive Maintenance?\n\nOur world is full of equipment. For example:\n* Aircraft consists of different equipments\n* HVAC (Heating, Ventilation, Air Conditioning) equipment consists of various parts\n\nAll these equipments or their parts meet failures and hence need maintenance. Thus maintenance is a big industry by itself. Maintenance is done either by replacing parts at regular intervals even when those are working (**Preventive Maintenance**) or by replacing the parts only when there is failure (**Reactive Maintenance**). **Predictive Maintenance** avoids the drawbacks of Preventive Maintenance (under utilization of a part's life) and Reactive Maintenance (unscheduled downtime). Based on the health of an equipment in the past, future point of failure can be predicted in Predictive Maintenance. Thus, replacement of parts can be scheduled just before the actual failure. \n\nTraditionally, predictive maintenance is being done using rule based techniques. With the advent of connected sensors (IoT), data from equipment is continuously collected and fed to Machine Learning based systems to predict its future health."},{"metadata":{},"cell_type":"markdown","source":"# Data Description\n\nThere are 5 CSV files consisting of:\n\n- **Telemetry Time Series Data** (PdM_telemetry.csv): It consists of hourly average of voltage, rotation, pressure, vibration collected from 100 machines for the year 2015.\n\n- **Error** (PdM_errors.csv): These are errors encountered by the machines while in operating condition. Since, these errors don't shut down the machines, these are not considered as failures. The error date and times are rounded to the closest hour since the telemetry data is collected at an hourly rate.\n\n- **Maintenance** (PdM_maint.csv): If a component of a machine is replaced, that is captured as a record in this table. Components are replaced under two situations:\n    - During the regular scheduled visit, the technician replaced it (Proactive Maintenance)\n    - A component breaks down and then the technician does an unscheduled maintenance to replace the component (Reactive  Maintenance). This is considered as a failure and corresponding data is captured under Failures.\n    Maintenance data has both 2014 and 2015 records. This data is rounded to the closest hour since the telemetry data is collected at an hourly rate.\n    \n    \n\n- **Failures** (PdM_failures.csv): Each record represents replacement of a component due to failure. This data is a subset of Maintenance data. This data is rounded to the closest hour since the telemetry data is collected at an hourly rate.\n\n- **Metadata of Machines** (PdM_Machines.csv): Model type & age of the Machines."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the data\nDATA_DIR = \"/kaggle/input/microsoft-azure-predictive-maintenance/\"\n\ntelemetry_df = pd.read_csv(f\"{DATA_DIR}/PdM_telemetry.csv\")\nerrors_df = pd.read_csv(f\"{DATA_DIR}/PdM_errors.csv\")\nmaint_df = pd.read_csv(f\"{DATA_DIR}/PdM_maint.csv\")\nfailures_df = pd.read_csv(f\"{DATA_DIR}/PdM_failures.csv\")\nmachines_df = pd.read_csv(f\"{DATA_DIR}/PdM_machines.csv\")\n\n# Format date & time. Sort based on date for better readability\ntables = [telemetry_df, maint_df, failures_df, errors_df]\nfor df in tables:\n    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], format=\"%Y-%m-%d %H:%M:%S\")\n    df.sort_values([\"datetime\", \"machineID\"], inplace=True, ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Telemetry Data\n\n### This data consists of hourly average of voltage, rotation, pressure, vibration collected from 100 machines for the year 2015."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Shape of the Telemetry Records: {telemetry_df.shape}\")\nprint(\"\\n\")\ntelemetry_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display the first few rows of the Telemetry data for Machine 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"telemetry_df[telemetry_df.machineID == 1].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How many Machines are there?"},{"metadata":{"trusted":true},"cell_type":"code","source":"telemetry_df.machineID.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What is the duration of the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"telemetry_df.datetime.describe(datetime_is_numeric=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Telemetry data is distributed between 1st Jan 2015 to 1st Jan 2016"},{"metadata":{},"cell_type":"markdown","source":"It seems that the data is having hourly frequency.\n\nLet's check if there are missing rows."},{"metadata":{},"cell_type":"markdown","source":"### Are there any missinge days in the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"get_missing_dates(telemetry_df.datetime, \n                  start_date=\"2015-01-01 06:00:00\", \n                  end_date=\"2016-01-01 06:00:00\", \n                  freq='H')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no missing data."},{"metadata":{},"cell_type":"markdown","source":"### Are there any duplicates?\n\nOne Machine should not have multiple rows with the same time stamp."},{"metadata":{"trusted":true},"cell_type":"code","source":"check_duplicate(telemetry_df, ['datetime', 'machineID'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no duplicates in the telemetry data."},{"metadata":{},"cell_type":"markdown","source":"### Are there any Null values in the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"check_null(telemetry_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values in the data"},{"metadata":{},"cell_type":"markdown","source":"### Let's plot Vibrarion of Machine 1 for 2015"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot Vibrarion of Machine 1 for 2015\ndf_vib_machine_1 = telemetry_df[\n    telemetry_df.machineID == 1][[\"datetime\", \"vibration\"]].set_index(\"datetime\")\nplot_ts(df_vib_machine_1, title=\"Vibration of Machine 1\", xlabel=\"Time\", ylabel=\"Vibration\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's plot voltage of Machine 2 for 1st two weeks of 2015"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot voltage of Machine 2 for 1st two weeks of 2015\ndf_vib_machine_1 = telemetry_df[\n    (telemetry_df.machineID == 2) & (\n        telemetry_df.datetime.dt.isocalendar().week.isin(\n            [1, 2, 3]))][[\"datetime\", \"volt\"]].set_index(\"datetime\")\nplot_ts(df_vib_machine_1, title=\"Volatage of Machine 2\", xlabel=\"Time\", ylabel=\"Voltage\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's add date related features to the telemetry data"},{"metadata":{"trusted":true},"cell_type":"code","source":"telemetry_df = create_date_features(telemetry_df, telemetry_df, \"datetime\")\ntelemetry_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the distribution of voltage across various months. Ideally there should be some amount seasonality in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_boxh_groupby(telemetry_df, feature_name=\"volt\", by=\"month_year\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It shows the voltage across Machines are not varying over month. \n\nWe can ignore the entry for 2016 since we only have data for one day in 2016.\n\n#### Let's plot it just for Machine 80."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_boxh_groupby(telemetry_df[telemetry_df.machineID == 80], feature_name=\"volt\", by=\"month_year\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This kind of shows the same thing. There is not much variation of voltage across months."},{"metadata":{},"cell_type":"markdown","source":"### Let's plot the distribution of Voltage across Machines."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(telemetry_df, feature_name=\"volt\", log=False, bins=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow! The distribution is a perfect normal curve. **This indicates the possibility of synethetically generated data.**\n\nLet's verify it by plotting histogram of other parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in ['rotate', 'pressure', 'vibration']:\n    plot_hist(telemetry_df, feature_name=name, log=False, bins=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vibration, rotation and pressure are also normally distributed. This verifies what we suspected.\n\n#### This data may be normally distributed. :-)"},{"metadata":{},"cell_type":"markdown","source":"## Observations about Telemetry Data\n- This may be synthetically generated data distributed between 1st Jan 2015 to 1st Jan 2016.\n- Each row represents the state of a machine on a particular hour. Voltage, vibration, pressure & rotation of a machine have been averaged hourly.\n- There are 100 unique Machines.\n- There are no duplicates or missing values in the dataset.\n- The four parameters voltage, vibration, pressure & rotation are normally distributed."},{"metadata":{},"cell_type":"markdown","source":"# Error Data\n\nThis data includes the errors encountered by the machines while in operating condition. Since, these errors don't shut down the machines, these are not considered as failures. The error date and times are rounded to the closest hour since the telemetry data is collected at an hourly rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Shape of the Error Records: {errors_df.shape}\")\nprint(\"\\n\")\nerrors_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort the Error based \"datetime\", \"machineID\", \"errorID\" for better readability\nerrors_df = errors_df.sort_values([\"datetime\", \"machineID\", \"errorID\"]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 3919 errors in total."},{"metadata":{"trusted":true},"cell_type":"code","source":"errors_df.machineID = errors_df.machineID.astype('category')\nerrors_df.errorID = errors_df.errorID.astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What is the duration of the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"errors_df.datetime.describe(datetime_is_numeric=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Error data is distributed between 1st Jan 2015 to 1st Jan 2016.\n\nAlso data is captured in hourly fashion."},{"metadata":{},"cell_type":"markdown","source":"### Are there any duplicates?\n\nOne Machine should not have multiple errors with the same time stamp."},{"metadata":{"trusted":true},"cell_type":"code","source":"check_duplicate(errors_df, ['datetime', 'machineID', 'errorID'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no duplicates in the error data."},{"metadata":{},"cell_type":"markdown","source":"### Are there any Null values in the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"check_null(errors_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot different types of errors"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_barh(errors_df, \n          feature_name=\"errorID\", \n          figsize=(10, 6), \n          normalize=False,\n          title=\"Different Types of Errors\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Type 1 & 2 errors are most frequent"},{"metadata":{},"cell_type":"markdown","source":"### Let's check if the failures are uniformly occuring across machines."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_barh(errors_df, \"machineID\", figsize=(6, 20), normalize=False, title=\"Number of errors across MachineID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, different machines has encountered, different number of errors."},{"metadata":{},"cell_type":"markdown","source":"### How does the Machine to type of error distribution looks like?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_errors = errors_df.groupby([\"machineID\", \"errorID\"]).size().reset_index()\ndf_errors.columns = [\"machineID\", \"errorID\", \"errorValues\"]\n#df_errors_pivot = pd.pivot(df_errors, index=\"machineID\", columns=\"errorID\", values=\"errorValues\").reset_index().rename_axis(None, axis=1)\ndf_errors_pivot = pd.pivot(df_errors, index=\"machineID\", columns=\"errorID\", values=\"errorValues\").rename_axis(None, axis=1)\n\ndf_errors_pivot.plot.bar(stacked=True, figsize=(20, 6), title=\"Count of Errors for different Machines\")\nplt.xlabel(\"Machine ID\")\nplt.ylabel(\"Number of Errors\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot number of errors across Machines over days"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ts(\n    errors_df.datetime.dt.date.value_counts().sort_index(), \n    figsize=(20, 6), \n    title=\"Number of Errors Across Days\", \n    xlabel=\"Time\",\n    ylabel=\"Number of Errors\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How does the error distribution looks for a particluar machine?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = errors_df[errors_df.machineID.isin([1, 2])].datetime.dt.date.value_counts().sort_index()\ndf_temp.plot(style=\"k.\", figsize=(8, 4), title=\"Number of Errors Across Days for Machine 1 & 2\")\nplt.ylabel(\"Count of Errors\")\nplt.xlabel(\"Time\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Machine 1 & 2, for most of the days, number of error is 1. But there are few days when number of errors are more than 1."},{"metadata":{},"cell_type":"markdown","source":"### Let's plot the distribution of the number of errors per day across Machine."},{"metadata":{"trusted":true},"cell_type":"code","source":"errors_df['date'] = errors_df.datetime.dt.date\n\nerrors_df.groupby('date').size().hist(bins=20, figsize=(10, 6))\nplt.title(\"Distribution of Number of Errors Per Day\")\nplt.xlabel(\"Number of Errors on a Particular Day\")\nplt.ylabel(\"Frequency\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Maintenance Data"},{"metadata":{},"cell_type":"markdown","source":"If a component of a machine is replaced, that is captured as a record in this table. Components are replaced under two situations:\n\n- During the regular scheduled visit, the technician replaced it (Proactive Maintenance)\n- A component breaks down and then the technician does an unscheduled maintenance to replace the component (Reactive Maintenance). This is considered as a failure and corresponding data is captured under Failures. Maintenance data has both 2014 and 2015 records. This data is rounded to the closest hour since the telemetry data is collected at an hourly rate.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Shape of the Maintenance Records: {maint_df.shape}\")\nprint(\"\\n\")\nmaint_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in [\"machineID\", \"comp\"]:\n    maint_df[name] = maint_df[name].astype(\"category\")\n    \nmaint_df.sort_values([\"datetime\", \"machineID\", \"comp\"], inplace=True)\n\n# Add date related features.\nmaint_df = create_date_features(maint_df, maint_df, \"datetime\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What is the duration of the data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"maint_df.datetime.describe(datetime_is_numeric=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Maintenance data is present June 2014 onwards. This is different from other data which are present between 2014 and 2015."},{"metadata":{"trusted":true},"cell_type":"code","source":"get_missing_dates(maint_df.datetime, \n                  start_date=\"2014-06-01 06:00:00\", \n                  end_date=\"2016-01-01 06:00:00\", \n                  freq='H')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's plot number of maintenance records across months"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_barh(maint_df, \"month_year\", normalize=False, sort_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of components replaced in the year 2015 are considerably higher compared to the 2014. \n\nAgain, we can ignore the data for 2016 (since we have only one day's data)"},{"metadata":{},"cell_type":"markdown","source":"### Let's check the number of components replaced"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_barh(maint_df, \n          feature_name=\"comp\", \n          figsize=(10, 6), \n          normalize=False,\n          title=\"Components Replaced\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Four types components are replaced almost in the same numbers."},{"metadata":{},"cell_type":"markdown","source":"### Let's plot the number of Maintenance Records Across Machines"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_barh(maint_df, \"machineID\", \n          figsize=(6, 20), \n          normalize=False, \n          title=\"Number of Maintenance Records across MachineID\", \n          sort_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How does the Machine to different component replaced looks like?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_maint = maint_df.groupby([\"machineID\", \"comp\"]).size().reset_index()\ndf_maint.columns = [\"machineID\", \"comp\", \"num_comp\"]\ndf_maint_pivot = pd.pivot(df_maint, index=\"machineID\", columns=\"comp\", values=\"num_comp\").rename_axis(None, axis=1)\n\ndf_maint_pivot.plot.bar(stacked=True, figsize=(20, 6), title=\"Count of Components Replaced for different Machines\")\nplt.xlabel(\"Machine ID\")\nplt.ylabel(\"Number of Components Replaced\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot number of Maintenance Issues reaised per day"},{"metadata":{"trusted":true},"cell_type":"code","source":"maint_df.datetime.dt.date.value_counts().plot(\n    style=\"k.\", \n    figsize=(20, 4), \n    title=\"Number of Maintenance Records Across Time\")\nplt.ylabel(\"Number of Maintenance Records\")\nplt.xlabel(\"Time\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This indicates that there is a drastic difference between the number of maintenance records in 2014 vs 2015."},{"metadata":{},"cell_type":"markdown","source":"# Failure Data"},{"metadata":{},"cell_type":"markdown","source":"# Static Data of Machines"},{"metadata":{},"cell_type":"markdown","source":"This data set includes some information about the machines: model type and age (years in service)."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Shape of the Machines Data: {machines_df.shape}\")\nprint(\"\\n\")\nmachines_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the distribution of age of the Machines"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_boxh(machines_df, feature_name=\"age\", log=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The age of the Machines is distributed between 0 to 20. The median age is to ~12.5. There are no outliers. Another indication that this is a synthetic data."},{"metadata":{},"cell_type":"markdown","source":"### Plot Age vs Number of Failures"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a DF with number of errors, maintenance records and failure records across machines\n\n# Create a DF consisting of number of erros across Machines\nerros_across_machine = errors_df.groupby(\"machineID\").size()\nerros_across_machine = pd.DataFrame(erros_across_machine, columns=[\"num_errors\"]).reset_index()\n\nmachines_errors_df = pd.merge(machines_df, erros_across_machine, how='left', on=\"machineID\")\n\n# Create a DF consisting of number of maintenance records across Machines\nmaint_across_machine = maint_df.groupby(\"machineID\").size()\nmaint_across_machine = pd.DataFrame(maint_across_machine, columns=[\"num_maint\"]).reset_index()\n\nmachines_errors_df = pd.merge(machines_errors_df, maint_across_machine, how='left', on=\"machineID\")\n\n# Create a DF consisting of number of failure records across Machines\nfailure_across_machine = failures_df.groupby(\"machineID\").size()\nfailure_across_machine = pd.DataFrame(failure_across_machine, columns=[\"num_failure\"]).reset_index()\n\nmachines_errors_df = pd.merge(machines_errors_df, failure_across_machine, how='left', on=\"machineID\")\n\nmachines_errors_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Number of Errors across Machine Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter(machines_errors_df, \"age\", \"num_errors\", \n             title=\"Age vs Number of Errors\", \n             xlabel=\"Age\", ylabel=\"Number of Errors\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Age vs Number of Maintenance Records"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter(machines_errors_df, \"age\", \"num_maint\", \n             title=\"Age vs Number of Maintenance Records\", \n             xlabel=\"Age\", ylabel=\"Number of Maintenance Records\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Age vs Number of Failure Records"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter(machines_errors_df, \"age\", \"num_failure\", \n             title=\"Age vs Number of Failure Records\", \n             xlabel=\"Age\", ylabel=\"Number of Failure Records\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### From the above three plots, it appears only Number of Failures is slightly correlated with Age.\n\nLet's verify it with a correlation values."},{"metadata":{"trusted":true},"cell_type":"code","source":"machines_errors_df.corr()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}