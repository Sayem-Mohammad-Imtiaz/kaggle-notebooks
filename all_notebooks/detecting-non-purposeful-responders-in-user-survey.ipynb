{"metadata":{"language_info":{"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","version":"3.6.3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"code","execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n#Basics\nimport pandas as pd\nimport numpy as np\n\n# visualization\nimport seaborn as sns\nsns.set(color_codes=True)\nimport matplotlib.pyplot as plt\n#%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n#os\nfrom os import listdir\nfrom os.path import isfile, join\n\n# machine learning\n# import random as rnd\n# import operator\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.svm import SVC, LinearSVC\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.naive_bayes import GaussianNB\n# from sklearn.linear_model import Perceptron\n# from sklearn.linear_model import SGDClassifier\n# from sklearn.tree import DecisionTreeClassifier\n\n# GLOBALS\n\nencoding_type = 'latin-1'\n\n\n\n","outputs":[],"metadata":{"_cell_guid":"87bdd6ab-b06d-46c6-890a-daa519d171cf","_kg_hide-output":false,"_uuid":"a04277f88e3b211db335a70be0ff3a7cfbaf3680","_kg_hide-input":false}},{"cell_type":"code","execution_count":null,"source":"# Get all of the files that have a csv in the file name\nonlyfiles = pd.DataFrame([f for f in listdir(\"../input/\") if isfile(join(\"../input/\", f)) and f.find('.csv')>0 ])\n\n# Print the descriptor for the datasets in the library\nprint(\"The .csv datasets included in the library are as follows:\")\n\n# Print the file names\nfor x in onlyfiles[0]:\n    print(x)\n\n# Create a dictionary of table names\nalltables = {'varname':[],\n            'filename':[],\n            'dataset':[]}\n\n# Loop through the file names and import them, adding a table name that reflects the file name\nfor i, onlyfile in enumerate(onlyfiles[0]):\n    varname = onlyfile[0:3] + str(i)\n    alltables['varname'].append(varname)\n    alltables['filename'].append(onlyfile)\n    \n    #test = pd.read_csv('../input/test.csv', encoding='latin-1')\n    exec(varname + \" = pd.read_csv('../input/\"+ onlyfile +\"',  encoding='\"+ encoding_type + \"')\") \n    exec(\"alltables['dataset'].append(\" + varname + \")\")\n    #print(test.columns)\n    #exec(\"print(\"+ varname + \".columns)\") \n\n\n# Print the list of table variable names\nalltables = pd.DataFrame(alltables)\n","outputs":[],"metadata":{"_cell_guid":"057cdd09-e4d7-4d40-98b1-ec76eb598cf2","_uuid":"328c1f04273fb33fdf940d6f1aa29ee61c6ef98f"}},{"cell_type":"code","execution_count":null,"source":"print(alltables.filter(['varname','filename']))","outputs":[],"metadata":{"_cell_guid":"569d79e8-8651-4789-9eac-802b611c9745","_uuid":"a90c1d2d5a6e11584f8d1d0f71c0dcbaff900e7d"}},{"cell_type":"code","execution_count":null,"source":"\n# Create a dataset of variable types, where we will store the names and types of variables\n# We will use this to loop through and get some distributions to find outliers\nvartypes = {'name': [],\n           'type': []}\n\n# Create an empty data frame for the numeric and string data\nnum_data = pd.DataFrame()\nstr_data = pd.DataFrame()\n\n#get metadata for all tables\nfor dataset in alltables['dataset']:\n    g = dataset.columns.to_series().groupby(dataset.dtypes).groups\n    # Loop through the metadata, and append the metadata to the vartypes dictionary\n    for k, v in g.items():\n        for x in v: \n            vartypes['name'].append(x)\n            vartypes['type'].append(str(k))\n            \n            if str(k) == 'float64':\n                newframe = pd.DataFrame({x:dataset[x]})\n                num_data = pd.concat([newframe, num_data])\n                \n            #if str(k) == 'object':\n                #newframe = pd.DataFrame({x:dataset[x]})\n                #str_data = pd.concat([newframe, str_data])\n","outputs":[],"metadata":{"_cell_guid":"bec1e5c8-20a3-42b6-8137-05acb47858d1","_uuid":"0ca430f9826b96289a950c51966a19450fbe3995","collapsed":true}},{"cell_type":"code","execution_count":null,"source":"num_data_desc = num_data.describe(percentiles=[.005, .05, .25, .5, .75, .95, .995])\nprint(num_data_desc)","outputs":[],"metadata":{"_cell_guid":"92c42486-8f22-4997-8c0c-93a017df5f2b","_uuid":"95c580fed4c59e71d36e5def2ce635d6dabb07c5"}},{"cell_type":"code","execution_count":null,"source":"plt.hist(num_data['Age'].dropna(), bins=100)","outputs":[],"metadata":{"_cell_guid":"bf16e894-3abf-4823-893c-fb066c84aded","_uuid":"afe883575f83c1ded7f2d6d0b35a23aca1d7c085"}},{"cell_type":"code","execution_count":null,"source":"for x in range(len(num_data)):\n    plt.hist(num_data.iloc[:,x].dropna()) \n    plt.title = num_data.columns[x]\n    plt.show()","outputs":[],"metadata":{"_cell_guid":"739acbee-61c1-4248-9479-8167d154d34b","_uuid":"f61f11a235b07b0512f55f441985933683496a47"}}]}