{"cells":[{"metadata":{},"cell_type":"markdown","source":">### **This notebook is an evolitionary review of building nn models with keras. I just focussed on base modeling.**\n>### **Final model can improve by EDA, Missing Value imputation, Feat eng, transformation and model tuning.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, GridSearchCV, StratifiedKFold\n\nfrom sklearn.metrics import *\nfrom sklearn import metrics\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom pathlib import Path\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\nimport sys, os\nimport random \n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\n    \nfrom IPython import display, utils\n\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)\npd.set_option('max_colwidth', 400)\n\n\ndef set_seed(seed=4242):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\nset_seed()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    \n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) / float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] / sum(cf[:,1])\n            recall    = cf[1,1] / sum(cf[1,:])\n            f1_score  = 2*precision*recall / (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data():\n    train = pd.read_csv('../input/flu-data/H1N1_Flu_Vaccines.csv')\n    #display(train.head())\n    \n    del train['respondent_id']\n   \n    \"\"\"cats = train.describe(include=['O']).columns\n    for c in cats:\n        le=LabelEncoder()\n        le.fit(list(train[c].astype(str)) + list(test[c].astype(str)))\n        train[c] = le.transform(train[c].astype(str))\n        test[c] = le.transform(test[c].astype(str))\"\"\"\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = read_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train.h1n1_vaccine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train.seasonal_vaccine)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Flu Vaccine Binary"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = train.isnull().sum()\nmissing = missing[missing>0]\n\nmiss = pd.DataFrame(missing, columns=['missing'])\n\nmiss = miss.reset_index()\n\nprint(miss.columns)\n\nmiss.sort_values(by='missing', ascending=False, inplace=True)\n\nplt.figure(figsize=(15, 10))\nsns.barplot(y = miss['index'], x= miss.missing, palette='bone')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats = [c for c in train.columns if train[c].dtypes=='object']\n\nnums = train.select_dtypes(exclude='object').columns\n\nnums","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in cats:\n    le=LabelEncoder()\n    train[c] = le.fit_transform(train[c].astype(str)) \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.style as style\nstyle.use('seaborn-poster')\nsns.set_style('ticks')\nplt.subplots(figsize = (27,20))\n## Plotting heatmap. \n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(train.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(train.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, );\n## Give title. \nplt.title(\"Heatmap of all the Features\", fontsize = 25);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train['h1n1_vaccine']\ntarget = train.pop('seasonal_vaccine')\n\ntrain.shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(-999, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\nmodel.add(Dense(8,  activation= 'relu' ))\nmodel.add(Dense(1,  activation= 'sigmoid' ))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train, target, validation_split=0.33 , epochs=15, batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(train, target)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KFold Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncvscores = []\nfor train_ind, test_ind in kfold.split(train, target):\n# create model\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    # Fit the model\n    model.fit(train.iloc[train_ind], target.iloc[train_ind], epochs=15, batch_size=10, verbose=1)\n    # evaluate the model\n    scores = model.evaluate(train.iloc[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport tensorflow as tf\nfrom keras.layers import Dense, Input\nfrom collections import Counter\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.models import Model, load_model\nfrom keras import callbacks\nfrom keras import backend as K\nfrom keras.layers import Dropout\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=45)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : --------------', fold_)\n    \n    trn_x, trn_y = train.iloc[train_ind], target.iloc[train_ind]\n    val_x, val_y = train.iloc[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    # Fit the model\n    model.fit(train.iloc[train_ind], target.iloc[train_ind], epochs=5, batch_size=10, verbose=1)\n    val_preds = model.predict(val_x)\n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    scores = model.evaluate(train.iloc[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    cvscores.append(scores[1] * 100)\nK.clear_session()\ngc.collect()\nprint(\"Accuracy Mean: ------->\" , (np.mean(cvscores)))\nprint('AUC mean: ------->', np.mean(auc_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scale data "},{"metadata":{"trusted":true},"cell_type":"code","source":"ss= StandardScaler()\ntrain = ss.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import metrics \nimport gc\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=45)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : --------------', fold_)\n    \n    trn_x, trn_y = train[train_ind], target.iloc[train_ind]\n    val_x, val_y = train[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    # Fit the model\n    model.fit(train[train_ind], target.iloc[train_ind], epochs=5, batch_size=10, verbose=1)\n    val_preds = model.predict(val_x)\n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    scores = model.evaluate(train[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    cvscores.append(scores[1] * 100)\nK.clear_session()\ngc.collect()\nprint(\"Accuracy Mean: ------->\" , (np.mean(cvscores)))\nprint('AUC mean: ------->', np.mean(auc_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AUC through epoches"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fallback_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except:\n        return 0.5\n\n\ndef auc(y_true, y_pred):\n    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import metrics \nimport gc\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=45)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : --------------', fold_)\n    \n    trn_x, trn_y = train[train_ind], target.iloc[train_ind]\n    val_x, val_y = train[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[auc])\n    # Fit the model\n    model.fit(train[train_ind], target.iloc[train_ind], epochs=5, batch_size=10, verbose=1)\n    val_preds = model.predict(val_x)\n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    scores = model.evaluate(train[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    cvscores.append(scores[1] * 100)\nK.clear_session()\ngc.collect()\nprint(\"Accuracy Mean: ------->\" , (np.mean(cvscores)))\nprint('AUC mean: ------->', np.mean(auc_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Better Network Topology"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport tensorflow as tf\nfrom keras.layers import Dense, Input\nfrom collections import Counter\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.models import Model, load_model\nfrom keras import callbacks\nfrom keras import backend as K\nfrom keras.layers import Dropout\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=142)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\n\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||>', fold_)\n    \n    trn_x, trn_y = train[train_ind], target.iloc[train_ind]\n    val_x, val_y = train[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(64, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dropout(0.2))\n    model.add(Dense(16,  activation= 'relu' ))\n    model.add(Dropout(0.2))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    #opt = keras.optimizers.Adam(learning_rate=0.01)\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'Adam' , metrics=[auc])\n    # Fit the model\n    cp = callbacks.ModelCheckpoint(filepath=\"cp.hdf5\", monitor=\"val_auc\",  verbose=0,\n        save_best_only=False, save_weights_only=False,  mode=\"auto\")\n    \n    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=20,\n                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n\n    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n    \n    model.fit(trn_x, trn_y, validation_data=(val_x, val_y),callbacks= [cp, es, rlr],  epochs=100, batch_size=16, verbose=0)\n    val_preds = model.predict(val_x)\n    \n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    #scores = model.evaluate(val_x, val_y, verbose=1)\n    #print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    model.save_weights(\"model.h5\")\n    \n    \nK.clear_session()\ngc.collect()\n\nprint('AUC mean: ------->', np.mean(auc_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"oof_nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"oof_nn_rd = np.where(oof_nn > 0.5, 1, 0)\ncf_matrix = confusion_matrix(target, oof_nn_rd) \n\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['Zero', 'One']\nplt.style.use('seaborn-poster')\nsns.set(font_scale=1.4)\nmake_confusion_matrix(cf_matrix, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='vlag', figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}