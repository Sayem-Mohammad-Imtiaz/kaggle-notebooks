{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport seaborn as sns\nimport transformers\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom transformers import RobertaModel, RobertaTokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv')\ntest = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[['OriginalTweet','Sentiment']]\ntest = test[['OriginalTweet','Sentiment']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('darkgrid')\nplt.figure(figsize = (8, 8))\nsns.countplot(x = train['Sentiment'] , palette = 'viridis')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef remove_links(text):\n    to_remove = ['\\r','\\n',',',';',':','.']\n    \n    out = re.sub(r'http\\S+', '', text)\n    \n    for token in to_remove:\n        out = out.replace(token, '')\n    \n    return re.sub(' +', ' ', out.lower()) #Remove duplicate spaces\n\ndef tokenize(text, tokenizer):\n    return tokenizer.encode(text, padding='max_length')\n\nname_to_idx = {\n    \"Extremely Negative\" : 0,\n    \"Negative\" : 1,\n    \"Neutral\" : 2,\n    \"Positive\" : 3,\n    \"Extremely Positive\" : 4\n}\n\ndef process_tgt(value):\n    return name_to_idx[value]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['OriginalTweet'] = train['OriginalTweet'].apply(remove_links)\ntrain['Sentiment'] = train['Sentiment'].apply(process_tgt)\ntest['OriginalTweet'] = test['OriginalTweet'].apply(remove_links)\ntest['Sentiment'] = test['Sentiment'].apply(process_tgt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TweetDataset(Dataset):\n    def __init__(self, df, tokenizer, maxlen):\n        self.tokenizer = tokenizer\n        self.data = df\n        self.text = df.OriginalTweet\n        self.targets = df.Sentiment\n        self.maxlen = maxlen\n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, idx):\n        text = str(self.text[idx])\n        text = ' '.join(text.split())\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens = True, \n            max_length = self.maxlen,\n            pad_to_max_length = True,\n            return_token_type_ids = True\n        )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs['token_type_ids']\n        \n        return {\n            'ids'  : torch.tensor(ids, dtype = torch.long),\n            'mask' : torch.tensor(mask, dtype = torch.long),\n            'token_type_ids' : torch.tensor(token_type_ids, dtype = torch.long),\n            'targets' : torch.tensor(self.targets[idx], dtype = torch.long)\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 256\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 4\n# EPOCHS = 1\nLEARNING_RATE = 1e-05\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TweetDataset(train, tokenizer, MAX_LEN)\ntest_dataset = TweetDataset(test, tokenizer, MAX_LEN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, shuffle = True, num_workers = 2)\ntest_loader = DataLoader(test_dataset, batch_size = VALID_BATCH_SIZE, shuffle = True, num_workers = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Roberta_Model(nn.Module):\n    \n    def __init__(self):\n        super(Roberta_Model, self).__init__()\n        self.l1 = RobertaModel.from_pretrained('roberta-base') \n        self.pre_classifier = nn.Linear(768, 768)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(768, 5)\n        \n    def forward(self, input_ids, attention_mask, token_type_ids):\n        x = self.l1(input_ids = input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids)\n        hidden_state = x[0]\n        pooler = hidden_state[:,0]\n        pooler = self.pre_classifier(pooler)\n        pooler = nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Roberta_Model()\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calcuate_accuracy(preds, targets):\n    n_correct = (preds==targets).sum().item()\n    return n_correct","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    tr_loss = 0\n    n_correct = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    model.train()\n    for _,data in tqdm(enumerate(train_loader, 0)):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.long)\n\n        outputs = model(ids, mask, token_type_ids)\n        loss = loss_function(outputs, targets)\n        tr_loss += loss.item()\n        big_val, big_idx = torch.max(outputs.data, dim=1)\n        n_correct += calcuate_accuracy(big_idx, targets)\n\n        nb_tr_steps += 1\n        nb_tr_examples+=targets.size(0)\n        \n        if _%5000==0:\n            loss_step = tr_loss/nb_tr_steps\n            accu_step = (n_correct*100)/nb_tr_examples \n            print(f\"Training Loss per 5000 steps: {loss_step}\")\n            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n\n        optimizer.zero_grad()\n        loss.backward()\n        # # When using GPU\n        optimizer.step()\n\n    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Training Loss Epoch: {epoch_loss}\")\n    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n\n    return ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1\nfor epoch in range(EPOCHS):\n    train(epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(model, testing_loader):\n    model.eval()\n    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n    with torch.no_grad():\n        for _, data in tqdm(enumerate(testing_loader, 0)):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n            targets = data['targets'].to(device, dtype = torch.long)\n            outputs = model(ids, mask, token_type_ids).squeeze()\n            loss = loss_function(outputs, targets)\n            tr_loss += loss.item()\n            big_val, big_idx = torch.max(outputs.data, dim=1)\n            n_correct += calcuate_accuracy(big_idx, targets)\n\n            nb_tr_steps += 1\n            nb_tr_examples+=targets.size(0)\n            \n            if _%5000==0:\n                loss_step = tr_loss/nb_tr_steps\n                accu_step = (n_correct*100)/nb_tr_examples\n                print(f\"Validation Loss per 100 steps: {loss_step}\")\n                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n    epoch_loss = tr_loss/nb_tr_steps\n    epoch_accu = (n_correct*100)/nb_tr_examples\n    print(f\"Validation Loss Epoch: {epoch_loss}\")\n    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n    \n    return epoch_accu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = valid(model, test_loader)\nprint(\"Accuracy on test data = %0.2f%%\" % acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_model_file = 'pytorch_roberta_sentiment.bin'\noutput_vocab_file = './'\n\nmodel_to_save = model\ntorch.save(model_to_save, output_model_file)\ntokenizer.save_vocabulary(output_vocab_file)\n\nprint('All files saved')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}