{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import struct\n# Load various imports \nimport pandas as pd\nimport os\nimport torch\nimport librosa\nimport librosa.display\n\nclass WavFileHelper():\n    \n    def read_file_properties(self, filename):\n\n        wave_file = open(filename,\"rb\")\n        \n        riff = wave_file.read(12)\n        fmt = wave_file.read(36)\n        \n        num_channels_string = fmt[10:12]\n        num_channels = struct.unpack('<H', num_channels_string)[0]\n\n        sample_rate_string = fmt[12:16]\n        sample_rate = struct.unpack(\"<I\",sample_rate_string)[0]\n        \n        bit_depth_string = fmt[22:24]\n        bit_depth = struct.unpack(\"<H\",bit_depth_string)[0]\n\n        return (num_channels, sample_rate, bit_depth)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(file_name):\n   \n    try:\n        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n        mfccsscaled = np.mean(mfccs.T,axis=0)\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_name)\n        print(e)\n        return None \n     \n    return mfccsscaled\n    \n    \n# Load various imports \nimport pandas as pd\nimport os\nimport librosa\n\n# Set the path to the full UrbanSound dataset \nfulldatasetpath = '../input/urbansound8k'\n\nmetadata = pd.read_csv(fulldatasetpath + '/UrbanSound8K.csv')\n\nfeatures = []\n\n# Iterate through each sound file and extract the features \nfor index, row in metadata.iterrows():\n    \n    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    class_label = row[\"class\"]\n    data = extract_features(file_name)\n    \n    features.append([data, class_label])\n\n# Convert into a Panda dataframe \nfeaturesdf = pd.DataFrame(features, columns=['feature','class_label'])\n\nprint('Finished feature extraction from ', len(featuresdf), ' files')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wavfilehelper = WavFileHelper()\n\naudiodata = []\nfor index, row in metadata.iterrows():\n    \n    file_name = os.path.join(os.path.abspath('../input/urbansound8k/'),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    data = wavfilehelper.read_file_properties(file_name)\n    audiodata.append(data)\n\n# Convert into a Panda dataframe\naudiodf = pd.DataFrame(audiodata, columns=['num_channels','sample_rate','bit_depth'])\nprint(audiodf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\n\n# Convert features and corresponding classification labels into numpy arrays\nX = np.array(featuresdf.feature.tolist())\ny = np.array(featuresdf.class_label.tolist())\n\n# Encode the classification labels\nle = LabelEncoder()\nyy = to_categorical(le.fit_transform(y)) \n\n# split the dataset \nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom sklearn import metrics \nnum_dim1 = x_train.shape[0]\nnum_rows = 10\nnum_columns = 2\nnum_channels = 2\n\nx_train = x_train.reshape(x_train.shape[0], num_rows, num_columns,num_channels)\nx_test = x_test.reshape(x_test.shape[0], num_rows, num_columns,num_channels)\n\nnum_labels = yy.shape[1]\nfilter_size = 1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct model \nmodel = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=1, input_shape=(num_columns, num_rows,num_channels), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\n#model.add(Conv2D(filters=32, kernel_size=1, activation='relu'))\n#model.add(MaxPooling2D(pool_size=2))\n#model.add(Dropout(0.2))\n\n#model.add(Conv2D(filters=64, kernel_size=1, activation='relu'))\n#model.add(MaxPooling2D(pool_size=2))\n#model.add(Dropout(0.2))\n\n#model.add(Conv2D(filters=128, kernel_size=1, activation='relu'))\n#model.add(MaxPooling2D(pool_size=2))\n#model.add(Dropout(0.2))\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(num_labels, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint \nfrom datetime import datetime \n\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n# Display model architecture summary \nmodel.summary()\n\nnum_epochs = 256\nnum_batch_size = 256\n\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\n\nmodel.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate pre-training accuracy \nscore = model.evaluate(x_test, y_test, verbose=1)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(X.reshape(X.shape[0],10,2,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}