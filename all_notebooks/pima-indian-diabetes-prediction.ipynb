{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Welcome to my Prediction Modeling Notebook **\n\nBackground:\n\nThe goal of this notebook is to predict weather or not a Pima Indian will have diabetes, given certain characteristics. The Pima Indians have the highest prevalence of type 2 diabetes in the world, and well above the U.S. average. \n\nAccording to the U.S. Department of Health and Human Services, \"You are more likely to develop type 2 diabetes if you are age 45 or older, have a family history of diabetes, or are overweight or obese.\"\n\nMany of the participants are below the age of 45 (635 out of 768 participants, 83%), and accuratley predicting weather or not an individual will get type 2 diabetes early is vital to the individual's health.\n\n\n***\n\nFor prediction modeling, I will be using KNN and Logistic Regression\n\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Imports\nimport numpy as np \nimport pandas as pd \nimport sklearn\nimport os\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\n\n\nfrom sklearn.linear_model import LogisticRegression\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observing and Formatting Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Observing and Formatting Data\n\ndf = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\n\n# print(df.isnull().values.any())\n# No missing values, but any value that is 0 is a missing entry, \n# so we must take care of these values\n\n# I will replace  \" 0s \" with the mean\n\n# Percentage of missing values\n\n\n\n\ncolumns_remove_zero = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"\n                      ,\"DiabetesPedigreeFunction\"]\n\n\nfor column in columns_remove_zero:\n    \n    df[column] = df[column].replace(0, np.NaN)\n    column_mean = int (df[column].mean(skipna = True))\n    df[column] = df[column].replace(np.NaN, column_mean)\n    \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing Data\n\nplt.figure(figsize=(10,10))\nsns.heatmap(df.corr(), annot=True, annot_kws={'size':10}, cmap='coolwarm')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There does not appear to be any strong correlations between predictors or outcome variables, Glucose level seems to have the highest correlation with the outcome variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(df['Outcome'].value_counts(),autopct='%.2f')\nplt.legend(['Non-Diabetic','Diabetic'],loc='best', bbox_to_anchor=(1, 0, .5, 0.75))\nplt.title(\"Percentage Breakdown of Non-Diabetic and Diabetic Individuals\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction Modeling KNN Model**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First Prediction Model: K-nearest neighbor\n\nx=df.drop('Outcome',axis=1)\ny=df['Outcome']\n\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state=0, test_size = 0.2)\n\nsc_x = StandardScaler()\n\nx_train = sc_x.fit_transform(x_train)\nx_test = sc_x.fit_transform(x_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find optimal k value\n\nacc = []\n\nfor k in range(1, 51):\n    knnModel = KNeighborsClassifier(n_neighbors=k, p = 2, metric = 'euclidean')\n    \n    knnModel.fit(x_train, y_train)\n    y_pred = knnModel.predict(x_test)\n    acc.append(accuracy_score(y_test, y_pred))\n    \nmax_value = np.argmax(acc)    \nprint(max_value)    \nplt.plot(acc)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# p = number of classes (0 or 1 in this case) p = 2\nknnModel = KNeighborsClassifier(n_neighbors=32, p = 2, metric = 'euclidean')\n\n# Train Model\nknnModel.fit(x_train, y_train)\n\ny_pred_knnModel = knnModel.predict(x_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Confusion Matrix of the KNN Model - Code from https://github.com/DTrimarchi10/confusion_matrix\n\n\n\nconfMatrix = confusion_matrix(y_test, y_pred)\n# sns.heatmap(confMatrix, annot= True, cmap = 'Blues')\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                confMatrix.flatten()]\n\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     confMatrix.flatten()/np.sum(confMatrix)]\n\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(confMatrix, annot=labels, fmt = '', cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(f1_score(y_test, y_pred_knnModel))\n\nprint(accuracy_score(y_test, y_pred_knnModel))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression for Prediction**\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"logModel= LogisticRegression(solver='liblinear')\nlogModel.fit(x_train,y_train)\n\n\ny_pred_logModel = logModel.predict(x_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix of the Logistic Model\n\n# Code is relativley similar - Code from https://github.com/DTrimarchi10/confusion_matrix\n\nconfMatrix = confusion_matrix(y_test, y_pred_logModel)\n# sns.heatmap(confMatrix, annot= True, cmap = 'Blues')\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\n\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                confMatrix.flatten()]\n\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     confMatrix.flatten()/np.sum(confMatrix)]\n\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(confMatrix, annot=labels, fmt = '', cmap='Blues')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy and f1-score\n\n\nprint(f1_score(y_test, y_pred_logModel))\n\nprint(accuracy_score(y_test, y_pred_logModel))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}