{"cells":[{"metadata":{},"cell_type":"markdown","source":"<b style=\"color:blue\">K-Nearest Neighbors (KNN)</b> is one of the simplest algorithms used in Machine Learning for regression and classification problem. KNN algorithms use data and classify new data points based on similarity measures (e.g. distance function). Classification is done by a majority vote to its neighbors.\n\n<img src=\"https://blog.eduonix.com/wp-content/uploads/2018/08/KNN-algorithm.jpg\" alt=\"KNN\" >","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Step 1: Import Libraries #Import pandas,seaborn, and the usual libraries.\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 2: Load Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = pd.read_csv('../input/datasetknn/DataSetKNN.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the head (first 3) of the dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 3: Plot using seaborn Since this data is artificial, we'll just do a large pairplot with seaborn.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(datasets, hue='TARGET CLASS')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 4: Standardize the Variables Time to standardize the variables. Import StandardScaler from Scikit learn.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a StandardScaler() object called scaler.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit scaler to the features.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.fit(datasets.drop('TARGET CLASS', axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the .transform() method to transform the features to a scaled version.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_features = scaler.transform(datasets.drop('TARGET CLASS', axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert the scaled features to a dataframe and check the head of this dataframe to make sure the scaling worked.\ndf_feat = pd.DataFrame(scaled_features, columns = df.columns[:-1])\ndf_feat.head()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets_feat = pd.DataFrame(scaled_features, columns = datasets.columns[:-1])\ndatasets_feat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 5: Train Test Split Use train_test_split to split your data into a training set and a testing set.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = datasets_feat\ny = datasets['TARGET CLASS']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 6: Using KNN Import KNeighborsClassifier from scikit learn.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a KNN model instance with n_neighbors=1\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit this KNN model to the training data.\nknn.fit(X_train, y_train)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 7: Predictions and Evaluations Let's evaluate our KNN model! Use the predict method to predict values using your KNN model and X_test.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a confusion matrix and classification report.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, pred))\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 8: Choosing a K Value Let's go ahead and use the elbow method to pick a good K Value! Create a for loop that trains various KNN models with different k values, then keep track of the error_rate for each of these models with a list. Refer to the lecture if you are confused on this step.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nerror_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now create the following plot using the information from for loop.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nplt.plot(range(1,40),error_rate,color='blue',linestyle='dashed',marker='o',\nmarkerfacecolor='red', markersize='10')\nplt.xlabel('no. of K')\nplt.ylabel('Error Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 9: Retrain with new K Value Retrain your model with the best K value (up to you to decide what you want) and re-do the classification report and the confusion matrix.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 31)\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\nprint(confusion_matrix(y_test, pred))\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}