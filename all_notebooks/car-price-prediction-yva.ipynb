{"cells":[{"metadata":{"papermill":{"duration":0.029718,"end_time":"2020-10-26T12:46:41.276296","exception":false,"start_time":"2020-10-26T12:46:41.246578","status":"completed"},"tags":[]},"cell_type":"markdown","source":"#### Образовательная платформа: SkillFactory\n#### Специализация: Data Science\n#### Группа: DST-17\n### Юнит 6. Проект 5: \"Выбираем автомобиль правильно\"\n##### Выполнил: Владимир Юшманов\n\n<img src=\"https://raw.githubusercontent.com/vyushmanov/skillfactory_rds/master/module_6/choice_the_car.jpg\"/>\n\n# Прогнозирование стоимости автомобиля по характеристикам\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-10-26T12:46:41.400302Z","iopub.status.busy":"2020-10-26T12:46:41.399317Z","iopub.status.idle":"2020-10-26T12:46:42.581426Z","shell.execute_reply":"2020-10-26T12:46:42.580431Z"},"papermill":{"duration":1.219772,"end_time":"2020-10-26T12:46:42.581597","exception":false,"start_time":"2020-10-26T12:46:41.361825","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import re\nimport sys\nimport numpy as np\nimport pandas as pd\nimport pandas.api.types as at\nfrom tqdm import tqdm\nfrom datetime import timedelta, datetime, date\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True) \n\nimport xgboost as xgb\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import LabelEncoder\n\nimport myfunction as mf\n\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\n\n# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt\n\n# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 123\n\ndef mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.028837,"end_time":"2020-10-26T12:46:47.981435","exception":false,"start_time":"2020-10-26T12:46:47.952598","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Setup"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.05046Z","iopub.status.busy":"2020-10-26T12:46:48.049412Z","iopub.status.idle":"2020-10-26T12:46:48.052578Z","shell.execute_reply":"2020-10-26T12:46:48.051917Z"},"papermill":{"duration":0.039969,"end_time":"2020-10-26T12:46:48.052728","exception":false,"start_time":"2020-10-26T12:46:48.012759","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"VERSION    = 9\nDIR_TRAIN  = '../input/autoru/' # подключил к ноутбуку внешний датасет\nDIR_TEST   = '../input/sf-dst-car-price-prediction/'\nVAL_SIZE   = 0.20   # 20%","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.030254,"end_time":"2020-10-26T12:46:48.112586","exception":false,"start_time":"2020-10-26T12:46:48.082332","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 1. Данные"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.179769Z","iopub.status.busy":"2020-10-26T12:46:48.178918Z","iopub.status.idle":"2020-10-26T12:46:48.924574Z","shell.execute_reply":"2020-10-26T12:46:48.925184Z"},"papermill":{"duration":0.783211,"end_time":"2020-10-26T12:46:48.925418","exception":false,"start_time":"2020-10-26T12:46:48.142207","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!ls '../input'\n\ntrain = pd.read_csv(DIR_TRAIN+'all_auto_ru_2021-01-08.csv') # датасет для обучения модели\ntest = pd.read_csv(DIR_TEST+'test.csv')\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n\npd.set_option('display.max_columns', None)\ndisplay(train.head(2))\ndisplay(test.head(2))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.033402,"end_time":"2020-10-26T12:47:02.866506","exception":false,"start_time":"2020-10-26T12:47:02.833104","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 1.1. Исследование соответствия тренировочного и тестового наборов данных"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.941177Z","iopub.status.busy":"2020-10-26T12:47:02.94004Z","iopub.status.idle":"2020-10-26T12:47:02.94372Z","shell.execute_reply":"2020-10-26T12:47:02.943059Z"},"papermill":{"duration":0.042812,"end_time":"2020-10-26T12:47:02.943868","exception":false,"start_time":"2020-10-26T12:47:02.901056","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Введем признак разделения на тренировочную и тестовую выбороки - sample\ntrain['sample'] = 1\ntest['sample'] = 0\n\n# Оставим в train только актуальные предложения (удалим скрытые объявления)\ndf_train = train[train['hidden'] == False]\ndf_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  у участников найдена функция по сравнению дата-сетов. Немного преобразовал для удобства восприятия\ndef check_df_before_merg(d_df1,d_df2):\n    \n    list_of_names1 = list(d_df1.columns)\n    temp_dict = {}\n    temp_dict['feature_train'] = list_of_names1\n    temp_dict['type_train'] = d_df1.dtypes\n    temp_dict['sample_train'] = d_df1.loc[5].values\n    temp_dict['# unique_train'] = d_df1.nunique().values\n    temp_df1 = pd.DataFrame.from_dict(temp_dict)\n    \n    \n    list_of_names2 = list(d_df2.columns)\n    temp_dict2 = {}\n    temp_dict2['feature_test'] = list_of_names2\n    temp_dict2['type_test'] = d_df2.dtypes\n    temp_dict2['sample_test'] = d_df2.loc[5].values\n    temp_dict2['# unique_test'] = d_df2.nunique().values\n    temp_df2 = pd.DataFrame.from_dict(temp_dict2)\n    \n    temp_insert = pd.DataFrame(columns=['< - >'])\n    \n    temp_df = pd.concat([temp_df1,temp_insert, temp_df2], axis=1, sort=False)\n    temp_df.reset_index(inplace = True)\n    del temp_df['index']\n    temp_df['< - >'] = '| - |'\n    display(temp_df)\n\n    temp_dict3 = {}\n    temp_df3= pd.DataFrame(temp_df)\n    temp_list  = []\n    temp_list2  = []\n    temp_list3  = []\n    temp_list4  = []\n    temp_list5  = []\n\n    for i in range(len(temp_df)):\n        if str(temp_df3['type_train'][i]) != str(temp_df3['type_test'][i]):\n            temp_list.append(temp_df3['feature_train'][i])\n            temp_list2.append(temp_df3['feature_test'][i])\n            temp_list3.append(str(temp_df3['type_train'][i]) + ' != ' + str(temp_df3['type_test'][i]))\n            temp_list4.append(i)\n        if temp_df3['# unique_test'][i]>0 and temp_df3['# unique_train'][i]/temp_df3['# unique_test'][i] > 2:\n            temp_list5.append(i)\n            \n    temp_dict3['index']= temp_list4\n    temp_dict3['feature_train']= temp_list\n    temp_dict3['не совпадают типы'] = temp_list3\n    temp_dict3['feature_test']= temp_list2\n\n    temp_df4 = pd.DataFrame.from_dict(temp_dict3)\n    temp_df4.set_index('index',inplace=True)\n\n    print(f'Резюме:\\n 1. Не совпали типы в:= {len(temp_df4)} столбцах\\n')\n    print(f'2. Уникальные значения различаются в:= {len(temp_list5)} столбцах {temp_list5}')\n    display(temp_df4)\n\n# После нескольких запусков выявили список столбцов, не полезных в дальнейшей работе\n# Это признаки, имеющие единственное значение, признаки не имеющие пары в обучающем и тестовом датасетах, признаки, \n# содержащие консолидированную информацию, уже сохраненную в других признаках\n\ndrop_cols = ['car_url', 'sell_id', 'image', 'hidden', 'parsing_unixtime', 'Состояние']\n\nfor col in drop_cols:\n    if col in list(df_train.columns):\n        df_train.drop(columns=[col], inplace=True)\n    if col in list(df_test.columns):\n        df_test.drop(columns=[col], inplace=True)\n    \ncheck_df_before_merg(df_train, df_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2. Стандартизация данных\nПриведение форматов и значений признаков тренировочной выборки к виду, принятому в тестовой выборке\n\n### 1.2.1. bodyType\nПроизведем укрупнение признаков в тренировочных данных до уровня, принятого в тестовой выборке"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['body_type'] = [str(x).lower().replace('.', '') for x in df_test['bodyType']]\ndf_train['body_type'] = [str(x).lower() for x in df_train['bodyType']]\n\n# Заменим длинные типы в train'е на обобщенные значения\nbody_type_list = list(df_test['body_type'].unique())\ndef get_perf_type(x, body_type_list):\n    for t in body_type_list:\n        if t in x:\n            return t\n        else: continue\n    else: return '0'\n    \ndf_train['body_type'] = df_train['body_type'].apply(lambda x: get_perf_type(x, body_type_list))\n\n# Удалим 7 предложений, для которых не нашлось соответствия типа кузова\ndf_train = df_train[df_train['body_type']!='0']\ndf_train.drop(columns=['bodyType'], inplace=True)\ndf_test.drop(columns=['bodyType'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.2. \n\nТренировочный датасет содержит 36 марок. В тестовой выборке только 12: 'SKODA', 'AUDI', 'HONDA', 'VOLVO', 'BMW', 'NISSAN', 'INFINITI',\n       'MERCEDES', 'TOYOTA', 'LEXUS', 'VOLKSWAGEN', 'MITSUBISHI'\n### 1.2.3. color\nПриведем обозначение цвета к "},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_color = {'040001':'чёрный', 'EE1D19':'красный', '0000CC':'синий', \n              'CACECB':'серебристый', '007F00':'зелёный', 'FAFBFB':'белый', \n              '97948F':'серый', '22A0F8':'голубой', '660099':'пурпурный', \n              '200204':'коричневый', 'C49648':'бежевый', 'DEA522':'золотистый', \n              '4A2197':'фиолетовый', 'FFD600':'жёлтый', 'FF8649':'оранжевый', \n              'FFC0CB':'розовый'}\ndf_train['color'] = df_train['color'].map(dict_color)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.4. complectation_dict\nВероятность использования признака мала. Его содержание повторяет другие признаки.\n### 1.2.5. description\nОписание технического состояния ТС, выполненное продавцом. Без применения анализа текстов признак не применим.\n### 1.2.6. engineDisplacement\nТтребуется удаление символов 'LTR' в тестовой выборке."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['engineDisplacement'] = df_test['engineDisplacement'].apply(lambda x: str(x).replace('LTR', ''))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.7. enginePower"},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern = re.compile('^(\\d+)\\.*')\ndf_test['enginePower'] = df_test['enginePower'].apply(lambda x: int(str(pattern.findall(x))[2:-2]))\ndf_train['enginePower'] = df_train['enginePower'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.8. equipment_dict\nПока оставим в качестве резервного источника информации. Поименение в модели без обработки невозможно.\n### 1.2.9. fuelType\nПреобразований не требуется\n### 1.2.10. mileage\nПреобразований не требуется\n### 1.2.11. modelDate\nЗаполним пропуски значением 0 и поправим формат в тренировочных данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['modelDate'] = df_train['modelDate'].fillna(0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.12. model_name\nНе требует преобразований\n### 1.2.13. name\nРезервный источник данных\n### 1.2.14. numberOfDoors\nЗаполним пропуски значением 0 и поправим формат в тренировочных данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['numberOfDoors'] = df_train['numberOfDoors'].fillna(0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.15. priceCurrency"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['priceCurrency'] = df_train['priceCurrency'].map({'RUR':'RUB'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.16. productionDate\nНе требует преобразований\n### 1.2.17. super_gen\nПока оставим в качестве резервного источника информации. Поименение в модели без обработки невозможно.\n### 1.2.18. vehicleConfiguration\nПока оставим в качестве резервного источника информации. Поименение в модели без обработки невозможно.\n### 1.2.19. vehicleTransmission\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['vehicleTransmission'] = df_train['vehicleTransmission'].map({'AUTOMATIC':'автоматическая', 'MECHANICAL':'механическая',\n                                                                 'ROBOT':'роботизированная', 'VARIATOR':'вариатор'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.20. vendor\nНе требует преобразований\n### 1.2.21. Владельцы"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Владельцы'] = df_train['Владельцы'].map({4.0:'3 или более', 3.0:'3 или более', 2.0:'2\\xa0владельца', 1.0:'1\\xa0владелец'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.22. Владение"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_delta_ouned(x):\n    if x['year'] > 0:\n        now = datetime.now()\n        return (now.year - x['year'])*12 - x['month'] + now.month\n    else: return 0\n\ndf_temp = pd.DataFrame(df_train['Владение'])\npattern = re.compile('\\d{4}')\ndf_temp['year'] = df_temp['Владение'].apply(lambda x:str(pattern.findall(str(x)))[2:-2])\npattern = re.compile('(\\d{1,2})\\}$')\ndf_temp['month'] = df_temp['Владение'].apply(lambda x:str(pattern.findall(str(x)))[2:-2])\ndf_temp['year'] = df_temp['year'].map(lambda x: int(x) if len(x)==4 else 0)\ndf_temp['month'] = df_temp['month'].map(lambda x: int(x) if len(x)>0 else 0)\ndf_temp['delta_own'] = df_temp.apply(lambda x: calc_delta_ouned(x), axis=1)\ndf_train['ownership'] = df_temp['delta_own']\n\ndf_temp = pd.DataFrame(df_test['Владение'])\npattern = re.compile('^\\d{1,2}')\ndf_temp['year'] = df_temp['Владение'].apply(lambda x:str(pattern.findall(str(x)))[2:-2])\npattern = re.compile('и\\s(\\d{1,2})\\sм')\ndf_temp['month'] = df_temp['Владение'].apply(lambda x:str(pattern.findall(str(x)))[2:-2])\ndf_temp['year'] = df_temp['year'].map(lambda x: int(x) if len(x)>0 else 0)\ndf_temp['month'] = df_temp['month'].map(lambda x: int(x) if len(x)>0 else 0)\ndf_temp['delta_own'] = df_temp.apply(lambda x: x['year']*12 + x['month'], axis=1)\ndf_test['ownership'] = df_temp['delta_own']\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.23. ПТС"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['ПТС'] = df_train['ПТС'].map({'ORIGINAL':'Оригинал', 'DUPLICATE':'Дубликат'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.24. Привод\nНе требует преобразований\n### 1.2.25. Руль"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Руль'] = df_train['Руль'].map({'RIGHT':'Правый', 'LEFT':'Левый'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2.26. Таможня"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Таможня'] = df_train['Таможня'].map({True: 'Растаможен', False:'Не растаможен'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3. Удаление строк с пропусками"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:03.025049Z","iopub.status.busy":"2020-10-26T12:47:03.024167Z","iopub.status.idle":"2020-10-26T12:47:03.134429Z","shell.execute_reply":"2020-10-26T12:47:03.133689Z"},"papermill":{"duration":0.156124,"end_time":"2020-10-26T12:47:03.134605","exception":false,"start_time":"2020-10-26T12:47:02.978481","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df_train.dropna(subset=['productionDate','mileage'], inplace=True)\ndf_train.dropna(subset=['price'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.4. Объединение \"лишних\" марок в признаке brand"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразование привело к снижению результата на 0.03\n\n#target_brand = df_test['brand'].unique().tolist()\n#df_train['brand'] = df_train['brand'].map(lambda x: x if x in target_brand else 'OTHER')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.5. Контроль соответствия форматов выборок и объединение"},{"metadata":{"trusted":true},"cell_type":"code","source":"check_df_before_merg(df_train, df_test)\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) \nmf.brief_summary(data, [100,75,75,75,75,75,150])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Дополнение и фильтрация признаков\n## 2.1. Исправление признака engineDisplacement\nПри парсинге тренировочной выборки была допущена ошибка и в признак engineDisplacement попали не корректные значения. Исправим ситуацию, использовав данные из признака name. Также выделим из name информацию об автмобилях с гибридной силовой установкой"},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern = re.compile('(\\d{1}\\.\\d{1})')\ndata['engine'] = data['name'].apply(lambda x:str(pattern.findall(str(x)))[2:5])\ndata['engine'] = pd.to_numeric(data['engine'], errors='coerce')\ndata['hybrid'] = data['name'].apply(lambda x: 1 if 'hyb' in x else 0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Тип продавца\nИсточником косвенной информации о типе продавца является аннотация к объявлению о продаже, сосредоточенная в признаке description. Исползуем проверку по ключевым словам для установления типа продавца."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['description'] = data['description'].map(lambda x: str(x).lower())\n\ndata['owner'] = data['description'].apply(lambda x: 1 if 'торг' in x or 'не нуждаюсь' in x or len(x)<200 else 0)\ndata['showroom'] = data['description'].apply(lambda x: 1 if 'traid-in' in x or 'дилер' in x or 'в кредит' in x or 'клиент' in x\n                                             or 'без комис' in x or 'страховани' in x or 'трейд-ин' in x \n                                             or 'в наличии' in x or 'выгодное пр' in x or 'автокредит' in x else 0)\ndisplay(data['owner'].value_counts())\ndisplay(data['showroom'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3. Период владения"},{"metadata":{"trusted":true},"cell_type":"code","source":"share = np.around(data['ownership'].value_counts()[0]/len(data)*100, 1)\nprint(f'Доля пустых значений признака продолжительности владения - {share}%')\n# Пока не будем ничего предпринимать в отношении этого признака","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4. Удаление технических столбцов"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['complectation_dict', 'description', 'equipment_dict', 'engineDisplacement'\n             ,'model_info', 'super_gen', 'vehicleConfiguration', 'Владение', 'name'\n             ,'priceCurrency', 'Таможня']\ndata.drop(columns=drop_cols, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.5. Заполнение пропусков"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отсутствие количества владельцев указывает на то, что автомобиль новый. Подставляем 0\ndata['Владельцы'].fillna('Новый', inplace=True)\n# Пропуск данных о ПТС заполним значением 'Оригинал'\ndata['ПТС'].fillna('Оригинал', inplace=True)\n# Пропуск данных о рабочем объеме ДВС возникают исключитлеьно у электромобилей. Подставляем 0\ndata['engine'].fillna(0, inplace=True)\nmf.brief_summary(data, [100,75,75,75,75,75,150])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.6. Сортировка признаков по типам"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sort_features(df_raw, target_cols, time_cols, num_cols, bin_cols, cat_cols, count_col):\n    for col in df_raw.columns:\n        if col in target_cols or col in time_cols or col in num_cols\\\n            or col in bin_cols or col in cat_cols or col in count_col:\n            continue\n        elif len(df_raw[col].value_counts()) == 1:\n                df_raw.drop(columns=[col], inplace=True)\n        elif at.is_datetime64_any_dtype(df_raw[col]):\n            time_cols.append(col)\n        elif at.is_numeric_dtype(df_raw[col]):\n            if len(df_raw[col].value_counts()) == 2:\n                bin_cols.append(col)\n            else: num_cols.append(col)\n        elif at.is_string_dtype(df_raw[col]):\n            cat_cols.append(col)\n        else: print(f'Столбец {col} не был причислен ни к одной категории\\n'+'_'*50)\n\n    print_cols_lists(df_raw, target_cols, time_cols, num_cols, bin_cols, cat_cols, count_col)\n\n    return target_cols, time_cols, num_cols, bin_cols, cat_cols, count_col\n\ndef print_cols_lists(df, target_cols, time_cols, num_cols, bin_cols, cat_cols, count_col):\n    print('\\nКлючевые признаки: ', target_cols)    \n    print('\\nПризнаки даты или времени: ', time_cols)    \n    print('\\nКатегориальные признаки: ', cat_cols)    \n    print('\\nБинарные признаки: ', bin_cols)    \n    print('\\nКоличественные признаки: ', num_cols)    \n    print('\\nПризнаки-счетчики: ', count_col)    \n\n    print('\\nВ датасете: строк - ', len(df), 'колонок - ', len(df.columns))\n\n\ntarget_cols = ['price']\nnum_cols, bin_cols, cat_cols, time_cols, count_col = [], [], [], [], []\n\ntarget_cols,time_cols,num_cols,bin_cols,cat_cols,count_col = sort_features(data\n                                                                           ,target_cols,time_cols\n                                                                           ,num_cols,bin_cols\n                                                                           ,cat_cols,count_col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.7. Оценка степени влияния признаков на целевые переменные"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    df_temp = mf.get_label_encoder(data, col, False)\nmf.view_important_sign(df_temp, num_cols, bin_cols, cat_cols, 'price')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Предподготовка данных\n## 3.1. Стандартизация"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = mf.normalisation(data, MinMaxScaler(), target_cols + cat_cols)\ndisplay(data.head(1))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.033657,"end_time":"2020-10-26T12:47:03.29162","exception":false,"start_time":"2020-10-26T12:47:03.257963","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3.2. Label Encoding"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:03.489637Z","iopub.status.busy":"2020-10-26T12:47:03.483022Z","iopub.status.idle":"2020-10-26T12:47:03.549376Z","shell.execute_reply":"2020-10-26T12:47:03.548539Z"},"papermill":{"duration":0.10809,"end_time":"2020-10-26T12:47:03.549533","exception":false,"start_time":"2020-10-26T12:47:03.441443","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"for colum in cat_cols:\n    data[colum] = data[colum].astype('category').cat.codes\ndisplay(data.head(1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3. Генерируем полиномиальные признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Результат применения неудовлетворительный. Рост MAPE при тестировании на 1%\n\n#pf = PolynomialFeatures(2)\n#poly_df = pf.fit_transform(data[num_cols])\n#poly_df = pd.DataFrame(poly_df)\n#poly_df = poly_df.drop(0, axis=1)\n#data = pd.concat([data, poly_df],axis=1)\n#data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.4. Поэлементный контроль"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:03.6352Z","iopub.status.busy":"2020-10-26T12:47:03.633973Z","iopub.status.idle":"2020-10-26T12:47:03.646722Z","shell.execute_reply":"2020-10-26T12:47:03.645899Z"},"papermill":{"duration":0.06183,"end_time":"2020-10-26T12:47:03.646867","exception":false,"start_time":"2020-10-26T12:47:03.585037","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndisplay(data.sample(3).head(1))\ndisplay(data.describe())","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:03.727044Z","iopub.status.busy":"2020-10-26T12:47:03.725742Z","iopub.status.idle":"2020-10-26T12:47:03.753844Z","shell.execute_reply":"2020-10-26T12:47:03.753001Z"},"papermill":{"duration":0.071275,"end_time":"2020-10-26T12:47:03.754","exception":false,"start_time":"2020-10-26T12:47:03.682725","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X = data.query('sample == 1').drop(['sample', 'price'], axis=1)\ny = data.query('sample == 1')['price'] \nX_sub = data.query('sample == 0').drop(['sample', 'price'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.035737,"end_time":"2020-10-26T12:47:03.826552","exception":false,"start_time":"2020-10-26T12:47:03.790815","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3.5. Разделение датасета"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:03.90948Z","iopub.status.busy":"2020-10-26T12:47:03.908518Z","iopub.status.idle":"2020-10-26T12:47:03.923409Z","shell.execute_reply":"2020-10-26T12:47:03.922602Z"},"papermill":{"duration":0.059208,"end_time":"2020-10-26T12:47:03.923564","exception":false,"start_time":"2020-10-26T12:47:03.864356","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_learn_report(start, y_test, y_pred):\n    print('\\nВремя выполнения - ', datetime.now() - start)\n    print(f\"Точность по метрике MAPE:{(mape(y_test, y_pred))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Наивная модель\nЭта модель будет предсказывать среднюю цену по рабочему объему двигателя. \nC ней будем сравнивать другие модели.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train = X_train.copy()\ntmp_train['price'] = y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Находим median по экземплярам engineDisplacement в трейне и размечаем тест\npredict = X_test['engine'].map(tmp_train.groupby('engine')['price'].median())\n\n#оцениваем точность\nprint(f\"Точность наивной модели по метрике MAPE: {(mape(y_test, predict.values))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.037164,"end_time":"2020-10-26T12:47:03.997616","exception":false,"start_time":"2020-10-26T12:47:03.960452","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 4.2. CatBoost\n![](https://pbs.twimg.com/media/DP-jUCyXcAArRTo.png:large)   \n\n\n### 4.2.1. Линейные данные"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:04.256865Z","iopub.status.busy":"2020-10-26T12:47:04.248328Z","iopub.status.idle":"2020-10-26T12:48:12.17834Z","shell.execute_reply":"2020-10-26T12:48:12.17762Z"},"papermill":{"duration":67.991521,"end_time":"2020-10-26T12:48:12.178488","exception":false,"start_time":"2020-10-26T12:47:04.186967","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nmodel = CatBoostRegressor(iterations = 50,\n                          cat_features=cat_cols,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          silent=True,\n                         )\nmodel.fit(X_train, y_train,\n         eval_set=(X_test, y_test),\n         use_best_model=True,\n         verbose=False,\n         plot=True\n         )\n\nmodel.save_model('catboost_model.model')\n\npredict = model.predict(X_test)\nprint_learn_report(start, y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для 5000 итераций:\nВремя выполнения -  0:09:43.214411\nТочность по метрике MAPE:12.89%\n### 4.2.2. Логарифмирование целевой переменной и подбор наилучших параметров\nПопробуем взять таргет в логорифм - это позволит уменьшить влияние выбросов на обучение модели (используем для этого np.log и np.exp).    "},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\n\n\nmodel = CatBoostRegressor(cat_features=cat_cols, iterations=50\n                          ,loss_function='MAPE', metric_period=10)\n\ngrid = {'learning_rate': [ 0.13, 0.14, 0.15]\n        ,'depth': [12]\n        ,'l2_leaf_reg': [7, 7.5, 8]\n        ,'random_strength': [0.3]}\n\n#grid_search_result = model.grid_search(grid\n#                                     ,X=X_train\n#                                     ,y=np.log(y_train)\n#                                     ,plot=True\n#                                     ,verbose=False)\n#print('\\nВремя выполнения - ', datetime.now() - start)\n#print('\\nНаилучшие параметры: ', grid_search_result['params'])\n\n\ncb = CatBoostRegressor(iterations = 5000,\n                       random_seed = RANDOM_SEED,\n                       eval_metric='MAPE',\n                       custom_metric=['R2', 'MAE'],\n                       silent=True,\n                       learning_rate=0.13, depth=12,\n                       l2_leaf_reg=8, random_strength=0.3)\n\n#cb.fit(X_train, np.log(y_train),\n#         eval_set=(X_test, np.log(y_test)),\n#         verbose=False,\n#         use_best_model=True,\n#         plot=True)\n\n#cb.save_model('catboost_log_model.model')\n\n#predict_test = np.exp(cb.predict(X_test))\n#print_learn_report(start, y_test, predict_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Время выполнения -  0:08:29.342993\n\nТочность по метрике MAPE:10.88%\n\n## 4.3. Random Forest\nОпределим лучшие параметры и обучим на них модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nrandom_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)],\n               'max_features': ['auto', 'sqrt'],\n               'max_depth': [int(x) for x in np.linspace(5, 15, num = 6)] + [None],\n               'min_samples_split': [2, 5, 10],\n               'min_samples_leaf': [1, 2, 4],\n               'bootstrap': [True, False]}\n\n#rfr = RandomForestRegressor(random_state = RANDOM_SEED)\n#rf_random = RandomizedSearchCV(estimator = rfr, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=10, random_state=RANDOM_SEED, n_jobs = -1)\n#rf_random.fit(X_train, np.log(y_train))\n#rf_random.best_params_\n\n#best_params_: \n#{'n_estimators': 300,\n# 'min_samples_split': 2,\n# 'min_samples_leaf': 1,\n# 'max_features': 'sqrt',\n# 'max_depth': None,\n# 'bootstrap': False}\n\n#best_rfr = rf_random.best_estimator_\nbest_rfr = RandomForestRegressor(random_state=RANDOM_SEED\n                      , n_estimators=300\n                      , min_samples_split=2\n                      , min_samples_leaf=1\n                      , max_features='sqrt'\n                      , max_depth=None\n                      , bootstrap=False)\n\n#best_rfr.fit(X_train, np.log(y_train))\n\n\n#predict_rfr = np.exp(best_rfr.predict(X_test))\n#print_learn_report(start, y_test, predict_rfr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Время выполнения -  0:00:52.179295\n\nТочность по метрике MAPE:10.96%\n\n## 4.4. Gradient Boosting Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nrandom_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 400, num = 8)],\n               'max_features': ['auto', 'sqrt', 'log2'],\n               'max_depth': [int(x) for x in np.linspace(5, 15, num = 6)] + [None],\n               'min_samples_split': [2, 5, 10],\n               'min_samples_leaf': [1, 2, 4]}\n\n#gbr = GradientBoostingRegressor()\n#gbr_random = RandomizedSearchCV(estimator = gbr, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=10, random_state=RANDOM_SEED, n_jobs = -1)\n#gbr_random.fit(X_train, np.log(y_train))\n#gbr_random.best_params_\nbest_gbr = GradientBoostingRegressor(random_state=RANDOM_SEED\n                      , n_estimators=800\n                      , min_samples_split=5\n                      , min_samples_leaf=4\n                      , max_features='sqrt'\n                      , max_depth=9)\n#best_gbr.fit(X_train, np.log(y_train))\n\n#predict_gbr = np.exp(best_gbr.predict(X_test))\n#print_learn_report(start, y_test, predict_gbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Время выполнения -  0:01:03.301634\n\nТочность по метрике MAPE:10.87%\n\n## 4.5. XGB Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nxgb_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.5,\n                          learning_rate=0.05, max_depth=12, alpha=1,\n                          n_estimators=1000)\n#xgb_reg.fit(X_train, np.log(y_train))\n#xgb_red_pred = np.exp(xgb_reg.predict(X_test))\n#print_learn_report(start, y_test, xgb_red_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Время выполнения -  0:00:58.151827\n\nТочность по метрике MAPE:10.53%\n\n# 5. Бэггинг\n## 5.1. Со случайным лесом"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nbagg_rfr = BaggingRegressor(best_rfr, n_estimators=3, n_jobs=1, random_state=RANDOM_SEED)\n#bagg_rfr.fit(X_train, np.log(y_train))\n#predict_bagg_rfr = np.exp(bagg_rfr.predict(X_test))\n#print_learn_report(start, y_test, predict_bagg_rfr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Время выполнения -  0:01:35.995616\n\nТочность по метрике MAPE:11.24%\n\n## 5.2. С градиентным бустингом"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nbagg_gbr = BaggingRegressor(best_gbr, n_estimators=3, n_jobs=1, random_state=RANDOM_SEED)\n#bagg_gbr.fit(X_train, np.log(y_train))\n#predict_bagg_gbr = np.exp(bagg_gbr.predict(X_test))\n#print_learn_report(start, y_test, predict_bagg_gbr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Время выполнения -  0:01:47.575827\n\nТочность по метрике MAPE:10.73%\n\n## 5.3. С xgb"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nbagg_xgb = BaggingRegressor(xgb_reg, n_estimators=3, n_jobs=1, random_state=RANDOM_SEED)\n#bagg_xgb.fit(X_train, np.log(y_train))\n#predict_bagg_xgb = np.exp(bagg_xgb.predict(X_test))\n#print_learn_report(start, y_test, predict_bagg_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Время выполнения -  0:02:35.895540\n\nТочность по метрике MAPE:10.62%\n\nВ результате применения бэггинга улучшены результаты для Gradient Boosting Regressor. Результаты Random Forest Regressor и XGB Regressor снизились.\n\n# 6. Стеккинг. Ансамбли моделей"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = datetime.now()\n\nestimators=[('b_gbr', BaggingRegressor(GradientBoostingRegressor(random_state=RANDOM_SEED\n                                                                ,n_estimators=800\n                                                                ,min_samples_split=5\n                                                                ,min_samples_leaf=4\n                                                                ,max_features='sqrt'\n                                                                ,max_depth=9)\n                                        ,n_estimators=3\n                                        ,n_jobs=1\n                                        ,random_state=RANDOM_SEED))\n            ,('xgb', xgb.XGBRegressor(objective='reg:squarederror'\n                                      ,colsample_bytree=0.5\n                                      ,learning_rate=0.05\n                                      ,max_depth=12\n                                      ,alpha=1\n                                      ,n_estimators=1000))]\n\nst_ensemble = StackingRegressor(estimators=estimators\n                                ,final_estimator = CatBoostRegressor(iterations = 5000\n                                                                     ,random_seed = RANDOM_SEED\n                                                                     ,eval_metric='MAPE'\n                                                                     ,custom_metric=['R2', 'MAE']\n                                                                     ,silent=True\n                                                                     ,learning_rate=0.13\n                                                                     ,depth=12\n                                                                     ,l2_leaf_reg=8\n                                                                     ,random_strength=0.3))\n\n    \nst_ensemble.fit(X_train, np.log(y_train))\n\npredict_ensemble = np.exp(st_ensemble.predict(X_test))\nprint_learn_report(start, y_test, predict_ensemble)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"st_ensemble.fit(X, np.log(y))\n\npredict_submission = np.round(np.exp(st_ensemble.predict(X_sub)),-3)\npredict_submission ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:48:13.227584Z","iopub.status.busy":"2020-10-26T12:48:13.226285Z","iopub.status.idle":"2020-10-26T12:48:13.762529Z","shell.execute_reply":"2020-10-26T12:48:13.763259Z"},"papermill":{"duration":0.628302,"end_time":"2020-10-26T12:48:13.763488","exception":false,"start_time":"2020-10-26T12:48:13.135186","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"sample_submission['price'] = predict_submission * k\nsample_submission.to_csv(f'submission_v{VERSION}.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.087712,"end_time":"2020-10-26T12:48:14.104388","exception":false,"start_time":"2020-10-26T12:48:14.016676","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# What's next?\nЧто еще можно сделать, чтобы улучшить результат:\n\n* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n* Попробовать другие алгоритмы и библиотеки ML\n* Использование Blending & Stacking не принесло ожидаемого улучшеня качества предсказани. Наилучший результат имело применение Random Forest с регуляризацией."},{"metadata":{},"cell_type":"markdown","source":"Подробный чек лист: https://docs.google.com/spreadsheets/d/1I_ErM3U0Cs7Rs1obyZbIEGtVn-H47pHNCi4xdDgUmXY/edit?usp=sharing"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}