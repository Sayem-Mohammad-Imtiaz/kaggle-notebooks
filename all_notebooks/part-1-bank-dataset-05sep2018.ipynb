{"cells":[{"metadata":{"_uuid":"64623c100403d47171866b2bbfd5ed512f78f680"},"cell_type":"markdown","source":"<a href = '#Basics'>1. Basics</a><br>\n<a href = '#LoadData'>1. a. Load Data</a><br>\n<a href = '#DataTypes'>1. b. Data Types</a><br>\n<br>\n<a href = '#Plots'>2. Plots</a><br>\n<a href = '#Univariate'>2.a. Univariate</a><br>\n<a href = '#Bivariate'>2.b. Bivariate</a><br>\n<br>\n<a href = '#PredictiveModelingStarts'>3. Predictive Modeling Starts</a><br>\n<a href = '#Logistic'>3.a. 1st model - Logistic</a><br>\n<a href = '#RandomForest'>3.b. Random Forest</a><br>\n<br>\n<a href = '#OverVsUnderFitting'>4. Over Vs Underfitting</a><br>\n<a href = '#BiasVsVariancec'>4.a. Bias Vs Variance</a><br>\n<a href = '#ValidationSet'>4.b. Validation Set</a><br>\n<br>\n<br>\n<a href = '#EvaluationMetrics'>5. Evaluation Metrics</a><br>\n<a href = '#Accuracy'>5.a. Accuracy</a><br>\n<a href = '#PrecisionRecallF1'>5.b. Precision, Recall, F1</a><br>\n<a href = '#AUCROC'>5.c. AUC-ROC</a><br>\n<br>"},{"metadata":{"_uuid":"c87d8e19d00e1464e01270621e6237f10ec1133a"},"cell_type":"markdown","source":"<a id = 'Basics'>1.Basics</a><br>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5a5011b9cefdc6bccf0330c0be9938bf2b184b6"},"cell_type":"markdown","source":"<a id = '#LoadData'>1. a. Load Data</a><br>"},{"metadata":{"trusted":true,"_uuid":"16b57451fadcd500b514160ebd0c0aa6c10af62a"},"cell_type":"code","source":"#read the data","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_data = pd.read_csv('../input/bank.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3767d1990d22bae90f5c0156fef7f8bf02f2fd1"},"cell_type":"code","source":"#kick start things - check the num rows and cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21d2b2857c1645f4d68325cc3516ddd669ed48bc"},"cell_type":"code","source":"print(input_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f621a3acc6be6e779e9949264353f4580dd6bea"},"cell_type":"code","source":"#there are 11,162 rows and 17 cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20078cd23d3a1fc3fca7d4f16925ab0bc23b1f61"},"cell_type":"code","source":"#next is to know more about the 17 cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac3fb7b8ba0ed5ad594a17907c5a5a4baebda083"},"cell_type":"code","source":"input_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c7e5f803035b27b24afe980e2479d7d9909c2b8"},"cell_type":"code","source":"# we can see that there are no null values in the dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e302b54341b429f4cb160d30a8093fddae8346a8"},"cell_type":"markdown","source":"\n<a href = '#DataTypes'>1. b. Data Types</a><br>\nwe can see that there are object and int datatypes"},{"metadata":{"trusted":true,"_uuid":"c9ebae8423b9b709792e6f51fdaa2e123fee6be9"},"cell_type":"code","source":"#get more details about the dataset\ninput_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85d18f2f49a2816b6d5f9cd9bb306e6bceedfc51"},"cell_type":"code","source":"plt.hist(data=input_data, x='duration', range=(0,2000))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cd941b49bb1fa04ab7b49b5e16ecb1a8cfd2110"},"cell_type":"code","source":"plt.boxplot(input_data['duration'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08a998d10978bd2c37fdf9c87844d0564e2e3407"},"cell_type":"code","source":"input_data.deposit.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b5b8136b82786f8816d4a9c4f4e2d4772af44e1"},"cell_type":"markdown","source":"<a id = 'Plots'> 2. Plots</a>"},{"metadata":{"trusted":true,"_uuid":"5185ecd6983a4b71f3c2cf21f5028da8fd736a1b"},"cell_type":"markdown","source":"<a id = 'Univariate'>2.a. Univariate </a>\n"},{"metadata":{"trusted":true,"_uuid":"81c72cb5b3ae0d2bf8f0a96b695a62ad58275642"},"cell_type":"code","source":"#simplest way to start is to plot the histogram of each variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23f7bfa39b89450ca8cf61d6a8edda303b98cacc"},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edbcdee3d9c7ae0076e2bb1289aca9513042fad0"},"cell_type":"code","source":"plt.hist(input_data['balance'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"219a7bd2f1065768f3f0da8b9ee766c1b7a4e45c"},"cell_type":"code","source":"plt.hist(input_data['balance'], bins = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53bb79d45f32fb4e4b44919df9f27a4a4cf100b1"},"cell_type":"code","source":"plt.hist(input_data[input_data['balance'] <= 30000]['balance'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5d7acd674a9d6e75249d223d8c05e13d7f1824f"},"cell_type":"code","source":"plt.boxplot(input_data['balance'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a1db044f7af4aae0bfed121739c84d172d57ad6"},"cell_type":"code","source":"plt.boxplot(input_data[input_data['balance'] <= 10000]['balance'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11fdbf75ad1ecdf1ca9d8519abf34bd97abc4f71"},"cell_type":"code","source":"input_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dd31cf2a81fe366110298ec19d827189b107dd8"},"cell_type":"code","source":"input_data['job'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baa78b1f81dda6f42d0577a2133283b27210aa35"},"cell_type":"code","source":"input_data.hist(bins=10, figsize=(14,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d77e881e2990442c1c630e0856ae58fc64964a65"},"cell_type":"markdown","source":"we see some interesting patterns here. But, we also note that there are a few variables for which the number of bins doesn't bring out the distribution clearly. For e.g., balance, campaign, previous. The reason for this is that there are a few outliers in these variables"},{"metadata":{"trusted":true,"_uuid":"b6e03a632fca143c0d0c6f9b9af716bb1cbd793c"},"cell_type":"code","source":"#let's take one of them and plot a hist with larger bin size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2567d52e3d3dcf60e834756cc0b843ed3e19379d"},"cell_type":"code","source":"plt.hist(input_data['balance'], bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d63c4f59e803f91c255197dd6b1740a8ca60c462"},"cell_type":"code","source":"#let's plot the boxplot for a not-so-skewed variable to understand boxplot better\nplt.boxplot(input_data['age'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98c9491edec257a9215b10bfe5a4cd7a73ff9e0a"},"cell_type":"markdown","source":"#the first horizontal line is 1 percentile,<br>\nstart of box is 25 percentile<br>\nmiddle  of box (red line) is 50 percentile<br>\nend  of box is 75 percentile<br>\nthe last horizontal line is 99 percentile,<br>\n\n# so, anything beyond the last horizontal line can be seen as an outlier<br>\nin this case, we will say that anything beyond 75 years is an outlier in age\n"},{"metadata":{"trusted":true,"_uuid":"c569482b3c057739c302e8735363bdb49f6cb6e2"},"cell_type":"code","source":"# boxplot to find more about the outliers\nplt.boxplot(input_data['balance'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03bf84d65d2132a9286510941c3e3cfd614d14b4"},"cell_type":"code","source":"#we can limit the balance value to 20K and plot a hist\nplt.hist(input_data['balance'][input_data['balance'] < 20000], bins =20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ed14be43b1ccb0d2dca2e92aa315f5365dd30bd"},"cell_type":"code","source":"#we can continue to refine this further as we see fit; let's move to next topic","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0787d84b85f54df2af707410cfafca64baa060ab"},"cell_type":"markdown","source":"# univariate for discrete variables\nyou would have noticed that the histogram is only for integer (numeric) variables. <br>\nFor categorical (object) variables we can do value counts to understand them better"},{"metadata":{"trusted":true,"_uuid":"4ebc832a6dbe1bcae1d72b606c620810922ff5ec"},"cell_type":"code","source":"input_data['marital'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"052531cdbf683ecfbb42a196f373ece975b27d02"},"cell_type":"code","source":"plt.bar(input_data['marital'].value_counts().keys(), input_data['marital'].value_counts().values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b5f998057d83e2f506f641bb7077289a1b1073a"},"cell_type":"markdown","source":"#dont get thrown off by the new constructs you see in the code above;<br>\nthe plt.bar function takes two arrays - one for the x axis and the other for the values in y axis <br>\nvalue_counts() outputs a dict; we provide that through the keys and values parameter <br>"},{"metadata":{"_uuid":"b9a3b9e2a758d7c6c0804076942ef2e295b2b469"},"cell_type":"markdown","source":"# can you plot the univariate for other categorical fields?"},{"metadata":{"_uuid":"d9970365b3fef57380a624b2c2838cd572a6e877"},"cell_type":"markdown","source":"**<a id = 'Bivariate'>2.b. Bivariate </a>**"},{"metadata":{"_uuid":"761d2278e3782842028388012f05562d3809eee1"},"cell_type":"markdown","source":"bivariate plot- as the name suggests are plots of one variable vs another<br>\nthe simplest bivariate plot can be a scatter plot"},{"metadata":{"trusted":true,"_uuid":"4415784bae5d10b2d8661de4cb736659e37eb5ed"},"cell_type":"code","source":"input_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed4a82af2a2e9077372a44a6199da8bf7271d3d8"},"cell_type":"code","source":"plt.scatter(x=input_data['age'].values, y = input_data['balance'].values, label = 'data')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5528e70f4255f3f8a2691b71ca94f1c95079d366"},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45d5b42b36805aa43defbffb02b014e0051829be"},"cell_type":"code","source":"sns.pairplot(data=input_data, vars=['age', 'balance', 'duration', 'campaign'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69363b030d965766eb484fab84dfa305b716c6f5"},"cell_type":"code","source":"#with sns we can do a number of interesting plots; for e.g., in the above chart, we can overlay the categorical var of 'deposit'\nsns.pairplot(data=input_data, vars=['age', 'balance', 'duration', 'campaign'], hue='deposit')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6c75c51d43d8600f3987e23d1fafe66f91b7a4d"},"cell_type":"code","source":"#we are now introducing our output variable - deposit\n#we can see some interesting patterns here; we can see that there is clearly demarcated groups of orange and blue\n#what this means is that these variables have some explanatory power for the output variable\n#to check this further, let's do a bivariate of one input var, say 'balance' vs the output var 'deposit'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aa7f58ec2a3c85bbc14d40ecfcd000902a7bf0f"},"cell_type":"code","source":"#before we do that, it would help to have our output variable as a numeric instead of the current object dtype\n#there are a number of ways to do these - one hot encoding, mapping dict to the col, etc. We will do the latter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcaa40eb41e5a1cad42c5a8230294341d9532ce5"},"cell_type":"code","source":"input_data['deposit_y_n'] = input_data['deposit'].map({'yes':1, 'no':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d7055adde939a1b243d671af7e3c97ae9697ed2"},"cell_type":"code","source":"input_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f30194fbaf09290330f5e06f839479813071d65"},"cell_type":"code","source":"input_data['deposit_y_n'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"691a87994143290134656631f27252699fca7790"},"cell_type":"code","source":"sns.catplot(x='deposit_y_n', y='balance', data=input_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19607a27f8d2cbabdd9705d7f2e29467d5c6f5ec"},"cell_type":"code","source":"#there are more interesting plots like violinplot\nsns.violinplot(x='deposit_y_n', y='balance', data=input_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87e5d40f13aac74c4719099b3084617a0be5b193"},"cell_type":"code","source":"sns.boxplot(x='deposit_y_n', y='balance', data=input_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"361c80e6c8073442c7f1a0af42e6d56f72c1b588"},"cell_type":"code","source":"sns.boxplot(x='deposit_y_n', y='balance', data=input_data[input_data['balance'] <10000])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"895a1fb6bb22e8368c3b2083b17cbfed6e24f79c"},"cell_type":"code","source":"#now we see some good stuff; there is a slightly higher median for deposit = y  (the left box)compared to deposit = n (right box)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b02a85fdcc9fe430141268b6afdef2d684e75463"},"cell_type":"code","source":"#lets take another variable: say education","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1422ee0145e42037b302ad3af42f2f558371d2a7"},"cell_type":"code","source":"input_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4c7070c111ac12ae1831b4a964cb4174e3fa99e"},"cell_type":"code","source":"sns.boxplot(x='education', y='balance', data=input_data[input_data['balance'] <20000])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"288c9259168bef92634db72f2f7969eb845a6955"},"cell_type":"code","source":"sns.boxplot(x='education', y='balance', data=input_data[input_data['balance'] <5000])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bf52f50351b572737f68012c943c9e8f8defe6d"},"cell_type":"code","source":"#countplot\nfig = plt.subplots(figsize=(12,8))\nsns.countplot(data=input_data, x='job')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32fe6bbac70e0c7f37c64c3d64cfea7d0c72a8ca"},"cell_type":"code","source":"#countplot\nfig = plt.subplots(figsize=(12,8))\nsns.countplot(data=input_data, x='job',hue='deposit_y_n')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89329a9d15ae68fd465eb8d49819722853265404"},"cell_type":"code","source":"#Management, retired, and student have more 1s than 0s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c8298aa01fe4ad81eae08df9ad39606730d92cf"},"cell_type":"code","source":"#correlation matrix is another useful bivariate plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c952bf5fec4e9089dfaaf237bbcaff278025de14"},"cell_type":"code","source":"corr = input_data.corr()\n\n#cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, annot=True,square=True)\n\nfig=plt.gcf()\nfig.set_size_inches(12,9)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f37c82392882a2308b7365c43aa570ecb1250ef4"},"cell_type":"code","source":"#we see that the variable that has is most correlated with output(deposit_y_n) is duration; let's explore furthre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1a324c49b372b032657f5f6713b252eec123e49"},"cell_type":"code","source":"plt.scatter(input_data['deposit_y_n'],input_data['duration'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"830fc998106bbb87c50d00b8c475cc2ad13ee37b"},"cell_type":"code","source":"sns.boxplot(data=input_data,x='deposit_y_n', y='duration')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60f164ab0939af716168c2e861561fb11b201673"},"cell_type":"code","source":"# explore the t test; t test compares the means of two distributions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fed9124eb672b10a6dc00e158eb0e5a64bc7d8d"},"cell_type":"code","source":"dep_0 = input_data['duration'][input_data['deposit_y_n'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf0139351b878a688186dc5895bf78d2276fa70a"},"cell_type":"code","source":"len(dep_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2c23c412be945a3daea198364d02226639ae0ef"},"cell_type":"code","source":"dep_1 = input_data['duration'][input_data['deposit_y_n'] == 1]\nlen(dep_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c673542fecef208dd08fcb4172a78f7d26d347d"},"cell_type":"code","source":"from scipy.stats import ttest_ind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21a4d91a80a138295a3af22b73e3de950d6d747d"},"cell_type":"code","source":"ttest_ind(dep_0, dep_1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf34cddc3aca1b913d3166768ffc72437bdd8564"},"cell_type":"markdown","source":"# If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages. <br>\nIn this case p-val is 0.0 which leads us to reject nll hypothesis; so averages are not equal"},{"metadata":{"_uuid":"c9666ccdd3a6c2d9226423aa4ad095b6a77bc07a"},"cell_type":"markdown","source":"# another aspect of EDA could be to check if a column has skewed distribution with the output variable; let's take the categorical columns"},{"metadata":{"trusted":true,"_uuid":"59ec1effd2cd84708135e976b2745b9729b0ae4a"},"cell_type":"code","source":"cat_cols = [col for col in input_data.columns if input_data[col].dtype == 'object']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f148d0b221a54fd6919436b5922f6cb4074bc221"},"cell_type":"code","source":"len(cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"73a8abb421d8b9ce20258d5854997514240254c7"},"cell_type":"code","source":"for col in cat_cols:\n    plt.bar(input_data[col].value_counts().keys(), input_data[col].value_counts().values)\n    plt.title(col)\n    fig=plt.gcf()\n    fig.set_size_inches(8,6)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93d746fd6c433ca0c7f28eedf4a375074a050f3d"},"cell_type":"code","source":"# we see that for the column 'default' most of the 'no' is much higher than 'yes'; let's get a number\ninput_data['default'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a687ccf41c0fe4a6f2762a348bc51cdbe104a18a"},"cell_type":"code","source":"#in many cases, we can afford to ignore this variable while building models","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83d2c05dcfe1cc37072d357b5f73e23b5459bf32"},"cell_type":"markdown","source":"# Exploratory questions:\n1.how does balance affect deposit y n? can we create new column based on balance value and plot this relationship?\n2. what is the relationship between the column housing and the output variable?"},{"metadata":{"trusted":true,"_uuid":"58fba51f95d07f22e1a5776f4975dbe3d2db2969"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"057102d69e9b2b9316e444bbaa5f8cb235cdec42"},"cell_type":"markdown","source":"<a id = '#PredictiveModelingStarts'>3. Predictive Modeling Starts</a><br>\n# Predictive Modeling Starts"},{"metadata":{"_uuid":"04a09366947d9fea54e435bedd044fead0839dc2"},"cell_type":"markdown","source":"<a id = '#Logistic'>3.a. 1st model - Logistic</a><br>"},{"metadata":{"trusted":true,"_uuid":"feb41e092a2f608118d13cc1e9be2b39269a6cbf"},"cell_type":"code","source":"#lets build a simple model - as is the custom we will use logistic regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d1a102b7e869a1f0adaff22b40247eba928f17d"},"cell_type":"code","source":"#we define the input and output variables\noutput_var = 'deposit_y_n'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"922de8aef152bb5bf54f17f335df5183c59d881f"},"cell_type":"code","source":"#lets use only the numeric cols for input vars\ninput_vars = [col for col in input_data.columns if input_data[col].dtype != 'object']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23c4df20fae961fb9928d86a84e2ddbeb2721bf6"},"cell_type":"code","source":"#the list of input vars also has our output var; lets remove it\ninput_vars.remove(output_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ee6b73a1ae3605f95995232ed647942646fd918"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b5c85a3b70dc935d3fb380f3891df6220e98742"},"cell_type":"code","source":"logit_regr1 = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3327f00847210a1f48b764878dadc3c1e58748d"},"cell_type":"code","source":"logit_regr1.fit(X=input_data[input_vars], y=input_data[output_var])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b4d982ad96b274f1991a9eeb4b37383405783c7"},"cell_type":"code","source":"#now we have created the model; how do we know how good it is? we check the accuracy of the prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3398a1a00b87022dde8fa5d4ca79af1ca12b736"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"145f60557285025aa97c1d22700dfb0bc3473bc0"},"cell_type":"code","source":"preds = logit_regr1.predict(X=input_data[input_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce3fefd63dfa3019789a896cbd6aaceb4c13449f"},"cell_type":"code","source":"print(accuracy_score(y_pred=preds, y_true=input_data[output_var]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"760965602748f57b9de3624841da849d3fdff4d9"},"cell_type":"code","source":"#accuracy of 74.6% is not bad; lets see if we can get a higher accuracy using other models, say random forest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22cd828d7b39342ee22098d09aabd78529c9ce9e"},"cell_type":"markdown","source":"<a id = '#RandomForest'>3.b. Random Forest</a><br>"},{"metadata":{"trusted":true,"_uuid":"27fbd47b4eda88abe3d2c698a26dff6b2c5c31a8"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbd21491c9dad9c0b9b333acc630bd89ba15c321"},"cell_type":"code","source":"random_forest1 = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20ef3f5fbbdf9f7c277d2f0c89452a9f75721114"},"cell_type":"code","source":"random_forest1.fit(X=input_data[input_vars], y=input_data[output_var])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcd5f28de82f95e6950edb0de3fe0581d4864017"},"cell_type":"code","source":"#lets get the accuracy\nprint(accuracy_score(y_pred=random_forest1.predict(X=input_data[input_vars]), y_true=input_data[output_var]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8fd9abe40bb0578e0afb0016c5810e52cb5ae08"},"cell_type":"code","source":"#wow - we have got an accuracy of 98.5% using the default settings; can we get to 100%?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7598250b4ea3146f2e04659884cbe9caf49898b0"},"cell_type":"code","source":"random_forest2 = RandomForestClassifier(n_estimators=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3d964b83af36c27f2f253ec00785c77d8c2b8a8"},"cell_type":"code","source":"random_forest2.fit(X=input_data[input_vars], y=input_data[output_var])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c55cd180ea0fa26743521b47785bba6958c31120"},"cell_type":"code","source":"print(accuracy_score(y_pred=random_forest2.predict(X=input_data[input_vars]), y_true=input_data[output_var]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efe86c6092e8d29f937fe92703b14470f8574a2b"},"cell_type":"code","source":"#congrats, we got 100% accuracy - we can all go home!!","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7611344d0bca992b826be055fcd866fa252ee61"},"cell_type":"markdown","source":"<a id = '#OverVsUnderFitting'>4. Over Vs Underfitting</a><br>"},{"metadata":{"trusted":true,"_uuid":"49412502d626d53632664d2dcbaccd636e3ae1bb"},"cell_type":"code","source":"#this is where we need to understand the concept of overfitting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ada465dbed701099b11c73c6a386bbd8934e24ee"},"cell_type":"code","source":"from IPython.display import Image\nfrom IPython.core.display import HTML \n\nImage(url= \"https://cdn-images-1.medium.com/max/800/1*_7OPgojau8hkiPUiHoGK_w.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bb596304a2f057279fb034861e51000097a2c99"},"cell_type":"code","source":"Image(url= \"http://documentation.statsoft.com/STATISTICAHelp/SANN/Images/ErrVsTrain.bmp\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85b56eec7d50bf374682eea3937db25f5793436a"},"cell_type":"markdown","source":"## increasing the complexity of the function can lead to overfitting; there are a few to ways to prevent this: <br>\n1.  penalize complexity\n2. in tree based algorithms, reduce the number of trees\n3. use a validation set to check for overfitting"},{"metadata":{"trusted":true,"_uuid":"30dfd864efe2ab8a63ee7031779b244310a821f8"},"cell_type":"code","source":"#this is a good time to discuss Bias - Variance tradeoff","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6832d130b6c444e313190fafc82d9ec0319ec9c6"},"cell_type":"markdown","source":"<a id = '#BiasVsVariancec'>4.a. Bias Vs Variance</a><br>"},{"metadata":{"trusted":true,"_uuid":"b225849eaacff8b8b511990e792a51e17937ed8f"},"cell_type":"code","source":"Image(url = 'http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d4dfd0097b89f6d50467d086b597fdfa07a7d29"},"cell_type":"markdown","source":"# We typically refer to the bias error and variance error when we say bias - variance\n\n# Bias:  are the simplifying assumptions made by a model to make the target function easier to learn.\n\nSo, if you have a lot of assumptions while creating the model for e.g., regression (normal distribution, non-collinear, etc.) your model will have high bias.  <br>\nThe opposite - models with little assumptions, e.g. decision tree have low bias <br>\n\n# Variance:  is the amount that the estimate of the target function will change if different training data was used.\nVariance acts opposite to bias, so models with lot of assumptions (regression) have low variance <br>\n models with little  assumptions (decision tree) have high variance <br><br>\n This is easy to imagine. Think of a dataset with a lot of variables; <br>\n case 1: we build regression model; if we tweak one of the variables a little, the output would not change much (change is controlled by the coefficient value of that parameter) <br>\n case 2: we build a decision tree: the output can be very different even for a small tweak <br>\n\n<br>\nImagine a scenario of simulation, where we build several versions of the model on the same dataset. We will get a prediction for each of these models <br>\nBias - You take the average (expected value) of these predictions. Bias tells how far off is this average from the actual value <br>\nVariance - How different or distributed are the range of predicition outputs?"},{"metadata":{"_uuid":"237ea6142fea06de31f1d78ac1cc5257fb616bb4"},"cell_type":"markdown","source":"# Another way to think about this: \n<br>\nIf the model uses all the data given for data and predicts everything correctly, technically bias is zero. But we know that, this model, when given a new data, will have high variance, i.e., it may not have generalized <br>\nOn the other hand, if the model doesn't use all the data, it would have high bias but the output will not vary much (low variance) <br>\nWait, but isn't this overfitting vs underfitting? <br>\nGood Question, please check out for yourself! <br>"},{"metadata":{"trusted":true,"_uuid":"b8f1ca641c64423b251f30348ba4ea6492822928"},"cell_type":"code","source":"# More details here: http://scott.fortmann-roe.com/docs/BiasVariance.html","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d468f5debd5936bd5e68fab69cf1135fdf5eae6"},"cell_type":"markdown","source":"<a id = '#ValidationSet'>4.b. Validation Set</a><br>"},{"metadata":{"trusted":true,"_uuid":"c0cb2c6ba115004c15c299a0b9017006535669ca"},"cell_type":"code","source":"#let's use point #3 - validation set to check overfitting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c535fb8c228236f765df0969e2301b5aad2b9f7c"},"cell_type":"markdown","source":"# We keep a part of the overall data separate from the training set; this is called holdout / validation / test set<br>\n# We compare models by checking how good they are on the validation set \n\n"},{"metadata":{"trusted":true,"_uuid":"4856feaeef1515c5074ecec0b24d3a019656c55b"},"cell_type":"code","source":"Image(url= 'https://cdn-images-1.medium.com/max/1600/1*Nv2NNALuokZEcV6hYEHdGA.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f20a6d68ce90f6e66ed7782c30a34199f5723b1"},"cell_type":"code","source":"#split data into train and validation\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1051a31918c5939b29f114a8d3c6bbd4dc3fea7f"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(input_data[input_vars], input_data[output_var], test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63bab11618576c9d67213079b640ae230e329a8f"},"cell_type":"code","source":"print(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21fa2b26bdfeba106e841fce2c87f330e86c5c7a"},"cell_type":"code","source":"#we train on the test set and check how the model performs on the val set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49634af0ddb8025b29f9e700af107357bb2788c5"},"cell_type":"code","source":"random_forest3 = RandomForestClassifier(n_estimators=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c01280148c2024261f12ab64f7c2fedc8d2a6f57"},"cell_type":"code","source":"random_forest3.fit(X=X_train, y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c81ab49b6ca64c41dd841280579d8b5aedbaeb7"},"cell_type":"code","source":"print(\"train accuracy is {}\".format(accuracy_score(y_pred=random_forest3.predict(X=X_train), y_true=y_train)))\nprint(\"val accuracy is {}\".format(accuracy_score(y_pred=random_forest3.predict(X=X_val), y_true=y_val)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64651038e1dfd326bafcb466ca516a5857b43001"},"cell_type":"code","source":"#let's see if we can improve the val accuracy by compromising the train accuracy; the parameter we target is the n_estimators\nrandom_forest4 = RandomForestClassifier(n_estimators=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"316e1a77183f8a1c1a81beb88343b948500faedb"},"cell_type":"code","source":"random_forest4.fit(X=X_train, y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc58e000afbbef4ce7b7bf4a67103a2586215727"},"cell_type":"code","source":"print(\"train accuracy is {}\".format(accuracy_score(y_pred=random_forest4.predict(X=X_train), y_true=y_train)))\nprint(\"val accuracy is {}\".format(accuracy_score(y_pred=random_forest4.predict(X=X_val), y_true=y_val)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56e16e49b7764b34ad441bedf60a66860315804e"},"cell_type":"markdown","source":"# in this case, we dont see an improvement in val accuracy by reducing compexity; \n# however, in certain algorithm such as XGB, we can pass the val set as a parameter to prevent overfitting"},{"metadata":{"trusted":true,"_uuid":"9ee398fa470b6997330ce15b0a0444186b690a2c"},"cell_type":"code","source":"# let's move on to understand the model output on the val set;","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9b290cfcf6dd1fd751d97288b6739aed67e3216"},"cell_type":"markdown","source":"<a id = '#EvaluationMetrics'>5. Evaluation Metrics</a><br>"},{"metadata":{"_uuid":"b0761115400681de22d28d82449e748241fbd642"},"cell_type":"markdown","source":"# key terminologies we will learn are: confusion matrix, accuracy, precision, recall, f1 score, roc_auc curve"},{"metadata":{"_uuid":"250ba9f8f79907bf2a8c1330a09310a45a4e88bb"},"cell_type":"markdown","source":"<a id = '#Accuracy'>5.a. Accuracy</a><br>"},{"metadata":{"trusted":true,"_uuid":"cf54a3b68e02ff7e73e827f192f88050ea7de221"},"cell_type":"code","source":"#confusion matrix is just a cross tab of what is actual vs what is predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e9dfc69d020deaa794578f3776ff8078d52dd8d"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aadf4b5235dce26f2b54cb2c78444445dc17e632"},"cell_type":"code","source":"confusion_matrix(y_true=y_val, y_pred=random_forest4.predict(X=X_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0a9f9a8dbcbe268705b582e6a13237553e4dddb"},"cell_type":"code","source":"#there are fancy ways to plot the conf matrix, but for our purposes the above view is sufficient; ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e46ae77376be499a1d2f34896fcf92ea13c322ac"},"cell_type":"code","source":"np.sum(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b25bf7e0c9afe1decd5173620401b878c91c6b0"},"cell_type":"code","source":"#typically in a conf matrix, the actuals are the rows and the predicted are the cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2ce7fed0692d646b8ecfd55c68339ebcf2e8c61"},"cell_type":"code","source":"Image(url= 'https://tatwan.github.io/images/mock.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e57add6ea5f623c183727a35ef3e1a61f5e221b"},"cell_type":"markdown","source":"# in our conf matrix, TP = 801, TN = 980"},{"metadata":{"_uuid":"b8b136ef3c4bf22eca06bf141c42593d94923248"},"cell_type":"markdown","source":"# Accuracy - how many predictions of ours (0s and 1s both included) were correct?\naccuracy = (TP + TN) / (total cases)"},{"metadata":{"trusted":true,"_uuid":"a42557668ab8464fb2286925aaedfdb85f19f905"},"cell_type":"code","source":"# Discuss why accuracy not a sufficient metric to check the validity of a model? e.g., imbalanced dataset,1s more important than 0s","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9733608777a67251ddb0a2126e721aa2db326e5"},"cell_type":"markdown","source":"<a id = '#PrecisionRecallF1'>5.b. Precision, Recall, F1</a><br>"},{"metadata":{"_uuid":"d8fdc7bf3a96db4f6e7c992dfee0c1699498730c"},"cell_type":"markdown","source":"# Precision - Of all the 1s you predicted, how many are actually 1s?"},{"metadata":{"trusted":true,"_uuid":"8cb82169d9d531ddfe175b74dd15c16353dd9fd9"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/800/1*C3ctNdO0mde9fa1PFsCVqA.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"841659bc24949006af8a5803cc4a556689b0ed44"},"cell_type":"markdown","source":"# Recall - Of all the actual 1s, how many did you predict correctly as 1?"},{"metadata":{"trusted":true,"_uuid":"a44ca02e9fbbb48e9d7e0533be926f5d42bd2531"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/800/1*dXkDleGhA-jjZmZ1BlYKXg.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"096411b835596325d16e76f0ab6cab09ffe89865"},"cell_type":"code","source":"#calculate the precision and recall from our conf matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fdc3c381cc71b0e18913a239d145286765889f8"},"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07300500b623e6eb234fee3091702ac8fa64aec3"},"cell_type":"code","source":"print(\"precision score : {}\".format(precision_score(y_true=y_val, y_pred=random_forest4.predict(X=X_val))))\nprint(\"recall score : {}\".format(recall_score(y_true=y_val, y_pred=random_forest4.predict(X=X_val))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2aabee0c1a29d8c3f89838c341112a8b1ebb5cca"},"cell_type":"markdown","source":"# f1 score is a composite score of precision and recall - Harmonic mean of the two"},{"metadata":{"trusted":true,"_uuid":"bcf6d5eaf9d8bf91cbb583ef8d3a3f82bae3d2f9"},"cell_type":"code","source":"Image(url = 'https://cdn-images-1.medium.com/max/800/1*T6kVUKxG_Z4V5Fm1UXhEIw.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c42d2ea8ddbef3787ea69f4003c05dbd961dc27f"},"cell_type":"code","source":"from sklearn.metrics import f1_score\nprint(\"f1 score : {}\".format(f1_score(y_true=y_val, y_pred=random_forest4.predict(X=X_val))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea57a2b870848bce15d7f580d5c7fea56fe6e26e"},"cell_type":"markdown","source":"<a id = '#AUCROC'>5.c. AUC-ROC</a><br>"},{"metadata":{"_uuid":"5707fea74da2b39e1e2967c5ee395b5d291eda20"},"cell_type":"markdown","source":"# one detour before ROC-AUC: prediction probability\nso far, we have predicted the class of our output variable; actually this is a derived variable. <br>\nThe item being predicted by the model is the probability of each class for a given train example <br>\nwe can get the probabilities directly using predict_proba function"},{"metadata":{"trusted":true,"_uuid":"5e007a664b5d017a55e117fc9063fd8885c93885"},"cell_type":"code","source":"random_forest4.predict_proba(X=X_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ede36bd1c4194757516ca28aebca4853a868abb"},"cell_type":"markdown","source":"# the output we see above is the probability of each class; in our case 0 and 1, for each val example"},{"metadata":{"trusted":true,"_uuid":"f9cb985898cfa7979a07f6231340934283d24351"},"cell_type":"code","source":"print(np.argmax(random_forest4.predict_proba(X=X_val)[0]))\nprint(random_forest4.predict(X=X_val))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"405a4eb19b3ebec53152d55dd96cceb52e0eebe8"},"cell_type":"markdown","source":"# from this idea of prediction probability, we can move to the concept of threshold; <br>\neach of the algorithm uses a default threshold value to convert the probability score to a class; most of the times it would be 0.5 <br>\nso, changing the threshold value will result in a different class prediction"},{"metadata":{"trusted":true,"_uuid":"53dde711ed534968c10c766ec292962c6cf49612"},"cell_type":"code","source":"#lets keep a higher threshold - say 0.75 and see how things change\npreds = random_forest4.predict_proba(X = X_val)\nprint(preds.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06d8e51639cb12df046ce532f556aa10668a10e8"},"cell_type":"code","source":"preds[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7135e5b4816e2c54b1a2b1b8b1e699cbfbe5e883"},"cell_type":"code","source":"preds[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52d91b0d454cd30fc0a2f6e87e9f573f873e60a8"},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6d6dfc5726f6324d3e7a6a96f9c1b2481fb5130"},"cell_type":"code","source":"roc_auc_score(y_true=y_val, y_score=preds[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44f246d16620e1fbb035ed1d9df03e9c4b092b26"},"cell_type":"code","source":"#lets play around with the threshold cutoff to see how it affects precision and recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9768fc65ec2fa55d4346ad3e24f8faeaabcea456"},"cell_type":"code","source":"prob_of_1s = preds[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1071b3a386e74f99dbcfb067690627dda916adcf"},"cell_type":"code","source":"threshold = 0.75","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"612d075e1407224b2e1d9aa7c47aff755c6ded4a"},"cell_type":"code","source":"prob_of_1s.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce0b185ee7763bbfe89601d06b3c631d5b1f5186"},"cell_type":"code","source":"pred_class_new_threshold = [1 if x > threshold else 0 for x in prob_of_1s ]\npred_class_new_threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0a4f9101a74c220de2a186b6d84f4415848cc56"},"cell_type":"code","source":"np.sum(pred_class_new_threshold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"841b6ae7640183b4f4aff26de1f852deb96a5efa"},"cell_type":"code","source":"len(pred_class_new_threshold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"512328358b4ffd4012494771ca9bebf574ed0586"},"cell_type":"code","source":"pred_class_new_threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daf35e4f1292e56b21a47f6ed2819a614a969be4"},"cell_type":"code","source":"print(\"precision score : {}\".format(precision_score(y_true=y_val, y_pred=pred_class_new_threshold)))\nprint(\"recall score : {}\".format(recall_score(y_true=y_val, y_pred=pred_class_new_threshold)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"157b8901b16c859edca04e473c7a64bbf7f28f7a"},"cell_type":"code","source":"for i in range(10):\n    threshold = i /10.0\n    pred_class_new_threshold = [1 if x > threshold else 0 for x in prob_of_1s]\n    print(\"for threshold of {}, precision: {} and recall: {}\".format(threshold, \n                                                                     precision_score(y_true=y_val, y_pred=pred_class_new_threshold),\n                                                                     recall_score(y_true=y_val, y_pred=pred_class_new_threshold)\n                                                                    ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"543fb5ddaa2e80f033436501b25cbb1330bf07de"},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"113d75dca41ed6584706a0777b8bbc27ebddebef"},"cell_type":"code","source":"fpr, tpr, threshold = roc_curve(y_true=y_val, y_score=prob_of_1s)\nroc_auc = auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"157c4a549ec72f9e6d8cedc345cce4a8ea2d83ff"},"cell_type":"code","source":"roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e5c3e3a1b6670d414df1e1fde4d7de3f4943a61"},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aad49c8d34d77771110d849a1a01e0ded41e6851","scrolled":true},"cell_type":"code","source":"plt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef92ea02c8e694f4b1cab1cb4098c9ad94ef0a41"},"cell_type":"code","source":"#enhance the plot\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c68c7b9940bf540866772d301377cf6cfcf49aa7"},"cell_type":"markdown","source":"# Understanding AUC-ROC"},{"metadata":{"trusted":true,"_uuid":"79f2aac581b9495c81dc4e5a4d2060ca3d4cd252"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/800/1*Uu-t4pOotRQFoyrfqEvIEg.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0109d0b023aa28bce02bf30a7b1e025474a5d8bc"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/400/1*HmVIhSKznoW8tFsCLeQjRw.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60ca1c6f89330bbe9a695139b62e255eb19f9ce5"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/800/1*yF8hvKR9eNfqqej2JnVKzg.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"636c6e50baf77b047764c994ec5dd2e863ba9fd7"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/400/1*-tPXUvvNIZDbqXP0qqYNuQ.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d794f72ccdf0fa84bdfdc7acd25623783dcd260"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/800/1*iLW_BrJZRI0UZSflfMrmZQ.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e842b83d8adec70cf5f8aa292031bbadab12fac4"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/400/1*k_MPO2Q9bLNH9k4Wlk6v_g.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bebcacba9ab625817cd2ae60832745a9c0450cc1"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/800/1*aUZ7H-Lw74KSucoLlj1pgw.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65dab84c683b50e44538ad17d4ec509d4e43b176"},"cell_type":"code","source":"Image(url='https://cdn-images-1.medium.com/max/400/1*H7JGQbaa06BUab6tvGNZKg.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0602c48215136e28110c4622c1ea719ccc8deb07"},"cell_type":"code","source":"#in summary, higher the AUC, better the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"628963046c01a09bf0b84bc23e9a504b0c5e43ae"},"cell_type":"code","source":"#lets see what is the accuracy of a logit model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0479fd925fe500ffa38b46620269dcf729a71f5"},"cell_type":"code","source":"logit_regr2 = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a6d5d6dfc9e82b4bd254af84045beb0d8259ceb"},"cell_type":"code","source":"logit_regr2.fit(X=X_train, y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"381d2c1597aaa35875d83fe6ba2a2dcc960201d3"},"cell_type":"code","source":"logit_probs = logit_regr2.predict_proba(X=X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bbd8ae4f1c966bd9ae36cb6a856e0752e6b18c0"},"cell_type":"code","source":"logit_probs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a364907ec126949a7c91edf1a98729acdbd8e62"},"cell_type":"code","source":"logit_probs_of_1s = logit_probs[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea8583d30640a38738862755572fe23b0841f243"},"cell_type":"code","source":"logit_probs_of_1s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5528f55de63a8a4753b265478ae612be1ee093ff"},"cell_type":"code","source":"print(roc_auc_score(y_true=y_val, y_score=logit_probs_of_1s))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69d6bd09aac470f70aa150f268b45c7980bf1514"},"cell_type":"code","source":"#for reference, the AUC of RF model was 0.87","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04f1bd015affeef52ee458cc3fe5a8e6edbfdba1"},"cell_type":"markdown","source":"# so far we have discussed using only the numeric fields available in the train data; \n# we ignored the categorical cols such as education, job, etc. let's see how we can use them"},{"metadata":{"trusted":true,"_uuid":"9aaf7899ab88ef1537b16f67b3dc3b6f91ae0339"},"cell_type":"code","source":"#get a list of categorical cols\ncat_cols = [col for col in input_data.columns if input_data[col].dtype == 'object']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da13cb1a3ca594d9024df5bebfa322ebf7bb251d"},"cell_type":"code","source":"cat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6522ac04447b8dca548248077da9d2696562ce01"},"cell_type":"code","source":"#explore one of them - say, education\ninput_data['education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84c7d246d189e9d8acb23f2a45d71a63e4db9b95"},"cell_type":"markdown","source":"# Almost all of the algorithms can work only with numeric data; so we need to convert these categorical cols to numeric. There are a couple of ways to do this <br>\n1. Label Encoding - We give a numeric label for each cat value; say 1 for secondary, 2 for tertiary, 3 for primary, 4 for unknown, etc.\n2. One Hot Encoding - We create new binary columns to indicate such as secondary_y_n, tertiary_y_n, primary_y_n\n\n<br>\nOHE is generally preferred over label encoding as the latter might suggest that there is a numeric relationship between different labels"},{"metadata":{"trusted":true,"_uuid":"f57748b09f896a8627cef1eef615097f16eaabf5"},"cell_type":"code","source":"#there are standard packages to do these encoding; pandas has a built in function -> get_dummies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb67f84a959179916ed262aabb65fec12b1860d5"},"cell_type":"code","source":"pd.get_dummies(data=input_data, columns=['education']).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66bfdc11d2802fc173feccd3f408969f909eaadb"},"cell_type":"code","source":"#as we can see, the function returns a new dataframe that has additional binary columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3d65bb7f7403ceea490817a46233348154366e9"},"cell_type":"code","source":"#one minor point- deposit (the output variable is also an object col, so we need to remove it from the cat cols for OHE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6444bc654d64dd9aafd5a3f69dc73afd778cfc5c"},"cell_type":"code","source":"cat_cols.remove('deposit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91f02f71a9b61af6d317c2a33b343268603ae118"},"cell_type":"code","source":"#lets do OHE for all cat cols\ninput_data_OHE = pd.get_dummies(data=input_data, columns=cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c4e351dfb9615972f7374b2a5e3fc8bffecdb9"},"cell_type":"code","source":"#check the shape after OHE\nprint(input_data.shape)\nprint(input_data_OHE.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f16583caf93ae8c283ca4e4914d0ac67d5063402"},"cell_type":"markdown","source":"#lets use the new cols created that have info abt cat cols and build a new model\n<br>\nWe need to create a new list of numeric cols and also new train and val sets"},{"metadata":{"trusted":true,"_uuid":"a4bf0daaa00a58e06673fd8e05421a7818811382"},"cell_type":"code","source":"all_numeric_cols = [col for col in input_data_OHE.columns if input_data_OHE[col].dtype != 'object']\nall_numeric_cols.remove(output_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b8742064e37a07ab57454f0ca527b875493b97f"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(input_data_OHE[all_numeric_cols], input_data_OHE[output_var], test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6cdba2660b5a5056638a8e1dc3688b75619ec4c"},"cell_type":"code","source":"random_forest5 = RandomForestClassifier(n_estimators=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88a703f1a7744bd15d68482b8e83bd7840b50411"},"cell_type":"code","source":"random_forest5.fit(X=X_train, y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"134270312f2f18a0c133bdf459d72b6e3d4fc625"},"cell_type":"code","source":"preds = random_forest5.predict_proba(X=X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42c81b006f48367d2ae613e2de403ef3003cef03"},"cell_type":"code","source":"preds_1_prob = preds[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c9bb32b20477dcafbd554b6a9c52b6032ef6ae3"},"cell_type":"code","source":"print(roc_auc_score(y_true=y_val, y_score=preds_1_prob))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eab2813afa6dc03c91698ac9d5191afff1880aa9"},"cell_type":"code","source":"fpr, tpr, threshold = roc_curve(y_true=y_val, y_score=preds_1_prob)\nroc_auc = auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3351860de14b77860106a66c27470bcd6e058a49"},"cell_type":"code","source":"#enhance the plot\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acd33173df9e64d55a96c71d87fe136427336471"},"cell_type":"code","source":"feature_importances = pd.DataFrame(random_forest5.feature_importances_,\n                                   index = X_train.columns,\n                                    columns=['importance']\n                                  ).sort_values('importance',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e20ba166101f6e59b75c7fb09459200a6d477d2"},"cell_type":"code","source":"feature_importances.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24a53878cee2f03aea1a2e568a0142edfcf4e206"},"cell_type":"code","source":"pd.DataFrame(random_forest4.feature_importances_,\n                                   index = input_vars,\n                                    columns=['importance']\n                                  ).sort_values('importance',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9ff9f0370cdc8e4b38a3fb31c15d7fe31ff425b"},"cell_type":"code","source":"#adding the categorical features, improved the AUC by a few percentage points","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"212271dc3b5ee53f2e54424d6b9e0cac78459919"},"cell_type":"markdown","source":"# So far, we used 1 slice of data as the validation set; we can expand on this to have a n-fold cross validation"},{"metadata":{"trusted":true,"_uuid":"db8074a95b1b2ad14c00b61f27614a759e4403fb"},"cell_type":"code","source":"Image(url = 'data:image/png;base64,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')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a257f86b131d34f4fe03fd12e73cf8d6088fe7a"},"cell_type":"code","source":"#kfold or nfold cross validation helps us compare different models - say RF Vs XGB Vs SVM, etc.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2e38c422b04c002efd3d7185b4cbf14eeaf70b8"},"cell_type":"code","source":"input_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4b3a5018366b94857a9bafd7b7a61ddf224bbfe"},"cell_type":"code","source":"11162/3.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e80a88108678013bf9c59463372045b60d39a106"},"cell_type":"code","source":"from sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d9faac703e657687e7bfd0a005041c8411bea28"},"cell_type":"code","source":"kf = KFold(n_splits=3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30bb25bfdc01d3d4c3e9388977c8b9f4d086569a"},"cell_type":"code","source":"for train_index, val_index in kf.split(X=input_data_OHE):\n    #create a set of train and val\n    X_train, X_val = input_data_OHE.loc[train_index][all_numeric_cols], input_data_OHE.loc[val_index][all_numeric_cols]\n    y_train, y_val = input_data_OHE.loc[train_index][output_var], input_data_OHE.loc[val_index][output_var]\n    \n    #initiate a RF model\n    random_forest_3fold = RandomForestClassifier(n_estimators=20)\n    \n    #train the model on X_train\n    random_forest_3fold.fit(X = X_train, y = y_train)\n    \n    #predict\n    preds = random_forest_3fold.predict_proba(X=X_val)\n    preds_1_prob = preds[:,1]\n    \n    #print the auc\n    print(roc_auc_score(y_true=y_val, y_score=preds_1_prob))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d159e757160be85343cea9420f03df3778c560db"},"cell_type":"code","source":"# we see that the AUC is consistent across folds which indicates that the model generalizes quite well","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22abcffe12de31fcf1f8f25eb82a1844b25b93fa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}