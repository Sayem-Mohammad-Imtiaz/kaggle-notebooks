{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import *\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 第1、2题结果"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 获取候选1项集，dataSet为事务集。返回一个list，每个元素都是set集合\ndef createC1(dataSet):\n    C1 = []   # 元素个数为1的项集（非频繁项集，因为还没有同最小支持度比较）\n    for transaction in dataSet:\n        for item in transaction:\n            if not [item] in C1:\n                C1.append([item])\n    C1.sort()  # 这里排序是为了，生成新的候选集时可以直接认为两个n项候选集前面的部分相同\n    # 因为除了候选1项集外其他的候选n项集都是以二维列表的形式存在，所以要将候选1项集的每一个元素都转化为一个单独的集合。\n    return list(map(frozenset, C1))   #map(frozenset, C1)的语义是将C1由Python列表转换为不变集合（frozenset，Python中的数据结构）","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 找出候选集中的频繁项集\n# dataSet为全部数据集，Ck为大小为k（包含k个元素）的候选项集，minSupport为设定的最小支持度\ndef scanD(dataSet, Ck, minSupport):\n    ssCnt = {}   # 记录每个候选项的个数\n    for tid in dataSet:\n        for can in Ck:\n            if can.issubset(tid):\n                ssCnt[can] = ssCnt.get(can, 0) + 1   # 计算每一个项集出现的频率\n    numItems = float(len(dataSet))\n    retList = []\n    supportData = {}\n    for key in ssCnt:\n        support = ssCnt[key] / numItems\n        if support >= minSupport:\n            retList.insert(0, key)  #将频繁项集插入返回列表的首部\n        supportData[key] = support\n    return retList, supportData   #retList为在Ck中找出的频繁项集（支持度大于minSupport的），supportData记录各频繁项集的支持度","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 通过频繁项集列表Lk和项集个数k生成候选项集C(k+1)。\ndef aprioriGen(Lk, k):\n    retList = []\n    lenLk = len(Lk)\n    for i in range(lenLk):\n        for j in range(i + 1, lenLk):\n            # 前k-1项相同时，才将两个集合合并，合并后才能生成k+1项\n            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]   # 取出两个集合的前k-1个元素\n            L1.sort(); L2.sort()\n            if L1 == L2:\n                retList.append(Lk[i] | Lk[j])\n    return retList","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 获取事务集中的所有的频繁项集\n# Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\ndef apriori(dataSet, minSupport):\n    C1 = createC1(dataSet)  # 从事务集中获取候选1项集\n    D = list(map(set, dataSet))  # 将事务集的每个元素转化为集合\n    L1, supportData = scanD(D, C1, minSupport)  # 获取频繁1项集和对应的支持度\n    L = [L1]  # L用来存储所有的频繁项集\n    k = 2\n    while (len(L[k-2]) > 0): # 一直迭代到项集数目过大而在事务集中不存在这种n项集\n        Ck = aprioriGen(L[k-2], k)   # 根据频繁项集生成新的候选项集。Ck表示项数为k的候选项集\n        Lk, supK = scanD(D, Ck, minSupport)  # Lk表示项数为k的频繁项集，supK为其支持度\n        L.append(Lk);supportData.update(supK)  # 添加新频繁项集和他们的支持度\n        k += 1\n    return L, supportData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/weathernominal/weather.nominal.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['outlook'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['temperature'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['humidity'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['windy'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['play'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlook_mapping = {\n           'sunny': 10,\n           'overcast': 11,\n           'rainy': 12}\ndf['outlook'] = df['outlook'].map(outlook_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temperature_mapping = {\n           'hot': 20,\n           'mild': 21,\n           'cool': 22}\ndf['temperature'] = df['temperature'].map(temperature_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"humidity_mapping = {\n           'high': 30,\n           'normal': 31}\ndf['humidity'] = df['humidity'].map(humidity_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list1 = ['windy','play']\nfor i in list1:\n    df[i]=LabelEncoder().fit_transform(df[i]).astype(np.int8)\n    df[i]=df[i].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataSet = df.values.tolist()  # 获取事务集。每个元素都是列表\n# C1 = createC1(dataSet)  # 获取候选1项集。每个元素都是集合\n# D = list(map(set, dataSet))  # 转化事务集的形式，每个元素都转化为集合。\n# L1, suppDat = scanD(D, C1, 0.5)\n# print(L1,suppDat)\n\nL, suppData = apriori(dataSet,minSupport=0.5)\nprint(L)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(suppData)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 第3题"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/apriori/Transactions.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataSet = df.values.tolist()\n\nL, suppData = apriori(dataSet,minSupport=0.5)\nprint(L)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(suppData)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}