{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this notebook, I try various imputation techniques for numerical variables to see which is the best imputation technique to get the best score. And for the categorical variable I didn't try to variate it, I just impute the Constant values and Most frequent values for Cabin and Embarked columns.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\nsubmission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\nperfect = pd.read_csv('/kaggle/input/perfecttitanic/PerfectScoreTitanic.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"perfect is the actual prediction of titanic problem, I use it because it saves me more time without doing submitting it again and again.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# credit: https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction. \n# One of the best notebooks on getting started with a ML problem.\n\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_missing= missing_values_table(train)\ntrain_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_missing= missing_values_table(test)\ntest_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine(train,test):\n    merged = pd.concat([train,test])\n    merged.drop('Survived',axis=1,inplace=True)\n    return merged\nmerged = combine(train,test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoding_label(merged, baseline= True):\n    from sklearn.preprocessing import LabelEncoder\n    encoder = LabelEncoder()\n    \n    if baseline == True:\n        merged['Sex'] = encoder.fit_transform(merged['Sex'])\n    else:\n        merged['Sex'] = encoder.fit_transform(merged['Sex'])\n        merged['Cabin'] = [0 if 'Cabin' in i else 1 for i in merged['Cabin']]\n        merged['Embarked'] = encoder.fit_transform(merged['Embarked'])\n    return merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scoring(merged):\n    trained = merged.iloc[:len(train)]\n    tested = merged.iloc[len(train):]\n    y = train.Survived\n    y_perfect = perfect.Survived\n    \n    from sklearn.linear_model import LogisticRegression\n    logreg = LogisticRegression()\n    \n    logreg.fit(trained,y)\n    return logreg.score(tested,y_perfect)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I use LogisticRegression to see the score, but different models can get different scores, feel free to change the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"name = list()\nscores = list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Base Model (drop missing values columns)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = combine(train,test)\nmerged.drop(columns = ['PassengerId','Name','Cabin','Ticket','Fare','Embarked','Age'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = encoding_label(merged)\nscores.append(scoring(merged))\nname.append('Base_Model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CABIN AND EMBARKED IMPUTATION\nIn this section we impute Cabin and Embarked columns with constant and most_frequent values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = combine(train,test)\nmerged = merged[['Sex','Pclass','Age','SibSp','Parch','Fare','Cabin','Embarked']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing the null values in the Age column with Mean\nfrom sklearn.impute import SimpleImputer\nfrom array import array\n\n# Imputers for Cabin\nimputer = SimpleImputer(missing_values= np.nan, strategy='constant', fill_value='No_Cabin')\n\n# Fit and transform to the parameters\nmerged['Cabin'] = imputer.fit_transform(np.array(merged['Cabin']).reshape(-1,1))\n\n# Imputers for Embarked\nimputer = SimpleImputer(missing_values= np.nan, strategy='most_frequent')\n\n# Fit and transform to the parameters\nmerged['Embarked'] = imputer.fit_transform(np.array(merged['Embarked']).reshape(-1,1))\n\n# Checking for any null values\nmerged.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = encoding_label(merged, baseline=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mean and Median Missing Value","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Simple Fillna using Mean","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_simple = merged.copy()\nmerged_simple['Fare'] = merged.Fare.fillna(merged.Fare.mean())\nmerged_simple['Age'] = merged_simple.Age.fillna(merged.Age.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_simple))\nname.append('Simple_Mean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fillna using mean based on Pclass","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_pclass = merged.copy()\nmerged_pclass['Age'] = merged.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.mean()))\nmerged_pclass['Fare'] = merged.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_pclass))\nname.append('Mean_Based_on_Pclass')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple fillna using Median","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_simple = merged.copy()\nmerged_simple['Fare'] = merged.Fare.fillna(merged.Fare.median())\nmerged_simple['Age'] = merged_simple.Age.fillna(merged.Age.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_simple))\nname.append('Simple_Median')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fillna using median based on Pclass","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_pclass = merged.copy()\nmerged_pclass['Age'] = merged.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))\nmerged_pclass['Fare'] = merged.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_simple))\nname.append('Median_Based_on_Pclass')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FFILL AND BFILL METHOD\nI know FFILL_Method and BFILL_Method is use for Time_Series, but it doesn't hurt to try","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Fillna using FFILL method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_ffill = merged.copy()\nmerged_ffill['Age'].fillna(method='ffill',inplace=True)\nmerged_ffill['Fare'].fillna(method='ffill',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_ffill))\nname.append('FFILL_Method')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fillna using BFILL method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_bfill = merged.copy()\nmerged_bfill['Age'].fillna(method='bfill',inplace=True)\nmerged_bfill['Fare'].fillna(method='bfill',inplace=True)\n\n# Because it still leaves 2 missing values using bfill, I use ffill to mask it\nmerged_bfill['Age'].fillna(method='ffill',inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_bfill))\nname.append('BFILL_Method')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FILLNA USING MODEL","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Fillna using KNN Imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import KNNImputer\nmerged_knn = merged.copy(deep=True)\n\nknn_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n\nmerged_knn['Age'] = knn_imputer.fit_transform(merged_knn[['Age']])\nmerged_knn['Fare'] = knn_imputer.fit_transform(merged_knn[['Fare']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_knn))\nname.append('KNN_Imputation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fillna using MICE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nmerged_mice = merged.copy(deep=True)\n\nmice_imputer = IterativeImputer()\nmerged_mice['Age'] = mice_imputer.fit_transform(merged_mice[['Age']])\n\nmice_imputer = IterativeImputer()\nmerged_mice['Fare'] = mice_imputer.fit_transform(merged_mice[['Fare']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_mice))\nname.append('MICE_Imputation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fillna using Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_regression = merged.copy()\nmerged_regression_train = merged_regression.iloc[:len(train)]\nmerged_regression_test = merged_regression.iloc[:len(test)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmerged_regression_train_age = merged_regression_train[merged_regression_train[\"Age\"].isna() == False]\nmerged_regression_test_age = merged_regression_test[merged_regression_test[\"Age\"].isna() == False]\n\nmerged_regression_new = merged_regression_train_age.append(merged_regression_test_age)\n\nmerged_regression_age_X = merged_regression_new.drop([\"Age\"], axis = 1)\nmerged_regression_age_y = merged_regression_new[\"Age\"]\n\nmerged_regression_age_X[\"Fare\"].fillna(merged_regression_age_X[\"Fare\"].median(), inplace = True)\n\nlinear_reg_model = LinearRegression().fit(merged_regression_age_X, merged_regression_age_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get indexes of rows that have NaN value\n\ndef get_age_indexes_to_replace(df):\n    age_temp_list = df[\"Age\"].values.tolist()\n    indexes_age_replace = []\n    age_temp_list = [str(x) for x in age_temp_list]\n    for i, item in enumerate(age_temp_list):\n        if item == \"nan\":\n            indexes_age_replace.append(i)\n    return indexes_age_replace\n\nindexes_to_replace_main = get_age_indexes_to_replace(merged_regression_train)\nindexes_to_replace_test = get_age_indexes_to_replace(merged_regression_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions on the missing values\ndef linear_age_predictions(reg_df, indexes_age_replace):\n    reg_df_temp = reg_df.drop([\"Age\"], axis = 1)\n    age_predictions = []\n    for i in indexes_age_replace:\n        x = reg_df_temp.iloc[i]\n        x = np.array(x).reshape(1,-1)\n        pred = linear_reg_model.predict(x)\n        age_predictions.append(pred)\n    return age_predictions\n\nage_predictions_main = linear_age_predictions(merged_regression_train, indexes_to_replace_main)\nage_predictions_test = linear_age_predictions(merged_regression_test, indexes_to_replace_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill the missing values with predictions\ndef fill_age_nan(merged_regression, indexes_age_replace, age_predictions):\n\n    for i, item in enumerate(indexes_age_replace):\n        merged_regression[\"Age\"][item] =  age_predictions[i]\n\n    return merged_regression\n\nmerged_regression_train = fill_age_nan(merged_regression_train, indexes_to_replace_main, age_predictions_main)\nmerged_regression_test = fill_age_nan(merged_regression_test, indexes_to_replace_test, age_predictions_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_regression = pd.concat([merged_regression_train, merged_regression_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.append(scoring(merged_regression))\nname.append('LinearRegression_Imputation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IMPUTATION TECHNIQUE COMPARISON","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"comparison = pd.DataFrame([scores],columns=name)\ncomparison","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see base_model (drop all the missing values ​​columns) has the highest score, I don't know why, definitely Age is an important factor to survive, but feel free to change the model maybe you get different results! \n\n<t> **Remember: Don't always believe your model results without comparing it with the domain knowledge**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## References\n* [A guide to Handling missing values](https://www.kaggle.com/parulpandey/a-guide-to-handling-missing-values)\n* [Handling missing values for beginner](https://www.kaggle.com/mojtylor/handling-missing-values-for-beginner)\n* [EDA, Handling missing values using Regression](https://www.kaggle.com/modojj/eda-handling-missing-values-using-regression)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}