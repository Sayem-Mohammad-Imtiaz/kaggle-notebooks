{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content</h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"##Library-and-Data\" role=\"tab\" aria-controls=\"profile\">#Library and Data<span class=\"badge badge-primary badge-pill\">1</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Reading-Data\" role=\"tab\" aria-controls=\"messages\">Reading Data<span class=\"badge badge-primary badge-pill\">2</span></a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#Logistic-Regression-Classifier\" role=\"tab\" aria-controls=\"settings\">Logistic Regression Classifier<span class=\"badge badge-primary badge-pill\">3</span></a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Support-Vector-Classifier\" role=\"tab\" aria-controls=\"settings\">Support Vector Classifier<span class=\"badge badge-primary badge-pill\">4</span></a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Multinomial-Naive-Bayes-Classifier\" role=\"tab\" aria-controls=\"settings\">Multinomial Naive Bayes Classifier<span class=\"badge badge-primary badge-pill\">5</span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Bernoulli-Naive-Bayes-Classifier\" role=\"tab\" aria-controls=\"settings\">Bernoulli Naive Bayes Classifier<span class=\"badge badge-primary badge-pill\">6</span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Gradient-Boost-Classifier\" role=\"tab\" aria-controls=\"settings\">Gradient Boost Classifier<span class=\"badge badge-primary badge-pill\">7</span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#XGBoost-Classifier\" role=\"tab\" aria-controls=\"settings\">XGBoost Classifier<span class=\"badge badge-primary badge-pill\">8</span></a>  \n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Stochastic-Gradient-Descent\" role=\"tab\" aria-controls=\"settings\">Stochastic Gradient Descent<span class=\"badge badge-primary badge-pill\">9</span></a>\n     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Decision-Tree\" role=\"tab\" aria-controls=\"settings\">Decision Tree<span class=\"badge badge-primary badge-pill\">10</span></a>\n     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Random-Forest-Classifier\" role=\"tab\" aria-controls=\"settings\">Random Forest Classifier<span class=\"badge badge-primary badge-pill\">11</span></a>\n     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#KNN-Classifier\" role=\"tab\" aria-controls=\"settings\">KNN Classifier<span class=\"badge badge-primary badge-pill\">12</span></a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#LSTM\" role=\"tab\" aria-controls=\"settings\">LSTM<span class=\"badge badge-primary badge-pill\">12</span></a>\n    "},{"metadata":{},"cell_type":"markdown","source":"# Library and Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, \\\n                            classification_report, f1_score, roc_curve, auc\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.callbacks import EarlyStopping\nfrom wordcloud import WordCloud\nfrom collections import Counter, defaultdict\n\nimport nltk\nimport nltk as nlp\nimport string\nimport re\ntrue = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")\nfake = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fake['target'] = 'fake'\ntrue['target'] = 'true'\nnewstot = pd.concat([fake, true]).reset_index(drop = True)\nnewstot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counting by Subjects \nfor key,count in fake.subject.value_counts().iteritems():\n    print(f\"{key}:\\t{count}\")\n    \n#Getting Total Rows\nprint(f\"Total Records:\\t{fake.shape[0]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counting by Subjects \nfor key,count in true.subject.value_counts().iteritems():\n    print(f\"{key}:\\t{count}\")\n    \n#Getting Total Rows\nprint(f\"Total Records:\\t{true.shape[0]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake['fake'] = 1\ntrue['fake'] = 0\n\ndata_df = pd.concat([fake, true], ignore_index=True)\n\n\nplt.figure(figsize=(6,6))\nsns.countplot(\"subject\", data=fake)\nplt.xticks(rotation=90)\nplt.xlabel('Subject-Fake')\nplt.show()\n\n\nplt.figure(figsize=(4,6))\nsns.countplot(\"subject\", data=true)\nplt.xticks(rotation=90)\nplt.xlabel('Subject-True')\nplt.show()\n\n\n\nplt.figure(figsize=(4,6))\nax = sns.countplot(x=\"fake\", data=data_df)\nax.set_xticklabels(['Real', 'Fake'])\nplt.xlabel('Classification')\nplt.xticks(rotation=90)\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['title_length'] = data_df['title'].apply(lambda x : len(x.strip().split()))\ndata_df['text_length'] = data_df['text'].apply(lambda x : len(x.strip().split()))\n\n\nplt.figure(figsize=(12,6))\nsns.distplot(data_df[data_df['fake'] == 1]['title_length'], \n             kde=False, label='Fake', bins=20)\nsns.distplot(data_df[data_df['fake'] == 0]['title_length'], \n             kde=False, label='True', bins=20)\nplt.xlabel('Title Length', weight='bold')\nplt.title('Length of title comparison', weight='bold')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 6))\nplt.title(\"Word counts of article titles\", fontsize=16, weight='bold')\nax = sns.boxplot(x=\"fake\", y=\"title_length\", data=data_df)\nax.set_xticklabels(['Real', 'Fake'])\nax.set_xlabel(\"Article Classification\", fontsize=14, weight='bold') \nax.set_ylabel(\"Length of Entry (Words)\", fontsize=14, weight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nplt.figure(figsize=(12,6))\nsns.distplot(data_df[data_df['fake'] == 1]['text_length'], \n             kde=False, label='Fake', bins=20)\nsns.distplot(data_df[data_df['fake'] == 0]['text_length'], \n             kde=False, label='True', bins=20)\nplt.xlabel('Text Length', weight='bold')\nplt.title('Length of title comparison', weight='bold')\nplt.xlim(0.0, 4500)\nplt.legend()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 6))\nplt.title(\"Word counts of article text\", fontsize=16, weight='bold')\nax = sns.boxplot(x=\"fake\", y=\"text_length\", data=data_df)\nax.set_xticklabels(['Real', 'Fake'])\nax.set_xlabel(\"Article Classification\", fontsize=14, weight='bold') \nax.set_ylabel(\"Length of Entry (Words)\", fontsize=14, weight='bold')\nplt.ylim(0.0, 3000.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_corpus(text_data):\n    \"\"\" Create a corpus from the given text array of sentences \"\"\"\n    corpus = []\n    for sentence in text_data:\n        for word in sentence.split():\n            corpus.append(word)\n    return corpus\n            \ndef top_words(text_corpus, top_n=25, return_dict=False):\n    \"\"\" Return the top n words from a given corpus \"\"\"\n    def_dict = defaultdict(int)\n    for word in text_corpus:\n        def_dict[word] += 1\n    most_common = sorted(def_dict.items(), key=lambda x : x[1], reverse=True)[:top_n]\n    if return_dict:\n        return most_common, def_dict\n    else:    \n        return most_common\n\n\ntop_n = 100\ntext_field = \"title\"\n\nfake_corpus = create_corpus(fake[text_field].values)\nfake_top_n_words, fake_symptom_dict = top_words(fake_corpus, top_n=top_n, return_dict=True)\nfake_words, fake_word_counts = zip(*fake_top_n_words)\n\ndef plot_words(word_list, word_counts, n, text_description, figsize=(30,5)):\n    plt.figure(figsize=figsize)\n    plt.xticks(rotation=90)\n    plt.bar(word_list, word_counts)\n    plt.title(f\"Top {n} words in {text_description}\", weight='bold')\n    plt.ylabel(\"Word Count\", weight='bold')\n    plt.show()\n\nplot_words(fake_words, fake_word_counts, 100, \"Fake Article Titles\")\nprint(f\"Total unique words in {text_field}: {len(fake_symptom_dict)}\")\n\n\ntop_n = 50\ntext_field = \"title\"\n\ntrue_corpus = create_corpus(true[text_field].values)\ntrue_top_n_words, true_symptom_dict = top_words(true_corpus, top_n=top_n, return_dict=True)\ntrue_words, true_word_counts = zip(*true_top_n_words)\n\nplot_words(true_words, true_word_counts, 50, \"True Article Titles\")\nprint(f\"Total unique words in {text_field}: {len(true_symptom_dict)}\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word Cloud\ntext = ''\nfor news in fake.text.values:\n    text += f\" {news}\"\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()\ndel text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word Cloud\ntext = ''\nfor news in true.text.values:\n    text += f\" {news}\"\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'black',\n    stopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\nfig = plt.figure(\n    figsize = (40, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()\ndel text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\n\ndef plot_confusion_matrix(true_y, pred_y, title='Confusion Matrix', figsize=(8,6)):\n    \"\"\" Custom function for plotting a confusion matrix for predicted results \"\"\"\n    conf_matrix = confusion_matrix(true_y, pred_y)\n    conf_df = pd.DataFrame(conf_matrix, columns=np.unique(true_y), index = np.unique(true_y))\n    conf_df.index.name = 'Actual'\n    conf_df.columns.name = 'Predicted'\n    plt.figure(figsize = figsize)\n    plt.title(title)\n    sns.set(font_scale=1.4)\n    sns.heatmap(conf_df, cmap=\"Blues\", annot=True, \n                annot_kws={\"size\": 16}, fmt='g')\n    plt.show()\n    return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(newstot['text'], newstot.target, test_size=0.2, random_state=2020)\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nprint(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Logistic Regression classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Logistic Regression Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(newstot['text'], newstot.target, test_size=0.2, random_state=2020)\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LinearSVC())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"SVC classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\n\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"SVC Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multinomial Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', MultinomialNB())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Multinomial Naive Bayes classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Multinomial Naive Bayes Classifier Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bernoulli Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', BernoulliNB())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Barnoulli Naive Bayes classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\n\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Barnoulli Naive Bayes Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', GradientBoostingClassifier(loss = 'deviance',\n                                                   learning_rate = 0.01,\n                                                   n_estimators = 10,\n                                                   max_depth = 5,\n                                                   random_state=55))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Gradient Boost classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\n\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Gradient Boost Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', XGBClassifier(loss = 'deviance',\n                                                   learning_rate = 0.01,\n                                                   n_estimators = 10,\n                                                   max_depth = 5,\n                                                   random_state=2020))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"XGBoost classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"XGBoost Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stochastic Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', SGDClassifier())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Stochastic Gradient Descent classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Stochastic Gradient Descent Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', DecisionTreeClassifier(criterion= 'entropy',\n                                           max_depth = 10, \n                                           splitter='best', \n                                           random_state=2020))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Decision Tree classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Decision Tree Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', RandomForestClassifier())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"Random Forest classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"Random Forest Confusion Matrix\", figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', KNeighborsClassifier(n_neighbors = 10,weights = 'distance',algorithm = 'brute'))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\n#print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Samples incorrectly classified: {0} out of {1}.\".format((y_test != prediction).sum(),\n                                                                len(y_test)))\nprint(\"KNN classifier accuracy: {0:.2f}%\".format(accuracy_score(prediction, y_test)*100.0))\n\nplot_confusion_matrix(y_test, prediction, \n                      title=\"KNN Confusion Matrix\", figsize=(5,5))\n\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = newstot.text\nY = newstot.target\nle = LabelEncoder()\nY = le.fit_transform(Y)\nY = Y.reshape(-1,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\nmax_words = 500\nmax_len = 75\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\ndef RNN():\n    inputs = Input(name='inputs',shape=[max_len])\n    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256,name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(1,name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs,outputs=layer)\n    return model\nmodel = RNN()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import plot_model \nplot_model(model, to_file='model1.png')\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(sequences_matrix,Y_train,batch_size=256,epochs=10,\n          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequences = tok.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\naccr = model.evaluate(test_sequences_matrix,Y_test)\nprint('Accuracy: {:0.2f}%'.format(accr[1]*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}