{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Q1create two NumPy array by takin user input of data stored in array, check if they have views to same memory, check if elements of arrays are divisible by 3 or not sort 2nd array and find sum of all elements of 1st array\nimport numpy as np\ninp1 = input(\"Enter first array:\")\na = inp1.split()\na = [int(i) for i in a]\ninp2 = input(\"Enter second array:\")\nb = inp2.split()\nb = [int(i) for i in b]\nArr1 = np.array(a)\nArr2 = np.array(b)\nprint(\"Array 1 :\")\nprint(Arr1)\nprint(\"Array 2 :\")\nprint(Arr2)\nprint(\"Do both of these arrays share the same memory :\")\nprint(id(Arr1)==id(Arr2))\ndiv1 = Arr1%3==0\ndiv2 = Arr2%3==0\nprint(\"elements of array 1 divisible by 3 are :\")\nprint(Arr1[div1])\nprint(\"elements of array 2 divisible by 3 are :\")\nprint(Arr2[div2])\nprint(\"Array 2 after sorting is :\")\nArr2.sort()\nprint(Arr2)\nprint(\"Sum of elements of array 1 is :\")\nprint (Arr1.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Q2 Load the titanic dataset, remove missing values from all attributes, find mean value of first 50 samples, find the mean of the number of male passengers( Sex=1) on the ship, find the highest fare paid by any passenger.\nimport pandas as pd\ndf = pd.read_csv(\"../input/titanic/train_and_test2.csv\")\ndf.head()\n\ndf.dropna(axis=1, how='all')\nprint(df.head())\nprint(df.shape)\n\nprint(df[:50].mean())\n\nprint(df[df['Sex']==1].mean())\n\nprint(df['Fare'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Q3.A student has got the following marks ( English = 86, Maths = 83, Science = 86, History =90, Geography = 88). Wisely choose a graph to represent this data such that it justifies the purpose of data visualization. Highlight the subject in which the student has got least marks. \nfrom matplotlib import pyplot as plt\nslices=[87,83,86,90,88]\nSubject=['English','Maths','Science','History','Geography']\nplt.pie(slices,labels=Subject,startangle=90,shadow=True,explode=(0.08,0.5,0.08,0.08,0.08),autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Q4 Load the iris dataset, print the confusion matrix and f1_score as computed on the features.\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\ntrain = pd.read_csv(\"../input/iris-flower-dataset/IRIS.csv\")\n\n\nX = train.drop(\"species\",axis=1)\ny = train[\"species\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\n\npredictions = logmodel.predict(X_test)\n\nprint(\"F1 Score(macro):\",f1_score(y_test, predictions,average='macro'))\nprint(\"F1 Score(micro):\",f1_score(y_test, predictions,average='micro'))\nprint(\"F1 Score(weighted):\",f1_score(y_test, predictions,average='weighted'))\nprint(\"\\nConfusion Matrix(below):\\n\")\nconfusion_matrix(y_test, predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}