{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Thinkful Project - Kalika Curry\n\nFind the factors that affect the life expectancy. Specifically, you need to find out which factors increase the expected life in the countries and which factors decrease it."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy.stats.mstats import winsorize\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nurl = os.path.join(dirname, filename)\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(url)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning\n*The Kaggle description for this dataset references that a lot of additional information has been added to the set for research purposes. This briefing references additional timeframes as well as countries. My goal is to observe the dataset with an idea in mind to create a predictive model with respect to life expectancy.*\n\n1. Detect the problems with the data such as missing values and outliers. \n2. Are there any nonsense values that seem to be stemmed from the data collection?\n3. For the missing values, discuss which technique would be the most suitable one in filling out these values. \n3. Regarding the outliers, discuss their potential effects on your analysis and select an appropriate method to deal with them."},{"metadata":{},"cell_type":"markdown","source":"### Missingness"},{"metadata":{"trusted":true},"cell_type":"code","source":"#look at all the variables.\ndf.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I want to take a look at some of the unique categorical values.\nfor col in df.describe(include='O'):\n    print(df[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data types. There are nulls. Year is reading as an integer. I might have to fix this, for now I take note.\n#I'm not noticing any nonesense values.\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A summary of missing variables represented as a percentage of the total missing content. \ndef missingness_summary(df, print_log=False, sort='ascending'):\n  s = df.isnull().sum()*100/df.isnull().count()\n  s = s [s > 0]\n  if sort.lower() == 'ascending':\n    s = s.sort_values(ascending=True)\n  elif sort.lower() == 'descending':\n    s = s.sort_values(ascending=False)  \n  if print_log: \n    print(s)\n  \n  return pd.Series(s)\n\nsuspects = missingness_summary(df, True, 'descending')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I do not notice any nonesense variables. "},{"metadata":{},"cell_type":"markdown","source":"\nDrop Null Potentials: \n* Investigate variables with less than 5% missing and see if those rows can be dropped\n* My variable of interest is the life expectancy. 0.34% of the data is missing for this variable. It is related to the [Adult Mortality](https://www.who.int/gho/mortality_burden_disease/mortality_adult/situation_trends_text/en/#:~:text=Adult%20mortality%20rate%20represents%20the,per%201000%20population%20in%202016.). I dropped all records where these values are null.\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping Life expectancy and adult mortality.\ndf.dropna(subset=['Life expectancy ', 'Adult Mortality'], inplace=True)\n\nsuspects = missingness_summary(df, False)\ndrop_suspects = suspects[ suspects < 5 ]\ndrop_suspects","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[drop_suspects.keys()].isnull().any(axis=1)]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Investigating the weight, polio, and diphtheria. There are a number of approaches I can take. I could go back and take the average for each country/region/area for these values. \n\nThey are all developing countries. I have forty rows of them, how is that going to impact the life expectancy and mortality calculations for those developing countries? When I weigh against polio, there's not a lot I can do about that. When I weigh against, say, population, HIV, etc, it could have a serious impact. Why don't we have polio information on these developing countries? Could it be because they didn't have access to the technology to test for polio? Were their systems down that year? Should I allow those possible interfering factors disallow their data to contribute to the other features that I'm observing? No.  \n\nAm I going to look at polio and diptheria? Is there any correlation on these items and life expectancy?\n\nI have a lot of features. I'm going to assign them to a different dataframe for the time being and remove the suspected null values from that dataframe. For the remainder of this project, I will omit these features. I might come back to them.\n\nRemember the country a person lives in could also impact the life expectancy. Do I want to just think about the time of year? I anticipate that the time of year would have a very real impact on the life expectancy of ESPECIALLY developing countries.\nYes. I could drop the nulls individually, but there's enough of a significance is the nulls for these features for me to go ahead and make the assumption. I just feel a little bad for Sedan - when I look at polio, etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"var = ['Life expectancy '] #variable of interest\nlost_development = list(drop_suspects.keys())\nlost_development.extend(var)\n\n#Lost Development dataframe. Short name for easy access.\nld = df[lost_development]\nld = ld.dropna()\n\n#No Missing Values for the lost development dataframe. \nmissingness_summary(ld)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove the drop_suspect features from the dataset. We will not use them with this dataset as this subset of data is incomplete.\ncols = list(df.columns)\ncols = [x for x in cols if x not in drop_suspects.keys()]\n\n#My new Life Expectancy dataframe, without those few missing entries.\nle = df[cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filling in Data\nNow I have to understand what's going on with those columns who have a larger portion of the data missing. The idea being that less than half but more than five percent of them contain null values. \n\nI want to take a look at these and determine if they should be imputed, interpolated, or given the same treatment as the others. "},{"metadata":{"trusted":true},"cell_type":"code","source":"miss = missingness_summary(le, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I've got seven features to think on. I'm not comfortable filling in Hepatitis B with an estimation. I will omit that feature. Rather than create another dataframe this time, I will just opt to exclude it because now I'm rethinking my plan of attack. \n\nI think perhaps there should be an alternate feature set that should be handled differently when there's more time available to explore this dataset. \n\nOmitted Features and Reasonings:\n* Total Expenditure - am satisfied with percentage expenditure.\n* Hepatitis B - should be treated separately. \n* Income Composition of Resources - I don't understand what this is. Further research would be required to determine the appropriate handling.\n* Alcohol - Treat it separately. \n* Population - 21% of the data with respect to the population is missing. I really want to use this feature, but there is a significant amount of data missing in developing countries, and it's consecutive. \n* Schooling has the same complication. I am required to omit that feature.\n* GDP also has the same complication as all the others. There's too much data missing with respect to the country and much of the data is consecutive. A little research suggests that there may be [some relationship between precentage expenditure and GDP.](https://en.wikipedia.org/wiki/Government_spending#:~:text=The%20figures%20below%20of%2042,was%20%2422%2C726%20in%20the%20U.S.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"le[le[miss.keys()].isnull().any(axis=1)].sort_values(['Country','Year'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[le['Schooling'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"omit = ['Total expenditure', 'Hepatitis B', 'Income composition of resources', 'Alcohol', 'Population', 'Schooling', 'GDP']\n\n#drop those features you don't want to use right now. \ncols =  [x for x in cols if x not in omit]\nle = le[cols]\nmiss = missingness_summary(le, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers\n\nNow that I have my data cleaned up enough to try and accomplish something with it, I want to take a look at it and see if there is any data that falls outside their normal means."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Country, Year, and Status should not have any outliers. \nout = [x for x in cols if x not in ['Country', 'Year', 'Status']]\n\nle[out[0]].plot.box(whis=3) \nplt.show()\nout.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[out[0]].plot.box(whis=3) \nplt.show()\nout.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[out[0]].plot.box(whis=3) \nplt.show()\nout.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#First incident of excessive outliers. Add the variable to an outlier list for future investigation.\noutlier = ['infant deaths']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[out[0]].plot.box(whis=3) \nplt.show()\nout.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier.append('percentage expenditure')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[out[0]].plot.box(whis=3) \nplt.show()\nout.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier.append('Measles ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[out[0]].plot.box(whis=3) \nplt.show()\nout.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier.append('under-five deaths ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[out[0]].plot.box(whis=3) \nplt.show()\nout.pop(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier.append(' HIV/AIDS')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good news! Our variables of interest don't have very many outliers. They're usable as is. \n\nThe rest do. The outliers can have an impact on the visual results. When there's too many outliers, the data needs to be compressed or transformed to make it easier to work with. \n\nThese outliers that we're seeing could be a result of bad data, they could just a few dozen falling outside of the norm, or they could be something more serious.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tukey's method.\ndef tukey(field):\n  q75, q25 = np.percentile(field, [75 ,25])\n  iqr = q75 - q25\n \n  for threshold in np.arange(1,5,0.5):\n      min_val = q25 - (iqr*threshold)\n      max_val = q75 + (iqr*threshold)\n      print(\"The score threshold is: {}\".format(threshold))\n      print(\"Number of outliers is: {}\".format(\n          len((np.where((field > max_val) \n                        | (field < min_val))[0]))\n      ))\n        \nfor col in outlier:\n    print(\"TUKEY INFORMATION FOR\", col)\n    print('____________________________')\n    tukey(le[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trying out winsorize. \nfrom scipy.stats.mstats import winsorize\n\n# Apply one-way winsorization to the highest end. I went with the 80th percentile. \nprint(outlier[0])\nwv1 = winsorize(le[outlier[0]], (0, 0.15))\nplt.boxplot(wv1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a column to the datatable for this transformation.\nle[\"w\"+ outlier[0]] = wv1\n\n# Apply one-way winsorization to the highest end. I went with the 80th percentile. \nprint(outlier[1])\nwv2 = winsorize(le[outlier[1]], (0, 0.15))\nplt.boxplot(wv2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a column to the datatable for this transformation.\nle[\"w\"+ outlier[1]] = wv2\n\n# Apply one-way winsorization to the highest end. I went with the 80th percentile. \nprint(outlier[2])\nwv3 = winsorize(le[outlier[2]], (0, 0.2))\nplt.boxplot(wv3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a column to the datatable for this transformation.\nle[\"w\"+ outlier[2]] = wv3\n\n# Apply one-way winsorization to the highest end. I went with the 80th percentile. \nprint(outlier[3])\nwv4 = winsorize(le[outlier[3]], (0, 0.0))\nplt.boxplot(wv4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a column to the datatable for this transformation.\nle[\"w\"+ outlier[3]] = wv4\n\n# Apply one-way winsorization to the highest end. I went with the 80th percentile. \nprint(outlier[4])\nwv5 = winsorize(le[outlier[4]], (0, 1.0))\nplt.boxplot(wv4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[outlier[4]].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A winsorize transformation worked for all variables except the HIV/AIDS variable. What impact do I believe that this data will have when run againsed the life expectancy? Even with this many outlier values, I should be able to gain a correlation understanding - I think. "},{"metadata":{"trusted":true},"cell_type":"code","source":"le['Life expectancy '].corr(le[' HIV/AIDS'])\nle.plot.scatter(x='Life expectancy ', y=' HIV/AIDS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution isn't normal, so it's difficult to get a good comparison between these two variables. When I think on whether or not they'll make a good feature in my model, I'm also thinking about the other features that I'm using. Measles and HIV/AIDS seem to make more sense in another model that is looking at the impact of diseases on our overall life expectancy. Wheras this dataset, seems to be looking at how the the percent expenditures and infant deaths would relate to our overall life expentancy. At least that appears to be the direction I'm heading.\n\nA log transformation COULD fit this data to the model, but because of the features that I've started to eliminate with respect to my approach, I'm going to work without measles and HIV/AIDS. They need to be investigated and handled separately - like all other diseases.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(le.columns)\nomit = [' HIV/AIDS', 'Measles ', 'wMeasles ' ]\n#drop those features you don't want to use right now. \ncols =  [x for x in cols if x not in omit]\nle = le[cols]\nle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Explore the data using univariate and multivariate exploration techniques. You should pay special attention to your target variable. In this regard, your focus should be on finding the relevant variables that may affect life expectancy.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"le.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le.plot.scatter(x='Life expectancy ', y=\"percentage expenditure\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le.plot.scatter(x='Life expectancy ', y=\"wpercentage expenditure\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max = 0.0\nvar = 'Life expectancy '\n\n\n#slice the columns from five on - since these are numerical data that don't include the area(s) of interest. \nfor col in cols[4:]:\n    correlation = le[var].corr(le[col])\n    print(\"The correlation score for {} is {} \".format(col, correlation ))\n    \n    if abs(correlation) >= max:\n        max = abs(correlation)\n        best = col\n\nprint(\"The greatest correlation of expenditures against the {} is {}\".format(var, best)) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering\n\nI want to take a closer look at the infant deaths and under five deaths. The percentage expenditures had the second highest correlation, so I want to see how these three relate. "},{"metadata":{"trusted":true},"cell_type":"code","source":"features = cols[-3:]\nle[features].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the infant and under five deaths have a low, but similar correlation to each other. \nthe percentage is pretty far from the rest of them. Good. I understand how these possible components might relate.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"features.append(var)\nle[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,7))\n#Including ci=None because I'm looking at the consequence of including bootstrapping on just two variables when we use all data - on a relatively small dataset. (See summary)\nsns.lineplot(data=le[features], x='Life expectancy ', y='wpercentage expenditure', ci=None)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le[['wunder-five deaths ','winfant deaths', var]].plot(x=var, y=['wunder-five deaths ','winfant deaths'], figsize=(20, 8))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oh yeah, that's right. I can't really plot the under-five deaths and the infant deaths against the life expectancy. I mean, they died before they got that old.\nI'm amazed that I managed to get a graph of this thing. They do relate to each other, though. "},{"metadata":{},"cell_type":"markdown","source":"# Summary\n\nThe life expectancy is most closely related to the country's percentage expenditure. I can see that as the expenditure increases there are gradual increases in the life expectancy. \n\nThis information comes from just one graph. It's inclusive of all people all over the world dating all the way back from 2000 to 2015, which is just five years ago. This is inclusive all of the developed countries, undeveloped countries and regardless of disease. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,7))\nsns.lineplot(data=le[features], x='Life expectancy ', y='wpercentage expenditure')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time, countries, whether or not those countries are developing. It would be interesting to pull these together and place them on this chart to see what impact they may have. \n\nAs far as the diseases are concerned. Well. The investigation on what impact disease has on life expectancy is a experiment for another day. I'd be most excited to see what impact they have on children, as well as to pull in some information about when we introduced the polio vaccine - and all the other vaccines. \n\nThat'll take a bit of time. "},{"metadata":{},"cell_type":"markdown","source":"#### Afterward \n\nI need to incorporate into my cleaning processes to include the removal of extra spaces that occur at the beginning and the end of these columns to increase the navigation through the data during my exploration. It's not something I have immediate time for, currently. It is something that happens, often.\n\nInplace reassignment had a big impact on my performance. I make a lot of typos, mini programming errs, etc. while I'm working. These inplace commands slow me down and force me to rerun an entire session. I might want to refrain from using them.\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}