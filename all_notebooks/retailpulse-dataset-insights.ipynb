{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Installing libraries for accessing excel data","metadata":{}},{"cell_type":"code","source":"!pip install xlrd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading required libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport datetime as dt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_excel('../input/uci-online-retail-ii-data-set/online_retail_II.xlsx', sheet_name=\"Year 2010-2011\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### General information and playing with dataset","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exploring individual variables","metadata":{}},{"cell_type":"code","source":"df['StockCode'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Printing the top 10 most ordered `StockCode` items (first item from each code)","metadata":{}},{"cell_type":"code","source":"top_codes = df.groupby('StockCode').agg({'Quantity': sum}).sort_values('Quantity', ascending=False).head(10)\ntop_codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = []\nfor code in top_codes.index:\n    idx.append(df[df['StockCode'] == code].index[0])\n\ndf.loc[idx].sort_values('Quantity', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quantity = df['Country'].value_counts().head()\nquantity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=quantity.values, y=quantity.index)\nax.set(title='Countries with max quantities', xlabel='Quantity', ylabel='Country')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is pretty clear that the dataset consists of transaction pre-dominantly from the UK, followed by Germany and France.","metadata":{}},{"cell_type":"markdown","source":"#### Let's see the most ordered items in various countries","metadata":{}},{"cell_type":"code","source":"df.loc[df.groupby('Country')['Quantity'].idxmax()].sort_values('Quantity', ascending=False).head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Well, it looks like Rabbit Night Light is pretty famous in Netherlands, Japan and France as it the most ordered item in all three countries!","metadata":{}},{"cell_type":"code","source":"df_cop = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Pre-processing\n#### Since, there are many null values present in the data, we will get rid of them to perform a more cleaner and safer data analysis.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are also many transactions with negative `Quantity`. Let;s remove these as well since they might interfere with the further analysis.","metadata":{}},{"cell_type":"code","source":"print(\"Number of negative-quantity transactions before: \", (df['Quantity'] < 1).sum())\ndf = df[df['Quantity'] > 1]\nprint(\"Number of negative-quantity transactions now: \", (df['Quantity'] < 1).sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Before moving further, let's add another column `Revenue` to the dataset which will denote the money made from each transaction.","metadata":{}},{"cell_type":"code","source":"df['Revenue'] = df['Quantity']*df['Price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Customer Segmentation using RFM Analysis: (R)ecency, (F)requency, (M)onetary\n\n#### This technique is used for determining marketing, PR and sales strategies based on the consumers' previous transaction data and habits.\n\n### Recency\n#### Recency refers to the time since the customer has made their last purchase. Thus, a lesser recency means that the customer was recently in cotact with the company\n\n\n### Frequency\n#### It determines how often the customer has been making purchases. The more, the merrier.\n\n\n### Monetary\n#### Total money spent by the customer in all transactions","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Recency Score\n\n#### Usually, Recency score is calculated by: Today's date - Last transaction date\n#### But it is not a very realistic idea to use today's day here as it will keep on changing. Instead we will use the last transaction date from the dataset","metadata":{}},{"cell_type":"code","source":"df['InvoiceDate'].max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"today_date = dt.datetime(2011, 12, 9)\ntoday_date","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert Customer ID to integer from string\ndf['Customer ID'] = df['Customer ID'].astype(int)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recency_df = today_date - df.groupby('Customer ID').agg({'InvoiceDate': 'max'})\nrecency_df.rename(columns={'InvoiceDate': 'Recency'}, inplace=True)\nrecency_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Convert recency score to numbers based on days","metadata":{}},{"cell_type":"code","source":"recency_df['Recency'] = recency_df['Recency'].apply(lambda score: score.days)\nrecency_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Frequency Score\n\n#### We can find the frequency for each CustomerID by counting the respective number invoices for each customer","metadata":{}},{"cell_type":"code","source":"temp_df = df.groupby([\"Customer ID\",\"Invoice\"]).agg({\"Invoice\":\"count\"})\ntemp_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_df = temp_df.groupby('Customer ID').agg({'Invoice': 'count'})\nfreq_df.rename(columns={'Invoice': 'Frequency'}, inplace=True)\nfreq_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Monetary Score\n#### We can calculate the monetary score by simply adding the Revenue for each CustomerID group","metadata":{}},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monetary_df = df.groupby(\"Customer ID\").agg({\"Revenue\":\"sum\"})\nmonetary_df['Revenue'] = monetary_df['Revenue'].astype(int)\nmonetary_df.rename(columns={'Revenue': 'Monetary'}, inplace=True)\nmonetary_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenating all three\nrfm = pd.concat([recency_df, freq_df, monetary_df],  axis=1)\nrfm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There is a table commonly used in RFM Analysis as shown below. \n#### Generally, 2 parameters are used in these tables. These are Recency and Frequency values. \n#### Here the values ​​for these parameters are given. As can be seen, the values ​​are between 1 and 5. 5 means very good, 1 means very bad. As seen in this table, customers are divided into segments. Customer segments are determined by looking at the parameter values. \n\n#### The group that we should pay attention to here is actually not the champions group that everyone thinks of, this group is already visiting us and shopping and leaving money. The most important class here is the class \"can't loose them\". Because these people almost never visit us and do a lot of shopping, so as you can see frequency values ​​5, we need to focus on this class. Because the customers in this group will leave us, therefore, they require attention and we must bring the customers in this group to us by making the necessary analysis. \n\n#### At the same time, there is a \"need attention\" group. We need to animate it by sending special mails to the group with a Recency value of 3 and the group with a Frequency value of 3, and to the group that is asleep, by making promotions, and moving it to the right or upwards in the table. In short, we can explain this table in this way. This table is the main logic of RFM analysis.","metadata":{}},{"cell_type":"markdown","source":"![](https://guillaume-martin.github.io/images/rfm-segments.png)","metadata":{}},{"cell_type":"markdown","source":"#### We divide all the score into 5 categories with qcut function where 5 is the best and 1 is the worst. For Frequency most recent transaction is the best.","metadata":{}},{"cell_type":"code","source":"rfm[\"RecencyScore\"] = pd.qcut(rfm['Recency'], 5, labels=[5, 4, 3, 2, 1])\nrfm[\"FrequencyScore\"] = pd.qcut(rfm['Frequency'].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\nrfm[\"MonetaryScore\"] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### After calculating RFM scores, we combine scores as a new column","metadata":{}},{"cell_type":"code","source":"rfm[\"RFM_SCORE\"] = (rfm['RecencyScore'].astype(str) +\n                    rfm['FrequencyScore'].astype(str) +\n                    rfm['MonetaryScore'].astype(str))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#### Here, classes are assigned based on rfm scores. The score range for these classes is stated below.\n#### As an example, the Hibernating class has the following score values.\n#### Those with Recency value 1-2 and Frequency value 1-2 are read in other classes in this way.\n#### The reason for adding only Recency and Frequency here is because only these two parameters are included in the table, but Monetary can also be added next to them.","metadata":{}},{"cell_type":"code","source":"seg_map = {\n    r'[1-2][1-2]': 'Hibernating',\n    r'[1-2][3-4]': 'At Risk',\n    r'[1-2]5': 'Can\\'t Loose',\n    r'3[1-2]': 'About to Sleep',\n    r'33': 'Need Attention',\n    r'[3-4][4-5]': 'Loyal Customers',\n    r'41': 'Promising',\n    r'51': 'New Customers',\n    r'[4-5][2-3]': 'Potential Loyalists',\n    r'5[4-5]': 'Champions'\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We add a new column to rfm dataframe as \"Segment\"\n\nrfm['Segment'] = rfm['RecencyScore'].astype(str) + rfm['FrequencyScore'].astype(str)\nrfm['Segment'] = rfm['Segment'].replace(seg_map, regex=True)\nrfm.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In this way, we have divided all the customers into 10 segments based on their Recency and Frequency Scores.\n#### We can easily determine the customers that the company needs to focus more upon or the new customers or which of them are the loyal ones etc..","metadata":{}},{"cell_type":"markdown","source":"### Visualizing the percentage of different segments","metadata":{}},{"cell_type":"code","source":"segments_counts = rfm['Segment'].value_counts().sort_values(ascending=True)\n\nfig, ax = plt.subplots()\n\nbars = ax.barh(range(len(segments_counts)),\n              segments_counts,\n              color='silver')\nax.set_frame_on(False)\nax.tick_params(left=False,\n               bottom=False,\n               labelbottom=False)\nax.set_yticks(range(len(segments_counts)))\nax.set_yticklabels(segments_counts.index)\n\nfor i, bar in enumerate(bars):\n        value = bar.get_width()\n        if segments_counts.index[i] in ['Can\\'t loose']:\n            bar.set_color('firebrick')\n        ax.text(value,\n                bar.get_y() + bar.get_height()/2,\n                '{:,} ({:}%)'.format(int(value),\n                                   int(value*100/segments_counts.sum())),\n                va='center',\n                ha='left'\n               )\n\nplt.title('Different Customer Segments')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm[[\"Segment\", \"Recency\",\"Frequency\",\"Monetary\"]].groupby(\"Segment\").agg([\"mean\",\"count\",\"max\"]).head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comments and Insights","metadata":{}},{"cell_type":"markdown","source":"#### I will make my comments according to the descriptive statistics above. The 4 segments to be selected are as follows;\n\n### 1. Champions\n#### There are 665 people in this segment,\n#### on average, their last purchase took place 4 days ago,\n#### their shopping frequency is 15, they have 248 purchases in total,\n#### They spent 279489 dollars / TL.\n\n### 2. About to Sleep\n#### There are 369 people in this segment,\n#### on average, their last shopping took place 51 days ago,\n#### their shopping frequency is 1, they have 2 purchases in total,\n#### They spent 6208 dollars / TL.\n\n### 3. Need Attention\n#### There are 190 people in this segment,\n#### On average, their last purchase took place 48 days ago,\n#### their shopping frequency is 3, they have 4 purchases in total,\n#### They had an expenditure of 3546 dollars / TL.\n\n### 4. Can't Loose \n#### There are 68 people in this segment,\n#### On average, their last purchase was 132 days ago,\n#### Shopping frequency is 10, they have 35 purchases in total\n#### 10217 dollars / TL spent.\n\n### ACTION \nCommunicating with people in the Champions segment will make them feel valued and appreciated. These customers are likely to account for a disproportionately high percentage of total revenues, so focusing on keeping them happy should be a top priority. By further analyzing individual preferences and affinities, it will provide additional opportunities for more personalized messaging. For example, personal messages such as congratulations on birthdays can be sent. They may be early adopters for new products, and they can help us promote our brand by communicating our new products to them free of charge.\n\nBy sharing our valuable resources to people in the about to sleep segment, we can recommend popular products / renewals at a discount, reconnect with them and make them our customers.\n\nWe can make limited-time offers to people in the Need Attention segment, which will push them to shop with us, we can make recommendations based on past purchases. That way, we can reactivate them so they can shop.\n\nCan't Loose is one of the segments that should be given importance. This segment is the one we do not want to lose. The fact that their last purchase was made 132 days ago is a bad result. However, the total number of purchases made is a very high figure. 35 total sales were made. Actually, they shop, but they do not shop at once or in a few times and do not shop again for a long time. We can win back by offering renewals, newer products to people in this segment, or by giving them special promotions, small-scale money points, we should not put the people here in competition, we can win by talking to them by sending e-mails and sms. We can make corrections from the survey results by conducting surveys to find out what went wrong.","metadata":{}},{"cell_type":"markdown","source":"# Customer Lifetime Value Calculation","metadata":{}},{"cell_type":"markdown","source":"Firms use many techniques and methods to make these critical decisions. Customer lifetime value (also called CLV or CLTV ) is one of the technique which is rapidly gaining acceptance as a metric to acquire, grow, and retain the “right” customers in customer relationship management (CRM).\n\nCustomer lifetime value for a firm is the net profit or loss to the firm from a customer over the entire life of transactions of that customer with the firm.\n\nThroughout this project, customer lifetime value example for the calculation will be discussed with and customers will be divided into 4 segments according to CLTV value.","metadata":{}},{"cell_type":"code","source":"# cltv_df dataframe is created in order for ease of calculation and observation\ncltv_df = df.groupby('Customer ID').agg({'Invoice': lambda x: len(x),\n                                         'Quantity': lambda x: x.sum(),\n                                         'Revenue': lambda x: x.sum()})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total transaction, total unit, total price\ncltv_df.columns = ['total_transaction', 'total_unit', 'total_price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cltv_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Required formulas for Customer Lifetime Value Calculation\n\n### - Average_Order_Value = Total_Revenue / Total_Number_of_Orders\n### - Purchase_Frequency =  Total_Number_of_Orders / Total_Number_of_Customers\n### - Customer_Value(CV)  = Average_Order_Value * Purchase_Frequency\n\n### - Churn_Rate = 1 - Repeat_Rate\n### - Profit_margin\n### - CLTV = (Customer_Value / Churn_Rate) x Profit_margin.","metadata":{}},{"cell_type":"markdown","source":"For CV calculation AOV and Frequency is required\n\nAverage Order Value = Total Revenue / Total Number of Orders\n\nAOV Calculation:","metadata":{}},{"cell_type":"code","source":"cltv_df[\"avg_order_value\"] = cltv_df[\"total_price\"]/ cltv_df[\"total_transaction\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Customer number:\ncltv_df.shape[0]\n\ncltv_df[\"purchase_frequency\"] = cltv_df[\"total_transaction\"]/cltv_df.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Repeat Rate & Churn Rate\n\n\nIf total transaction is bigger than 1 means that these customers were here more than once\nFor repeat rate, the value where the total transaction is greater than 1 is selected.\n\n\n**Repeat Rate** = Number of customers who have purchased more than once / Number of Customers\n\nThe churn rate, also known as the customer churn, is the rate at which customers stop doing business with an instution.\n\nFormula for the calculation of churn rate:\n**churn_rate** = 1- repeat_rate\n","metadata":{}},{"cell_type":"code","source":"repeat_rate = cltv_df[cltv_df.total_transaction > 1].shape[0]/cltv_df.shape[0]\n\nchurn_rate = 1- repeat_rate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Profit Margin\n\n\nHere for this problem profit margin is chosen as 5%, actually the calculated value here can be called as Profit\nHowever it can be named as profit margin in order not to confuse the formulas.\n","metadata":{}},{"cell_type":"code","source":"# profit margin : 5 %\ncltv_df[\"profit_margin\"] = cltv_df[\"total_price\"]* 0.05\ncltv_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Calculate Customer Lifetime Value\n\nCustomer value (CV) is calculated by using average order value and purchase frequency. Then by using CV, profit margin and churn rate CLTV is calculated.\n","metadata":{}},{"cell_type":"code","source":"# Customer Value(CV):\ncltv_df[\"CV\"] = cltv_df[\"avg_order_value\"] * cltv_df[\"purchase_frequency\"]\ncltv_df.head()\n\n#Customer Lifetime Value(CLTV):\ncltv_df[\"CLTV\"] = (cltv_df[\"CV\"] /churn_rate)* cltv_df[\"profit_margin\"]\n\ncltv_df.sort_values(\"CLTV\", ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range= (1,100))\nscaler.fit(cltv_df[[\"CLTV\"]])\ncltv_df[\"SCALED_CLTV\"] = scaler.transform(cltv_df[[\"CLTV\"]])\ncltv_df.sort_values(\"CLTV\", ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" For comparison of values, variables are chosen from dataframe and values are sorted by \"SCALED_CLTV\"\n","metadata":{}},{"cell_type":"code","source":"cltv_df[[\"total_transaction\", \"total_unit\",\"total_price\",\"CLTV\", \"SCALED_CLTV\"]].\\\nsort_values(by = \"SCALED_CLTV\",ascending= False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Segments are created by using qcut.\n\nSegments are helpful to make the customer experience personalized","metadata":{}},{"cell_type":"code","source":"cltv_df[\"Segment\"] = pd.qcut(cltv_df[\"SCALED_CLTV\"], 4, labels = [\"D\", \"C\", \"B\", \"A\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total transaction, total unit, total price, CLTV and SCALED CLTV values are interpreted with their count, sum, and mean values.","metadata":{}},{"cell_type":"code","source":"cltv_df.groupby(\"Segment\")[[\"total_transaction\", \"total_unit\", \"total_price\", \"CLTV\", \"SCALED_CLTV\"]].agg(\n    {\"count\", \"mean\", \"sum\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This way, we can segment the customers according to their Life Time Value","metadata":{}},{"cell_type":"markdown","source":"### Calculating the most popular month of the year","metadata":{}},{"cell_type":"code","source":"def num_to_name(month):\n    names = {\n        1: \"January\",\n        2: \"February\",\n        3: \"March\",\n        4: \"April\",\n        5: \"May\",\n        6: \"June\",\n        7: \"July\",\n        8: \"August\",\n        9: \"September\",\n        10: \"October\",\n        11: \"November\",\n        12: \"December\"\n    }\n    \n    return names[month]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monthly_data = df['InvoiceDate'].apply(lambda date: date.month).value_counts().sort_values(ascending=False)\nmonthly_data = pd.DataFrame(monthly_data)\nmonthly_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monthly_data['Month'] = monthly_data.index\nmonthly_data['Month'] = monthly_data['Month'].apply(lambda num: num_to_name(num))\nmonthly_data.rename(columns={'InvoiceDate': 'Invoices'}, inplace=True)\nmonthly_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x='Invoices', y='Month', data=monthly_data)\nax.set(title='Popularity across months', xlabel='Number of invoices', ylabel='Month')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Therefore, we can conclude that November was the most popular and the most profitable month for the company.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}