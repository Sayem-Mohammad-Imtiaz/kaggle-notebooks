{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"4324c511-2ee9-8382-a4e4-6c88a7eb5e5c"},"source":"A script to show how to get started with segmenting superpixels in PETCT images. Here we show both 2d, 3d, single channel and multichannel analyses"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd1d06de-3331-4fb7-fef2-1250ca6ab4ee"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom skimage.util.montage import montage2d\nimport os\nimport h5py\nmake_proj = lambda x: np.sum(x,1)[::-1]\nmake_mip = lambda x: np.max(x,1)[::-1]"},{"cell_type":"markdown","metadata":{"_cell_guid":"b508aa73-eb83-77d0-6d1b-15e98e5ea52f"},"source":"# Loading and Displaying PET and CT\nHere we load the PET and CT data from a single patient and show the projection image for CT and the MIP view for the PET data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f75abea4-fcd8-12d0-339a-98a5fbea8306"},"outputs":[],"source":"%matplotlib inline\nwith h5py.File(os.path.join('..', 'input', 'lab_petct_vox_5.00mm.h5'), 'r') as p_data:\n    id_list = list(p_data['ct_data'].keys())\n    print(list(p_data.keys()))\n    ct_image = p_data['ct_data'][id_list[0]].value\n    pet_image = p_data['pet_data'][id_list[0]].value\n    label_image = (p_data['label_data'][id_list[0]].value>0).astype(np.uint8)\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (12, 4))\nct_proj = make_proj(ct_image)\nsuv_max = make_mip(pet_image)\nlab_proj = make_proj(label_image)\nax1.imshow(ct_proj, cmap = 'bone')\nax1.set_title('CT Image')\nax2.imshow(np.sqrt(suv_max), cmap = 'magma')\nax2.set_title('SUV Image')\nax3.imshow(lab_proj, cmap = 'gist_earth')\nax3.set_title('Tumor Labels')"},{"cell_type":"markdown","metadata":{"_cell_guid":"610beb89-b447-5d85-75c0-eb2cf9146a96"},"source":"# Make a Superpixel Segmentation of the images\nWe make basic superpixels for the CT image here. The primary parameters we adjust are the \n\n - **n_segments** the number of different segments to make (approximately)\n - **compactness** the weight of spatial dimensions versus image intensity (low values are more irregularly shaped)"},{"cell_type":"markdown","metadata":{"_cell_guid":"530bff45-04f1-d4d7-9f59-da11767ee48f"},"source":"# Combined PET/CT Super-pixels\nHere we use image data from both PET and CT\n# Full 3D Superpixels\nHere we make full 3D superpixels for PETCT and show a simple rendering of them"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fef8216f-d1d3-040a-3bad-4811dab5a419"},"outputs":[],"source":"pet_weight = 1.0 # how strongly to weight the pet_signal (1.0 is the same as CT)\npetct_vol = np.stack([np.stack([(ct_slice+1024).clip(0,2048)/2048, \n                            pet_weight*(suv_slice).clip(0,5)/5.0\n                           ],-1) for ct_slice, suv_slice in zip(ct_image, pet_image)],0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ca7a2ea-6dcf-8722-5ee6-4ff6c2ed49ec"},"outputs":[],"source":"%%time\nfrom skimage.segmentation import slic\nfrom skimage.segmentation import mark_boundaries\n\npetct_segs = slic(petct_vol, \n                  n_segments = 2000, \n                  compactness = 0.1,\n                 multichannel = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d722d804-2218-335c-86cf-62e8de438f35"},"outputs":[],"source":"petct_max_segs = make_mip(petct_segs)\nct_proj = make_proj(petct_vol[:,:,:,0])\nsuv_mip = make_mip(petct_vol[:,:,:,1])\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (14, 6))\nax1.imshow(suv_mip, cmap = 'magma')\nax1.set_title('SUV Image')\nax2.imshow(petct_max_segs, cmap = plt.cm.rainbow)\nax2.set_title('Segmented Image')\nax3.imshow(mark_boundaries(suv_mip, petct_max_segs))"},{"cell_type":"markdown","metadata":{"_cell_guid":"788bb6ee-07a3-2ab8-e13c-b5cc1e574ef5"},"source":"## Compare Segments to Labels\nWe look at each superpixel and see how many different labels are inside it. We want each superpixel to be an 'atomic' unit of the image and so we only want one in each"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"485205e9-10fe-0926-41cc-16ab790c3aad"},"outputs":[],"source":"for idx in np.unique(petct_segs):\n    cur_region_mask = petct_segs == idx\n    labels_in_region = label_image[cur_region_mask]\n    labeled_regions_inside = np.unique(labels_in_region)\n    if len(labeled_regions_inside)>1:\n        print('Superpixel id', idx, 'regions', len(labeled_regions_inside))\n        print('\\n',pd.value_counts(labels_in_region))\n        print('Missclassified Pixels:', np.sum(pd.value_counts(labels_in_region)[1:].values))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e93a6f6-5059-baf6-c8cd-bf1319811614"},"outputs":[],"source":"pd.value_counts(labels_in_region)[1:].values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"592e61d9-a830-a7ef-e1fa-85f005d6b987"},"outputs":[],"source":"nz_labels = [i for i in np.unique(label_image) if i>=0]\nfig, m_axs = plt.subplots(len(nz_labels), 2, figsize = (5, 15))\nfor (ax1, ax2), i_label in zip(m_axs, nz_labels):\n    out_sp = np.zeros_like(petct_segs)\n    cur_label_mask = label_image == i_label\n    labels_in_region = petct_segs[cur_label_mask]\n    \n    superpixels_in_region = np.unique(labels_in_region)\n    for i, sp_idx in enumerate(superpixels_in_region):\n        out_sp[petct_segs == sp_idx] = i+1\n    \n    ax1.imshow(make_proj(cur_label_mask), cmap = 'bone')\n    ax1.set_title('Label Map {}'.format(i_label) if i_label>0 else 'Background Label')\n    ax1.axis('off')\n    \n    ax2.imshow(make_proj(out_sp), cmap = 'gist_earth')\n    ax2.set_title('Superpixels ({})'.format(len(superpixels_in_region)))\n    ax2.axis('off')"},{"cell_type":"markdown","metadata":{"_cell_guid":"3215327d-ad91-e365-9c02-ee735fd0d083"},"source":"## Show the superpixels for each label\nHere we can show which superpixels are inside each label."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68bd9eaf-6a55-c4a7-5ace-d67c3b4056b5"},"outputs":[],"source":"for idx in np.unique(label_image):\n    cur_region_mask = label_image == idx\n    labels_in_region = petct_segs[cur_region_mask]\n    labeled_regions_inside = np.unique(labels_in_region)\n    print('Label id', idx, 'superpixels inside', len(labeled_regions_inside))\n    #print(pd.value_counts(labels_in_region))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7c3c6145-b642-981c-78e2-052bd39c1b11"},"source":"# Optimize Superpixel Size"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26b3915a-53bd-4a44-77f9-bf092683bf4c"},"outputs":[],"source":"def label_score(gt_labels, sp_segs):\n    # type: (np.ndarray, np.ndarray) -> float\n    \"\"\"\n    Score how well the superpixels match to the ground truth labels. \n    Here we use a simple penalty of number of pixels misclassified\n    :param gt_labels: the ground truth labels (from an annotation tool)\n    :param sp_segs: the superpixel segmentation\n    :return: the score (lower is better)\n    \"\"\"\n    out_score = 0\n    for idx in np.unique(sp_segs):\n        cur_region_mask = sp_segs == idx\n        labels_in_region = gt_labels[cur_region_mask]\n        out_score += np.sum(pd.value_counts(labels_in_region)[1:].values)\n    return out_score\n\nprint('Label Score', label_score(label_image, petct_segs))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4a39a44-8d01-e835-8843-f6de60f97e03"},"outputs":[],"source":"# Make new superpixels\ndef make_superpixel(pet_weight = 1.0, # how strongly to weight the pet_signal (1.0 is the same as CT)\n                    n_segments = 1000, # number of segments\n                    compactness = 0.1): # how compact the segments are\n    \n    t_petct_vol = np.stack([np.stack([(ct_slice+1024).clip(0,2048)/2048, \n                            pet_weight*(suv_slice).clip(0,5)/5.0\n                           ],-1) for ct_slice, suv_slice in zip(ct_image, pet_image)],0)\n    petct_segs = slic(t_petct_vol, \n                  n_segments = n_segments, \n                  compactness = compactness,\n                 multichannel = True)\n    return petct_segs\n\ndef make_and_score(*args, **kwargs):\n    n_segs = make_superpixel(*args, **kwargs)\n    return label_score(label_image, n_segs)\n# run it quickly with 10000 segments and it should have many fewer misclassified\nprint('Misclassified Pixels', make_and_score(n_segments = 100000))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33a2fe44-f9ee-4381-852b-db33e8235a65"},"outputs":[],"source":"# test 3 different values for n_segments to see how the performance changes\nn_segments = [10, 100, 1000]\nn_score = [make_and_score(n_segments = c_seg) for c_seg in n_segments]\nprint(n_score)\nplt.plot(n_segments, n_score, 'b-')\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b6ad94e-25f7-03ac-e6be-194196fe20ac"},"outputs":[],"source":"# Optimize the values\nfrom scipy.optimize import fmin"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c42dcbb8-83d7-86a6-b3a8-202b677dec46"},"outputs":[],"source":"bright_segs = np.zeros_like(petct_segs)\nkept_comps = 0\nfor i in np.unique(petct_segs):\n    if pet_image[petct_segs == i].mean()>1.5:\n        bright_segs[petct_segs == i] = 1\n        kept_comps+=1\nprint('Kept', kept_comps,'of', len(np.unique(petct_segs)))\nbright_sum_segs = make_proj(bright_segs)\nfig, (ax1, ax2) = plt.subplots(1,2, figsize = (14, 6))\nax1.imshow(suv_max, cmap = 'magma')\nax1.set_title('SUV Image')\nax2.imshow(bright_sum_segs, cmap = plt.cm.bone)\nax2.set_title('Segments Image')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"214b214f-3f3c-48c1-599a-f252cf7c8319"},"outputs":[],"source":"from mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage import measure\ndef show_3d_mesh(image, threshold):\n    p = image[::-1].swapaxes(1,2)\n    \n    verts, faces = measure.marching_cubes(p, threshold)\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n    mesh = Poly3DCollection(verts[faces], alpha=0.15, edgecolor='none', linewidth = 0.1)\n    mesh.set_facecolor([.1, 1, .1])\n    mesh.set_edgecolor([1, 0, 0])\n    \n    ax.add_collection3d(mesh)\n\n    ax.set_xlim(0, p.shape[0])\n    ax.set_ylim(0, p.shape[1])\n    ax.set_zlim(0, p.shape[2])\n    \n    ax.view_init(80, 5)\n    return fig"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46d626e5-7949-2d6f-0baf-e464749525c4"},"outputs":[],"source":"_ = show_3d_mesh(bright_segs, 0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9022888f-b74f-d4d5-26ee-2c0893eb104e"},"outputs":[],"source":"from mpl_toolkits.mplot3d.axes3d import Axes3D\ndef show_pet_3d(image, pet_signal, threshold):\n    p = image[::-1].swapaxes(1,2)\n\n    fig = plt.figure(figsize=(10, 10))\n    ax1 = fig.add_subplot(121, projection='3d')\n    \n    verts, faces = measure.marching_cubes(p, 0)\n    mesh = Poly3DCollection(verts[faces], alpha=0.15, edgecolor='none', linewidth = 0.1)\n    mesh.set_facecolor([.1, 1, .1])\n    mesh.set_edgecolor([1, 0, 0])\n    \n    ax1.add_collection3d(mesh)\n\n    ax1.set_xlim(0, p.shape[0])\n    ax1.set_ylim(0, p.shape[1])\n    ax1.set_zlim(0, p.shape[2])\n    \n    ax1.view_init(80, 5)\n    \n    ax2 = fig.add_subplot(122, projection='3d')\n    p_pet = pet_signal[::-1].swapaxes(1,2)\n    \n    verts, faces = measure.marching_cubes(p_pet, threshold)\n    mesh = Poly3DCollection(verts[faces], alpha=0.15, edgecolor='none', linewidth = 0.1)\n    mesh.set_facecolor([1, 0, .1])\n    mesh.set_edgecolor([.1, 0, 1.0])\n    \n    ax2.add_collection3d(mesh)\n\n    ax2.set_xlim(0, p.shape[0])\n    ax2.set_ylim(0, p.shape[1])\n    ax2.set_zlim(0, p.shape[2])\n    ax2.view_init(80, 5)\n    return fig"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"229c2be0-6e65-ea7a-73e9-645261d58f01"},"outputs":[],"source":"bright_seg_pet = pet_image.copy()\nbright_seg_pet[bright_segs==0] = 0\n_ = show_pet_3d(bright_segs, bright_seg_pet, 1.5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50ee5e29-cdfb-03c5-61ce-39e2a27b6165"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}