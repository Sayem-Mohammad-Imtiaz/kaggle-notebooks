{"cells":[{"metadata":{},"cell_type":"markdown","source":"## RFM Analysis & Association Rules For Successful Customer Segmentation\n*“RFM is a method used for analyzing customer value”.*\n* It groups customers based on their transaction history :\n  * Recency        — How many days ago was their last purchase?\n  * Frequency      — How many times has the customer purchased from our store?\n  * Monetary Value — How much do they spend?\n\n\n<hr>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n<br>\n<font color = 'blue'>\n<b>Content: </b>\n\n1. [Load Libraries](#1)\n1. [Load Dataset](#2)\n1. [Spending of Countries](#3)\n1. [How RFM Analysis Works](#4)\n1. [Find Recency, Monetary and Frequency](#5)\n    * [RFM Dataframe](#6)\n    * [RFM Segmentation](#7)\n    * [RFM Segmentation Readily Answers These Questions For Business](#8)\n        * [Who are my best customers?](#9)\n        * [Which customers are at the verge of churning?](#10)\n        * [Who are the lost customers?](#11)\n        * [Who are the loyal customers?](#12)\n    * [Summing the RFM Score](#13)\n        * [Making Classification For Customers Depends On RFM Sum Score](#14) \n        * [RFM Segmentation Visualization](#15)\n1. [K-Means Segmentation](#16)\n    * [Plot RFM Distributions](#17)\n    * [Normalization](#18)\n    * [Elbow Method](#19)\n    * [KMeans Clustering with 4 Clusters](#20)\n    * [Which Cluster Is Our Best Customers](#21)\n1. [Association Rules](#22)\n    * [Support & Confidence Values](#23)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"1\"></a><br>\n## Load Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport datetime as dt\nimport matplotlib.pyplot as plt\nimport squarify\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import MinMaxScaler\n#\nfrom sklearn.cluster import KMeans\n#\nimport plotly.offline as pyo \nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n#\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"2\"></a><br>\n## Load Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/ecommerce-data/data.csv\",encoding = 'unicode_escape')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of Countries \ndata[\"Country\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check missing values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total Price\ndata['TotalPrice'] = data['UnitPrice'] * data['Quantity']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total Spending of Countries\ndata_country = data.groupby(\"Country\").agg({'TotalPrice': lambda x: x.sum()})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Unnecessary Countries for Visualization \ndata_country.drop([\"RSA\",\"Unspecified\",\"EIRE\",\"European Community\",\"Channel Islands\"],axis=0,inplace=True)\ndata_country.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"3\"></a><br>\n## Spending of Countries","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"price = []\nfor i in range(len(data_country[\"TotalPrice\"])):\n    price.append(data_country[\"TotalPrice\"][i])\n\ncountry_price = pd.DataFrame(index=[\"AUS\",\"AUT\",\"BHR\",\"BEL\",\"BRA\",\"CAN\",\"CYP\",\"CZE\",\"DNK\",\"FIN\",\"FRA\",\"DEU\",\"GRC\",\"HKG\",\"ISL\",\"ISR\",\n                                    \"ITA\",\"JPN\",\"LBN\",\"LTU\",\"MLT\",\"NLD\",\"NOR\",\"POL\",\"PRT\",\"SAU\",\"SGP\",\"ESP\",\"SWE\",\"CHE\",\"USA\",\n                                    \"ARE\",\"GBR\"],columns=[\"TotalPrice\",\"country\"])\ncountry_price[\"country\"] = data_country.index\ncountry_price[\"TotalPrice\"] = price\ncountry_price.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"worldmap = [dict(type = 'choropleth', locations = country_price['country'], locationmode = 'country names',\n                 z = country_price['TotalPrice'], autocolorscale = True, reversescale = False, \n                 marker = dict(line = dict(color = 'rgb(180,180,180)', width = 0.5)), \n                 colorbar = dict(autotick = False, title = 'Total Price'))]\n\nlayout = dict(title = 'Total Price For Each Country', geo = dict(showframe = False, showcoastlines = True, \n                                                                projection = dict(type = 'Mercator')))\n\nfig = dict(data=worldmap, layout=layout)\npyo.iplot(fig, validate=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"4\"></a><br>\n## How RFM Analysis Works","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Choose the event that signifies activity for your application, and set the date range you want to analyze. An ecommerce app might track purchases, while a media app might monitor content viewed or rated.\n\n* For every user who has performed the defined event, the Analysis will calculate:\n\n  * How many times the event has occurred\n  * The last time a user performed the event\nView a complete analysis of your user base on a Recency and Frequency Grid, broken down into segments.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://d35fo82fjcw0y8.cloudfront.net/2017/12/06085307/In-content-screen-shot-1.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Recency and Frequency Grid\n* A low recency and frequency score (bottom left) represents hibernating users who haven’t been active recently or frequently. A high recency and frequency score (top right) represents users who have been active recently and frequently, indicating your app’s champions.\n\n* Users are then ranked in order of percentile. For example, a user who has performed the activity most recently would constitute the 100th percentile. Users are then ranked by a score of 1 through 5, based on their percentile, with 5 being the highest.\n\n### The Recency and Frequency Grid breaks your user base down into:\n\n* Champions [R(4 – 5), F(4 – 5)]\n* Loyal Customers [R(3 – 4), F(4 – 5)]\n* Potential Loyalists [R(4 – 5), F(2 – 3)]\n* Promising [R(3 – 4), F(0 – 1)]\n* Can’t Lose Them [R(1 – 2), F(4 – 5)]\n* At Risk [R(1 – 2), F(3 – 4)]\n* About to Sleep [R(2 – 3), F(1-2)]\n* Hibernating [R(1 – 2), F(1 – 2)]\n* New Customers R [(4 – 5), F(0 – 1)]\n* Need Attention R [(2 – 3), F(2 – 3)]","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change Data Type:\ndata['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n\n# Adjust today:\ntoday = dt.datetime(2012,1,1)\nprint(today)\n\n# Bigger than zero and just UK\ndata = data[data['Quantity'] > 0]\ndata = data[data['TotalPrice'] > 0]\ndata = data[data[\"Country\"] == \"United Kingdom\"]\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"5\"></a><br>\n## Find Recency, Monetary and Frequency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recency and Monetary \ndata_x = data.groupby('CustomerID').agg({'TotalPrice': lambda x: x.sum(),\n                                        'InvoiceDate': lambda x: (today - x.max()).days})\ndata_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset is basis on StockCode    \ndata_y = data.groupby(['CustomerID','InvoiceNo']).agg({'TotalPrice': lambda x: x.sum()})\ndata_y.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find Frequency\ndata_z = data_y.groupby('CustomerID').agg({'TotalPrice': lambda x: len(x)})\ndata_z.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"6\"></a><br>\n## RFM Dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# RFM Dataframe\nrfm_table= pd.merge(data_x,data_z, on='CustomerID')\n\n# Change Column Name\nrfm_table.rename(columns= {'InvoiceDate': 'Recency',\n                          'TotalPrice_y': 'Frequency',\n                          'TotalPrice_x': 'Monetary'}, inplace= True)\nrfm_table.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"7\"></a><br>\n## RFM Segmentation\n\n* Customers with the lowest recency, highest frequency and monetary amounts considered as top customers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Frequency bulma\ndef FScore(x,p,d):\n    if x <= d[p][0.20]:\n        return 0\n    elif x <= d[p][0.40]:\n        return 1\n    elif x <= d[p][0.60]: \n        return 2\n    elif x <= d[p][0.80]:\n        return 3\n    else:\n        return 4\n\nquantiles = rfm_table.quantile(q=[0.20,0.40,0.60,0.80])\nquantiles = quantiles.to_dict()\nrfm_table['Freq_Tile'] = rfm_table['Frequency'].apply(FScore, args=('Frequency',quantiles,))\n\n#Recency \nrfm_table = rfm_table.sort_values('Recency',ascending=True)\nrfm_table['Rec_Tile'] = pd.qcut(rfm_table['Recency'],5,labels=False)\n\n#Monetary \nrfm_table['Mone_Tile'] = pd.qcut(rfm_table['Monetary'],5,labels=False)\n\n# instead of zero, plus 1 \nrfm_table['Rec_Tile'] = rfm_table['Rec_Tile'] + 1\nrfm_table['Freq_Tile'] = rfm_table['Freq_Tile'] + 1\nrfm_table['Mone_Tile'] = rfm_table['Mone_Tile'] + 1\n\n# Add to dataframe\nrfm_table['RFM Score'] = rfm_table['Rec_Tile'].map(str) + rfm_table['Freq_Tile'].map(str) + rfm_table['Mone_Tile'].map(str)\nrfm_table.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"8\"></a><br>\n## RFM Segmentation Readily Answers These Questions For Business","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"9\"></a><br>\n## Who are my best customers?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm_table[rfm_table['RFM Score'] == '555'].sort_values('Monetary', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"10\"></a><br>\n## Which customers are at the verge of churning?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Customers who's recency value is low\nrfm_table[rfm_table['Rec_Tile'] <= 2 ].sort_values('Monetary', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"11\"></a><br>\n## Who are the lost customers?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Customers who's recency, frequency as well as monetary values are low \nrfm_table[rfm_table['RFM Score'] == '111'].sort_values('Recency',ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"12\"></a><br>\n## Who are the loyal customers?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Customers with high frequency value\n\nrfm_table[rfm_table['Freq_Tile'] >= 3 ].sort_values('Monetary', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"13\"></a><br>\n## Summing the RFM Score\n* One of the most straightforward methods is to sum our scores to a single number and define RFM levels for each score range.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate RFM_Score\nrfm_table['RFM_Sum'] = rfm_table[['Freq_Tile','Rec_Tile','Mone_Tile']].sum(axis=1)\nrfm_table.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"14\"></a><br>\n## Making Segmentation For Customers Depends On RFM Sum Score","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* We can get creative and hypothesize about what each score range entails, but for this exercise I will take inspiration from some common segment names.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define rfm_level function\ndef rfm_level(df):\n    if df['RFM_Sum'] >= 9:\n        return 'Can\\'t Loose Them'\n    elif ((df['RFM_Sum'] >= 8) and (df['RFM_Sum'] < 9)):\n        return 'Champions'\n    elif ((df['RFM_Sum'] >= 7) and (df['RFM_Sum'] < 8)):\n        return 'Loyal'\n    elif ((df['RFM_Sum'] >= 6) and (df['RFM_Sum'] < 7)):\n        return 'Potential'\n    elif ((df['RFM_Sum'] >= 5) and (df['RFM_Sum'] < 6)):\n        return 'Promising'\n    elif ((df['RFM_Sum'] >= 4) and (df['RFM_Sum'] < 5)):\n        return 'Needs Attention'\n    else:\n        return 'Require Activation'\n# Create a new variable RFM_Level\nrfm_table['RFM_Level'] = rfm_table.apply(rfm_level, axis=1)\n# Print the header with top 5 rows to the console\nrfm_table.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm_table[\"RFM_Level\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate average values for each RFM_Level, and return a size of each segment \nrfm_level_agg = rfm_table.groupby('RFM_Level').agg({\n    'Recency': 'mean',\n    'Frequency': 'mean',\n    'Monetary': ['mean', 'count']}).round(1)\n# Print the aggregated dataset\nprint(rfm_level_agg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"15\"></a><br>\n## RFM Segmentation Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfm_level_agg.columns = rfm_level_agg.columns.droplevel()\nrfm_level_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean', 'Count']\n#Create our plot and resize it.\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(16, 9)\nsquarify.plot(sizes=rfm_level_agg['Count'], \n              label=['Can\\'t Loose Them',\n                     'Champions',\n                     'Loyal',\n                     'Needs Attention',\n                     'Potential', \n                     'Promising', \n                     'Require Activation'], alpha=.6 )\nplt.title(\"RFM Segments\",fontsize=18,fontweight=\"bold\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"16\"></a><br>\n## K-Means Segmentation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"17\"></a><br>\n## Plot RFM distributions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\n# Plot distribution of R\nplt.subplot(3, 1, 1); sns.distplot(rfm_table['Recency'],fit=norm)\n# Plot distribution of F\nplt.subplot(3, 1, 2); sns.distplot(rfm_table['Frequency'],fit=norm)\n# Plot distribution of M\nplt.subplot(3, 1, 3); sns.distplot(rfm_table['Monetary'],fit=norm)\n# Show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"18\"></a><br>\n## Normalization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clustering_fm = rfm_table[['Recency',\"Frequency\",\"Monetary\"]].copy()\nclustering_fm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler = MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(clustering_fm)\ndata_scaled2 = pd.DataFrame(x_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_scaled2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"19\"></a><br>\n## Elbow Method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"wscc = []\nfor i in range(1,15): \n    kmeans = KMeans(n_clusters=i, init=\"k-means++\",random_state=0)\n    kmeans.fit(data_scaled2)\n    wscc.append(kmeans.inertia_)  \n\nplt.plot(range(1,15),wscc,marker=\"*\",c=\"black\")\nplt.title(\"Elbow plot for optimal number of clusters\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"20\"></a><br>\n## KMeans clustering with 4 clusters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters = 4, init='k-means++', n_init =10,max_iter = 300)\nkmeans.fit(data_scaled2)\npred = kmeans.predict(data_scaled2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(kmeans.labels_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import silhouette_score\nscore = silhouette_score (data_scaled2, kmeans.labels_)\nprint(\"Score = \", score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_kmeans = kmeans.predict(data_scaled2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_kmeans[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of Clusters\nd_frame = pd.DataFrame(clustering_fm)\nd_frame['cluster'] = y_kmeans\nd_frame['cluster'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_frame.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"21\"></a><br>\n## Which Cluster Is Our Best Customers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"d_frame.groupby('cluster').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = \"22\"></a><br>\n## Association Rules\n* Apriori is an algorithm for frequent item set mining and association rule learning over relational databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_apriori = data[data['Country']=='United Kingdom']\ndata_apriori.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_apriori[\"Description\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Which Product and Their Count \ndata_apr = data_apriori.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\ndata_apr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def num(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n\nbasket_new = data_apr.applymap(num)\nbasket_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.frequent_patterns import fpgrowth\nrule_fp = fpgrowth(basket_new, min_support=0.02, use_colnames=True)\nrule_fp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items = apriori(basket_new, min_support=0.02, use_colnames=True)\nitems","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"23\"></a><br>\n## Support & Confidence Values\t","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Support\n<br>\n\n![](https://miro.medium.com/max/1400/1*bqdq-z4Ec7Uac3TT3H_1Gg.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Confidence\n<br>\n\n![](https://miro.medium.com/max/1400/1*E3mNKHcudWzHySGMvo_vPg.png)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rule = association_rules(items, metric=\"lift\", min_threshold=1)\nrule","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}