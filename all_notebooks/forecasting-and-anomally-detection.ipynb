{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is part of an article about how to forecast and detect anomalies on time-series data. The main objective is to train a RNN regressor on the Bitcoin dataset to predict future values on then detect anomalies in the whole data window - that last step achieved by implementing a RNN Autoencoder.\n\nYou'll see some other models in the notebook that I've provided to you in case they are of your interest and this RNN regressor + RNN Autoencoder doesn't perform well for your purpose in any other scenario.\n\nThe dataset used is available at https://www.kaggle.com/mczielinski/bitcoin-historical-data and contains BITCOIN/USD 1-minute candle data, from 2012-01-01 to 2020-12-31. I hope you can get advantage of this approach!"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport plotly.graph_objects as go\nfrom sklearn.preprocessing import MinMaxScaler\nimport gc\nimport joblib\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers \nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.cluster import KMeans\nimport json\nimport urllib\nfrom datetime import datetime, timedelta,timezone\nimport requests\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"btc = pd.read_csv('/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-12-31.csv')\nbtc.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing\nLet's resample the data, take only the variable we're going to use and determine what's the window of data that's more meaningful for our purpose. Let's also clean null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"btc['Timestamp'] = pd.to_datetime(btc.Timestamp, unit='s')\nbtc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Minutes in dataset: ',len(btc))\nprint('Hours in dataset: ',len(btc)/60)\nprint('Days in dataset: ',len(btc)/60/24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"btc = btc[['Timestamp','Weighted_Price']]\nbtc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"btc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data re-sampling based on 1 hour\n# If you want to sample by day, change H by D\nbtc = btc.resample('H', on='Timestamp')[['Weighted_Price']].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot the whole panorama to visually understand what portion of the set must me removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"    pano = btc.copy() #We're going to use this later\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=pano.index, y=pano['Weighted_Price'],name='Full history BTC price'))\n    fig.update_layout(showlegend=True,title=\"BTC price history\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see above, there's a portion of data at the beginning of the set that contains null values. In addition, those are values that are not common in the current BTC price. We need to get rid of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Starting date selected: ',btc.index[51000])\nprint('NaN values: ',btc.iloc[51000:].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"btc = btc.iloc[51000:]\nbtc.fillna(method ='bfill', inplace = True)\nprint('NaN values: ',btc.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('New data points quantity: ',len(btc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how the new dataset looks like once the null and the close-to-cero values were removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=btc.index, y=btc['Weighted_Price'],name='BTC price'))\nfig.update_layout(showlegend=True,title=\"BTC price history\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that charts fits better with the current BTC price reality. Let's use those samples as our new dataset."},{"metadata":{},"cell_type":"markdown","source":"# Data Splitting\nWe're going to take the test set as the first 20% window. The next 80s as the training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_for_us = btc.copy() #To be used later on Unsupervised Learning\ntraining_start = int(len(btc) * 0.2)\n\ntrain = btc.iloc[training_start:]\ntest = btc.iloc[:training_start]\nprint(\"Total datasets' lenght: \",train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data scaling\n\nThis stage is extremely important as a requisite to train Neural Networks. If you skip this step maybe your model won't converge."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler().fit(train[['Weighted_Price']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_samples(data,column_name,scaler):\n    data[column_name] = scaler.transform(data[[column_name]])\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"joblib.dump(scaler, 'scaler.gz')\nscaler = joblib.load('scaler.gz')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = scale_samples(train.copy(),train.columns[0],scaler)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = scale_samples(test,test.columns[0],scaler)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sequences generation and dataset creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def shift_samples(data,column_name,lookback=24):\n    \"\"\"This function takes a *data* dataframe and returns two numpy arrays: \n    - X corresponds to the same values but packed into n frames of *lookback* values each\n    - Y corresponds to the sample shifted *lookback* steps to the future\n    \"\"\"\n    data_x = []\n    data_y = []\n    for i in range(len(data) - int(lookback)):\n        x_floats = np.array(data.iloc[i:i+lookback])\n        y_floats = np.array(data.iloc[i+lookback])\n        data_x.append(x_floats)\n        data_y.append(y_floats)\n    return np.array(data_x), np.array(data_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = shift_samples(train[['Weighted_Price']],train.columns[0])\nX_test, y_test = shift_samples(test[['Weighted_Price']], test.columns[0])\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Final datasets' shapes:\")\nprint('X_train: '+str(X_train.shape)+', y_train: '+str(y_train.shape))\nprint('X_test: '+str(X_test.shape)+', y_train: '+str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsteps = X_train.shape[1]\nnfeatures = X_train.shape[2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Anomaly detectors' training\n## LSTM Autoencoder Neural Network\n\nThe one that we'll be using along this notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"#First model - LSTM Autoencoder for anomaly detections\n\ndetector = Sequential()\ndetector.add(layers.LSTM(128, input_shape=(tsteps, nfeatures),dropout=0.2))\ndetector.add(layers.Dropout(rate=0.5))\ndetector.add(layers.RepeatVector(tsteps))\ndetector.add(layers.LSTM(128, return_sequences=True,dropout=0.2))\ndetector.add(layers.Dropout(rate=0.5))\ndetector.add(layers.TimeDistributed(layers.Dense(nfeatures))) \n\ndetector.compile(loss='mae', optimizer='adam')\ndetector.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"/kaggle/working/detector.hdf5\", monitor='val_loss', verbose=1,save_best_only=True, mode='auto', period=1)\nhistory1 = detector.fit(X_train,y_train,epochs=50,batch_size=128,verbose=1,validation_split=0.1,callbacks=[checkpoint],shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history1.history['loss'], label='Training Loss')\nplt.plot(history1.history['val_loss'], label='Validation Loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's load the best model obtained during training\ndetector = load_model(\"detector.hdf5\")\ndetector.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Determining threshold for Autoencoder detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pred = detector.predict(X_train)\nloss_mae = np.mean(np.abs(X_train_pred - X_train), axis=1) #This is the formula to calculate MAE\nsns.distplot(loss_mae, bins=100, kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pred = detector.predict(X_test)\nloss_mae = np.mean(np.abs(X_test_pred - X_test), axis=1) \nsns.distplot(loss_mae, bins=100, kde=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see in the charts from above, observations after 0.150 become unusual. Let's set that number as the threshold."},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.15\n\ntest_df = pd.DataFrame(test[tsteps:])\ntest_df['loss'] = loss_mae\ntest_df['threshold'] = threshold\ntest_df['anomaly'] = test_df.loss > test_df.threshold\ntest_df['Weighted_Price'] = test[tsteps:].Weighted_Price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting prices' anomalies"},{"metadata":{"trusted":true},"cell_type":"code","source":"anomalies = test_df[test_df.anomaly == True]\nanomalies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yvals1 = scaler.inverse_transform(test[tsteps:][['Weighted_Price']])\nyvals1 = yvals1.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yvals2 = scaler.inverse_transform(anomalies[['Weighted_Price']])\nyvals2 = yvals2.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=test[tsteps:].index, y=yvals1,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=anomalies.index, y=yvals2,mode='markers',name='Anomaly'))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_pano = test.append(train, ignore_index=False)\nX_shifted, y_shifted = shift_samples(scaled_pano[['Weighted_Price']], scaled_pano.columns[0])\nprint(\"Scaled pano datasets' shapes:\")\nprint('X_shifted: '+str(X_shifted.shape)+', y_shifted: '+str(y_shifted.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_shifted_pred = detector.predict(X_shifted)\nloss_mae = np.mean(np.abs(X_shifted_pred - X_shifted), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_scaled_pano = pano.copy()[51000:]\nnon_scaled_pano.fillna(method ='bfill', inplace = True)\nnon_scaled_pano = non_scaled_pano[:-24]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_scaled_pano['loss_mae'] = loss_mae\nnon_scaled_pano['threshold'] = threshold\nnon_scaled_pano['anomaly'] = non_scaled_pano.loss_mae > non_scaled_pano.threshold\nnon_scaled_pano.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pano_outliers = non_scaled_pano[non_scaled_pano['anomaly'] == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=non_scaled_pano.index, y=non_scaled_pano['Weighted_Price'].values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=pano_outliers.index, y=pano_outliers['Weighted_Price'].values,mode='markers',name='Anomaly'))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies - Autoencoder\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Isolation forest model (Bonus)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing data to be passed to the model\noutliers = pano.copy()[51000:]\noutliers.fillna(method ='bfill', inplace = True)\n\n# Training the model\nisolation_detector = IsolationForest(n_estimators=150,random_state=0,contamination='auto')\nisolation_detector.fit(outliers['Weighted_Price'].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_ready = np.linspace(outliers['Weighted_Price'].min(), outliers['Weighted_Price'].max(), len(outliers)).reshape(-1,1)\noutlier = isolation_detector.predict(data_ready)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers['outlier'] = outlier\noutliers.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting prices' anomalies"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = outliers.loc[outliers['outlier'] == 1] #anomaly\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=outliers['Weighted_Price'].index, y=outliers['Weighted_Price'].values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=a.index, y=a['Weighted_Price'].values,mode='markers',name='Anomaly',marker_symbol='x',marker_size=2))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies - IsolationForest\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Means Clustering (Bonus)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing data to be passed to the model\noutliers_k_means = pano.copy()[51000:]\noutliers_k_means.fillna(method ='bfill', inplace = True)\nkmeans = KMeans(n_clusters=2, random_state=0).fit(outliers_k_means['Weighted_Price'].values.reshape(-1, 1))\noutlier_k_means = kmeans.predict(outliers_k_means['Weighted_Price'].values.reshape(-1, 1))\noutliers_k_means['outlier'] = outlier_k_means\noutliers_k_means.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = outliers_k_means.loc[outliers_k_means['outlier'] == 1] #anomaly\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=outliers_k_means['Weighted_Price'].index, y=outliers_k_means['Weighted_Price'].values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=a.index, y=a['Weighted_Price'].values,mode='markers',name='Anomaly',marker_symbol='x',marker_size=2))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies - KMeans\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you may see and compare, K-Means model achieved better results than IsolationForest and very similar results than the Autoencoder."},{"metadata":{},"cell_type":"markdown","source":"# Time-series forecasting models\n\nLet's test a few models to determine which one fits better the dataset and delivers better results"},{"metadata":{},"cell_type":"markdown","source":"## LSTM Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Second model - LSTM regressor for price predictions\nregressor = Sequential()\nregressor.add(layers.LSTM(256, activation='relu', return_sequences=True, input_shape=(tsteps, nfeatures),dropout=0.2))\nregressor.add(layers.LSTM(256, activation='relu',dropout=0.2))\nregressor.add(layers.Dense(1))\n\nregressor.compile(loss='mse', optimizer='adam')\nregressor.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"/kaggle/working/regressor.hdf5\", monitor='val_loss', verbose=1,save_best_only=True, mode='auto', period=1)\nhistory2 = regressor.fit(X_train,y_train,epochs=30,batch_size=128,verbose=1,validation_data=(X_test, y_test),callbacks=[checkpoint],shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conv1D Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Third model - Conv1D regressor for price prediction\n\nregressor2 = Sequential()\nregressor2.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(tsteps, nfeatures)))\nregressor2.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\nregressor2.add(layers.Dropout(0.5))\nregressor2.add(layers.MaxPooling1D(pool_size=2))\nregressor2.add(layers.Flatten())\nregressor2.add(layers.Dense(50, activation='relu'))\nregressor2.add(layers.Dense(1))\n\nregressor2.compile(optimizer='adam', loss='mse')\nregressor2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"/kaggle/working/regressor2.hdf5\", monitor='val_loss', verbose=1,save_best_only=True, mode='auto', period=1)\nhistory3 = regressor.fit(X_train,y_train,epochs=30,batch_size=128,verbose=1,validation_data=(X_test, y_test),callbacks=[checkpoint],shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural networks' evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history2.history['loss'], label='Training Loss')\nplt.plot(history2.history['val_loss'], label='Validation Loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history3.history['loss'], label='Training Loss')\nplt.plot(history3.history['val_loss'], label='Validation Loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = load_model(\"regressor.hdf5\")\nregressor.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor2 = load_model(\"regressor2.hdf5\")\nregressor2.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = regressor.predict(X_test[0].reshape(1,24,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you could see above, the LSTM model delivers better results. Let's keep that. Let's inspect now if the output has the shape that we were expecting. The model must return a single scalar by each sequence of 24 floating numbers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.inverse_transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Let's move on."},{"metadata":{},"cell_type":"markdown","source":"# Gathering crypto data from the API"},{"metadata":{},"cell_type":"markdown","source":"## Getting current date and time"},{"metadata":{"trusted":true},"cell_type":"code","source":"past = datetime.now(tz=timezone.utc) - timedelta(days=1) #yesterday's date\npast = datetime.strftime(past, '%s') #reshaping to unix format\ncurrent = datetime.now(tz=timezone.utc).strftime('%s') #today's date\n\nprint(past)\nprint(current)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Connecting to Poloniex public API"},{"metadata":{"trusted":true},"cell_type":"code","source":"# connect to poloniex's API\nurl = 'https://poloniex.com/public?command=returnChartData&currencyPair=USDT_BTC&start='+str(past)+'&end='+str(current)+'&period=300'\nresult = requests.get(url)\nresult = result.json()\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_data = pd.DataFrame(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing API data"},{"metadata":{"trusted":true},"cell_type":"code","source":"last_data['date'] = pd.to_datetime(last_data.date, unit='s') #To get date in readable format\nlast_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_data = last_data[['date','weightedAverage']]\nlast_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_data = last_data.resample('H', on='date')[['weightedAverage']].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_data = last_data[-24:]\nunscaled = last_data.copy()\nlen(last_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_data_scaled = scale_samples(last_data,last_data.columns[0],scaler)\nlast_data_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting on API data"},{"metadata":{},"cell_type":"markdown","source":"## Implementing Neural Networks approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = regressor.predict(last_data_scaled.values.reshape(1,24,1))\nunscaled = unscaled.iloc[1:]\nunscaled = unscaled.append(pd.DataFrame(scaler.inverse_transform(predictions)[0], index= [unscaled.index[len(unscaled)-1] + timedelta(hours=1)],columns =['weightedAverage']))\nfuture_scaled = scale_samples(unscaled.copy(),unscaled.columns[0],scaler)\nfuture_scaled_pred = detector.predict(future_scaled.values.reshape(1,24,1))\nfuture_loss = np.mean(np.abs(future_scaled_pred - future_scaled.values.reshape(1,24,1)), axis=1)\nunscaled['threshold'] = threshold \nunscaled['loss'] = future_loss[0][0]\nunscaled['anomaly'] = unscaled.loss > threshold\nunscaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled.weightedAverage.values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled[unscaled['anomaly']==True]['weightedAverage'].values,mode='markers',marker_symbol='x',marker_size=10,name='Anomaly'))\nfig.add_vrect(x0=unscaled.index[-2], x1=unscaled.index[-1],fillcolor=\"LightSalmon\", opacity=1,layer=\"below\", line_width=0)\nfig.update_layout(showlegend=True,title=\"BTC price predictions and anomalies\",xaxis_title=\"Time (UTC)\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Detecting outliers with classic Unsupervised Learning models"},{"metadata":{},"cell_type":"markdown","source":"### Isolation Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"anomalies_24h = np.linspace(unscaled['weightedAverage'].min(), unscaled['weightedAverage'].max(), len(unscaled)).reshape(-1,1)\noutlier = isolation_detector.predict(anomalies_24h)\nunscaled['outlier'] = outlier\nunscaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Anomalies in prediction: ',len(unscaled[unscaled['outlier'] == 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KMeans"},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_k_means = kmeans.predict(unscaled['weightedAverage'].values.reshape(-1, 1))\nunscaled['outlier'] = outlier_k_means\nunscaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Anomalies in prediction: ',len(unscaled[unscaled['outlier'] == 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled.weightedAverage.values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled[unscaled['outlier']==True]['weightedAverage'].values,mode='markers',marker_symbol='x',marker_size=10,name='Anomaly'))\nfig.add_vrect(x0=unscaled.index[-2], x1=unscaled.index[-1],fillcolor=\"LightSalmon\", opacity=1,layer=\"below\", line_width=0)\nfig.update_layout(showlegend=True,title=\"BTC price predictions and anomalies\",xaxis_title=\"Time (UTC)\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I hope this notebook has been useful to you! Thanks a lot."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}