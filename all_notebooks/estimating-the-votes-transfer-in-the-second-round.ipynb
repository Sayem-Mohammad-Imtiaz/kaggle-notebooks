{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"a424111e-1e62-4052-6874-745c1fc4bd68"},"source":"There were 11 candidates in the first round of the last French elections and 2 in the second: Macron and Le Pen.  Thus in the second round supporters of the eliminated candidates redistributed their votes between Macron, Le Pen, NOTA, Null, or Absent. \n\nIn some cases votes transfer is rather obvious: most people who voted Macron in the first round would probably vote for him in the second. Sometimes it is non-trivial: for example, Mélenchon, who came 4th in the first round, didn't endorse any of the leading candidates. We can only try to estimate how did his supporters actually vote in the second round.\n\n What can we say about this votes transfer using the data, without  assuming any previous knowledge about the political affiliations of the candidates? I discuss the method in some detail in a [blog post here][1] and below give a shorter but more technical description.\n\nSuppose a person who voted for candidate A in the first round has a probability p<sub>A,B</sub> of voting for candidate B in the second. Since we know the results for both rounds for each polling station, it is not difficult to estimate p<sub>A,B</sub>. \n\nIndeed, suppose  x<sub>A</sub> and  y<sub>A</sub> are results of candidate A in the first and second round respectively. <br>\n<p>Then y<sub>B</sub>= &sum;<sub>A</sub> p<sub>A,B</sub> x<sub>A</sub>.</p>\n<br>\nWe know x<sub>A</sub> and y<sub>A</sub>, so one can just run linear regression in order to recover p<sub>A,B</sub>. However,  p<sub>A,B</sub> found in this way may not satisfy the basic properties of probabilities: they should take values between 0 and 1 and they should sum to 1. \nThus it is more correct to reformulate this problem as a quadratic optimisation with constraints:\n\nFind p<sub>A,B</sub> such that the squared deviation of &sum;<sub>A</sub> p<sub>A,B</sub> x<sub>A</sub> from y<sub>B</sub> is minimal under the condition that\n<br>0&le; p<sub>A,B</sub> &le;1,\n<br> &sum;<sub>B </sub>p<sub>A,B</sub>=1 for all A\n\nI used the standard SciPy optimiser to solve this problem and got the following result:\n\n![Vote transfer in the second round][2]\n\n Below is code which leads to this result. Would be happy to hear your questions and comments!\n  [1]: https://grishaoryol.wordpress.com/2017/05/17/vote-transfers-in-french-election/\n  [2]: https://grishaoryol.files.wordpress.com/2017/05/sankeymatic_2400x2400-v2.png?w=1400 "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c076f15-2970-6cbd-dcca-82174796bcda"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors as mcolors,cm,colorbar\nimport scipy\nimport re\nfrom IPython.display import HTML\nfrom sklearn import model_selection"},{"cell_type":"markdown","metadata":{"_cell_guid":"4e93a700-5cdc-92f8-53d0-996c401a7273"},"source":"## Load the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32f4ac91-f862-cd01-c94d-dc68ad125bed"},"outputs":[],"source":"def cleanup(df_bur):\n    # Clean the dataset: drop some columns we won't need, drop leading zeros from the\n    # codes, transform from long to wide format\n    df_bur=df_bur.drop(['First name','Sex'],axis=1)\n    df_bur['Polling station']=df_bur['Polling station'].apply(lambda x:str(x)[2:] if (str(x)[:2]=='BV') else x).apply(lambda x: re.sub(\"^[0]+\",\"\",str(x)))\n    df_bur['Commune code']=df_bur['Commune code'].apply(lambda x: re.sub(\"^[0]+\",\"\",str(x)))\n    df_bur['Department code']=df_bur['Department code'].apply(lambda x: re.sub(\"^[0]+\",\"\",str(x)))\n    df_bur['Constituency code']=df_bur['Constituency code'].apply(lambda x: re.sub(\"^[0]+\",\"\",str(x)))\n    e1=df_bur[[u'Department',\n       u'Constituency', u'Commune','Polling station']+[u'Registered',u'Abstentions',                  u'% Abs/Reg',\n                          u'Voters',                  u'% Vot/Reg',\n                           u'None of the above(NOTA)',               u'% NOTA/Reg',\n                     u'% NOTA/Vot',                       u'Nulls',\n                       u'% Nulls/Reg',                 u'% Nulls/Vot',\n                         u'Expressed']].set_index([u'Department',\n       u'Constituency', u'Commune', 'Polling station']).drop_duplicates()\n    \n    df_b1=df_bur.pivot_table(index=[u'Department',\n       u'Constituency', u'Commune', 'Polling station'],columns = u'Surname',values='Voted')\n    \n    tab=pd.merge(df_b1,e1,left_index=True,right_index=True)\n    \n    if ('MÉLENCHON' in tab.columns):\n        tab=tab.rename(columns={'MÉLENCHON':'MELENCHON'})\n    \n    return tab"},{"cell_type":"markdown","metadata":{"_cell_guid":"1717d45b-4cae-c1ed-0f3a-097496c33097"},"source":"#### Load the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6347a54-5eb5-a011-f05f-4fba4143ef24"},"outputs":[],"source":"df_bur = pd.read_csv(\"../input/French_Presidential_Election_2017_First_Round.csv\",sep=',',\n                    dtype={'Department code':'object','Polling station':'object',29:'object'})\ndf_bur2 = pd.read_csv(\"../input/French_Presidential_Election_2017_Second_Round.csv\",sep=',',\n                     dtype={'Polling station':'object'})"},{"cell_type":"markdown","metadata":{"_cell_guid":"3965eea6-a8ea-e32f-24ee-9bd7abce7220"},"source":"#### and clean it up a bit"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2b3fd3e-2832-21b7-dd5e-169beb9557f0"},"outputs":[],"source":"tab=cleanup(df_bur)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cac981c3-c152-9951-2fa2-6a3e5be3d40a"},"outputs":[],"source":"tab2=cleanup(df_bur2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7a3db6b0-2aeb-80ea-b26c-37984622b926"},"source":"#### Check that the data if consistent"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff3bde09-db89-e35b-a1d2-f169bc74fdba"},"outputs":[],"source":"print(np.all(tab['Voters']+tab['Abstentions']-tab['Registered']==0))\nprint((tab[[u'ARTHAUD', u'ASSELINEAU', u'CHEMINADE', u'DUPONT-AIGNAN', u'FILLON',\n       u'HAMON', u'LASSALLE', u'LE PEN', u'MACRON', u'POUTOU',u'MELENCHON']].sum(axis=1)-tab[u'Expressed']!=0).sum())\nprint((tab[[u'ARTHAUD', u'ASSELINEAU', u'CHEMINADE', u'DUPONT-AIGNAN', u'FILLON',\n       u'HAMON', u'LASSALLE', u'LE PEN', u'MACRON', u'POUTOU',u'MELENCHON', u'None of the above(NOTA)',u'Nulls']].sum(axis=1)-tab[u'Voters']!=0).sum())"},{"cell_type":"markdown","metadata":{"_cell_guid":"dcc5566e-f2b0-23d1-8dbf-6aecd088fa08"},"source":"#### Merge the results of two rounds into one table"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd5a1c49-5d45-d46b-18da-47227dccd53d"},"outputs":[],"source":"merged=pd.merge(tab,tab2,left_index=True,right_index=True,how='inner')"},{"cell_type":"markdown","metadata":{"_cell_guid":"bb2e3153-ead8-1032-2ebb-3123da211114"},"source":"Below we merge into one category voters who voted NOTA, voters who voted Null and \nthose who abstained. We also merge into one category the five least successful candidates .\nThis step is not strictly necessary, but there are two reasons for doing it: first, with less categories\nthere are less parameters to tune and the model turns out more robust. Second, the shares of votes corresponding to \nthese minor categories are so small that they are comparable with the precision of the model itself, so by including them \nwe won't get any reliable new information"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3612d4ca-df6c-0662-7658-c4e22084726b"},"outputs":[],"source":"merged['Abstentions, NOTA, null_y']=merged[['None of the above(NOTA)_y','Nulls_y','Abstentions_y']].sum(axis=1)\nmerged['Abstentions, NOTA, null_x']=merged[['None of the above(NOTA)_x','Nulls_x','Abstentions_x']].sum(axis=1)\nmerged['Other candidates']=merged[['ARTHAUD','ASSELINEAU','CHEMINADE','LASSALLE','POUTOU']].sum(axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a614ca6d-3f17-2a94-30f0-d49a8619d791"},"outputs":[],"source":"nms_compressed=['Other candidates',\n u'DUPONT-AIGNAN',\n u'FILLON',\n u'HAMON',\n u'LE PEN_x',\n u'MELENCHON',\n 'MACRON_x','Abstentions, NOTA, null_x']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"669464e6-db01-960b-3682-e527828c2c2f"},"outputs":[],"source":"options_2iem_compressed=['LE PEN_y', 'MACRON_y', 'Abstentions, NOTA, null_y']"},{"cell_type":"markdown","metadata":{"_cell_guid":"85f340f5-75d4-416f-5709-f8f45b18a39b"},"source":"## Optimization procedure"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3002b827-ddc2-e785-8938-2b284a3371b2"},"outputs":[],"source":"def optimize(merged):\n    print('opimizing, input table has '+str(merged.shape[0])+\" rows\")\n    \n    y1=(merged[options_2iem_compressed].T/merged['Registered_y']).T[merged['Registered_x']!=0]\n    X1=(merged[nms_compressed].T/merged['Registered_x']).T[merged['Registered_x']!=0]\n    n_2iem=len(options_2iem_compressed)\n    \n    # Probabilities are naturally organized as a table, but scipy.optimize.minimize works with \n    # a list of parameters. So this functions reshapes this list to a table\n    def rshp(prob):\n        tmp1=np.reshape(prob,(len(options_2iem_compressed)-1,X1.shape[1])).T\n        tmp2=np.concatenate((tmp1,np.array([1-tmp1.sum(axis=1)]).T),axis=1)\n        return(tmp2)\n\n    # This is a loss function, with takes as an input probabilities and outputs the quadratic\n    # deviation of the computed results of the second round from the actual ones\n    def loss_func(prob):\n        y1=(merged[options_2iem_compressed].T/merged['Registered_y']).T[merged['Registered_x']!=0]\n        tmp2=rshp(prob)\n        ret=np.sum((np.dot(X1,tmp2)-y1)**2).sum()\n        return ret\n    \n    \n    # Constraint for the probabilities table: sum of values in each row should be equalt to 1.\n    def fun_constr(prob):\n        return 1-np.reshape(prob,(n_2iem-1,X1.shape[1])).sum(axis=0)\n    \n    bs=[(0,1)]*(X1.shape[1])*(n_2iem-1) # bounds for probabilities: bewteen 0 and 1\n    x0=np.array(X1.shape[1]*(n_2iem-1)*[1/float(n_2iem)]) # starting point for the optimization procedure\n    constr={'type':'ineq','fun':fun_constr} # impose the constraint: sum inside each row omitting the last element should be smaller than 1\n    print(x0)\n    print(bs)\n    # run the quadratic optimization\n    opt=scipy.optimize.minimize(loss_func,\n                   x0,#jac=jac,\n                   method = 'SLSQP',\n                   bounds = bs,\n                   constraints = constr\n\n        )\n    print(opt)\n    print('error: '+str(np.sqrt(opt.fun/len(y1))))\n    res=pd.DataFrame(rshp(opt.x),columns=options_2iem_compressed,index=nms_compressed).round(3)\n    return(res)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63cf4346-18a7-61a1-3f72-b0987fd14778"},"outputs":[],"source":"# run the optimization procedure on the whole dataset\nres_c=optimize(merged)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9e8bba2e-4b44-4e16-fdd3-7ecd67f4e55f"},"source":"###Precision of the model"},{"cell_type":"markdown","metadata":{"_cell_guid":"04e267b8-12c5-ee20-c03c-cee880cdd4bc"},"source":"#### Let us see how the results change if we take two different subsets of the original data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8ba9e94d-d874-477a-e326-dcc996b9fb3d"},"outputs":[],"source":"# take a random subset of the original table droping 1/10 of the data\nsplitter = model_selection.ShuffleSplit(1,0.1)\ntrain = merged.iloc[[x for x in splitter.split(merged)][0][0]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09cbb7b7-cb17-bbdd-803a-1976571670ff"},"outputs":[],"source":"#run the optimization procedure on the first random subset\nres_train=optimize(train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"174fc411-5ef6-e77e-7c71-c59dc8691989"},"outputs":[],"source":"# take another random subset\nsplitter = model_selection.ShuffleSplit(1,0.1)\ntrain = merged.iloc[[x for x in splitter.split(merged)][0][0]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e475685-bc56-9fd6-fb66-23bc42f2752a"},"outputs":[],"source":"#run the optimization procedure on the second random subset\nres_train1=optimize(train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a34b3fec-07fb-3371-59d1-16cc28c43c0e"},"source":"Are the results different?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"add6cf67-8365-9498-0aac-494bc553df5f"},"outputs":[],"source":"res_train1-res_train"},{"cell_type":"markdown","metadata":{"_cell_guid":"06e69f83-1231-aca7-a326-0ff0cbe50960"},"source":"The difference is small, so the model is pretty robust"},{"cell_type":"markdown","metadata":{"_cell_guid":"c157e014-ae40-8428-4130-e48d0be9c911"},"source":"## Visualization of the results"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8dba5530-a858-b8a2-6bb8-63c1abf09530"},"outputs":[],"source":"# Votes for particular candidates as a share of all registered voters (first round)\nres_premier=merged[nms_compressed].sum()/merged['Registered_x'].sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0ad98a23-34cc-12ba-7909-b9f813227004"},"source":"Which percentage of all registered voters went from candidate A in the first to candidate B in the second round:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3184e035-a217-6a8d-a49b-2d55602ff179"},"outputs":[],"source":"res_new=((res_premier*res_c.T).T).round(3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6be23812-cf30-7b37-1ab2-370efd6ebdd8"},"source":"Draw the bar plot"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30d1585c-2cd5-4e47-3b4a-65ed7d130c13"},"outputs":[],"source":"def form(x): \n    return x if ((len(x)<2) or ((x[len(x)-2:]!='_x') and  (x[len(x)-2:]!='_y') )) else x[:len(x)-2]\nchart1=res_new.copy()\nchart1['total']=chart1.sum(axis=1)\nchart1=chart1.sort_values(['total'])*100\nbar_h=10\nx_init=0.14*100\nfig=plt.figure(facecolor='white')\nax=fig.add_subplot(111)\nax.set_facecolor('white')\nax.text(0,bar_h*len(chart1.index)+bar_h*0.2,'First round',fontsize=13)\nfor i in range(len(chart1.index)):\n    ax.bar(left=x_init+chart1.iloc[i,0],height=bar_h,width=chart1.iloc[i,1],\n           bottom=bar_h*i,color='red',align='edge',edgecolor='black')\n    ax.bar(left=x_init,height=bar_h,width=chart1.iloc[i,0],\n           bottom=bar_h*i,color='blue',align='edge',edgecolor='black')\n    ax.bar(left=x_init+chart1.iloc[i,0]+chart1.iloc[i,1],height=bar_h,width=chart1.iloc[i,2],\n           bottom=bar_h*i,color='grey',align='edge',edgecolor='black')\n    ax.text(0,bar_h*i+bar_h*0.5,form(chart1.index[i]),fontweight='bold',fontsize=13)\nlg=ax.legend(['Macron','Le Pen','Abstentions, NOTA, null'],loc=(0.65,0.12),title='Second round',fontsize=13)\nplt.setp(lg.get_title(),fontsize=14)\nax.set_yticks([])\nticks=np.arange(0,40,5)\nax.set_xticks(ticks+x_init)\nax.set_xticklabels([str(x) for x in ticks],fontsize=13)\nax.text(0,bar_h*(len(chart1.index)+1),'Transfer of votes between the two rounds',\n             fontweight='bold',\n             fontsize=17\n             )\nax.set_xlabel('% of all votes',fontsize=13)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0bfd5923-5939-d739-fdf1-544734980d27"},"source":"#### The table containing percents of vote transfers"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c80c19f2-a550-ea27-1f1a-8a794c3e4e7e"},"outputs":[],"source":"table_html=(pd.DataFrame(np.array(res_c),columns=['Le Pen','Macron','Abstentions, NOTA, null'],\n             index=['Other candidates','Dupont-Aignan','Fillon','Hamon',\n                    'Le Pen','Melenchon','Macron','Abstentions, NOTA, null']).sort_values('Macron',ascending=False)*100).round(1)\ntable_html"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b84b47f1-a7e3-3d50-1ff2-25ccf5f70baa"},"outputs":[],"source":"res_new.columns=['Le Pen','Macron','Abstentions, NOTA, null']\nres_new.index=['Other candidates','Dupont-Aignan','Fillon','Hamon',\n                    'Le Pen','Melenchon','Macron','Abstentions, NOTA, null']\nres_new"},{"cell_type":"markdown","metadata":{"_cell_guid":"2381b0d2-7a63-5766-bfbc-1fb4c7a99bd6"},"source":"This is the final result. The flow chart in the beginning of the notebook was generated from this table using an online tool sankeymatic.com. Feel free to comment and ask questions!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9495b074-347a-eb59-ec12-9a7fd4ec6144"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}