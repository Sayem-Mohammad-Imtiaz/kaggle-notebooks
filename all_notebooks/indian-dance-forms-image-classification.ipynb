{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Indian Dance Forms - Image Classification (Keras)\n\nIn this notebook,we'll create a CNN Model using Keras to train on the various Indian Dance Forms and then will try to predict the dance forms from Test images. The database that we're going to use is [Indian Dance Classification](https://www.kaggle.com/shubham7169/indian-dance-classification?).\n\nPlease do UPVOTE if you find it interesting/informative :-).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Generic Packages\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\n\n#SKLearn Library\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils import shuffle  \nfrom sklearn.model_selection import train_test_split\n\n#Plotting Libraries\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\n#openCV\nimport cv2                                 \n\n#Tensor Flow\nimport tensorflow as tf   \nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nfrom keras.utils import to_categorical\nfrom keras.layers. normalization import BatchNormalization\nfrom keras.optimizers import Adam\n\n#Display Progress\nfrom tqdm import tqdm\n\n#Garbage Collector\nimport gc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Directories","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Define Directory Path\ntrain_images = '../input/indian-dance-classification/Indian_Dance/train/'\ntest_images = '../input/indian-dance-classification/Indian_Dance/test/'\ncsv_files = '../input/indian-dance-classification/Indian_Dance/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Class Definition & Parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting the Class from the Folder Names in Train Folder\n\nclass_names = []\npath, dirs, files = next(os.walk(train_images))\nclass_names = dirs\nclass_names.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Class Name Labels \nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\nIMAGE_SIZE = (150, 150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Function to Load Images & Labels\ndef load_data(path):\n    \n    output = []\n    images = []\n    labels = []\n        \n    print(\"Loading from {}\".format(path))\n        \n    # Iterate through each folder corresponding to a category\n    for folder in os.listdir(path):\n            label = class_names_label[folder]\n            \n            \n        #Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(path, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(path, folder), file)\n                 \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n    images = np.array(images, dtype = 'float32')\n    labels = np.array(labels, dtype = 'int32')   \n    output.append((images, labels))\n    return output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Training Data\n(data_images, data_labels), = load_data(train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shuffle The Dataset\ndata_images, data_labels = shuffle(data_images, data_labels, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Dataset Shape\nn = data_labels.shape[0]\n\nprint (\"Number of examples: {}\".format(n))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"_, lb_count = np.unique(data_labels, return_counts=True)\ndata_dance = pd.DataFrame({'Label_Count': lb_count}, index=class_names)\nfig = px.bar(data_dance, x=class_names, y='Label_Count', hover_data=['Label_Count'], \n             color_discrete_sequence=px.colors.qualitative.Antique, opacity=0.8, text='Label_Count')\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Split - 90% Train & 10% Validation\nImage_train, Image_val, Label_train, Label_val = train_test_split(data_images,data_labels, \n                                                                    test_size = 0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Scale ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Image_train = Image_train / 255.0\nImage_val = Image_val / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Data Exploration","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Visualise the data [random image from training dataset]\n\ndef display_random_img(class_names, images, labels, val=0):\n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    \n    if val != 0:\n        plt.title(class_names[labels[index]] + ' - {:.4}%'.format(str(val)), fontsize=16)\n    else:\n        plt.title(class_names[labels[index]], fontsize=16)\n        \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display Random Image\ndisplay_random_img (class_names, Image_train, Label_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model - Build, Train & Evaluate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(8, activation=tf.nn.softmax)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Summary\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compile Model\nlr = 1e-3 # learn rate\nmodel.compile(optimizer = Adam(lr), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train\nhistory = model.fit(Image_train, Label_train, batch_size=10, epochs=10, validation_split = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = model.evaluate(Image_val,Label_val, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction (Validation Data)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(Image_val) \npred_labels = np.argmax(predictions, axis = 1) \nconf = 100*np.max(predictions)\n\ndisplay_random_img(class_names, Image_val, pred_labels, conf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction (Unseen Data)","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Function to Load Test Data (Unseen)\ndef load_Testdata(path):\n    \n    images = []\n      \n    print(\"Loading from {}\".format(path))\n    \n    for file in tqdm(os.listdir(path)):\n        # Get Image Path    \n        img_path = os.path.join(path, file)\n        \n        # Open and resize the img\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, IMAGE_SIZE) \n                \n        # Append the image and its corresponding label to the output\n        images.append(image)\n                \n    images = np.array(images, dtype = 'float32')\n    return images\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Images from Test Folder\n(Test_Images) = load_Testdata(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale Data\nTest_Images = Test_Images / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making Predictions\nTest_Pred = model.predict(Test_Images)          # Vector of probabilities\nTest_Pred_lb = np.argmax(Test_Pred, axis = 1) # We take the highest probability\nTest_conf = 100*np.max(Test_Pred)\ndisplay_random_img(class_names, Test_Images, Test_Pred_lb,Test_conf)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}