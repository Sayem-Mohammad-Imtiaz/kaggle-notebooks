{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Importing Libraries***"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn import ensemble, tree, linear_model, preprocessing\nimport missingno as msno\nimport pandas_profiling\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading in the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise = pd.read_csv('../input/education-in-india/2015_16_Districtwise.csv')\nState_wise_elementry = pd.read_csv('../input/education-in-india/2015_16_Statewise_Elementary.csv')\nState_wise_secondary = pd.read_csv('../input/education-in-india/2015_16_Statewise_Secondary.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_met = pd.read_csv('../input/education-in-india/2015_16_Districtwise_Metadata.csv')\nState_wise_elementry_met = pd.read_csv('../input/education-in-india/2015_16_Statewise_Elementary_Metadata.csv')\nState_wise_secondary_met = pd.read_csv('../input/education-in-india/2015_16_Statewise_Secondary_Metadata.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Going through the basic structure of Data."},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Going through the metadata of the data files."},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_met.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For doing a primitive analysis we are taking out the total number of schools in various categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_total = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"i=0\nfor name in District_wise_met['Description']:\n    if 'Total' in name:\n        District_wise_total[District_wise_met.iloc[i][1]] = District_wise[District_wise_met.iloc[i][0]]\n    i=i+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking how Schools are classified on the basis of their Ownership."},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_total['Schools_By_Category: Total']/(District_wise_total['Schools_by_Category:_Government: Total']+District_wise_total['Schools_by_Category:_Private_: Total']+District_wise_total['Schools_by_Category:_Madarsas_&_Unrecognised: Total'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Therefore Goverment, Private and Unrecoganized are 3 catagories of Schools based on ownership."},{"metadata":{},"cell_type":"markdown","source":"Grouping the data frame on the basics of States."},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_new = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_new['STATNAME'] = District_wise['STATNAME']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_new['DISTNAME'] = District_wise['DISTNAME']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_new = pd.concat([District_wise_new, District_wise_total], axis = 1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"District_wise_grouped = District_wise_new.groupby(by = 'STATNAME')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_sum = District_wise_grouped.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding out the sum various states data which is already grouped."},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_sum.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_sum.index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding out what is the average number of persons avilable per school in various states."},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_sum['People_per_School'] = State_wise_sum['Basic_data_from_Census_2011: Total_Population(in_1000\\'s)']/State_wise_sum['Schools_By_Category: Total']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(y=State_wise_sum.index, x='People_per_School', data = State_wise_sum  )\n#ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n#plt.tight_layout()\n\nplt.figure(figsize=(16,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot shows us the average number of people dependend per school in the particular state."},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_sum.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_fac = pd.DataFrame()\nfor name in State_wise_sum.columns[21:31]:\n    \n    State_wise_fac[name] = State_wise_sum[name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_fac['Total_Schools'] = State_wise_sum['Schools_By_Category: Total']\nState_wise_fac['Population_school_serves'] = State_wise_sum['People_per_School']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in State_wise_fac.columns[0:8]:\n    State_wise_fac[name] = State_wise_fac[name]/State_wise_fac['Total_Schools']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_fac['Fraction_of_required_ramps'] = State_wise_fac['Schools_with_Ramp_(where_needed): Total']/State_wise_fac['Schools_where_Ramp_is_Required: Total']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_fac = State_wise_fac.drop(['Schools_with_Ramp_(where_needed): Total','Schools_where_Ramp_is_Required: Total'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_fac.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"21 - All_whetherd roads 31 -- establishment"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(State_wise_fac, alpha = 0.3, figsize = (21,12), diagonal = 'kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_std[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_fac_scaled = pd.DataFrame()\ni=0\nfor name in State_wise_fac.columns:\n    State_wise_fac_scaled[name] = df_std[:,i]\n    i=i+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Schools_with_Computer: Total,Total_Schools,Population_school_serves"},{"metadata":{"trusted":true},"cell_type":"code","source":"State_wise_fac.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = State_wise_fac\ntemp['Schools_with_Computer: Total'] = np.log(State_wise_fac['Schools_with_Computer: Total'])\ntemp['Total_Schools'] = np.log(State_wise_fac['Total_Schools'])\ntemp['Population_school_serves'] =  np.log(State_wise_fac['Population_school_serves'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(temp, alpha = 0.3, figsize = (21,12), diagonal = 'kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.drop(['Schools_with_Girls\\'_Toilet: Total','Schools_with_Drinking_Water: Total'], inplace = True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp['Schools_with_Boys\\'_Toilet: Total'] = np.arcsin(temp['Schools_with_Boys\\'_Toilet: Total'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"std_scale = preprocessing.StandardScaler().fit(temp)\ndf_std = std_scale.transform(temp)\ndf_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame()\ni=0\nfor name in State_wise_fac.columns:\n    temp[name] = df_std[:,i]\n    i=i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(temp, alpha = 0.3, figsize = (21,12), diagonal = 'kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(12,9))\nsns.heatmap(abs(temp.cov()), vmax=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=temp.shape[1]).fit(temp)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the PCA algorithm with our Data\npca = PCA().fit(temp)\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\n#plt.title('Pulsar Dataset Explained Variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=5)\ntransformed_temp = pca.fit_transform(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_temp[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for_train = pd.DataFrame()\ni=0\nfor name in ['1','2','3','4','5']:\n    for_train[name] = transformed_temp[:,i]\n    i=i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans \nfrom sklearn import metrics \nfrom scipy.spatial.distance import cdist \n\ndistortions = [] \ninertias = [] \nmapping1 = {} \nmapping2 = {} \nK = range(1,10) \n  \nfor k in K: \n    #Building and fitting the model \n    kmeanModel = KMeans(n_clusters=k).fit(for_train) \n    kmeanModel.fit(for_train)     \n      \n    distortions.append(sum(np.min(cdist(for_train, kmeanModel.cluster_centers_, \n                      'euclidean'),axis=1)) / for_train.shape[0]) \n    inertias.append(kmeanModel.inertia_) \n  \n    mapping1[k] = sum(np.min(cdist(for_train, kmeanModel.cluster_centers_, \n                 'euclidean'),axis=1)) / for_train.shape[0] \n    mapping2[k] = kmeanModel.inertia_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key,val in mapping1.items(): \n    print(str(key)+' : '+str(val)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.plot(K, distortions, 'bx-') \nplt.xlabel('Values of K') \nplt.ylabel('Distortion') \nplt.title('The Elbow Method using Distortion') \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}