{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# The first step is to utilize one-hot encoding in order to allow for us to use\n# categorical data to make predictions with out Iowa House dataset\nimport pandas as pd\ndata = pd.read_csv('../input/train.csv')\n# Let's take a look at the columns and choose some categorical values that\n# sound useful for determining the selling price of a house\nlist(data.columns.values)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"# Oh, I left SalePrice in there.  Let's save it separately and remove it from our data before we move on.\ny_train = data['SalePrice']\n# The above list was a lot less helpful than I had anticipated.  Let me exclude all numerical\n# column headers and just show the categorical ones.\nlist(data.select_dtypes(include=['object']))","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e79cbd1935c0ccac6d71b5cd43d05a686de0b28"},"cell_type":"code","source":"# This still is not halpful.  Perhaps I need to just look at a few rows and see what sticks out.\ncat_data = data.select_dtypes(include=['object'])\ncat_data.head(10)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09f021092de99185bb11d9781abf9521df83e798"},"cell_type":"code","source":"# So, what looks important up there?  I imagine that the following are important:\n# Utilities\n# Neighborhood\n# SaleCondition\n# Even if there are more, let us just start with that and see how much our model\n# improves vs the other Kernal \"Iowa Housing ML2: 1\", which ranged from about 19500 to 22000.\n# It seems that the easiest way to do this is one-hot encode everything first.\n# It would be useful to learm how to not waste time encoding unused columns.\n#iowa_data = data.select_dtypes(exclude=[\"object\"]) + data['Utilities']\none_hot_encoded_data = pd.get_dummies(data)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bea0c2de8e5cfcbb38d7797ac9109bac4c31457"},"cell_type":"code","source":"data = data.drop(['SalePrice'], axis=1)\ndata.head()","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06b85b95d64d0f76fbc047fe5b2d43bdb26897bd"},"cell_type":"code","source":"ohe_data = pd.get_dummies(data)\nohe_data.head()","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"fcca3ac97dcc9528a9ce897b0384aadae0e1cfa0"},"cell_type":"code","source":"# I'm honestly worried because some of the columns seem to be missing now.\n# It'll waste a ton of space, but let's look at col names for bthe new data.\nlist(ohe_data.columns.values)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3e1f213dbd8e48186d9a87b069dd295bf53f513"},"cell_type":"code","source":"list(data.columns.values)\n# Nothin is missing.  It just seems that when you OHE something, it puts those new columns\n# in the back rather than squeezing them in where the original was.","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bffd8f440a1c7bfa9d30b69ff2b1d2ddd1ed10f7"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ecab72c6b9d79f372113c553391b7b4834e5bc08"},"cell_type":"code","source":"# Let's do this again and see what score we get\ndef score_dataset(X_train, X_test, y_train, y_test):\n    model = RandomForestRegressor()\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    return mean_absolute_error(y_test, preds)","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee82300623ad05e855095032e7e4844aeb28fc92"},"cell_type":"code","source":"X = ohe_data\ny = y_train\n# oops\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nfrom sklearn.preprocessing import Imputer\nmy_imputer = Imputer()\nimputed_X_train = my_imputer.fit_transform(X_train)\nimputed_X_test = my_imputer.transform(X_test)\nprint(\"Mean Absolute Error from Imputation:\")\nprint(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))\n# Before the error, the score was just under 20,000.  Cool.","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"90e30a7918f2378d0d1bec131b2699fa1c8d994e"},"cell_type":"code","source":"# This is a little disappointing, but I am rather certain that I did it right.","execution_count":45,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}