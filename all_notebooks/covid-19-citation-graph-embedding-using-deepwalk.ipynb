{"cells":[{"metadata":{},"cell_type":"markdown","source":"* In this kernel, I create a citation graph based on the research papers in the json file. \n* Most papers have bibref section which captures the citations in the paper.\n* Most of the papers in the citation are not present in the cord-19 dataset and details are also in the kernel.\n* I create a citation graph and then apply DeepWalk algorithm to create embeddings of the papers such that related papers are closer.\n* Due to memory constraint of the kernel, I have pruned the graph such that each paper can have at most 25 directed edges going to its references (fan-out). They are selected based on the freqency. \n* However, a paper can have many edges (fan-in).\n\nAlso, reference to my other kernel on creating vocabulary of short-hand notation in the research papers https://www.kaggle.com/midnitekoder/coronavirus-jargon-vocabulary\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nimport json\nfrom multiprocessing import Pool\nimport random\nimport pickle\nimport re\nfrom functools import reduce\n# Any results you write to the current directory are saved as output.\nimport networkx as nx\n\nfrom gensim.models import Word2Vec\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filenames_list = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for each_filename in filenames:\n        filenames_list.append(os.path.join(dirname, each_filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(filenames_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for filename in random.sample(filenames_list, 2):\n#     if filename.split(\".\")[-1] == \"json\":\n#         ifp = open(os.path.join(dirname, filename))\n#         research_paper = json.load(ifp)\n#         title = research_paper[\"metadata\"][\"title\"]\n#         print(title, \"\\n\\n\")\n#         abstract_text = \" \".join([each[\"text\"] for each in research_paper[\"abstract\"]])\n#         print(abstract_text, \"\\n\\n\")\n#         body_text = \" \".join([each[\"text\"] for each in research_paper[\"body_text\"]])\n#         print(body_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"research_paper_title_list = []\nfor filename in filenames_list:\n    if filename.split(\".\")[-1] == \"json\":\n        ifp = open(os.path.join(dirname, filename))\n        research_paper = json.load(ifp)\n        research_paper_title_list.append(research_paper[\"metadata\"][\"title\"])\n        for each_ref in research_paper[\"bib_entries\"]:\n            research_paper_title_list.append(research_paper[\"bib_entries\"][each_ref][\"title\"])\n\n        \n        \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(research_paper_title_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_id_dict= dict(zip(research_paper_title_list, list(map(lambda x: str(x), range(len(research_paper_title_list))))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_paper_dict = dict(zip(paper_id_dict.values(), paper_id_dict.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_undirected_degree_dict= dict(zip(research_paper_title_list, [0]*len(research_paper_title_list)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adj_mat = {}\nfor filename in filenames_list:\n    if filename.split(\".\")[-1] == \"json\":\n        ifp = open(os.path.join(dirname, filename))\n        research_paper = json.load(ifp)\n        adj_mat[paper_id_dict[research_paper[\"metadata\"][\"title\"]]] = [paper_id_dict[research_paper[\"bib_entries\"][each_key][\"title\"]] for each_key in research_paper[\"bib_entries\"]]\n        paper_undirected_degree_dict[research_paper[\"metadata\"][\"title\"]] += len(adj_mat[paper_id_dict[research_paper[\"metadata\"][\"title\"]]])\n        for each_key in research_paper[\"bib_entries\"]:\n            paper_undirected_degree_dict[research_paper[\"bib_entries\"][each_key][\"title\"]] += 1\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pruned_adj_mat = {}\nfor each_key in adj_mat:\n    freq_ref = [paper_undirected_degree_dict[id_paper_dict[each_id]] for each_id in adj_mat[each_key]]\n    ref_freq_dict = dict(zip(adj_mat[each_key], freq_ref))\n    pruned_adj_mat[each_key] = sorted(adj_mat[each_key], key=lambda x: ref_freq_dict[x], reverse=True)[:25]\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for each_key in random.sample(adj_mat.keys(), 5):\n    print(each_key, adj_mat[each_key])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"degrees = [len(adj_mat[each_key]) for each_key in adj_mat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(degrees)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.median(degrees)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(degrees)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.min(degrees)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nodes_in_pruned_graph = list(reduce(lambda x, y: x + y, pruned_adj_mat.values())) + list(pruned_adj_mat.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(nodes_in_pruned_graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(nodes_in_pruned_graph))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"citation_graph = nx.from_dict_of_lists(pruned_adj_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adj_mat = None\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pruned_degrees = list(dict(citation_graph.degree).values())\nprint(len(pruned_degrees), np.mean(pruned_degrees), np.median(pruned_degrees), np.min(pruned_degrees), np.max(pruned_degrees))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_walk(arg):\n    root_node, walk_length = arg\n    walk = [root_node]\n\n    for i in range(1, walk_length):\n        cur = walk[i-1]\n#         try:\n        neighbours = list(citation_graph.neighbors(cur))\n        if len(neighbours) > 0:\n            walk.append(random.choice(neighbours))\n        else:\n            walk = walk[:-1]\n            break\n#         if type(walk[-1]) == str:\n#             print(walk[-1])\n#             walk = walk[:-1]\n#             break\n#         except:\n#             break\n    return walk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def deepwalk_random_walks(num_walks, walk_length):\n    nodes = list(citation_graph.nodes())\n    walks = []\n    for i in range(num_walks):\n        print(\"walk no. \", i)\n        random.shuffle(nodes)\n        with Pool(processes=32) as pool:\n            walks = walks + pool.map(random_walk, zip(nodes,[walk_length]*len(nodes)))\n    return walks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_walks = deepwalk_random_walks(20, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(random_walks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_walks[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Word2Vec(random_walks, size=32, window=4, alpha=0.005, min_count=0, sg=1, workers=16, iter=5, negative=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def most_similar_papers(title, topn=20):\n    return [(id_paper_dict[each[0]], each[1]) for each in model.wv.most_similar(paper_id_dict[title], topn=topn)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"most_similar_papers('Discovery and Characterization of Novel Bat Coronavirus Lineages from Kazakhstan. Viruses')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_similar_papers('Ebola virus enters host cells by macropinocytosis and clathrin-mediated endocytosis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_similar_papers('Enhanced growth of a murine coronavirus in transformed mouse cells')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"/kaggle/working/node2vec_citation_graph_covid19.wv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paper_id_ = list(zip(paper_id_dict.keys(), paper_id_dict.values()))\npaper_id_df = pd.DataFrame(paper_id_, columns=[\"paper_title\", \"paper_id\"])\npaper_id_df.to_csv(\"/kaggle/working/paper_id_map.csv\")\nofp = open(\"/kaggle/working/id_paper_map.pickle\", \"wb\")\npickle.dump(id_paper_dict, ofp)\nofp = open(\"/kaggle/working/paper_id_map.pickle\", \"wb\")\npickle.dump(paper_id_dict, ofp)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}