{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#open the dataset\ndataset = pd.read_csv('../input/drugsrec/datasetmed.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"#print the first ten rows\ndataset.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove duplicate rows\ndataset.drop_duplicates(inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.drop('duration', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.reindex(['sex','age','disease','price','admin_way','rating','drug'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting Dependent variable\nX= dataset.iloc[:,0: -3].values\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#handling missing data(Replacing missing data with the mean value) \nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting imputer object to the independent varibles x.   \nimputerimputer= imputer.fit(X[:, 1:2])  \n  \n#Replacing missing data with the calculated mean value  \nX[:, 1:2]= imputer.transform(X[:, 1:2])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting imputer object to the independent varibles x.   \nimputerimputer= imputer.fit(X[:, -1:])  \n  \n#Replacing missing data with the calculated mean value  \nX[:, -1:]= imputer.transform(X[:, -1:])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoding sex column\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder  \nlabel_encoder_X= LabelEncoder()  \nX[:, 0]= label_encoder_X.fit_transform(X[:, 0])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[0:5, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n# Country column\nct = ColumnTransformer([(\"disease\", OneHotEncoder(), [2])], remainder = 'passthrough',sparse_threshold=0)\nX = ct.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y= dataset.iloc[:, -1].values\n#df = pd.DataFrame(y.reshape(len(y),-1),columns=['drug'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df = pd.get_dummies(df, columns=['drug'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y = df.to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into training and test set.  \nfrom sklearn.model_selection import train_test_split  \nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state=0)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Scaling of datasets  \nfrom sklearn.preprocessing import StandardScaler  \nst_x= StandardScaler()  \nX_train[:,51:]= st_x.fit_transform(X_train[:,51:])  \nX_test[:,51:]= st_x.transform(X_test[:,51:])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Random Forest Classification model on the Training set","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting the Test set results","metadata":{}},{"cell_type":"code","source":"y_pred = classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Try Knn algorithm","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nhistory=classifier.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint(\"The accuracy is {}\".format(accuracy_score(y_test, y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\nprecision = metrics.precision_score(y_test, y_pred, average='macro')\nrecall = metrics.recall_score(y_test, y_pred, average='macro')\nf1_score = metrics.f1_score(y_test, y_pred, average='macro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The precision is {}\".format(precision))\nprint(\"The recall is {}\".format(recall))\nprint(\"The f1_score is {}\".format(f1_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncm = confusion_matrix(y_test, y_pred)\n\nax = sns.heatmap(cm, annot=True, fmt=\".2f\")\n#print(f\"Confusion matrix:\\n{img.confusion_matrix}\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}