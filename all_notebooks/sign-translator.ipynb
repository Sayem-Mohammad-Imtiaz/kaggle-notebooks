{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/input/isl-dataset/'\nfor folder in os.listdir(train_dir):\n    print(folder) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display the datset\n\ndef load_unique(train_dir):\n    images_for_plot = []\n    labels_for_plot = []\n    for folder in os.listdir(train_dir):\n        for file in os.listdir(train_dir + '/' + folder):\n            filepath = train_dir + '/' + folder + '/' + file\n            if filepath.endswith('txt'):\n                continue\n            image = cv2.imread(filepath)\n            image=cv2.resize(image,(64,64))\n           # blurred_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n           # print(blurred_img.shape)\n            images_for_plot.append(image)\n            labels_for_plot.append(folder)\n            break\n    return images_for_plot, labels_for_plot\n\n\nimages_for_plot, labels_for_plot = load_unique(train_dir+'Digits')\nimages_tmp, labels_tmp = load_unique(train_dir+'Letters')\n\nimages_for_plot.extend(images_tmp)\nlabels_for_plot.extend(labels_tmp)\nprint(\"unique_labels = \", labels_for_plot)\n\nfig = plt.figure(figsize = (15,15))\n\nrow = 6\ncol = 6\nfor i in range(1, 33):\n    fig.add_subplot(row, col, i)\n    plt.imshow(images_for_plot[i])\n    plt.title(labels_for_plot[i])\n    plt.axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_dict = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'a':10,'b':11,'c':12,\n                   'd':13,'e':14,'f':15,'g':16,'i':17,'k':18,'l':19,'m':20,'n':21,'o':22,'p':23,'q':24,\n                   'r':25,'s':26,'t':27,'u':28,'w':29,'x':30,'y':31,'z':32}\n\nimage_size=(128,128)\n\ndef read_from_folder(train_dir):\n    \"\"\"\n    Loads data and preprocess. Returns train and test data along with labels.\n    \"\"\"\n    images = []\n    labels = []\n    print(\"LOADING DATA FROM \",end = \"\")\n    for folder in os.listdir(train_dir):\n        print(folder, end = ' | ')\n        for image in os.listdir(train_dir + \"/\" + folder):\n            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n            temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2GRAY)\n            img_np = cv2.resize(temp_img,image_size) \n       #    img_np = cv2.normalize(img_np, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n            images.append(img_np)\n            labels.append(labels_dict[folder])  \n            \n    return images, labels\n\n\ndef load_data():\n    images, labels = read_from_folder(train_dir+'Digits')\n    img_tmp, label_tmp = read_from_folder( train_dir +'Letters')\n    images.extend(img_tmp)\n    labels.extend(label_tmp)   \n    images = np.array(images)\n    print(images.shape)\n    labels = tf.keras.utils.to_categorical(labels)\n    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n    print(labels.shape)\n    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n    \n    return X_train, X_test, Y_train, Y_test\n\n\nX_train, X_test, Y_train, Y_test = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshaping images \nX_train = X_train.reshape(X_train.shape[0],128, 128, 1)\nX_test = X_test.reshape(X_test.shape[0], 128, 128, 1)\n\n#normalizing\nX_train.astype('float32')\nX_test.astype('float32')\n\nX_train = X_train/255.0\nX_test = X_test/ 255.0\n\nX_train.shape\n#Y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = datagen.flow(X_train, Y_train, batch_size=64)\ntest_gen = ImageDataGenerator()\ntest_generator = test_gen.flow(X_test, Y_test, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef create_model():\n    model = models.Sequential()\n\n    model.add(layers.Conv2D(32, (3, 3), input_shape=(128,128,1)))\n    model.add(layers.BatchNormalization(axis=-1))\n    model.add(layers.Activation('relu'))\n    model.add(layers.Conv2D(64, (3, 3)))\n    model.add(layers.BatchNormalization(axis=-1))\n    model.add(layers.Activation('relu'))\n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n    \n    model.add(layers.Conv2D(128,(3, 3)))\n    model.add(layers.BatchNormalization(axis=-1))\n    model.add(layers.Activation('relu'))\n    model.add(layers.Conv2D(128, (3, 3)))\n    model.add(layers.BatchNormalization(axis=-1))\n    model.add(layers.Activation('relu'))\n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n        \n    model.add(layers.Flatten())\n\n    # Fully connected layer\n    model.add(layers.Dense(512))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Activation('relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(33))\n    model.add(layers.Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n\ndef fit_model():\n    model_hist = model.fit_generator(train_generator, epochs = 10, validation_data=test_generator)\n    return model_hist ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/gpu:0'):\n    model = create_model()\n    curr_model_hist = fit_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(curr_model_hist.history['accuracy'])\nplt.plot(curr_model_hist.history['val_accuracy'])\nplt.legend(['train', 'test'], loc='lower right')\nplt.title('accuracy plot - train vs test')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.show()\n\nplt.plot(curr_model_hist.history['loss'])\nplt.plot(curr_model_hist.history['val_loss'])\nplt.legend(['training loss', 'validation loss'], loc = 'upper right')\nplt.title('loss plot - training vs vaidation')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_metrics = model.evaluate(X_test, Y_test)\nprint(\"\\nEvaluation Accuracy = \", \"{:.2f}%\".format(evaluate_metrics[1]*100),\"\\nEvaluation loss = \" ,\"{:.6f}\".format(evaluate_metrics[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving the model\nfrom keras.models import load_model\nmodel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n# returns a compiled model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\nFileLinks('.') #lists all downloadable files on server","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = [model.predict_classes(image.reshape(1,64,64,1))[0] for image in X_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predfigure = plt.figure(figsize = (13,13))\ndef plot_image_1(fig, image, label, prediction, predictions_label, row, col, index):\n    fig.add_subplot(row, col, index)\n    plt.axis('off')\n    plt.imshow(image)\n    title = \"prediction : [\" + str(predictions_label) + \"] \"+ \"\\n\" + label\n    plt.title(title)\n    return\n\nimage_index = 0\nrow = 5\ncol = 6\nfor i in range(1,(row*col-1)):\n    plot_image_1(predfigure, X_test[image_index], Y_test[image_index], predictions[image_index], predictions_labels_plot[image_index], row, col, i)\n    image_index = image_index + 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}