{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"/kaggle/input/flower-recognition/flower_recognition\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Need pretrainedmodels to load the pretrained Cedene models into fastai.\n### https://github.com/Cadene/pretrained-models.pytorch"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.models import *\n# import pretrainedmodels\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.vision.models import *\nfrom fastai.vision.learner import model_meta\nimport fastai\n\nfrom utils import *\nimport sys\nimport torch\nfastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis = os.listdir('/kaggle/input/flower-recognition/flower_recognition/train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/flower-recognition/flower_recognition/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"/kaggle/input/flower-recognition/flower_recognition/train\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## test filenames to be used to create final submission.\nfilenames = os.listdir('/kaggle/input/flower-recognition/flower_recognition/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/flower-recognition/flower_recognition/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CenterCrop(32)\n## These Transformation applied based upon my previous competition Experience.\n## if you want to try other transformation check this link\n## https://docs.fast.ai/vision.transform.html\ntfms = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0,do_flip=False,xtra_tfms=[cutout()])\ntfms1 = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0,do_flip=False,xtra_tfms=[cutout()])\ndata = (ImageList.from_csv(path, csv_name = '../train.csv', suffix='.jpg')\n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms, size=400)\n        .databunch(num_workers=0,bs=8))\n\ndata1 = (ImageList.from_csv(path, csv_name = '../train.csv', suffix='.jpg')\n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms1, size=400)\n        .databunch(num_workers=0,bs=8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## to see the images in train with there labels\ndata.show_batch(rows=3, figsize=(8,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## print the target classes\nprint(data.classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## load the pretrained imagenet model\n## you can try other models from this link\n## https://docs.fast.ai/vision.models.html\nlearn = cnn_learner(data, models.densenet169, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## training with one cycle which used cyclic learning rate and learning rate annhelling\nlearn.fit_one_cycle(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.recorder.plot(suggestion=True)\n# best_clf_lr = learn.recorder.min_grad_lr\n# best_clf_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.fit_one_cycle(2, max_lr=best_clf_lr)\nlearn.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## 2nd model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn1 = cnn_learner(data1, models.densenet201, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## training with one cycle which used cyclic learning rate and learning rate annhelling\nlearn1.fit_one_cycle(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn1.unfreeze()\nlearn1.lr_find()\nlearn1.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn2 = cnn_learner(data1, models.resnet152, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n## training with one cycle which used cyclic learning rate and learning rate annhelling\nlearn2.fit_one_cycle(1)\nlearn2.unfreeze()\nlearn2.lr_find()\nlearn2.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn3 = cnn_learner(data, models.densenet121, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")\n## training with one cycle which used cyclic learning rate and learning rate annhelling\nlearn3.fit_one_cycle(1)\nlearn3.unfreeze()\nlearn3.lr_find()\nlearn3.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Applied Test Time Augmentation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn.TTA(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1,_ = learn1.TTA(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2,_ = learn2.TTA(ds_type=DatasetType.Test)\npreds3,_ = learn3.TTA(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## create the submission file ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelled_preds = []\npred11 = preds + preds1 + preds2 + preds3\nfor pred in pred11:\n    labelled_preds.append(int(np.argmax(pred))+1)\n\nsubmission = pd.DataFrame(\n    {'image_id': filenames,\n     'category': labelled_preds,\n    })\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['image_id'] = submission['image_id'].apply(lambda x:x.split('.')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = submission.sort_values(by = ['image_id'], ascending = [True])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## To download the submission file without Commiting the kernel.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"subm.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}