{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Gender Recognition by voice","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2018/01/09162655/voice-biometrics-large1-1024x448.jpg\"  width=\"700\" height=\"100\" />","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Problem Statement","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Gender Recognition by Voice and Speech Analysis\n\n##### This database was created to identify a voice as male or female, based upon acoustic properties of the voice and speech","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Import Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt\n#import category_encoders as ce #encoding\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA #dim red\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR \n\n\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading the comma separated values file into the dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-3/master/Projects/gender_recognition_by_voice.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"   The dataset consists of 3,168 recorded voice samples, collected from male and female speakers. The voice samples are pre-processed by acoustic analysis in R using the seewave and tuneR packages, with an analyzed frequency range of 0hz-280hz","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### To find count of Null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" There is no null values in this dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### To find the category type features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.select_dtypes(include=['object']).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of labels : {} \".format(GenReg_ds.shape[0]))\nprint(\"Total number of males : {}\".format(GenReg_ds[GenReg_ds.label=='male'].shape[0]))\nprint(\"Total number of females : {}\".format(GenReg_ds[GenReg_ds.label=='female'].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the correlation between each feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.heatmap( GenReg_ds.corr());","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Centroid and dfrange both are having more correlated. So, we are going to drop both features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.drop(['centroid'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.drop(['dfrange'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GenReg_ds['label'].value_counts().plot(kind='bar',figsize = (12,5),fontsize = 14,colormap='Dark2', yticks=np.arange(0, 19, 2))\nplt.xlabel('Gender')\nplt.ylabel('No. of persons')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Male_df = GenReg_ds.loc[GenReg_ds.label == \"male\"]\nFemale_df = GenReg_ds.loc[GenReg_ds.label == \"female\"]\nprint(Male_df.shape)\nprint(Female_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Male_df['meanfreq'].plot(kind='line', figsize=(12,5), color='blue', fontsize=13, linestyle='-.')\nplt.ylabel('Meanfreq')\nplt.title('Mean Frequency for Male persons')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Female_df['meanfreq'].plot(kind='line', figsize=(12,5), color='blue', fontsize=13, linestyle='-.')\nplt.ylabel('Meanfreq')\nplt.title('Mean Frequency for Female persons')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To findout the features which are standard deviation equals zero","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stdcol = GenReg_ds['modindx'].std()==0     \nstdcol","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining X and Y values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = GenReg_ds.loc[:,GenReg_ds.columns != 'label']\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols=[]\nfor cols in X.columns:\n    if X[cols].std()==0:\n        drop_cols.append(cols)\nprint(\"Number of constant columns to be dropped: \", len(drop_cols))\nprint(drop_cols)\nX.drop(drop_cols,axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We do not have constant columns in this dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = GenReg_ds.loc[:,GenReg_ds.columns == 'label']\nY.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_encoder = LabelEncoder()\nY = gender_encoder.fit_transform(Y)\nY","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Standardisation\n\nStandardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance). It is useful to standardize attributes for a model. Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting dataset into training set and testing set for better generalisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2 , random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Running SVM with default hyperparameter","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn import metrics\nsvc=SVC()\nsvc.fit(X_train,Y_train)\nY_pred = svc.predict(X_test)\nprint('Accuracy Score : ')\nprint(metrics.accuracy_score(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Default Linear kernel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(kernel='linear')\nsvc.fit(X_train,Y_train)\nY_pred = svc.predict(X_test)\nprint('Accuracy Score : ')\nprint(metrics.accuracy_score(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Default RBF kernel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svc=SVC(kernel='rbf')\nsvc.fit(X_train,Y_train)\nY_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from above accuracy score that svm default parameter for kernel is \"rbf\" ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Default Polynomial kernel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svc=SVC(kernel='poly')\nsvc.fit(X_train,Y_train)\nY_pred=svc.predict(X_test)\nprint('Accuracy Score : ')\nprint(metrics.accuracy_score(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Polynomial kernel is performing poorly. The reasonbbehind this maybe it is overfitting the training dataset. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Cross validation with different kernels","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### CV for Linear kernel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nsvc=SVC(kernel='linear')\nscores = cross_val_score(svc, X, Y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CV for RBF kernel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nsvc=SVC(kernel='rbf')\nscores = cross_val_score(svc, X, Y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CV for polynomial kernel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nsvc=SVC(kernel='poly')\nscores = cross_val_score(svc, X, Y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When K-fold cross validation is done we can see different score in each iteration.This happens because when we use train_test_split method,the dataset get split in random manner into testing and training dataset.Thus it depends on how the dataset got split and which samples are training set and which samples are in testing set.\n\nWith K-fold cross validation we can see that the dataset got split into 10 equal parts thus covering all the data into training as well into testing set.This is the reason we got 10 different accuracy score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}