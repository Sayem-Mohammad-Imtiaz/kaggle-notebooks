{"cells":[{"metadata":{},"cell_type":"markdown","source":"___\n<h1><center>  Clustering</center></h1>\n\n___\n\n## Customer Segmentation of   Product company\n\n###Q3a Description :\n\nThe objective of the problem is to analyze the user buying behavior based on their historical data.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import display, HTML\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom scipy.stats import boxcox, probplot, norm, shapiro\nfrom sklearn.preprocessing import PowerTransformer, MinMaxScaler\nfrom sklearn.cluster import KMeans\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Main function for plot. Usefull for other case of clustering.\n\ndef comprueba_normalidad(df, return_type='axes', title='Normalization'):\n    '''\n    '''\n    fig_tot = (len(df.columns))\n    fig_por_fila = 3.\n    tamanio_fig = 4.\n    num_filas = int( np.ceil(fig_tot/fig_por_fila) )    \n    plt.figure( figsize=( fig_por_fila*tamanio_fig+5, num_filas*tamanio_fig+2 ) )\n    c = 0 \n    shapiro_test = {}\n    lambdas = {}\n    for i, col in enumerate(df.columns):\n        ax = plt.subplot(num_filas, fig_por_fila, i+1)\n        probplot(x = df[df.columns[i]], dist=norm, plot=ax)\n        plt.title(df.columns[i])\n        shapiro_test[df.columns[i]] = shapiro(df[df.columns[i]])\n    plt.suptitle(title)\n    plt.show()\n    shapiro_test = pd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()\n    return shapiro_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center> First Step </center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY = pd.read_csv('../input/customerbehaviour/q3a-product-user.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center> GRAPHICS </center></h1>"},{"metadata":{},"cell_type":"markdown","source":"I save in a XY_cuants ** with  the non-missing and numerical features "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1 , figsize = (15 , 5))\nsns.countplot(x = 'STATE' , data = XY)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY_cuants = XY[['AGE', 'EDU', 'YEARS_EMPLOYED', 'INCOME', \n       'CARD_DEBT', 'OTHER_DEBT',  'DEBT_INCOME_RATIO']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XY_normalizado = (XY_cuants-XY_cuants.mean())/XY_cuants.std()\n# This function shows more ordered graph. \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nax = sns.boxplot(data=XY_normalizado)\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)\nplt.title(u'Representation of (Normarlized) Product User Information ')\nplt.ylabel('The Normalized Value ')\n_ = plt.xlabel('Product User Information')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Representation of the distributions of the variables using histograms.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nn = 0\nfor i, column in enumerate(XY_cuants.columns):\n    n+=1\n    plt.subplot(5, 5, n)\n    sns.distplot(XY_cuants[column], bins=30)\n    plt.title('Distribution of Product User Info'.format(column))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center> Representation of the correlation Matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_corr = XY_cuants.corr(method='pearson')\nn_ticks = len(XY_cuants.columns)\nplt.figure( figsize=(15, 10) )\nplt.xticks(range(n_ticks), XY.columns, rotation='vertical')\nplt.yticks(range(n_ticks), XY.columns)\nplt.colorbar(plt.imshow(matrix_corr, interpolation='nearest', \n                            vmin=-1., vmax=1., \n                            cmap=plt.get_cmap('Blues')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 8)\nsns.heatmap(XY_cuants.corr(), cmap = 'Wistia', annot = True)\nplt.title('Heatmap for the Data', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center> Data Transformation to find the hypothesis."},{"metadata":{},"cell_type":"markdown","source":"# Data normalization:"},{"metadata":{},"cell_type":"markdown","source":"Variable normalization is the process in which a variable is transformed to follow a normal or Gaussian distribution.\n\nIn general, we will only want to normalize the data if we are going to use a machine learning algorithm or a statistical technique that assumes that the data is distributed in a Gaussian or normal way. For example, student's t tests, ANOVAs, linear regressions, logistic regressions, linear discriminant analysis (LDA), k-means, etc.\n\nAmong the ways to transform a variable to normal are methods such as the Box-Cox transformation or the Yeo-Johnson method."},{"metadata":{},"cell_type":"markdown","source":"The following graphs represent the <a href='https://es.wikipedia.org/wiki/Gr%C3%A1fico_Q-Q'>Q-Q Plot</a>, which is a graph that compares between two distributions. In this case, each of the variables with a normal distribution. If they follow the same distribution, the points fall close to the red line."},{"metadata":{"trusted":true},"cell_type":"code","source":"shapiro_test = comprueba_normalidad(XY_cuants, title='Variable Normalization')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shapiro_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All variables are statistically significantly not distributed as a normal.\n\n** Shapiro-Wilk test: ** If the p-value is less than a significance level , it is concluded that the distribution does not come from a normal one."},{"metadata":{},"cell_type":"markdown","source":"\n## Pre-scaling the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))\nX_escalado = scaler.fit_transform(XY_cuants)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shapiro_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center> Segmentation using K-means clustering:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, with the next code, we are looking for the best number of cluster for our dataset.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_range = range(1,20)\ncluster_wss=[] \nfor cluster in cluster_range:\n    model = KMeans(cluster)\n    model.fit(X_escalado)\n    cluster_wss.append(model.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,6])\nplt.title('WSS curve to find the optimal value of clusters ')\nplt.xlabel('# groups')\nplt.ylabel('WSS')\nplt.plot(list(cluster_range),cluster_wss,marker='o')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThe graph assumes the optimal point when the curve creates a bend. In this case it would be about 4-6 groups."},{"metadata":{},"cell_type":"markdown","source":"We will choose the number of groups at 6, but what is usually done is to try several and see if the final results make sense from a business point of view, as I will comment later."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KMeans(n_clusters=6,random_state=0)\nmodel.fit(X_escalado)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### I predict and get customers with your prediction"},{"metadata":{},"cell_type":"markdown","source":"I create a dataframe with all the variables and a new one that is the prediction of the assigned cluster:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Original Dataset with the predictions\ndf_total = XY_cuants.copy()\ndf_total['cluster']=model.predict(X_escalado)\ndf_total[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total.cluster.value_counts().plot(kind='bar', figsize=(10,4))\nplt.title('Count of users per group')\nplt.xlabel('Group')\n_ = plt.ylabel('Counting')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here, we coud see our clients inside of a cluster","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now, we have to obtain the characteristic of each group to find the hiden information inside our DF and give value to our analysis."},{"metadata":{},"cell_type":"markdown","source":"I also get a dataframe with the means of the variables in each group. This would represent each of the groups.\n\nThis is very necessary since the actions that the objective of this problem would be to do actions to each of the groups separately. For this, it is very important to know what each group is like, in order to act differently."},{"metadata":{"trusted":true},"cell_type":"code","source":"descriptivos_grupos = df_total.groupby(['cluster'],as_index=False).mean()\ndescriptivos_grupos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I explain the groups using the means of each variable per group: ¶\n\nI distingusih the group by the income "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total.groupby('cluster').mean().plot(kind='bar', figsize=(15,7))\nplt.xlabel(u'Cluster Number')\n_ = plt.ylabel('Customer Characteristics')\nplt.title('Customer Characteristics based on Income')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, for each of the groups, I obtain their user behaviors or characteristics based on different income level\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total[:2]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}