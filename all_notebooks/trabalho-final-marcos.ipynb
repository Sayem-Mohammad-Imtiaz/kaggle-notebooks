{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>Centro Universitário IESB</center></h1>\nCurso: Ciências de Dados - Põs-Graduação<br>\nAluno: ROBSON BATISTA DA SILVA<br>\nDisciplina: Data Mining e Machine Learning II\n\n   "},{"metadata":{},"cell_type":"markdown","source":"# Importando as bibliotecas"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>Dicionário de Dados</center>\n\n\n**BAD:** 1 = cliente inadimplente no empréstimo 0 = empréstimo reembolsado (variável target)\n\n**LOAN**: Valor do empréstimo\n\n**MORTDUE**: Valor devido da hipoteca existente\n\n**VALUE**: valor da propriedade atual\n\n**REASON**: DebtCon = consolidação da dívida; HomeImp = melhoramento da casa\n\n**JOB**: Seis categorias profissionais\n\n**YOJ**: Anos no emprego atual\n\n**DEROG**: Número de principais relatórios depreciativos\n\n**DELINQ**: número de linhas de crédito inadimplentes\n\n**CLAGE**: Idade da linha comercial mais antiga em meses\n\n**NINQ**: Número de linhas de crédito recentes\n\n**CLNO**: Número de linhas de crédito\n\n**DEBTINC**: Rácio dívida / rendimento"},{"metadata":{},"cell_type":"markdown","source":"* ### Carregando os dados"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # Verificando os tipos e os valores nulos"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O Dataset possui 5.960 linhas e 13 colunas,com exceção das variáveis BAD e LOAN todas as outras variáveis possui valores missing e duas variáveis object JOB e REASON"},{"metadata":{},"cell_type":"markdown","source":"# <center>**Exploração dos Dados**</center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Estatísticas Descritivas\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Estatísticas de todas variáveis quantitativas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a distribuição da variável BAD(Target)\ndf['BAD'].plot.hist(bins=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#frenquência dos dados da variável BAD\ndf['BAD'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Como podemos observar no gráfico acima e na frequência, a distribuição da variável Target(BAD) não está equilibrada, provavelmente as pessoas que pagaram vão enviesar o modelo."},{"metadata":{},"cell_type":"markdown","source":"# <center>Tratamento dos Dados</center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando a quantidade de valores missing nas variáveis\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ao analisar a quantidade de missing na base, temos duas opções: imputação de dados ou a remoção dos valores com missing, nesse caso eu vou remover os valores missing."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removendo os valores missing value da base\n#df2 =df.copy()\ndf.dropna(axis=0,how='any',inplace= True)\ndf.info(), df.isna().any() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#valores da variável target\ndf['BAD'].value_counts().plot(kind='bar',title='Frequência da Variável BAD')\ndf['BAD'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ao remover os missing da base a variável target, continuou muito desbalanceada "},{"metadata":{},"cell_type":"markdown","source":"### Análise Descritiva Exploratória\n\n"},{"metadata":{},"cell_type":"markdown","source":"A avaliação dos histogramas mostra inicialmente que :\n- A variável BAD (Target) possui poucos valores 1 para treinamento do modelo\n- A maior parte dos valores totais de financiamento (LOAN) possuem uma distribuição próxima da normalidade, e os valores a receber(MORTDUE), na média, são maiores que os totais emprestados. Observa-se o terror dos juros bancários\n- Os valores das propriedades possuem distribuição próxima dos valores dos financiamentos\n- O DEROG, algo equivalente à um aviso de negativação do serviço de proteção ao consumidor, é baixo, contudo possui uma correlação próxima de moderada(p=0,25) com os maus pagadores.\n- O DELINQ, linhas de crédito com inadimplência, também possui correlação próxima à moderada(p=0,27) com maus pagadores\n- O número de linhas de crédito possui correlação, mas a intensidade é menor(p=0,13), com maus pagadores\n- Por fim, a base possui um indicador (Débitos/Renda) que possui uma correlação próxima a moderada (p=0,23), sendo um bom indicador."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlação das variáveis numéricas\nplt.figure(figsize= (15, 8))\nsns.heatmap(df.corr(), square=True, annot=True, linewidth=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ao verificar a análise de correlação, observa-se que as variáveis VALUE X MORTDUE tem a maior correlação."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribuição da variável REASON por BAD\ndf.groupby(['BAD'])['REASON'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A variável razão do débito apresentou na categoria Debtcon a maior quatidade de não pagar, mas por um outro lado essa categoria é aque mais quinta seu debidos."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribuição da variável JOB por BAD\ndf.groupby(['BAD'])['JOB'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observa-se que o grupo que trabalho Other e ProfExe possuem um número maior de maus pagadores"},{"metadata":{},"cell_type":"markdown","source":"### Featuring Engineering"},{"metadata":{},"cell_type":"markdown","source":"Para melhor ajuste ao modelo, foram dummizadas as tabelas com type Object"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gerando Dummies para modelos que utilizam apenas variaveis numéricas\n\ndf = pd.get_dummies(df, columns=['REASON', 'JOB'])\ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalizando os dados\n\n#from sklearn.preprocessing import StandardScaler\n#sc = StandardScaler()\n#df = pd.DataFrame(sc.fit_transform(df), columns=df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Geração Amostras de Treino e Teste"},{"metadata":{},"cell_type":"markdown","source":"Nota: Neste trabalho foi realizada a modelagem utilzando uma amostra para validação inclusive, contudo, devida a baixa quantidade de registros, foi utilizado apenas treino e teste "},{"metadata":{"trusted":true},"cell_type":"code","source":"# importando a biblioteca\nfrom sklearn.model_selection import train_test_split\n\n#Separando em treino e teste\ntreino, teste = train_test_split(df, test_size=0.20, random_state=42)\n\n# Não vou usar o dataset de validação\n\ntreino.shape, teste.shape  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lista das colunas que serão usadas\nusadas = [c for c in treino.columns if c not in ['BAD','REASON','JOB']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importando métrica\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import f1_score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelo RandomForest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importanto o modelo\nfrom sklearn.ensemble import RandomForestClassifier\n\n#instanciando o modelo\nrf = RandomForestClassifier(n_estimators=200,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# treinando o modelo\nrf.fit(treino[usadas], treino['BAD'])\n\n# gerando predicoes do modelo com os dados de teste\npred_teste = rf.predict(teste[usadas])\n\n#Medindo a acuracia nos dados de teste\naccuracy_score(teste['BAD'],pred_teste), balanced_accuracy_score(teste['BAD'],pred_teste), f1_score(teste['BAD'],pred_teste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Avaliando a importancia de cada coluna (cada variável de entrada)\npd.Series(rf.feature_importances_, index=usadas).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No gráfico acima observa-se que as variáveis que foram geradas dummers, não são importantes para o modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importando a bilbioteca para plotar o gráfico de Matriz de Confusão\nimport scikitplot as skplt\n\n# Matriz de Confusão - Dados de Validação\nskplt.metrics.plot_confusion_matrix(teste['BAD'], pred_teste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nA Matriz de Confusão mostra que a base de dados é bastante desbalanceada, Assim, a análise das métricas de especifidade e esforço pode realçar os falsos positivos"},{"metadata":{},"cell_type":"markdown","source":"### Utilizando o RandonForest Classifier com ajuste nos parâmetros\n"},{"metadata":{},"cell_type":"markdown","source":"Foram ajustados os parâmetros de aumentando o número de estimadores para 500, quando o default é 100, e informando que o número de folhas aceitavel para as ramificações das árvores de decisão como 2."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setando parametros\nrf2 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=-1, n_estimators=500,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,  class_weight='balanced')\n# treinando o modelo RF2\nrf2.fit(treino[usadas], treino['BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#relizando a predicao do RF2 com base teste\npred_teste2 = rf2.predict(teste[usadas])\n\n#métrica para RF2 validacao\naccuracy_score(teste['BAD'],pred_teste2), balanced_accuracy_score(teste['BAD'],pred_teste2), f1_score(teste['BAD'],pred_teste2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de Confusão - Dados de Validação\nskplt.metrics.plot_confusion_matrix(teste['BAD'], pred_teste2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Após o ajustes no modelo, deve um pequena melhora, mas nada muito significativos."},{"metadata":{},"cell_type":"markdown","source":"## Modelo XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importar o modelo\nfrom xgboost import XGBClassifier\n\n# Instanciar o modelo\nxgb = XGBClassifier(n_estimators=900, n_jobs=-1, random_state=42, learning_rate=0.05)\n\n# treinando o modelo\nxgb.fit(treino[usadas],treino['BAD']) \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo predições\npred_xgb_teste = xgb.predict(teste[usadas])\n\n# Metrícas XGB teste\naccuracy_score(teste['BAD'],pred_xgb_teste), balanced_accuracy_score(teste['BAD'],pred_xgb_teste), f1_score(teste['BAD'],pred_xgb_teste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de Confusão - Dados de Validação\nskplt.metrics.plot_confusion_matrix(teste['BAD'], pred_xgb_teste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O XGBoost apresentou uma melhora um pouco maior no modelo, contudo não foi significante."},{"metadata":{},"cell_type":"markdown","source":"# Conclusão\n\nAo comparar os modelos pela a acurácia e o F1 score, o modelo que teve o melhor desenpenho foi o\nXGBoost, ele obteve 0,96 de acuracia e 0,70 de F1 score, o modelo RandonForest Classifier sem ajustes  0.958 e o f1 score foi de 0,66, já o modelo RandomForest Classifier com ajustes  obteve a acuracia de 0.956 e o F1 Score 0,68.\n\nTodos os modelos se sairam bem, mas quando olhamos as matriz de confusão, percebemos que os modelos não são bons para prever se o cliente estão inadimplente , mas é otimo para prever se em dia, os modelos tem muitas falso positivos nesse caso, \n\nPortanto teria que fazer um novo tratamento nos dados e ou uma imputação  missing values ou até normalizar os dados, para que seja rodado um novo modelo. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}