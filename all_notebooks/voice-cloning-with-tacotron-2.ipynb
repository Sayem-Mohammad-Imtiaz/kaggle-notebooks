{"cells":[{"metadata":{},"cell_type":"markdown","source":"Clone the repo from GitHub"},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/Ryan-Rudes/tacotron2\n%cd tacotron2\n!git submodule init; git submodule update","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create file lists from train and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nmetadata = pd.read_csv(\"../../input/johnoliver/metadata.csv\")\nmetadata = metadata[metadata['include']]\n\ntotal = len(metadata)\nsplit = 0.9\ntrain = int(total * split)\n\ntrain_metadata = metadata[:train]\nval_metadata = metadata[train:]\n\nwith open('filelists/audio_text_train_filelist.txt', 'w') as f:\n    for _, (index, _, _, _, text, _) in train_metadata.iterrows():\n        filepath = '../../input/johnoliver/wav/%05d.wav' % index\n        f.write(filepath + '|' + text + '\\n')\n\nwith open('filelists/audio_text_test_filelist.txt', 'w') as f:\n    for _, (index, _, _, _, text, _) in val_metadata.iterrows():\n        filepath = '../../input/johnoliver/wav/%05d.wav' % index\n        f.write(filepath + '|' + text + '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Install dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==1.15\n!pip install unidecode\n!pip install inflect","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Download pretrained model from Google Drive for transfer learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install gdown\n!gdown https://drive.google.com/uc?id=1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the model for 1000 epochs with a batch size of 32"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python train.py --output_directory=outdir --log_directory=logdir -c tacotron2_statedict.pt --warm_start","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inference\n### Synthesize generated audio samples from text"},{"metadata":{"trusted":true},"cell_type":"code","source":"from multiprocessing import Pool\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom tqdm.notebook import tqdm\nimport IPython.display as ipd\nfrom time import time, sleep\nimport scipy.io.wavfile\nimport numpy as np\nimport matplotlib\nimport torch\nimport sys\n\nsys.path.append('waveglow/')\n\nfrom audio_processing import griffin_lim\nfrom layers import TacotronSTFT, STFT\nfrom hparams import create_hparams\nfrom text import text_to_sequence\nfrom denoiser import Denoiser\nfrom train import load_model\nfrom model import Tacotron2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_data(data, figsize=(16, 4)):\n    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n    for i in range(len(data)):\n        axes[i].imshow(data[i], aspect='auto', origin='lower', interpolation='none')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hparams = create_hparams()\nhparams.sampling_rate = 22000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = int(input(\"Enter steps at latest checkpoint: \"))\ncheckpoint_path = f\"outdir/checkpoint_{checkpoint}\"\nmodel = load_model(hparams)\nmodel.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n_ = model.cuda().eval().half()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"waveglow_path = 'waveglow_256channels_universal_v5.pt'\nwaveglow = torch.load(waveglow_path)['model']\nwaveglow.cuda().eval().half()\nfor k in waveglow.convinv:\n    k.float()\ndenoiser = Denoiser(waveglow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def synthesize(word, n=5, cleaners=['english_cleaners'], sigma=0.666, strength=0.01):\n    sequence = np.array(text_to_sequence(word, cleaners))[None, :]\n    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n    with torch.no_grad():\n        mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n    audio = waveglow.infer(mel_outputs_postnet, sigma=sigma)\n    audio_denoised = denoiser(audio, strength=strength)[:, 0]\n    audio = audio[0].data.cpu().numpy().tolist()\n    mel_outputs = mel_outputs.float().data.cpu().numpy()[0]\n    mel_outputs_postnet = mel_outputs_postnet.float().data.cpu().numpy()[0]\n    alignments = alignments.float().data.cpu().numpy()[0]\n    return audio, mel_outputs, mel_outputs_postnet, alignments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tests = [\n         \"Scientists at the CERN laboratory say they have discovered a new particle.\",\n         \"The state of Florida reports a surge in coronavirus deaths as restrictions are upended.\",\n         \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\",\n         \"A woodchuck would chuck all the wood it could chuck if a woodchuck could chuck wood.\",\n         \"Peter Piper picked a peck of pickled peppers. How many pickled peppers did Peter Piper pick?\",\n         \"Sally sells seashells by the seashore. The shells she sells are seashells I'm sure.\",\n         \"The blue lagoon is a nineteen eighty American romance adventure film.\",\n         \"George Washington was the first President of the United States.\",\n         \"Basilar membrane and otolaryngology are not auto-correlations.\",\n         \"Biden holds first foreign meeting with Canada's Justin Trudeau.\"\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for text in tests:\n    audio, mel_outputs, mel_outputs_postnet, alignments = synthesize(text, n=15)\n    ipd.display_html(ipd.HTML(f\"\"\"\n    <h3>{text}</h3>\n    <br/>\n    \"\"\"))\n    ipd.display(ipd.Audio(data = audio, rate = 22000, autoplay = False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}