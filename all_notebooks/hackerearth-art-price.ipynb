{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train =pd.read_csv('../input/hackerearth-machine-learning-exhibit-art/dataset/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test  =pd.read_csv('../input/hackerearth-machine-learning-exhibit-art/dataset/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('shape of train',np.shape(train))\nprint('shape of test',np.shape(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Null value in training set',train.isnull().sum())\nprint('Null value in test set',test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Transport','Customer Id','Artist Name','Scheduled Date','Delivery Date','Customer Location'],axis =1,inplace=True)\ntest.drop(['Transport','Customer Id','Artist Name','Scheduled Date','Delivery Date','Customer Location'],axis =1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('unique value of material',train['Material'].nunique())\nprint('unique value of Customer Information',train['Customer Information'].nunique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('Null value in training set',train.isnull().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"he_m =np.mean(train['Height'])\nwi_m =np.mean(train['Width'])\nwe_m=np.mean(train['Weight'])\nrepu_m=np.mean(train['Artist Reputation'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"he_m =np.mean(test['Height'])\nwi_m =np.mean(test['Width'])\nwe_m=np.mean(test['Weight'])\nrepu_m=np.mean(test['Artist Reputation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Height']=train['Height'].replace(np.nan,he_m)\ntrain['Width']=train['Width'].replace(np.nan,wi_m)\ntrain['Weight']=train['Weight'].replace(np.nan,we_m)\ntrain['Artist Reputation']=train['Artist Reputation'].replace(np.nan,repu_m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Material'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Remote Location'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Remote Location']= train['Remote Location'].replace(np.nan,'No')\ntest['Remote Location']= test['Remote Location'].replace(np.nan,'No')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Height']=train['Height'].apply(np.ceil)\ntrain['Weight']=train['Weight'].apply(np.ceil)\n\ntest['Height']=test['Height'].apply(np.ceil)\ntest['Weight']=test['Weight'].apply(np.ceil)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \n  \nle = LabelEncoder() \n  \ntrain['International']= le.fit_transform(train['International']) \ntrain['Express Shipment']= le.fit_transform(train['Express Shipment']) \n\ntrain['Installation Included']= le.fit_transform(train['Installation Included']) \ntrain['Fragile']= le.fit_transform(train['Fragile'])\ntrain['Material']= le.fit_transform(train['Material'])\ntrain['Remote Location']= le.fit_transform(train['Remote Location'])\n\ntrain['Customer Information']= le.fit_transform(train['Customer Information'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['International']= le.fit_transform(test['International']) \ntest['Express Shipment']= le.fit_transform(test['Express Shipment']) \n\ntest['Installation Included']= le.fit_transform(test['Installation Included']) \ntest['Fragile']= le.fit_transform(test['Fragile'])\ntest['Material']= le.fit_transform(test['Material'])\ntest['Remote Location']= le.fit_transform(test['Remote Location'])\n\ntest['Customer Information']= le.fit_transform(test['Customer Information'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler =StandardScaler()\ntrain['Artist Reputation']= le.fit_transform(train['Artist Reputation'])\ntrain['Height']= le.fit_transform(train['Height'])\ntrain['Width']= le.fit_transform(train['Width'])\ntrain['Weight']= le.fit_transform(train['Weight'])\ntrain['Price Of Sculpture']= le.fit_transform(train['Price Of Sculpture'])\ntrain['Base Shipping Price']= le.fit_transform(train['Base Shipping Price'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Artist Reputation']= le.fit_transform(test['Artist Reputation'])\ntest['Height']= le.fit_transform(test['Height'])\ntest['Width']= le.fit_transform(test['Width'])\ntest['Weight']= le.fit_transform(test['Weight'])\ntest['Price Of Sculpture']= le.fit_transform(test['Price Of Sculpture'])\ntest['Base Shipping Price']= le.fit_transform(test['Base Shipping Price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(train))\ntrain['Cost']= train['Cost'].abs()\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(test))\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y =train['Cost']\nX =train.drop(['Cost'],axis =1)\nprint(np.shape(y))\nprint(np.shape(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nscaler = sklearn.preprocessing.StandardScaler()\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score , mean_squared_error\nmodel1 =RandomForestRegressor(n_estimators=100, random_state=0)\nmodel1.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred =model1.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yf_pred =model1.predict(test)\n\nyf_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/hackerearth-machine-learning-exhibit-art/dataset/sample_submission.csv')\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test =pd.read_csv('../input/hackerearth-machine-learning-exhibit-art/dataset/test.csv')\nsubmit = pd.DataFrame(index=test['Customer Id'],data=yf_pred,columns=['Cost'])\nsubmit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('hackthon.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}