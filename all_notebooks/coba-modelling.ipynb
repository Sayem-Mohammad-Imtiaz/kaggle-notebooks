{"cells":[{"metadata":{"id":"78_41B0M1ez8","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"id":"zgKVnN8216zA","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/31012021-insurance/data-stage1-31012021.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"NdAO3X5E1-5M","outputId":"2bb4b3be-82db-4ec6-d7b2-bdf7fd351c82","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = reduce_mem_usage(df)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"vN0sf5qF2Amm","trusted":true},"cell_type":"code","source":"X = df.drop('Response', axis = 1).values\ny = df['Response'].values","execution_count":null,"outputs":[]},{"metadata":{"id":"gyGGvlaxATWg","outputId":"30c8882d-6e55-4538-c9f1-d1697f2f22c6","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"bR_FrE462K4X","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"id":"k-jlkE912MgF","outputId":"5da9c44e-5217-4cc7-c5ae-70a5349b83a9","trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"sUg25fLO2Nrw","outputId":"02c0ebdc-8f66-4fcd-f8f0-ed8f2c9e4f9b","trusted":true},"cell_type":"code","source":"print(X_train)\nprint(X_test)\nprint(y_train)\nprint(y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"v2yYQr-22TZw"},"cell_type":"markdown","source":"Library Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = pd.DataFrame(columns = ['Method', 'Accuracy', 'F1_score', 'AUC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results","execution_count":null,"outputs":[]},{"metadata":{"id":"gAdkgpK1brMp"},"cell_type":"markdown","source":"Logistic"},{"metadata":{"id":"BcEQhSHHbqXm","outputId":"869f8a2d-10aa-4abe-bc46-405fbe8fe440","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom scipy.stats import uniform\n\n# Hyperparameters\npenalty = ['l2']\nC = [0.2,0.22,0.24, 0.26, 0.28, 0.3, 0.32, 0.36]\n\n# Dict\nhyperparameters = dict(penalty=penalty, C=C)\n\nclassifier = LogisticRegression(random_state = 42)\n\nclf = RandomizedSearchCV(classifier, hyperparameters, cv = 5, random_state=42, scoring='roc_auc', verbose = 1, n_jobs=-1)\nbest_model = clf.fit(X_train, y_train)\n\nprint(best_model.best_estimator_)\n\ny_pred = best_model.predict(X_test)\ny_pred_proba = best_model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"QUG7G_wJ3VKW","outputId":"62d348fd-1752-4896-d5b5-5bc6a7c78fb1","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\nprint('\\nConfusion matrix')\nprint(confusion_matrix(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import accuracy_score\nprint('\\nAccuracy')\nprint(accuracy_score(y_test, best_model.predict(X_test)))\n\nprint('\\nF1_Score')\nprint(f1_score(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification report')\nprint(classification_report(y_test, best_model.predict(X_test))) # generate the precision, recall, f-1 score, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = df_results.append({ 'Method' : 'Logistic Regression',\n                               'Accuracy' : accuracy_score(y_test, best_model.predict(X_test)),\n                               'F1_score' : f1_score(y_test, best_model.predict(X_test)),\n                               'AUC' : roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1])\n                            }, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\nfpr, tpr, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:,1])\n\nplt.title('Logistic Regression')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))\nprint (roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'logistic.sav'\npickle.dump(best_model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'logistic.sav'\nbest_model = pickle.load(open(filename, 'rb'))\nbest_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"id":"areL2kIthuNe"},"cell_type":"markdown","source":"KNN"},{"metadata":{"id":"LZLRCzxLctzM","outputId":"3e72e17c-3d5e-4011-983f-e86579762cba","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom scipy.stats import uniform\n\n# Hyperparameters\nn_neighbors = [3, 5, 7, 9, 11, 13]\nmetric = ['euclidean', 'manhattan', 'minkowski']\nalgorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n\n# Dict\nhyperparameters = dict(n_neighbors=n_neighbors, metric=metric, algorithm = algorithm)\n\nclassifier = KNeighborsClassifier()\n\nclf = RandomizedSearchCV(classifier, hyperparameters, cv = 5, random_state=42, scoring='roc_auc', verbose = 1, n_jobs = -1)\nbest_model = clf.fit(X_train, y_train)\n\nprint(best_model.best_estimator_)\n\ny_pred = best_model.predict(X_test)\ny_pred_proba = best_model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"j8hiR6qFid4A","outputId":"d7355d79-1c12-418a-83be-7b3f80d2bc77","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\nprint('\\nConfusion matrix')\nprint(confusion_matrix(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import accuracy_score\nprint('\\nAccuracy')\nprint(accuracy_score(y_test, best_model.predict(X_test)))\n\nprint('\\nF1_Score')\nprint(f1_score(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification report')\nprint(classification_report(y_test, best_model.predict(X_test))) # generate the precision, recall, f-1 score, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = df_results.append({ 'Method' : 'KNN',\n                               'Accuracy' : accuracy_score(y_test, best_model.predict(X_test)),\n                               'F1_score' : f1_score(y_test, best_model.predict(X_test)),\n                               'AUC' : roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1])\n                            }, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\nfpr, tpr, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:,1])\n\nplt.title('KNN')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))\nprint (roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'knn.sav'\npickle.dump(best_model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'knn.sav'\nbest_model = pickle.load(open(filename, 'rb'))\nbest_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"id":"VlRSGEK2jKlM"},"cell_type":"markdown","source":"Kernel SVM"},{"metadata":{"id":"mBcc-HhGjHiF","outputId":"a4dd9bd8-1a37-402e-ffef-665f9e688b82","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Hyperparameters\nkernel = ['rbf']\nC = [0.1, 0.3, 0.5, 0.7]\n\n# Dict\nhyperparameters = dict(kernel=kernel, C=C)\n\nclassifier = SVC(random_state = 42, probability = True)\n# classifier.fit(X_train, y_train)\nclf = RandomizedSearchCV(classifier, hyperparameters, cv = 2, random_state=42, scoring='roc_auc', verbose = 1, n_jobs= -1)\nbest_model = clf.fit(X_train, y_train)\n\nprint(best_model.best_estimator_)\n\ny_pred = best_model.predict(X_test)\ny_pred_proba = best_model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"QrgXGNjJjqH1","outputId":"91385aa6-1e19-4267-b431-3ece8b71890d","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\nprint('\\nConfusion matrix')\nprint(confusion_matrix(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import accuracy_score\nprint('\\nAccuracy')\nprint(accuracy_score(y_test, best_model.predict(X_test)))\n\nprint('\\nF1_Score')\nprint(f1_score(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification report')\nprint(classification_report(y_test, best_model.predict(X_test))) # generate the precision, recall, f-1 score, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = df_results.append({ 'Method' : 'SVM',\n                               'Accuracy' : accuracy_score(y_test, best_model.predict(X_test)),\n                               'F1_score' : f1_score(y_test, best_model.predict(X_test)),\n                               'AUC' : roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1])\n                            }, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\nfpr, tpr, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:,1])\n\nplt.title('SVM')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))\nprint (roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'svm.sav'\npickle.dump(best_model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'svm.sav'\nbest_model = pickle.load(open(filename, 'rb'))\nbest_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"id":"o9wxMvDQj5EN"},"cell_type":"markdown","source":"Naive Bayes"},{"metadata":{"id":"Sdy3RmEpj6UZ","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\ny_pred_proba = classifier.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Zw84bLGvj7Rs","outputId":"71fdb7ff-34de-479a-dc8f-1dfb4826fb27","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\nprint('\\nConfusion matrix')\nprint(confusion_matrix(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import accuracy_score\nprint('\\nAccuracy')\nprint(accuracy_score(y_test, best_model.predict(X_test)))\n\nprint('\\nF1_Score')\nprint(f1_score(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification report')\nprint(classification_report(y_test, best_model.predict(X_test))) # generate the precision, recall, f-1 score, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = df_results.append({ 'Method' : 'Naive Bayes',\n                               'Accuracy' : accuracy_score(y_test, best_model.predict(X_test)),\n                               'F1_score' : f1_score(y_test, best_model.predict(X_test)),\n                               'AUC' : roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1])\n                            }, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\nfpr, tpr, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:,1])\n\nplt.title('Naive Bayes')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))\nprint (roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'naiveb.sav'\npickle.dump(classifier, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'naiveb.sav'\nbest_model = pickle.load(open(filename, 'rb'))\nprint(\"Done\")\nbest_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"id":"Sy2RBI0bksdw"},"cell_type":"markdown","source":"Decision Tree"},{"metadata":{"id":"F9g7ew2hktX3","outputId":"3bd09da4-8af2-4227-c10f-269e76ab8601","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Hyper Parameter\n\nmax_depth = [int(x) for x in np.linspace(1, 110, num = 30)] # Maximum number of levels in tree\nmin_samples_split = [2, 5, 10, 100] # Minimum number of samples required to split a node\nmin_samples_leaf = [1, 2, 4, 10, 20, 50] # Minimum number of samples required at each leaf node\nmax_features = ['auto', 'sqrt'] # Number of features to consider at every split\ncriterion= ['gini', 'entropy']\n# Dict\nhyperparameters = {\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'max_features': max_features,\n               'criterion' : criterion\n                }\n\nclassifier = DecisionTreeClassifier(random_state = 42)\n\nclf = RandomizedSearchCV(classifier, hyperparameters, cv = 5, random_state=42, n_iter = 15, scoring='roc_auc', verbose = 1, n_jobs = -1)\nbest_model = clf.fit(X_train, y_train)\n\nprint(best_model.best_estimator_)\n\ny_pred = best_model.predict(X_test)\ny_pred_proba = best_model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Hy4FHL1zmjNp","outputId":"242dec4f-0e85-4e04-f039-6a2a75f79375","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\nprint('\\nConfusion matrix')\nprint(confusion_matrix(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import accuracy_score\nprint('\\nAccuracy')\nprint(accuracy_score(y_test, best_model.predict(X_test)))\n\nprint('\\nF1_Score')\nprint(f1_score(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification report')\nprint(classification_report(y_test, best_model.predict(X_test))) # generate the precision, recall, f-1 score, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = df_results.append({ 'Method' : 'Decision Tree',\n                               'Accuracy' : accuracy_score(y_test, best_model.predict(X_test)),\n                               'F1_score' : f1_score(y_test, best_model.predict(X_test)),\n                               'AUC' : roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1])\n                            }, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\nfpr, tpr, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:,1])\n\nplt.title('Logistic Regression')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))\nprint (roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"id":"BYLZ6mgibl5q","outputId":"3cd9b91e-f4bb-4d49-992f-a6ba88d031e4","trusted":true},"cell_type":"code","source":"importance = best_model.best_estimator_.feature_importances_\nfeat_importances = pd.Series(importance, index= pd.Series(df.drop('Response', axis = 1).columns))\n# feat_importances.plot(kind =\"barh\")\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.xlabel('score')\nplt.ylabel('feature')\nplt.title('feature importance score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'dectree.sav'\npickle.dump(best_model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'dectree.sav'\nbest_model = pickle.load(open(filename, 'rb'))\nbest_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"id":"R547nsSBmkT3"},"cell_type":"markdown","source":"# Bagging"},{"metadata":{"id":"3MZw5WOUmnRk"},"cell_type":"markdown","source":"Random forest"},{"metadata":{"id":"4zq5bNEimlj8","outputId":"361c08d1-6dd1-408f-9467-4fa85fe638b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Hyper Parameter\n\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 20)] # Number of trees in random forest\nmax_features = ['auto', 'sqrt', 'log2'] # Number of features to consider at every split\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 5)] # Maximum number of levels in tree\nmin_samples_split = [int(x) for x in np.linspace(start = 2, stop = 10, num = 5)] # Minimum number of samples required to split a node\nmin_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 10, num = 5)] # Minimum number of samples required at each leaf node\nbootstrap = [True, False] # Method of selecting samples for training each tree\nn_jobs = [-1]\n\n#Menjadikan ke dalam bentuk dictionary\nrandom_search = {'criterion': ['entropy','gini'],\n               'max_depth': max_depth,\n               'min_samples_leaf': min_samples_split,\n               'min_samples_split': min_samples_leaf,\n               'n_estimators': n_estimators,\n                'max_features' : max_features}\n\n# random_search = {'criterion': ['entropy','gini'],\n#                'max_depth': [10],\n#                'min_samples_leaf': [6],\n#                'min_samples_split': [7],\n#                'n_estimators': [300]}\n\nclassifier = RandomForestClassifier(random_state = 42)\n\nclf = RandomizedSearchCV(classifier, random_search, cv = 5, random_state=42, scoring='roc_auc', verbose = 4, n_jobs = -1)\nbest_model = clf.fit(X_train, y_train)\n\nprint(best_model.best_estimator_)\n\ny_pred = best_model.predict(X_test)\ny_pred_proba = best_model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"a9t5jc1XpDqY","outputId":"8a3175c2-f509-44b4-fc3d-243938a824c1","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\nprint('\\nConfusion matrix')\nprint(confusion_matrix(y_test, y_pred))\n\nfrom sklearn.metrics import accuracy_score\nprint('\\nAccuracy')\nprint(accuracy_score(y_test, y_pred))\n\nprint('\\nF1_Score')\nprint(f1_score(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification report')\nprint(classification_report(y_test, y_pred)) # generate the precision, recall, f-1 score, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = df_results.append({ 'Method' : 'Random Forest',\n                               'Accuracy' : accuracy_score(y_test, best_model.predict(X_test)),\n                               'F1_score' : f1_score(y_test, best_model.predict(X_test)),\n                               'AUC' : roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1])\n                            }, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"id":"3jkiCy-zsk8b","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba[:,1])\n\nplt.title('Random Forest ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_test, y_pred_proba[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'rforest1.sav'\npickle.dump(best_model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'rforest1.sav'\nbest_model = pickle.load(open(filename, 'rb'))\nbest_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.metrics import AUC\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_baseline():\n    model = Sequential()\n    model.add(Dense(15, input_dim = 15, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=[AUC()])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvscores = []\nkfold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 42)\nfor train, test in kfold.split(X_train,y_train):\n    model = create_baseline()\n    history = model.fit(X_train, y_train, epochs = 3, batch_size = 32, verbose = 1, validation_data =(X_test,y_test))\n    scores = model.evaluate(X_test, y_test, verbose = 1)\n    print(\"\\n %s: %.2f%%\\n---------\\n\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\nprint(\"AUC Result for Testing\")\nprint(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n# kfold = StratifiedKFold(n_splits = 3, shuffle = True)\n# results = cross_val_score(model,  X, y, cv = kfold, scoring = 'roc_auc')\n# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test, batch_size = 32)\ny_pred = np.where(y_pred >= 0.5, 1, 0)\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\nprint('\\nConfusion matrix')\nprint(confusion_matrix(y_test, y_pred))\n\nfrom sklearn.metrics import accuracy_score\nprint('\\nAccuracy')\nprint(accuracy_score(y_test, y_pred))\n\nprint('\\nF1_Score')\nprint(f1_score(y_test, best_model.predict(X_test)))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification report')\nprint(classification_report(y_test, y_pred)) # generate the precision, recall, f-1 score, num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, model.predict(X_test, batch_size = 32)[:,0])\n\nplt.title('Random Forest ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h5py\n\n#Serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n#Serialize weights to HDF5\nmodel.save_weights(\"ANN.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = df_results.append({ 'Method' : 'ANN',\n                               'Accuracy' : accuracy_score(y_test, y_pred),\n                               'F1_score' : f1_score(y_test, y_pred),\n                               'AUC' : np.mean(cvscores)/100\n                            }, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}