{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\ncolor = sns.color_palette()\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\nimport plotly.tools as tls\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nos.listdir(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/grammar-and-online-product-reviews/GrammarandProductReviews.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna(subset=['reviews.text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=200,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n).generate(str(data))\n\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n\nshow_wordcloud(df['reviews.text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_srs = df['reviews.rating'].value_counts().head()\ntrace = go.Bar(\n    y=cnt_srs.index[::-1],\n    x=cnt_srs.values[::-1],\n    orientation = 'h',\n    marker=dict(\n        color=cnt_srs.values[::-1],\n       #colorscale = 'Cividis',\n        colorscale = [[0.0, \"rgb(165,0,38)\"],\n                [0.1111111111111111, \"rgb(215,48,39)\"],\n                [0.2222222222222222, \"rgb(244,109,67)\"],\n                [0.3333333333333333, \"rgb(253,174,97)\"],\n                [0.4444444444444444, \"rgb(254,224,144)\"],\n                [0.5555555555555556, \"rgb(224,243,248)\"],\n                [0.6666666666666666, \"rgb(171,217,233)\"],\n                [0.7777777777777778, \"rgb(116,173,209)\"],\n                [0.8888888888888888, \"rgb(69,117,180)\"],\n                [1.0, \"rgb(49,54,149)\"]],\n        reversescale = True\n    ),\n)\n\nlayout = dict(\n    title='Ratings distribution',\n    )\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"Ratings\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['reviews_length']=df['reviews.text'].apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=2.0)\n\ng = sns.FacetGrid(df,col='reviews.rating',size=5)\ng.map(plt.hist,'reviews_length')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['reviews.didPurchase'].fillna(\"Review N/A\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax=sns.countplot(df['reviews.didPurchase'])\nax.set_xlabel(xlabel=\"People's Reviews\",fontsize=17)\nax.set_ylabel(ylabel='No. of Reviews',fontsize=17)\nax.axes.set_title('Genuine No. of Reviews',fontsize=17)\nax.tick_params(labelsize=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1.4)\nplt.figure(figsize = (10,5))\nsns.heatmap(df.corr(),cmap='coolwarm',annot=True,linewidths=.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nall_text=df['reviews.text']\ntrain_text=df['reviews.text']\ny=df['reviews.rating']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 1),\n    max_features=20000)\nword_vectorizer.fit(all_text)\ntrain_word_features = word_vectorizer.transform(train_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"char_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(2, 6),\n    max_features=60000)\nchar_vectorizer.fit(all_text)\ntrain_char_features = char_vectorizer.transform(train_text)\n\ntrain_features = hstack([train_char_features, train_word_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_features, y,test_size=0.4,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train,y_train)\npreds=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb=xgb.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2=xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_accuracy=accuracy_score(preds2,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_accuracy=accuracy_score(preds,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Random Forest Model accuracy\",rf_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost Model accuracy\",xgb_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment'] = df['reviews.rating']<4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_text, test_text, train_y, test_y = train_test_split(df['reviews.text'],df['sentiment'],test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_NB_WORDS = 30000\n\n# get the raw text data\ntexts_train = train_text.astype(str)\ntexts_test = test_text.astype(str)\n\n# finally, vectorize the text samples into a 2D integer tensor\ntokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\ntokenizer.fit_on_texts(texts_train)\nsequences = tokenizer.texts_to_sequences(texts_train)\nsequences_test = tokenizer.texts_to_sequences(texts_test)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 200\n#pad sequences are used to bring all sentences to same size.\n# pad sequences with 0s\nx_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\nx_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', x_train.shape)\nprint('Shape of data test tensor:', x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, 128))\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,input_shape=(1,)))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, train_y,\n          batch_size=130,\n          epochs=12,\n          validation_data=(x_test, test_y))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}