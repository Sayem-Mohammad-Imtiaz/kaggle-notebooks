{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classificação - Presença de Doença Cardíaca\n\nEste notebook realiza um estudo, um conjunto de experimentos, sobre algoritmos de classificação no dataset [Heart Disease UCI](https://www.kaggle.com/ronitf/heart-disease-uci). Um conjunto de dados que reúne mais de 300 pacientes com 14 atributos, tais como idade, sexo, nível do colesterol, nível de açucar no sangue, entre outros. Nosso objetivo é distinguir a presença (valor 1) ou ausência (valor 0) de uma doença cardíaca.\n\n> Conteúdo voltado para iniciantes na área de Aprendizado de Máquina e Ciência de Dados!\n\n\n<a id=\"top\"></a>\n\n## Conteúdo\n\n> **Nota.** Alguns códigos foram ocultados a fim de facilitar a leitura.\n\nO notebook está organizado como segue:\n\n- [Dados](#data) - Carregamento dos dados, pré-processamento.\n- [Visualização](#visual) - Análise exploratória dos dados.\n- [Classificação](#class) - Aplicação de algoritmos de Aprendizado de Máquina.\n    - [KNN](#knn) - Classificação com k-NN.\n    - [Naive Bayes](#naive) - Classificação com Naive Bayes.\n    - [Support Vector Machines](#svm) - Classificação com Support Vector Machines.\n    - [Árvore de Decisão](#decision) - Classificação com Decision Tree.\n    - [Random Forest](#forest) - Classificação com Random Forest.\n    - [Bagging](#bagging) - Classificação com estratégia de Bagging.\n    - [Ensemble](#ensemble) - Classificação com estratégia de Ensemble.\n    - [AutoML](#automl) - Classificação usando Automated Machine Learning.\n- [Hyperparameter Tuning](#tuning) - Tuning de parâmetros."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install auto-sklearn==0.12.0\n!pip install scikit-learn==0.23.2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"data\"></a>\n\n-----\n\n# Dados\n\n- Carregamento dos dados.\n- Pré-processamento dos dados.\n\n[Voltar para o Topo](#top)"},{"metadata":{},"cell_type":"markdown","source":"## Carregamento dos Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# algebra linear\nimport numpy as np \n# processamento de dados\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# imprime os arquvios\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pré-Processamento dos Dados\n\nVamos normalizar os dados entre valor 0 e 1, utilizando o transformador `MinMaxScaler`. \nEste transformador normaliza os valores por coluna, utilizando o valor máximo e mínimo para normalizar o valor real.\n\n> Este procedimento é necessário, pois alguns algoritmos de classificação se beneficiam de valores normalizados, tal como o K-NN."},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalizador\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Segmenta os dados e as classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# recupera os valores (X), e as classes (Y)\nX = df.drop('target', axis=1)\nY = df['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalização dos Dados\n\nNesta seção vamos utilizar a normalização [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?highlight=minmaxscaler#sklearn.preprocessing.MinMaxScaler). Esta função de preprocessamento normaliza os dados conforme segue:\n\n$$x_{new} = x_{\\sigma} * (x_{max} - x_{min}) + x_{min}{}$$\n\nEm que:\n\n$$x_{\\sigma} = \\frac{(x - x_{min})}{(x_{max} - x_{min})}$$\n\n\nA grosso modo, normaliza os dados entre 0 e 1 e mantem sua distribuição original."},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\nX = min_max_scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"visual\"></a>\n\n-----\n\n# Visualização\n\nNesta seção será realizado a transformação dos 13 atributos (removendo a classe) para 2 dimensões utilizando um algortimos de redução de dimensionadade, chamado de [PCA - Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis). \n\n> Faremos este procedimento a fim de visualizar os dados em 2 dimensões.\n\n[Voltar para o Topo](#top)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualização de dados\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# redutor de dimensionalidade\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# redução da dimensionalidade\npca = PCA(n_components=2).fit(X)\nX_reduced = pca.fit_transform(X)\n\n# registrando os valores num novo DataFrame\ndf_2d = pd.DataFrame(X_reduced)\ndf_2d.columns = ['0', '1']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualização dos Dados transformados em duas dimensões.\n\n> **Note**. Os dados transformados não representam a realidade, ou seja, eles não são linearmente divididos como demonstrado visualmente. Contudo, indica que é possível realizar uma divisão nos dados."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df_2d, x='0', y='1')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizando os dados transformados, colorindo pela classe."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df_2d, x='0', y='1', hue=Y, style=Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"class\"></a>\n\n-----\n\n# Classificação\n\n- Conjunto de dados.\n- Experimentos.\n\n[Voltar para o Topo](#top)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# métricas\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# variável de resultado final\n# será armazenado o resultado de todos experimentos\nexperiment = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conjunto de Dados\n\nSepara os conjuntos de treinamento e teste."},{"metadata":{"trusted":true},"cell_type":"code","source":"# treinamento, test split\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=26)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('treinamento:', len(y_train))\nprint('teste      :', len(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"knn\"></a>\n\n## K-NN\n\n_(k-Nearest Neighbors)_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classificador\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = KNeighborsClassifier(n_neighbors=3)\nmodel1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['KNN'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão k-NN**\n\nO k-NN conseguiu classificar bem o conjunto de dados, alcançando resultados satisfatórios.   \nAcurácia de 79% e F1-score de 82%.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"naive\"></a>\n\n## Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classificador\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = GaussianNB()\nmodel2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Naive Bayes'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Naive Bayes**\n\nNeste conjunto de dados, o Naive Bayes teve um desempenho inferior ao k-NN.   \nContudo, apresentou uma acurácia de 74% e F1-Score de 77%.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"svm\"></a>\n\n## Support Vector Machines (SVM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classificador\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = SVC()\nmodel3.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model3.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['SVM'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Support Vector Machines (SVM)**\n\nO SVM foi o melhor modelo até o momento.   \nUltrapassando o k-NN, com acurácia de 79% e F1-score de 82%.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"decision\"></a>\n\n## Árvore de Decisão"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classificador\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = DecisionTreeClassifier(random_state=26)\nmodel4.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model4.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Decision Tree'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização\n\nNós conseguimos visualizar a árvore de decisão, como as ramificações ocorreram.   \nÉ muito útil para uma apresentação de negócio, em que você consegue explicar a inteligência induzida."},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizador da árvore\nfrom sklearn.tree import plot_tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizando a árvore inteira."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n_ = plot_tree(model4) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizando a primeira profundidade, apenas para observarmos os valores presentes na figura.\n\n> Na figura vemos: (1) O atributo selecionado e a questão (condição de separação) (nota, este nome pode ser personalizado); (2) a métrica de impureza; (3) número de exemplos; (4) número de exemplo para cada classe; e (5) a cor significa a classe majoritária do respectivo nó."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n_ = plot_tree(model4, max_depth=1) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Árvore de Decisão**\n\nA Árvore de Decisão obteve resultados razoáveis.   \nCom acurácia de 68% e F1-score de 70%, abaixo do k-NN.   \n\nSão excelente algoritmos de Aprendizado de Máquina para compreensão/estudo do negócio.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"forest\"></a>\n\n## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# classificador\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model5 = RandomForestClassifier(n_estimators=100, random_state=26)\nmodel5.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model5.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Random Forest'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização\n\nTambém é possível extrar as `DecisionTree`do `RandomForest` para visualização. Neste caso, é necessário acessar cada uma das árvores utilizando o comando `RandomForest.estimators_[indice]` e visualizar como demonstrado na seção da Árvore de Decisão."},{"metadata":{},"cell_type":"markdown","source":"**Discussão Random Forest**\n\nRandom Forest obteve um dos melhores resultados.   \nCom acurácia de 75% e F1-score de 79%, abaixo do k-NN.   \n\nRandom Forests são um dos algoritmos mais utilizados em competições de Aprendizado de Máquina.\n\n> **Nota**. Possui alto custo computacional, pois tem que treinar vários modelos.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"bagging\"></a>\n\n## Bagging\n\nClassificação com estratégia de Bagging, com algoritmo base SVM."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble\nfrom sklearn.ensemble import BaggingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_base = SVC()\nmodel6 = BaggingClassifier(base_estimator=model_base, n_estimators=10, random_state=26)\nmodel6.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model6.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Bagging'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Bagging**\n\nBagging obteve o melhor resultado, utilizando 10 modelos SVM.   \nCom acurácia de 82% e F1-score de 84%.   \n\n> **Nota**. Possui alto custo computacional, pois tem que treinar vários modelos.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ensemble\"></a>\n\n## Ensemble\n\nClassificação com estratégia de Ensemble, utilizando os algoritmos SVM e Random Forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble\nfrom sklearn.ensemble import VotingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = SVC()\nclf2 = RandomForestClassifier(n_estimators=100, random_state=26)\nestimators=[('SVM', clf1), ('RandomForest', clf2)]\n\nmodel7 = VotingClassifier(estimators=estimators, voting='hard')\nmodel7.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model7.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Ensemble'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Ensemble**\n\nEnsemble obteve bons resultados, porém não o melhor.   \nCom acurácia de 78% e F1-score de 80%.   \n\n> **Nota**. Possui alto custo computacional, pois tem que treinar vários modelos.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"automl\"></a>\n\n## AutoML\n\nAutomated Machine Learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"# automl\nimport autosklearn.classification as autoclassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"automl = autoclassifier.AutoSklearnClassifier(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n    tmp_folder='/automl/tmp/',\n    output_folder='/automl/output/',\n)\nautoml.fit(X_train, y_train, dataset_name='heart-disease-uci')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = automl.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['AutoML'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização\n\nPodemos ver o modelo ou o ensemble de modelos utilizado no AutoML.\n\n> Para isto, utilize o comando `automl.show_models()`."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# output escondido, ficou muito grande\nautoml.show_models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusão\n\nPor fim, o melhor algoritmo foi o SVM com a mesma acurácia do KNN, mas com precisão e f1-score maiores.   \nA estratégia de ensemble Bagging superou todos os classificadores, porém teve maior custo computacional."},{"metadata":{"trusted":true},"cell_type":"code","source":"# palheta de cores\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cm = sns.color_palette('Blues_r', as_cmap=True)\npd.DataFrame(experiment).T.style.background_gradient(subset=['acc', 'f1'], cmap=cm).highlight_max(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"tuning\"></a>\n\n-----\n\n# Hyperparameter Tuning\n\n[Random Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) no algoritmo SVM.\n\n[Voltar para o Topo](#top)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# random search\nfrom sklearn.model_selection import RandomizedSearchCV\n# uniform distribution\nfrom scipy.stats import uniform","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hiper-parâmetros\n\nQuais são os hiper-parâmetros do SVM?"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVC()\nmodel.get_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Escolhendo uma distribuição dos parâmetros, _i.e.,_ um espaço de busca."},{"metadata":{"trusted":true},"cell_type":"code","source":"distributions = {\n    'random_state':[26],\n    'C':uniform(loc=1, scale=9),\n    'kernel': ['rbf', 'sigmoid'],\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Busca / Tuning\n\nExecutando a tunagem de parâmetros pelo espaço pré-fixado, utilizando 10-fold cross validation e em no máximo 50 experimentos, bem como otimizando a acurácia."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomizedSearchCV(model, distributions, n_iter=50, random_state=26, refit='acc', cv=10)\nsearch = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quais foram os melhores parâmetros?"},{"metadata":{"trusted":true},"cell_type":"code","source":"search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Qual foi a acurácia deste parâmetro no dataset de validação?"},{"metadata":{"trusted":true},"cell_type":"code","source":"search.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação\n\nAvaliando o melhor modelo no dataset de teste."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = search.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrec = recall_score(y_pred, y_test)\nf1  = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"experiment['Random Search'] = {'acc':acc, 'pre':pre, 'rec':rec, 'f1':f1}\n\nprint('acurácia :', acc)\nprint('precisão :', pre)\nprint('revocação:', rec)\nprint('f1-score :', f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparando o modelo padrão com o Tuning\n\nSerá que o Hyperparameter Tuning melhorou os resultados do SVM?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.DataFrame(experiment)[['SVM', 'Random Search']].T.style.highlight_max(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}