{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Import common packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import packages for text\nimport nltk\nimport re\nfrom wordcloud import WordCloud\n\n#Set ignore warning for futureWarning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#import deep learning packages for text classification\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfake_news = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")\ntrue_news = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_news.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See how many fake news are there from different subjects\nfake_news_by_subject = fake_news.groupby(by=\"subject\").count()[\"title\"]\nprint(fake_news_by_subject)\nplt.figure(figsize=(10,3))\nsns.countplot(\"subject\", data=fake_news, palette=\"Blues\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_text_data = \"\".join(str(x) for x in fake_news[\"text\"])\nstop_words = set(nltk.corpus.stopwords.words(\"english\"))\nword_cloud_fake = WordCloud(stopwords=stop_words, width=2000, height=1000,\\\n                            max_font_size=160, min_font_size=30).generate(fake_text_data)\nplt.figure(figsize=(12,6), facecolor=\"k\")\nplt.imshow(word_cloud_fake)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA for Real News","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets do the wordcloud for true news\ntrue_text_data = \"\".join(str(x) for x in true_news[\"text\"])\nword_cloud_fake = WordCloud(stopwords=stop_words, width=2000, height=1000,\\\n                            max_font_size=160, min_font_size=30).generate(true_text_data)\nplt.figure(figsize=(12,6), facecolor=\"k\")\nplt.imshow(word_cloud_fake)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del fake_text_data, true_text_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label the true_or_not for concat\ntrue_news[\"true\"]=1\nfake_news[\"true\"]=0\ndf = pd.concat([fake_news, true_news])\n# df.shape[0] # 44898 rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Worth to mention, we are not supposed to use \"subject\" as a feature for classification since the two datasets have different subjects. It is \"cheating\" to let the ML tell the difference by subjects. So here we only use title and text.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"text\"] = df[\"text\"]+\" \"+df[\"title\"]\n#I am not sure whether giving different weights to these two vars show difference. \ndf = df.filter([\"text\",\"true\"], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import unicodedata\ndef remove_punct(text):\n    text  = \"\".join([char for char in text if char not in string.punctuation])\n    text = re.sub('[0-9]+', '', text)\n    return text\n\ndef remove_stopwords(text):\n    filtered_text = []\n    for i in text.split():\n        i = i.strip()\n        if i.lower() not in stop_words:\n            filtered_text.append(i)\n    filtered_text = ' '.join(filtered_text)    \n    return filtered_text\n\ndef normalize_accented_characters(text):\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf8')\n    return text\n\ndef normalize_text(text):\n    text = remove_punct(text)\n    text = remove_stopwords(text)\n    text = normalize_accented_characters(text)\n    return text    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text']=df['text'].apply(normalize_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tokenization & Vectorization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we have two tasks:\nwhich text feature engineering method we should use and which ML/DL models we should use\n\nFeature Engineering(Vectorization) Methods:\n1. TF-IDF\n2. Word2Vec (YES)\n3. GloVe \n\n#There are two great notebooks illustrating GloVe.So here I am gonna use Word2Vec\n\nThe common methods I learned about text classification:\n1. SVM\n2. Naive Beyes (Normally SVM performs better)\n3. Logistic Regression (Since here it is a binary classification problem)\n4. CNN (Most reasonable since we have enough training set)\n\nWe will try CNN here for general purpose. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Upvoted if you like it! Big Thanks!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_text(text):\n    lemmas = []\n    for word in text.split():\n        lemmas.append(lemmatizer.lemmatize(word))\n    return \" \".join(lemmas)\ndf['text']=df['text'].apply(lemmatize_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = df[\"text\"].values, df[\"true\"].values\ntokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\nX=[]\nfor article in x:\n    sentence_list = []\n    article = nltk.sent_tokenize(article)\n    for sentence in article:\n        sentence = sentence.lower()\n        #The seqence here is very important since they are different data types.\n        #Generally speaking, Word2Vec needs a \"list of list\" for input. \n        tokens = tokenizer.tokenize(sentence)\n        sentence_list.extend([x.strip() for x in tokens])\n    X.append(sentence_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\nemb_dim = 100 #vector dimension\nword2vec_model = gensim.models.Word2Vec(sentences=X, size=emb_dim, window=10, min_count=1)\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nX = tokenizer.texts_to_sequences(X)\nX = pad_sequences(X, maxlen=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_index = tokenizer.word_index #A dictionary with index and words\nvocab_size = len(word_index) + 1\n#Get the weight matrix for embedding layer\ndef get_weight(model,word_index):\n    weight_matrix = np.zeros((vocab_size,emb_dim))\n    for word, index in word_index.items():\n        weight_matrix[index]=model[word]\n    return weight_matrix\nemb_vec = get_weight(word2vec_model,word_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nnn_model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, output_dim=emb_dim, weights = [emb_vec], input_length=1000,trainable=False),\n    #REMEMBER TO PUT THE EMBEDDING VECTORS TO A LIST\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dense(32,activation=\"relu\"),\n    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n])\nnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nnn_model.summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = nn_model.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test),batch_size=128)\nclassification_result = nn_model.evaluate(x_test,y_test)\nclassification_result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The However Part","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. When the model trained 7000 out of 35918 in epoch 1, the accuracy already reached 93%. Some of the words like \"Reuters\" \"WASHINGTON\" can ensure the news is true. So this model cannot produce as good results when applying to a new dataset. \n2. I think you can use one less layer for this. The traning time is a little bit too long.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}