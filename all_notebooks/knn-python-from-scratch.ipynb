{"cells":[{"metadata":{},"cell_type":"markdown","source":"# KNN-Python from Scratch","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# # Here we are going to implement KNN algorithm from scratch without using any machine-learning libraries","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[KNN Introduction](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)\n> K Nearest Neighbour is a simple algorithm that stores all the available cases and classifies the new data or case based on a similarity measure. It mostly used to classifies a data point based on how its neighbours are classified.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# # # How KNN works\n* Let us consider we have 10 classifiers.\n* You want to predict new sample data point belongs to which classifier.\n* Here KNN comes into picture to solve your problem.\n\nConfused!?\nLet me explain \n\n* KNN measures the distance between new data point and all the available data.\n* 'K' in KNN refers to number of nearest neighbours, consider k = 5\n* Collect five nearest data points based on distace we measured.\n* Our new data point is classified by majority of votes from its five neighbours and new data point would be 4th classifier (among 10 classifiers) as four out of five nearest neighbours belong to 4th classifier\n\nGot an Idea!\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Choosing k value varies with dataset your working\n* Recommendation\n    *         k = sqrt(N)\n    *         where N is total number of samples","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Let's Start ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here we are going to work with\n[iris-data](https://www.kaggle.com/uciml/iris)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # load the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/iris-data/Iris.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Visualising different species(Classifiers) on which we are going to work","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Species = list(set(data['Species']))\nSpecie1 = data[data['Species']==Species[0]]\nSpecie2 = data[data['Species']==Species[1]]\nSpecie3 = data[data['Species']==Species[2]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(Specie1['PetalLengthCm'], Specie1['PetalWidthCm'], label=Species[0])\nplt.scatter(Specie2['PetalLengthCm'], Specie2['PetalWidthCm'], label=Species[1])\nplt.scatter(Specie3['PetalLengthCm'], Specie3['PetalWidthCm'], label=Species[2])\nplt.xlabel('PetalLengthCM')\nplt.ylabel('PetalWidthCM')\nplt.legend()\nplt.title('Different Species Visualization')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Independent Variables: ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n* Dependent Variables: ['Species']","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# # *Now our task is to predict the new data point belongs to which species based on sepalLength, sepalWidth, petalLength, petalWidth*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# # # Preprocessing Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Removing Id column from data, which is unnecessary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"req_data = data.iloc[:,1:]\nreq_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shuffling the data, to avoid overFitting problem","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffle_index = np.random.permutation(req_data.shape[0])        #shuffling the row index of our dataset\nreq_data = req_data.iloc[shuffle_index]\nreq_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Setting 70% data into training data\n* Therefore 30% data will be our test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(req_data.shape[0]*0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = req_data.iloc[:train_size,:] \ntest_df = req_data.iloc[train_size:,:]\ntrain = train_df.values\ntest = test_df.values\ny_true = test[:,-1]\nprint('Train_Shape: ',train_df.shape)\nprint('Test_Shape: ',test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN in 3 Steps\n> 1 Measure distance (Euclidean Distance or Manhattan Distance)\n\n> 2 Get nearest neighbours\n\n> 3 Predict Classifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# # Step 1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Measuring Distance using Euclidean Distance\n>Mathematical formula  √ (x2 − x1)2 + (y2 − y1)2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sqrt\ndef euclidean_distance(x_test, x_train):\n    distance = 0\n    for i in range(len(x_test)-1):\n        distance += (x_test[i]-x_train[i])**2\n    return sqrt(distance)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Step 2","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Getting the nearest neighbours","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_neighbors(x_test, x_train, num_neighbors):\n    distances = []\n    data = []\n    for i in x_train:\n        distances.append(euclidean_distance(x_test,i))\n        data.append(i)\n    distances = np.array(distances)\n    data = np.array(data)\n    sort_indexes = distances.argsort()             #argsort() function returns indices by sorting distances data in ascending order\n    data = data[sort_indexes]                      #modifying our data based on sorted indices, so that we can get the nearest neightbours\n    return data[:num_neighbors]               ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Step 3","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Predicting the classifier of which our new data point belongs too","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction(x_test, x_train, num_neighbors):\n    classes = []\n    neighbors = get_neighbors(x_test, x_train, num_neighbors)\n    for i in neighbors:\n        classes.append(i[-1])\n    predicted = max(classes, key=classes.count)              #taking the most repeated class\n    return predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def predict_classifier(x_test):\n    classes = []\n    neighbors = get_neighbors(x_test, req_data.values, 5)\n    for i in neighbors:\n        classes.append(i[-1])\n    predicted = max(classes, key=classes.count)\n    print(predicted)\n    return predicted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Measuring the accuracy. So that we can know how accurate our model would predict new data samples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(y_true, y_pred):\n    num_correct = 0\n    for i in range(len(y_true)):\n        if y_true[i]==y_pred[i]:\n            num_correct+=1\n    accuracy = num_correct/len(y_true)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\nfor i in test:\n    y_pred.append(prediction(i, train, 5))\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Evaluating model performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We are getting pretty good accuracy\n* If your are getting low accuracy tune the value of k(nearest neighbours)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.insert(5, 'Predicted_Species', y_pred, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.sample(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}