{"cells":[{"metadata":{},"cell_type":"markdown","source":"----YAPAY ZEKA VERİ ÖN İŞLEME DERSİ----"},{"metadata":{},"cell_type":"markdown","source":"![](http://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSDPogmH0eh6Co1on4XoHu3H_TNFl-ZSRyORg&usqp=CAU)"},{"metadata":{},"cell_type":"markdown","source":"King County, Washington State şehirlerindeki emlak fiyatlarının çeşitli regresyon modelleri ile tahmin edimesi amacı ile paylaşılan bu veri setini kullanarak veri ön işleme yapacağız. "},{"metadata":{},"cell_type":"markdown","source":"Kaggle web sitesi notebook açtığımız zaman aşağıdaki kütüpaneleri hazır olarak vermektedir. Biz kendi bilgisayarımızdaki PyCharm veya Spyder gibi programlar ile çalıştığımızda el ile bu kütüphaneleri yükleriz. Numpy kütüphanesi bizim lineer cebir kütüphanesi dediğimiz matris işlemlerini yapmamıza olanak sağlayan bir kütüphanedir. Pandas kütüphanesi ise veri üzerinde çalışmamıza; okuma, filtreleme, satır sütun seçme gibi işlemleri yapmamıza olanak sağlar. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bu aşamada pandas kütüphanesinin read_csv fonksiyonunu kullanarak veri setimizi bir değişkene atıyoruz."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/kc-house-data/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veri setimizi dataset isimli değişkene başarılı bir şekilde atadık. Şimdi veri setimizi incelemek için baştan 5 satırı yazdırıp inceleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veri setinin kaç satır ve sütundan oluştuğunu incelemek için shape fonksiyonunu kullanıyoruz."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verimiz 21 sütun 21613 satırdan oluşmakta."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"columns fonksiyonu ile veri setinin sütun isimlerini inceleyebiliriz. Veri setimizi içerisinde tahmin etmemiz gereken sütun price, yani fiyat sütunu. Diğer sütunlara baktığımızda veri setimizin oda sayısı, banyo sayısı, evin büyüklüğü, manzara, deniz kenarında olması, yapım yılı, konumu gibi bigileri içerdiğini görebiliyoruz. "},{"metadata":{},"cell_type":"markdown","source":"info() fonksiyonu ile veri seti içerisindeki sütunların tiplerini tespit ediyoruz ve boş, eksik değer olup olmadığına bakıyoruz."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veri setinin içeirsinde boş değer olmadığı açık olduğundan boş değer doldurma ile ilgili bir işlem yapmamıza gerek kalmıyor."},{"metadata":{},"cell_type":"markdown","source":"Veri setini incelediğimizde ilk sütunun id olduğunu, ikinci sütunun ise tarih olduğunu görüyoruz. Tahminleme algoritmasında id değerinin bir önemi olmadığını ve bu sütunu veri seti içerisinden çıkarmamızın doğru bir yaklaşım olacağını söylemek yanlış olmaz. Tarih sütununu da uygun biçimde düzenleyemeyeceğimizden yine veri setimizden çıkaracağız. Yine zipcode değerinin de algoritma için bir anlam ifade etmeyeceğini ve çıkarmamız gerektiğini söyleyebiliriz. Bu problem için tahmin edilmesi gereken değerin \"price\"olduğu açık. Öyle ise artık feature sütunlarımızı ve tahmin edilmesi gereken değerimizi ayırabiliriz.\n"},{"metadata":{},"cell_type":"markdown","source":"Veri setimizde 3. sütundan 15. sütuna kadar olan değerleri ayırıyoruz. Sonra da 17. sütundan 21.sütuna kadar olan değerlerle birleştirerek feature sütunlarımızı  oluşturuyoruz. 16. sütunumuz zipcode. Bu sebeple o sütunu dışarıda bıraktık. Sütunları ayırmak için iloc fonksiyonunu kullanacağız. İki parça olan feature'larımızı birleştirmek için ise numpy kütüphanesinden append fonksiyonunu kullanacağız.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.iloc[:, 3:15].values\nX = np.append(X, dataset.iloc[:,17:21].values, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"iloc fonksiyonunu inceleyecek olursak; köşeli parantez içerisindeki ilk parametre seçmek istediğimiz sayıları, noktalı virgülden sonraki parametreler ise seçmek istediğimiz sütunları temsil etmektedir. Tüm satırları seçmek istiyorsak yukarıdaki gibi noktalı virgülden önce bir şey yazmayız.\n\nMesela 1'den 5'e kadar olan satırları ve 4'ten 9'a kadar olan sütunları seçmek istesek dataset.iloc[1:5:,4:9] şeklinde yazarız.\n\nAppend fonksiyonu ise array tipindeki verilerimizi birleştirmemize yarıyor. append fonksiyonunun içerisine birleştirmek istediğimiz verileri parametre olarak yazarız. axis ise birleştirmenin yatay ya da dikey olarak yapılacağını belirler. Biz burada sütunları birleştireceğimiz için '1' değerini yazarız. Birleştirme alt alta yapılacak olsaydı '0' yazardık. Burada dikkat etmemiz gereken sütunları birleştirirken her iki verimizin de aynı satır sayısına sahip olması. Verileri alt alta birleştirecek olsaydık da verilerin aynı sütun sayısına sahip olması gerekecekti."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dataset.iloc[:, 2].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"price kolonunu da y değişkenine atadık. Bu aşamadan sonra verilerimizi train ve test olarak bölmemiz gerekiyor. Bunun için de sci-kit learn kütüphanesini kullanıyoruz. Sci-kit learn hem veri ön işleme araçlarını hem de çok sayıda makine öğrenme algoritmalarını içermektedir.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = True, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sklearn kütüphanesinin model_selection sınıfı içerisindeki train_test_split fonksiyonu ile verilerimizi eğitim ve test olarak ayırdık. Bunun için fonksiyona parametre olarak X, y değerlerini verdik. Test için verimizin %25'ini ayıracağımızı bildirdik. Verilerin karışık seçilmesi için shuffle=true değerini seçtik. random_state parametresini için de 1 seçerek random veri seçiminin kodu her çalıştırdığımızda değişmemesini sağladık. Her seferinde eğitim ve test için seçilen veriler değişseydi kurduğumuz algoritmanın başarısını ölçmek daha güç olurdu."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}