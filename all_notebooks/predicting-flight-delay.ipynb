{"cells":[{"metadata":{"_uuid":"115fd9c33987ea50036eee371c3fbf27495bd54d"},"cell_type":"markdown","source":"# Flight Delay"},{"metadata":{"_uuid":"fd4330821536a68f6b8e8497bca791ab86009378"},"cell_type":"markdown","source":"### Summary\n\n__I. Reading and Cleaning__\n\n__II. Exploration__\n\n    1.1 Day of The week Bar Chart\n    \n    1.2 Distance Histogram\n    \n    1.3 Histogram of Taxi-Out times\n    \n    1.4 Carrier Delay and reasons\n    \n    1.5 Carrier Cancellations and reasons\n\n__III. Machine Learning__\n\n    1.1 Random Forest Classifier\n    \n    1.2 Gradient Boosting Tree\n    \n    1.3 Logistic Regression and GridSearch\n    \n    1.4 MLPClassifier\n    \n__IV. Cancellation Classification__"},{"metadata":{"_uuid":"47a71d34eabf6cf16cbf4a3a3af3e8dc239c325a"},"cell_type":"markdown","source":"____________________\nThis dataset is composed by the following variables: \n\n1.\t**Year**\t2016\n2.\t**Month**\t1-12\n3.\t**DayofMonth**\t1-31\n4.\t**DayOfWeek**\t1 (Monday) - 7 (Sunday)\n5.\t**DepTime**\tactual departure time (local, hhmm)\n6.\t**CRSDepTime**\tscheduled departure time (local, hhmm)\n7.\t**ArrTime**\tactual arrival time (local, hhmm)\n8.\t**CRSArrTime**\tscheduled arrival time (local, hhmm)\n9.\t**UniqueCarrier**\tunique carrier code\n10.\t**FlightNum**\tflight number\n11.\t**TailNum** plane tail number: aircraft registration, unique aircraft identifier\n12.\t**ActualElapsedTime**\tin minutes\n13.\t**CRSElapsedTime**\tin minutes\n14.\t**AirTime**\tin minutes\n15.\t**ArrDelay**\tarrival delay, in minutes: **A flight is counted as \"on time\" if it operated less than 15 minutes later the scheduled time shown in the carriers' Computerized Reservations Systems (CRS).** \n16.\t**DepDelay**\tdeparture delay, in minutes\n17.\t**Origin**\torigin IATA airport code\n18.\t**Dest**\tdestination IATA airport code\n19.\t**Distance**\tin miles\n20.\t**TaxiIn**\ttaxi in time, in minutes\n21.\t**TaxiOut**\ttaxi out time in minutes\n22.\t**Cancelled**\t*was the flight cancelled\n23.\t**CancellationCode**\treason for cancellation (A = carrier, B = weather, C = NAS, D = security)\n24.\t**Diverted**\t1 = yes, 0 = no\n25.\t**CarrierDelay**\tin minutes: Carrier delay is within the control of the air carrier. Examples of occurrences that may determine carrier delay are: aircraft cleaning, aircraft damage, awaiting the arrival of connecting passengers or crew, baggage, bird strike, cargo loading, catering, computer, outage-carrier equipment, crew legality (pilot or attendant rest), damage by hazardous goods, engineering inspection, fueling, handling disabled passengers, late crew, lavatory servicing, maintenance, oversales, potable water servicing, removal of unruly passenger, slow boarding or seating, stowing carry-on baggage, weight and balance delays.\n26.\t**WeatherDelay**\tin minutes: Weather delay is caused by extreme or hazardous weather conditions that are forecasted or manifest themselves on point of departure, enroute, or on point of arrival.\n27.\t**NASDelay**\tin minutes: Delay that is within the control of the National Airspace System (NAS) may include: non-extreme weather conditions, airport operations, heavy traffic volume, air traffic control, etc. \n28.\t**SecurityDelay**\tin minutes: Security delay is caused by evacuation of a terminal or concourse, re-boarding of aircraft because of security breach, inoperative screening equipment and/or long lines in excess of 29 minutes at screening areas.\n29.\t**LateAircraftDelay**\tin minutes: Arrival delay at an airport due to the late arrival of the same aircraft at a previous airport. The ripple effect of an earlier delay at downstream airports is referred to as delay propagation."},{"metadata":{"_uuid":"bddfaf40f2310def1622628ba4f92028d96a15af"},"cell_type":"markdown","source":"________________\n# I. Reading and Cleaning\n\nFirst we read in the data, do some basic cleaning, and display the first few values to check"},{"metadata":{"trusted":false,"_uuid":"dc61ab2327b587cf0be5b05b3bfb607a0785755a"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.impute import SimpleImputer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c2456710dc3a8af493b05e673b9aaba1ceba0c28"},"cell_type":"code","source":"pd.set_option('display.max_columns',None)\n\nuse_cols = ['YEAR','MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', \n            'DEP_TIME', 'CRS_DEP_TIME', 'ARR_TIME','CRS_ARR_TIME',\n            'UNIQUE_CARRIER','FL_NUM','TAIL_NUM','ACTUAL_ELAPSED_TIME',\n            'CRS_ELAPSED_TIME','AIR_TIME','ARR_DELAY','DEP_DELAY',\n            'ORIGIN','DEST','DISTANCE','TAXI_IN','TAXI_OUT','CANCELLED',\n            'CANCELLATION_CODE','DIVERTED','CARRIER_DELAY',\n            'WEATHER_DELAY','NAS_DELAY','SECURITY_DELAY',\n            'LATE_AIRCRAFT_DELAY'\n]\n\ndf = pd.read_csv('../input/final_data.csv', usecols=use_cols).sample(300000, random_state=44)\ndf = df[df[\"MONTH\"].isin([10,11,12])]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"998cd466e1153984baa10af61b41f3bc97ddbb4d"},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14b0a018d82a2f405306b5a25f965bb823e200ce"},"cell_type":"markdown","source":"__Here we simply select all the rows with cancelled flights and insert them into their own dataframe__"},{"metadata":{"trusted":false,"_uuid":"529cd99f6b4905f5f6179b68cfb2d1a7ad7b2b80"},"cell_type":"code","source":"df['TAXI_OUT'].fillna(0, inplace=True)##### needed for later\n\ncancelled = df[df['CANCELLED']==1]\n\ncancelled.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f08169204f1afe8626fc2fb43e86b7f20a78f23"},"cell_type":"markdown","source":"# II. Exploration\n\n## 1.1 Day of the Week Bar Chart\n\nHere we group both dataframes by the DayOfWeek, and calculate the percentage of cancelled flights for each day of the week and display them in a bar chart"},{"metadata":{"trusted":false,"_uuid":"54d9bc8a5fc8907d8cecc97e44c9aba0e6daf7ff"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfont = {'size'   : 16}\nplt.rc('font', **font)\n\ndays_cancelled = cancelled['CANCELLED'].groupby(df['DAY_OF_WEEK']).count()\ndays_total = df['CANCELLED'].groupby(df['DAY_OF_WEEK']).count()\ndays_frac = np.divide(days_cancelled, days_total)\nx=days_frac.index.values\nweek = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\nfig, ax = plt.subplots(figsize = (12,6))\nax.bar(x,days_frac*100, align='center')\nax.set_ylabel('Percentage of Flights Cancelled')\nax.set_xticks(x)\nax.set_xticklabels(week, rotation = 45)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e88b557165ab080cf4251ef4cc6118191fbd831"},"cell_type":"markdown","source":"This shows that Monday has the lowest percentage of cancelled flights, and Tuesday has the highest, double that of Monday's percentage."},{"metadata":{"trusted":false,"_uuid":"d3c3852ba30bd7cb6c74fdc14f1be5d32c4cad23"},"cell_type":"code","source":"df['CRS_DEP_TIME'].head(10)\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nax.hist([df['CRS_DEP_TIME'], cancelled['CRS_DEP_TIME']], normed=1, bins=20, label=['All', 'Cancelled'])\n\nax.set_xlim(0,2400)\n\nax.set_xlabel('Scheduled Departure Time')\nax.set_title('Normalized histogram of Scheduled Departure Times')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec82a919bdb1b269d87426130eef744aef4a5172"},"cell_type":"markdown","source":"This shows that early morning and late night flights are slightly more likely to be cancelled"},{"metadata":{"trusted":false,"_uuid":"e2ae0e6bb9baf4ff036b786a1ec50f7166dbaacd"},"cell_type":"code","source":"df['DAY_OF_MONTH'].head(10)\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nax.hist([df['DAY_OF_MONTH'], cancelled['DAY_OF_MONTH']], normed=1, bins=31, label=['All', 'Cancelled'])\n\nax.set_xlim(0,31)\n\nax.set_xlabel('Day of Month')\nax.set_title('Normalized histogram of Day of Month')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a59610b24fc1a34f57a873ab781f5301e1169be2"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nax.hist([df['MONTH'], cancelled['MONTH']], normed=1, bins=3, label=['All', 'Cancelled'])\n\nax.set_xlim(10,12)\n\nax.set_xlabel('Month')\nax.set_title('Normalized histogram of Months')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4eafcc71bbf0afa0d608d892bea68b8e0fa1938"},"cell_type":"markdown","source":"We only have three months of data, so the structure here is most likely due to small number statistics"},{"metadata":{"_uuid":"29d941f6238e0bb0a919eb5fc3326669b0c791e9"},"cell_type":"markdown","source":"## 1.2 Distance Histogram\n\nHere we create a normalized histogram of flight distances to compare the differences in the distribution of cancelled vs non-cancelled flights\n\nThis shows us that shorter distance flights are over-represented in the distribution of cancelled flights. In other words, short flights are more likely to be cancelled."},{"metadata":{"trusted":false,"_uuid":"5a00c90fc183fef70b5e5ce50c2864ea1a343b34"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nax.hist([df['DISTANCE'], cancelled['DISTANCE']], normed=1, bins=20, label=['All', 'Cancelled'])\n\nax.set_xlim(0,3000)\nax.set_xlabel('Flight Distance in miles')\nax.set_title('Normalized histogram of Flight Distances')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0caa807a302411030097abf7ea8c788e4a537fc"},"cell_type":"markdown","source":"## 1.3 Histogram of Taxi-Out times\n\nWe can see here that many flights are cancelled before the plane has a chance to taxi-out to the runway."},{"metadata":{"trusted":false,"_uuid":"3985ef3f3aacb89670d7874a8c8b96a745cf21ea"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nax.hist([df['TAXI_OUT'], cancelled['TAXI_OUT']], normed=1, bins=100, label=['All', 'Cancelled'])\n\nax.set_xlim(0,100)\nax.set_xlabel('Taxi-Out Time (minutes)')\nax.set_title('Normalized histogram of Taxi-Out times')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fe59aa7c1c16142018be9a895e2796e432a1eae"},"cell_type":"markdown","source":"Let's make the same plot, but exclude all flights with Taxi-Out times of zero. This shows us that flights that are cancelled after taxiing-out to the runway have longer taxi-out times on average."},{"metadata":{"trusted":false,"_uuid":"4b9f59678e1e6cf92dcec35dcc93c16430d20d4c"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nx = df['TAXI_OUT'][df['TAXI_OUT' ] > 0]\ny = cancelled['TAXI_OUT'][cancelled['TAXI_OUT' ] > 0]\n\nx_mean = np.mean(x)\ny_mean = np.mean(y)\n\nax.hist([x, y], normed=1, bins=100, label=['All', 'Cancelled'])\nax.plot([x_mean, x_mean],[-0.01,0.07],color='#1f77b4')\nax.plot([y_mean, y_mean],[-0.01,0.07],color='#ff7f0e')\n\nax.set_xlim(0,100)\nax.set_xlabel('Taxi-Out Time (minutes)')\nax.set_title('Normalized histogram of Taxi-Out times')\nplt.ylim(0.00,.35)\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72711b84cd6cf31d171b1b0128080b28d6dd1ee6"},"cell_type":"markdown","source":"## 1.4 Carrier Delay and reasons\n\nHere we grouped by the carriers and added up all the delay time reasons to get an idea of average delay times and their reasons for all the different carriers"},{"metadata":{"trusted":false,"_uuid":"0e35ff8ac3b7fbcf6b57c3aa6645ee2ac661d1e4"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf['total_delay'] = (df['CARRIER_DELAY'] + df['WEATHER_DELAY']\n             + df['NAS_DELAY'] + df['SECURITY_DELAY'] + df['LATE_AIRCRAFT_DELAY'])\n\ndf_delayed = df[~np.isnan(df['total_delay'])]\ndf['total_delay'].fillna(0, inplace=True)\ndf_delayed.head()\n\ncarrier_group = df_delayed['CARRIER_DELAY'].groupby(df_delayed['UNIQUE_CARRIER']).mean()\nweather_group = df_delayed['WEATHER_DELAY'].groupby(df_delayed['UNIQUE_CARRIER']).mean()\nnas_group = df_delayed['NAS_DELAY'].groupby(df_delayed['UNIQUE_CARRIER']).mean()\nsecurity_group = df_delayed['SECURITY_DELAY'].groupby(df_delayed['UNIQUE_CARRIER']).mean()\nlate_group = df_delayed['LATE_AIRCRAFT_DELAY'].groupby(df_delayed['UNIQUE_CARRIER']).mean()\n\nw_bottom = carrier_group.values\nn_bottom = w_bottom + weather_group.values\ns_bottom = n_bottom + nas_group.values\nl_bottom = s_bottom + security_group.values\n\nx = carrier_group.index.values\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nax.set_xticks(np.arange(len(x)))\nax.set_xticklabels(x, rotation = 45)\nax.bar(np.arange(len(x)),carrier_group.values, align='center', label='Carrier Delay')\nax.bar(np.arange(len(x)),weather_group.values, align='center', bottom=w_bottom, label='Weather Delay')\nax.bar(np.arange(len(x)),nas_group.values, align='center', bottom=n_bottom, label='NAS Delay')\nax.bar(np.arange(len(x)),security_group.values, align='center', bottom=s_bottom, label='Security Delay')\nax.bar(np.arange(len(x)),late_group.values, align='center', bottom=l_bottom, label='Late Aircraft Delay')\n\nax.set_xlabel('Aircraft Carrier Code')\nax.set_ylabel('Departure Delay in minutes')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01dfb088c6c84490f8bdee4d22b9bce7c79908ff"},"cell_type":"markdown","source":"## 1.5 Carrier Cancellations and reasons\n\nHere we grouped by carrier and cancellation code to see how many cancellations each carrier had and the distributions of the reasons for cancellation. We also plot below the total flights from each carrier for normalization purposes.\n\nWe can see that Hawaiian Airlines had very few cancellation (but also relatively few flights) but also that none of them were due to weather, whichs makes sense because Hawaii usually has good weather."},{"metadata":{"trusted":false,"_uuid":"080d9e9346e88e9e00662386378e5b912322b830"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ncancelled_group = cancelled.groupby(['UNIQUE_CARRIER','CANCELLATION_CODE']).size().reindex(fill_value=0.0).unstack()\ncg = cancelled_group.fillna(0)\n\nb_bottom = cg.loc[:,'A'].values\nc_bottom = b_bottom + cg.loc[:,'B'].values\nd_bottom = c_bottom + cg.loc[:,'B'].values\n\nx = cg.loc[:,'A'].index.values\n\nfig, ax = plt.subplots(figsize = (12,6))\n\nax.set_xticks(np.arange(len(x)))\nax.set_xticklabels(x, rotation = 45)\nax.bar(np.arange(len(x)),cg.loc[:,'A'].values, align='center', label='Carrier')\nax.bar(np.arange(len(x)),cg.loc[:,'B'].values, align='center', bottom=b_bottom, label='Weather')\nax.bar(np.arange(len(x)),cg.loc[:,'C'].values, align='center', bottom=c_bottom, label='NAS')\n#ax.bar(np.arange(len(x)),cancelled_group.loc[:,'D'].values, align='center', bottom=d_bottom, label='Security')\n\nax.set_xlabel('Aircraft Carrier Code')\nax.set_ylabel('Number of Cancellations')\n\nplt.legend()\nplt.show()\n\ntotal_flights_per_carrier = df['UNIQUE_CARRIER'].groupby(df['UNIQUE_CARRIER']).count()\n\nfig, ax1 = plt.subplots(figsize = (12,6))\n\nx = total_flights_per_carrier.index.values\n\nax1.set_xticks(np.arange(len(x)))\nax1.set_xticklabels(x, rotation = 45)\nax1.bar(np.arange(len(x)),total_flights_per_carrier.values, align='center')\n\nax1.set_xlabel('Aircraft Carrier Code')\nax1.set_ylabel('Total Number of Flights')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ee8fd9cd9711679bd65b26a4003154028c5a720"},"cell_type":"markdown","source":"Here we show a summary table for the carriers showing several totals and averages\n\nThe point of this table is just to help us get a better sense of our data"},{"metadata":{"trusted":false,"_uuid":"e5183ef42dd3a97254562b459f05078fe9f0ff58"},"cell_type":"code","source":"carrier_flights = df['UNIQUE_CARRIER'].groupby(df['UNIQUE_CARRIER']).count()\ncarrier_cancelled = df['CANCELLED'].groupby(df['UNIQUE_CARRIER']).sum()\ncarrier_delayed = df_delayed['UNIQUE_CARRIER'].groupby(df_delayed['UNIQUE_CARRIER']).count()\ncarrier_diverted = df['DIVERTED'].groupby(df['UNIQUE_CARRIER']).sum()\ncarrier_avg_time = df['AIR_TIME'].groupby(df['UNIQUE_CARRIER']).mean()\ncarrier_avg_dist = df['DISTANCE'].groupby(df['UNIQUE_CARRIER']).mean()\ncarrier_avg_delay = df['total_delay'].groupby(df['UNIQUE_CARRIER']).mean()\ncarrier_avg_taxiIn = df['TAXI_IN'].groupby(df['UNIQUE_CARRIER']).mean()\ncarrier_avg_taxiOut = df['TAXI_OUT'].groupby(df['UNIQUE_CARRIER']).mean()\ncarrier_pct_cancelled = 100*np.divide(carrier_cancelled, carrier_flights)\n\ncarrier_names = pd.Series(['American Airlines','Alaska Airlines','JetBlue Airways',\n                          'Delta Airlines','Atlantic Southeast Airlines','Frontier Airlines',\n                          'Hawaiian Airlines','Northwest Airlines','Skywest Airlines','United Airlines',\n                          'Mesa Airlines','Southwest Airlines'], index=carrier_flights.index)\n# carrier_names = pd.Series(['Pinnacle Airlines', 'American Airlines', 'Alaska Airlines', 'Jetblue Airways',\n#                       'Cobaltair', 'Delta Air Lines', 'ExpressJet Airlines', 'Frontier Airlines', 'AirTran Airways',\n#                       'Hawaiian Airlines', 'Envoy Air', 'Northwest Airlines', 'US Airways Express', \n#                       'SkyWest Airlines', 'United Airlines', 'US Airways', 'Southwest Airlines',\n#                       'JetSuiteX Air', 'Mesa Airlines'], index=carrier_flights.index)\n\nsummary_table_carrier = pd.concat([carrier_names, carrier_flights, carrier_cancelled, carrier_pct_cancelled, \n                                   carrier_diverted, \n                           carrier_avg_time, carrier_avg_dist, carrier_avg_delay,\n                          carrier_avg_taxiIn, carrier_avg_taxiOut], axis=1)\n\nsummary_table_carrier.columns = ['Carrier Name', 'Total Flights', 'Cancelled Flights', 'Percent Cancelled',\n                         'Diverted Flights', 'Average Flight Time (minutes)',\n                         'Average Flight Distance (miles)', 'Average Flight Delay (minutes)', \n                         'Average Taxi-In (minutes)', 'Average Taxi-Out (minutes)']\n\n\n\nsummary_table_carrier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d760549b5edcabbf65489b42f8516f7c53793202"},"cell_type":"code","source":"#plt.matshow(summary_table_carrier.corr())\ndef plot_corr(df,size=10):\n    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n\n    Input:\n        df: pandas DataFrame\n        size: vertical and horizontal size of the plot'''\n\n    corr = df.corr()\n    fig, ax = plt.subplots(figsize=(size, size))\n    ax.matshow(corr)\n    #plt.xticks(range(len(corr.columns)), corr.columns);\n    plt.yticks(range(len(corr.columns)), corr.columns);\n    \nplot_corr(summary_table_carrier)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"82115b5fdc4b1d83589eee0d89fe9aaf21331e9e"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\nfig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\n\n\nax1.scatter(carrier_avg_taxiOut, carrier_avg_delay)\nX = carrier_avg_taxiOut.values.reshape(-1,1)\nlinreg = LinearRegression().fit(X, carrier_avg_delay)\nax1.plot(carrier_avg_taxiOut, linreg.coef_ * carrier_avg_taxiOut + linreg.intercept_, 'r-')\nax1.text(14,12,'R-squared score: {:.3f}'\n     .format(linreg.score(X, carrier_avg_delay)))\nax1.set_xlabel('Average Taxi-Out (minutes)')\nax1.set_ylabel('Average Flight Delay (minutes)')\n\n####################################################################################\n\nax2.scatter(carrier_avg_dist, carrier_avg_delay)\nX = carrier_avg_dist.values.reshape(-1,1)\nlinreg = LinearRegression().fit(X, carrier_avg_delay)\nax2.plot(carrier_avg_dist, linreg.coef_ * carrier_avg_dist + linreg.intercept_, 'r-')\nax2.text(900,12,'R-squared score: {:.3f}'\n     .format(linreg.score(X, carrier_avg_delay)))\nax2.set_xlabel('Average Flight Distance (miles)')\nax2.set_ylabel('Average Flight Delay (minutes)')\n\n####################################################################################\n\nX = summary_table_carrier['Average Flight Delay (minutes)']\ny = summary_table_carrier['Percent Cancelled']\nax3.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax3.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax3.text(10,0.5,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax3.set_xlabel('Average Flight Delay (minutes)')\nax3.set_ylabel('Percent Cancelled')\n\n####################################################################################\n\nX = summary_table_carrier['Average Taxi-Out (minutes)']\ny = summary_table_carrier['Percent Cancelled']\nax4.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax4.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax4.text(12,0.45,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax4.set_xlabel('Average Taxi-Out (minutes)')\nax4.set_ylabel('Percent Cancelled')\n\n####################################################################################\n\nX = summary_table_carrier['Average Flight Time (minutes)']\ny = summary_table_carrier['Percent Cancelled']\nax5.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax5.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax5.text(80,0.45,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax5.set_xlabel('Average Flight Time (minutes)')\nax5.set_ylabel('Percent Cancelled')\n\nfig.subplots_adjust(hspace=0.2, wspace=0.3)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"827761db45fdb999c29c41ff9cad95fef9082752"},"cell_type":"markdown","source":"This shows that the average flight delay is positively correlated with the average taxi-out time, and that the percent of flights cancelled is negatively correlated with average flight times, when averages are calculated across carriers. None of these correlations are particularly strong, however."},{"metadata":{"_uuid":"d3f2f35c808e267aba0423d5f0c4c9b5678c3063"},"cell_type":"markdown","source":"Now lets group by Origin city, of which there are many more than unique carries, so we may be able to see more intricate aspects of the data."},{"metadata":{"trusted":false,"_uuid":"a63dd55c2177abbfd5fa9c00b7cc4ec42643cd75"},"cell_type":"code","source":"origin_flights = df['ORIGIN'].groupby(df['ORIGIN']).count()\norigin_cancelled = df['CANCELLED'].groupby(df['ORIGIN']).sum()\norigin_delayed = df_delayed['UNIQUE_CARRIER'].groupby(df_delayed['ORIGIN']).count()\norigin_diverted = df['DIVERTED'].groupby(df['ORIGIN']).sum()\norigin_avg_time = df['AIR_TIME'].groupby(df['ORIGIN']).mean()\norigin_avg_dist = df['DISTANCE'].groupby(df['ORIGIN']).mean()\norigin_avg_delay = df['total_delay'].groupby(df['ORIGIN']).mean()\n#origin_avg_taxiIn = df['TaxiIn'].groupby(df['Origin']).mean()\norigin_avg_taxiOut = df['TAXI_OUT'].groupby(df['ORIGIN']).mean()\norigin_pct_cancelled = 100*np.divide(origin_cancelled, origin_flights)\n\nsummary_table_origin = pd.concat([origin_flights, origin_cancelled, origin_pct_cancelled, origin_diverted, \n                           origin_avg_time, origin_avg_dist, origin_avg_delay,\n                           origin_avg_taxiOut], axis=1)\n\nsummary_table_origin.columns = ['Total Flights', 'Cancelled Flights', 'Percent Cancelled',\n                         'Diverted Flights', 'Average Flight Time (minutes)',\n                         'Average Flight Distance (miles)', 'Average Flight Delay (minutes)', \n                         'Average Taxi-Out (minutes)']\n\nsummary_table_origin = summary_table_origin.sort_values('Total Flights', ascending=False)\nsummary_table_origin.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dfcad6329a0d3769d011719d2488f209cf66ce5a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\ndf1 = summary_table_origin[summary_table_origin['Total Flights']>1000]\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 20))\n\nX = df1['Average Taxi-Out (minutes)']\ny = df1['Average Flight Delay (minutes)']\nax1.scatter(X, y)\n\nX = X.values.reshape(-1,1)\ny = y.values.reshape(1,-1)\n\nfrom sklearn.preprocessing import Imputer\ny_imputer = Imputer(axis=1)\n\ny_imputed = y_imputer.fit_transform(y)\ny_imputed = y_imputed[0]\n\nlinreg = LinearRegression().fit(X, y_imputed)\nax1.plot(origin_avg_taxiOut, linreg.coef_ * origin_avg_taxiOut + linreg.intercept_, 'r-')\nax1.text(20,10,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y_imputed)))\nax1.set_xlabel('Average Taxi-Out (minutes)')\nax1.set_ylabel('Average Flight Delay (minutes)')\n\n####################################################################################\n\nX = df1['Average Flight Distance (miles)']\ny = df1['Average Flight Delay (minutes)']\nax2.scatter(X, y)\n\nX = X.values.reshape(-1,1)\ny = y.values.reshape(1,-1)\n\nlinreg = LinearRegression().fit(X, y_imputed)\nax2.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax2.text(1100,10,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y_imputed)))\nax2.set_xlabel('Average Flight Distance (miles)')\nax2.set_ylabel('Average Flight Delay (minutes)')\n\n####################################################################################\n\nX = df1['Average Flight Delay (minutes)']\ny = df1['Percent Cancelled']\nax3.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax3.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax3.text(12,0.4,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax3.set_xlabel('Average Flight Delay (minutes)')\nax3.set_ylabel('Percent Cancelled')\n\n####################################################################################\n\nX = df1['Average Taxi-Out (minutes)']\ny = df1['Percent Cancelled']\nax4.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax4.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax4.text(20,0.45,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax4.set_xlabel('Average Taxi-Out (minutes)')\nax4.set_ylabel('Percent Cancelled')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7329a46f8f28964affe07635a886c9a3a83f0801"},"cell_type":"markdown","source":"Now we can do the same thing but grouping by destination instead of origin to see if we can  find anything interesting."},{"metadata":{"trusted":false,"_uuid":"97ccac31aedd82835d633c03bcdf99dfe8af2416"},"cell_type":"code","source":"dest_flights = df['DEST'].groupby(df['DEST']).count()\ndest_cancelled = df['CANCELLED'].groupby(df['DEST']).sum()\ndest_delayed = df_delayed['UNIQUE_CARRIER'].groupby(df_delayed['DEST']).count()\ndest_diverted = df['DIVERTED'].groupby(df['DEST']).sum()\ndest_avg_time = df['AIR_TIME'].groupby(df['DEST']).mean()\ndest_avg_dist = df['DISTANCE'].groupby(df['DEST']).mean()\ndest_avg_delay = df['total_delay'].groupby(df['DEST']).mean()\ndest_avg_taxiIn = df['TAXI_IN'].groupby(df['DEST']).mean()\n#dest_avg_taxiOut = df['TaxiOut'].groupby(df['Dest']).mean()\ndest_pct_cancelled = 100*np.divide(dest_cancelled, dest_flights)\n\nsummary_table_dest = pd.concat([dest_flights, dest_cancelled, dest_pct_cancelled, dest_diverted, \n                           dest_avg_time, dest_avg_dist, dest_avg_delay,\n                           dest_avg_taxiIn], axis=1)\n\nsummary_table_dest.columns = ['Total Flights', 'Cancelled Flights', 'Percent Cancelled',\n                         'Diverted Flights', 'Average Flight Time (minutes)',\n                         'Average Flight Distance (miles)', 'Average Flight Delay (minutes)', \n                         'Average Taxi-In (minutes)']\n\nsummary_table_dest = summary_table_dest.sort_values('Total Flights', ascending=False)\nsummary_table_dest.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"62ca7e0d37d02a2013fb92ac2a5902ff0025e37d"},"cell_type":"code","source":"df2 = summary_table_dest[summary_table_dest['Total Flights']>1000]\n\nplot_corr(df2)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a5f5c8415d370a2969862917d70be07163319467"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n#df2 = summary_table_dest[summary_table_dest['Cancelled Flights']>1]\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 20))\n\nX = df2['Average Taxi-In (minutes)']\ny = df2['Average Flight Delay (minutes)']\nax1.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax1.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax1.text(10,10,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax1.set_xlabel('Average Taxi-In (minutes)')\nax1.set_ylabel('Average Flight Delay (minutes)')\n\n####################################################################################\n\nX = df2['Average Flight Delay (minutes)']\ny = df2['Percent Cancelled']\nax2.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax2.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax2.text(15,0.4,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax2.set_xlabel('Average Flight Delay (minutes)')\nax2.set_ylabel('Percent Cancelled')\n\n####################################################################################\n\nX = df2['Average Flight Distance (miles)']\ny = df2['Percent Cancelled']\nax3.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax3.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax3.text(600,0.4,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax3.set_xlabel('Average Flight Distance (miles)')\nax3.set_ylabel('Percent Cancelled')\n\n####################################################################################\n\nX = df2['Average Taxi-In (minutes)']\ny = df2['Percent Cancelled']\nax4.scatter(X, y)\n\nX = X.values.reshape(-1,1)\n\nlinreg = LinearRegression().fit(X, y)\nax4.plot(X, linreg.coef_ * X + linreg.intercept_, 'r-')\nax4.text(4,0.4,'R-squared score: {:.3f}'\n     .format(linreg.score(X, y)))\nax4.set_xlabel('Average Taxi-In (minutes)')\nax4.set_ylabel('Percent Cancelled')\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32565fd428bdd15a331346b20b64dd133d8f38d1"},"cell_type":"markdown","source":"This shows that average flight delays and taxi times are more correlated with cancellations when grouped by carriers rather than origin or destination airports"},{"metadata":{"_uuid":"22dfbedc53f69fbefc04a285362fe4e7df1b4a4e"},"cell_type":"markdown","source":"# III. Machine learning:\n\nSince carrier mean delay seemed to be correlated to cancellations when grouped by carrier, we add the average carrier delay as a column to the main dataset, and we will use this as a feature rather than the carrier column"},{"metadata":{"trusted":false,"_uuid":"a65e9d84e2dd7feb51b6b2a40f1429629ae5a2f9"},"cell_type":"code","source":"df['Carrier mean delay'] = df['total_delay'].groupby(df['UNIQUE_CARRIER']).transform('mean')\ndf['Carrier mean distance'] = df['DISTANCE'].groupby(df['UNIQUE_CARRIER']).transform('mean')\ndf['Carrier cancellations'] = df['CANCELLED'].groupby(df['UNIQUE_CARRIER']).transform('mean')\ndf['Origin cancellations'] = df['CANCELLED'].groupby(df['ORIGIN']).transform('mean')\ndf['Dest cancellations'] = df['CANCELLED'].groupby(df['DEST']).transform('mean')\n\ndf['Origin TaxiOut'] = df['TAXI_OUT'].groupby(df['ORIGIN']).transform('mean')\ndf['Origin Delay'] = df['total_delay'].groupby(df['ORIGIN']).transform('mean')\n\ndf['ORIGIN'] = df['ORIGIN'].astype('category').cat.codes\ndf['DEST'] = df['DEST'].astype('category').cat.codes\ndf['CANCELLATION_CODE'] = df['CANCELLATION_CODE'].astype('category').cat.codes\ndf.fillna(0, inplace=True)\n\n#print(len(df))\n\n# X = df[['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'Origin', 'Dest', 'Distance', 'Carrier mean distance',\n#         'total_delay', 'TaxiOut']]\n# X = df[['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'Origin', 'Dest', 'Distance', 'Carrier mean distance',\n#        'Carrier cancellations', 'Origin cancellations', 'Dest cancellations']]\n# X = df[['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime']]\nX = df[['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_DEP_TIME', 'ORIGIN', 'DEST', 'DISTANCE', 'Carrier mean distance',\n        'Origin Delay', 'Origin TaxiOut']]\ny = df['CANCELLED']\n\n\n# The code below was used for intermediate parameter searches as the full set was too big \n# and took too long to train each set of parameters\n\n# df1 = df.sample(n=50000, random_state = 47)\n# X = df1[['Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', 'Origin', 'Dest', 'Distance', 'Carrier mean distance',\n#         'Origin Delay', 'Origin TaxiOut']]\n# y = df1['Cancelled']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"76ae71eb698571bf82d3d8112eb7d2769e911f26"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n# we must apply the scaling to the test set that we computed for the training set\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eb87ef64a89653ef417f7fc43a81e19f5b9c7fa"},"cell_type":"markdown","source":"## 1.1 Random Forest Classifier"},{"metadata":{"trusted":false,"_uuid":"6e00f8d7bb0f278f25c212332af0b536cc29846c"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\nclf = RandomForestClassifier(n_estimators=50, random_state=47).fit(X_train, y_train)\n\n# sum(y_test)\n# clf.score(X_test, y_test)\n\ny_predicted = clf.predict(X_test)\nconfusion = confusion_matrix(y_test, y_predicted)\n#confusion\n#sum(y_predicted)\n\nprint('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\nprint('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\nprint('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\nprint('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\nconfusion = confusion_matrix(y_test, y_predicted)\nprint(confusion)\nprint('Feature importances: {}'.format(clf.feature_importances_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4371e3f822ffbffb8e3eacb907a249f541bd94f5"},"cell_type":"markdown","source":"### 1.2 Gradient Boosting Tree."},{"metadata":{"trusted":false,"_uuid":"9dd7a6f8c753991ef0eb4d2c07ef8672eb18f90b"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nclf = GradientBoostingClassifier(n_estimators=300, learning_rate = 0.003, \n                                 max_depth = 2, random_state=37).fit(X_train, y_train)\n\ny_predicted = clf.predict(X_test)\nconfusion = confusion_matrix(y_test, y_predicted)\n\nprint('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\nprint('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\nprint('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\nprint('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\nconfusion = confusion_matrix(y_test, y_predicted)\nprint(confusion)\nprint('Feature importances: {}'.format(clf.feature_importances_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef26f1d56d76ad402a1b4efa1b25750c0d0ea903"},"cell_type":"markdown","source":"With the given data, the decision tree algorithms were unable to correctly predict any cancelled flights\n\nNow let's try a grid search in Support Vector classifiers."},{"metadata":{"trusted":false,"_uuid":"eb13de255b0ba4d9e4fbe76a6df02cb8351069b1"},"cell_type":"code","source":"# np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n# from sklearn.svm import SVC\n# from sklearn.model_selection import GridSearchCV\n\n# clf = SVC(kernel='rbf')\n# #grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100], 'C': [0.01, 0.1, 1, 10, 100]}\n# #grid_values = {'gamma': [0.1, 1, 10, 100], 'C': [100, 300, 1000, 3000]}\n# grid_values = {'gamma': [3, 6, 10], 'C': [100, 300, 1000, 3000]}\n\n# grid_clf = GridSearchCV(clf, param_grid = grid_values, scoring = 'recall')\n# grid_clf.fit(X_train_scaled, y_train)\n# grid_clf.cv_results_['mean_test_score'].reshape(4,3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39372a6918d864761f9d72b61a9d73a7b768ccbb"},"cell_type":"markdown","source":"The grid search was first performed using samples of the full dataset with only 50,000 rows, then when I found the right set of parameters I did the grid search using the full dataset. This takes several hours on my macbook, so I've commented it out here, but the best parameters for the support classifier are gamma$\\approx6$, C$\\approx1000$"},{"metadata":{"trusted":false,"_uuid":"eaf0c53204b74652729a54f14240a4393acee95f"},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nnp.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n\nsvm = SVC(kernel='rbf', C=1000, gamma=6, random_state=47).fit(X_train_scaled, y_train)\ny_pred = svm.predict(X_test_scaled)\n\nprint('Recall: {:.3f}'.format(recall_score(y_test, y_pred)))\nprint('Precision: {:.3f}'.format(precision_score(y_test, y_pred)))\nprint('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\nprint('F1: {:.3f}'.format(f1_score(y_test, y_pred)))\nconfusion = confusion_matrix(y_test, y_pred)\nprint(confusion)\n\ny_scores = svm.decision_function(X_test_scaled)\ny_score_list = list(zip(y_test[0:20], y_scores[0:20]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1545c243d6fa3aaf8896a1a3adf05c719705dcbf"},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, roc_curve, auc\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_scores)\nclosest_zero = np.argmin(np.abs(thresholds))\nclosest_zero_p = precision[closest_zero]\nclosest_zero_r = recall[closest_zero]\n\nfig, ax1= plt.subplots(figsize=(8,8))\n#plt.figure(figsize=(8,8))\nax1.plot(precision, recall, label='Precision-Recall Curve')\nax1.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\nax1.set_xlabel('Precision', fontsize=16)\nax1.set_ylabel('Recall', fontsize=16)\nax1.set_aspect('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c536f6cc84252ffccb5dfb79c68d75aebfe8fc9a"},"cell_type":"code","source":"fpr, tpr, _ = roc_curve(y_test, y_scores)\nroc_auc = auc(fpr, tpr)\nprint('AUC: {:.3f}'.format(roc_auc))\n\nfig, ax1= plt.subplots(figsize=(8,8))\n#plt.figure(figsize=(8,8))\nax1.set_xlim([-0.01, 1.00])\nax1.set_ylim([-0.01, 1.01])\nax1.plot(fpr, tpr, lw=3, label='SVC ROC curve (area = {:0.2f})'.format(roc_auc))\nax1.set_xlabel('False Positive Rate', fontsize=16)\nax1.set_ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curve', fontsize=16)\nplt.legend(loc='lower right', fontsize=13)\nax1.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\nax1.set_aspect('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0aa62fe7b6f9c5d59dc526165ca3ea58b14d5f3b"},"cell_type":"markdown","source":"### 1.3 Logistic regression and gridsearch"},{"metadata":{"trusted":false,"_uuid":"c796bfe10b36a2b1d5325601b8dafd57e88f8016"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nnp.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n\nlr = LogisticRegression()\ngrid_values = {'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\ngrid_lr = GridSearchCV(lr, param_grid = grid_values, scoring = 'recall').fit(X_train_scaled, y_train)\nprint(grid_lr.cv_results_['mean_test_score'].reshape(9,2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a046a08665275ecf225c1791e50e0a245c0a91c1"},"cell_type":"markdown","source":"### 1.4 Finally, let's try a neural network approach."},{"metadata":{"trusted":false,"_uuid":"59e5527fb03aea6b10d42cb945ccdd421ff25cd6"},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nnnclf = MLPClassifier(hidden_layer_sizes = [5,5], solver='adam', alpha=0.0003, activation='relu',\n                     max_iter = 100, random_state = 47).fit(X_train_scaled, y_train)\n\ny_predicted = nnclf.predict(X_test_scaled)\nconfusion = confusion_matrix(y_test, y_predicted)\n\nprint('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\nprint('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\nprint('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\nprint('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\nconfusion = confusion_matrix(y_test, y_predicted)\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"211067fcecc8dd9cf39805579ade6205987cf29e"},"cell_type":"markdown","source":"# IV. Cancellation Classification summary:\n\nUnsurprisingly, all of the machine learning algorithms presented here did a poor job predicting cancelled flights. Only the support vector classifier was able to correctly predict any cancelled flights, but only about 2% of them. If airlines do employ machine learning models to predict cancellations, they are most likely more sophisticated and include all sorts of data that we don't have access to here. Namely, current weather and aircraft/airport maintenance data. It makes sense that if you didn't need that current data to predict cancellations, there would be a lot fewer last-minute cancellations.\n\n\nNow let's see how well we can predict the delay times of flights (regression):"},{"metadata":{"trusted":false,"_uuid":"0464254f376020579965749fc1f4d1756407a0a1"},"cell_type":"code","source":"df['Dest mean taxiIn'] = df['TAXI_IN'].groupby(df['DEST']).transform('mean')\ndf['Origin mean taxiOut'] = df['TAXI_IN'].groupby(df['DEST']).transform('mean')\n\nX = df[['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_DEP_TIME', 'DISTANCE', 'Carrier mean distance',\n       'Dest mean taxiIn', 'Origin mean taxiOut']]\n\ny = df['total_delay']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c7e9b06c5335bdaa3cf7994f20bb841877239e07"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d4c851a14e43ade4ca2397e0f46d2493dc5cd01"},"cell_type":"markdown","source":"Here we'll try to use polynomials of our features to fit a linear regression model that attempts to predict delay times."},{"metadata":{"trusted":false,"_uuid":"1e16bebe615ffc93633774ca656c88285bd4e118"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=5)\nX_train_scaled_poly = poly.fit_transform(X_train_scaled)\n\nX_test_scaled = scaler.transform(X_test)\nX_test_scaled_poly = poly.transform(X_test_scaled)\n\nlinreg = Ridge(alpha=1.0).fit(X_train_scaled_poly, y_train)\n\nprint('(poly deg 5 + ridge) R-squared score (training): {:.3f}'\n     .format(linreg.score(X_train_scaled_poly, y_train)))\nprint('(poly deg 5 + ridge) R-squared score (test): {:.3f}'\n     .format(linreg.score(X_test_scaled_poly, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12a9df375edb5a24a74c0dac64d38f37ddd67b50"},"cell_type":"markdown","source":"I found that a 5th degree polynomial of the features worked best, but not that great"},{"metadata":{"trusted":false,"_uuid":"066e09250a98c56a13c599e2dfe3ade6f03e221e"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\nknnreg = KNeighborsRegressor(n_neighbors = 31, algorithm='auto').fit(X_train_scaled, y_train)\n\nprint('R-squared test score: {:.3f}'\n     .format(knnreg.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6b5956887ed64f47f2d03d17bfe5ae1b26748191"},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\nmlpreg = MLPRegressor(hidden_layer_sizes = [50,50,50],\n                             activation = 'relu',\n                             alpha = 0.0003,   #0.0003,\n                             solver = 'lbfgs').fit(X_train_scaled, y_train)\n\nprint('R-squared test score: {:.3f}'\n     .format(mlpreg.score(X_test_scaled, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb30892b4dfdbaf31a3dbbcaf321eb8301b0ca4a"},"cell_type":"markdown","source":"# Delay Time Regression Summary:\n\nThe features used for predicting delay times did not use data that could not be know days/weeks in advance of the flights. However, the argument could be made that the averaged features include __future__ data from the perspective of many of the flights. I don't think this introduces any significant concerns of __data leakage__, as there is no reason to expect these averages to be changing significantly with time. Furthermore, any __production ready__ models could be engineered to avoid this problem and only use averages of flights before the one being predicted.\n\nEven so, the models did not do a great job predicting flight delay times. The KNN regressor did the best job with and R-squared score of 0.025, while both the linear regressor (with Ridge regularization and 5th degree polynomial features) and the neural network (with 3 hidden layers each of size 150) had R-squared scores of 0.034 and 0.043. Similarly to the cancellation prediction models, these could be augmented with real-time data about current weather and aircraft/airport maintenance data to give much more accurate results."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}