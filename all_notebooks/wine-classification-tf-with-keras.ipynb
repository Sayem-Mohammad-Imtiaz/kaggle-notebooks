{"cells":[{"metadata":{},"cell_type":"markdown","source":"Carlo Antonio T. Taleon BSCS-2A | 2020-2021 | Written January 2021\n\n# **Wine Classification using Tensorflow with Keras**\n- This is my final project for the 1st semester of Introduction to Artificial Intelligence class at WVSU-CICT.\n- It's also the first notebook I'm writing on Kaggle. :)\n- This project classifies Wine using the [Wine Data Set on UCI](https://archive.ics.uci.edu/ml/datasets/wine)."},{"metadata":{},"cell_type":"markdown","source":"## **1. Import modules**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **2. Data Preparation**\n### Import data and adding headers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/wineuci/Wine.csv')\n\ndf.columns = [  'name',\n                'alcohol',\n             \t'malicAcid',\n             \t'ash',\n            \t'ashalcalinity',\n             \t'magnesium',\n            \t'totalPhenols',\n             \t'flavanoids',\n             \t'nonFlavanoidPhenols',\n             \t'proanthocyanins',\n            \t'colorIntensity',\n             \t'hue',\n             \t'od280_od315',\n             \t'proline'\n                ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining features and labels"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"X = df.drop(['name','alcohol'],axis=1)\ny = df['name'] - 1 # shifted y to range 0 to 1\nlabels = ['Wine 1', 'Wine 2', 'Wine 3'] # dataset does not supply the names of the labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting X and y and defining input shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=1) # random_state=1 for same results every time.\ninput_shape = [X_train.shape[1]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3. The Model**\n### Defining and compiling the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    # input layer\n    layers.BatchNormalization(input_shape=input_shape),\n    # hidden layer 1\n    layers.Dense(units=256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    # hidden layer 2\n    layers.Dense(units=128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    # hidden layer 3\n    layers.Dense(units=64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    # hidden layer 4\n    layers.Dense(units=32, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(rate=0.4),\n    layers.Dense(units=3, activation='softmax')\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **4. Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=512,\n    epochs=700,\n)\nprint(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5. Evaluation of Model's Performance**\n### Results of Training\nLearning Curve showing Loss and Accuracy during training."},{"metadata":{"trusted":true},"cell_type":"code","source":"### Loss Graph\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Learning Curve: Loss over Epochs\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Training Loss', 'Validation Loss'])\n\n### Accuracy Graph\nhistory_df.loc[:, ['accuracy', 'val_accuracy']].plot(title=\"Learning Curve: Accuracy over Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend(['Training Accuracy', 'Validation Accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results of Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_actual = y_train.to_numpy()\ny_pred = model.predict(X_train, verbose=0)\ny_pred = np.argmax(y_pred, axis=-1)\n\nprint(\"On {} samples of untrained(test) dataset:\".format(len(y_pred)))\nprint(\"Prediction:\")\nprint(y_pred)\nprint(\"Actual:\")\nprint(y_actual)\n\n### Classification Report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_actual,y_pred, target_names=labels))\n\n### Confusion Matrix Graph\ncm = confusion_matrix(y_true=y_actual, y_pred=y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()\nplt.title('Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### My Evaluation:\n\n- I tweaked the neural network through trial and error to consistently get low loss values for both the training and validation data for training.\n- I also made sure that the accuracy for both the training and validation data are above 0.9\n- Specifically, I increased the dropout rate and added batch normalization to try and reduce overfitting. I learned this from the Deep Learning course here on Kaggle.\n- Although the learning curve for loss and accuracy show that there are signs of overfitting as the training data does better than the validation data, it's miniscule enough to not affect the precision of the model."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}