{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom wordcloud import WordCloud\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_plot(col, n_keys=None, d=None):\n    \n    if d is None:\n        d = Counter(df[col].dropna())\n    d = {k: v for k, v in sorted(d.items(), key=lambda item: -item[1])}\n    plt.figure(figsize=(20,4))\n    plt.ylabel('Frequency')\n    plt.xlabel(col.capitalize())\n    \n    if n_keys is None:\n        keys = list(d.keys())\n        values = list(d.values())\n    else:\n        keys = list(d.keys())[:n_keys]\n        values = list(d.values())[:n_keys]\n        keys.append('other')\n        values.append(sum(list(d.values())[n_keys:]))\n\n    plt.bar(keys, values, width=0.8)\n    return None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/coronanews/clean_news.csv')\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How many articles do we have from each news source?"},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot('source')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### When were the articles published?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot('publish_date', n_keys=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How long are the articles?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_length(text):\n    try:\n        return len(text.split(' '))\n    except AttributeError:\n        return 0\n\narticle_lengths = df['text'].apply(lambda x: calculate_length(x))\nplt.figure(figsize=(20,4))\nplt.xlabel('Article lengths')\nplt.ylabel('Frequency')\nax = plt.hist(article_lengths, bins=25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What are the common terms in the articles?"},{"metadata":{"trusted":true},"cell_type":"code","source":"text = ' '.join(list(df['text'].dropna()))\nbad_words = {'Getty Images', 'Getty', 'AFP', 'via', 'could', 'would', 'also', 'said'}\nstop_words = set(stopwords.words('english')) | bad_words\n\nwordcloud = WordCloud(stopwords=stop_words).generate(text)\nplt.figure(figsize=(16, 8))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}