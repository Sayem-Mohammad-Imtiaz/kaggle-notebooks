{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introducción\n\nMétodo para clasificar las enfermedades respiratorias mediante una red neuronal convolucional."},{"metadata":{"id":"BbVepFu3S32R","trusted":true},"cell_type":"code","source":"from os import listdir\nfrom os.path import isfile, join\n\nimport pandas as pd\nimport librosa\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras import regularizers, optimizers\nfrom tensorflow.keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling1D, Dropout\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.utils import plot_model,to_categorical\nimport seaborn as sn\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Navegando el conjunto de datos"},{"metadata":{"id":"Q1bkcmLQ_6dZ","trusted":true},"cell_type":"code","source":"class Diagnosis():\n  def __init__ (self, id, diagnosis, image_path):\n    self.id = id\n    self.diagnosis = diagnosis \n    self.image_path = image_path   ","execution_count":null,"outputs":[]},{"metadata":{"id":"XEw8uPp301Nr","trusted":true},"cell_type":"code","source":"def get_wav_files():\n  audio_path = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\n  files = [f for f in listdir(audio_path) if isfile(join(audio_path, f))]  # Gets all files in dir\n  wav_files = [f for f in files if f.endswith('.wav')]  # Gets wav files \n  wav_files = sorted(wav_files)\n  return wav_files, audio_path","execution_count":null,"outputs":[]},{"metadata":{"id":"wRqqAOFZdz4r","trusted":true},"cell_type":"code","source":"def diagnosis_data():\n  diagnosis = pd.read_csv('../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv')\n  \n  wav_files, audio_path = get_wav_files()\n  diag_dict = { 101 : \"URTI\"}  \n  diagnosis_list = []\n  \n  for index , row in diagnosis.iterrows():\n    diag_dict[row[0]] = row[1]     \n\n  c = 0\n  for f in wav_files:\n    diagnosis_list.append(Diagnosis(c, diag_dict[int(f[:3])], audio_path+f))  \n    c+=1  \n\n  return diagnosis_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Extracción de características"},{"metadata":{"id":"85SsSiJrX9f6","trusted":true},"cell_type":"code","source":"def audio_features(filename): \n  sound, sample_rate = librosa.load(filename)\n  stft = np.abs(librosa.stft(sound))  \n \n  mfccs = np.mean(librosa.feature.mfcc(y=sound, sr=sample_rate, n_mfcc=40),axis=1)\n  chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate),axis=1)\n  mel = np.mean(librosa.feature.melspectrogram(sound, sr=sample_rate),axis=1)\n  contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate),axis=1)\n  tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound), sr=sample_rate),axis=1)\n    \n  concat = np.concatenate((mfccs,chroma,mel,contrast,tonnetz))\n  return concat\n\ndef data_points():\n  labels = []\n  images = []\n\n  to_hot_one = {\"COPD\":0, \"Healthy\":1, \"URTI\":2, \"Bronchiectasis\":3, \"Pneumonia\":4, \"Bronchiolitis\":5, \"Asthma\":6, \"LRTI\":7}\n\n  count = 0\n  for f in diagnosis_data():\n    print(count)\n    labels.append(to_hot_one[f.diagnosis]) \n    images.append(audio_features(f.image_path))\n    count+=1\n\n  return np.array(labels), np.array(images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-procesamiento"},{"metadata":{"id":"KRc768XTi7su","outputId":"cdf4fc15-73e8-4249-bb24-73cdc55939d5","trusted":true},"cell_type":"code","source":"def preprocessing(labels, images):    \n  images = np.delete(images, np.where((labels == 7) | (labels == 6))[0], axis=0) \n  labels = np.delete(labels, np.where((labels == 7) | (labels == 6))[0], axis=0)      \n\n  x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=10)\n\n  y_train = to_categorical(y_train)\n  y_test = to_categorical(y_test)  \n\n  y_train = np.reshape(y_train, (y_train.shape[0], 6))\n  x_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n  y_test = np.reshape(y_test, (y_test.shape[0], 6))\n  x_test = np.reshape(X_test, (X_test.shape[0], X_train.shape[1],  1))\n\n  return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"id":"wsKxTYDTVGcK","outputId":"abbadb4c-86c6-4c4d-a57e-36895f1e9249","trusted":true},"cell_type":"code","source":"labels, images = data_points()\nX_train, X_test, y_train, y_test = preprocessing(labels, images)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convolutional Neural Network "},{"metadata":{"id":"Xwge0iUqTlmZ","outputId":"d2a61ca9-2476-4c6d-dad1-1ff0499d2994","trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(193, 1)))\n\nmodel.add(Conv1D(128, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(2)) \n\nmodel.add(Conv1D(256, kernel_size=5, activation='relu'))\n\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))   \nmodel.add(Dense(6, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=200, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluación"},{"metadata":{"id":"y5aGCpC2N4XV","outputId":"ffc1fa85-ce74-4d62-dcfd-73c6883ea0c1","trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test, batch_size=60, verbose=0)\nprint('Accuracy: {0:.0%}'.format(score[1]/1))\nprint(\"Loss: %.4f\\n\" % score[0])\n\n# Plot accuracy and loss graphs\nplt.figure(figsize = (15,5))\nplt.subplot(1,2,1)\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label = 'training acc')\nplt.plot(history.history['val_accuracy'], label = 'validation acc')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.title('Loss')\nplt.plot(history.history['loss'], label = 'training loss')\nplt.plot(history.history['val_loss'], label = 'validation loss')\nplt.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}