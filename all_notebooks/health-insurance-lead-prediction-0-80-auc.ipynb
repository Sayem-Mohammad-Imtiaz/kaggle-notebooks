{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\n#!pip install catboost\nfrom catboost import CatBoostClassifier\nfrom sklearn.utils import class_weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the Data Files\ntrain=pd.read_csv('../input/jobathon-analytics-vidhya/train.csv')\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('../input/jobathon-analytics-vidhya/test.csv')\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Response',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Accomodation_Type',data=train,hue='Response')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Health Indicator',data=train,hue='Response')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Filling missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing = [col for col in train.columns if train[col].isnull().any()]\nprint('Columns with Missing values : ')\ncols_with_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding new columns to give the information about missing rows\nfor col in cols_with_missing:\n  train[col + '_was_missing'] = train[col].isnull()\n  train[col + '_was_missing']=train[col + '_was_missing'].apply(lambda x: 1 if x==True else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing = [col for col in test.columns if test[col].isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cols_with_missing:\n  test[col + '_was_missing'] = test[col].isnull()\n  test[col + '_was_missing']=test[col + '_was_missing'].apply(lambda x: 1 if x==True else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filling missing values with a new category 'X'\n\ntrain['Health Indicator'].fillna('X',inplace=True)\ntest['Health Indicator'].fillna('X',inplace=True)\n\ntrain['Holding_Policy_Duration'].fillna('X',inplace=True)\ntest['Holding_Policy_Duration'].fillna('X',inplace=True)\n\ntrain['Holding_Policy_Type'].fillna('X',inplace=True)\ntest['Holding_Policy_Type'].fillna('X',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making the column to be a categorical\n\ntrain['Holding_Policy_Type']=train['Holding_Policy_Type'].apply(lambda x:str(x))\ntest['Holding_Policy_Type']=test['Holding_Policy_Type'].apply(lambda x:str(x))\n\n#Making the column to be a categorical\n\ntrain['Reco_Policy_Cat']=train['Reco_Policy_Cat'].apply(lambda x:str(x))\ntest['Reco_Policy_Cat']=test['Reco_Policy_Cat'].apply(lambda x:str(x))\n\n\n#Getting a new feature age_diff\ntrain['age_diff']=train['Upper_Age']-train['Lower_Age']\ntest['age_diff']=test['Upper_Age']-test['Lower_Age']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making a copies of original data\n\ntrain_org=train.copy()\ntest_org=test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def response_coding(data,column,alpha):\n  '''This function performs reponse coding on the given column with laplace smoothing'''\n  responses={}\n  train=train_org\n  unique_categories=list(train[column].unique())\n  for category in unique_categories:\n    prob_score=0\n    if 1 in list(train[train[column]==category]['Response'].value_counts().index):\n      prob_score=(train[train[column]==category]['Response'].value_counts()[1]+alpha*1)/(len(train[train[column]==category]['Response'])+alpha*2)\n    else:\n      prob_score=(alpha*1)/(len(train[train[column]==category]['Response'])+alpha*2)\n    responses[category]=prob_score\n  data[column+'_response']=data[column].apply(lambda x : responses[x] if x in responses.keys() else 0 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the reponse coded columns\n\nresponse_coding_columns=['Region_Code','City_Code','Health Indicator','Holding_Policy_Duration','Reco_Policy_Cat','age_diff','Reco_Policy_Premium']\nfor col in response_coding_columns:\n  response_coding(train,col,1)\n  response_coding(test,col,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performing One hot Encoding on Categoricla columns\ncategory_labels_dict={}\ncategory_columns=['Holding_Policy_Type','Reco_Policy_Cat','City_Code','Health Indicator']\nfor column in category_columns:\n  unq_categories=list(train[column].unique())\n  #dictionary=dict((value,index) for index,value in enumerate(unq_categories) )\n  category_labels_dict[column]=unq_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dummies(data,column):\n  category_labels=category_labels_dict[column]\n  for category in category_labels:\n    data[column+'_'+category]=data[column].apply(lambda x:1 if x==category else 0)\n  data.drop([column],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in category_columns:\n  get_dummies(train,column)\n  get_dummies(test,column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Holding_Policy_Duration into a numeric column\n\ntrain['Holding_Policy_Duration']=train['Holding_Policy_Duration'].replace('14+','15')\ntest['Holding_Policy_Duration']=test['Holding_Policy_Duration'].replace('14+','15')\ntrain['Holding_Policy_Duration']=train['Holding_Policy_Duration'].apply(lambda x: float(x) if x!='X' else 0 )\ntest['Holding_Policy_Duration']=test['Holding_Policy_Duration'].apply(lambda x: float(x) if x!='X' else 0 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performing Label encoding on some columns\ntrain['Accomodation_Type']=train['Accomodation_Type'].apply(lambda x : 1 if x=='Rented' else 0)\ntest['Accomodation_Type']=test['Accomodation_Type'].apply(lambda x : 1 if x=='Rented' else 0)\n\ntrain['Reco_Insurance_Type']=train['Reco_Insurance_Type'].apply(lambda x : 1 if x=='Joint' else 0)\ntest['Reco_Insurance_Type']=test['Reco_Insurance_Type'].apply(lambda x : 1 if x=='Joint' else 0)\n\ntrain['Is_Spouse']=train['Is_Spouse'].apply(lambda x : 1 if x=='Yes' else 0)\ntest['Is_Spouse']=test['Is_Spouse'].apply(lambda x : 1 if x=='Yes' else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a new column  is_joint_and_married\ntrain['is_joint_and_married']=train['Reco_Insurance_Type']^train['Is_Spouse']\ntest['is_joint_and_married']=test['Reco_Insurance_Type']^test['Is_Spouse']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=train.drop(['ID','Response'],axis=1)\ny_train=train[['Response']]\nX_test=test.drop(['ID'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating train and test split\nX_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train,stratify=y_train, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train : ',X_train.shape,' y_train : ',y_train.shape)\nprint('X_cv : ',X_cv.shape,' y_cv : ',y_cv.shape)\nprint('X_test : ',X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scalar=StandardScaler()\ncolumns_std=['City_Code_response','Region_Code_response','Upper_Age','Lower_Age','Health Indicator_response','Holding_Policy_Duration','Region_Code',\n             'Holding_Policy_Duration_response','Reco_Policy_Premium','age_diff','Reco_Policy_Cat_response','age_diff_response','Reco_Policy_Premium_response']\nscalar.fit(X_train[columns_std])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[columns_std]=scalar.transform(X_train[columns_std])\nX_cv[columns_std]=scalar.transform(X_cv[columns_std])\nX_test[columns_std]=scalar.transform(X_test[columns_std])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = class_weight.compute_class_weight('balanced',np.unique(y_train['Response']),y_train['Response'])\nprint('Using class weights while training')\nlist(weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training catboost Classifier model\nparams={\n    'loss_function':'Logloss',\n    'eval_metric':'AUC',\n    'verbose':200,\n    'random_seed':42,\n    'class_weights':list(weights)\n}\n\ncat_boost=CatBoostClassifier(**params,)\ncat_boost.fit(X_train,y_train,eval_set=(X_cv,y_cv),use_best_model=True,plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train AUC :',roc_auc_score(y_train, cat_boost.predict_proba(X_train)[:, 1]))\nprint('CV AUC :',roc_auc_score(y_cv, cat_boost.predict_proba(X_cv)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_imp=[t for t in zip(X_train.columns,cat_boost.get_feature_importance())]\nfeat_imp_df=pd.DataFrame(feat_imp,columns=['feature','importance'])\nfeat_imp_df=feat_imp_df.sort_values('importance',ascending=False)\nprint('Most important Features are :')\nfeat_imp_df=feat_imp_df[feat_imp_df['importance']>=1]\nsns.barplot(x='importance',y='feature',data=feat_imp_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model,filename):\n  '''This function takes model and filename and gives predictions csv file'''\n  predicted_proba=model.predict_proba(X_test)\n  predicted_proba=np.asarray(predicted_proba)\n  predicted_proba=predicted_proba[:,1]\n  predictions=pd.DataFrame(columns=['ID','Response'])\n  predictions['ID']=test['ID']\n  predictions['Response']=predicted_proba\n  predictions.to_csv(filename,index=False)\n  return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=predict(cat_boost,'submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}