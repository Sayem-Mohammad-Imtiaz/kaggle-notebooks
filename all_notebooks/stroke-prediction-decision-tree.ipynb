{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Objective****\n\nPredict whether a Patient will have stroke or not based on some given attributes. Evaluation metric was AUC-ROC Score","metadata":{}},{"cell_type":"markdown","source":"****Understanding Data****\nHere is the Definitions of the columns of the data\n\nid-Patient ID\n\ngender-Gender of Patient\n\nage-Age of Patient\n\nhypertension-0 - no hypertension, 1 - suffering from hypertension\n\nheart_disease-0 - no heart disease, 1 - suffering from heart disease\n\never_married-Yes/No\n\nwork_type-Type of occupation\n\nResidence_type-Area type of residence (Urban/ Rural)\n\navg_glucose_level-Average Glucose level (measured after meal)\n\nbmi-Body mass index\n\nsmoking_status-patientâ€™s smoking status\n\nstroke-0 - no stroke, 1 - suffered stroke","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndf =pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***DATA PRE-PROCESSING***","metadata":{}},{"cell_type":"code","source":"df['gender'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(df[df['gender']== 'Other'].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='gender' , data = df, palette=\"Set3\")\nxlabel='gender' \nylabel='count'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='smoking_status', y='age' , data = df, palette=\"Set3\")\nxlabel='smoking_status'\nylabel='age'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='bmi', y='work_type' , data = df,palette=\"Set3\")\nxlabel='bmi'\nylabel='work_type'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.catplot(x=\"gender\", hue=\"work_type\", col=\"stroke\",\n...                 data=df, kind=\"count\",\n...                 height=4, aspect=.7, palette=\"Set2\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.catplot(x=\"gender\", hue=\"ever_married\", col=\"stroke\",\n...                 data=df, kind=\"count\",\n...                 height=4, aspect=.7, palette=\"Set2\");\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.catplot(x=\"gender\", hue=\"heart_disease\", col=\"stroke\",\n...                 data=df, kind=\"count\",\n...                 height=4, aspect=.7, palette=\"husl\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.catplot(x=\"gender\", hue=\"Residence_type\", col=\"stroke\",\n...                 data=df, kind=\"count\",\n...                 height=4, aspect=.7, palette=\"Set3\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='smoking_status',data=df, hue= 'gender', palette= \"Set3\")\nxlabel='Smoking status' \nylabel='count'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.catplot(x=\"gender\", hue=\"smoking_status\", col=\"stroke\",\n...                 data=df, kind=\"count\",\n...                 height=4, aspect=.7, palette=\"Set3\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.distplot(df[df['stroke'] == 0]['avg_glucose_level'],color='green')\nsns.distplot(df[df['stroke'] == 1]['avg_glucose_level'],color='red')\nplt.title('No Stroke vs Stroke by Avg Glucose Level',fontsize=15)\nplt.xlim([30,330])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.select_dtypes(['object']).columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummies = pd.get_dummies(df[['gender','ever_married','work_type','Residence_type','smoking_status']],drop_first=True)\ndf = pd.concat([df,dummies],axis=1)\ndf = df.drop(['gender','ever_married','work_type','Residence_type','smoking_status'], axis=1)\ndf= df.drop(['id'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****CHECKING FOR NULL VALUES AND USING KNN****","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5)\ndataset = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(dataset.corr(), annot = True )\nxlabel='' \nylabel=''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute the corr matrix\n\ncorr = df.corr()\n\n# generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr,dtype=bool))\n\n# set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11,9))\n\n# generate a custom diverging colormap\ncmap = sns.diverging_palette(230,20,as_cmap=True)\n\n#draw the heatpmap with the mask and correct aspect ratio\nsns.heatmap(corr,mask=mask,cmap=cmap,vmax=.3,center=0,square=True,linewidths=.5,cbar_kws={'shrink':.5})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****OVERSAMPLING MY DATASET DUE THE DATA IS UNEVEN****","metadata":{}},{"cell_type":"code","source":"X = dataset.drop('stroke',axis=1).values\ny = dataset['stroke'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn import under_sampling, over_sampling\nprint(\"Before OverSampling, counts of label '1': {}\".format(sum(y == 1))) \nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y == 0))) \n  \n# import SMOTE module from imblearn library  \n\nfrom imblearn.combine import SMOTEENN \nsm = SMOTEENN(random_state=10) \nX_over, y_over = sm.fit_resample(X, y) \n  \nprint('After OverSampling, the shape of train_X: {}'.format(X_over.shape)) \nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_over.shape)) \n  \nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_over == 1))) \nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_over == 0)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****BEFORE START THE TRAINING I WILL NORMALIZE MY DATA****","metadata":{}},{"cell_type":"markdown","source":"Applying Model\nDividing the data into Train and validate (80:20) ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nX_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.20, random_state=7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nX_train_norm= preprocessing.normalize(X_train)\nX_test_norm =preprocessing.normalize(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****ALGORITHMS****","metadata":{}},{"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# prepare configuration for cross validation test harness\nseed = 7\n#MODELS\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\nmodels.append(('RF', RandomForestClassifier()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10)\n    cv_results = model_selection.cross_val_score(model, X_train_norm, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n# boxplot algorithm comparison\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Decision Tree****","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train_norm,y_train)\npredictions = dtree.predict(X_test_norm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,classification_report,roc_curve,plot_roc_curve,auc,precision_recall_curve,plot_precision_recall_curve,average_precision_score\nfrom sklearn.model_selection import cross_val_score\n\n\n\n# Roc Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Prediction and Result****\n\nPost that I used the models to predict the value for the Test set given in for the competition and submitted the result. It gave 94% AUC-ROC value for the submitted result.\n\n\n****Conclusion****\n\nOverall we used decision tree to forecast weather a patient can have stroke or not. We has to deal with imbalanced data which is common in such healthcare problems. For improving the model we could try out other ways of dealing with imbalanced data like SMOTE.\n\nAlso we could have dealt with missing data of smoke status in other ways as well for e.g. Age less than 10 or 15 years patients could have been tagged as never_smoked etc.\n\nFinally just one thought on why the 2 models were so different, one of the reasons could be the age distribution of the 2 data set. Median age of Smoke dataset was 48 while that of Non smoke dataset was 21. These are some ways Logistic model could have been improved.\n\nPlease share you thoughts on how else this model could have been improved or some other ML technique we can use for such datasets.","metadata":{}}]}