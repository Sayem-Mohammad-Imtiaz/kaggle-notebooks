{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report,accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the dataset\nkidney = pd.read_csv(\"../input/kidney-disease-dataset/kidney_disease.csv\")\nkidney.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney[['htn','dm','cad','pe','ane']] = kidney[['htn','dm','cad','pe','ane']].replace(to_replace={'yes':1,'no':0})\nkidney[['rbc','pc']] = kidney[['rbc','pc']].replace(to_replace={'abnormal':1,'normal':0})\nkidney[['pcc','ba']] = kidney[['pcc','ba']].replace(to_replace={'present':1,'notpresent':0})\nkidney[['appet']] = kidney[['appet']].replace(to_replace={'good':1,'poor':0,'no':np.nan})\nkidney['classification'] = kidney['classification'].replace(to_replace={'ckd':1.0,'ckd\\t':1.0,'notckd':0.0,'no':0.0})\nkidney.rename(columns={'classification':'class'},inplace=True)\n\nkidney['pe'] = kidney['pe'].replace(to_replace='good',value=0) # Not having pedal edema is good\nkidney['appet'] = kidney['appet'].replace(to_replace='no',value=0)\nkidney['cad'] = kidney['cad'].replace(to_replace='\\tno',value=0)\nkidney['dm'] = kidney['dm'].replace(to_replace={'\\tno':0,'\\tyes':1,' yes':1, '':np.nan})\nkidney.drop('id',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney.rbc.value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney.fillna(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import minmax_scale\n\n# set seed for reproducibility\nnp.random.seed(0)\n\n# generate 1000 data points randomly drawn from an exponential distribution\noriginal_data = np.random.exponential(size = 1000)\n\n# mix-max scale the data between 0 and 1\nscaled_data = minmax_scale(original_data)\n\n# plot both together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(original_data, ax=ax[0], color='y')\nax[0].set_title(\"Original Data\")\nsns.distplot(scaled_data, ax=ax[1])\nax[1].set_title(\"Scaled data\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix = kidney.corr()\nplt.figure(figsize=(15, 15))\n\nplt.title(\"Correlation Graph\")\n\ncmap = sns.diverging_palette( 1000, 120, as_cmap=True)\nsns.heatmap(corr_matrix, annot=True, fmt='.2f',  linewidths=.8, cmap='coolwarm');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ns_sc = StandardScaler()\ncol_to_scale = ['age', 'bp', 'sg']\nkidney[col_to_scale] = s_sc.fit_transform(kidney[col_to_scale])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score , classification_report\nimport seaborn as sns\nclasses=['healthy','Un-healthy']\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_train, pred) * 100:.2f}%\")\n       # recall=recall_score(y_train, pred) \n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_train, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        sns.heatmap(confusion_matrix(y_test, pred), annot= True, cmap='YlGnBu',fmt = 'g')\n        print(classification_report(y_test,pred))\n        cm=(confusion_matrix(y_test,pred))\n       # ax.xaxis.set_label_position('top')\n        plt.tight_layout()\n        plt.title('Confusion matrix for Decision Tree Model', y = 1.1)\n        plt.ylabel('Actual label')\n        plt.xlabel('Predicted label')\n        plt.show()\n        total = sum(sum(cm))\n        acc = (cm[0, 0] + cm[1, 1]) / total\n        sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n        specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n       # print(cm)\n\n        FP = cm.sum(axis=0) - np.diag(cm)  \n        FN = cm.sum(axis=1) - np.diag(cm)\n        TP = np.diag(cm)\n        TN = cm.sum() - (FP + FN + TP)\n\n        FP = FP.astype(float)\n        FN = FN.astype(float)\n        TP = TP.astype(float)\n        TN = TN.astype(float)\n\n        # Sensitivity, hit rate, recall, or true positive rate\n        TPR = TP/(TP+FN)\n        print('Sensitivity (TPR) : ',TPR)\n        # Specificity or true negative rate\n        TNR = TN/(TN+FP) \n        print('Specificity (TNR) : ',TNR)\n        # Overall accuracy\n        print(\" Overall accuracy\")\n        ACC = (TP+TN)/(TP+FP+FN+TN)\n        print('Accuracy : ',ACC)\n        print(\"Accuracy: {:.4f}\".format(acc))\n        print(\"Average Sensitivity: {:.4f}\".format(sensitivity))\n        print(\"Average Specificity: {:.4f}\".format(specificity))\n        print('\\n')\n        \n        conf_matrix=cm\n        print(\"=========================================\")\n        # save confusion matrix and slice into four pieces\n        TP = conf_matrix[1][1]\n        TN = conf_matrix[0][0]\n        FP = conf_matrix[0][1]\n        FN = conf_matrix[1][0]\n        print('True Positives:', TP)\n        print('True Negatives:', TN)\n        print('False Positives:', FP)\n        print('False Negatives:', FN)\n\n        # calculate accuracy\n        conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n\n        # calculate mis-classification\n        conf_misclassification = 1- conf_accuracy\n\n        # calculate the sensitivity\n        conf_sensitivity = (TP / float(TP + FN))\n        # calculate the specificity\n        conf_specificity = (TN / float(TN + FP))\n\n        # calculate precision\n        conf_precision = (TN / float(TN + FP))\n        # calculate f_1 score\n        conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n        print('-'*50)\n        print(f'Accuracy: {round(conf_accuracy,2)}') \n        print(f'Mis-Classification: {round(conf_misclassification,2)}') \n        print(f'Sensitivity: {round(conf_sensitivity,2)}') \n        print(f'Specificity: {round(conf_specificity,2)}') \n        print(f'Precision: {round(conf_precision,2)}')\n        print(f'f_1 Score: {round(conf_f1,2)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\ndef plotting(true,pred):\n    fig,ax=plt.subplots(1,2,figsize=(15,5))\n    precision,recall,threshold = precision_recall_curve(true,pred[:,1])\n    ax[0].plot(recall,precision,'g--')\n    ax[0].set_xlabel('Recall')\n    ax[0].set_ylabel('Precision')\n    ax[0].set_title(\"Average Precision Score : {}\".format(average_precision_score(true,pred[:,1])))\n    fpr,tpr,threshold = roc_curve(true,pred[:,1])\n    ax[1].plot(fpr,tpr)\n    ax[1].set_title(\"AUC Score is: {}\".format(auc(fpr,tpr)))\n    ax[1].plot([0,1],[0,1],'k--')\n    ax[1].set_xlabel('False Positive Rate')\n    ax[1].set_ylabel('True Positive Rate')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = kidney.drop('rbc', axis=1)\ny = kidney.rbc\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kidney2 = kidney.dropna()\nprint(kidney2.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(kidney2.groupby('class').bp.max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(kidney2.iloc[:,:-1], kidney2['class'], test_size=0.33, random_state=44, stratify= kidney2['class'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(random_state = 22)\nrfc_fit = rfc.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_pred = rfc_fit.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,rfc_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,rfc_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score( y_test, rfc_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = knn.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score( y_test,pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = logmodel.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score( y_test, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp_list = np.arange(3, 30)\ntrain = []\ntest = []\n\nfor depth in dp_list:\n    forest = RandomForestClassifier(max_depth=depth, n_jobs = -1, random_state=42)\n    forest.fit(X_train, y_train)\n    prediction = forest.predict(X_test)\n    trainpred = forest.predict(X_train)\n    train_acc = accuracy_score(y_train, trainpred)\n    test_acc = accuracy_score(y_test, prediction)\n    train.append(train_acc)\n    test.append(test_acc)\n    \nperformance = pd.DataFrame({'n_estimators':dp_list,'Train_acc':train,'Test_acc':test})\n\nfig, ax = plt.subplots()\nx_axis = dp_list\nax.plot(x_axis, performance['Train_acc'], label='Train')\nax.plot(x_axis, performance['Test_acc'], label='Test')\nax.legend()\nplt.ylabel('accuracy')\nplt.title('Forest accuracy vs depth')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neighbors = np.arange(1, 9)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, k in enumerate(neighbors):\n    \n    # Setup a k-NN Classifier with k neighbors\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    #Fit the classifier to the training data\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = knn.score(X_train, y_train)\n    \n    #Compute accuracy on the test set\n    test_accuracy[i] = knn.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('KNN varying number of neighbors')\nplt.plot(neighbors, test_accuracy, label='Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label='Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = knn.predict(X_test)\n\n# Generate the confusion matrix and classification report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_prob = knn.predict_proba(X_test)[:,1]\n\n# Generate ROC curve values (false positive rate, true positive rate, thresholds)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\n# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_classifier = KNeighborsClassifier()\nknn_classifier.fit(X_train, y_train)\n\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n\ntree = DecisionTreeClassifier(random_state=42)\ntree.fit(X_train, y_train)\n\nprint_score(tree, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n\nsvm_model = SVC(kernel='rbf', gamma=0.1, C=1.0, probability=True)\nsvm_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_score(svm_model, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_model, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nNN=MLPClassifier(hidden_layer_sizes=(10,50),momentum=0.9,solver='sgd',random_state=42)\n               \nNN.fit(X_train, y_train)\n\nprint_score(NN, X_train, y_train, X_test, y_test, train=True)\nprint_score(NN, X_train, y_train, X_test, y_test, train=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrand_forest = RandomForestClassifier(n_estimators=1000, random_state=42)\nrand_forest.fit(X_train, y_train)\n\nprint_score(rand_forest, X_train, y_train, X_test, y_test, train=True)\nprint_score(rand_forest, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\n\nprint_score(nb, X_train, y_train, X_test, y_test, train=True)\nprint_score(nb, X_train, y_train, X_test, y_test, train=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_score = []\ntest_score = []\nneighbors = range(1, 20)\n\nfor k in neighbors:\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    train_score.append(accuracy_score(y_train, model.predict(X_train)))\n    test_score.append(accuracy_score(y_test, model.predict(X_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\nplt.plot(neighbors, train_score, label=\"Train score\")\nplt.plot(neighbors, test_score, label=\"Test score\")\nplt.xticks(np.arange(1, 20, 1))\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Model score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the test data: {max(test_score)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_classifier = KNeighborsClassifier(n_neighbors=30)\nknn_classifier.fit(X_train, y_train)\n\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model = SVC(kernel='rbf', gamma=0.1, C=1.0)\n\n\nparams = {\"C\":(0.1, 0.5, 1, 2, 5, 10, 20), \n          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n          \"kernel\":('linear', 'poly', 'rbf')}\n\nsvm_grid = GridSearchCV(svm_model, params, n_jobs=-1,   cv=5, verbose=1, scoring=\"accuracy\")\nsvm_grid.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_grid.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\nsvm_model.fit(X_train, y_train)\n\nprint_score(svm_grid, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_grid, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\"criterion\":(\"gini\", \"entropy\"), \n          \"splitter\":(\"best\", \"random\"), \n          \"max_depth\":(list(range(1, 20))), \n          \"min_samples_split\":[2, 3, 4], \n          \"min_samples_leaf\":list(range(1, 20))\n          }\n\ntree = DecisionTreeClassifier(random_state=42)\ngrid_search_cv = GridSearchCV(tree, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\ngrid_search_cv.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_cv.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, \n                       random_state=42, splitter='random')\ntree.fit(X_train, y_train)\n\nprint_score(tree, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num=11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\nrandom_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n\nrand_forest = RandomForestClassifier(random_state=42)\n\nrf_random = RandomizedSearchCV(estimator=rand_forest, param_distributions=random_grid, n_iter=100, cv=3, \n                               verbose=2, random_state=42, n_jobs=-1)\n\n\nrf_random.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_random.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_forest=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=4, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                       warm_start=False)\nrand_forest.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_score(rand_forest, X_train, y_train, X_test, y_test, train=True)\nprint_score(rand_forest, X_train, y_train, X_test, y_test, train=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.classifier import StackingCVClassifier\n\nscv=StackingCVClassifier(classifiers=[rf_random,knn_classifier,svm_grid],meta_classifier= rf_random,random_state=42)\nscv.fit(X_train,y_train)\nscv_predicted = scv.predict(X_test)\nscv_conf_matrix = confusion_matrix(y_test, scv_predicted)\nscv_acc_score = accuracy_score(y_test, scv_predicted)\nprint(\"confussion matrix\")\nprint(scv_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of StackingCVClassifier:\",scv_acc_score*100,'\\n')\nprint(classification_report(y_test,scv_predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_score(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_score(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}