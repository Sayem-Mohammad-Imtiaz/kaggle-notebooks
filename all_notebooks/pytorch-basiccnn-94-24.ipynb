{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = pd.read_csv('../input/english-handwritten-characters-dataset/english.csv')\ndata_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, cv2\nfrom glob import glob\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\nclass dataset(Dataset) :\n    def __init__(self, image_list, image_names, image_labels, image_label_dict, transform, device) :\n        self.image_list = image_list\n        self.image_names = image_names\n        self.image_labels = image_labels\n        self.image_label_dict = image_label_dict\n        self.transform = transform\n        self.device = device\n            \n    def __len__(self) :\n        return len(self.image_list)\n    \n    def __getitem__(self, index) :\n        x = cv2.imread(self.image_list[index])\n        x = self.transform(x).to(device)\n        \n        image_name = image_list[index][48:]\n        y = self.image_labels[np.where(self.image_names == image_name)]\n        y = self.image_label_dict[y[0]]\n        y = torch.LongTensor([y]).to(device)\n        \n        return x, y\n    \nimage_list = glob('../input/english-handwritten-characters-dataset/Img/*.png')\nimage_names = data_df[\"image\"].values\nimage_labels = data_df[\"label\"].values\ndevice = torch.device('cuda' if torch.cuda.is_available else 'cpu')\ntransform = transforms.Compose([\n      transforms.ToTensor(),\n      transforms.Resize((224, 224)) #900, 1200 => 224, 224\n])\n\nimage_label_dict = dict()\ntmp = 0\nfor label in set(list(image_labels)) :\n    image_label_dict[label] = tmp\n    tmp += 1\n    \ntrain_data = image_list[:-10]\ntest_data = image_list[-10:]\n\ntrain_data = dataset(train_data, image_names, image_labels, image_label_dict, transform, device)\ntrain_data = DataLoader(train_data, batch_size = 64, shuffle = True)\n\ntest_data = dataset(test_data, image_names, image_labels, image_label_dict, transform, device)\ntest_data = DataLoader(test_data, batch_size = 1, shuffle = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.optim import Adam\nfrom torchvision.models import resnet34\n\nclass resnet(nn.Module) :\n    def __init__(self, output) :\n        super().__init__()\n        self.model = resnet34(pretrained = False)\n        self.model.fc = nn.Linear(512, output)\n        \n    def forward(self, x) :\n        output = self.model(x)\n        return output\n    \nmodel = resnet(62).to(device)\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = Adam(model.parameters(), lr = 0.01)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\nepoch_num = 30\ntorch.cuda.empty_cache()\n\nfor epoch in range(epoch_num) :\n    epoch_loss = 0\n    epoch_acc = 0\n    for i, (x, y) in tqdm(enumerate(train_data)) :\n        y = y.reshape(-1)\n        \n        predict = model(x)\n        loss = criterion(predict, y)\n        \n        epoch_loss += loss / len(train_data)\n        correct_prediction = torch.argmax(predict, 1) == y\n        correct_prediction = correct_prediction.sum()\n        epoch_acc += correct_prediction\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    epoch_acc = epoch_acc / (64 * len(train_data))\n    print('Epoch : {}/{},   loss : {:.5f},    acc : {:.5f}'.format(epoch+1, epoch_num, epoch_loss, epoch_acc))\n    \n    if epoch_acc > 0.98 : break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodel.eval()\nwith torch.no_grad() :\n    for i, (x, y) in tqdm(enumerate(test_data)) :\n        y = y.reshape(-1)\n        predict = model(x)\n        \n        predict = torch.argmax(predict)\n        \n        chk1, chk2 = False, False\n        for key, value in image_label_dict.items() :\n            if predict == value :\n                predict = key\n                chk1 = True\n            if y == value :\n                y = key\n                chk2 = True\n                \n            if chk1 and chk2 : break\n                \n        x = x.reshape((3, 224, 224)).to('cpu').numpy()\n        plt.imshow(x.transpose(1, 2, 0))\n        plt.title(predict)\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}