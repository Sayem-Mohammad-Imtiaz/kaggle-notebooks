{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/star-type-classification/Stars.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix,classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"shape: {data.shape}\")\nprint('\\n')\nprint(f\"missing value:\\n{data.isnull().sum()}\")\nprint('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Dataset is including with numeric and category features\n* 240 records, 6 features and 1 label\n* No missing value","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\ndata.drop('Type',axis=1).boxplot(vert=False)\nplt.title('Data Distribution')\nplt.xlabel('value')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,3))\ndata.Type.value_counts().plot.bar()\nplt.title('Record count of each Type')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The range of values is very wide\n* But the balancing is perfect (40 records per Type)\n* So let's drop feature that not related to Type","metadata":{}},{"cell_type":"code","source":"col_num = ['Temperature', 'L', 'R', 'A_M']\ncol_cat = ['Color','Spectral_Class']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=1\nplt.figure(figsize=(20,5))\nfor c in col_num:\n  ax = plt.subplot(1,4,i)\n  data.groupby('Type').mean()[c].plot.bar(ax=ax)\n  ax.set_title(f'Mean of {c}')\n  i+=1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Can cleary see the difference between each Type of numeric features","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\n# Correlation\nnum_corr=data.drop('Type',axis=1).corr()\nsns.heatmap(num_corr,vmin=-1,vmax=1,annot=True,cmap='RdBu')\nplt.title('Nemeric Feature Correlation')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> y = mx + c","metadata":{}},{"cell_type":"code","source":"a = 1\nplt.figure(figsize=(22,22))\nfor j in range(len(col_num)):\n    for k in range(len(col_num)):\n        ax = plt.subplot(4,4,a)\n        plt.scatter(data[col_num[k]],data[col_num[j]],color='gray')\n        m, c = np.polyfit(data[col_num[k]],data[col_num[j]], 1)\n        plt.plot(data[col_num[k]], m*data[col_num[k]] + c,'blue')\n        plt.xlabel(col_num[k])\n        plt.ylabel(col_num[j])\n        a+=1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There're relationship between pair of numeric features\n* So all numeric features might be related with Type\n* What about relation of category features?","metadata":{}},{"cell_type":"code","source":"data.Color.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There're duplicate color such as 'Blue-white' and 'Blue White'\n* Transform characters to lowercase and remove non-word characters","metadata":{}},{"cell_type":"code","source":"data.Color=list(map(lambda x: x.lower(),data.Color.values))\ndata.Color.replace('\\W','',regex=True,inplace=True)\ndata.Color.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,10))\n# Map class and count values between Color and Spectrum\nax1 = plt.subplot(2,1,1)\ncat_dep1 = data.pivot_table(index='Spectral_Class',columns='Type', aggfunc='size')\nmask1=cat_dep1.isnull()\nsns.heatmap(cat_dep1,annot=True,fmt='g',cmap='Blues',mask=mask1,ax=ax1)\n\nax2 = plt.subplot(2,1,2)\ncat_dep2 = data.pivot_table(index='Color',columns='Spectral_Class', aggfunc='size')\nmask2=cat_dep2.isnull()\nsns.heatmap(cat_dep2,annot=True,fmt='g',cmap='Greens',mask=mask2,ax=ax2)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We can see group of data\n* So Color and Spectral_Class might be related with Type\n* No need to drop any features!","metadata":{}},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"* Categorical Encoding","metadata":{}},{"cell_type":"code","source":"data_enc = pd.get_dummies(data.drop('Type',axis=1), prefix=('c','S'))\ndata_enc.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Normalization\n> X = (X0 - Xmin) / (Xmax - Xmin)","metadata":{}},{"cell_type":"code","source":"min = data_enc.min()\nmax = data_enc.max()\ndata_norm = (data_enc - min) / (max - min)\ndata_norm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_norm.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Train/Test set split","metadata":{}},{"cell_type":"code","source":"train_x,train_y,test_x,test_y = train_test_split(data_norm,data.Type,test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transform dataframe to array\ntrain_xa = np.array(train_x)\ntest_xa = np.array(test_x)\ntrain_ya = np.array(train_y)\ntest_ya = np.array(test_y)\nprint(train_xa.shape)\nprint(test_xa.shape)\nprint(train_ya.shape)\nprint(test_xa.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"* Using Gaussian Naive Bayes","metadata":{}},{"cell_type":"code","source":"model_g = [GaussianNB(),'GaussianNB()']\nmodel_g[0].fit(train_xa,test_xa)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"* Using confusion metrix to evaluate model","metadata":{}},{"cell_type":"code","source":"def modelEvaluate(model,y_train,y_test):\n  y_pred = model[0].predict(y_train)\n  plt.figure(figsize=(5,5))\n  conf = confusion_matrix(y_test,y_pred)\n  sns.heatmap(conf,annot=True,cmap='Blues')\n  plt.title(f'Confusion Metrix\\n-- {model[1]} --')\n  plt.ylabel('Prediction')\n  plt.xlabel('Actual')\n  plt.show()\n  print(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelEvaluate(model_g,train_ya,test_ya)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Tuning","metadata":{}},{"cell_type":"markdown","source":"* Adjust var_smoothing","metadata":{}},{"cell_type":"code","source":"model_tune = [GaussianNB(var_smoothing=0.01),'GaussianNB(var_smoothing=0.01)']\nmodel_tune[0].fit(train_xa,test_xa)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelEvaluate(model_tune,train_ya,test_ya)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"* GaussianNB(var_smoothing=0.01)\n* Accuracy = 99%","metadata":{}}]}