{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Loading the required libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score,train_test_split,RepeatedKFold,KFold,GridSearchCV\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,mean_squared_error,classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the objects of the classes we require further"},{"metadata":{"trusted":true},"cell_type":"code","source":"ss=StandardScaler()\nsvm=SVC()\nknn=KNeighborsClassifier()\nrf=RandomForestClassifier()\nad=AdaBoostClassifier()\nxg=XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. ### age      >>   age\n1. ### sex      >>   sex\n1. ### cp       >>   chest pain type (4 values)\n1. ### trestbps >>   resting blood pressure\n1. ### chol     >>   serum cholestoral in mg/dl\n1. ### fbs      >>   fasting blood sugar > 120 mg/dl\n1. ### restecg  >>   resting electrocardiographic results (values 0,1,2)\n1. ### thalach  >>   maximum heart rate achieved\n1. ### exang    >>   exercise induced angina\n1. ### oldpeak  >>   ST depression induced by exercise relative to rest\n1. ### slope    >>   the slope of the peak exercise ST segment\n1. ### ca       >>   number of major vessels (0-3) colored by flourosopy\n1. ### thal: 3 = normal; 6 = fixed defect; 7 = reversable defect \n1. ### target   >>   0 indicates healthy and 1 indicates illness"},{"metadata":{},"cell_type":"markdown","source":"## Here,we are splitting the dataset into two sets i.e. train and test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\nx=dt.iloc[:,:-1]\ny=dt.iloc[:,-1]\n\n# Splitting the dataset into train and test set in 80/20 ration for evaluating the model performance \nX_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=42)\nX_test.reset_index(drop=True,inplace=True)\ny_test.reset_index(drop=True,inplace=True)\nX_train.reset_index(drop=True,inplace=True)\ny_train.reset_index(drop=True,inplace=True)\n\n\nfinal_X_test=X_test.to_numpy()\nfinal_y_test=y_test.to_numpy()\nx=X_train\ny=y_train\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Next, we will perform feature selection on the given dataset to find the best features to do our classification task based on their score using SelectKBest class of sklearn. To decide the value of k we will plot the mean squared error curve at different values of k. We are performing this operation on only the train set with 10 fold validation and here we are using KNearestNeighbour as our base model for getting the final scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nkf=KFold(n_splits=10)\n\nfinal_error={}\nindices={}\n\nk=x.shape[1]\nfor i in range(1,k+1):\n    sk=SelectKBest(chi2, k=i)\n    data_temp=sk.fit_transform(x, y)\n    indices[i]=(list(sk.get_support(True)))\n\n    error=list()\n    for train_index,test_index in kf.split(data_temp):\n        X_train,y_train=data_temp[train_index],y[train_index]\n        X_test,y_test=data_temp[test_index],y[test_index]\n        X_train=ss.fit_transform(X_train)\n        X_test=ss.transform(X_test)\n        knn.fit(X_train,y_train)\n        error.append(mean_squared_error(y_test,knn.predict(X_test)))\n    final_error[i]=error[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Optimal features are: ',pd.DataFrame(indices.values(),index=final_error.values()).sort_index().iloc[0,:].values)\nplt.plot(np.array(list(final_error.keys())),final_error.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=pd.DataFrame(indices.values(),index=final_error.values()).sort_index().iloc[0,:]\nind=list(temp[temp.notnull()].values.astype(int))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using only the selected columns from the given dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"xcopy=x.iloc[:,ind]\nxcopy.columns=list(range(xcopy.shape[1]))\nxcopy=xcopy.to_numpy()\nfinal_X_test=final_X_test[:,ind]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we are training different models like SVM, KNearestNeighbour, RandomForest, AdaBoost with the selected features in the training set only. We are using RepeatedKfold class and splitting the training set into 10 folds and we are repeating all evaluations for 15 iterations. After splitting we transformed the data using standard scalar and finally we are using accuracy as the performance metrics to evaluate our models performances    "},{"metadata":{"trusted":true},"cell_type":"code","source":"models=[svm,knn,rf,ad]\nrkf=RepeatedKFold(n_splits=10,n_repeats=15)\nresult=[]\nfor train_index,test_index in rkf.split(xcopy):\n    X_TRAIN,y_TRAIN=xcopy[train_index],y[train_index]\n    X_TEST,y_TEST=xcopy[test_index],y[test_index]\n    X_TRAIN=ss.fit_transform(X_TRAIN)\n    X_TEST=ss.transform(X_TEST)\n    temp=list()\n    for model in models:\n        model.fit(X_TRAIN,y_TRAIN)\n        temp.append(accuracy_score(y_TEST,model.predict(X_TEST)))\n    result.append(temp)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The obtianed accuracy with differnt models in each of the 15 iterations are shown below in the Dataframe:"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_frame=pd.DataFrame(result)\n\nresult=[]\nfor i in range(0,result_frame.shape[0],10):\n    result.append(result_frame.iloc[i:i+10,:].mean())\n\nresult=pd.DataFrame(result)\nresult.columns=['svm','knn','rf','ad']\nresult\n# print('\\n')\n#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print(\"The mean result of the 15 iterations are: \",result.mean())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now i am just checking the model performance on the test set that we created above. The result may be biased because it may happens that the distribution of test set is not as same as the train set or this test set is easier or difficult for the model to recognize. I am just doing it to avoid any Data leakage and just for getting the whole classification report on a test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_transformed=ss.fit_transform(xcopy)\ntransformed_final_X_test=ss.transform(final_X_test)\nfor model in models:\n    model.fit(x_transformed,y)\n    target=['class 0', 'class 2']\n    print('for {} the results are: '.format(model))\n    print('\\n')\n    print(classification_report(final_y_test,model.predict(transformed_final_X_test),target_names=target))\n    print('\\n')\n    print('\\n')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Above are the classification reports of each classifier. We don't need to use accuracy_score, precision, recall, f1 score separately. We can do it in just one go using the above used class. Isn't this COOL!."},{"metadata":{},"cell_type":"markdown","source":"## Now we will do some hyperparameters tuning of the models that we are using to check how much it can impact the performance of our models. I am using GridSearchCV for this. You can use other methods for this also."},{"metadata":{},"cell_type":"markdown","source":"### 1. SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'kernel':['rbf','poly','linear'], 'C':[0.1,0.5,1,5,10,100],'gamma':('scale','auto')}\nclf = GridSearchCV(svm, parameters, refit = True, verbose = 1)\nclf.fit(x_transformed,y)\n\nsorted(clf.cv_results_.keys())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_param=clf.best_params_\nsvm_param","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Random Forest  "},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [int(x) for x in np.linspace(start = 5, stop = 50, num = 10)]\nmax_depth = [int(x) for x in np.linspace(1, 50, num = 10)]\n# max_depth.append(None)\nmin_samples_split = [2, 5,8]\nmin_samples_leaf = [1, 2,6]\nparameters = {'n_estimators': n_estimators,\n               \n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\n\n\nclf = GridSearchCV(rf, parameters, refit = True, verbose = 1)\nclf.fit(x_transformed,y)\n\nsorted(clf.cv_results_.keys())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_param=clf.best_params_\nrf_param","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. KNN\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn=KNeighborsClassifier()\nleaf_size = list(range(1,40,4))\nn_neighbors = list(range(1,30,3))\np=[1,2,4]\nweights=['uniform', 'distance']\nparameters={'leaf_size':leaf_size,'n_neighbors':n_neighbors,'p':p}\n\nclf=GridSearchCV(knn,param_grid=parameters,refit=True,verbose=1)\nclf.fit(x_transformed,y)\n\nsorted(clf.cv_results_.keys())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_param=clf.best_params_\nknn_param","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# AdaBoostClassifier()\nn_estimators=list(range(1,40,5))\nlearning_rate=[0.01,0.1,0.6,1]\nparameters={'n_estimators':n_estimators,'learning_rate':learning_rate}\nclf=GridSearchCV(ad,param_grid=parameters,refit=True,verbose=1)\nclf.fit(x_transformed,y)\n\nsorted(clf.cv_results_.keys())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ad_param=clf.best_params_\nad_param","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now using these hyperparamters, i will again test the models on the test set as i did above with to check whether performance imroved or not. "},{"metadata":{"trusted":true},"cell_type":"code","source":"svm=SVC(C= svm_param['C'], gamma= svm_param['gamma'], kernel= svm_param['kernel'])\nknn=KNeighborsClassifier(leaf_size= knn_param['leaf_size'], n_neighbors= knn_param['n_neighbors'], p=knn_param['p'])\nrf=RandomForestClassifier(max_depth= rf_param['max_depth'],min_samples_leaf= rf_param['min_samples_leaf'], min_samples_split= rf_param['min_samples_split'],n_estimators= rf_param['n_estimators'])\nad=AdaBoostClassifier(learning_rate= ad_param['learning_rate'], n_estimators= ad_param['n_estimators'])\n\nmodels=[svm,knn,rf,ad]\n\nfor model in models:\n    model.fit(x_transformed,y)\n    target=['class 0', 'class 2']\n    print('for {} the results are: '.format(model))\n    print('\\n')\n    print(classification_report(final_y_test,model.predict(transformed_final_X_test),target_names=target))\n    print('\\n')\n    print('\\n')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Above shown arre the classification reports of each classifier trained on the transformed train set and tested on the test set. "},{"metadata":{},"cell_type":"markdown","source":"## Here i am again doing tests on the Train set with 10 fold validation to cross check the results."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrkf=RepeatedKFold(n_splits=10,n_repeats=15)\nresult=[]\nfor train_index,test_index in rkf.split(xcopy):\n    X_TRAIN,y_TRAIN=xcopy[train_index],y[train_index]\n    X_TEST,y_TEST=xcopy[test_index],y[test_index]\n    X_TRAIN=ss.fit_transform(X_TRAIN)\n    X_TEST=ss.transform(X_TEST)\n    temp=list()\n    for model in models:\n        model.fit(X_TRAIN,y_TRAIN)\n        temp.append(accuracy_score(y_TEST,model.predict(X_TEST)))\n    result.append(temp)\nresult_frame=pd.DataFrame(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=[]\nfor i in range(0,result_frame.shape[0],10):\n    result.append(result_frame.iloc[i:i+10,:].mean())\n\nresult=pd.DataFrame(result)\nresult.columns=['svm','knn','rf','ad']\nresult.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finally, we can see that for the test set evaluation case, the accuracy of all classiefiers besides SVM increased but in the case of 10 fold validation on training data, the accuracy only in case of AdaBoost classifier increased."},{"metadata":{},"cell_type":"markdown","source":"## Just vary the random state value while splitting the dataset into train/test set and see the results before and after tuning."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}