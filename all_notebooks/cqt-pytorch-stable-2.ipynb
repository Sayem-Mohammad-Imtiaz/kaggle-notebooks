{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport random\nimport collections\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-06T06:08:34.389946Z","iopub.execute_input":"2021-09-06T06:08:34.39067Z","iopub.status.idle":"2021-09-06T06:08:34.396093Z","shell.execute_reply.started":"2021-09-06T06:08:34.390629Z","shell.execute_reply":"2021-09-06T06:08:34.39511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## things to try:\n# 1) smaller img\n# 2) save both best auc and best acc\n# 3) change to fold 3\n# 4) add warm up to learning rate; try new optimizer\n# 5) swapping channels\n# 6) shorten cqt convolution kernel\n# 7) change pretrain to True (with learning rate warm up)\n# 8) remove mixup; soft labels\n# 9) try stochastic depth\n# 10) try noisy student training","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:34.400742Z","iopub.execute_input":"2021-09-06T06:08:34.401069Z","iopub.status.idle":"2021-09-06T06:08:34.409799Z","shell.execute_reply.started":"2021-09-06T06:08:34.401039Z","shell.execute_reply":"2021-09-06T06:08:34.408961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet_pytorch -qq\n\n!pip install -q nnAudio -qq\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2, CQT2010v2\n\nimport time\nimport gc\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nfrom torch.autograd import Variable\nimport efficientnet_pytorch\nfrom tqdm.auto import tqdm\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, ExponentialLR\nfrom torchaudio.functional import lfilter\nfrom torch.fft import fft, rfft, ifft\nimport numpy as np\nimport torchvision\n\n\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import StratifiedKFold\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:34.417821Z","iopub.execute_input":"2021-09-06T06:08:34.41818Z","iopub.status.idle":"2021-09-06T06:08:46.804771Z","shell.execute_reply.started":"2021-09-06T06:08:34.418151Z","shell.execute_reply":"2021-09-06T06:08:46.803473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sys.path.append('../input/pytorch-swa')\n#import swa","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:46.806712Z","iopub.execute_input":"2021-09-06T06:08:46.807004Z","iopub.status.idle":"2021-09-06T06:08:46.811046Z","shell.execute_reply.started":"2021-09-06T06:08:46.806972Z","shell.execute_reply":"2021-09-06T06:08:46.810094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\ntrain_df = pd.read_csv(\"../input/g2net-gravitational-wave-detection/training_labels.csv\")\ntrain_df_pred = pd.read_csv(\"../input/train-pred-cqt-v10/train_preds_CQT_V10.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:46.813634Z","iopub.execute_input":"2021-09-06T06:08:46.813934Z","iopub.status.idle":"2021-09-06T06:08:48.471999Z","shell.execute_reply.started":"2021-09-06T06:08:46.813889Z","shell.execute_reply":"2021-09-06T06:08:48.470914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['preds'] = train_df_pred['target']\nweight = 0.5\ntrain_df['soft_target'] = train_df['preds']*weight + train_df['target']*(1-weight)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.473787Z","iopub.execute_input":"2021-09-06T06:08:48.474255Z","iopub.status.idle":"2021-09-06T06:08:48.505115Z","shell.execute_reply.started":"2021-09-06T06:08:48.47421Z","shell.execute_reply":"2021-09-06T06:08:48.504093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_pred","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.506462Z","iopub.execute_input":"2021-09-06T06:08:48.50674Z","iopub.status.idle":"2021-09-06T06:08:48.521661Z","shell.execute_reply.started":"2021-09-06T06:08:48.506711Z","shell.execute_reply":"2021-09-06T06:08:48.520621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define config","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass CFG:\n    \n    TRAIN = True\n    \n    WARM_START = False\n    \n    EPOCHS = 10\n    \n    # batch size\n    BATCH = 192\n    \n    \n    \n    n_fold = 5\n    fold = 3\n    \n    # scheduler_params\n    scheduler='CosineAnnealingLR'\n    if scheduler == 'CosineAnnealingLR':\n        lr = 1.5*1e-2\n        schedulerStepFreq = 10\n        T_max=EPOCHS*3500*128/BATCH/schedulerStepFreq # CosineAnnealingLR\n        T_0=3 # CosineAnnealingWarmRestarts\n        min_lr=1e-6\n    elif scheduler == 'ExponentialLR':\n        lr = 3e-2\n        schedulerStepFreq = 500\n        T_max=EPOCHS*3500*128/BATCH/schedulerStepFreq # CosineAnnealingLR\n        min_lr = 1e-4\n        gamma = (min_lr/lr)**(1/T_max)\n    \n    \n    \n    # Parameters CWT\n    cwt_params = {'fs':2048, 'lower_freq':10, 'upper_freq': 500, \n                  'n_scales':81, 'wavelet_width':1, 'stride':12, 'border_crop':0, 'train_width':True}\n    \n    useCWT = False\n    #cqt_params = {'sr':2048, 'fmin':25, 'fmax':512, 'hop_length':32, 'n_bins':69, 'bins_per_octave': 8}\n    cqt_params = {'sr':2048, 'fmin':20, 'fmax':512, 'hop_length':32, 'bins_per_octave': 12, 'filter_scale': 0.6}\n    # cqt_params = {'sr':2048, 'fmin':20, 'fmax':512, 'hop_length':32, 'bins_per_octave': 25, 'norm':1}\n    \n    BPfilter = True\n    \n    \n    \n    \n    # Post Proc Option\n    PREPROC = 'Q_transform'\n    \n    # scale:linear or log\n    SCALE = 'linear'\n    \n    DEBUG = False\n    \n    SMALL_TRAIN_SET = False\n    \n    seed = 42\n    \n    model_name = 'tf_efficientnet_b0' #'tf_efficientnet_b4' #'efficientnet-b7'\n    pretrained = True\n    unfreezeStep = 5 # set 0 for no freezing\n    \n    useSoftLabels = True\n    useTestLabels = False\n    \n    NORM_MODE = 'global_channel' # 'global' or 'local' or 'local_std' or 'global_channel'\n    \n    DENOISE = False\n    \n    image_size = (101,201)\n    \n    \nif CFG.DEBUG:\n    CFG.EPOCHS = 2\n    train_df = train_df.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\nelif CFG.SMALL_TRAIN_SET:\n    CFG.EPOCHS = 4\n    train_df = train_df.sample(n=CFG.BATCH*500, random_state=CFG.seed).reset_index(drop=True)\nelif CFG.WARM_START:\n    CFG.EPOCHS = 3\n    CFG.lr = 1e-3\n    CFG.useTestLabels = True\n    if CFG.scheduler == 'CosineAnnealingLR':\n        # scheduler_params\n        CFG.schedulerStepFreq = 10\n        CFG.T_max=CFG.EPOCHS*4200*128/CFG.BATCH/CFG.schedulerStepFreq # CosineAnnealingLR\n        CFG.min_lr=1e-7\n    \n\nif not CFG.pretrained:\n    unfreezeStep = 5\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.524835Z","iopub.execute_input":"2021-09-06T06:08:48.525166Z","iopub.status.idle":"2021-09-06T06:08:48.538317Z","shell.execute_reply.started":"2021-09-06T06:08:48.525137Z","shell.execute_reply":"2021-09-06T06:08:48.537174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\ndef set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.539875Z","iopub.execute_input":"2021-09-06T06:08:48.540266Z","iopub.status.idle":"2021-09-06T06:08:48.553267Z","shell.execute_reply.started":"2021-09-06T06:08:48.540232Z","shell.execute_reply":"2021-09-06T06:08:48.552469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CWT\n\nhttps://www.kaggle.com/anjum48/continuous-wavelet-transform-cwt-in-pytorch/notebook","metadata":{}},{"cell_type":"code","source":"#!pip install torch --upgrade --quiet","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.55512Z","iopub.execute_input":"2021-09-06T06:08:48.555373Z","iopub.status.idle":"2021-09-06T06:08:48.567136Z","shell.execute_reply.started":"2021-09-06T06:08:48.555348Z","shell.execute_reply":"2021-09-06T06:08:48.56621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pywt\nimport torch\nimport torch.nn as nn\nfrom scipy import signal\nfrom scipy import optimize\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom IPython.display import Image\n\nINPUT_PATH = Path(\"../input/g2net-gravitational-wave-detection/\")","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.569261Z","iopub.execute_input":"2021-09-06T06:08:48.569534Z","iopub.status.idle":"2021-09-06T06:08:48.577492Z","shell.execute_reply.started":"2021-09-06T06:08:48.569503Z","shell.execute_reply":"2021-09-06T06:08:48.57685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From https://github.com/tomrunia/PyTorchWavelets/blob/master/wavelets_pytorch/wavelets.py\nclass Morlet(object):\n    def __init__(self, w0=6):\n        \"\"\"w0 is the nondimensional frequency constant. If this is\n        set too low then the wavelet does not sample very well: a\n        value over 5 should be ok; Terrence and Compo set it to 6.\n        \"\"\"\n        self.w0 = w0\n        if w0 == 6:\n            # value of C_d from TC98\n            self.C_d = 0.776\n\n    def __call__(self, *args, **kwargs):\n        return self.time(*args, **kwargs)\n\n    def time(self, t, s=1.0, complete=True):\n        \"\"\"\n        Complex Morlet wavelet, centred at zero.\n        Parameters\n        ----------\n        t : float\n            Time. If s is not specified, this can be used as the\n            non-dimensional time t/s.\n        s : float\n            Scaling factor. Default is 1.\n        complete : bool\n            Whether to use the complete or the standard version.\n        Returns\n        -------\n        out : complex\n            Value of the Morlet wavelet at the given time\n        See Also\n        --------\n        scipy.signal.gausspulse\n        Notes\n        -----\n        The standard version::\n            pi**-0.25 * exp(1j*w*x) * exp(-0.5*(x**2))\n        This commonly used wavelet is often referred to simply as the\n        Morlet wavelet.  Note that this simplified version can cause\n        admissibility problems at low values of `w`.\n        The complete version::\n            pi**-0.25 * (exp(1j*w*x) - exp(-0.5*(w**2))) * exp(-0.5*(x**2))\n        The complete version of the Morlet wavelet, with a correction\n        term to improve admissibility. For `w` greater than 5, the\n        correction term is negligible.\n        Note that the energy of the return wavelet is not normalised\n        according to `s`.\n        The fundamental frequency of this wavelet in Hz is given\n        by ``f = 2*s*w*r / M`` where r is the sampling rate.\n        \"\"\"\n        w = self.w0\n\n        x = t / s\n\n        output = np.exp(1j * w * x)\n\n        if complete:\n            output -= np.exp(-0.5 * (w ** 2))\n\n        output *= np.exp(-0.5 * (x ** 2)) * np.pi ** (-0.25)\n\n        return output\n\n    # Fourier wavelengths\n    def fourier_period(self, s):\n        \"\"\"Equivalent Fourier period of Morlet\"\"\"\n        return 4 * np.pi * s / (self.w0 + (2 + self.w0 ** 2) ** 0.5)\n\n    def scale_from_period(self, period):\n        \"\"\"\n        Compute the scale from the fourier period.\n        Returns the scale\n        \"\"\"\n        # Solve 4 * np.pi * scale / (w0 + (2 + w0 ** 2) ** .5)\n        #  for s to obtain this formula\n        coeff = np.sqrt(self.w0 * self.w0 + 2)\n        return (period * (coeff + self.w0)) / (4.0 * np.pi)\n\n    # Frequency representation\n    def frequency(self, w, s=1.0):\n        \"\"\"Frequency representation of Morlet.\n        Parameters\n        ----------\n        w : float\n            Angular frequency. If `s` is not specified, i.e. set to 1,\n            this can be used as the non-dimensional angular\n            frequency w * s.\n        s : float\n            Scaling factor. Default is 1.\n        Returns\n        -------\n        out : complex\n            Value of the Morlet wavelet at the given frequency\n        \"\"\"\n        x = w * s\n        # Heaviside mock\n        Hw = np.array(w)\n        Hw[w <= 0] = 0\n        Hw[w > 0] = 1\n        return np.pi ** -0.25 * Hw * np.exp((-((x - self.w0) ** 2)) / 2)\n\n    def coi(self, s):\n        \"\"\"The e folding time for the autocorrelation of wavelet\n        power at each scale, i.e. the timescale over which an edge\n        effect decays by a factor of 1/e^2.\n        This can be worked out analytically by solving\n            |Y_0(T)|^2 / |Y_0(0)|^2 = 1 / e^2\n        \"\"\"\n        return 2 ** 0.5 * s\n\n\nclass CWT(nn.Module):\n    def __init__(\n        self,\n        dj=0.0625,\n        dt=1 / 2048,\n        fmin: int = 20,\n        fmax: int = 500,\n        output_format=\"Magnitude\",\n        trainable=False,\n        padding = 0,\n        stride = (1,1)\n    ):\n        super().__init__()\n        self.wavelet = Morlet()\n\n        self.dt = dt\n        self.dj = dj\n        self.fmin = fmin\n        self.fmax = fmax\n        self.output_format = output_format\n        self.trainable = trainable  # TODO make kernel a trainable parameter\n        self.stride = stride  # Strides > 1 not yet supported\n        self.padding = padding\n\n        self._scale_minimum = self.compute_minimum_scale()\n\n        self.signal_length = None\n        self._channels = None\n\n        self._scales = None\n        self._kernel = None\n        self._kernel_real = None\n        self._kernel_imag = None\n\n    def compute_optimal_scales(self):\n        \"\"\"\n        Determines the optimal scale distribution (see. Torrence & Combo, Eq. 9-10).\n        :return: np.ndarray, collection of scales\n        \"\"\"\n        if self.signal_length is None:\n            raise ValueError(\n                \"Please specify signal_length before computing optimal scales.\"\n            )\n        J = int(\n            (1 / self.dj) * np.log2(self.signal_length * self.dt / self._scale_minimum)\n        )\n        scales = self._scale_minimum * 2 ** (self.dj * np.arange(0, J + 1))\n\n        # Remove high and low frequencies\n        frequencies = np.array([1 / self.wavelet.fourier_period(s) for s in scales])\n        if self.fmin:\n            frequencies = frequencies[frequencies >= self.fmin]\n            scales = scales[0 : len(frequencies)]\n        if self.fmax:\n            frequencies = frequencies[frequencies <= self.fmax]\n            scales = scales[len(scales) - len(frequencies) : len(scales)]\n\n        return scales\n\n    def compute_minimum_scale(self):\n        \"\"\"\n        Choose s0 so that the equivalent Fourier period is 2 * dt.\n        See Torrence & Combo Sections 3f and 3h.\n        :return: float, minimum scale level\n        \"\"\"\n        dt = self.dt\n\n        def func_to_solve(s):\n            return self.wavelet.fourier_period(s) - 2 * dt\n\n        return optimize.fsolve(func_to_solve, 1)[0]\n\n    def _build_filters(self):\n        self._filters = []\n        for scale_idx, scale in enumerate(self._scales):\n            # Number of points needed to capture wavelet\n            M = 10 * scale / self.dt\n            # Times to use, centred at zero\n            t = torch.arange((-M + 1) / 2.0, (M + 1) / 2.0) * self.dt\n            if len(t) % 2 == 0:\n                t = t[0:-1]  # requires odd filter size\n            # Sample wavelet and normalise\n            norm = (self.dt / scale) ** 0.5\n            filter_ = norm * self.wavelet(t, scale)\n            self._filters.append(torch.conj(torch.flip(filter_, [-1])))\n\n        self._pad_filters()\n\n    def _pad_filters(self):\n        filter_len = self._filters[-1].shape[0]\n        padded_filters = []\n\n        for f in self._filters:\n            pad = (filter_len - f.shape[0]) // 2\n            padded_filters.append(nn.functional.pad(f, (pad, pad)))\n\n        self._filters = padded_filters\n\n    def _build_wavelet_bank(self):\n        \"\"\"This function builds a 2D wavelet filter using wavelets at different scales\n\n        Returns:\n            tensor: Tensor of shape (num_widths, 1, channels, filter_len)\n        \"\"\"\n        self._build_filters()\n        wavelet_bank = torch.stack(self._filters)\n        wavelet_bank = wavelet_bank.view(\n            wavelet_bank.shape[0], 1, 1, wavelet_bank.shape[1]\n        )\n        return wavelet_bank\n\n    def forward(self, x):\n        \"\"\"Compute CWT arrays from a batch of multi-channel inputs\n\n        Args:\n            x (torch.tensor): Tensor of shape (batch_size, channels, time)\n\n        Returns:\n            torch.tensor: Tensor of shape (batch_size, channels, widths, time)\n        \"\"\"\n        if self.signal_length is None:\n            self.signal_length = x.shape[-1]\n            self.channels = x.shape[-2]\n            self._scales = self.compute_optimal_scales()\n            self._kernel = self._build_wavelet_bank()\n\n            if self._kernel.is_complex():\n                self._kernel_real = self._kernel.real\n                self._kernel_imag = self._kernel.imag\n\n        x = x.unsqueeze(1)\n\n        if self._kernel.is_complex():\n            if (\n                x.dtype != self._kernel_real.dtype\n                or x.device != self._kernel_real.device\n            ):\n                self._kernel_real = self._kernel_real.to(device=x.device, dtype=x.dtype)\n                self._kernel_imag = self._kernel_imag.to(device=x.device, dtype=x.dtype)\n\n            output_real = nn.functional.conv2d(\n                x, self._kernel_real, padding=self.padding, stride=self.stride\n            )\n            output_imag = nn.functional.conv2d(\n                x, self._kernel_imag, padding=self.padding, stride=self.stride\n            )\n            output_real = torch.transpose(output_real, 1, 2)\n            output_imag = torch.transpose(output_imag, 1, 2)\n\n            if self.output_format == \"Magnitude\":\n                return torch.sqrt(output_real ** 2 + output_imag ** 2)\n            else:\n                return torch.stack([output_real, output_imag], -1)\n\n        else:\n            if x.device != self._kernel.device:\n                self._kernel = self._kernel.to(device=x.device, dtype=x.dtype)\n\n            output = nn.functional.conv2d(\n                x, self._kernel, padding=self.padding, stride=self.stride\n            )\n            return torch.transpose(output, 1, 2)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.578561Z","iopub.execute_input":"2021-09-06T06:08:48.578933Z","iopub.status.idle":"2021-09-06T06:08:48.613786Z","shell.execute_reply.started":"2021-09-06T06:08:48.578905Z","shell.execute_reply":"2021-09-06T06:08:48.613047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data retrieving and related functions","metadata":{}},{"cell_type":"code","source":"from scipy import signal \n\nfrom scipy import signal\n\nbHP, aHP = signal.butter(8, (20, 500), btype='bandpass', fs= 2048)\ndef filterSig(waves, a=aHP, b=bHP, axis = 1):\n    '''Apply a 20Hz high pass filter to the three events'''\n    if not CFG.BPfilter:\n        return waves\n    return signal.filtfilt(b, a, waves, axis = axis) #lfilter introduces a larger spike around 20hz\n\nclass DataRetriever(torch_data.Dataset):\n    def __init__(self, paths, targets):\n        self.paths = paths\n        self.targets = targets\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __get_qtransform(self, x):\n        # image = x / np.max(x,axis=1,keepdims = True)\n        image = x/(2.8679e-20)\n        if CFG.DEBUG:\n            image = filterSig(image).copy()\n        # image = image / np.max(np.abs(image),axis=1,keepdims = True)\n        # image is [chan x time]\n        image = torch.tensor(image).float()\n        return image\n\n    \n    def __getitem__(self, index):\n        #file_path = convert_image_id_2_path(self.paths[index])\n        file_path = self.paths[index]\n        x = np.load(file_path)\n        image = self.__get_qtransform(x)\n        \n        y = torch.tensor(self.targets[index], dtype=torch.float)\n            \n        return {\"X\": image, \"y\": y}\n    \n    \nclass TestDataRetriever(torch_data.Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n        \n        self.q_transform = CQT1992v2(\n            sr=2048, fmin=20, fmax=1024, hop_length=32\n        ) if CFG.PREPROC == 'Q_transform' else None\n        \n          \n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __get_qtransform(self, x):\n        image = x/(2.8679e-20)\n        # image = x / np.max(x,axis=1,keepdims = True)\n        if CFG.DEBUG:\n            image = filterSig(image).copy()\n        # image = image / np.max(np.abs(image),axis=1,keepdims = True)\n        # image is [chan x time]\n        image = torch.tensor(image).float()\n        return image\n    \n    def __getitem__(self, index):\n        # file_path = convert_image_id_2_path(self.paths[index], is_train=False)\n        file_path = self.paths[index]\n        x = np.load(file_path)\n        image = self.__get_qtransform(x)\n            \n        return {\"X\": image, \"id\": self.paths[index]}","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.614842Z","iopub.execute_input":"2021-09-06T06:08:48.615256Z","iopub.status.idle":"2021-09-06T06:08:48.635176Z","shell.execute_reply.started":"2021-09-06T06:08:48.615228Z","shell.execute_reply":"2021-09-06T06:08:48.634389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if True:\n    Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n    for n, (train_index, val_index) in enumerate(Fold.split(train_df, train_df['target'])):\n        train_df.loc[val_index, 'fold'] = int(n)\n    train_df['fold'] = train_df['fold'].astype(int)\n    display(train_df.groupby(['fold', 'target']).size())\n\n    df_train = train_df.loc[train_df['fold'] != CFG.fold,:]\n    df_valid= train_df.loc[train_df['fold'] == CFG.fold,:]\nelse:\n    df_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.2, \n    random_state=42, \n    stratify=train_df[\"target\"],\n    )\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.636201Z","iopub.execute_input":"2021-09-06T06:08:48.636595Z","iopub.status.idle":"2021-09-06T06:08:48.950228Z","shell.execute_reply.started":"2021-09-06T06:08:48.636567Z","shell.execute_reply":"2021-09-06T06:08:48.949313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_true = train_df.loc[train_df.target == 1]\ntrain_df_false = train_df.loc[train_df.target == 0]\ndisplay(train_df_true.groupby('fold').mean())\ndisplay(train_df_false.groupby('fold').mean())","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:48.951311Z","iopub.execute_input":"2021-09-06T06:08:48.95172Z","iopub.status.idle":"2021-09-06T06:08:49.058668Z","shell.execute_reply.started":"2021-09-06T06:08:48.95169Z","shell.execute_reply":"2021-09-06T06:08:49.057753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    return \"../input/g2net-gravitational-wave-detection/train/{}/{}/{}/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ndef get_test_file_path(image_id):\n    return \"../input/g2net-gravitational-wave-detection/test/{}/{}/{}/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)\n\ndf_train['file_path'] = df_train['id'].apply(get_train_file_path)\ndf_valid['file_path'] = df_valid['id'].apply(get_train_file_path)\n\nsubmission['file_path'] = submission['id'].apply(get_test_file_path)\n\nsubmission_8748 = pd.read_csv('../input/submission-08748/submission.csv')\nsubmission_8748['file_path'] = submission_8748['id'].apply(get_test_file_path)\n\nif CFG.useTestLabels:\n    submission_8748['soft_target'] = submission_8748['target']#0.5*(submission_8748['target']+np.round(submission_8748['target']))\n    tmp_df_0 = submission_8748.loc[submission_8748['target']<0.25,:]\n    tmp_df_1 = submission_8748.loc[submission_8748['target']>0.9,:]\n    print('No. test negatives selected: '+str(len(tmp_df_0)))\n    print('No. test positives selected: '+str(len(tmp_df_1)))\n    \n    print('Train size: '+str(len(df_train)))\n    if CFG.SMALL_TRAIN_SET:\n        tmp_df_0 = tmp_df_0.head(CFG.BATCH*50)\n        tmp_df_1 = tmp_df_1.head(CFG.BATCH*50)\n    else:\n        tmp_df_0 = tmp_df_0.head(44800) # 128*300\n        tmp_df_1 = tmp_df_1.head(44800)\n    print(tmp_df_0.head())\n    df_train = df_train.append(tmp_df_0)\n    df_train = df_train.append(tmp_df_1).sample(frac=1)\n    df_train['target'] = df_train['target'].clip(lower = 0., upper = 1.)\n    print('Train size with test: '+str(len(df_train)))\n\n\ntrain_data_retriever = DataRetriever(\n    df_train['file_path'].values, \n    df_train[\"target\"].values, \n)\n\ntrain_data_retriever_soft = DataRetriever(\n    df_train['file_path'].values, \n    df_train[\"soft_target\"].values, \n)\n\nvalid_data_retriever = DataRetriever(\n    df_valid['file_path'].values, \n    df_valid[\"target\"].values,\n)\n\ntest_data_retriever = TestDataRetriever(\n    submission[\"file_path\"].values, \n)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:49.05989Z","iopub.execute_input":"2021-09-06T06:08:49.060482Z","iopub.status.idle":"2021-09-06T06:08:49.994605Z","shell.execute_reply.started":"2021-09-06T06:08:49.060439Z","shell.execute_reply":"2021-09-06T06:08:49.993727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch_data.DataLoader(\n    train_data_retriever,\n    batch_size=CFG.BATCH,\n    shuffle=True,\n    num_workers=12,\n    drop_last = True\n)\n\ntrain_loader_soft = torch_data.DataLoader(\n    train_data_retriever_soft,\n    batch_size=CFG.BATCH,\n    shuffle=True,\n    num_workers=12,\n    drop_last = True\n)\n\nvalid_loader = torch_data.DataLoader(\n    valid_data_retriever, \n    batch_size=512,\n    shuffle=False,\n    num_workers=8,\n)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=512,\n    shuffle=False,\n    num_workers=8,\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:49.996072Z","iopub.execute_input":"2021-09-06T06:08:49.996459Z","iopub.status.idle":"2021-09-06T06:08:50.023433Z","shell.execute_reply.started":"2021-09-06T06:08:49.996418Z","shell.execute_reply":"2021-09-06T06:08:50.022087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Different heads\n\nclass BasicHead(nn.Module):   \n    def __init__(self,n_features):\n        super().__init__()\n        self.classifier = nn.Sequential(\n          nn.Dropout(0.5),\n          nn.Linear(in_features=n_features, out_features=256, bias=True),\n          nn.ReLU(),\n          # nn.Dropout(0.5), # p is probability of zeroing\n          nn.Linear(in_features=256, out_features=1, bias=True),\n        )\n        \n    def forward(self,x):\n        return self.classifier(x)\n    \nclass MultiDropoutHead(nn.Module):\n    def __init__(self,n_features):\n        super().__init__()\n        if False:\n            self.classifier = nn.Sequential(\n              nn.Linear(in_features=n_features, out_features=256, bias=True),\n              nn.ReLU(),\n              # nn.Dropout(0.5), # p is probability of zeroing\n              nn.Linear(in_features=256, out_features=1, bias=True),\n            )\n        else:\n            self.classifier = nn.Linear(in_features=n_features, out_features=1, bias=True)\n        self.dropout = lambda p: nn.Dropout(p)\n        \n    def forward(self,x):\n        return torch.mean(torch.stack([\n            self.classifier(self.dropout(p)(x))\n            for p in np.linspace(0.3, 0.7, 5)\n        ], dim=0), dim=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:08:50.025476Z","iopub.execute_input":"2021-09-06T06:08:50.025891Z","iopub.status.idle":"2021-09-06T06:08:50.036377Z","shell.execute_reply.started":"2021-09-06T06:08:50.025846Z","shell.execute_reply":"2021-09-06T06:08:50.035402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef whiten(signal):\n    # From here: https://www.kaggle.com/kevinmcisaac/g2net-spectral-whitening\n    length = signal.size(2)\n    hann = torch.hann_window(length, periodic=True, dtype=float).view(1,1,-1)\n    spec = fft(signal* hann, dim = 2)\n    mag = torch.sqrt(torch.real(spec*torch.conj(spec))) \n\n    return torch.real(ifft(spec/mag)) * np.sqrt(length/2)\n\ndef batch_preprocessing(X):\n    # X = whiten(X)\n    X = X.numpy()\n    if CFG.BPfilter:        \n        X = filterSig(X,axis=2).copy()\n    X = torch.tensor(X).float()\n    return X      \n        \n\nHead = MultiDropoutHead#BasicHead\n\nmodel_no = 1\n\ndef Backbone():\n    if 'tf_efficientnet' in CFG.model_name:\n        model = timm.create_model(CFG.model_name, pretrained=CFG.pretrained, \n                                  drop_path_rate = 0.4 if CFG.useTestLabels else 0.,\n                                  in_chans = 6 if CFG.useCWT else 3)\n        n_features = model.classifier.in_features\n        model.classifier = nn.Identity()\n    elif 'efficientnet-' in CFG.model_name:\n        model = efficientnet_pytorch.EfficientNet.from_pretrained(CFG.model_name)\n        n_features = model._fc.in_features\n        model._fc = nn.Identity()\n    elif 'rexnet_' in CFG.model_name:\n        model = timm.create_model(CFG.model_name, pretrained=CFG.pretrained)\n        n_features = model.head.fc.in_features\n        model.head.fc = nn.Identity()\n        \n    return model, n_features\n\nclass Transform:\n    \n    def __init__(self,useCWT = CFG.useCWT):\n        self.q_transform = CQT1992v2(\n                **CFG.cqt_params\n            ).to(device)\n        self.useCWT =  useCWT\n        if self.useCWT:\n            self.pycwt = CWT(fmin=20, fmax=512, stride = (1,26)).to(device)\n        self.nH = 75\n        self.resize = torchvision.transforms.Resize(CFG.image_size)\n        \n        if CFG.DENOISE:\n            masks = np.load('../input/g2netmasks/masks.npy')\n            self.masks = torch.tensor(masks,dtype = torch.float32).to(device)\n            self.masks = (self.masks*20)+1\n            self.normalize = torchvision.transforms.Normalize((0.0782925,0.07827569,0.07719089),\n                                                              (0.03546559,0.03547181,0.0346077))\n        else:\n            #mean = (-0.49382125+0.5,-0.49382148+0.5,-0.49036058+0.5)\n            #std = (0.00531079,0.00531216,0.00816139)\n            mean = (0.00776412,0.00775545,0.01362684)\n            std = (0.00917761,0.00914989,0.01805867)\n            self.normalize = torchvision.transforms.Normalize(mean,\n                                                          std)\n            self.normalize_cwt = torchvision.transforms.Normalize((0.00469631,0.00469434,0.00796551),\n                                                                  (0.00338371,0.00338833,0.00668454))\n            \n    def transform(self,x):\n        if CFG.NORM_MODE == 'local':\n            x = x/torch.amax(x, dim = (1,2), keepdim = True)\n        if self.useCWT:\n            x_cwt = self.pycwt(x)\n        batch_size = x.size(0)\n        x = torch.reshape(x,(batch_size*3,-1))\n        x = self.q_transform(x)\n        size = list(x.size())\n        x = torch.reshape(x,(batch_size,3,size[1],size[2]))\n        x = self.resize(x)\n        x = x[:,:,np.arange(CFG.image_size[0]-1,-1,-1),:]\n        if CFG.DENOISE:\n            x =  x/(self.masks)\n        if CFG.SCALE == 'log':\n            x = (torch.log10(x) + 1.)/1.5\n        else:\n            if CFG.NORM_MODE == 'global':\n                x = (x + 0.4926)/np.sqrt(5.33e-5)\n            elif CFG.NORM_MODE == 'local':\n                xmin = torch.amin(x, dim = (1,2,3), keepdim = True)\n                xmax = torch.amax(x, dim = (1,2,3), keepdim = True)\n                x = (x-xmin)/(xmax-xmin)\n            elif CFG.NORM_MODE == 'local_std':\n                xmean = torch.mean(x, dim = (1,2,3), keepdim = True)\n                xstd = torch.std(x, dim = (1,2,3), keepdim = True)\n                x = (x-xmean)/(xstd)\n            elif CFG.NORM_MODE == 'global_channel':\n                x = self.normalize(x)\n            elif CFG.NORM_MODE == 'global_channel_local':\n                x = self.normalize(x)\n                xmean = torch.mean(x, dim = (1,2,3), keepdim = True)\n                xstd = torch.std(x, dim = (1,2,3), keepdim = True)\n                x = (x-xmean)/(xstd)\n                \n        if self.useCWT:\n            if CFG.NORM_MODE == 'global':\n                x_cwt = (x_cwt - 0.00579486)/np.sqrt(2.57e-5)\n            elif CFG.NORM_MODE == 'local':\n                xmin = torch.amin(x_cwt, dim = (1,2,3), keepdim = True)\n                xmax = torch.amax(x_cwt, dim = (1,2,3), keepdim = True)\n                x_cwt = (x_cwt-xmin)/(xmax-xmin)\n            elif CFG.NORM_MODE == 'local_std':\n                xmean = torch.mean(x_cwt, dim = (1,2,3), keepdim = True)\n                xstd = torch.std(x_cwt, dim = (1,2,3), keepdim = True)\n                x_cwt = (x_cwt-xmean)/(xstd)\n            elif CFG.NORM_MODE == 'global_channel':\n                x_cwt = self.normalize_cwt(x_cwt)\n            x = torch.cat((x,x_cwt),dim=1)\n        return x\n        \n\nif model_no == 1:\n    print('Selecting multi channel model ... ')\n    class Model(nn.Module):\n        def __init__(self, get_spectrogram = False):\n            self.get_spectrogram = get_spectrogram\n            super().__init__()\n            self.q_transform = CQT1992v2(\n                **CFG.cqt_params\n            )\n            self.transform = Transform()\n            if not self.get_spectrogram:\n                \n                self.model, n_features = Backbone()\n                self.head = Head(n_features)\n\n        def freezeModel(self):\n            for param in self.model.parameters():\n                param.requires_grad = False\n\n        def unfreezeModel(self):\n            for param in self.model.parameters():\n                param.requires_grad = True\n\n        def forward(self, x):\n            # reshape from [batch by chan by time] [(batch x chan) by time]\n            \n            # x = torch.divide(x,torch.max(torch.abs(x),dim=2,keepdims = True)[0])\n            x = self.transform.transform(x)\n                #x = torch.divide(x,torch.mean(x,dim=2,keepdims = True))\n            if self.get_spectrogram:\n                return x\n            x = self.model(x)\n            out = self.head(x)\n            return out\nelif model_no == 2:        \n    print('Selecting single channel model ... ')\n    \n    class Model(nn.Module):\n        def __init__(self, get_spectrogram = False):\n            self.get_spectrogram = get_spectrogram\n            super().__init__()\n            self.q_transform = CQT1992v2(\n                **CFG.cqt_params\n            )\n            if not self.get_spectrogram:\n                self.model, n_features = Backbone()\n                self.head = Head(n_features)\n\n        def freezeModel(self):\n            for param in self.model.parameters():\n                param.requires_grad = False\n\n        def unfreezeModel(self):\n            for param in self.model.parameters():\n                param.requires_grad = True\n\n        def forward(self, x):\n            # reshape from [batch by chan by time] [(batch x chan) by time]\n            batch_size = x.size(0)\n\n            x = torch.divide(x,torch.max(torch.abs(x),dim=2,keepdims = True)[0])\n            x = torch.reshape(x,(batch_size*3,-1))\n            x = self.q_transform(x)\n            x = x[:,0:-1,0:-1]\n            if CFG.SCALE == 'log':\n                x = (torch.log10(x) + 1.)/1.5\n            else:\n                x = torch.clamp(x,max=2.5)-1\n            if self.get_spectrogram:\n                size = list(x.size())\n                x = torch.reshape(x,(batch_size,3,size[1],size[2]))\n                return x\n            \n            x = torch.unsqueeze(x,1)\n            \n            # x_mean = torch.mean(x,dim=1,keepdims = True)\n            # x = torch.stack([x,x_mean],dim=1)\n            \n            x = self.model(x)\n            size = list(x.size())\n            x = torch.reshape(x,(batch_size,-1,size[1]))\n            x = torch.max(x,dim=1,keepdims = False)[0]\n            out = self.head(x)\n            out = out\n            return out\n        \nelif model_no == 3:\n    print('Selecting experimental model ... ')\n    class Model(nn.Module):\n        def __init__(self, get_spectrogram = False):\n            self.get_spectrogram = get_spectrogram\n            super().__init__()\n            self.q_transform = CQT1992v2(\n                **CFG.cqt_params\n            )\n            if not self.get_spectrogram:\n                self.model, n_features = Backbone()\n                self.head = Head(2*n_features)\n\n        def freezeModel(self):\n            for param in self.model.parameters():\n                param.requires_grad = False\n\n        def unfreezeModel(self):\n            for param in self.model.parameters():\n                param.requires_grad = True\n\n        def forward(self, x):\n            # reshape from [batch by chan by time] [(batch x chan) by time]\n            batch_size = x.size(0)\n\n            x = torch.divide(x,torch.max(torch.abs(x),dim=2,keepdims = True)[0])\n            x = torch.reshape(x,(batch_size*3,-1))\n            x = self.q_transform(x)\n            x = x[:,0:-1,0:-1]\n            if CFG.SCALE == 'log':\n                x = (torch.log10(x) + 1.)/1.5\n            else:\n                x = torch.clamp(x,max=2.5)-1\n            if self.get_spectrogram:\n                size = list(x.size())\n                x = torch.reshape(x,(batch_size,3,size[1],size[2]))\n                return x\n            \n            x = torch.unsqueeze(x,1)\n            \n            size = list(x.size())\n            x = torch.reshape(x,(batch_size,3,size[2],size[3]))\n            x_mean = torch.mean(x,dim=1,keepdims = True)\n            x = torch.cat([x,x_mean],dim=1)\n            x = torch.reshape(x,(batch_size*4,1,size[2],size[3]))\n            \n            x = self.model(x)\n            size = list(x.size())\n            x = torch.reshape(x,(batch_size,-1,size[1]))\n            x_mean = x[:,3,:].squeeze(1)\n            x = torch.max(x,dim=1,keepdims = False)[0]\n            # this will be [batch by (2 x n_features)]\n            x = torch.cat([x,x_mean],dim=1)\n            \n            out = self.head(x)\n            out = out\n            return out\n    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:15:01.450778Z","iopub.execute_input":"2021-09-06T06:15:01.451181Z","iopub.status.idle":"2021-09-06T06:15:01.498516Z","shell.execute_reply.started":"2021-09-06T06:15:01.45115Z","shell.execute_reply":"2021-09-06T06:15:01.497051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if False:\n    masks = np.load('../input/g2netmasks/masks.npy')\n    masks = masks*0.9+0.1\n    for i in range(3):\n        plt.figure()\n        plt.title('Channel ' + str(i) + '; Target = '+ str(targets[n]))\n        plt.imshow(np.mean(masks[:,i,:,:],axis=0).squeeze())\n        plt.colorbar()\n        #plt.clim([0.1,1])","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:15:01.50017Z","iopub.execute_input":"2021-09-06T06:15:01.500455Z","iopub.status.idle":"2021-09-06T06:15:01.51536Z","shell.execute_reply.started":"2021-09-06T06:15:01.500429Z","shell.execute_reply":"2021-09-06T06:15:01.514228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if True:\n    modelTmp = Model(get_spectrogram = True)\n    tmp = np.zeros([0,3 if not CFG.useCWT else 6,CFG.image_size[0],CFG.image_size[1]])\n    for step, batch in enumerate(train_loader,1):\n        X = batch[\"X\"]\n        y = batch[\"y\"]\n        print(torch.max(X))\n        X = batch_preprocessing(X)\n        modelTmp.to(device)\n        X = X.to(device)\n        targets = batch[\"y\"].to(device)\n        outputs = modelTmp(X)\n        print(outputs.size())\n        n = np.random.randint(32)\n        import matplotlib.pyplot as plt\n        # tmp = outputs[n].cpu().numpy()\n        tmp = np.concatenate((tmp,outputs.cpu().numpy()[y.numpy()==0,:,:,:]),axis = 0)\n        if step == 20:\n            break\n    count = np.cumsum(np.size(tmp))\n    print('Mean = ' + str(np.sum(tmp)/count))\n    print('std = ' + str(np.sqrt(np.sum(tmp**2)/count - (np.sum(tmp)/count)**2)))\n    print('Max = ' + str(np.max(tmp)))\n    \n    print('Mean = ' + str(np.mean(tmp,axis = (0,2,3))))\n    print('std = ' + str(np.std(tmp,axis = (0,2,3))))\n    print('Max = ' + str(np.max(tmp,axis = (0,2,3))))\n    \n    for i in range(3):\n        plt.figure()\n        plt.title('Channel ' + str(i) + '; Target = '+ str(targets[n]))\n        plt.imshow(np.mean(tmp[:,i,:,:],axis=0).squeeze())\n        plt.colorbar()\n    masks = np.mean(tmp[:,:,:,:],axis=0,keepdims = True)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:15:01.636106Z","iopub.execute_input":"2021-09-06T06:15:01.636647Z","iopub.status.idle":"2021-09-06T06:15:26.670252Z","shell.execute_reply.started":"2021-09-06T06:15:01.636613Z","shell.execute_reply":"2021-09-06T06:15:26.66903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nif True:\n    \n    modelTmp = Model(get_spectrogram = True)\n    for step, batch in enumerate(train_loader_soft,1):\n        X = batch[\"X\"]\n        print(torch.max(X))\n        X = batch_preprocessing(X)\n        modelTmp.to(device)\n        X = X.to(device)\n        targets = batch[\"y\"].to(device)\n        outputs = modelTmp(X)\n        print(outputs.size())\n        n = np.random.randint(32)\n        import matplotlib.pyplot as plt\n        tmp = outputs[n].cpu().numpy()\n        count = np.cumsum(np.size(tmp))\n        print('Mean = ' + str(np.sum(tmp)/count))\n        print('std = ' + str(np.sum(tmp**2)/count - (np.sum(tmp)/count)**2))\n        for i in range(3):\n            plt.figure()\n            plt.title('Target = '+ str(targets[n]))\n            plt.imshow((tmp[i,:,:]).squeeze())\n            plt.colorbar()\n            if CFG.useCWT:\n                plt.figure()\n                plt.title('CWT: Target = '+ str(targets[n]))\n                plt.imshow((tmp[i+3,:,:]).squeeze())\n                plt.colorbar()\n        plt.figure()\n        plt.title('Target = '+ str(targets[n]))\n        plt.imshow(np.mean(tmp[:,:,:],axis=0).squeeze())\n        plt.colorbar()\n        print(tmp.shape)\n        break","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:15:26.672568Z","iopub.execute_input":"2021-09-06T06:15:26.673032Z","iopub.status.idle":"2021-09-06T06:15:32.564586Z","shell.execute_reply.started":"2021-09-06T06:15:26.672984Z","shell.execute_reply":"2021-09-06T06:15:32.563499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss related functions","metadata":{}},{"cell_type":"code","source":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n\n    def update(self, val):\n        self.n += 1\n        # incremental update\n        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n\n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().round().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update\n        self.avg = true_count / self.n + last_n / self.n * self.avg\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:15:32.566544Z","iopub.execute_input":"2021-09-06T06:15:32.566829Z","iopub.status.idle":"2021-09-06T06:15:32.574767Z","shell.execute_reply.started":"2021-09-06T06:15:32.566801Z","shell.execute_reply":"2021-09-06T06:15:32.573502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trainer related functions","metadata":{}},{"cell_type":"code","source":"def get_scheduler(optimizer):\n    if CFG.scheduler=='ReduceLROnPlateau':\n        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n    elif CFG.scheduler=='CosineAnnealingLR':\n        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n    elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n    elif CFG.scheduler == 'ExponentialLR':\n        scheduler = ExponentialLR(optimizer, gamma = CFG.gamma)\n    return scheduler\n\nclass Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion, \n        loss_meter, \n        score_meter,\n        use_swa = False\n    ):\n        self.model = model\n        # freeze model by default\n        self.model.freezeModel()\n        \n        self.device = device\n        self.use_swa = use_swa\n        self.optimizer = swa.SWA(optimizer) if self.use_swa else optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        self.scheduler = get_scheduler(optimizer)\n        self.learning_rate = self.scheduler.get_lr()\n        \n        self.best_valid_score = -np.inf\n        self.best_valid_rocauc = -np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, auc_score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"checkpoint_auc\": \"The rocauc improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n        self.training_step = 0\n        self.prevbatch = []\n        self.epoch = -1 \n    \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience,train_loader_soft = False):        \n        for n_epoch in range(1, epochs + 1):\n            gc.collect()\n            self.epoch = n_epoch\n            \n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            if self.epoch==1 or (not train_loader_soft):\n                train_loss, train_score, train_time = self.train_epoch(train_loader)\n            else:\n                train_loss, train_score, train_time = self.train_epoch(train_loader_soft)\n                \n            valid_loss, valid_score, valid_time, valid_rocauc = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, 0, train_time\n            )\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_rocauc, valid_time\n            )\n            \n            self.n_patience += 1\n            if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n                )\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n                \n            if self.best_valid_rocauc < valid_rocauc:\n                self.info_message(\n                    self.messages[\"checkpoint_auc\"], self.best_valid_rocauc, valid_rocauc, 'rocauc'+save_path\n                )\n                self.best_valid_rocauc = valid_rocauc\n                self.save_model(n_epoch, 'rocauc_'+ save_path)\n                self.n_patience = 0\n                \n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n        if self.use_swa:\n            self.optimizer.bn_update(train_loader, self.model)\n            self.optimizer.swap_swa_sgd()\n        \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(tqdm(train_loader),1):\n            \n            if self.training_step == CFG.unfreezeStep:\n                self.model.unfreezeModel()\n            \n            X = batch[\"X\"]\n            if self.prevbatch:\n                prevX = self.prevbatch[\"X\"]\n                prevY = self.prevbatch['y']\n                rndNum = np.random.rand()\n                if rndNum<0.5:\n                    # only keep prevX where there is no wave\n                    prevX = torch.where(prevY.view(-1,1,1)>0.5,X,prevX)\n                    # weight for prevX is at most 0.5, and not replaced\n                    # when there is a wave\n                    X = (1-rndNum)*X + rndNum*prevX \n\n            self.prevbatch = batch.copy()  \n            X = batch_preprocessing(X)\n            X = X.to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n\n            self.optimizer.step()\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            \n            message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}, learning_rate: {:.7e}/{:.7e}'\n            self.info_message(message, step, len(train_loader), _loss, _score, self.learning_rate[0], self.learning_rate[1],end=\"\\r\")\n            self.training_step += 1\n            \n            if self.training_step%CFG.schedulerStepFreq==0:\n                if isinstance(self.scheduler, CosineAnnealingLR):\n                    self.scheduler.step()\n                elif isinstance(self.scheduler, CosineAnnealingWarmRestarts):\n                    self.scheduler.step()\n                elif isinstance(self.scheduler, ExponentialLR):\n                    self.scheduler.step()\n                self.learning_rate = self.scheduler.get_lr()\n        # print('\\n Updated learning rate: '+ str(self.scheduler.get_lr()))\n        \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader,returnPred = False):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n        \n        for step, batch in enumerate(valid_loader, 1):\n            y_pred = []\n            tgts = []\n            with torch.no_grad():\n                X = batch[\"X\"]  \n                X = batch_preprocessing(X)\n                X = X.to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                outputs = outputs\n                y_pred.extend(torch.sigmoid(outputs).cpu().numpy().squeeze())\n                tgts.extend(batch[\"y\"].numpy())\n                    \n            rocauc = roc_auc_score(tgts,y_pred)\n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_score: {:.5f},valid_roc_auc: {:.5f}'\n            self.info_message(message, step, len(valid_loader), _loss, _score, rocauc, end=\"\\r\")\n        if not returnPred:\n            return valid_loss.avg, valid_score.avg, int(time.time() - t), rocauc\n        else:\n            return y_pred, tgts\n    \n    def test_eval(self,test_loader):\n        y_pred = []\n        ids = []\n        for e, batch in enumerate(test_loader):\n            print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n            with torch.no_grad():\n                X = batch[\"X\"]\n                X = batch_preprocessing(X)\n                X = X.to(self.device)\n                outputs = self.model(X)\n                y_pred.extend(torch.sigmoid(outputs).cpu().numpy().squeeze())\n                ids.extend(batch[\"id\"])\n        return y_pred, ids\n    \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            save_path,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:15:32.577144Z","iopub.execute_input":"2021-09-06T06:15:32.577619Z","iopub.status.idle":"2021-09-06T06:15:32.612519Z","shell.execute_reply.started":"2021-09-06T06:15:32.577542Z","shell.execute_reply":"2021-09-06T06:15:32.611257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = Model()\nmodel.to(device)\nif (not CFG.TRAIN) or CFG.WARM_START:\n    startCheckpoint = torch.load(\"../input/cqtpt2v10/best-model.pth\")\n    checkpoint = torch.load(\"../input/cqtpt2v10/best-model.pth\")\n    model.load_state_dict(startCheckpoint[\"model_state_dict\"])\n\noptimizer = torch.optim.Adam([{\"params\": model.model.parameters(), \"lr\": CFG.lr},\n                              {\"params\": model.head.parameters(), \"lr\": CFG.lr/5}], \n                             lr=CFG.lr)\ncriterion = torch_functional.binary_cross_entropy_with_logits\n\ntrainer = Trainer(\n    model, \n    device, \n    optimizer, \n    criterion, \n    LossMeter, \n    AccMeter\n)\n\nif CFG.TRAIN:\n    history = trainer.fit(\n        CFG.EPOCHS, \n        train_loader, \n        valid_loader, \n        \"best-model.pth\", \n        400,\n        train_loader_soft = train_loader_soft if CFG.useSoftLabels else False\n    )\n    \n    y_pred_val,tgts = trainer.valid_epoch(valid_loader,returnPred = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:15:32.613953Z","iopub.execute_input":"2021-09-06T06:15:32.614253Z","iopub.status.idle":"2021-09-06T06:16:45.130799Z","shell.execute_reply.started":"2021-09-06T06:15:32.614226Z","shell.execute_reply":"2021-09-06T06:16:45.127661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(tgts,y_pred_val,1)\nplt.xlabel('targets')\nplt.ylabel('predictions')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:16:45.133301Z","iopub.status.idle":"2021-09-06T06:16:45.134115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.TRAIN:\n    checkpoint = torch.load(\"best-model.pth\")\n\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel.eval();\ngc.collect()\ny_pred, ids = trainer.test_eval(test_loader)\nsubmission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\nsubmission = pd.DataFrame({\"id\": submission['id'].values, \"target\": y_pred})\nsubmission.to_csv(\"model_submission.csv\", index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:16:45.135599Z","iopub.status.idle":"2021-09-06T06:16:45.136517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.TRAIN:\n    checkpoint = torch.load(\"rocauc_best-model.pth\")\n\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel.eval();\ngc.collect()\ny_pred, ids = trainer.test_eval(test_loader)\nsubmission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\nsubmission = pd.DataFrame({\"id\": submission['id'].values, \"target\": y_pred})\nsubmission.to_csv(\"model_submission_rocauc.csv\", index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-09-06T06:16:45.137979Z","iopub.status.idle":"2021-09-06T06:16:45.138558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}