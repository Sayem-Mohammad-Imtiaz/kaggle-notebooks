{"cells":[{"metadata":{},"cell_type":"markdown","source":"**I have taken the insurance dataset to predict the charges. Here I will be using linear regression, ridge regression and lasso regression.**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing of basic libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing of the dataset as dataframe\nins_df=pd.read_csv(\"../input/insurance/insurance.csv\")\n\nins_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ins_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ins_df.age.min(),ins_df.age.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To change the age values in age column to a categorical values\nl=[]\nfor i,j in ins_df.iteritems():\n    if(i=='age'):\n        for m in range(len(j)):\n            if(j[m]<=35):\n                l.append('Young Adult')\n            elif((j[m]>=36)&(j[m]<=55)):\n                l.append('Senior Adult')\n            elif(j[m]>=56):\n                l.append('Elder')    \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To check first few elements\nl[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ins_df['age_cat']=l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ins_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heatmap showing correlation between the feature variables\nsns.heatmap(ins_df.corr(),annot=True,cmap='YlGnBu')\nplt.title(\"Correlaton between feature variables\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So, here we see that the correlation between children and the amount being paid is 0.068 which is quite high while the correlation between bmi and age are 0.2 and 0.3 which show that the variables are less correlated.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#To transform the categorical variables to dummy variables\n#And we drop one column for each categorical dummy variable\nin_df=pd.get_dummies(ins_df,drop_first=True)\n\n#To drop the age column as we have considered it as categorical variable\nin_df=in_df.drop(columns=['age'])\nin_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=in_df.drop(columns=['charges']).values\ny=in_df['charges'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting of linear regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=21)\nreg=LinearRegression()\nreg.fit(X_train,y_train)\ny_predict=reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# R-square value\nreg.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To find the coefficient and the intercept\ncoefficient=reg.coef_\nintercept=reg.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"The values of coefficient and intercept are {coefficient} and { intercept} .\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now using cross validation with n=5\nfrom sklearn.model_selection import cross_val_score\nreg=LinearRegression()\nscores=cross_val_score(reg,X,y,cv=5)\nnp.mean(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we will be using regularized regression:-**\n\n**The reson behind use of regularized regression is to regularizing the large coefficients**\n\n**1. Ridge Regression**\n\n**2. Lasso Regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge Regression\n# Hyperparameter tuning using gridsearch\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nparam_grid={'alpha':np.arange(0.1,1,0.1)}\nridge=Ridge()\nridge_cv=GridSearchCV(ridge,param_grid,cv=5)\nridge_cv.fit(X,y)\n\n#Best value of alpha parameter\nridge_cv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best score value \nridge_cv.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lasso Regression\n# Hyperparameter tuning using gridsearch\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nparam_grid={'alpha':np.arange(0.1,1,0.1)}\nlasso=Ridge()\nlasso_cv=GridSearchCV(lasso,param_grid,cv=5)\nlasso_cv.fit(X,y)\n\n#Best value of alpha parameter\nlasso_cv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_cv.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thus, we see that using both type of regularized regression we get the same results .**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#To check for alpha =0.7\n#ridge regression\nridge=Ridge(alpha=0.7)\nridge.fit(X_train,y_train)\nridge.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To find the coefficient and the intercept of ridge regression\ncoefficient=ridge.coef_\nintercept=ridge.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"The values of coefficient and intercept of ridge regression are {coefficient} and { intercept} .\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To check for alpha=0.7\n#lasso regression\nlasso=Lasso(alpha=0.7)\nlasso.fit(X_train,y_train)\nlasso.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To find the coefficient and the intercept of lasso regression\ncoefficient=lasso.coef_\nintercept=lasso.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"The values of coefficient and intercept for lasso regression are {coefficient} and { intercept} .\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thus we see that the coefficient as well as intercept values are less for the regularized regression i.e. ridge gegression as well as lasso regression as compared to the linear regression with the exception of 1st coefficient for the ridge regression which is more then 1st coefficient of the linear regression**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}