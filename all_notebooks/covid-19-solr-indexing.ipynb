{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Install and import relevant libraries\n!python -m easy_install ../input/compiledlucene/bk/lucene-8.1.1-py3.6-linux-x86_64.egg\n!cp -r ../input/compiledlucene/bk/JCC-3.7-py3.6-linux-x86_64.egg /opt/conda/lib/python3.6/site-packages/\nimport sys\nsys.path\nsys.path.append('/opt/conda/lib/python3.6/site-packages/JCC-3.7-py3.6-linux-x86_64.egg')\nsys.path.append('/opt/conda/lib/python3.6/site-packages/lucene-8.1.1-py3.6-linux-x86_64.egg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this kernel, we provide an installation/ configuration/ compilation package for PyLucene 8.1.1 as an external data called “compiledlucene” which provide all required software dependencies for installation and deployment of PyLucene. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys, os, lucene, threading, time\nfrom datetime import datetime\nfrom java.nio.file import Paths\nfrom org.apache.lucene.analysis.miscellaneous import LimitTokenCountAnalyzer\nfrom org.apache.lucene.document import Document, Field, FieldType\nfrom org.apache.lucene.index import FieldInfo, IndexWriter, IndexWriterConfig, IndexOptions\nfrom org.apache.lucene.analysis.standard import StandardAnalyzer\nfrom org.apache.lucene.index import DirectoryReader\nfrom org.apache.lucene.queryparser.classic import QueryParser\nfrom org.apache.lucene.store import SimpleFSDirectory\nfrom org.apache.lucene.search import IndexSearcher\nimport pandas as pd\n\nLUCENE_INDEX_DIR = \"documentLevel\"\nLUCENE_BASE_DIR = \"/kaggle/working\"\n#COVID_FULLTEXT_DF = \"../input/covidfulltext/metadata_and_fulltext_2020-04-17.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport numpy as np\nimport pandas as pd\nimport bs4 as bs\nimport urllib.request\nfrom time import sleep\nimport os\nfrom IPython.display import display, HTML","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Map abstract and respective JSON data into one data frame**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk import PorterStemmer\nfrom IPython.core.display import display, HTML\nimport pandas as pd\nimport torch\nfrom transformers import *\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keep only documents with covid -cov-2 and cov2\ndef search_focus(df):\n    dfa = df[df['abstract'].str.contains('covid')]\n    dfb = df[df['abstract'].str.contains('-cov-2')]\n    dfc = df[df['abstract'].str.contains('cov2')]\n    dfd = df[df['abstract'].str.contains('ncov')]\n    frames=[dfa,dfb,dfc,dfd]\n    df = pd.concat(frames)\n    df=df.drop_duplicates(subset='title', keep=\"first\")\n    return df\n\n# load the meta data from the CSV file\n#usecols=['title','journal','abstract','authors','doi','publish_time','sha','full_text_file']\ndf=pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\nprint ('ALL CORD19 articles',df.shape)\n#fill na fields\ndf=df.fillna('no data provided')\n#drop duplicate titles\ndf = df.drop_duplicates(subset='title', keep=\"first\")\n#keep only 2020 dated papers\ndf=df[df['publish_time'].str.contains('2020')]\n# convert abstracts to lowercase\ndf[\"abstract\"] = df[\"abstract\"].str.lower()+df[\"title\"].str.lower()\n#show 5 lines of the new dataframe\n#df=search_focus(df)\nprint ('Keep only COVID-19 related articles',df.shape)\n\nimport os\nimport json\nfrom pprint import pprint\nfrom copy import deepcopy\nimport math\n\n\ndef format_body(body_text):\n    texts = [(di['section'], di['text']) for di in body_text]\n    texts_di = {di['section']: \"\" for di in body_text}\n    \n    for section, text in texts:\n        texts_di[section] += text\n\n    body = \"\"\n\n    for section, text in texts_di.items():\n        body += section\n        body += \"\\n\\n\"\n        body += text\n        body += \"\\n\\n\"\n    \n    return body\n\n\nfor index, row in df.iterrows():\n    #print (row['pdf_json_files'])\n    if 'no data provided' not in row['pdf_json_files'] and os.path.exists('/kaggle/input/CORD-19-research-challenge/'+row['pdf_json_files'])==True:\n        with open('/kaggle/input/CORD-19-research-challenge/'+row['pdf_json_files']) as json_file:\n            #print ('in loop')\n            data = json.load(json_file)\n            body=format_body(data['body_text'])\n            #print (body)\n            body=body.replace(\"\\n\", \" \")\n            text=row['abstract']+' '+body.lower()\n            df.loc[index, 'abstract'] =text\n\ndf=df.drop(['pdf_json_files'], axis=1)\ndf=df.drop(['sha'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#basic seach based result start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1= df[['title','publish_time','journal','url','abstract','doi','cord_uid']]\n#Make a copy to work with\ndf_relevant=df1.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#separate each word in the column: abstract for browsing\ndf_relevant['words'] = df_relevant.abstract.str.strip().str.split('[\\W_]+')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#separate words in the abstract column and create a new column\nAbstracts1 = df_relevant[df_relevant.words.str.len() > 0]\nAbstracts1.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Abstracts1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# saving the Abstracts Table (dataframe) \nAbstracts1.to_csv('All_Abstracts.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assay = Abstracts1[Abstracts1['abstract'].str.contains('assay')]\nassay.to_csv('Assay.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"methods=['RT-iiPCR', 'Isothermal amplification', 'Antigen EIA', 'SENSR (Novel pathogen diagnostic technique)', 'rRT-PCR', 'Roche Platform',\n 'ELISA', 'rapid test IgG/IgM', 'Microarray', 'One Step rRT-PCR', 'specific-HCoV', 'RT-LAMP,', 'Rapid antigen test', 'monoplex', 'Antigen Detection test',\n 'Euroimmun IgA ELISA', 'HTS', 'Ultrasound', 'Serology', 'Penn-RAMP', 'Cell culture', 'pan-HCoV', 'RT-LAMP', 'LAMP', 'Rapid antigen test ', 'Multiple discussed',\n 'COVID-19 IgM/IgG Rapid Test of BioMedomics', 'Antigen EIA; ', 'dPCR', 'Lateral Flow Assay', 'RT-PCR (Novel Procedure)', 'multiplex', 'Roche cobas SARS-CoV-2 assay',\n 'Cepheid Xpert Xpress SARS-CoV-2 assay', 'mini-PCR', 'Euroimmun IgG ELISA', 'Antigen IFA', 'Serology (IgM & IgG Ab Eval)', 'Spiral CT', 'CXR',\n 'Wantai SARS-CoV-2 Total Antibody ELISA', 'VivaDiag COVID-19 IgM / IgG Rapid Test lateral flow immunoassay (LFIA)', 'Lateral Flow Antigen Detection',\n 'One step RT-PCR', 'All-in-One Dual CRISPR-Cas12a (AIOD-CRISPR)', 'mNGS', 'CRISPR', 'NAAT (PCR)', 'CT', 'NAAT', 'rapid serological test Viva-Diag analyzingCOVID-19 associated-IgG/IgM.',\n 'Serology ', 'RT-dPCR', 'Pixelated colorimetric nucleic acid assay', 'COVID-19 FET sensor', 'RT-PCR ', 'RT-PCR', 'Microfluidic Devices',\n 'RT-PCR, Serology', 'rRT-PCR kit (QIAStat-Dx Respiratory Panel)', 'iLAMP']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"detection_Method = Abstracts1[Abstracts1['abstract'].str.contains('|'.join(methods),case=False)]\ndetection_Method.shape\ndetection_Method.to_csv('detection_Method.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FDA=Abstracts1[Abstracts1['abstract'].str.contains('FDA',case=False)]\nFDA.shape\nFDA.to_csv('FDA.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyType=['Simulation', 'Simulation Study', 'Simlation Study', 'Clinical trial', 'Retrospective Cohort', 'Expert Review', 'Review', 'Proof of concept', 'Investigative Study', 'Simulation study', 'Prospective Cohort', 'Clinical Study', 'Clinical Trial', 'Case Report', 'Systematic Review',\n 'Retrospective Cohort Study']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study_type=Abstracts1[Abstracts1['abstract'].str.contains('|'.join(studyType),case=False)]\nstudy_type.shape\nstudy_type.to_csv('study_type.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Measure_Accuracy=['sensitivity','specifity','positive predictive value','negative predicitve value','accuracy',]\nMeasure_of_Testing_Accuracy=Abstracts1[Abstracts1['abstract'].str.contains('|'.join(Measure_Accuracy),case=False)]\nprint(Measure_of_Testing_Accuracy.shape)\nMeasure_of_Testing_Accuracy.to_csv('Measure_of_Testing_Accuracy.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'Measure_of_Testing_Accuracy.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final csv merged based on cord_uid","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.read_csv('All_Abstracts.csv')\ndf_assay = pd.read_csv('Assay.csv')\ndf_fda = pd.read_csv('FDA.csv')\ndf_accuracy =pd.read_csv('Measure_of_Testing_Accuracy.csv')\ndf_detection = pd.read_csv('detection_Method.csv')\ndf_study_type=pd.read_csv('study_type.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = [df_all,df_assay,df_fda,df_accuracy,df_detection,df_study_type]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final_1 = pd.merge(df_all, df_assay, on='cord_uid', how='left')\ndf_final_1=df_final_1.drop(['Unnamed: 0_y', 'title_y','publish_time_y', 'journal_y', 'url_y', 'abstract_y', 'doi_y',\n       'words_y'], axis=1)\ndf_final_2 = pd.merge(df_final_1, df_fda, on='cord_uid', how='left')\ndf_final_2=df_final_2.drop(['Unnamed: 0', 'title','publish_time', 'journal', 'url', 'abstract', 'doi','words'], axis=1)\ndf_final_3 = pd.merge(df_final_2, df_accuracy, on='cord_uid', how='left')\ndf_final_3=df_final_3.drop(['Unnamed: 0', 'title','publish_time', 'journal', 'url', 'abstract', 'doi','words'], axis=1)\ndf_final_4 = pd.merge(df_final_3, df_detection, on='cord_uid', how='left')\ndf_final_4=df_final_4.drop(['Unnamed: 0', 'title','publish_time', 'journal', 'url', 'abstract', 'doi','words'], axis=1)\ndf_final_5 = pd.merge(df_final_4, df_study_type, on='cord_uid', how='left')\ndf_final_New=df_final_5.drop(['Unnamed: 0', 'title','publish_time', 'journal', 'url', 'abstract', 'doi','words'], axis=1)\n\n#df_left","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final_New.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final_New.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final_New.columns = ['Unnamed: 0', 'title', 'publish_time', 'journal', 'url','abstract', 'doi', 'cord_uid', 'words']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final_New.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final_New.to_csv('df_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'df_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import reduce\ndf_final = reduce(lambda left,right: pd.merge(left,right,on='cord_uid'), dfs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.to_csv('df_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'df_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import functools\n\ndef remove_stopwords(text,stopwords):\n    text = \"\".join(c for c in text if c not in ('!','.',',','?','(',')','-'))\n    text_tokens = word_tokenize(text)\n    #remove stopwords\n    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n    str1=''\n    str1=' '.join(word for word in tokens_without_sw)\n    return str1\n\n### spacy score sentence\ndef score_sentence(search,sentence):\n        main_doc=nlp(sentence)\n        search_doc=nlp(search)\n        sent_score=main_doc.similarity(search_doc)\n        return sent_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom sentence score\ndef score_sentence_prob(search,sentence,focus):\n    keywords=search.split()\n    sent_parts=sentence.split()\n    word_match=0\n    missing=0\n    for word in keywords:\n        word_count=sent_parts.count(word)\n        word_match=word_match+word_count\n        if word_count==0:\n            missing=missing+1\n    percent = 1-(missing/len(keywords))\n    final_score=abs((word_match/len(sent_parts)) * percent)\n    if missing==0:\n        final_score=final_score+1\n    if focus not in sentence:\n        final_score=0\n    return final_score\n\n# BERT pretrained question answering module\ndef answer_question(question,text, model,tokenizer):\n    input_text = \"[CLS] \" + question + \" [SEP] \" + text + \" [SEP]\"\n    input_ids = tokenizer.encode(input_text)\n    token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n    start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n    all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n    #print(' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n    answer=(' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n    # show qeustion and text\n    #tokenizer.decode(input_ids)\n    answer=answer.replace(\" ##\", \"\")\n    answer=answer.replace(\" · \", \"·\")\n    answer=answer.replace(\" . \", \".\")\n    answer=answer.replace(\" , \", \",\")\n    if '[SEP]'in answer or '[CLS]' in answer or answer=='':\n        answer='unk'\n        \n    return answer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test on limite dataset\ndef process_question(df,search,focus):\n    print('--------0----------')\n    df_table = pd.DataFrame(columns = ['date','study','link','Journal','studytype','sample','method','ObtainedSample','MeasureofTestingAccuracy','Speedofassay','cord_uid','FDAapproval','Addedon','DOI'])\n    # focuses to make sure the exact phrase in text\n    #df1 = df[df['abstract'].str.contains(focus)]\n    # focus to make sure all words in text\n    df1=df[functools.reduce(lambda a, b: a&b, (df['abstract'].str.contains(s) for s in search.split()))]\n    print('-----1-------',df['abstract'])\n    search=remove_stopwords(search,stopwords)\n    print('-------2-----',search)\n    print('-----df1-------',df1)\n    for index, row in df1.iterrows():\n        print('-----3------',row)\n        sentences = row['abstract'].split('. ')\n        pub_sentence=''\n        hi_score=0\n        study=''\n        hi_study_score=0\n        for sentence in sentences:\n            if len(sentence)>75 and focus in sentence:\n                rel_score=score_sentence_prob(search,sentence,focus)\n                if rel_score>.02:\n                    sentence=sentence.capitalize()\n                    if sentence[len(sentence)-1]!='.':\n                        sentence=sentence+'.'\n                    pub_sentence=pub_sentence+' '+sentence\n                    if rel_score>hi_score:\n                        hi_score=rel_score\n                \n        if pub_sentence!='':\n            text=row['abstract'][0:100]\n            \n            question='how many patients or cases were in the study, review or analysis?'\n            sample=answer_question(question,text,model,tokenizer)\n            sample=sample.replace(\"#\", \"\")\n            sample=sample.replace(\" , \", \",\")\n            if sample=='19' or sample=='' or '[SEP]'in sample:\n                sample='unk'\n            if len(sample)>50:\n                sample='unk'\n            sample=sample.replace(\" \", \"\")\n            print('-------sample----',sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_demo = df[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search ='Diagnosing SARS-COV-2 with antibodies'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd = (df['abstract'].str.contains(s) for s in search.split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print(*cd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df[functools.reduce(lambda a, b: a&b, (df['abstract'].str.contains(s) for s in search.split()))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd=process_question(df_demo,'Diagnosing SARS-COV-2 with antibodies','diagnostics')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dummy test\n###################### MAIN PROGRAM ###########################\n\n\n### focus quesiton with single keyword\n#keywords = ['hypertension']\nkeywords = ['hypertension','diabetes','heart disease','gender','copd','smoking','age','stroke','cerbrovascular','cancer','kidney disease','drinking','tuberculosis','obesity']\n#'diabetes','heart disease','male gender','copd','smoking','age','stroke','cerbrovascular','cancer','kidney disease','drinking','tuberculosis','bmi'\n\nq=0\n\ndf_all_risk_factors = pd.DataFrame(columns = [\"date\",\"study\",\"link\",\"journal\",\"severe\",\"sever sig.\",\"severe age adj.\",\"Severe OR Calculated or Extracted\",\"fatality\",\"fatality sig.\",\"fatality age adj.\",\"Fatality OR Calculated or Extracted\",\"design\",\"sample\",\"risk factor\"])\n\n# loop through the list of questions\nfor keyword in keywords:\n    # limit results to severe risk factors\n    search_words = keyword+' risk factor severe'\n    # get best sentences\n    df_table=process_question(df,search_words,keyword)\n    df_answers=df_table  \n    #print (text)\n    #limit the size of the df for the html table\n    #df_table=df_table.head(100)\n    df_table=df_table.drop_duplicates(subset='study', keep=\"first\")\n    df_table = df_table.sort_values(by=['date'], ascending=False)\n    \n    df_allriskcsv=df_table\n    \n    #convert df to html\n    df_table=HTML(df_table.to_html(escape=False,index=False))\n    \n    # show the HTML table with responses\n    display(df_table)\n    \n    \n    q=q+1\n    df_allriskcsv.to_csv(keyword+'_risk_factors.csv',index = False)\n    df_all_risk_factors=df_all_risk_factors.append(df_allriskcsv, ignore_index=True)\ndf_all_risk_factors.to_csv('all_risk_factors.csv',index = False)\nprint ('done')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_question(df,search,focus):\n    df_table = pd.DataFrame(columns = ['date','study','link','Journal','studytype','sample','method','ObtainedSample','MeasureofTestingAccuracy','Speedofassay','cord_uid','FDAapproval','Addedon','DOI'])\n    # focuses to make sure the exact phrase in text\n    #df1 = df[df['abstract'].str.contains(focus)]\n    # focus to make sure all words in text\n    df1=df[functools.reduce(lambda a, b: a&b, (df['abstract'].str.contains(s) for s in search))]\n    search=remove_stopwords(search,stopwords)\n    for index, row in df1.iterrows():\n        sentences = row['abstract'].split('. ')\n        pub_sentence=''\n        hi_score=0\n        study=''\n        hi_study_score=0\n        for sentence in sentences:\n            if len(sentence)>75 and focus in sentence:\n                rel_score=score_sentence_prob(search,sentence,focus)\n                if rel_score>.02:\n                    sentence=sentence.capitalize()\n                    if sentence[len(sentence)-1]!='.':\n                        sentence=sentence+'.'\n                    pub_sentence=pub_sentence+' '+sentence\n                    if rel_score>hi_score:\n                        hi_score=rel_score\n                \n        if pub_sentence!='':\n            text=row['abstract'][0:1000]\n            \n            question='how many patients or cases were in the study, review or analysis?'\n            sample=answer_question(question,text,model,tokenizer)\n            sample=sample.replace(\"#\", \"\")\n            sample=sample.replace(\" , \", \",\")\n            if sample=='19' or sample=='' or '[SEP]'in sample:\n                sample='unk'\n            if len(sample)>50:\n                sample='unk'\n            sample=sample.replace(\" \", \"\")\n            \n            question='what type or kind of review study analysis model was used?'\n            design=answer_question(question,text,model,tokenizer)\n            design=design.replace(\" ##\", \"\")\n            if '[SEP]'in design or '[CLS]' in design or design=='':\n                design='unk'\n            \n            ### get sever numbers\n            question='what is the '+keyword+' HR OR RR AOR hazard odds ratio ()?'\n            severe=answer_question(question,text,model,tokenizer)\n            df_table.loc[index,'severe']=severe\n            \n            authors=row[\"authors\"].split(\" \")\n            link=row['doi']\n            title=row[\"title\"]\n            score=hi_score\n            journal=row[\"journal\"]\n            if journal=='':\n                journal=row['full_text_file']\n            linka='https://doi.org/'+link\n            linkb=title\n            final_link='<p align=\"left\"><a href=\"{}\">{}</a></p>'.format(linka,linkb)\n            #author_link='<p align=\"left\"><a href=\"{}\">{}</a></p>'.format(linka,authors[0]+' et al.')\n            #sentence=pub_sentence+' '+author_link\n            sentence=pub_sentence\n            #sentence='<p fontsize=tiny\" align=\"left\">'+sentence+'</p>'\n            to_append = [row['publish_time'],title,linka,journal,severe,\"-\",\"-\",\"-\",\"-\",\"-\",\"-\",\"-\",design,sample,keyword]\n            df_length = len(df_table)\n            df_table.loc[df_length] = to_append\n            \n    return df_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################### MAIN PROGRAM ###########################\n\n\n### focus quesiton with single keyword\n#keywords = ['hypertension']\nkeywords = ['hypertension','diabetes','heart disease','gender','copd','smoking','age','stroke','cerbrovascular','cancer','kidney disease','drinking','tuberculosis','obesity']\n#'diabetes','heart disease','male gender','copd','smoking','age','stroke','cerbrovascular','cancer','kidney disease','drinking','tuberculosis','bmi'\n\nq=0\n\ndf_all_risk_factors = pd.DataFrame(columns = [\"date\",\"study\",\"link\",\"journal\",\"severe\",\"sever sig.\",\"severe age adj.\",\"Severe OR Calculated or Extracted\",\"fatality\",\"fatality sig.\",\"fatality age adj.\",\"Fatality OR Calculated or Extracted\",\"design\",\"sample\",\"risk factor\"])\n\n# loop through the list of questions\nfor keyword in keywords:\n    # limit results to severe risk factors\n    search_words = keyword+' risk factor severe'\n    \n    # get best sentences\n    df_table=process_question(df,search_words,keyword)\n    df_answers=df_table\n        \n    display(HTML('<h3>'+search_words+'</h3>'))\n    \n    #print (text)\n    \n    #limit the size of the df for the html table\n    #df_table=df_table.head(100)\n    df_table=df_table.drop_duplicates(subset='study', keep=\"first\")\n    df_table = df_table.sort_values(by=['date'], ascending=False)\n    \n    df_allriskcsv=df_table\n    \n    #convert df to html\n    df_table=HTML(df_table.to_html(escape=False,index=False))\n    \n    # show the HTML table with responses\n    display(df_table)\n    \n    \n    q=q+1\n    df_allriskcsv.to_csv(keyword+'_risk_factors.csv',index = False)\n    df_all_risk_factors=df_all_risk_factors.append(df_allriskcsv, ignore_index=True)\ndf_all_risk_factors.to_csv('all_risk_factors.csv',index = False)\nprint ('done')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load indexed metadata \n# final_df = pd.read_csv('../input/covidfulltext/metadata_and_fulltext_2020-04-17.csv')\n# final_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.read_csv('../input/CORD-19-research-challenge/metadata.csv')\n#('../input/covidfulltext/metadata_and_fulltext_2020-04-17.csv')\nfinal_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df=final_df[:500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LUCENE_BASE_DIR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.path.join(LUCENE_BASE_DIR, LUCENE_INDEX_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class IndexFiles(object):\n    \"\"\"Usage: python IndexFiles <doc_directory>\"\"\"\n\n    def __init__(self, root, storeDir, analyzer):\n        ##print(\"before store\")\n        if not os.path.exists(storeDir):\n            os.mkdir(storeDir)\n        ##print(\"after store\")\n\n        store = SimpleFSDirectory(Paths.get(storeDir))\n        ##print(storeDir)\n        analyzer = LimitTokenCountAnalyzer(analyzer, 1048576)\n        ##print(\"after analyzer \")\n\n        config = IndexWriterConfig(analyzer)\n        ##print(\"after config\")\n\n        config.setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        ##print(\"before writer\")\n        writer = IndexWriter(store, config)\n        ##print(\"after writer\")\n        self.indexDocs(root, writer)\n        #indexDocs(root, writer)\n        #ticker = Ticker()\n        ##print ('commit index')\n        #threading.Thread(target=ticker.run).start()\n        writer.commit()\n        writer.close()\n        #ticker.tick = False\n        ##print ('done')\n\n    def indexDocs(self, root, writer):\n\n        t1 = FieldType()\n        t1.setStored(True)\n        t1.setTokenized(False)\n        t1.setStoreTermVectors(True)\n        t1.setStoreTermVectorOffsets(True)\n        t1.setStoreTermVectorPositions(True)\n        t1.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS)\n        \n\n        t2 = FieldType()\n        t2.setStored(True)\n        t2.setTokenized(True)\n        t2.setStoreTermVectors(True)\n        t2.setStoreTermVectorOffsets(True)\n        t2.setStoreTermVectorPositions(True)\n        t2.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS)\n                \n        i = 1\n        for index, row in final_df.iterrows():\n            print (\"adding \", i , \"th document:\", row['cord_uid'])\n            try :\n                doc = Document()\n                doc.add(Field(\"cord_uid\", row['cord_uid'], t1))\n                doc.add(Field(\"title\", row['title'], t2))\n                doc.add(Field(\"doi\",row['doi'], t1))\n                doc.add(Field(\"pmcid\", row['pmcid'], t1))\n                doc.add(Field(\"publish_time\", row['publish_time'], t1))\n                doc.add(Field(\"journal\", row['journal'], t1))\n                doc.add(Field(\"url\", row['url'], t1))\n                \n                if len(row['abstract']) > 0:\n                    doc.add(Field(\"full_text\", row['abstract'], t2))\n                else :\n                    print (\"warning: no fulltext available in %s\", row['title'])\n                    \n#                 if len(row['abstract_y']) > 0:\n#                     doc.add(Field(\"abstract\", row['abstract_y'], t2))\n#                 else :\n#                     print (\"warning: no abstract available in %s\", row['title'])\n                writer.addDocument(doc)\n            except (RuntimeError, TypeError, NameError):\n                pass\n            i=i+1\n            \n            \nlucene.initVM()\nstart = datetime.now()\ntry:\n    IndexFiles(LUCENE_BASE_DIR, os.path.join(LUCENE_BASE_DIR, LUCENE_INDEX_DIR),StandardAnalyzer())\n    end = datetime.now()\n    print (end - start)\nexcept (RuntimeError, TypeError, NameError):\n    print (\"Failed: \")\n    raise        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# static_risk_factors = pd.DataFrame([\"sex\",\"gender\",\"male\",\"cancer\",\"cerebral\",\"hypertension\", \"smok\", \"respiratory\", \n#             \"pneumonia\", \"vascular\", \"influenza\", \"tobacco\", \"obes\", \"virus\",\n#             \"cardio\", \"bronchitis\"], columns=[\"name\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"static_risk_factors = pd.DataFrame([\"diagnostics\",\"findings\",\"future\",\"discover\",\"advances\",\"development\", \"X-ray\", \"symptoms\", \n            \"scan\", \"antibodies\", \"RT-PCR\", \"viral test\", \"viral\", \"evidence\",\n            \"studies show\", \"sample\",\"COVID\",\"test\",\"diagnostic tools\",\"corona\",\"diagnostics\"], columns=[\"name\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TOP_K = 20\ndf_relevant_papers = []\n\ndef run(searcher, analyzer, search_topic):\n    if search_topic == '':\n        return\n\n#     print (\"Searching for:\", search_topic)\n    query = QueryParser(\"full_text\", analyzer).parse(search_topic)\n    #print('---------query-------',query)\n\n    scoreDocs = searcher.search(query, TOP_K).scoreDocs\n    print (\"%s total matching documents.\" , len(scoreDocs))\n    \n    for scoreDoc in scoreDocs:\n        doc = searcher.doc(scoreDoc.doc)\n        result = {\n            'date': doc.get(\"publish_time\"),\n            'title': doc.get(\"title\"),\n            'url': doc.get(\"url\"),\n            'journal': doc.get(\"journal\"),\n            'cord_uid': doc.get('cord_uid'),\n            'abstract': doc.get('abstract'),\n            #'risk_factor': risk_factor,\n            'pmcid': doc.get(\"pmcid\")\n        }\n\n        df_relevant_papers.append(result)                \n\ndirectory = SimpleFSDirectory(Paths.get(os.path.join(LUCENE_BASE_DIR, LUCENE_INDEX_DIR)))\nsearcher = IndexSearcher(DirectoryReader.open(directory))\nanalyzer = StandardAnalyzer()\n\nPROXIMITY = 5\nfor id, item in static_risk_factors.iterrows():\n    diagnostics_factor = item['name']\n    #search_topic = (\"\\\"{}\\\" AND (\\\"coronavirus disease 19\\\" OR \\\"sars cov 2\\\" OR \\\"2019 ncov\\\" OR \\\"2019ncov\\\" OR \\\"coronavirus 2019\\\", \\\"wuhan pneumonia\\\" OR \\\"wuhan virus\\\"OR \\\"wuhan coronavirus\\\",OR \\\"covid19\\\" OR \\\"covid-19\\\")\".format(diagnostics_factor))\n    #search_topic = (\"(\\\"clinical\\\" OR \\\"epidem\\\" OR \\\"virological\\\" OR \\\"host susceptibility to serve\\\" OR \\\"coronavirus disease 19\\\") AND \\\"characteristic\\\" AND (\\\"coronavirus disease 19\\\" OR \\\"sars cov 2\\\" OR \\\"2019 ncov\\\" OR \\\"2019ncov\\\" OR \\\"coronavirus 2019\\\", \\\"wuhan pneumonia\\\" OR \\\"wuhan virus\\\"OR \\\"wuhan coronavirus\\\",OR \\\"covid19\\\" OR \\\"covid-19\\\")\")\n    search_topic = (\"\\\"{}\\\" AND (\\\"covid\\\" OR \\\"sars cov 2\\\"  OR \\\"coronavirus 2019\\\",\\\"wuhan pneumonia\\\" OR \\\"wuhan virus\\\"OR \\\"wuhan coronavirus\\\",OR \\\"covid19\\\" OR \\\"covid-19\\\")\".format(diagnostics_factor))\n    print(diagnostics_factor)\n    print('search_topic: ', search_topic)    \n    run(searcher, analyzer, search_topic)\ndel searcher\n\ndf_relevant_papers = pd.DataFrame(df_relevant_papers)\ndf_relevant_papers = df_relevant_papers.drop_duplicates()\nlen(df_relevant_papers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_relevant_papers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_relevant_papers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_relevant_papers['url']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id={0}'.format('PMC2769550')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"source = urllib.request.urlopen(url).read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsoup = bs.BeautifulSoup(source,'lxml')\ndf = None\ncols = None\ndfs = []\ntitle = ''\nabstract = ''\njournal = ''\ntitle = soup.findAll('article-title')[0].find(text=True)# title\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#title = soup.findAll('article-title')[0].find(text=True)# title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"get_all_tables('PMC2769550')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method will display all tables in a paper and will return them as a list of dfs\ndef get_all_tables(pmcid, show_tables = True):\n#     print(\"\", end = '.')\n    sleep(0.5) # This line is needed as the NCBI server will block if there are too many frequent requests\n    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id={0}'.format(pmcid)\n    #beautiful soup\n    source = urllib.request.urlopen(url).read()\n    soup = bs.BeautifulSoup(source,'lxml')\n    df = None\n    cols = None\n    dfs = []\n    title = ''\n    abstract = ''\n    journal = ''\n    title = soup.findAll('article-title')[0].find(text=True)# title\n    try:\n        abstract = soup.find(\"abstract\").text\n    except:\n        abstract = ''\n    #getting the table\n    tables = soup.findAll('table')  # Note: \n    i = 1\n    for table in tables:\n        if(show_tables):\n            print(\"\\nTable {0}  for paper id {1}: \".format(i, pmcid))\n        table_rows = table.find_all('tr')\n        #generate df\n        df = pd.DataFrame()\n        for tr in table_rows:\n            td = tr.find_all(['td'])\n            row = [i.text for i in td]\n            \n            if(len(row) > 0):\n                s = pd.Series(row)\n                df = df.append(s, ignore_index=True)\n            else: # it is a header\n                th = tr.find_all(['th'])\n                cols = [i.text for i in th]\n        \n        if(cols): #assign header\n            if(len(df.columns) == len(cols)+1):\n                #add one column for the title\n                cols.insert(0,'')\n            if(len(df.columns) == len(cols)):\n                df.columns = cols\n        \n        dfs.append( df )\n        if(show_tables):\n            print(title)\n            print(abstract)\n            display(HTML(df.to_html()))\n        i = i + 1\n\n    return dfs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n# This section loads the indexs and takes about 4 minutes to run\nclass Ticker(object):\n\n    def __init__(self):\n        self.tick = True\n\n    def run(self):\n        while self.tick:\n            sys.stdout.write('.')\n            sys.stdout.flush()\n            time.sleep(1.0)\n\nclass IndexFiles(object):\n    \"\"\"Usage: python IndexFiles <doc_directory>\"\"\"\n\n    def __init__(self, root, storeDir, analyzer):\n        ##print(\"before store\")\n        if not os.path.exists(storeDir):\n            os.mkdir(storeDir)\n        ##print(\"after store\")\n\n        store = SimpleFSDirectory(Paths.get(storeDir))\n        ##print(storeDir)\n        analyzer = LimitTokenCountAnalyzer(analyzer, 1048576)\n        ##print(\"after analyzer \")\n\n        config = IndexWriterConfig(analyzer)\n        ##print(\"after config\")\n\n        config.setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n        ##print(\"before writer\")\n        writer = IndexWriter(store, config)\n        ##print(\"after writer\")\n        self.indexDocs(root, writer)\n        ticker = Ticker()\n        ##print ('commit index')\n        threading.Thread(target=ticker.run).start()\n        writer.commit()\n        writer.close()\n        ticker.tick = False\n        ##print ('done')\n\n    def indexDocs(self, root, writer):\n\n        t1 = FieldType()\n        t1.setStored(True)\n        t1.setTokenized(False)\n        t1.setStoreTermVectors(True)\n        t1.setStoreTermVectorOffsets(True)\n        t1.setStoreTermVectorPositions(True)\n        t1.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS)\n        \n\n        t2 = FieldType()\n        t2.setStored(True)\n        t2.setTokenized(True)\n        t2.setStoreTermVectors(True)\n        t2.setStoreTermVectorOffsets(True)\n        t2.setStoreTermVectorPositions(True)\n        t2.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS)\n                \n        i = 1\n        for index, row in final_df.iterrows():\n            print (\"adding \", i , \"th document:\", row['paper_id'])\n            try :\n                doc = Document()\n                doc.add(Field(\"paper_id\", row['paper_id'], t1))\n                doc.add(Field(\"title\", row['title'], t2))\n                doc.add(Field(\"doi\",row['doi'], t1))\n                doc.add(Field(\"pmcid\", row['pmcid'], t1))\n                doc.add(Field(\"publish_time\", row['publish_time'], t1))\n                doc.add(Field(\"journal\", row['journal'], t1))\n                doc.add(Field(\"url\", row['url'], t1))\n                \n                if len(row['text']) > 0:\n                    doc.add(Field(\"full_text\", row['text'], t2))\n                else :\n                    print (\"warning: no fulltext available in %s\", row['title'])\n                    \n                if len(row['abstract_y']) > 0:\n                    doc.add(Field(\"abstract\", row['abstract_y'], t2))\n                else :\n                    print (\"warning: no abstract available in %s\", row['title'])\n                writer.addDocument(doc)\n            except (RuntimeError, TypeError, NameError):\n                pass\n            i=i+1\n            \n\nlucene.initVM()\nstart = datetime.now()\ntry:\n    IndexFiles(LUCENE_BASE_DIR, os.path.join(LUCENE_BASE_DIR, LUCENE_INDEX_DIR),StandardAnalyzer())\n    end = datetime.now()\n    print (end - start)\nexcept (RuntimeError, TypeError, NameError):\n    print (\"Failed: \")\n    raise ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Search String\nThis sub-section finds the most relevant papers related to risk factors. The dataframe *static_risk_factors* is used, but can be updated as needed:\n\n\"sex\",\"gender\",\"male\",\"cancer\",\"cerebral\",\"hypertension\", \"smok\", \"respiratory\", \"pneumonia\", \"vascular\", \"influenza\", \"tobacco\", \"obes\", \"virus\", \"cardio\", \"bronchitis\"\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"static_risk_factors = pd.DataFrame([\"sex\",\"gender\",\"male\",\"cancer\",\"cerebral\",\"hypertension\", \"smok\", \"respiratory\", \n            \"pneumonia\", \"vascular\", \"influenza\", \"tobacco\", \"obes\", \"virus\",\n            \"cardio\", \"bronchitis\"], columns=[\"name\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TOP_K = 200\ndf_relevant_papers = []\n\ndef run(searcher, analyzer, search_topic):\n    if search_topic == '':\n        return\n\n#     print (\"Searching for:\", search_topic)\n    query = QueryParser(\"full_text\", analyzer).parse(search_topic)\n\n    scoreDocs = searcher.search(query, TOP_K).scoreDocs\n    print (\"%s total matching documents.\" , len(scoreDocs))\n    \n    for scoreDoc in scoreDocs:\n        doc = searcher.doc(scoreDoc.doc)\n        result = {\n            'date': doc.get(\"publish_time\"),\n            'study': doc.get(\"title\"),\n            'study_link': doc.get(\"url\"),\n            'journal': doc.get(\"journal\"),\n            'paper_id': doc.get('paper_id'),\n            'paper_full_text': doc.get('full_text'),\n            #'risk_factor': risk_factor,\n            'pmcid': doc.get(\"pmcid\")\n        }\n\n        df_relevant_papers.append(result)                \n\ndirectory = SimpleFSDirectory(Paths.get(os.path.join(LUCENE_BASE_DIR, LUCENE_INDEX_DIR)))\nsearcher = IndexSearcher(DirectoryReader.open(directory))\nanalyzer = StandardAnalyzer()\n\nPROXIMITY = 20\nfor id, item in static_risk_factors.iterrows():\n    risk_factor = item['name']\n    #search_topic = (\"\\\"{}\\\" AND (\\\"coronavirus disease 19\\\" OR \\\"sars cov 2\\\" OR \\\"2019 ncov\\\" OR \\\"2019ncov\\\" OR \\\"coronavirus 2019\\\", \\\"wuhan pneumonia\\\" OR \\\"wuhan virus\\\"OR \\\"wuhan coronavirus\\\",OR \\\"covid19\\\" OR \\\"covid-19\\\")\".format(risk_factor))\n    search_topic = (\"(\\\"clinical\\\" OR \\\"epidem\\\" OR \\\"virological\\\" OR \\\"host susceptibility to serve\\\") AND \\\"characteristic\\\" AND (\\\"coronavirus disease 19\\\" OR \\\"sars cov 2\\\" OR \\\"2019 ncov\\\" OR \\\"2019ncov\\\" OR \\\"coronavirus 2019\\\", \\\"wuhan pneumonia\\\" OR \\\"wuhan virus\\\"OR \\\"wuhan coronavirus\\\",OR \\\"covid19\\\" OR \\\"covid-19\\\")\")\n    print(risk_factor)\n    print('search_topic: ', search_topic)    \n    run(searcher, analyzer, search_topic)\ndel searcher\n\ndf_relevant_papers = pd.DataFrame(df_relevant_papers)\ndf_relevant_papers = df_relevant_papers.drop_duplicates()\nlen(df_relevant_papers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Examine results \ndf_relevant_papers.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[](http://)Filtering articles that have a PMCID, as these publications store tabular data on PubMed.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only use papers that have a PMCID\ndf_relevant_papers = df_relevant_papers[~df_relevant_papers['pmcid'].str.contains('NaN')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This list will be used to pull publication data from PubMed servers\nrelevant_papers = df_relevant_papers.pmcid.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Tables <a class=\"anchor\" id=\"xml-header\"></a>\n![](http://)\nThis section will retrieve tables from the publications. It will then parse the XML table data to retrieve relevant information.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load Kaggle Metadata\nmetadata = pd.read_csv('../input/CORD-19-research-challenge/metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract Information from Tables <a class=\"anchor\" id=\"manual-header\"></a>\n![](http://)\nWe are relying on the search above to identify the most relevant tables.\nThis section will get information from the extracted tables related to a given disease. \n\n** However, this works best for a fixed set of consistent table styles.** The system can be updated in the future to accommodate more diverse tables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Input: the dataframe you are looking for and the set of synonyms to search in the header\n#Output: the indexes where the non severe and severe cases are described, in this order.\ndef get_column_index_severities(df, severe_synonyms_set):\n    \n    synonyms_non = set([\"non\", \"non \",\"non-\",\"no \",\"dead\",\"death\",\"died\",\"3\",\"mort\"])\n\n    row = list(df.columns)\n    \n    severe_index = None\n    non_severe_index = None\n    \n    severe_value = \"\"\n    non_severe_value = \"\"\n\n    for i, r in enumerate(row):\n        r = str(r).lower().replace('‐', '-')\n        #print(\"r is\",r)\n        for sv in severe_synonyms_set:\n            if(sv in r):   \n                #print(\"Checking\",sv)\n                #check if its not severe\n                severe_value = sv\n                for n in synonyms_non:\n                    #print(\"Checking\",sv,\" and\",n)\n                    if(n+sv in r) or (n in r):\n                        non_severe_index = i\n                        non_severe_value = n\n                        #print(\"n\"+n)\n                        break\n                \n                if(not non_severe_index):\n                    severe_index = i\n\n                if(severe_index and non_severe_index):\n                    #print(\"Found index for \" + severe_value + \" and \" + non_severe_value)\n                    return [non_severe_index, severe_index]                \n                \n                break #not necessary to look for more synonyms on severe set\n    return [non_severe_index, severe_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### NOTE:\nWith a pmcid, it is possible to get download tables from studies in XML format.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_only_number(val):\n    if isinstance(val, str):\n        i = val.find(\"(\")\n        if(i > 0):\n            val = val[0:i]\n        i = val.find(\"/\")\n        if(i > 0):\n            val = val[0:i]\n    try:\n        f = float(val)\n        return f\n    except:\n        return 0\n\ndef get_total_number(header):\n    \n    val = header[header.find(\"=\")+1:header.find(\")\")].strip() #pattern (n = 12)\n    if(val.isdigit()):\n        return int(val)\n    return 0\n    \n\ndef get_numbers_by_disease(df, disease, header_synonyms):\n    disease = disease.lower()\n    non_severe_index, severe_index = get_column_index_severities(df, header_synonyms)\n    \n    if(not non_severe_index or not severe_index):\n        # print(\"Info: Severity not found on header\")\n        return\n        \n    # get row\n    row = df[df.iloc[:,0].str.lower().str.contains(disease)].values\n    if(len(row) == 0): #did not find the disease\n         # print(\"Info: Disease not found\")\n        return \n    row = row[0]\n    \n    header = list(df.columns)\n\n    if(non_severe_index):\n        non_severe = get_only_number(row[non_severe_index])\n        non_severe_n = get_total_number(header[non_severe_index])\n\n\n    if(severe_index):\n        severe = get_only_number(row[severe_index])\n        severe_n = get_total_number(header[severe_index])\n\n\n    return [non_severe, non_severe_n, severe, severe_n]\n\n\ndef get_severity_numbers(df, disease):\n    synonyms_severe = set([\"severe\", \"critical\", \"icu\", \"picu\",\"poor\",\"mild\",\"ecmo\", \"mv\",\"gi\",\"corticosteroids\",\"2\"])\n    return get_numbers_by_disease(df, disease, synonyms_severe)\n\ndef get_fatality_numbers(df, disease):\n    synonyms_fatality = set([\"surviv\"])\n    return get_numbers_by_disease(df, disease, synonyms_fatality)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method will display all tables in a paper and will return them as a list of dfs\ndef get_all_tables(pmcid, show_tables = True):\n#     print(\"\", end = '.')\n    sleep(0.5) # This line is needed as the NCBI server will block if there are too many frequent requests\n    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id={0}'.format(pmcid)\n    #beautiful soup\n    source = urllib.request.urlopen(url).read()\n    soup = bs.BeautifulSoup(source,'lxml')\n    df = None\n    cols = None\n    dfs = []\n    title = ''\n    abstract = ''\n    journal = ''\n    title = soup.findAll('article-title')[0].find(text=True)# title\n    try:\n        abstract = soup.find(\"abstract\").text\n    except:\n        abstract = ''\n    #getting the table\n    tables = soup.findAll('table')  # Note: \n    i = 1\n    for table in tables:\n        if(show_tables):\n            print(\"\\nTable {0}  for paper id {1}: \".format(i, pmcid))\n        table_rows = table.find_all('tr')\n        #generate df\n        df = pd.DataFrame()\n        for tr in table_rows:\n            td = tr.find_all(['td'])\n            row = [i.text for i in td]\n            \n            if(len(row) > 0):\n                s = pd.Series(row)\n                df = df.append(s, ignore_index=True)\n            else: # it is a header\n                th = tr.find_all(['th'])\n                cols = [i.text for i in th]\n        \n        if(cols): #assign header\n            if(len(df.columns) == len(cols)+1):\n                #add one column for the title\n                cols.insert(0,'')\n            if(len(df.columns) == len(cols)):\n                df.columns = cols\n        \n        dfs.append( df )\n        if(show_tables):\n            print(title)\n            print(abstract)\n            display(HTML(df.to_html()))\n        i = i + 1\n\n    return dfs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compute Odds Ratio <a class=\"anchor\" id=\"odds-header\"></a>\n![](http://)\nAs we are analysing count data, such as the number of severe outcomes versus the number of non-severe outcomes, we will compute the summary statistics using an odds ratio. \nThe term “odds” refers to the probability of an event occurring versus the probability of the event not occurring.\n\nThese can be illustrated with the following example, based on [Ranganathan](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640017):\n\n| | Fatal | Survive | Total |\n| --- | --- | --- | --- |\n| A | 18 | 46 | 64 |\n| B | 29 | 36 | 65 |\n| Totals | 47 | 82 | 129 |\n\nOdds is defined as:\n\n$$Odds = \\frac{Fatal}{Survive}$$\n\nThe odds of death in group A is 18/46 (0.39) and in group B it is 29/36 (0.81).\n\nThe odds *ratio* (OR) is the ratio of the odds of an event in group A to the odds of an event in group B. \n\nOur Covid-19 data is mainly from retrospective cohort studies, which are studies that examine existing data to identify risk factors for particular conditions, therefore we will utilise  odds  ratio.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_statistical_info(severity_numbers):\n#severity_number pattern: non-severity, non-severity_n, severity, severity_n\n    OR, lower_CI, higher_CI, CI, p_value = 0.0, 0.0, 0.0, 0.0, 0.0\n    ##Cases with positive (bad) outcome\n    a = severity_numbers[2]     # Number in exposed group\n    b = severity_numbers[3] - a # Number in control group\n\n    ##Cases with negative (good) outcome\n    c = severity_numbers[0]     # Number in exposed group\n    d = severity_numbers[1] - c # Number in control group\n    \n    if(a == 0 or b <= 0 or c == 0 or d <=0): # cannot calculate division by 0 or sqrt < 0\n        return OR, lower_CI, higher_CI, CI, p_value\n    \n    \n    OR = (a*d)/(b*c)\n    std_error  = np.sqrt(1/a + 1/b + 1/c +1/d) \n    \n    lower_CI = np.exp(np.log(OR)-1.96*std_error)\n    higher_CI = np.exp(np.log(OR)+1.96*std_error)\n    \n    CI = \"95% CI: {:.2f}-{:.2f}\".format(lower_CI, higher_CI)\n    \n    #P-value: φ(z) = (1 / √2π) × e -z2/2\n    z = np.log(OR) / std_error\n    \n    p_value = (1/(np.sqrt(2*np.pi))) * np.exp(-(z**2)/2)\n    \n    #return \"OR: {:.2f} ({:}) p={:.2f}\".format(OR, CI, p_value)\n    return OR, lower_CI, higher_CI, CI, p_value\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display Results <a class=\"anchor\" id=\"display-header\"></a>\n![](http://)\nDisplay the results and save findings in CSV files.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_csv_file(tables_by_pmcid, disease):\n# Generates a CSV file for risk factor, comorbidity (disease) in line with target format\n    result_df = pd.DataFrame(columns=['Risk','Date', 'Title','url','Journal','Severe','Severe Lower Bound','Severe Upper Bound','Severe p-value','Severe Significant'])\n\n    for t in tables_by_pmcid:\n        pmcid = t['pmcid']\n        paper_data_dict = {}\n        #get information from the metadata\n        paper_info = metadata[metadata.pmcid == pmcid][['title', 'publish_time', 'source_x', 'url', 'pmcid','journal']]\n        if(len(paper_info) == 0):\n            #if does not find the paper, don't continue the process\n            break\n\n        paper_info = paper_info.iloc[0]\n        paper_data_dict['Risk']   = disease\n        paper_data_dict['Date']   = paper_info.publish_time\n        paper_data_dict['Title']  = paper_info.title\n        paper_data_dict['url']    = paper_info.url\n        paper_data_dict['Journal']    = paper_info.journal\n        \n        fatality_numbers = None\n        severe_numbers = None\n        for df in t['df_list']:\n            df.columns = df.iloc[0]\n            f = get_fatality_numbers(df, disease)\n            s = get_severity_numbers(df, disease)\n\n            if(f): fatality_numbers = f\n            if(s): severe_numbers = s\n         \n\n        if(severe_numbers): \n            #try:\n            severe_OR, severe_lower_CI, severe_higher_CI, severe_CI, severe_p_value = get_statistical_info(severe_numbers)\n            paper_data_dict['Severe'] = severe_OR\n            paper_data_dict['Severe Lower Bound'] = severe_lower_CI\n            paper_data_dict['Severe Upper Bound'] = severe_higher_CI\n            paper_data_dict['Severe p-value'] = severe_p_value\n            if (float(severe_p_value)<0.05):\n                paper_data_dict['Severe Significant'] = \"Significant\"\n            else:\n                paper_data_dict['Severe Significant'] = \"Not Significant\"\n            #paper_data_dict['Counts'] = str(severe_numbers[1]) + \",\" + str(severe_numbers[3])\n            #paper_data_dict['Sample'] = severe_numbers[1] + severe_numbers[3] \n            #except:\n                # No data  \n                #print(\"Insuffient data\")\n\n        if('Severe' in paper_data_dict): #or ('Fatality' in paper_data_dict):\n            result_df = result_df.append(paper_data_dict, ignore_index=True)\n            break\n    \n    if(len(result_df) > 0):\n        result_df.to_csv(disease + \".csv\")\n        display(HTML(result_df.to_html()))\n    return result_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_summary_csv_file(tables_by_pmcid, disease):\n# Generates a summary CSV file for risk factor, comorbidity (disease)\n    result_df = pd.DataFrame(columns=['Risk','Date', 'Study', 'pmcid','Source','url','Severe','Counts','Fatality', 'Sample'])\n    for t in tables_by_pmcid:\n        pmcid = t['pmcid']\n        paper_data_dict = {}\n        #get information from the metadata\n        paper_info = metadata[metadata.pmcid == pmcid][['title', 'publish_time', 'source_x', 'url', 'pmcid']]\n        if(len(paper_info) == 0):\n            #if does not find the paper, don't continue the process\n            break\n\n        paper_info = paper_info.iloc[0]\n        paper_data_dict['Risk']   = disease\n        paper_data_dict['Date']   = paper_info.publish_time\n        paper_data_dict['Study']  = paper_info.title\n        paper_data_dict['pmcid']    = paper_info.pmcid\n        paper_data_dict['Source'] = paper_info.source_x\n        paper_data_dict['url']    = paper_info.url\n\n        fatality_numbers = None\n        severe_numbers = None\n        for df in t['df_list']:\n            df.columns = df.iloc[0]\n            f = get_fatality_numbers(df, disease)\n            s = get_severity_numbers(df, disease)\n            if(f): fatality_numbers = f\n            if(s): severe_numbers = s\n                \n        if(fatality_numbers): \n            #f = get_statistical_info(fatality_numbers)\n            fatal_OR, fatal_lower_CI, fatal_higher_CI, fatal_CI, fatal_p_value = get_statistical_info(fatality_numbers)\n            paper_data_dict['Fatality'] = \"OR: {:.2f} ({:}) p={:.2f}\".format(fatal_OR, fatal_CI, fatal_p_value)\n            paper_data_dict['Sample'] = fatality_numbers[1] + fatality_numbers[3] \n\n        if(severe_numbers): \n            #s = get_statistical_info(fatality_numbers)\n            severe_OR, severe_lower_CI, severe_higher_CI, severe_CI, severe_p_value = get_statistical_info(severe_numbers)\n            paper_data_dict['Severe'] = \"OR: {:.2f} ({:}) p={:.2f}\".format(severe_OR, severe_CI, severe_p_value)\n            paper_data_dict['Counts'] = str(severe_numbers[1]) + \",\" + str(severe_numbers[3])\n            paper_data_dict['Sample'] = severe_numbers[1] + severe_numbers[3] \n\n                \n        if('Severe' in paper_data_dict) or ('Fatality' in paper_data_dict):\n            result_df = result_df.append(paper_data_dict, ignore_index=True)\n            break\n    \n    if(len(result_df) > 0):\n        result_df.to_csv(disease + \"-summary.csv\")\n        display(HTML(result_df.to_html()))\n    return result_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting all tables from the relevant papers\ntables_by_pmcid = []\nfor pmcid in relevant_papers:\n    df_list = get_all_tables(pmcid, False)\n    if(len(df_list) > 0): tables_by_pmcid.append({'pmcid': pmcid, 'df_list': df_list})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print some stats on tables \nm = 0\nn = 0\nfor paper in tables_by_pmcid:\n    if paper is not None:\n        m += len(paper['df_list'])\n        n += 1\nprint('Average number of tables per paper: {0}'.format(1.0*m/n))\nprint('Number of papers with tables: {0}'.format(n))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate target tables\ndiseases = static_risk_factors.name.values.tolist()\nfor d in diseases:\n    #print(\"\\nTable for disease\",d)\n    generate_csv_file(tables_by_pmcid, d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate summary tables\ndiseases = static_risk_factors.name.values.tolist()\nfor d in diseases:\n    #print(\"\\nTable for disease\",d)\n    generate_summary_csv_file(tables_by_pmcid, d)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion <a class=\"anchor\" id=\"conclusion-header\"></a>\n\nWe set out to provide a reproducible pipeline to search and extract quantitative, formal, data from previous research studies to derive odds ratios and confidence intervals for risk factors and comorbidities for Covid-19. \n\n### Pros and Cons of this Approach\n\n#### Pros\nOur approach provides the following features:\n* We combine high performance indexing and search features with online web services to extract quantitative data related to Covid-19. \n* We automate all of the steps needed to extract this crucial information in one reusable pipeline.\n* The end result is a set of odds ratios and confidence interval that provide statistical insight into Covid-19 risk factors.\n* The aggregation of data from multiple risk factor studies, can lead to a higher statistical power and more robust estimates than is possible from any individual study.\n* The analysis is highly reproducible, allowing other researchers to replicate and reuse the pipeline.\n* The system can be re-run as more data becomes available.\n    \n#### Cons \nThe following are the shortfalls of our approach:\n* We are pulling tables automatically where they have been provided in XML. We can expand the technique to HTML and PDF tables in the future.\n* The technique could suffer from publication bias, which is a type of bias that occurs when publishers favour results that show significant findings, potentially allowing the results to be generalized to a larger population.\n\n### Future Work\n* Expand the technique to HTML and PDF tables.\n* Add meta-analysis.\n* Inconsistency of results across studies can be quantified and analyzed.\n* Compute risk ratios\n* Process more table types.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}