{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install bs4","metadata":{"execution":{"iopub.status.busy":"2021-06-25T06:56:15.3631Z","iopub.execute_input":"2021-06-25T06:56:15.363492Z","iopub.status.idle":"2021-06-25T06:56:25.275816Z","shell.execute_reply.started":"2021-06-25T06:56:15.363378Z","shell.execute_reply":"2021-06-25T06:56:25.27469Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd#to read csv files\nimport numpy as np\nimport matplotlib.pyplot as plt#to plot data\nimport seaborn as sns\nimport string\nimport re\n\nfrom numpy import median\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\n\n\nfrom nltk.corpus import stopwords\nfrom bs4 import BeautifulSoup\n\n# from nltk.stem import WordNetLemmatizer\n# from nltk.stem import SnowballStemmer\n# from sklearn.feature_extraction.text import CountVectorizer\n# from nltk import pos_tag\n# from nltk.corpus import wordnet\n\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score\n# from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n# # from keras.optimizers import RMSprop\n# from keras.preprocessing.text import Tokenizer\n# from keras.preprocessing import sequence\n# # from keras.utils import to_categorical\n# from keras.preprocessing import sequence\n# from keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:06:45.382354Z","iopub.execute_input":"2021-06-25T07:06:45.382742Z","iopub.status.idle":"2021-06-25T07:06:45.389225Z","shell.execute_reply.started":"2021-06-25T07:06:45.382706Z","shell.execute_reply":"2021-06-25T07:06:45.388403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating an object by reading csv with encoding=latin-1\ndat = pd.read_csv('../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv', encoding= 'latin-1')\n#creating a new column which stores the len of the current message cell\ndat['len'] = dat['Message'].apply(len)\n#head is used to preview the first 5 lines\ndat.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T06:57:28.595813Z","iopub.execute_input":"2021-06-25T06:57:28.596192Z","iopub.status.idle":"2021-06-25T06:57:28.667835Z","shell.execute_reply.started":"2021-06-25T06:57:28.596156Z","shell.execute_reply":"2021-06-25T06:57:28.666686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EDA applied\n#it sets the figure size w=12 and height=5 and dpi=60\nplt.figure(figsize=(12,5), dpi=60)\n#It will declare space for subplots\nplt.subplot(1,2,1)\n#it will plot counts-plot-graph the number of times Category column values appear\nsns.countplot(y=dat['Category'], palette=\"Set3\")\n#It will declare space for subplots\nplt.subplot(1,2,2)\n#it will plot bar graph with x-axix of len column and y-axix of category column\nsns.barplot(x=dat['len'],y=dat['Category'],data=dat, estimator=median, palette=\"Set3\")","metadata":{"execution":{"iopub.status.busy":"2021-06-25T06:58:10.840243Z","iopub.execute_input":"2021-06-25T06:58:10.840605Z","iopub.status.idle":"2021-06-25T06:58:11.264218Z","shell.execute_reply.started":"2021-06-25T06:58:10.840573Z","shell.execute_reply":"2021-06-25T06:58:11.263105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(text):\n    #here we will use tranlated to remove the punctuation symbols\n    text = text.translate(str.maketrans('','', string.punctuation))\n    #following list comprehension will only add words that are not common words like a, an, the etc\n    #for this we first convert the word to lower and then check that it doesn't belong to stop-words\n    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n    #it will return a string that joins a list with name text\n    return \" \".join(text)\n\ndef strip_html(text):\n    #beautiful soap is used to get data from web pages by removing the html tags\n    soup = BeautifulSoup(text, \"html.parser\")\n    #returns by getting text from soup\n    return soup.get_text()\n\ndef remove_between_square_brackets(text):\n    #re.sub delete symbols from the text\n    return re.sub('\\[[^]]*\\]', '', text)\n\ndef remove_between_square_brackets(text):\n    #re.sub delete https protocols links from the text\n    return re.sub(r'http\\S+', '', text)\n\ndef denoise_text(text):\n    text = preprocess(text)\n    text = strip_html(text)\n    text = remove_between_square_brackets(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-06-25T06:58:28.679937Z","iopub.execute_input":"2021-06-25T06:58:28.68027Z","iopub.status.idle":"2021-06-25T06:58:28.689934Z","shell.execute_reply.started":"2021-06-25T06:58:28.68024Z","shell.execute_reply":"2021-06-25T06:58:28.688982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#it preprocesses the message and create new c_message column\ndat['C_Message'] = dat['Message'].apply(denoise_text)\ndat.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T06:58:31.934745Z","iopub.execute_input":"2021-06-25T06:58:31.935092Z","iopub.status.idle":"2021-06-25T06:58:42.121849Z","shell.execute_reply.started":"2021-06-25T06:58:31.935062Z","shell.execute_reply":"2021-06-25T06:58:42.121062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#it replace ham with 0 and spam with 1 in category column\ndat['Category'] = dat['Category'].map({'ham': 0, 'spam': 1})\ndat.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T06:59:01.009674Z","iopub.execute_input":"2021-06-25T06:59:01.010185Z","iopub.status.idle":"2021-06-25T06:59:01.023256Z","shell.execute_reply.started":"2021-06-25T06:59:01.010151Z","shell.execute_reply":"2021-06-25T06:59:01.022352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dat['C_Message']\nY = dat['Category']\n#we used the train test split to split data to evaluate data without any biasedness\n#for splitting data arrays into two subsets: for training data and for testing data. \n#With this function, you don't need to divide the dataset manually\n# print(Y)\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n#it transforms text into a meaningful representation of numbers which is used to fit machine algorithm\nvect = TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n#it is used to scale the training and test data\nx_train = vect.fit_transform(x_train)\nx_test = vect.transform(x_test)\nprint(x_train.shape)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T06:59:50.456754Z","iopub.execute_input":"2021-06-25T06:59:50.457334Z","iopub.status.idle":"2021-06-25T06:59:50.742847Z","shell.execute_reply.started":"2021-06-25T06:59:50.457288Z","shell.execute_reply":"2021-06-25T06:59:50.74161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we use imported classifiers to fit the trained data to make it ready for the predict function\nsvc = SVC(kernel='sigmoid', gamma=1.0)\nknc = KNeighborsClassifier(n_neighbors=49)\nmnb = MultinomialNB(alpha=0.2)\ndtc = DecisionTreeClassifier(min_samples_split=7, random_state=111)\nlrc = LogisticRegression(solver='liblinear', penalty='l1')\nrfc = RandomForestClassifier(n_estimators=31, random_state=111)\nabc = AdaBoostClassifier(n_estimators=62, random_state=111)\nbc = BaggingClassifier(n_estimators=9, random_state=111)\netc = ExtraTreesClassifier(n_estimators=9, random_state=111)\nscore = []\nfor i,j in enumerate([svc,knc,mnb,dtc,lrc,rfc,abc,bc,etc]):\n    j.fit(x_train,y_train)\n    pred = j.predict(x_test)\n    score.append([accuracy_score(y_test,pred)])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:20:35.711573Z","iopub.execute_input":"2021-06-25T07:20:35.712551Z","iopub.status.idle":"2021-06-25T07:21:55.977525Z","shell.execute_reply.started":"2021-06-25T07:20:35.712418Z","shell.execute_reply":"2021-06-25T07:21:55.976502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#here created a dictionary with classifier name as key and and value from the fit score list items\nlab = {'SVM': [score[0]],'KNeighborClassifier': [score[1]],'MultinomialNB':[score[2]],\n      'DecisionTreeClassifier':[score[3]],'LogisticRegression':[score[4]],\n      'RandomForestClassifier':[score[5]],'Adaboost':[score[6]],'BaggingClassifier':[score[7]],\n      'ExtraTreesClassifier':[score[8]]}\n\n#created data frame by passing lab as a dict and column as the name of the classifier\nresult = pd.DataFrame(lab, columns = ['SVM','KNeighborClassifier', 'MultinomialNB',\n                                  'DecisionTreeClassifier','LogisticRegression','RandomForestClassifier',\n                                  'Adaboost','BaggingClassifier','ExtraTreesClassifier'])\n#Took the transpose of the first five rows\nnp.transpose(result.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-25T07:08:47.578684Z","iopub.execute_input":"2021-06-25T07:08:47.579316Z","iopub.status.idle":"2021-06-25T07:08:47.596457Z","shell.execute_reply.started":"2021-06-25T07:08:47.579281Z","shell.execute_reply":"2021-06-25T07:08:47.595472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}