{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the right libraries\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.set_option('max_columns', 100)\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport re\nfrom collections import Counter\nfrom wordcloud import WordCloud\nfrom datetime import datetime\nimport nltk\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/amazon-top-50-bestselling-books-2009-2019/bestsellers with categories.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There seems to be no missing data in this dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop_duplicates(subset = ['Name'])\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I decided to remove books that are of the same title but published in a different year. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using a describe function can catch some anomalies from the very start. Look at the minimum price for some books. They are basically free and those are anomalies. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Price'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['Price'] != 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Books that are unpriced should be removed from the data set. "},{"metadata":{},"cell_type":"markdown","source":"# Data Visualisation "},{"metadata":{},"cell_type":"markdown","source":"**Price**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(1,3,1)\nsns.distplot(df['Price'])\n\nfig.add_subplot(1,3,2)\nsns.distplot(np.log1p(df['Price']))\nplt.xlabel('log1p(price)')\n\nfig.add_subplot(1,3,3)\nsns.distplot(np.log(df['Price']))\nplt.xlabel('log(price)')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I plotted a total of three distributions of price. As seen from the first plot, the distribution is skewed. Therefore, i used a log function to create a more even distribution as seen from the second and third plot. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['log(price)'] = np.log1p(df['Price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I added log(price) into our dataframe."},{"metadata":{},"cell_type":"markdown","source":"**Name**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(rows):\n    title = str(rows).lower()\n    title = re.sub(\"[^a-zA-Z_]\", ' ', title)\n    #title = re.sub('[+-\\/|]', ' ', title)\n    #title = re.sub('[!#\\\"~*)(,.:;?]', ' ', title)\n    #title = \"\".join(re.findall('[a-zA-Z0-9\\s]', title))\n    return title\n\ndf['process_name'] = df['Name'].apply(preprocess)\ndf['process_name'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, I needed to clean the titles. Then, we are able to obtain character length and word length. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['name_character_length'] = df['process_name'].apply(lambda x : len(x.strip()))\ndf['name_word_length'] = df['process_name'].apply(lambda x : len(x.split(' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,10))\n\nfig.add_subplot(3,2,1)\nsns.distplot(df['name_character_length'])\nplt.title('Distribution of character length in name')\n\nfig.add_subplot(3,2,2)\nsns.distplot(df['name_word_length'])\nplt.title('Distribution of word length in name')\n\n\nfig.add_subplot(3,2,3)\nsns.scatterplot(df['name_character_length'], df['Price'])\n\nfig.add_subplot(3,2,4)\nsns.scatterplot(df['name_word_length'], df['Price'])\n\nfig.add_subplot(3,2,5)\nsns.scatterplot(df['name_character_length'], df['log(price)'])\n\n\nfig.add_subplot(3,2,6)\nsns.scatterplot(df['name_word_length'], df['log(price)'])\n\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most titles have around 25 characters and about a total of 5 words. I attempted to visualise the relationship between price and words. However, as seen from the scatterplot, there seems to be no clear relationship."},{"metadata":{"trusted":true},"cell_type":"code","source":"name_words = []\nenglish_stopwords = stopwords.words('english')\n#english_stopwords.append('book', 'books')\nfor element in df['process_name'].values:\n    name_words.extend(element.split(' '))\n\nname_words = [word for word in name_words if word not in english_stopwords]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total no of words : \", len(name_words))\nprint(\"Total unique words : \", len(set(name_words)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name_reqs = {i[0] : i[1] for i in Counter(name_words).most_common(100)}\nplt.figure(figsize = (20,20))\nwordcloud = WordCloud(width=800,height=600,min_font_size=10, background_color = 'white').generate_from_frequencies(name_reqs)\nplt.imshow(wordcloud)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the wordcloud, you could see the most common words. "},{"metadata":{"trusted":true},"cell_type":"code","source":"list_word = Counter(name_words).most_common(30)\ndf_words = pd.DataFrame(list_word, columns = ['word', 'frequency'])\ndf_words = df_words.drop(df.index[0])\ndf_words.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = df[['process_name', 'Price', 'log(price)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_list = df_words.word.values.tolist()\nfor word in words_list:\n    temp_df[word] = temp_df['process_name'].apply(lambda x : 1 if word in x else 0)\n    \ntemp_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = dict()\nwords['word'] = []\nwords['mean_price'] = []\nwords['median_price'] = []\n\nfor word in words_list:\n    words['word'].append(word)\n    words['mean_price'].append(temp_df[temp_df[word] == 1]['Price'].mean())\n    words['median_price'].append(temp_df[temp_df[word] == 1]['Price'].median())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = pd.DataFrame(words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15, 10))\n\nfig.add_subplot(2,1,1)\nsns.barplot(words['word'], words['mean_price'], label = \"average price of the books with words\", order = words['word'])\nplt.axhline(df['Price'].mean(), linestyle = \":\", label = \"average mean price of all the books\")\nplt.xticks(rotation = 45)\nplt.title(\"Plot showing average price of books with most frequent words\")\nplt.legend()\n\nfig.add_subplot(2,1,2)\nsns.barplot(words['word'], words['median_price'], label = \"median price of the books with words\")\nplt.axhline(df['Price'].median(), linestyle = \":\", label = \"median mean price of all the books\")\nplt.xticks(rotation = 45)\nplt.title(\"Plot showing Median price of books with most frequent words\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The visualisations above shows you the average price of the book containing the most frequent words. Books that have different editions are more expensive on average. Perhaps because the books are textbooks (usually many editions printed) which are usually already more expensive. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 5))\nsns.distplot(df['log(price)'], label = \"Price distribution of overall dataset\")\nsns.distplot(np.log1p(words['mean_price']), label = \"Average Price distribution records with frequent words\")\nsns.distplot(np.log1p(words['median_price']), label = \"Median Price distribution of records with frequent words\")\nplt.legend()\nplt.grid(linestyle = \":\")\nplt.xlabel(\"Price Distribution\")\nplt.title(\"Price Distribution of books having top 30 most frequent words in name vs Overall data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the distribution above, there is no clear relationship that price is affected by the words used. "},{"metadata":{},"cell_type":"markdown","source":"**Author**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_author = df[['Author', 'Price']]\n\nauthors = dict()\nauthors['author'] = []\nauthors['mean_price'] = []\n\nfor n in df_author['Author'].unique().tolist():\n    authors['author'].append(n)\n    authors['mean_price'].append(df_author[df_author['Author'] == n]['Price'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"authors = pd.DataFrame(authors)\nauthors = authors.sort_values('mean_price', ascending = False).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize =(100,100))\nsns.barplot(authors['author'], authors['mean_price'], label = 'mean price for each author')\nplt.axhline(df['Price'].mean(), label = 'overall mean price')\nplt.axhline(df['Price'].median(), label = 'overall median price')\nplt.xticks(rotation = 90)\nplt.title('Average price of books sold by each author')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"authors.iloc[0:10,]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**User Rating**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,5))\nsns.distplot(df['User Rating'])\nplt.title('Distribution of user ratings')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(2,1,1)\nsns.scatterplot(df['User Rating'], df['Price'])\nplt.title('price against user rating')\n\nfig.add_subplot(2,1,2)\nsns.scatterplot(np.log1p(df['User Rating']), np.log1p(df['Price']))\nplt.title('log(price) against log(user rating)')\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Price seems to increase with rating. But it may not be conclusive as data is also cluttered at higher ratings. "},{"metadata":{},"cell_type":"markdown","source":"**Reviews**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,5))\nsns.distplot(df['Reviews'])\nplt.title('Distribution of reviews')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(2,1,1)\nsns.scatterplot(df['Reviews'], df['Price'])\nplt.title('price against reviews')\n\nfig.add_subplot(2,1,2)\nsns.scatterplot(np.log1p(df['Reviews']), np.log1p(df['Price']))\nplt.title('log(price) against log(reviews)')\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, there seem to be no relationship between reviews and price as seen from the scatter plot. Is there any way to draw relationships? Am i doing this wrong?"},{"metadata":{},"cell_type":"markdown","source":"**Genre**"},{"metadata":{},"cell_type":"markdown","source":"There are only 2 main genres. Fiction and non-fiction. There are more non-fiction books than fiction books in this dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,5))\nplt.pie(df['Genre'].value_counts(), labels = ['Non Fiction', 'Fiction'], autopct=\"%.1f%%\")\nplt.title('distribution of genres')\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also use groupby functions to split genres and count the number of reviews each genre has. "},{"metadata":{"trusted":true},"cell_type":"code","source":"genre = df.groupby('Genre')['Reviews'].agg(['count', 'mean', 'median'])\ngenre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(1,2,1)\nsns.barplot(y= 'mean' , x= genre.index, data=genre)\nplt.title('mean reviews across genres')\n\nfig.add_subplot(1,2,2)\nsns.barplot(y= 'median' , x= genre.index, data=genre)\nplt.title('median reviews across genres')\n\nplt.tight_layout()\n\n\n#how to combine using seaborn? send help","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15, 5))\n\nfig.add_subplot(1,2,1)\nsns.boxplot(x = df['Genre'], y = df['Reviews'])\n\nfig.add_subplot(1,2,2)\nsns.violinplot(x = df['Genre'], y = df['Reviews'])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Year**"},{"metadata":{},"cell_type":"markdown","source":"In this section, I attempted to use a pivot table for the first time. Indexing by year and genre, we can get the average of each other features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize = (15, 10))\npivot = pd.pivot_table(df, index =('Year','Genre'), aggfunc = np.mean)\npivot\n#sns.heatmap(pivot, annot = True, fmt = 'g')\n#plt.xticks(labels = ['Non Fiction', 'Fiction'])\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using 'values' = price would give you the price for each data point. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot = pd.pivot_table(df, index = 'Year', columns = 'Genre', values = 'Price' )\npivot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is also possible to better visualise a pivot table through a heatmap which i thought was pretty cool. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,5))\nsns.heatmap(pivot, annot = True)\nplt.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}