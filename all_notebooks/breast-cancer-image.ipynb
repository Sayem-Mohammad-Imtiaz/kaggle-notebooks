{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7fb1404-c211-4415-aa01-bdd0d1d6e8ce"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71d3d68a-cf13-5761-a59d-ca7516951077"},"outputs":[],"source":"#Read data\ndf=pd.read_csv('../input/data.csv',index_col='id')\n# Change diagnosis cell to int and keep it in 'type' column\ndf['type']=df['diagnosis'].map({'B':0,'M':1}).astype(int)\ndel df['diagnosis']\n\n#There is an extra comma at the end of the csv file header. remove it\ndf=df[df.columns[~df.columns.str.contains('Unnamed:')]]\n\n# get a list of the header names\nheader=list(df.columns.values)\nheader.remove('type')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e6c3bf46-399d-03b5-c539-5079ffd151d1"},"outputs":[],"source":"#Check the ditribution of features in regard to the cancer type\ndf.groupby('type').hist(figsize=(6, 6))\n\n#get correlation of features among eachother\n#from pandas.tools.plotting import scatter_matrix\n#scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal='kde')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"64888737-bc71-ec12-6757-42d3abf77616"},"outputs":[],"source":"# get the correlation of features to the type of tumor \ndf.corr()['type'].plot(kind='bar')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0a3497f-e7c1-14d3-e82a-ec4d6a70c4fc"},"outputs":[],"source":"#Scale values to plot them as boxplot and to cheak the outliers\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\ndf[header] = MinMaxScaler().fit_transform(df[header])\nbar=df.boxplot(rot=90,column=header,return_type='axes')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c4264d4-e80f-3bc4-346c-41c57d92ce0c"},"outputs":[],"source":"# Create a test and training dataset and create a simple classifier\n# Break data to training and test\n# Generate the training set.  Set random_state to be able to replicate results.\ntrain = df.sample(frac=0.8, random_state=1)\n# Select anything not in the training set and put it in the testing set.\ntest = df.loc[~df.index.isin(train.index)]\n\ntrain_features_value=train.ix[:,train.columns !='type']\ntest_features_value=test.ix[:,test.columns !='type']\nh=train_features_value.columns.values\n\ntrain_data=train_features_value.values\ntest_data=test_features_value.values\n\nactual_test_prediction=test['type'].values\n\n# Build a simple RandomForest Classifier using all features\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import cross_validation\n\nclf = RandomForestClassifier(n_estimators=100)\nscores = cross_validation.cross_val_score(clf, train_data,train['type'].values, cv=3)\nprint(scores)\n\n#Or\n\n# forest = RandomForestClassifier(n_estimators = 100)\n#  Fit the training data to the Survived labels and create the decision trees\n# forest = forest.fit(train_data,train['type'].values)\n# # # Take the same decision trees and run it on the test data\n# prediction_array = forest.predict(test_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66b227e2-9cc9-2995-b2d7-ec47bf45625e"},"outputs":[],"source":"#Is our simple calssifier doing better than majority vote class\ndef majority_class_classifier(actual):\n    num_positive = ( actual == 1).sum()\n    num_negative = ( actual== 0).sum()\n    if num_positive>num_negative:\n        majority_class= 1\n    else:\n        majority_class= 0\n\n    # build an array where all the prediction is the majority vote class: e.g. a list of all +1\n    class_prediction_array=[majority_class]*len(actual)\n    # use this to calculate the accuracy\n    acc_majority=calculate_accuracy(actual,class_prediction_array)\n\n    print (\"Majority_class_classifier_accuracy _is:\",acc_majority)\n\ndef calculate_accuracy(actual,prediction):\n    # print \"actual data:\",test_data['sentiment']\n    actual_data_array=np.array(actual)\n    prediction_array=np.array(prediction)\n    # print actual_data_array\n\n    accuracy= accuracy_score(actual_data_array, prediction_array)\n    return accuracy\n\n#Yes it does!\nmajority_class_classifier(actual_test_prediction)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8a74125-ac87-66f6-0973-4d1b9065d324"},"outputs":[],"source":"# Use Random Forest to calculate feature importance \n\nfrom sklearn.ensemble import ExtraTreesClassifier\nforest = ExtraTreesClassifier(n_estimators=100,random_state=0)\nX=train_data\ny=train['type'].values\nforest.fit(X, y)\nimportances = forest.feature_importances_\n\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\nindices = np.argsort(importances)[::-1]\nlable_features_sorted=[]\nfor i in indices:\n     lable_features_sorted.append(header[i])\n\nplt.title(\"Feature importances\")\nplt.bar(range(X.shape[1]), importances[indices],color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(X.shape[1]),lable_features_sorted ,rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}