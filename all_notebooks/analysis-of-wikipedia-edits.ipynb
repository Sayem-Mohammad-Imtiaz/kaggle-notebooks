{"cells":[{"metadata":{"_uuid":"a11079d242c85d868575dab346910333545d69c9"},"cell_type":"markdown","source":"# Research Questions\nThere are 3 research questions in this study, as enrolled below:\n1. Can we treat Wikipedia as a stable source of information?\n1. Is the published material on Wikipedia accountable?\n1. What are the most frequent words in edited titles?"},{"metadata":{"_uuid":"dcef8b841e6192b56a64252dc099cb0cb6bf3f15"},"cell_type":"markdown","source":"# Setup and Initial Exploration of the Dataset"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2817da3bd4c5b90b2cf7ac170e649dbe494fb813"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport nltk","execution_count":1,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3dd1556d18ff12aecdc4cb94adcbf5c339b462e7","collapsed":true},"cell_type":"code","source":"%%javascript\n// We disable auto-scrolling in our notebook.\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"1cdad0c0a3bdfffe9f5aa47a9203d5470c4e294a"},"cell_type":"markdown","source":"Let's first make a working copy of our input file:"},{"metadata":{"trusted":false,"_uuid":"c14346df31cbc1d0457ccfc96f1c69dd90fb8932","collapsed":true},"cell_type":"code","source":"!cp -rf ../input/edits.csv edits.csv","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d3f12fd554ef229540e63bdabca8582c842e5f30"},"cell_type":"markdown","source":"We must replace all GEO IP information (represented as embedded dictionaries) with null to allow Pandas to properly process the CSV file. Otherwise, it may get confused about unequal number of fields, while encountering nested structures (they also contain fields separated by commas). The easiest way is to rely on `sed`."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"14cafd9733f24f3e93c71e4ee7d1dd7a8bd0f6bd"},"cell_type":"code","source":"!sed -Ei 's/\\{.+\\}/null/' edits.csv","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"8b351a3c0b925b46de254c04be228936b9672d4c"},"cell_type":"markdown","source":"Now, we must put all titles under double quotation marks, as some contain commas."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0c5d076368a5995710702ef677a714b6ead30678"},"cell_type":"code","source":"!sed -Ei 's/([^,]+,)([^,]+,)([^,]+,)([^,]+,)([^,]+,)([^,]+,)(.+),http/\\1\\2\\3\\4\\5\\6\"\\7\",http/' edits.csv","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"80791469b0aeb66b7f26efb34a446a5ba845ff52"},"cell_type":"markdown","source":"We will read in the dataset, show some statistics, and drop unused columns."},{"metadata":{"trusted":false,"_uuid":"62d53bf3987643a4531b69a67a9f4da362883dee","collapsed":true},"cell_type":"code","source":"all_edits = pd.read_csv('edits.csv',\n                        header = None,\n                        names=[\"Action\", \"Size\", \"Geo IP\", \"Is Anonymous?\", \n                               \"Is Bot?\", \"Is Minor?\", \"Title\", \"URL\", \"User\"])\nall_edits.shape","execution_count":6,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"903b27bdc5bc682b4d89183d381130588263f213","collapsed":true},"cell_type":"code","source":"all_edits.dtypes","execution_count":7,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"d69f9e9cd0c12683b0bf8f4cd0b3322142698562","collapsed":true},"cell_type":"code","source":"all_edits.head(10)","execution_count":8,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f23a27294b504af163b6a922f221d5892cd71598","collapsed":true},"cell_type":"code","source":"all_edits.drop(all_edits.columns[[0, 2, 8]], axis=1, inplace=True)\nall_edits.head()","execution_count":9,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8b0687eac91005552662855db67ee63bb2de66e3","collapsed":true},"cell_type":"code","source":"all_edits[\"URL\"].nunique()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"3c9fc0bb5a1acb62a62a2344f306092e3917ce1e"},"cell_type":"markdown","source":"Obviously there are two edits for the same URL. Nonetheless, this single outlier is negligible. We can drop now the URL column, too."},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"d8a602b1cde11b781327da341c5fb54c71b64f4b","collapsed":true},"cell_type":"code","source":"all_edits.drop(\"URL\", axis=1, inplace=True)\nall_edits.head()","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"2d5f39aa02c7853f6a120b896a19113fc8e885aa"},"cell_type":"markdown","source":"Finally, we must convert sizes to positive values, and introduce an extra boolean column regarding the edit type. A zero means that an equal number of characters were deleted and added during an edit. Of course, this doesn't imply a small update, though."},{"metadata":{"trusted":false,"_uuid":"5853af608ebf66ffd31b6b75f2241a271cd93073","collapsed":true},"cell_type":"code","source":"all_edits[\"Is Deletion?\"] = all_edits[\"Size\"] < 0\nall_edits[\"Size\"] = abs(all_edits[\"Size\"])\nall_edits.head()","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"cbcda7e4944cacdaec72bbeb742124ad10b81723"},"cell_type":"markdown","source":"Let we see the summary statistics of sizes, and how many of them are zeroes."},{"metadata":{"trusted":false,"_uuid":"0e948c4fdb9282f92cad8f1b79b76b44f4aa624c","collapsed":true},"cell_type":"code","source":"all_edits[\"Size\"].describe()","execution_count":13,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1b25fab77dcbc35d921f5d0dc8b86154b5204374","collapsed":true},"cell_type":"code","source":"sum(all_edits[\"Size\"] == 0)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"715b3e3edee2dc497373cfc6f64cbf6d438ce515"},"cell_type":"markdown","source":"# Can we Treat Wikipedia as a Reliable Source of Information?"},{"metadata":{"_uuid":"0894873f85bd248f266fb678f38b238b00afabf5"},"cell_type":"markdown","source":"To answer our first and second research questions we will produce stacked histograms. Nonetheless, our first step is to look at the relationship (pattern) between sizes of changes and whether they are minor/major. There is no much sense to try establish the correlation coefficient here, since the Y axis contains only two values."},{"metadata":{"trusted":false,"_uuid":"14896d667af65b9c68d4fb779ed7cf0758237d2a","collapsed":true},"cell_type":"code","source":"fig, axis = plt.subplots(figsize=(12, 7))\n\naxis.xaxis.grid(True)\naxis.set_title(\"Are size differences related to importance?\", fontsize=13)\naxis.set_xlabel(\"Size of Change (in number of characters)\", fontsize=10)\naxis.set_ylabel(\"Is Minor?\", fontsize=10)\naxis.set_yticks([0, 1])\naxis.set_yticklabels([\"False\", \"True\"])\n\naxis.scatter(all_edits[\"Size\"], all_edits[\"Is Minor?\"])\nplt.show()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"5aea8b3a5c6e9d8b400c2ccd174164cfb03e41cc"},"cell_type":"markdown","source":"We may notice that bigger changes (whose size is above 2500) are major ones. In other words, a large difference in content's size is regarded as an important edit.  "},{"metadata":{"trusted":false,"_uuid":"61eb5bc9485ee386d446aebdc973d5ecd62485db","collapsed":true},"cell_type":"code","source":"fig, axis = plt.subplots(figsize=(20, 15), nrows=2, ncols=2)\nax0, ax1, ax2, ax3 = axis.flatten()\ncolors = ['red', 'green']\n\n# Contains common logic for setting up the subplots.\ndef setup_hist(ax, labels, data):\n    ax.set_title(\"Distribution of {} vs. {} edits\".format(labels[0], labels[1]), fontsize=13)\n    ax.set_xlabel(\"Size of Change (in number of characters)\", fontsize=11)\n    ax.set_ylabel(\"Number of edits (log. scale)\", fontsize=11)\n    ax.set_yscale(\"log\", nonposy='clip')\n    ax.hist(data, 15, histtype='bar', density=False, color=colors, label=labels, stacked=True)\n    ax.legend(prop={'size': 15})\n\n# Contains logic to retrieve pertinent data for the next plot.\ndef filter_edits(column):\n    data_mask = all_edits[column]\n    primary_edits = all_edits[data_mask][\"Size\"]\n    complementary_edits = all_edits[np.logical_not(data_mask)][\"Size\"]\n    return (primary_edits, complementary_edits)\n\nsetup_hist(ax0, [\"Anonymous\", \"Registered\"], filter_edits(\"Is Anonymous?\"))\nax0.annotate(\">2500 only major edits are present,\\nas depicted on the previous scatter plot.\",\n             xy=(2800, 3), xycoords='data',\n             xytext=(2800, 30), textcoords='data',\n             arrowprops=dict(arrowstyle=\"->\",\n                             connectionstyle=\"arc3\"),\n             fontsize=13\n            )\n\nsetup_hist(ax1, [\"Bot\", \"Human\"], filter_edits(\"Is Bot?\"))\nsetup_hist(ax2, [\"Minor\", \"Major\"], filter_edits(\"Is Minor?\"))\nsetup_hist(ax3, [\"Reduction in Size\", \"Non-reduction in Size\"], filter_edits(\"Is Deletion?\"))\n\nfig.tight_layout()\nplt.show()","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"d8697926c7946bc2b3c973fc874368484677a438"},"cell_type":"markdown","source":"We may observe the following patterns in these diagrams:\n- Updates entailing larger differences in size are made by registered users. This suggests that anonymous edits are mostly about correcting smaller issues, and somehow establishes a proper accountability mechanism in Wikipedia, where the bulk of the new material does possess a lineage. \n- There are no bots doing the edits, which boosts our confidence in Wikipedia's content.\n- As we have noticed before, alterations resulting in larger differences in size are considered as major changes.\n- Larger edits are mostly about adding content. This means that material on Wikipedia is mostly stable, and deletions are probably for smaller changes.\n- Most frequent updates are about minor fixes.\n\n**The size attribute is about relative difference in size. We will assume that a small size indicates a small change!**"},{"metadata":{"_uuid":"86a167b60efc49307953cb4e2e4fde2f1db8869b"},"cell_type":"markdown","source":"# List of the Most Frequent Words in Edited Titles"},{"metadata":{"_uuid":"7b672429f1115cc54f8404386b4c4f9fdca9c30e"},"cell_type":"markdown","source":"`nltk` has a sophisticated  `word_tokenize` function to properly tokenize the titles:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a529bbc5dc4ea8d27e5255d63764715aa0c122a9"},"cell_type":"code","source":"titles = ''.join(all_edits[\"Title\"])\ntokenized_titles = nltk.word_tokenize(titles)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"eee377521dd59b0857c9417836cb9f9c02e82043"},"cell_type":"markdown","source":"The tokenized titles are full of punctuations, and words useless for counting purposes like \"of\" or \"that\" are also included. Those words are named *stopwords* and `nltk` has a convenient set that we can use:"},{"metadata":{"trusted":false,"_uuid":"58aade6698b86ae6eb92f1bcfeece4c2f00f600c","collapsed":true},"cell_type":"code","source":"import string\nprint(\"Punctuations as defined in Python:\", string.punctuation)","execution_count":19,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"99dc09604a75da8f79e6b456c0049ac54b965ef6"},"cell_type":"code","source":"# Remove punctuations.\nfiltered_words = [word.translate(str.maketrans('', '', string.punctuation)) for word in tokenized_titles]\n# Remove empty strings.\nfiltered_words = [word.lower() for word in filtered_words if word]\n# Eliminate stopwords.\nstopwords = set(nltk.corpus.stopwords.words(\"english\"))\nfiltered_words = [word for word in filtered_words if not word in stopwords]","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"3c6a81bf2d727fdd0d67161dc860520dd734b4e8"},"cell_type":"markdown","source":"The `collection` package of the standard library contains a `Counter` class that is handy for counting frequencies of words in our list:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"813b0f7fd9136cba0bb2064cfb85cc2bc53a904d"},"cell_type":"code","source":"from collections import Counter\n\nword_counter = Counter(filtered_words)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"9ca85bee394f35f311e2ff62ac2ffc4d6b41cb41"},"cell_type":"markdown","source":"It also has a `most_common()` method to access the words with the higher count:"},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"7e6fe30f6de7a61b597b24c1270f9674182b571e","collapsed":true},"cell_type":"code","source":"most_common_words = word_counter.most_common()[:30]\nmost_common_words","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"f3a5a62a64fc78e4fe6075c8d67e8c11206dad5f"},"cell_type":"markdown","source":"We will now produce a Word Cloud using the open-source Python library [worldcloud](https://github.com/amueller/word_cloud):"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"de407e1c4b43c665535a8e289db0bd9f580c4f18"},"cell_type":"code","source":"from wordcloud import WordCloud","execution_count":23,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d9afe4c7d2de2fdc29ca689231e313d46a6e80d9","collapsed":true},"cell_type":"code","source":"wordcloud = WordCloud(max_font_size=40).generate(' '.join(filtered_words))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"e05515790a27ed563ad56252f90407a592be20a6"},"cell_type":"markdown","source":"Based upon this sample we can see terms related to movies, sport, music, etc. Scientific and advanced technical concepts are rare, which means that sort of material is more steady (requires a higher expertise to edit).  "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}