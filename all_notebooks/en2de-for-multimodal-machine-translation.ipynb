{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport matplotlib.image as mp\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T10:56:05.582788Z","iopub.execute_input":"2021-06-11T10:56:05.583102Z","iopub.status.idle":"2021-06-11T10:56:05.717405Z","shell.execute_reply.started":"2021-06-11T10:56:05.583029Z","shell.execute_reply":"2021-06-11T10:56:05.716637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/en2deformultimodelmac/training/train.de') as f:\n    train_de = f.read().split('\\n')\nwith open('../input/en2deformultimodelmac/training/train.en') as f:\n    train_en = f.read().split('\\n')\nwith open('../input/en2deformultimodelmac/splits/train_images.txt') as f:\n    train_img_name = f.read().split('\\n')\ntrain_de.pop()\ntrain_de.pop()\ntrain_en.pop()\ntrain_en.pop()\ntrain_img_name.pop()\nprint(len(train_de))\nprint(len(train_en))\nprint(len(train_img_name))\nimg_path=[]\nfor s in train_img_name:\n    img_path.append(\"../input/flickr-image-dataset/flickr30k_images/flickr30k_images/\"+s)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:56:05.718916Z","iopub.execute_input":"2021-06-11T10:56:05.719261Z","iopub.status.idle":"2021-06-11T10:56:05.887219Z","shell.execute_reply.started":"2021-06-11T10:56:05.719224Z","shell.execute_reply":"2021-06-11T10:56:05.88629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im=mp.imread(img_path[1])\nplt.imshow(im)\nprint(img_path[1])\nprint(\"de:\"+train_de[1])\nprint(\"en:\"+train_en[1])","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:56:05.888814Z","iopub.execute_input":"2021-06-11T10:56:05.889062Z","iopub.status.idle":"2021-06-11T10:56:06.125426Z","shell.execute_reply.started":"2021-06-11T10:56:05.889038Z","shell.execute_reply":"2021-06-11T10:56:06.124608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"choicenum=5000\ntrain_de=train_de[:choicenum]\ntrain_en=train_en[:choicenum]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:56:06.126717Z","iopub.execute_input":"2021-06-11T10:56:06.127017Z","iopub.status.idle":"2021-06-11T10:56:06.133484Z","shell.execute_reply.started":"2021-06-11T10:56:06.126983Z","shell.execute_reply":"2021-06-11T10:56:06.132446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"de_df = pd.DataFrame(train_de, columns=['de']) \nen_df = pd.DataFrame(train_en, columns=['en']) \nimport re\ndef clean_text(text):\n    '''Clean text by removing unnecessary characters and altering the format of words.'''\n    text = text.lower()\n    text = re.sub(r\" ᠃\", \"\", text)\n    text = re.sub(r\" ᠂\", \"\", text)\n    text = re.sub(r\"-\", \" \", text)\n    text = re.sub(r\"<5>\", \"5\", text)\n    text = re.sub(r\"“ \", \"\", text)\n    text = re.sub(r\" ”\", \"\", text)\n    text = re.sub(r\"[+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，〈〉《》。︱？?、．％~@#￥%……&*（）’]\", \"\", text)\n    text=text.rstrip()\n    #text=' '.join(text.split())\n    return text\n\ntext1 = en_df[\"en\"].apply(clean_text)\ntext2 = de_df[\"de\"].apply(clean_text)\ntext1 = list(text1.values)\ntext2 = list(text2.values)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:56:06.134935Z","iopub.execute_input":"2021-06-11T10:56:06.135505Z","iopub.status.idle":"2021-06-11T10:56:06.253293Z","shell.execute_reply.started":"2021-06-11T10:56:06.135469Z","shell.execute_reply":"2021-06-11T10:56:06.252491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texttemp=[]\nfor s in text2:\n    temp=\"cls \"+s+\" eos\"\n    texttemp.append(temp)\ntext2=[]\ntext2=texttemp\nfrom sklearn.model_selection import train_test_split\nenglish_words = []\nfrench_words = []\n\nfor i in text1:\n    english_words.append(len(i.split()))\n\nfor j in text2:\n    french_words.append(len(j.split()))\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\nsn.countplot(english_words)\nplt.show()\n\nsn.countplot(x = french_words)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:56:06.254464Z","iopub.execute_input":"2021-06-11T10:56:06.254835Z","iopub.status.idle":"2021-06-11T10:56:07.675643Z","shell.execute_reply.started":"2021-06-11T10:56:06.254799Z","shell.execute_reply":"2021-06-11T10:56:07.674846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len_english = max(english_words)\nmax_len_french = max(french_words)\n\n#from sklearn.model_selection import train_test_split\n#x_tr,x_val,y_tr,y_val=train_test_split(text1,text2,test_size=0.3,random_state=12,shuffle=True)\n#print(len(x_tr))\n#print(len(x_val))\nx_tr=text1[:choicenum-500]\ny_tr=text2[:choicenum-500]\nx_val=text1[choicenum-500:]\ny_val=text2[choicenum-500:]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:38:12.713067Z","iopub.execute_input":"2021-06-11T11:38:12.713424Z","iopub.status.idle":"2021-06-11T11:38:12.719946Z","shell.execute_reply.started":"2021-06-11T11:38:12.713392Z","shell.execute_reply":"2021-06-11T11:38:12.719114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nx_tokens = Tokenizer()\nx_tokens.fit_on_texts(x_tr)\n\nx_tr = x_tokens.texts_to_sequences(x_tr)\nx_val = x_tokens.texts_to_sequences(x_val)\n\nfrom keras.preprocessing.sequence import pad_sequences\nx_tr = pad_sequences(x_tr,maxlen = max_len_english,padding = 'post')\nx_val = pad_sequences(x_val,maxlen = max_len_english,padding = 'post')\n\n# +1 for padding \nx_voc_size   =  len(x_tokens.word_index) +1\n\n# y data\nfrom keras.preprocessing.text import Tokenizer\ny_tokens = Tokenizer()\ny_tokens.fit_on_texts(y_tr)\n\ny_tr = y_tokens.texts_to_sequences(y_tr)\ny_val = y_tokens.texts_to_sequences(y_val)\n\nfrom keras.preprocessing.sequence import pad_sequences\ny_tr = pad_sequences(y_tr,maxlen = max_len_french,padding = 'post')\ny_val = pad_sequences(y_val,maxlen = max_len_french,padding = 'post')\n\n# +1 for padding \ny_voc_size   =  len(y_tokens.word_index) +1","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:38:15.275835Z","iopub.execute_input":"2021-06-11T11:38:15.276154Z","iopub.status.idle":"2021-06-11T11:38:15.751952Z","shell.execute_reply.started":"2021-06-11T11:38:15.276123Z","shell.execute_reply":"2021-06-11T11:38:15.751052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport pickle\nimport numpy as np\nimport os\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.optimizers import Adam\nfrom keras.layers import Dense, GlobalAveragePooling2D,BatchNormalization,Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\nfrom keras.models import Sequential, Model\nfrom keras.utils import np_utils\nimport random\nfrom keras.preprocessing import image, sequence\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras import backend as K \nimport gensim\nfrom numpy import *\nimport numpy as np\nimport pandas as pd \nimport re\nfrom keras.applications import VGG16\nfrom keras.preprocessing.text import Tokenizer \nfrom keras.preprocessing.sequence import pad_sequences\nfrom nltk.corpus import stopwords\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed,Conv2D,MaxPooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport warnings\nmodelvgg = VGG16(include_top=True,weights=\"imagenet\")\n## load the locally saved weights \nmodelvgg.layers.pop()\nmodelvgg = Model(inputs=modelvgg.inputs, outputs=modelvgg.layers[-2].output)\nmodelvgg.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:57:33.189301Z","iopub.execute_input":"2021-06-11T10:57:33.189629Z","iopub.status.idle":"2021-06-11T10:57:34.969151Z","shell.execute_reply.started":"2021-06-11T10:57:33.189598Z","shell.execute_reply":"2021-06-11T10:57:34.968252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagedata=np.zeros(shape=(choicenum,224,224,3))\nfor i in range(choicenum):\n    temp=mp.imread(img_path[i])\n    temp=cv2.resize(temp,(224,224))\n    imagedata[i]=temp\nimagedata=imagedata/255\nimagedata=imagedata.astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:02:58.353951Z","iopub.execute_input":"2021-06-11T11:02:58.354292Z","iopub.status.idle":"2021-06-11T11:03:59.641074Z","shell.execute_reply.started":"2021-06-11T11:02:58.354258Z","shell.execute_reply":"2021-06-11T11:03:59.640192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.vgg16 import preprocess_input\nfrom collections import OrderedDict\njpgs=img_path[:choicenum]\n\nimages = OrderedDict()\nnpix = 224\ntarget_size = (npix,npix,3)\nfor i,name in enumerate(jpgs): \n    filename = name\n    image = load_img(filename, target_size=target_size)\n    # convert the image pixels to a numpy array\n    image = img_to_array(image)\n    nimage = preprocess_input(image)\n    y_pred = modelvgg.predict(nimage.reshape( (1,) + nimage.shape[:3]))\n    images[name] = y_pred.flatten()\n    if i%200==0:\n        print(i,filename)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:18:36.41714Z","iopub.execute_input":"2021-06-11T11:18:36.417462Z","iopub.status.idle":"2021-06-11T11:28:36.324848Z","shell.execute_reply.started":"2021-06-11T11:18:36.417431Z","shell.execute_reply":"2021-06-11T11:28:36.323898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_imfea=np.zeros(shape=(len(jpgs),4096))\nfor i in range(len(jpgs)):\n    vgg_imfea[i]=images[jpgs[i]]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:34:31.591037Z","iopub.execute_input":"2021-06-11T11:34:31.591363Z","iopub.status.idle":"2021-06-11T11:34:31.6801Z","shell.execute_reply.started":"2021-06-11T11:34:31.591331Z","shell.execute_reply":"2021-06-11T11:34:31.679231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vggf=vgg_imfea[:choicenum-500]\nval_vggf=vgg_imfea[choicenum-500:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#g_1=GlobalAveragePooling2D()(conv_3)\nimg_inputs=Input(shape=(4096,))\nd_1=Dense(512, activation='relu')(img_inputs)\nr_1=RepeatVector(max_len_english)(d_1)\nvf_model = Model(img_inputs, r_1)\nvf_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:38:29.377188Z","iopub.execute_input":"2021-06-11T11:38:29.377515Z","iopub.status.idle":"2021-06-11T11:38:29.401384Z","shell.execute_reply.started":"2021-06-11T11:38:29.377484Z","shell.execute_reply":"2021-06-11T11:38:29.400442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_voc=x_voc_size\ny_voc=y_voc_size\n\n# img_inputs=Input(shape=(224,224,3))\n# conv_1=Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1), padding='valid')(img_inputs)\n# m_pool=MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(conv_1)\n# bn_1=BatchNormalization()(m_pool)\n# conv_2=Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='valid')(bn_1)\n# conv_2=Conv2D(filters=128, kernel_size=(3,3), strides=(1, 1), padding='valid')(conv_2)\n# m_pool1=MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(conv_2)\n# conv_3=Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding='valid')(m_pool1)\n# conv_3=Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding='valid')(conv_3)\n# m_pool2=MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(conv_3)\n# bn_2=BatchNormalization()(m_pool2)\n# conv_3=Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1), padding='valid')(bn_2)\n# conv_3=Conv2D(filters=512, kernel_size=(3,3), strides=(1, 1), padding='valid')(conv_3)\n# g_1=GlobalAveragePooling2D()(conv_3)\n# d_1=Dense(512, activation='relu')(g_1)\n# r_1=RepeatVector(max_len_english)(d_1)\n# vf_model = Model(img_inputs, r_1)\n#vf_model.summary()\n\n\nlatent_dim = 512\nembedding_dim=512\n\n# Encoder\nencoder_inputs = Input(shape=(max_len_english,))\n\n#embedding layer\nenc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n\n#encoder lstm 1\nencoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n\n#encoder lstm 2\nencoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\nencoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n\nencoder_output2=Concatenate(axis=-1)([encoder_output2,r_1])\n\n#encoder lstm 3\nencoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\nencoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\n\n#embedding layer\ndec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\ndec_emb = dec_emb_layer(decoder_inputs)\n\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\ndecoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n\n#dense layer\ndecoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model \n#model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel = Model([encoder_inputs,decoder_inputs,img_inputs], decoder_outputs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:38:36.133552Z","iopub.execute_input":"2021-06-11T11:38:36.133903Z","iopub.status.idle":"2021-06-11T11:38:37.389043Z","shell.execute_reply.started":"2021-06-11T11:38:36.133863Z","shell.execute_reply":"2021-06-11T11:38:37.388231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\nhistory=model.fit([x_tr,y_tr[:,:-1],train_vggf], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,validation_data=([x_val,y_val[:,:-1],val_vggf], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]),epochs=100,batch_size=512)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:38:49.055199Z","iopub.execute_input":"2021-06-11T11:38:49.055515Z","iopub.status.idle":"2021-06-11T11:38:49.071724Z","shell.execute_reply.started":"2021-06-11T11:38:49.055484Z","shell.execute_reply":"2021-06-11T11:38:49.070887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#history=model.fit([x_tr,y_tr[:,:-1],vgg_imfea], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=40,batch_size=512)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:56:27.85805Z","iopub.execute_input":"2021-06-11T11:56:27.858397Z","iopub.status.idle":"2021-06-11T11:56:36.135187Z","shell.execute_reply.started":"2021-06-11T11:56:27.858363Z","shell.execute_reply":"2021-06-11T11:56:36.132545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reverse_target_word_index=y_tokens.index_word\nreverse_source_word_index=x_tokens.index_word\ntarget_word_index=y_tokens.word_index\n\n# Encode the input sequence to get the feature vector\nencoder_model = Model(inputs=[encoder_inputs,img_inputs],outputs=[encoder_outputs, state_h, state_c])\nencoder_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:54:40.283826Z","iopub.execute_input":"2021-06-11T11:54:40.28415Z","iopub.status.idle":"2021-06-11T11:54:40.299859Z","shell.execute_reply.started":"2021-06-11T11:54:40.284122Z","shell.execute_reply":"2021-06-11T11:54:40.299097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_hidden_state_input = Input(shape=(max_len_english,latent_dim))\n\n# Get the embeddings of the decoder sequence\ndec_emb2= dec_emb_layer(decoder_inputs) \n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\n# A dense softmax layer to generate prob dist. over the target vocabulary\ndecoder_outputs2 = decoder_dense(decoder_outputs2) \n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs2] + [state_h2, state_c2])\ndecoder_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:54:42.964311Z","iopub.execute_input":"2021-06-11T11:54:42.964654Z","iopub.status.idle":"2021-06-11T11:54:43.089471Z","shell.execute_reply.started":"2021-06-11T11:54:42.964623Z","shell.execute_reply":"2021-06-11T11:54:43.088669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_sequence(input_seq,img):\n    img=img[np.newaxis,:]\n    # Encode the input as state vectors.\n    e_out, e_h, e_c = encoder_model.predict([input_seq,img])\n    \n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    \n    # Populate the first word of target sequence with the start word.\n    target_seq[0, 0] = target_word_index['cls']\n\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n      \n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_word_index[sampled_token_index]\n        \n        if(sampled_token!='eos'):\n            decoded_sentence += ' '+sampled_token\n\n        # Exit condition: either hit max length or find stop word.\n        if (sampled_token == 'eos'  or len(decoded_sentence.split()) >= (max_len_french -1)):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update internal states\n        e_h, e_c = h, c\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:54:45.757012Z","iopub.execute_input":"2021-06-11T11:54:45.757336Z","iopub.status.idle":"2021-06-11T11:54:45.767641Z","shell.execute_reply.started":"2021-06-11T11:54:45.757305Z","shell.execute_reply":"2021-06-11T11:54:45.766789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seq2summary(input_seq):\n    newString=''\n    for i in input_seq:\n        if((i!=0 and i!=target_word_index['cls']) and i!=target_word_index['eos']):\n            newString=newString+reverse_target_word_index[i]+' '\n    return newString\n\ndef seq2text(input_seq):\n    newString=''\n    for i in input_seq:\n        if(i!=0):\n            newString=newString+reverse_source_word_index[i]+' '\n    return newString\n\nfor i in range(5):\n    print(\"Review:\",seq2text(x_tr[i]))\n    print(\"Original summary:\",seq2summary(y_tr[i]))\n    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_len_english),train_vggf[i]))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:54:47.916355Z","iopub.execute_input":"2021-06-11T11:54:47.916727Z","iopub.status.idle":"2021-06-11T11:54:51.711071Z","shell.execute_reply.started":"2021-06-11T11:54:47.916693Z","shell.execute_reply":"2021-06-11T11:54:51.709989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=3\nprint(\"Review:\",seq2text(x_tr[i]))\nprint(\"Original summary:\",seq2summary(y_tr[i]))\nprint(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_len_english),vgg_imfea[i]))\nplt.imshow(imagedata[i].astype(np.float32))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:54:55.174053Z","iopub.execute_input":"2021-06-11T11:54:55.174372Z","iopub.status.idle":"2021-06-11T11:54:56.008925Z","shell.execute_reply.started":"2021-06-11T11:54:55.174341Z","shell.execute_reply":"2021-06-11T11:54:56.008163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=2\nprint(\"Review:\",seq2text(x_tr[i]))\nprint(\"Original summary:\",seq2summary(y_tr[i]))\nprint(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_len_english),vgg_imfea[i]))\nplt.imshow(imagedata[i].astype(np.float32))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:46:32.311051Z","iopub.execute_input":"2021-06-11T11:46:32.311387Z","iopub.status.idle":"2021-06-11T11:46:33.063889Z","shell.execute_reply.started":"2021-06-11T11:46:32.311356Z","shell.execute_reply":"2021-06-11T11:46:33.063112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=0\nprint(\"Review:\",seq2text(x_tr[i]))\nprint(\"Original summary:\",seq2summary(y_tr[i]))\nprint(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_len_english),vgg_imfea[i]))\nplt.imshow(imagedata[i].astype(np.float32))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:46:37.088666Z","iopub.execute_input":"2021-06-11T11:46:37.088998Z","iopub.status.idle":"2021-06-11T11:46:38.288447Z","shell.execute_reply.started":"2021-06-11T11:46:37.088966Z","shell.execute_reply":"2021-06-11T11:46:38.287453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sacrebleu\nimport sacrebleu\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:46:42.047788Z","iopub.execute_input":"2021-06-11T11:46:42.048114Z","iopub.status.idle":"2021-06-11T11:46:49.409445Z","shell.execute_reply.started":"2021-06-11T11:46:42.048085Z","shell.execute_reply":"2021-06-11T11:46:49.408563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_o=[]\ntemp_p=[]\nfor i in range(50):\n    s=random.randint(0,len(y_tr)-1)\n    temp_o.append(seq2summary(y_tr[s]))\n    temp_p.append(decode_sequence(x_tr[s].reshape(1,max_len_english),train_vggf[s]))\n\nbleu = sacrebleu.corpus_bleu(temp_o, [temp_p],lowercase=True, tokenize='intl')\nprint(bleu.score)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:55:02.699053Z","iopub.execute_input":"2021-06-11T11:55:02.699483Z","iopub.status.idle":"2021-06-11T11:55:33.555988Z","shell.execute_reply.started":"2021-06-11T11:55:02.699441Z","shell.execute_reply":"2021-06-11T11:55:33.554926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_o=[]\ntemp_p=[]\nfor i in range(100):\n    s=random.randint(0,len(y_tr)-1)\n    temp_o.append(seq2summary(y_tr[s]))\n    temp_p.append(decode_sequence(x_tr[s].reshape(1,max_len_english),train_vggf[s]))\n\nbleu = sacrebleu.corpus_bleu(temp_o, [temp_p],lowercase=True, tokenize='intl')\nprint(bleu.score)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T10:56:31.548595Z","iopub.status.idle":"2021-06-11T10:56:31.549399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_o=[]\ntemp_p=[]\nfor i in range(100):\n    s=random.randint(0,len(y_tr)-1)\n    temp_o.append(seq2summary(y_tr[s]))\n    temp_p.append(decode_sequence(x_tr[s].reshape(1,max_len_english),val_vggf[s]))\n\nbleu = sacrebleu.corpus_bleu(temp_o, [temp_p],lowercase=True, tokenize='intl')\nprint(bleu.score)","metadata":{},"execution_count":null,"outputs":[]}]}