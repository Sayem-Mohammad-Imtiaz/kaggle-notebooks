{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a project to classify spam and ham messages using LSTM and based on Classification approach.\n\n**Steps involved in the Project:**\n\n**Data Cleaning:**\n\nRemoving unwanted columns.\nExploring & comparing length of messages.\nPerforming undersampling on dataset.\n\n**Text preparation:**\n\nTokenization of Messages.\nOne hot implementation on tokenized message(corpus)\nPerform word embedding\n\n**Data preparation/Data Splitting:**\n\nSplit the data into training+validation(85%) & testing(15%) data.\nFurther split the training+validation data into training(85%) and validation(15%) data.\n\n**Building the model:**\n\nBuild a Sequential model: Embedding Layer->LSTM->Dense(output layer)\nFit and Validate model on training and validation model\n\n**Evaluation:**\n\nEvaluate the model on test dataset.\nGet the model accuracy score and visualize confusion matrix\n\n**Testing:**\nCreated a function that would classifiy the messages using the model","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndata=pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\",encoding=\"latin\")\ndata.head()\n\ndata.columns\ndata=data.drop(columns=[\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"])\n\ndata=data.rename(\n{\n    \"v1\":\"Category\",\n    \"v2\":\"Message\"\n},\n    axis=1\n)\n\ndata.head()\ndata.isnull().sum()\n\ndata.info()\n\ndata[\"Message Length\"]=data[\"Message\"].apply(len)\nfig=plt.figure(figsize=(12,8))\nsns.histplot(\n    x=data[\"Message Length\"],\n    hue=data[\"Category\"]\n)\nplt.title(\"ham & spam messege length comparision\")\nplt.show()\n\nham_desc=data[data[\"Category\"]==\"ham\"][\"Message Length\"].describe()\nspam_desc=data[data[\"Category\"]==\"spam\"][\"Message Length\"].describe()\n\nprint(\"Ham Messege Length Description:\\n\",ham_desc)\nprint(\"************************************\")\nprint(\"Spam Message Length Description:\\n\",spam_desc)\n\ndata.describe(include=\"all\")\ndata[\"Category\"].value_counts()\n\nsns.countplot(\n    data=data,\n    x=\"Category\"\n)\nplt.title(\"ham vs spam\")\nplt.show()\n\nham_count=data[\"Category\"].value_counts()[0]\nspam_count=data[\"Category\"].value_counts()[1]\n\ntotal_count=data.shape[0]\n\nprint(\"Ham contains:{:.2f}% of total data.\".format(ham_count/total_count*100))\n\nprint(\"Spam contains:{:.2f}% of total data.\".format(spam_count/total_count*100))\n\n#compute the length of majority & minority class\nminority_len=len(data[data[\"Category\"]==\"spam\"])\nmajority_len=len(data[data[\"Category\"]==\"ham\"])\n\n#store the indices of majority and minority class\nminority_indices=data[data[\"Category\"]==\"spam\"].index\nmajority_indices=data[data[\"Category\"]==\"ham\"].index\n\n#generate new majority indices from the total majority_indices\n#with size equal to minority class length so we obtain equivalent number of indices length\nrandom_majority_indices=np.random.choice(\n    majority_indices,\n    size=minority_len,\n    replace=False\n)\n\n#concatenate the two indices to obtain indices of new dataframe\nundersampled_indices=np.concatenate([minority_indices,random_majority_indices])\n\n#create df using new indices\ndf=data.loc[undersampled_indices]\n\n#shuffle the sample\ndf=df.sample(frac=1)\n\n\n#reset the index as its all mixed\ndf=df.reset_index()\n\n#drop the older index\ndf=df.drop(\n    columns=[\"index\"],\n)\ndf.shape\n\ndf[\"Category\"].value_counts()\n\nsns.countplot(\n    data=df,\n    x=\"Category\"\n)\nplt.title(\"ham vs spam\")\nplt.show()\n\ndf.head()\ndf[\"Label\"]=df[\"Category\"].map(\n    {\n        \"ham\":0,\n        \"spam\":1\n    }\n)\ndf.head()\n\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\nstemmer=PorterStemmer()\n#declare empty list to store tokenized message\ncorpus=[]\n\n#iterate through the df[\"Message\"]\nfor message in df[\"Message\"]:\n    \n    #replace every special characters, numbers etc.. with whitespace of message\n    #It will help retain only letter/alphabets\n    message=re.sub(\"[^a-zA-Z]\",\" \",message)\n    \n    #convert every letters to its lowercase\n    message=message.lower()\n    \n    #split the word into individual word list\n    message=message.split()\n    \n    #perform stemming using PorterStemmer for all non-english-stopwords\n    message=[stemmer.stem(words)\n            for words in message\n             if words not in set(stopwords.words(\"english\"))\n            ]\n    #join the word lists with the whitespace\n    message=\" \".join(message)\n    \n    #append the message in corpus list\n    corpus.append(message)\n\nfrom tensorflow.keras.preprocessing.text import one_hot\nvocab_size=10000\n\noneHot_doc=[one_hot(words,n=vocab_size)\n           for words in corpus\n           ]\n\ndf[\"Message Length\"].describe()\n\nfig=plt.figure(figsize=(12,8))\nsns.kdeplot(\n    x=df[\"Message Length\"],\n    hue=df[\"Category\"]\n)\nplt.title(\"ham & spam messege length comparision\")\nplt.show()\n\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nsentence_len=200\nembedded_doc=pad_sequences(\n    oneHot_doc,\n    maxlen=sentence_len,\n    padding=\"pre\"\n)\n\nextract_features=pd.DataFrame(\n    data=embedded_doc\n)\ntarget=df[\"Label\"]\n\ndf_final=pd.concat([extract_features,target],axis=1)\ndf_final.head()\n\nX=df_final.drop(\"Label\",axis=1)\ny=df_final[\"Label\"]\n\nfrom sklearn.model_selection import train_test_split\n\nX_trainval,X_test,y_trainval,y_test=train_test_split(\n    X,\n    y,\n    random_state=42,\n    test_size=0.15\n)\n\nX_train,X_val,y_train,y_val=train_test_split(\n    X_trainval,\n    y_trainval,\n    random_state=42,\n    test_size=0.15\n)\n\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.models import Sequential\n\nmodel=Sequential()\n\nfeature_num=100\nmodel.add(\n    Embedding(\n        input_dim=vocab_size,\n        output_dim=feature_num,\n        input_length=sentence_len\n    )\n)\nmodel.add(\n    LSTM(\n    units=128\n    )\n)\n\nmodel.add(\n    Dense(\n        units=1,\n        activation=\"sigmoid\"\n    )\n)\n\nfrom tensorflow.keras.optimizers import Adam\nmodel.compile(\n    optimizer=Adam(\n    learning_rate=0.001\n    ),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.fit(\n    X_train,\n    y_train,\n    validation_data=(\n        X_val,\n        y_val\n    ),\n    epochs=10\n)\n\ny_pred=model.predict(X_test)\ny_pred=(y_pred>0.5)\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nscore=accuracy_score(y_test,y_pred)\nprint(\"Test Score:{:.2f}%\".format(score*100))\n\nprint(\"/n\")\n\ncm=confusion_matrix(y_test,y_pred)\nfig=plt.figure(figsize=(12,8))\nsns.heatmap(\n    cm,\n    annot=True,\n)\nplt.title(\"Confusion Matrix\")\ncm\n\n#The function take model and message as parameter\ndef classify_message(model,message):\n    \n    #We will treat message as a paragraphs containing multiple sentences(lines)\n    #we will extract individual lines\n    for sentences in message:\n        sentences=nltk.sent_tokenize(message)\n        \n        #Iterate over individual sentences\n        for sentence in sentences:\n            #replace all special characters\n            words=re.sub(\"[^a-zA-Z]\",\" \",sentence)\n            \n            #perform word tokenization of all non-english-stopwords\n            if words not in set(stopwords.words('english')):\n                word=nltk.word_tokenize(words)\n                word=\" \".join(word)\n    \n    #perform one_hot on tokenized word            \n    oneHot=[one_hot(word,n=vocab_size)]\n    \n     #create an embedded documnet using pad_sequences \n    #this can be fed to our model\n    text=pad_sequences(oneHot,maxlen=sentence_len,padding=\"pre\")\n    \n    #predict the text using model\n    predict=model.predict(text)\n    \n    #if predict value is greater than 0.5 its a spam\n    if predict>0.5:\n        print(\"It is a spam\")\n    #else the message is not a spam    \n    else:\n        print(\"It is not a spam\")\n        \nmessage1=\"I am having a bad day and I would like to have a break today\"\n\nmessage2=\"This is to inform you had won a lottery and the subscription will end in a week so call us.\"\n\nclassify_message(model,message1)\n\nclassify_message(model,message2)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:44:53.27614Z","iopub.execute_input":"2021-06-09T01:44:53.276596Z","iopub.status.idle":"2021-06-09T01:44:55.195462Z","shell.execute_reply.started":"2021-06-09T01:44:53.276503Z","shell.execute_reply":"2021-06-09T01:44:55.194239Z"},"trusted":true},"execution_count":null,"outputs":[]}]}