{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Random Forest Project \n\nFor this project we will be exploring publicly available data from [LendingClub.com](www.lendingclub.com). Lending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, as an investor you would want to invest in people who showed a profile of having a high probability of paying you back. We will try to create a model that will help predict this.\n\nLending club had a [very interesting year in 2016](https://en.wikipedia.org/wiki/Lending_Club#2016), so let's check out some of their data and keep the context in mind. This data is from before they even went public.\n\nWe will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full. You can download the data from [here](https://www.lendingclub.com/info/download-data.action) or just use the csv already provided. It's recommended you use the csv provided as it has been cleaned of NA values.\n\nHere are what the columns represent:\n* credit.policy: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n* purpose: The purpose of the loan (takes values \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", and \"all_other\").\n* int.rate: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n* installment: The monthly installments owed by the borrower if the loan is funded.\n* log.annual.inc: The natural log of the self-reported annual income of the borrower.\n* dti: The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n* fico: The FICO credit score of the borrower.\n* days.with.cr.line: The number of days the borrower has had a credit line.\n* revol.bal: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n* revol.util: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n* inq.last.6mths: The borrower's number of inquiries by creditors in the last 6 months.\n* delinq.2yrs: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n* pub.rec: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries\n\n**Import the usual libraries for pandas and plotting. You can import sklearn later on.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get the Data\n\n** Use pandas to read loan_data.csv as a dataframe called loans.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loans = pd.read_csv(\"../input/lending-club-data/loan_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Check out the info(), head(), and describe() methods on loans.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nLet's do some data visualization! We'll use seaborn and pandas built-in plotting capabilities, but feel free to use whatever library you want. Don't worry about the colors matching, just worry about getting the main idea of the plot.\n\n** Create a histogram of two FICO distributions on top of each other, one for each credit.policy outcome.**\n\n*Note: This is pretty tricky, feel free to reference the solutions. You'll probably need one line of code for each histogram, I also recommend just using pandas built in .hist()*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize=(15,4))\nsns.distplot(loans[loans[\"credit.policy\"] == 1][\"fico\"], kde=False, label=\"Credit Policy = 1\")\nsns.distplot(loans[loans[\"credit.policy\"] == 0][\"fico\"], kde=False, label=\"Credit Policy = 0\")\nplt.legend(loc=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Create a similar figure, except this time select by the not.fully.paid column.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nfig = plt.figure(figsize=(15,4))\nsns.distplot(loans[loans[\"not.fully.paid\"] == 0][\"fico\"], kde=False, label=\"Not Fully Paid = 0\")\nsns.distplot(loans[loans[\"not.fully.paid\"] == 1][\"fico\"], kde=False, label=\"Not Fully Paid = 1\")\nplt.legend(loc=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid. **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.countplot(x=\"purpose\", data=loans, hue=\"not.fully.paid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Let's see the trend between FICO score and interest rate. Recreate the following jointplot.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"fico\", y=\"int.rate\", data=loans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Create the following lmplots to see if the trend differed between not.fully.paid and credit.policy. Check the documentation for lmplot() if you can't figure out how to separate it into columns.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x=\"fico\", y=\"int.rate\", col=\"not.fully.paid\", data=loans, hue=\"credit.policy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setting up the Data\n\nLet's get ready to set up our data for our Random Forest Classification Model!\n\n**Check loans.info() again.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Features\n\nNotice that the **purpose** column as categorical\n\nThat means we need to transform them using dummy variables so sklearn will be able to understand them. Let's do this in one clean step using pd.get_dummies.\n\nLet's show you a way of dealing with these columns that can be expanded to multiple categorical features if necessary.\n\n**Create a list of 1 element containing the string 'purpose'. Call this list cat_feats.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feats = [\"purpose\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now use pd.get_dummies(loans,columns=cat_feats,drop_first=True) to create a fixed larger dataframe that has new feature columns with dummy variables. Set this dataframe as final_data.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data = pd.get_dummies(loans, columns=cat_feats, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loans.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split\n\nNow its time to split our data into a training set and a testing set!\n\n** Use sklearn to split your data into a training set and a testing set as we've done in the past.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_data.drop(\"not.fully.paid\", axis=1)\ny = final_data[\"not.fully.paid\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training a Decision Tree Model\n\nLet's start by training a single decision tree first!\n\n** Import DecisionTreeClassifier**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions and Evaluation of Decision Tree\n**Create predictions from the test set and create a classification report and a confusion matrix.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = dtree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Random Forest model\n\nNow its time to train our model!\n\n**Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions and Evaluation\n\nLet's predict off the y_test values and evaluate our model.\n\n** Predict the class of not.fully.paid for the X_test data.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_predictions = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now create a classification report from the results. Do you get anything strange or some sort of warning?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, rfc_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Show the Confusion Matrix for the predictions.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, rfc_predictions))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"**What performed better the random forest or the decision tree?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}