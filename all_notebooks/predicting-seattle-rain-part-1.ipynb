{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# An Analysis by an Atmospheric Scientist regarding Rain Forecast in Seattle\n\n## Objective:\n\n- The customer would like to know the likelihood of predicting whether it rains or not on a specific day ins Seattle by using MLAs. The input dataset (seattleWeather_1948-2017.csv) provides information on a few Meteorological variables in Seattle from 1948 to 2017.\n\n- The input variables (predictors) are Date, PRCP, TMAX, and TMIN. The last three are numerical continuous variables.\n\n- The outcome or dependent variable is RAIN (boolean).\n\n- This is part 1: I will only use the available predictors (as they are) and will drop the ones that are not independent.\n\n- In part 2, I will perform advanced feature engineering and will extract new variables based on the available predictors in order to improve the accuracy score.\n----\n\nNote that the other solutions to this problem, that I found on this website, did a terrible mistake and kept the variable PRCP (precipitation amount) to predict RAIN (binary rain: did it rain or not). This is cheating: your model would provide a perfect answer when the outcome is included among the predictors. When your model knows the amount of precipitation on a specific day, it can certainly say whether it rains or not. This motivated me to provide a better methodology.\n\n\n### Importing important libraries:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport os\n\nfrom pandas import Series, DataFrame\nfrom pylab import rcParams\nfrom sklearn import preprocessing\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import classification_report\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df = pd.read_csv('/kaggle/input/did-it-rain-in-seattle-19482017/seattleWeather_1948-2017.csv')\nprint(met_df.head()); print(); print()\nmet_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The description and unit of each variable:\n- DATE = the date of the observation\n- PRCP = the amount of precipitation, in inches\n- TMAX = the maximum temperature for that day, in degrees Fahrenheit\n- TMIN = the minimum temperature for that day, in degrees Fahrenheit\n- RAIN = TRUE if rain was observed on that day, FALSE if it was not"},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaing:\n\n### Step 1: Correcting wrong values or outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data description makes sense, and the mean, min, and max values of each variable is reasonable meaning there should not be a mistake in the data (such as a very large temperature of 200 F)."},{"metadata":{},"cell_type":"markdown","source":"### Step 2: Imputing missing values:\n\nThere are only three missing data points for each PRCP and RAIN. So, we use median for PRCP and mode for RAIN to fill in the gaps."},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P_median = met_df.PRCP.median()\nR_mode   = met_df.RAIN.mode()[0]\n\nmet_df.PRCP.fillna(P_median, inplace = True)\nmet_df.RAIN.fillna(R_mode, inplace = True)\n\nmet_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 3: Converting boolean variable to dummy variable:\n- We should change RAIN from True/False to 1/0.\n- We then replace the new variable with the original one."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nRAIN_encode = LabelEncoder().fit_transform(met_df.RAIN)\nRAIN_encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df['RAIN'] = RAIN_encode\n\nmet_df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making sure all predictors are independent\n\n### Insightful plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nrcParams['figure.figsize'] = 6, 5\nsb.set_style('whitegrid')\n\nsb.pairplot(met_df, palette = 'husl', hue = 'RAIN')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.heatmap(met_df.corr(), vmin=-1, vmax=1, annot=True, cmap = 'RdBu_r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.scatterplot(x = 'TMIN', y ='TMAX', data = met_df, hue = 'RAIN')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Ax expected, TMIN and TMAX are highliy correlated, so we drop TMIN that has lower correlation with RAIN."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axis = plt.subplots(1, 2,figsize=(10,4))\nsb.boxplot(x = 'RAIN', y ='TMAX', data = met_df, ax = axis[0], showfliers = False)\nsb.boxplot(x = 'RAIN', y ='TMIN', data = met_df, ax = axis[1], showfliers = False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Here, each TMAX and TMIN is grouped based on RAIN.\n- Again, we see that TMAX is a better predictor of RAIN.\n\n- We should also drop 'PRCP' variable: if we know the amount of precipitation on each day, we can certainly say whether it rains or not on that day."},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df.drop(['TMIN', 'PRCP','DATE'], inplace = True, axis=1)\nmet_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing MLAs:\n\n### Spliting the data into test and train sets:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(met_df.drop('RAIN', axis=1),\n                                                   met_df['RAIN'], test_size=0.2, random_state=10)                             \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using a variety of MLAs to get the best results\n\n- The outcome is binary, so we can use Logistic Regression, Decision Tree, or Naive Bayes. \n- We also use ensemble algorithms (such as Random Forest) to see if the score can be improved."},{"metadata":{"trusted":true},"cell_type":"code","source":"all_classifiers = {'Ada Boost': AdaBoostClassifier(),\n                 'Random Forest': RandomForestClassifier(n_estimators=50, min_samples_leaf=1, min_samples_split=2, max_depth=4),\n                 'Gaussian NB': GaussianNB(),\n                 'Logistic Regression': LogisticRegression(solver='liblinear'),#fit_intercept=True,\n                 'Decision Tree' : DecisionTreeClassifier(),\n                  'SVC': SVC()} #probability = False ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ML_name = []\nML_accuracy = []\nfor Name,classifier in all_classifiers.items():\n    classifier.fit(X_train,Y_train)\n    Y_pred = classifier.predict(X_test)\n    ML_accuracy.append(metrics.accuracy_score(Y_test,Y_pred)) \n    ML_name.append(Name) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 8, 4\nplt.barh(ML_name, ML_accuracy, color = 'brown')\nplt.xlabel('Accuracy Score', fontsize = '14')\nplt.ylabel('Machine Learning Algorithms', fontsize = '14')\nplt.xlim([0.65, 0.685])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Tuning models with hyper parameters:\n\n- Let's see if we can improve a model performance by changing the hyper parameters.\n- We are not going to test all the models, but just a few of them.\n\n\n### Decision Tree:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"criteri       = ['gini', 'entropy']\nmin_samp_lf   = [1, 2, 5, 10]\nmin_samp_splt = [2, 4, 8, 12]\nmaxim_depth   = [2, 4, 8, 12, None]\n\nmax_score = 0\n\nfor c in criteri:\n    for ml in min_samp_lf:\n        for ms in min_samp_splt:\n            for md in maxim_depth:\n                MLA = DecisionTreeClassifier(criterion=c, min_samples_leaf=ml, min_samples_split=ms, max_depth=md)\n                MLA.fit(X_train,Y_train)\n                Y_pred = MLA.predict(X_test)\n                if metrics.accuracy_score(Y_test,Y_pred) > max_score:\n                    max_score, c_best, l_best, s_best, d_best = metrics.accuracy_score(Y_test,Y_pred), c, ml, ms, md\n\nprint('maximum accuracy score, criterion, min_samples_leaf, min_samples_split, max_depth:')\nprint(max_score, c_best, l_best, s_best, d_best)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ada Boost Classifier:"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_R    = [1, 2, 3]\nrandom_st     = [None, 20]\nn_estimat     = [50, 100]\n\nmax_score = 0\n\nfor lr in learning_R:\n    for rs in random_st:\n        for ne in n_estimat:\n            MLA = AdaBoostClassifier(random_state=rs, learning_rate=lr, n_estimators=ne)\n            MLA.fit(X_train,Y_train)\n            Y_pred = MLA.predict(X_test)\n            if metrics.accuracy_score(Y_test,Y_pred) > max_score:\n                max_score, r_best, l_best, n_best = metrics.accuracy_score(Y_test,Y_pred), rs, lr, ne\n\nprint('maximum accuracy score, random_state, learning_rate, n_estimators:')\nprint(max_score, r_best, l_best, n_best)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Validation:\n\nSee Part 2.\n\n----\n\n## Discussion:\n\n- It seems that tuning hyper-parameters for various MLAs would give us an accuracy score of ~ 68.1%, meaning that our MLAs can predict the rain correctly in 68% of times for test datasets.\n\n- This is better than the baseline: we should be able to predict rain by 50% accuracy only by tossing a coin. Moreover, there are 57% of instances of not rain and 43% instances of rain. So, if we always select not rain, we would get a score of 57%. So far, we improved the accuracy score by 11.1%.\n\n- In part 2, we will utilize advanced feature engineering and subject-matter expertise to increase the accuracy score.\n\n- Note that the limited number of predictors and the highly uncertain and non-linear nature of weather make it very difficult to increase the accuracy score to higher than ~85%. If it was possible, there would not be a need for super complex numerical weather prediction (NWP) models that use thousands of processes and mathematical models and are now very common for weather forecasts with high accuracy.\n\n- I saw that other solutions claimed they reached an accuracy of higher than 90%. This is an artifact and mistake because they did not drop the 'PRCP' variable from the predictor list when using MLAs.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}