{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. EDA","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/used-car-dataset-ford-and-mercedes/ford.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.model.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Stratifying sample","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Alternative 1","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\ndata[\"tax_cat\"] = pd.cut(data[\"tax\"], bins=[-1, 116, 232, 348, 464, np.inf], labels=[1 ,2, 3, 4, 5])\ndata.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"tax_cat\"].value_counts().sort_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Alternative 2","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data[\"tax_cat\"]):\n    strat_train_set = data.loc[train_index]\n    strat_test_set = data.loc[test_index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Result Alternative 2:\nstrat_test_set[\"tax_cat\"].value_counts().sort_index() / len(strat_test_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Result Alternative 1:\ndata[\"tax_cat\"].value_counts().sort_index() / len(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Compare stratification results to default","metadata":{}},{"cell_type":"code","source":"def tax_cat_proportions(test_values):\n    return test_values[\"tax_cat\"].value_counts() / len(test_values)\n\ntrain_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n\ncompare_props = pd.DataFrame({\n    \"Overall\": tax_cat_proportions(data),\n    \"Stratified\": tax_cat_proportions(strat_test_set),\n    \"Random\": tax_cat_proportions(test_set),\n}).sort_index()\ncompare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\ncompare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_props","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"tax_cat\", axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Encoding Categorical and Numerical variables","metadata":{}},{"cell_type":"code","source":"# Split into independent variables and dependent variable (y)\nx_predictors = strat_train_set.drop(\"price\", axis=1)\ny_labels = strat_train_set[\"price\"].copy()\n\n# Generate variable without strings\nford_num = x_predictors.drop([\"model\", \"transmission\", \"fuelType\"], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pipeline for NUMERICAL values\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n    (\"std_scaler\", StandardScaler()),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform CATEGORICAL values\nfrom sklearn.preprocessing import OneHotEncoder\n\nford_cat = x_predictors[[\"model\", \"transmission\", \"fuelType\"]]\ncat_encoder = OneHotEncoder()\nford_cat_1hot = cat_encoder.fit_transform(ford_cat)\nford_cat_1hot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do all at once (i.e. NUMERICAL/CATAGEORICAL variables)\nfrom sklearn.compose import ColumnTransformer\n\nnum_attribs = list(ford_num)\ncat_attribs = [\"model\", \"transmission\", \"fuelType\"]\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", OneHotEncoder(), cat_attribs),\n])\n\nford_prepared = full_pipeline.fit_transform(x_predictors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Using a Support Vector Machine (SVM) regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\n\nsvr_linear = SVR(kernel=\"linear\", C=100)\nsvr_linear.fit(ford_prepared, y_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1 Evaluation of results","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ndata_predictions = svr_linear.predict(ford_prepared)\nsvr_mse = mean_squared_error(y_labels, data_predictions)\nsvr_rmse = np.sqrt(svr_mse)\nsvr_rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Testing different kernels and hyperparameter combinations with GridSearch","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100, 1000]}\nsvr_eval = SVR()\nclf = GridSearchCV(svr_eval, parameters)\nclf.fit(ford_prepared, y_labels)\n\nsorted(clf.cv_results_.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.best_index_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3 Using optimised parameters","metadata":{}},{"cell_type":"code","source":"svr_linear_opt = SVR(kernel=\"rbf\", C=1000)\nsvr_linear_opt.fit(ford_prepared, y_labels)\n\ndata_predictions = svr_linear_opt.predict(ford_prepared)\nsvr_mse = mean_squared_error(y_labels, data_predictions)\nsvr_rmse = np.sqrt(svr_mse)\nsvr_rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.4 Overview of all combinations","metadata":{}},{"cell_type":"code","source":"clf_results = clf.cv_results_\nfor svr_mse, params in zip(clf_results[\"mean_test_score\"], clf_results[\"params\"]):\n    print(np.sqrt(svr_mse), params)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Evaluation on the test set","metadata":{}},{"cell_type":"code","source":"final_model = clf.best_estimator_\n\nX_test = strat_test_set.drop(\"price\", axis=1)\ny_test = strat_test_set[\"price\"].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_prepared = full_pipeline.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nconfidence = 0.95\nsquared_errors = (final_predictions - y_test) ** 2\nnp.sqrt(stats.t.interval(confidence, len(squared_errors) - 1, loc=squared_errors.mean(), scale=stats.sem(squared_errors)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the test set, the SVM model predicts prices for Ford cars with a RMSE of ~1,247, which is off by about 10% of the average price.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}