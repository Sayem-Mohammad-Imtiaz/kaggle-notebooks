{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom datetime import datetime\nimport glob\nimport seaborn as sns\nimport re\nimport os\nimport io\nfrom scipy.stats import boxcox","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('../input/us-accidents/US_Accidents_Dec20.csv')\nraw_df = pd.read_csv('../input/us-accidents/US_Accidents_Dec20_Updated.csv')\nprint(\"The shape of data is:\",(raw_df.shape))\ndisplay(raw_df.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = raw_df.loc[(raw_df['City'] == 'Orlando')\n                 | (raw_df['City'] == 'Jacksonville')\n                 | (raw_df['City'] == 'Chicago')\n                 | (raw_df['City'] == 'Houston')\n                 | (raw_df['City'] == 'Miami')\n                 | (raw_df['City'] == 'Tampa')\n                 | (raw_df['City'] == 'New York')\n                 | (raw_df['City'] == 'Los Angeles')]\n# cdf = raw_df.loc[df['City'] == 'Orlando']\ndf = df.copy()\nprint(len(df))\nprint(df['City'].value_counts())\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('8_Cities_historical_accidents.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Severity'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix datetime type\ndf['Start_Time'] = pd.to_datetime(df['Start_Time'])\ndf['End_Time'] = pd.to_datetime(df['End_Time'])\ndf['Weather_Timestamp'] = pd.to_datetime(df['Weather_Timestamp'])\n\n# calculate duration as the difference between end time and start time in minute\ndf['Duration'] = df['End_Time'] - df['Start_Time'] \ndf['Duration'] = df['Duration'].apply(lambda x:round(x.total_seconds() / 60) )\nprint(\"The overall mean duration is: \", (round(df['Duration'].mean(),3)), 'min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['ID','Description','Distance(mi)', 'End_Time', 'Duration', \n              'End_Lat', 'End_Lng'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_names = ['Side', 'Country', 'Timezone', 'Amenity', 'Bump', 'Crossing', \n             'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', \n             'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', \n             'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\nprint(\"Unique count of categorical features:\")\nfor i in cat_names:\n  print(i,df[i].unique().size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Country','Turning_Loop'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Wind Direction: \", df['Wind_Direction'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[df['Wind_Direction']=='Calm','Wind_Direction'] = 'CALM'\ndf.loc[(df['Wind_Direction']=='West')|(df['Wind_Direction']=='WSW')|(df['Wind_Direction']=='WNW'),'Wind_Direction'] = 'W'\ndf.loc[(df['Wind_Direction']=='South')|(df['Wind_Direction']=='SSW')|(df['Wind_Direction']=='SSE'),'Wind_Direction'] = 'S'\ndf.loc[(df['Wind_Direction']=='North')|(df['Wind_Direction']=='NNW')|(df['Wind_Direction']=='NNE'),'Wind_Direction'] = 'N'\ndf.loc[(df['Wind_Direction']=='East')|(df['Wind_Direction']=='ESE')|(df['Wind_Direction']=='ENE'),'Wind_Direction'] = 'E'\ndf.loc[df['Wind_Direction']=='Variable','Wind_Direction'] = 'VAR'\nprint(\"Wind Direction after simplification: \", df['Wind_Direction'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show distinctive weather conditions \nweather ='!'.join(df['Weather_Condition'].dropna().unique().tolist())\nweather = np.unique(np.array(re.split(\n    \"!|\\s/\\s|\\sand\\s|\\swith\\s|Partly\\s|Mostly\\s|Blowing\\s|Freezing\\s\", weather))).tolist()\nprint(\"Weather Conditions: \", weather)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Clear'] = np.where(df['Weather_Condition'].str.contains('Clear', case=False, na = False), True, False)\ndf['Cloud'] = np.where(df['Weather_Condition'].str.contains('Cloud|Overcast', case=False, na = False), True, False)\ndf['Rain'] = np.where(df['Weather_Condition'].str.contains('Rain|storm', case=False, na = False), True, False)\ndf['Heavy_Rain'] = np.where(df['Weather_Condition'].str.contains('Heavy Rain|Rain Shower|Heavy T-Storm|Heavy Thunderstorms', case=False, na = False), True, False)\ndf['Snow'] = np.where(df['Weather_Condition'].str.contains('Snow|Sleet|Ice', case=False, na = False), True, False)\ndf['Heavy_Snow'] = np.where(df['Weather_Condition'].str.contains('Heavy Snow|Heavy Sleet|Heavy Ice Pellets|Snow Showers|Squalls', case=False, na = False), True, False)\ndf['Fog'] = np.where(df['Weather_Condition'].str.contains('Fog', case=False, na = False), True, False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assign NA to created weather features where 'Weather_Condition' is null.\nweather = ['Clear','Cloud','Rain','Heavy_Rain','Snow','Heavy_Snow','Fog']\nfor i in weather:\n    df.loc[df['Weather_Condition'].isnull(),i] = df.loc[df['Weather_Condition'].isnull(),'Weather_Condition']\n    df[i] = df[i].astype('bool')\n\ndf.loc[:,['Weather_Condition'] + weather]\n\ndf = df.drop(['Weather_Condition'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# average difference between weather time and start time\nprint(\"Mean difference between 'Start_Time' and 'Weather_Timestamp': \", \n(df.Weather_Timestamp - df.Start_Time).mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop([\"Weather_Timestamp\"], axis=1)\n\ndf['Year'] = df['Start_Time'].dt.year\n\nnmonth = df['Start_Time'].dt.month\ndf['Month'] = nmonth\n\ndf['Weekday']= df['Start_Time'].dt.weekday\n\ndays_each_month = np.cumsum(np.array([0,31,28,31,30,31,30,31,31,30,31,30,31]))\nnday = [days_each_month[arg-1] for arg in nmonth.values]\nnday = nday + df[\"Start_Time\"].dt.day.values\ndf['Day'] = nday\n\ndf['Hour'] = df['Start_Time'].dt.hour\n\ndf['Minute']=df['Hour']*60.0+df[\"Start_Time\"].dt.minute\n\ndf.loc[:4,['Start_Time', 'Year', 'Month', 'Weekday', 'Day', 'Hour', 'Minute']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing = pd.DataFrame(df.isnull().sum()).reset_index()\nmissing.columns = ['Feature', 'Missing_Percent(%)']\nmissing['Missing_Percent(%)'] = missing['Missing_Percent(%)'].apply(lambda x: x / df.shape[0] * 100)\nmissing.loc[missing['Missing_Percent(%)']>0,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Number','Wind_Chill(F)'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Precipitation_NA'] = 0\ndf.loc[df['Precipitation(in)'].isnull(),'Precipitation_NA'] = 1\ndf['Precipitation(in)'] = df['Precipitation(in)'].fillna(df['Precipitation(in)'].median())\ndf.loc[:5,['Precipitation(in)','Precipitation_NA']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset=['City','Zipcode','Airport_Code',\n                       'Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group data by 'Airport_Code' and 'Start_Month' then fill NAs with median value\nWeather_data=['Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)']\nprint(\"The number of remaining missing values: \")\nfor i in Weather_data:\n  df[i] = df.groupby(['Airport_Code','Month'])[i].apply(lambda x: x.fillna(x.median()))\n  print( i + \" : \" + df[i].isnull().sum().astype(str))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset=Weather_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group data by 'Airport_Code' and 'Start_Month' then fill NAs with majority value\nfrom collections import Counter\nweather_cat = ['Wind_Direction'] + weather\nprint(\"Count of missing values that will be dropped: \")\nfor i in weather_cat:\n  df[i] = df.groupby(['Airport_Code','Month'])[i].apply(lambda x: x.fillna(Counter(x).most_common()[0][0]) if all(x.isnull())==False else x)\n  print(i + \" : \" + df[i].isnull().sum().astype(str))\n\n# drop na\ndf = df.dropna(subset=weather_cat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Severity.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def resample(dat, col, n):\n#     return pd.concat([dat[dat[col]==1].sample(n, replace = True),\n#                    dat[dat[col]==0].sample(n)], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_bl = resample(df, 'Severity', 1000)\n# print('resampled data:', df_bl.Severity.value_counts())\ndf_bl = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_bl.Year = df_bl.Year.astype(str)\nsns.countplot(x='Year', hue='Severity', data=df_bl ,palette=\"Set2\")\nplt.title('Count of Accidents by Year', size=15, y=1.05)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a dataframe used to plot heatmap\ndf_date = df.loc[:,['Start_Time','Severity']]         # create a new dateframe only containing time and severity\ndf_date['date'] = df_date['Start_Time'].dt.normalize() # keep only the date part of start time\ndf_date = df_date.drop(['Start_Time'], axis = 1)\ndf_date = df_date.groupby('date').sum()                # sum the number of accidents with severity by date\ndf_date = df_date.reset_index().drop_duplicates()\n\n# join the dataframe with full range of date from 2016 to 2020\nfull_date = pd.DataFrame(pd.date_range(start=\"2016-01-02\",end=\"2020-12-31\"))    \ndf_date = full_date.merge(df_date, how = 'left',left_on = 0, right_on = 'date')\ndf_date['date'] = df_date.iloc[:,0]\ndf_date = df_date.fillna(0)\ndf_date = df_date.iloc[:,1:].set_index('date')\n\n# group by date\ngroups = df_date['Severity'].groupby(pd.Grouper(freq='A'))\nyears = pd.DataFrame()\nfor name, group in groups:\n    if name.year != 2020:\n        years[name.year] = np.append(group.values,0)\n    else:\n        years[name.year] = group.values\n  \n\n# plot\nyears = years.T\nplt.matshow(years, interpolation=None, aspect='auto')\nplt.title('Time Heatmap of Accident with Severity Levels (raw data)', y=1.2, fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.loc[df['Start_Time'] > \"2019-03-10\",:]\ndf = df.drop(['Year', 'Start_Time'], axis=1)\ndf['Severity'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(x='Month', hue='Severity', data=df_bl ,palette=\"Set2\")\nplt.title('Count of Accidents by Month', size=15, y=1.05)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(x='Weekday', hue='Severity', data=df_bl ,palette=\"Set2\")\nplt.title('Count of Accidents by Weekday', size=15, y=1.05)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"period_features = ['Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight']\nfig, axs = plt.subplots(ncols=1, nrows=4, figsize=(13, 5))\n\nplt.subplots_adjust(wspace = 0.5)\nfor i, feature in enumerate(period_features, 1):    \n    plt.subplot(1, 4, i)\n    sns.countplot(x=feature, hue='Severity', data=df_bl ,palette=\"Set2\")\n    \n    plt.xlabel('{}'.format(feature), size=12, labelpad=3)\n    plt.ylabel('Accident Count', size=12, labelpad=3)    \n    plt.tick_params(axis='x', labelsize=12)\n    plt.tick_params(axis='y', labelsize=12)\n    \n    plt.legend(['0', '1'], loc='upper right', prop={'size': 10})\n    plt.title('Count of Severity in\\n{} Feature'.format(feature), size=13, y=1.05)\nfig.suptitle('Count of Accidents by Period-of-Day',y=1.08, fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.countplot(x='Hour', hue='Severity', data=df_bl ,palette=\"Set2\")\nplt.title('Count of Accidents by Hour', size=15, y=1.05)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # frequence encoding and log-transform\n# df['Minute_Freq'] = df.groupby(['Minute'])['Minute'].transform('count')\n# df['Minute_Freq'] = df['Minute_Freq']/df.shape[0]*24*60\n# df['Minute_Freq'] = df['Minute_Freq'].apply(lambda x: np.log(x+1))\n\n# # resampling\n# df_bl = resample(df, 'Severity', 20000)\n\n# # plot\n# df_bl['Severity4'] = df_bl['Severity'].astype('category')\n# sns.violinplot(x='Minute_Freq', y=\"Severity4\", data=df_bl, palette=\"Set2\")    \n# plt.xlabel('Minute_Fre', size=12, labelpad=3)\n# plt.ylabel('Severity4', size=12, labelpad=3)    \n# plt.tick_params(axis='x', labelsize=12)\n# plt.tick_params(axis='y', labelsize=12)\n# plt.title('Minute Frequency by Severity (resampled data)', size=16, y=1.05)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6,5))\nchart = sns.countplot(x='Timezone', hue='Severity', data=df_bl ,palette=\"Set2\")\nplt.title(\"Count of Accidents by Timezone\", size=15, y=1.05)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fre_list = ['Zipcode', 'Airport_Code','State']\nfor i in fre_list:\n  newname = i + '_Freq'\n  df[newname] = df.groupby([i])[i].transform('count')\n  df[newname] = df[newname]/df.shape[0]*df[i].unique().sizea\n  df[newname] = df[newname].apply(lambda x: np.log(x+1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(df.Zipcode_Freq.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resample again\n# df_bl = resample(df, 'Severity4', 20000)\n\ndf_bl['Severity'] = df_bl['Severity'].astype('category')\nfig, axs = plt.subplots(ncols=2, nrows=3, figsize=(10, 10))\nplt.subplots_adjust(hspace=0.4,wspace = 0.2)\nfig.suptitle('Location Frequency by Severity', fontsize=16)\nfor i, feature in enumerate(fre_list, 1): \n    feature = feature + '_Freq'   \n    plt.subplot(2, 3, i)\n    sns.violinplot(x=feature, y=\"Severity\", data=df_bl, palette=\"Set2\")\n    \n    plt.xlabel('{}'.format(feature), size=12, labelpad=3)\n    plt.ylabel('Severity', size=12, labelpad=3)    \n    plt.tick_params(axis='x', labelsize=12)\n    plt.tick_params(axis='y', labelsize=12)\n\n    plt.title('{}'.format(feature), size=16, y=1.05)\nplt.show i'm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(fre_list, axis  = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Pressure_bc']= boxcox(df['Pressure(in)'].apply(lambda x: x+1),lmbda=6)\ndf['Visibility_bc']= boxcox(df['Visibility(mi)'].apply(lambda x: x+1),lmbda = 0.1)\ndf['Wind_Speed_bc']= boxcox(df['Wind_Speed(mph)'].apply(lambda x: x+1),lmbda=-0.2)\ndf = df.drop(['Pressure(in)','Visibility(mi)','Wind_Speed(mph)'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resample again\n# df_bl = resample(df, 'Severity', 20000)\n\ndf_bl['Severity'] = df_bl['Severity'].astype('category')\nnum_features = ['Temperature(F)', 'Humidity(%)', 'Pressure_bc', 'Visibility_bc', 'Wind_Speed_bc']\nfig, axs = plt.subplots(ncols=2, nrows=3, figsize=(15, 10))\nplt.subplots_adjust(hspace=0.4,wspace = 0.2)\nfor i, feature in enumerate(num_features, 1):    \n    plt.subplot(2, 3, i)\n    sns.violinplot(x=feature, y=\"Severity\", data=df_bl, palette=\"Set2\")\n    \n    plt.xlabel('{}'.format(feature), size=12, labelpad=3)\n    plt.ylabel('Severity', size=12, labelpad=3)    \n    plt.tick_params(axis='x', labelsize=12)\n    plt.tick_params(axis='y', labelsize=12)\n\n    plt.title('{} Feature by Severity'.format(feature), size=14, y=1.05)\nfig.suptitle('Density of Accidents by Weather Features', fontsize=18)\nplt.show()p","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, nrows=4, figsize=(15, 10))\nplt.subplots_adjust(hspace=0.4,wspace = 0.6)\nfor i, feature in enumerate(weather, 1):    \n    plt.subplot(2, 4, i)\n    sns.countplot(x=feature, hue='Severity', data=df_bl ,palette=\"Set2\")\n    \n    plt.xlabel('{}'.format(feature), size=12, labelpad=3)\n    plt.ylabel('Accident Count', size=12, labelpad=3)    \n    plt.tick_params(axis='x', labelsize=12)\n    plt.tick_params(axis='y', labelsize=12)\n    \n    plt.legend(['0', '1'], loc='upper right', prop={'size': 10})\n    plt.title('Count of Severity in \\n {} Feature'.format(feature), size=14, y=1.05)\nfig.suptitle('Count of Accidents by Weather Features', fontsize=18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Heavy_Rain','Heavy_Snow','Fog'], axis  = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nchart = sns.countplot(x='Wind_Direction', hue='Severity', data=df_bl ,palette=\"Set2\")\nplt.title(\"Count of Accidents in Wind Direction\", size=15, y=1.05)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Wind_Direction'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"POI_features = ['Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal']\n\nfig, axs = plt.subplots(ncols=3, nrows=4, figsize=(15, 10))\n\nplt.subplots_adjust(hspace=0.5,wspace = 0.5)\nfor i, feature in enumerate(POI_features, 1):    \n    plt.subplot(3, 4, i)\n    sns.countplot(x=feature, hue='Severity', data=df_bl ,palette=\"Set2\")\n    \n    plt.xlabel('{}'.format(feature), size=12, labelpad=3)\n    plt.ylabel('Accident Count', size=12, labelpad=3)    \n    plt.tick_params(axis='x', labelsize=12)\n    plt.tick_params(axis='y', labelsize=12)\n    \n    plt.legend(['0', '1'], loc='upper right', prop={'size': 10})\n    plt.title('Count of Severity in {}'.format(feature), size=14, y=1.05)\nfig.suptitle('Count of Accidents in POI Features',y=1.02, fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= df.drop(['Amenity','Bump','Give_Way','No_Exit','Roundabout','Traffic_Calming'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation analysis","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelling","metadata":{}},{"cell_type":"code","source":"# one-hot encoding\ndf[period_features] = df[period_features].astype('category')\ndf = pd.get_dummies(df, columns=period_features, drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resample again\n# df_bl = resample(df, 'Severity4', 20000)\n\n# plot correlation\ndf_bl['Severity'] = df_bl['Severity'].astype(int)\nplt.figure(figsize=(25,25))\ncmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\nsns.heatmap(df_bl.corr(), annot=True,cmap=cmap, center=0).set_title(\"Correlation Heatmap\", fontsize=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Temperature(F)', 'Humidity(%)', 'Precipitation(in)', 'Precipitation_NA','Visibility_bc', 'Wind_Speed_bc',\n              'Clear','Cloud','Snow','Crossing','Junction','Railway','Month',\n              'Hour', 'Day','Minute', 'City_Freq','County_Freq','Airport_Code_Freq','Zipcode_Freq',\n              'Sunrise_Sunset_Night', 'Civil_Twilight_Night', 'Nautical_Twilight_Night'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resample again\n# df_bl = resample(df, 'Severity', 20000)\n\n# plot correlation\ndf_bl['Severity'] = df_bl['Severity'].astype(int)\nplt.figure(figsize=(20,20))\ncmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\nsns.heatmap(df_bl.corr(), annot=True,cmap=cmap, center=0).set_title(\"Correlation Heatmap\", fontsize=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(df_bl.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(df_bl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_b2 = df_bl.copy()\ndf_b2 = df_b2.drop(['Temperature(F)', 'Humidity(%)', 'Precipitation(in)', 'Precipitation_NA',\n              'Clear','Cloud','Snow','Crossing','Junction','Railway','Month',\n              'Hour', 'Day','Minute', 'Astronomical_Twilight', 'Civil_Twilight', 'Nautical_Twilight'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(df_b2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot correlation\ndf_b2['Severity'] = df_b2['Severity'].astype(int)\nplt.figure(figsize=(25,25))\ncmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\nsns.heatmap(df_bl.corr(), annot=True,cmap=cmap, center=0).set_title(\"Correlation Heatmap\", fontsize=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrrelation    = df_b2.corr(method=\"pearson\");\n\nprint(\"Pearson correlation coefficient:\");\n\nprint(corrrelation);\n\n \n\ncorrrelation    = df_b2.corr(method=\"kendall\");\n\nprint(\"Kendall Tau correlation coefficient:\");\n\nprint(corrrelation);\n\n \n\ncorrrelation    = df_b2.corr(method=\"spearman\");\n\nprint(\"Spearman rank correlation:\");\n\nprint(corrrelation);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(df_b2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_b3 = df_b2.copy()\ndf_b3 = df_b3.drop(['Airport_Code', 'Year','Amenity', 'Bump', 'City', 'County', 'Fog', 'Give_Way', 'No_Exit','Roundabout','Traffic_Calming'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(df_b3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_b3.Severity.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_b3.Zipcode.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_b3['Severity'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"0.0001 * len(df_b3['Severity'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = df_b3[df_b3.groupby('Zipcode').Zipcode.transform('count')>10].copy()\nsub_df.Zipcode.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cor = sub_df.corr(method=\"pearson\");\n\n# print(\"Pearson correlation coefficient:\");\n\n# print(cor);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Correlation with output variable\n# cor_target = abs(cor[\"Severity\"])\n# #Selecting highly correlated features\n# relevant_features = cor_target[cor_target>0.001]\n# relevant_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(sub_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot correlation\nsub_df['Severity'] = sub_df['Severity'].astype(int)\nplt.figure(figsize=(25,25))\ncmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\nsns.heatmap(sub_df.corr(), annot=True,cmap=cmap, center=0).set_title(\"Correlation Heatmap\", fontsize=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert all columns of DataFrame\n# sub_df = sub_df.apply(pd.to_numeric) # convert all columns of DataFrame\n\n# # convert just columns \"a\" and \"b\"\n# sub_df[[\"Street\", \"Zipcode\"]] = sub_df[[\"Street\", \"Zipcode\"]].apply(pd.to_numeric)\nsub_df[[\"Zipcode\"]] = sub_df[[\"Zipcode\"]].apply(pd.to_numeric)\n\nsub_df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sample Real Time API","metadata":{}},{"cell_type":"code","source":"input = ['weather_Event','time_of_day','day_ofweek', 'landmark', 'temp', 'zipcode']\n\n\nSeverity_type_value = (1,2,3,4)\n\npredict_severity_by_zipcode(input) = Severity_type_value","metadata":{},"execution_count":null,"outputs":[]}]}