{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Time Series LSTM - FORECAST NEW DATA","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import libraries\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Activation, Dense, LSTM, Dropout, GlobalMaxPooling1D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom keras.preprocessing.sequence import TimeseriesGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nFunction to access a specific set of information, which will be used in the predictive model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def GlobalTemperature_values(chart_time,inicial_date = '1995-01-01',final_date = '2019-12-31',Region=None,Country=None,City=None):  \n  \"\"\"\n  Funtion which returns the values of the Average Temperature from a given location and time.\n\n  If any location is specified the function returns a chart related with the data from the whole world.\n  To know what is the exactly list of Regions/Country/City for the parameters, involke the GlobalTemperature_dataInfo.\n  \n  The Parameter chart_time only accepts the following string names: [Day, Month, Year].\n\n  The correct format for the inicial_date and final_date is: Year-Month-Day.\n  If not specified, the inicial_date and final_date are: '1995-01-01', '2019-12-31'.\n  The Parameters inicial_date and final_date only accepts values in the interval of: 1995-01-01 ------ 2019-12-31.\n\n  \"\"\"\n  #Operations\n  def AvgperDate(data):\n    avgperDate = data.groupby('Date')['AvgTemperature'].mean()\n    return avgperDate\n  def Avgperday(data):\n    avgperday = data.groupby('Day')['AvgTemperature'].mean()\n    return avgperday\n  def Avgpermonth(data):\n    avgpermonth = data.groupby('Month')['AvgTemperature'].mean()\n    return avgpermonth\n  def Avgperyear(data):  \n    avgperyear = data.groupby('Year')['AvgTemperature'].mean()\n    return avgperyear\n\n  data = pd.read_csv('/kaggle/input/daily-temperature-of-major-cities/city_temperature.csv',low_memory=False) #import data\n  data.drop(columns = 'State',inplace=True) #drop column state\n  data['AvgTemperature'] = (data['AvgTemperature']-32)*(5/9) #transforming in Celsius\n  remove = data.loc[(data['AvgTemperature']< -50)] #removing outliers\n  data.drop(remove.index,inplace=True)\n  remove = data.loc[(data['Year'] == 2020)] #removing data from incomplete year\n  data.drop(remove.index,inplace=True)\n  date = pd.to_datetime(data[['Month','Day','Year']],errors='coerce') #data format\n  data['Date'] = date #new column\n \n  #Location choice\n  if Region != None and Country == None and City == None:\n    if any(data['Region'].unique() == Region) == False:\n      return print('Please check the list of locations and the spelling accepted using the funtion: GlobalTemperature_dataInfo ')\n    data = data[data['Region'] == Region]\n\n  elif Region == None and Country != None and City == None:\n    if any(data['Country'].unique() == Country) == False:\n      return print('Please check the list of locations and the spelling accepted using the funtion: GlobalTemperature_dataInfo ')\n    data = data[data['Country'] == Country]\n\n  elif Region == None and Country == None and City != None:\n    if any(data['City'].unique() == City) == False:\n      return print('Please check the list of locations and the spelling accepted using the funtion: GlobalTemperature_dataInfo ')\n    data = data[data['City'] == City]\n  \n  elif Region == None and Country == None and City == None:\n    data = data\n\n  else:\n    return print('Please select just one of types of location: Region, Country, City or let None in all for World data')\n\n\n\n  #Date choice\n  if inicial_date<'1995-01-01' or inicial_date>'2019-12-31':\n    return print('Please choose a initial_date greater than 1995-01-01 and lesser than 2019-12-31.')\n  elif final_date<'1995-01-01' or final_date>'2019-12-31':\n    return print('Please choose a initial_date greater than 1995-01-01 and lesser than 2019-12-31.')\n\n  data = data[(data['Date'] >= inicial_date) & (data['Date'] <= final_date)]\n\n  #chart period choice\n\n  if chart_time == 'Day':\n    return Avgperday(data)\n\n  elif chart_time == 'Month':\n    return Avgpermonth(data)\n\n  elif chart_time == 'Year':\n    return Avgperyear(data)\n  \n  elif chart_time == 'Date':\n    return AvgperDate(data)\n\n  elif chart_time == None:\n    return Avgperyear(data)\n  \n  else:\n    return print('Please type one of the following: Day,Month,Year or None ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = GlobalTemperature_values(chart_time='Date',inicial_date = '1995-01-01',final_date = '2019-12-31',Region=None,Country=None,City='Sao Paulo')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forecast Time Series","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\nAfter obtaining the data you want to perform the forecast, it is necessary to separate the data in training and testing.\n\nTest = %TOTAL_LENGTH (usually ~30%)\n\nTrain = TOTAL_LENGTH - Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train,test= train_test_split(data.values,test_size=0.3,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling the values\nIt is necessary to reshape the values to 2 dimensions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler1 = MinMaxScaler()\ntrain = scaler1.fit_transform(train.reshape(-1, 1))\ntest = scaler1.transform(test.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For data visualizations purpose, we gonna keep the dates into separate variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"split=int((1-0.3)*len(data))\n\ndate_train = data.index[:split]\ndate_test = data.index[split:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most difficult part in time series is to separate the data in batches, transforming in proper way.\n\nThere is a keras API for help us make this.\n\nThe parameter length, is how much of previus data we want to use to make predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"look_back = 20\ntrain_gen = TimeseriesGenerator(train, train, length=look_back, batch_size=20)     \ntest_gen = TimeseriesGenerator(test, test, length=look_back, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model structure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(500,activation='relu', return_sequences=True, input_shape=(look_back, 1)))\nmodel.add(LSTM(200,activation='relu', return_sequences=True, input_shape=(look_back, 1)))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\nmodel.compile(loss='mae', optimizer='adam')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trainning the model\n\nIf it is taking too long, set less steps or change the look back value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(train_gen, epochs=20, \n      verbose=1)\nmodel.save('model.pb')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Scalling back to the original data, to visualize the results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = scaler1.inverse_transform(test)\ntrain = scaler1.inverse_transform(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performing predictions with the test data\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = scaler1.inverse_transform(model.predict_generator(test_gen))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ploting the whole data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\n# plt.plot(date_train,train, label = \"Train data\")\n# plt.plot(date_test[:-look_back],pred, label = \"Prediction based in the Test data\")\nplt.plot(data.index,data.values, label = \"Data\")\nplt.title('Avg Temperature in C° per {}'.format(data.index.name))\nplt.xlabel('{}'.format(data.index.name),fontsize=15)\nplt.ylabel('Avg Temperature in C°',fontsize=15)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ploting the train and the predicted test data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(date_train,train, label = \"Train data\")\nplt.plot(date_test[:-look_back],pred, label = \"Prediction based in the Test data\")\n# plt.plot(data.index,data.values, label = \"Data\")\nplt.title('Avg Temperature in C° per {}'.format(data.index.name))\nplt.xlabel('{}'.format(data.index.name),fontsize=15)\nplt.ylabel('Avg Temperature in C°',fontsize=15)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"predicted test data and the original test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\n#plt.plot(date_train,train, label = \"Train data\")\nplt.plot(date_test[:-look_back],pred, label = \"Prediction based in the Test data\")\nplt.plot(date_test[:-look_back],test.reshape(-1)[:-look_back],label = \"Test Data\")\nplt.title('Avg Temperature in C° per {}'.format(data.index.name))\nplt.xlabel('{}'.format(data.index.name),fontsize=15)\nplt.ylabel('Avg Temperature in C°',fontsize=15)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Metrics of the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"  from sklearn import metrics\n  print('MAE:', metrics.mean_absolute_error(data.values[split+look_back:],pred))\n  print('MSE:', metrics.mean_squared_error(data.values[split+look_back:],pred))\n  print('RMSE:', np.sqrt(metrics.mean_squared_error(data.values[split+look_back:],pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After you train and test your model, with the data that you already had, you want to predict future data, which is, I think, the trully interresting thing about recurrent networks.\n\nSo in order to make this, you need to start predicting the values from one day after your final date in your original dataset, using the model (which is trained with this past data). Once you predict this value, you do the same thing, but considering the last values predict, and so on.\n\nThe fact that you are using a prediction to make others predictions, implies that is much more difficult to get good results, so is common to try to predict short ranges of time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(forecast_num, model,data,look_back):\n  prediction_list = data[-look_back:]\n\n  for _ in range(forecast_num):\n      x = prediction_list[-look_back:]\n      x = x.reshape((1, look_back, 1))\n      out = model.predict(x)[0][0]\n      prediction_list = np.append(prediction_list, out)\n  prediction_list = prediction_list[look_back-1:]\n\n  return prediction_list\n\ndef predict_dates(forecast_num):\n    last_date = data.index[-1]\n    prediction_dates = pd.date_range(last_date, periods=forecast_num+1).tolist()\n    return prediction_dates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"forecast_num = 2 #number of day to predict after the last date in data\nforecast=predict(forecast_num, model=model,data=data.values,look_back=look_back)\nforecast_date=predict_dates(forecast_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  print('forecast',forecast)\n  print('forecast dates',forecast_date)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the data in 2020, that was not used in the train or test for the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/daily-temperature-of-major-cities/city_temperature.csv',low_memory=False) #import data\ndata.drop(columns = 'State',inplace=True) #drop column state\ndata['AvgTemperature'] = (data['AvgTemperature']-32)*(5/9) #transforming in Celsius\nremove = data.loc[(data['AvgTemperature']< -50)] #removing outliers\ndata.drop(remove.index,inplace=True)\ndate = pd.to_datetime(data[['Month','Day','Year']],errors='coerce') #data format\ndata['Date'] = date #new column\nd=data[((data['Date'] =='2020-1-1') | (data['Date'] =='2020-1-2'))& (data['City'] == 'Sao Paulo')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model predicts that the average temperature would be 48 ° C and the correct answer is 26 ° C. We need to improve the model by using more layers and testing other parameters\n\n\nThis kernel was a simple example to show only the basic steps, I hope this can help someone.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}