{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc  # Garbage collection. We will use it a lot.\n\nfrom tqdm.notebook import trange, tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_from_records():\n    \"\"\"\n    This function may dowmload all records from Iowa.gov;\n    but it is too slow so it times out. You can get full csv from the same site though.\n    \"\"\"\n    # make sure to install these packages before running:\n    !pip install sodapy\n\n    from sodapy import Socrata\n\n    # Unauthenticated client only works with public data sets. Note 'None'\n    # in place of application token, and no username or password:\n    client = Socrata(\"data.iowa.gov\", None)\n\n    # Example authenticated client (needed for non-public datasets):\n    # client = Socrata(data.iowa.gov,\n    #                  MyAppToken,\n    #                  userame=\"user@example.com\",\n    #                  password=\"AFakePassword\")\n\n    # First 2000 results, returned as JSON from API / converted to Python list of\n    # dictionaries by sodapy.\n    results = client.get_all(\"m3tr-qhgy\")\n\n    # Convert to pandas DataFrame\n    results_df = pd.DataFrame.from_records(results)\n    \n    return results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_preprocessing(df):\n    \"\"\"\n    Basic preprocessing of the original Iowa Liquor Sales dataframe:\n    - cast all object values to lowercase\n    - split names into meaningfull parts [Store_Name, Store_subname, Store_Number]\n    \n    NOTE: the latter part needs improvement:\n    - some names have mulitple \"/\", need to eyeball such strings\n    - some do not have # before the number, possible solution .str.extract(pat=r'(\\d+$)')\n    \"\"\"\n    # get object columns\n    object_column_list = list(df.dtypes[df.dtypes == object].index)\n    \n    # cast all object values to lowercase\n    for object_column in object_column_list:\n        df.loc[:,object_column] = df.loc[:,object_column].str.lower().str.strip().str.split().str.join(' ')\n        gc.collect()\n    \n    # split Store_Names to [Store_Name, Store_subname, Store_Number]\n    df[['Store Name','Store Subname']] = df['Store Name'].str.rsplit(pat=\" / \", expand=True, n=1)\n    df[['Store Name','Store SubNumber']] = df['Store Name'].str.rsplit(pat=\" #\", expand=True, n=1)\n    \n    return df\n\ndef get_number_to_name_dict(df, name_to_number_dict):\n    \"\"\"\n    For every column pair (name_column, id_column) in name_to_number_dict\n    creates one-to-one mapping of id_number to longest_name_string.\n    \"\"\"\n    def max_length_dict(df, number_column, name_column):\n        \"\"\"\n        For given pair of (name_column, id_column) creates one-to-one mapping of id_number to longest_name_string.\n        \"\"\"\n        # get all unique pairs of (id_number, name),\n        # usually there are multiple names for every id\n        stores_df = df.loc[:,[number_column, name_column]].drop_duplicates()\n\n        # create dictionary to map id_number to longest name,\n        # so that we can only keep the longest names\n        number_to_name_dict = stores_df.fillna('#').groupby(number_column)[name_column].max().to_dict()\n\n        return number_to_name_dict\n\n    map_dict = {}\n    \n    # for every pair of id_column, name_column\n    for name in name_to_number_dict:\n        # add dict record: {name: number_to_name_dict}\n        map_dict[name] = max_length_dict(df,name_to_number_dict[name],name)\n    \n    return map_dict\n\n# dict of name_column, id_column pairs:\nname_to_number_dict = {\n    'Store Name':'Store Number',\n    'Store Subname':'Store Number',\n    'County':'County Number',\n    'Vendor Name':'Vendor Number',\n    'Category Name':'Category'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_columns = ['Invoice/Item Number', 'Date', 'Store Number', 'Store Name', 'Address',\n       'City', 'Zip Code', 'County Number', 'County',\n       'Category', 'Category Name', 'Vendor Number', 'Vendor Name',\n       'Item Number', 'Item Description', 'Pack', 'Bottle Volume (ml)',\n       'State Bottle Cost', 'State Bottle Retail', 'Bottles Sold',\n       'Sale (Dollars)', 'Volume Sold (Liters)']\n\n# Load raw dataset and sample 10% of it right away:\nFILE_NAME = '/kaggle/input/iowaliquorsales2020/Iowa_Liquor_Sales.csv'\nraw_df = pd.read_csv(FILE_NAME, parse_dates=['Date'], usecols=useful_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the latest date\nraw_df['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# permutate and split index in 10 parts\nsamples_idx = np.array_split(\n    np.random.permutation(raw_df.shape[0]), # permutated index\n    10 # number of parts to split index\n)\n\n# use index values from the first part:\nraw_df = raw_df.iloc[samples_idx[0],:]\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cast to lowercase & split the names\nraw_df = basic_preprocessing(raw_df)\n\n# get a dict to map id_number to longest name\nnumber_to_name_dict = get_number_to_name_dict(raw_df, name_to_number_dict)\n\n# map names to longest names based on id_numbers\nfor name in name_to_number_dict:\n    raw_df[name] = raw_df[name_to_number_dict[name]].map(number_to_name_dict[name])\n    \n# save the processed chunk\nraw_df.to_csv('iowa_processed.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indeces in other parts\nfor idx in tqdm(samples_idx[1:]):\n\n    raw_df = pd.read_csv(\n        FILE_NAME,\n        parse_dates=['Date'],\n        usecols=useful_columns\n    )  # skiprows = lambda x: x not in np.append([0],idx)  # append column names row in the beginning \n    \n    raw_df = raw_df.iloc[idx,:] # the lamda seemed to be faster but it is not\n    gc.collect() # this might be unnecessary if using lambdas\n    \n    # same as above: lowercase, split, map using existing dicts, save_append\n    raw_df = basic_preprocessing(raw_df)\n    for name in name_to_number_dict:\n        raw_df[name] = raw_df[name_to_number_dict[name]].map(number_to_name_dict[name])\n    raw_df.to_csv('iowa_processed.csv', mode='a', header=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"things to work on:\n* change column names to pythonic\n* export list of columns that chould be cast to categorical at import\n* clean names\n* add geotagging function for locations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Q1 How Covid 19 effects sale of alcolhol in Iowa?\n# Q2 Is 2020 sale the lowest sale point for alcohol?\n# Q3 Which brands and alcolhol types have benefited from coronavirus break out?\n# Q4 What is the highest selling brand and the lowest selling brand? What brand should store supply more in inventory?\n# Q5 What city has a most alcohol consumption in 2020 in term of alcohol purchased?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_df['month'] = pd.DatetimeIndex(raw_df['Date']).month\nraw_df['year'] = pd.DatetimeIndex(raw_df['Date']).year\n\ndf_month_category = raw_df.groupby(['Category Name','year','month']).mean()[['Volume Sold (Liters)', 'Sale (Dollars)']]\ndf_month_category.reset_index(inplace=True)\n\niowa_temp_month_high_avg = [29.1,35.4,48.2,61.3,72.3,81.8,86.0,83.9,75.9,63.5,46.7,33.1]\niowa_temp_month_high_avg_dict = dict(zip(list(range(1,13)),iowa_temp_month_high_avg))\ndf_month_category['mnth_avg_temp'] = df_month_category.month.map(iowa_temp_month_high_avg_dict)\ndf_month_category\n# code a graph to answer the question","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year2020 = df_month_category.groupby('year').month.describe()\nyear2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_year = df_month_category.groupby('year').mean().drop('month', axis = 1).drop('mnth_avg_temp', axis = 1)\ndf_year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rc('font', size=12)\nfig, ax = plt.subplots(figsize=(10, 6))\nax.plot(df_month_category.year, df_month_category.Sale(Dollars))\nax.set_xlabel('year')\nax.set_ylabel('Sale (Dollars)')\nax.set_title('Sale (Dollars) through the years')\nax.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minSale = df_year['Sale (Dollars)'].min()\nif minSale == df_year.iloc[8,1]:\n    print('Year 2020 has a lowest sale point for alcohol since 2012.')\nelse:\n    print('Year 2020 does not has a lowest sale point for alcohol since 2012.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncategory_names_list = list(df_month_category['Category Name'].unique())\nfor i, category_name in enumerate(category_names_list):\n    category_mask = df_month_category['Category Name']==category_name\n    pivot_data = df_month_category[category_mask].pivot('year','month','Sale (Dollars)')\n    fig, ax = plt.subplots()\n    fig.set_size_inches(12, pivot_data.shape[0])\n    sns.heatmap(pivot_data).set_title(category_name.upper(),pad=20, fontdict={'fontsize': 20, 'fontweight': 'medium'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_category = df_month_category.groupby\n('Category Name').mean().drop('month', \naxis = 1).drop('mnth_avg_temp', axis = \n1).drop('year', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Q4\nmax_sale_brand = df_category['Sale (Dollars)'].idxmax()\nmin_sale_brand = df_category['Sale (Dollars)'].idxmin()\nprint('The brand with highest sales is ' + max_sale_brand)\nprint('The brand with lowest sales is ' + min_sale_brand)\nprint('Stores should supply more ' + max_sale_brand + 'rather than ' + min_sale_brand)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_consumption_df = raw_df.groupby(['City'])\n.sum()[['Volume Sold (Liters)', 'Sale (Dollars)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_city_sales = city_consumption_df['Sale (Dollars)'].idxmax()\nmax_city_volumes = city_consumption_df['Volume Sold (Liters)'].idxmax()\nprint( max_city_sales + 'has the most sales in Iowa')\nprint( max_city_volumes + 'has the most volume sold in Iowa')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}