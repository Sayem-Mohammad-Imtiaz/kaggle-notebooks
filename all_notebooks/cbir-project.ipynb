{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#miscellaneous libreries used \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 as cv #\nfrom matplotlib import pyplot as plt\nimport sys\nimport random\nfrom sklearn.neighbors import NearestNeighbors\nimport math\n\n#Keras modules used\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras import datasets\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import TensorBoard\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining what artists will be included in our database of images aswell as the sample size for each one\nartists=[\"Vincent_van_Gogh\",\"Pablo_Picasso\",\"Hieronymus_Bosch\",\"Giotto_di_Bondone\",\"Salvador_Dali\"]\nsampleSize = 100\nimgDatabase = []\n#creation of the initial img database\nfor artist in artists:\n    for i in range(sampleSize):\n        img = cv.imread(\"../input/best-artworks-of-all-time/resized/resized/\" + artist + \"_\" + str(i + 1) + \".jpg\", 1)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        if img is None:\n            sys.exit(\"Error. Image not found\")\n        imgDatabase.append([img,artist])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displays a random image from the dataset\nplt.imshow(imgDatabase[random.randint(1,(len(artists)*sampleSize))][0])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counts how many images exist in a list per artist\ndef countImgsByArtist(imgSet):\n    result = {}\n    for (img,artist) in imgSet:\n        result[artist] = result.get(artist, 0) +1\n    print(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prepars the images for the autoencoder by normalizing all values between 1 & 0 aswell as flatterning down the images \ndef prepareImgs(imgSet):\n    imgs = np.array([cv.resize(img[0].astype('float32') / 255,(width,height)) for img in imgSet])\n    imgs2 = np.array([img.flatten() for img in imgs])\n    return(imgs,imgs2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shuffling the img database before performing a train test split on it\nsplitIndx = int(len(imgDatabase)*0.75)\nrandom.shuffle(imgDatabase)\n\n#setting the image size for the pictures\nwidth = 100\nheight = 100\ndim = width * height\n\n# This is our input image for our autoencoders\ninput_img = keras.Input(shape=(dim*3,))\n\n#the content and labels for the train set\ntrain = imgDatabase[:splitIndx]\nx_train2, x_train = prepareImgs(train)\ny_train = [img[1] for img in train]\n\n#the content and labels for the test set\ntest = imgDatabase[splitIndx:]\nx_test2, x_test = prepareImgs(test)\n\ny_test = [img[1] for img in test]\n\n#How many images of each artist is in each set.\ncountImgsByArtist(train)\ncountImgsByArtist(test)\nprint(dim)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"encoded\" is the encoded representation of the input\nencoded = layers.Dense(32, activation='relu')(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = layers.Dense(dim*3, activation='sigmoid')(encoded)\n\n# This model maps an input to its reconstruction\nautoencoder1 = keras.Model(input_img, decoded)\n\n# This model maps an input to its encoded representation\nencoder1 = keras.Model(input_img, encoded)\n\n# This is our encoded (32-dimensional) input\nencoded_input = keras.Input(shape=(32,))\n\n# Retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder1.layers[-1]\n\n# Create the decoder model\ndecoder = keras.Model(encoded_input, decoder_layer(encoded_input))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compile and train the single node autoencoder\nautoencoder1.compile(optimizer='adam', loss='binary_crossentropy')\n\nautoencoder1.fit(x_train, x_train,\n                epochs=200,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode and decode the test images\nencodedImgs1 = encoder1.predict(x_test)\ndecodedImgs1 = decoder.predict(encodedImgs1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Display random examples of the denoised images from the autoencoders\ndef displayDenoiseResults(test, decodedImgs):\n    n = 10  # How many Images that will display\n    plt.figure(figsize=(20, 4))\n    for i in range(n):\n        # Display original paintings\n        ax = plt.subplot(1, n, i + 1)\n        plt.imshow(test[i].reshape(width, height, 3))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        # Display reconstruction\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(decodedImgs[i].reshape(width, height, 3))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"displayDenoiseResults(x_test, decodedImgs1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Our deep stacked autoencoder\n\n# \"encoded\" is the encoded representation of the input\nencoded = layers.Dense(128, activation='relu')(input_img)\nencoded = layers.Dense(64, activation='relu')(encoded)\nencoded = layers.Dense(32, activation='relu')(encoded)\n\ndecoded = layers.Dense(dim*3, activation='sigmoid')(encoded)\n# This model maps an input to its reconstruction\nautoencoder2 = keras.Model(input_img, decoded)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This model maps an input to its encoded representation\nencoder2 = keras.Model(input_img, encoded)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is our encoded (32-dimensional) input\nencoded_input2 = keras.Input(shape=(32,))\n# Retrieve the last layer of the autoencoder model\ndecoder_layer2 = autoencoder2.layers[-1]\n# Create the decoder model\ndecoder2 = keras.Model(encoded_input2, decoder_layer2(encoded_input2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compiles and train our deep stacked autoencoder\nautoencoder2.compile(optimizer='adam', loss='binary_crossentropy')\n\nautoencoder2.fit(x_train, x_train,\n                epochs=200,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode and decode the test images\nencodedImgs2 = encoder2.predict(x_test)\ndecodedImgs2 = decoder2.predict(encodedImgs2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"displayDenoiseResults(x_test,decodedImgs2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Texture feature extraction by using gabor filters\nksize = 15\nsigma = 4\ntheta = 2*np.pi/2\nlamda = 1*np.pi/4\ngamma=0.5\nphi=0.7\nkernel = cv.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv.CV_32F)\n\n#creating the filters of the training and testing sets\nplt.imshow(kernel)\ntrain_fimgs = [cv.filter2D(cv.cvtColor(img.reshape(width, height, 3), cv.COLOR_BGR2GRAY), cv.CV_8UC3, kernel) for img in x_train]\ntest_fimgs = [cv.filter2D(cv.cvtColor(img.reshape(width, height, 3), cv.COLOR_BGR2GRAY), cv.CV_8UC3, kernel) for img in x_test]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Displays 5 Gabor Filter maps geenrated on top of 4 random samples from the training set.\nfor i in range(5):\n    ax = plt.figure()\n    ax.add_subplot(1,2, 1)\n    plt.imshow(train_fimgs[i])\n    ax.add_subplot(1,2, 2)\n    plt.imshow(train[i][0])\n    plt.show(block=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creation of our Convolutional Autoencoder\ninput_img = keras.Input(shape=(width, height,3))\n# \"encoded\" is the encoded representation of the input\nx = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D((2, 2), padding='same')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\nencoded = layers.MaxPooling2D((2, 2), padding='same', name = 'features')(x)#Layer given a name to access later on.\n\n#\"decoded\" is the decoded representation of the created binary code from the encoder\nx = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\nx = layers.UpSampling2D((2, 2))(x)\nx = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = layers.UpSampling2D((2, 2))(x)\nx = layers.Conv2D(16, (3, 3), activation='relu')(x)\nx = layers.UpSampling2D((2, 2))(x)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n# This model maps an input to its reconstruction\n\nautoencoder3 = keras.Model(input_img, decoded)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trains and compiles the convolutional autoencoder \nautoencoder3.compile(optimizer='adam', loss='binary_crossentropy')\n\nautoencoder3.fit(x_train2, x_train2,\n                epochs=100,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test2, x_test2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracts the features from the images of both the training and testing sets.\nencoder3 = Model(inputs=autoencoder3.input, outputs=autoencoder3.get_layer('features').output)#grabs the final layer from the encoder component for feature extraction\ntestBinaryCodes = encoder3.predict(x_test2)\ntemp = testBinaryCodes.shape\ndecodedImgs4 = autoencoder3.predict(x_test2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 10  # How many Images that will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # Display original paintings\n    ax = plt.subplot(1, n, i + 1)\n    plt.imshow(decodedImgs4[i])\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting the nearest neighbour objects for each classifier to compare agaisn't each test image.\n#Setting the number of images we want returned \nkNeighbors = 5\n\n#Fitting the train data features from the single node autoencoder\nneighbor1 = NearestNeighbors(n_neighbors = kNeighbors)\nneighbor1.fit(encoder1.predict(x_train))\n\n#Fitting the train data features from the deep stacked autoencoder\nneighbor2 = NearestNeighbors(n_neighbors = kNeighbors)\nneighbor2.fit(encoder2.predict(x_train))\n\n#Fitting the texture features from the gabour filter\nneighbor3 = NearestNeighbors(n_neighbors = kNeighbors)\nneighbor3.fit([fimg.flatten() for fimg in train_fimgs])\n\n#Fitting the train data features from the convolutional autoencoder\nneighbor4 = NearestNeighbors(n_neighbors = kNeighbors)\ntrainBinaryCodes = encoder3.predict(x_train2)\ntemp = trainBinaryCodes.shape\ntrainBinaryCodes = trainBinaryCodes.reshape(temp[0],(temp[1]*temp[2]*temp[3]))\nneighbor4.fit(trainBinaryCodes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating the accuracy of the CBIR with our deep stacked autoencoder\ndef cbirScore(nn,encodedImgs, test = test, y_train = y_train, y_test = y_test):\n    score = []\n    for i in range(len(test)):\n        results = nn.kneighbors(encodedImgs[[i]])[1][0]\n        query = y_test[i]\n        temp = 0\n        for pos in results:\n            if(query == y_train[pos]):\n                temp += 1\n        score.append((temp/kNeighbors)*100)\n    return(str(sum(score)/len(score)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating the accuracy of the CBIR with Gabour Filters\ndef filterScore(nn,test_fimgs = test_fimgs, test = test, y_train = y_train, y_test = y_test):\n    score = []\n    for i in range(len(test)):\n        results = nn.kneighbors([test_fimgs[indx].flatten()])[1][0]\n        query = y_test[i]\n        temp = 0\n        for pos in results:\n            if(query == y_train[pos]):\n                temp += 1\n        score.append((temp/kNeighbors)*100)\n    return(str(sum(score)/len(score))) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Displaying retrieved images for a query images\ndef displayQuerySample(results, indx, title, y_test = y_test, train = train):\n    positions = results[1][0]\n    plt.figure(figsize=(20,5))\n    plt.suptitle(title, fontsize=16)\n    plt.tight_layout()\n    ax = plt.subplot(1, kNeighbors+1, 1)\n    fig = ax.get_figure()\n    #Sets the first image in the figure as the query image\n    plt.imshow(test[indx][0])\n    ax.set_title(\"Query:\\n\" + y_test[indx])\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    #Iterate through the retrieved images to add them to the figure\n    for i in range(kNeighbors):\n        img = train[positions[i]]\n        ax = plt.subplot(1, kNeighbors+1, i + 2)\n        plt.imshow(img[0])\n        ax.set_title(img[1])\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n    positions = results[1][0]\n    results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#showing a sample of each classifier using the same query image\nindx = random.randint(1,125)\n#Sample of the single node autoencoder\ndisplayQuerySample(neighbor1.kneighbors(encodedImgs1[[indx]]), indx, \"Single Node Autoencoder\")\nprint(\"Single Node Autoencoder Accuracy: \" + cbirScore(neighbor1, encodedImgs1))\n#Sample of the deep stacked auto encoder\ndisplayQuerySample(neighbor2.kneighbors(encodedImgs2[[indx]]), indx, \"Deep Stacked Autoencoder\")\nprint(\"Deep Stacked Autoencoder Accuracy: \" + cbirScore(neighbor2, encodedImgs2))\n#Sample of the Gabor filter extraction\ndisplayQuerySample(neighbor3.kneighbors([test_fimgs[indx].flatten()]), indx,\"Gabor Filter Texture extraction\")\nprint(\"Gabor Filter Texture extraction: \" + filterScore(neighbor3))\n#Sample of the convolutional autoencoder\ntestBinaryCodes = encoder3.predict(x_test2)\ntemp = testBinaryCodes.shape\ntestBinaryCodes = testBinaryCodes.reshape(temp[0],(temp[1]*temp[2]*temp[3]))\ndisplayQuerySample(neighbor4.kneighbors(testBinaryCodes[[indx]]), indx, \"Convolutional Autoencoder\")\nprint(\"Convolutional Autoencoder: \" + cbirScore(neighbor4, trainBinaryCodes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}