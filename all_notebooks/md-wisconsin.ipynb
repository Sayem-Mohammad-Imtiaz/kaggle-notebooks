{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación \n\n### Minería de datos: Curso 2020-2021 \n\n* José Gabriel Ruiz Gomez\n* Francisco Javier Vicente Martínez\n\n**Base de datos Wisconsin**\n"},{"metadata":{},"cell_type":"markdown","source":"# 1. Preliminares"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport seaborn as sns\nsns.set()\nfrom sklearn.impute import SimpleImputer\n\n#IMPORTANTE AÑADIRLO EN NUESTRO LOCAL\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fijación de la semilla \nseed = 27912","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"El conjunto datos a utilizar es `Breast Cancer Wisconsin`. \nContiene 546 muestras que se clasifican en dos tipos de tumores:\n* `B = Benigno`\n* `M = Maligno`\n\nPara cada tumor se han realizado una serie de mediciones correspondientes a las variables predictoras del problema:\n* `radius` : media de distancias entre el centro de los puntos al perímetro\n* `texture` : desviación estandard de los valores de escala de grises\n* `perimeter` : perímetro\n* `area` : área\n* `smoothness` : variación local en la longitud de los radios\n* `compactness` : perímetro^2 / area - 1.0\n* `concavity` : severidad de las porciones cóncavas del contorno\n* `concave points` : numero de las porciones cóncavas del contorno\n* `symetry` : simetría\n* `fractal dimension` : aproximación de la línea de costa - 1\n\nEn las tablas se representa la media, la desviación típica y un valor \"worst\" que es la media de los tres mayores valores. Resultando 30 variables distribuidas de forma que el campo 3 es Media del Radio, el campo 13 desviación típica del Radio y campo 23 es \"worst\" del radio.\n\nEl objetivo sería clasificar una nueva instancia (cuya clasificación es desconocida) en función de sus variables.\n\n"},{"metadata":{},"cell_type":"markdown","source":"Comenzamos cargando el conjunto de datos `Breast Cancer Wisconsin`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos el conjunto de datos en dos subconjuntos, uno con variables predictoras (X) y otro con la variable objetivo (y)."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Además debemos separar nuestro conjunto de datos en dos:\n\n* Una muestra de entrenamiento (típicamente, 70%)\n* Una muestra de prueba (típicamente, 30%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                     stratify=y, \n                                                     random_state=seed,\n                                                     train_size=train_size)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para facilitar el análisis exploratorio de datos, volvemos a juntar las variables predictoras con la variable clase. Comenzamos con el conjunto de datos entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Continuamos con el conjunto de datos de prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar el preprocesamiento es interesante observar las propiedades del conjunto de datos, analizando sus variables y la interacción entre estas. No obstante, no podemos usar el formato tabular directamente puesto que para un humano es casi imposible extraer conclusiones a partir del análisis de valores numéricos. Por ello, nos apoyaremos en gráficos y estadísticos."},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de realizar cualquier operación es fundamental conocer nuestro problema. Hay dos dimensiones básicas que deben ser exploradas:\n\n* Número de casos\n* Número de variables\n    * Tipo de las variables: Continuas (t.c.c. numéricas) o discretas (t.c.c. categóricas)\n\nPara ello, consultaremos las estructuras de datos correspondientes."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tal y como se puede observar, el conjunto de datos de entrenamiento está formado por 398 casos y 31 variables (30 variables predictoras y 1 variable clase)\n\nPara conocer cuál es el tipo de las variables, recurrimos al método `info`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todas las variables son numéricas, excepto la variable objetivo. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La variable clase tiene dos estados *(M y B)*."},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"Una vez conocemos con más detalle el conjunto de datos de entrenamiento, lo que debemos hacer es representar y analizar las distribuciones de las variables. Para ello, utilizaremos métodos univariados, esto es, histogramas para las variables numéricas y diagramas de barras para las variables categóricas. En particular:\n\n* Un histograma muestra la densidad de ejemplos para los distintos valores de una variable numérica.\n* Un diagrama de barras representa la frecuencia de cada estado de una variable categórica."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que la clase objetivo no tiene el mismo número de variables para cada clasificación por lo tanto no es un problema que se encuentre balanceado. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para que las gráficas sean más representativas dividimos el conjunto de datos de entrenamiento en tres subconjuntos, que representarán cada uno los valores de las medias (means_data), los valores de el error standard (SE_data) y los valores \"worst\" (worst_data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"means_data = data_train[[\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\", \"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"diagnosis\"]]\nSE_data = data_train[[\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\", \"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"diagnosis\"]]\nworst_data = data_train[[\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\", \"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\",\"diagnosis\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora representaremos en diferentes gráficas los datos para obtener más conocimiento"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(means_data.corr(), annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(SE_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(worst_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(means_data, target=\"diagnosis\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(SE_data, target=\"diagnosis\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(worst_data, target=\"diagnosis\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Dentro del preprocesamiento de datos, podemos destacar las siguientes tareas:\n\n* Limpieza de datos (imputación de valores perdidos, suavizado del ruido, etc.)\n* Integración de datos (a partir de múltiples fuentes)\n* Transformación de datos (normalización, construcción, etc.)\n* Reducción de datos (discretización de variables numéricas, selección de variables, selección de instancias, etc.)"},{"metadata":{},"cell_type":"markdown","source":"### Valores perdidos"},{"metadata":{},"cell_type":"markdown","source":"Para poder usar un pipeline y poder distinguir las variables con valores perdidos tenemos que \"modificar\" toda la base de datos, realmente no vamos a modificar los datos, simplemente vamos a indicar como nan los valores perdidos, de esta forma podemos aplicar el mismo pipeline al conjunto de entrenamiento, al conjunto de test y a los datos que vengan despues."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(100, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Discretización"},{"metadata":{},"cell_type":"markdown","source":"Como hemos visto, la discretización permite transformar variables numéricas en categóricas, siendo este paso beneficioso para algunos algoritmos de aprendizaje, pues permite que modelos lineales resuelvan problemas no lineales.\n\n`scikit-learn` permite realizar tres tipos de discretización (`strategy`) mediante el transformador `KBinsDiscretizer`:\n\n* `uniform`: Igual anchura.\n* `quantile`: Igual frecuencia.\n* `kmeans`: Discretización basada en k-medias.\n\nTras el análisis exploratorio de datos realizado previamente, parece lógico realizar una discretización en 3 intevalos de igual anchura:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\n#imputer = SimpleImputer(missing_values=np.NaN, strategy='mean')\nimputer = SimpleImputer(missing_values=np.NaN, strategy='median')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = make_pipeline(imputer, DummyClassifier(strategy=\"most_frequent\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo CART "},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = make_pipeline(imputer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(imputer, discretizer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"### Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n              X_train, X_test,\n              y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Arbol de clasificación"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n              X_train, X_test,\n              y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De los tres algoritmos evaluados el que mayor precisión tiene es cuando hemos discretizado los valores. Sin embargo, en la aplicación real de este problema nos parece que es mejor la estrategia sin discretizar ya que nuestro objetivo sería minimizar el número de falsos negativos, es decir, que el algoritmo te clasifique como Benigno y realmente sea Maligno, para este caso sin discretizar tenemos mejores resultados. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}