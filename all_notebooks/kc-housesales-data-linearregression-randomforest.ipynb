{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Let's get started!"},{"metadata":{},"cell_type":"markdown","source":"# KC_Housesales_Data\n- Predict House sale prices using Multi-Linear Regression\n- Predict the sales of houses in King County with an accuracy of at least 75-80% and \n- understand which factors are responsible for higher property value  \"$650K and above.\"\n"},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#basic eda packages\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 7, 5\npd.options.display.max_columns = 25\nsns.set(style='darkgrid')\n\n#validation\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\n#models \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/kc-housesales-data/kc_house_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Basic eda checks"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of the data :\",df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(df.isna().sum()).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here their are no null values found!!"},{"metadata":{},"cell_type":"markdown","source":"**correlation** w.r.t price "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(df.corr()['price']).sort_values(by='price',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# lets plot the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Counter(df.bedrooms))\nsns.countplot(df.bedrooms,order=df.bedrooms.value_counts().index);\nplt.title(\"No of Bedrooms count\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xticks(rotation=90)\nsns.countplot(df.bathrooms,order=df.bathrooms.value_counts().index);\nplt.title('No of bathroom Counts');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Counter(df.floors))\nsns.countplot(df.floors,order=df.floors.value_counts().index);\nplt.title(\"Number of Floors\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets have handson on pie chart as well!!"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Counter(df.waterfront))\nplt.pie(df.waterfront.value_counts(),explode=[0,0.5],\\\n        autopct=\"%01.1f\",labels=df.waterfront.unique(),shadow=True,startangle=10,colors=['gold','red'],\\\n        textprops={'fontsize': 14});\nplt.axis(\"equal\");\nplt.title('Waterfront in Percentage');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Counter(df.view))\nsns.countplot(df.view);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(list(Counter(df.grade).keys()),list(Counter(df.grade).values()));\nplt.xlabel(\"Grade\");\nplt.ylabel(\"Count of Grades\");\nplt.title(\"Types of Grades\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature engineering \n- and yea it's a vast topic but i just went with basics here "},{"metadata":{},"cell_type":"markdown","source":"lets drop the non contribution variables here"},{"metadata":{"trusted":true},"cell_type":"code","source":"unwanted = ['id','date']\ndf.drop(unwanted,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #id and data variable coll is droped","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we'll calculate the number of year's between present year and mentioned year in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['built_age'] = 2020 - df.yr_built \ndf.drop('yr_built',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = list(df.iloc[:,1:].values) # independent variables\ny = df.price.values # dependent variable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sn = StandardScaler()\nX = sn.fit_transform(X)\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We'll check the distrubution of the dependent variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(y);\nplt.xticks(rotation=90);\nplt.title(\"Before normalizing the dependent variable\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Here we can see that data is \"Highly positively skewed\"\n- Lets normalize the y variable (dependent variable)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.log10(y)\n#we just normalized the y variable using log10 which is available in numpy package \n#now lets plot the data\n\nsns.distplot(y);\nplt.xticks(rotation=90);\nplt.title(\"After normalizing the dependent variable\");\nprint(\"This is also called as normal gaussian distribution\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n- We start machine learning by setting the features and target:\n\n- Features: x\n- Target: y"},{"metadata":{},"cell_type":"markdown","source":"Then, we split them to train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train ,X_test , y_train ,y_test = train_test_split(X,y,test_size=0.2,random_state=10)\nprint(X_train.shape,X_test.shape,y_train.shape,y_test.shape) #printing the shape of splited data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine learning\n> here i have taken 2 regression algorithms i.e\n- LinearRegression\n- RandomForestRegressor\n\n\n- Here we'er calculating both train and test data so that we can check if the data is overfitted , underfitted of optimal in state"},{"metadata":{},"cell_type":"markdown","source":"# 1. LinearRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_line = LinearRegression(normalize=True,fit_intercept=True,n_jobs=1)\nmodel_line.fit(X_train,y_train)\n\ny_train_pred = model_line.predict(X_train)\ny_pred = model_line.predict(X_test)\n\n\nprint(\"Train score:\",r2_score(y_train,y_train_pred))\nprint(\"Test score:\",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.RandomForestRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(n_estimators=190,max_depth=100,random_state=25,max_features='auto',n_jobs=1)\nmodel.fit(X_train,y_train)\n\ny_train_pred = model.predict(X_train)\ny_pred = model.predict(X_test)\n\n\nprint(\"Train score:\",r2_score(y_train,y_train_pred))\nprint(\"Test score:\",r2_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## If you made it this far, thank you for your attention.\n### In order to improve my score, I will keep updating this kernel by:\n\n- Creating new features\n- normalizing the data \n- I will bring more updates, stay tuned!"},{"metadata":{},"cell_type":"markdown","source":"#### if you find this kernal helpfull please vote :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}