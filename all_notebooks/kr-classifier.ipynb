{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nfrom kor_preprocessing import encode_str\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\n\ntf.version.VERSION","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is 1 csv file in the current version of the dataset:\n"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"nRowsRead = None # specify 'None' if want to read whole file\n# hate_speech_data.csv has 2000 rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('../input/korean-extremist-website-womad-hate-speech-data/hate_speech_data.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'hate_speech_data.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a quick look at what the data looks like:"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, label = df1.iloc[:,1], df1.iloc[:,2]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\ntrain_size = 1900\nX_train, X_test = shuffle(X[:train_size]), shuffle(X[train_size:])\nlabel_train, label_test = shuffle(label[:train_size]), shuffle(label[train_size:])\n\n# https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train)\n\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n\nfrom sklearn.naive_bayes import MultinomialNB\ntext_clf = MultinomialNB().fit(X_train_tfidf, label_train)\n\npredicted = text_clf.predict(tfidf_transformer.transform(count_vect.transform(X_test)))\nprint(\"Naive_Bayes baseline: {}\".format(np.mean(predicted == label_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = tf.data.Dataset.from_tensor_slices((X, label))\nfor value in ds.take(5):\n    print(value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_X = ds.map(lambda x, Y: x)\nds_Y = ds.map(lambda x, Y: Y)\n\ndef encode(str_tensor, length=20):\n    s = str_tensor.numpy().decode('UTF-8')\n    try:\n        return np.array(encode_str(s, length))\n    except Exception as ex:\n        print(s, ex)\n        raise ex\n\ndef tf_encode(str_tensor, length=20):\n    return tf.py_function(encode,\n                       [str_tensor, length],\n                       [tf.int64])\n\nds_X = ds_X.map(tf_encode)\nfor value in ds_X.take(5):\n    print(value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_SIZE = 100\nBATCH = 25\n\nds_X_test = ds_X.take(TEST_SIZE)\nds_Y_test = ds_Y.take(TEST_SIZE)\n\nds_X_train = ds_X.skip(TEST_SIZE)\nds_Y_train = ds_Y.skip(TEST_SIZE)\n\nds_test = tf.data.Dataset.zip((ds_X_test, ds_Y_test)) \nds_train = tf.data.Dataset.zip((ds_X_train, ds_Y_train))\n\n#BATCH x length x ENCODE\nds_test = ds_test.repeat().batch(BATCH, True)\nds_train = ds_train.repeat().batch(BATCH, True)\n\nfor value in ds_test.take(2):\n    print(value)\nfor value in ds_train.take(2):\n    print(value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_model = keras.Sequential()\n\n# embedding 25 x length x 256\nsimple_model.add(keras.layers.Dense(256, input_shape=(20, 120)))\n# biGRU 25 x 256\nsimple_model.add(keras.layers.Bidirectional(keras.layers.GRU(256)))\n# dense output 25 x 1\nsimple_model.add(keras.layers.Dense(1, activation='sigmoid'))\n\nsimple_model.compile(loss='binary_crossentropy', metrics=['acc'])\nsimple_model.summary()\n\nEPOCHS = 100\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\nsimple_model.fit(x=ds_train.repeat().as_numpy_iterator(),\n                 validation_data=ds_test.repeat().as_numpy_iterator(),\n                 batch_size=BATCH,\n                 epochs=EPOCHS,\n                 steps_per_epoch=int((nRow - TEST_SIZE) / BATCH),\n                 validation_steps=int(TEST_SIZE / BATCH),\n                 callbacks=[callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pred(sentence):\n    predicted = simple_model.predict(np.array([encode_str(sentence)], dtype=np.int64))\n    print(\"{}-Prediction: {}\".format(sentence, predicted))\n\npred(\"한남충 개돼지 뒤져라 좆팔\")\npred(\"안녕하세요? 반갑습니다.\")\npred(\"ㅎㄴㅊ 재기해\")\npred(\"안녕하세요 ㅎㄴㅊ ㅅㅋ야\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}