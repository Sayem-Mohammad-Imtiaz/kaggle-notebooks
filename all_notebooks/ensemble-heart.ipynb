{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # 导入NumPy数学工具箱\nimport pandas as pd # 导入Pandas数据处理工具箱\ndf = pd.read_csv(\"../input/heartdataset/heart.csv\")  # 读取文件\ndf.head() # 显示前5行数据","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:03:21.364079Z","iopub.execute_input":"2021-08-04T14:03:21.364474Z","iopub.status.idle":"2021-08-04T14:03:21.505666Z","shell.execute_reply.started":"2021-08-04T14:03:21.36444Z","shell.execute_reply":"2021-08-04T14:03:21.504321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns #导入seaborn画图工具箱\nsns.countplot(x=\"target\", data=df, palette=\"bwr\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:03:30.831933Z","iopub.execute_input":"2021-08-04T14:03:30.832333Z","iopub.status.idle":"2021-08-04T14:03:31.968625Z","shell.execute_reply.started":"2021-08-04T14:03:30.832298Z","shell.execute_reply":"2021-08-04T14:03:31.967383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 将某些特征转换为数值类型的哑变量\na = pd.get_dummies(df['cp'], prefix = \"cp\")\nb = pd.get_dummies(df['thal'], prefix = \"thal\")\nc = pd.get_dummies(df['slope'], prefix = \"slope\")\nframes = [df, a, b, c]\ndf = pd.concat(frames, axis = 1)\ndf.head()\ndf = df.drop(columns = ['cp', 'thal', 'slope'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:03:41.165121Z","iopub.execute_input":"2021-08-04T14:03:41.165529Z","iopub.status.idle":"2021-08-04T14:03:41.202772Z","shell.execute_reply.started":"2021-08-04T14:03:41.165497Z","shell.execute_reply":"2021-08-04T14:03:41.201625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 构建特征和标签集\ny = df.target.values\nX = df.drop(['target'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:03:52.384989Z","iopub.execute_input":"2021-08-04T14:03:52.385479Z","iopub.status.idle":"2021-08-04T14:03:52.391389Z","shell.execute_reply.started":"2021-08-04T14:03:52.385437Z","shell.execute_reply":"2021-08-04T14:03:52.390501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split # 拆分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:04:02.868777Z","iopub.execute_input":"2021-08-04T14:04:02.869163Z","iopub.status.idle":"2021-08-04T14:04:03.054169Z","shell.execute_reply.started":"2021-08-04T14:04:02.869133Z","shell.execute_reply":"2021-08-04T14:04:03.053242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 进行特征缩放\nfrom sklearn import preprocessing\nscaler = preprocessing.MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:04:12.892767Z","iopub.execute_input":"2021-08-04T14:04:12.893307Z","iopub.status.idle":"2021-08-04T14:04:12.907425Z","shell.execute_reply.started":"2021-08-04T14:04:12.893273Z","shell.execute_reply":"2021-08-04T14:04:12.906156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bagging with a decision tree regressor\nfrom sklearn.ensemble import BaggingClassifier \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import (f1_score, confusion_matrix) # 导入评估标准\ndt = BaggingClassifier(DecisionTreeClassifier()) # 只使用一棵决策树\ndt.fit(X_train, y_train) # 拟合模型\ny_pred = dt.predict(X_test) # 进行预测\nprint(\"决策树测试准确率: {:.2f}%\".format(dt.score(X_test, y_test)*100))\nprint(\"决策树测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\nbdt = BaggingClassifier(DecisionTreeClassifier()) #树的Bagging\nbdt.fit(X_train, y_train) # 拟合模型\ny_pred = bdt.predict(X_test) # 进行预测\nprint(\"决策树Bagging测试准确率: {:.2f}%\".format(bdt.score(X_test, y_test)*100))\nprint(\"决策树Bagging测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:05:04.874054Z","iopub.execute_input":"2021-08-04T14:05:04.874858Z","iopub.status.idle":"2021-08-04T14:05:05.157257Z","shell.execute_reply.started":"2021-08-04T14:05:04.874798Z","shell.execute_reply":"2021-08-04T14:05:05.156014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV # 导入网格搜索工具\n# 使用网格搜索优化参数\nbdt_param_grid = {\n    'base_estimator__max_depth' : [5,10,20,50,100],\n    'n_estimators' : [1, 5, 10, 50]}\nbdt_gs = GridSearchCV(BaggingClassifier(DecisionTreeClassifier()),\n                   param_grid = bdt_param_grid, scoring = 'f1',\n                   n_jobs= 10, verbose = 1)\nbdt_gs.fit(X_train, y_train) # 拟合模型\nbdt_gs = bdt_gs.best_estimator_ # 最佳模型\ny_pred = bdt.predict(X_test) # 进行预测\nprint(\"决策树Bagging测试准确率: {:.2f}%\".format(bdt_gs.score(X_test, y_test)*100)) \nprint(\"决策树Bagging测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:05:14.580337Z","iopub.execute_input":"2021-08-04T14:05:14.580724Z","iopub.status.idle":"2021-08-04T14:05:21.856827Z","shell.execute_reply.started":"2021-08-04T14:05:14.580693Z","shell.execute_reply":"2021-08-04T14:05:21.855887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier # 导入随机森林分类器\nrf = RandomForestClassifier() # 随机森林模型\n# 使用网格搜索优化参数\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n#               \"min_samples_split\": [2, 3, 10],\n#               \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [True,False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\nrf_gs = GridSearchCV(rf,param_grid = rf_param_grid, \n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\nrf_gs.fit(X_train,y_train) # 拟合模型\nrf_gs = rf_gs.best_estimator_ # 最佳模型\ny_pred = rf_gs.predict(X_test) # 进行预测\nprint(\"随机森林测试准确率: {:.2f}%\".format(rf_gs.score(X_test, y_test)*100))\nprint(\"随机森林测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:05:51.326445Z","iopub.execute_input":"2021-08-04T14:05:51.327184Z","iopub.status.idle":"2021-08-04T14:06:01.416567Z","shell.execute_reply.started":"2021-08-04T14:05:51.327143Z","shell.execute_reply":"2021-08-04T14:06:01.415433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier # 导入AdaBoost模型\ndt = DecisionTreeClassifier() # 选择决策树分类器作为AdaBoost的基准算法\nada = AdaBoostClassifier(dt) # AdaBoost模型\n# 使用网格搜索优化参数\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n                  \"base_estimator__splitter\" :   [\"best\", \"random\"],\n                  \"base_estimator__random_state\" :   [7,9,10,12,15],\n                  \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n                  \"n_estimators\" :[1,2,5,10],\n                  \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\nada_gs = GridSearchCV(ada,param_grid = ada_param_grid, \n                        scoring=\"f1\", n_jobs= 10, verbose = 1)\nada_gs.fit(X_train,y_train) # 拟合模型\nada_gs = ada_gs.best_estimator_ # 最佳模型\ny_pred = ada_gs.predict(X_test) # 进行预测\nprint(\"Adaboost测试准确率: {:.2f}%\".format(ada_gs.score(X_test, y_test)*100))\nprint(\"Adaboost测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:06:20.066239Z","iopub.execute_input":"2021-08-04T14:06:20.066736Z","iopub.status.idle":"2021-08-04T14:06:32.730924Z","shell.execute_reply.started":"2021-08-04T14:06:20.066699Z","shell.execute_reply":"2021-08-04T14:06:32.729673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier # 导入GBDT分类器\ngb = GradientBoostingClassifier() # GBDT分类器\n# 使用网格搜索优化参数\ngb_param_grid = {'loss' : [\"deviance\"],\n                 'n_estimators' : [100,200,300],\n                 'learning_rate': [0.1, 0.05, 0.01],\n                 'max_depth': [4, 8],\n                 'min_samples_leaf': [100,150],\n                 'max_features': [0.3, 0.1]}\ngb_gs = GridSearchCV(gb,param_grid = gb_param_grid,\n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\ngb_gs.fit(X_train,y_train) # 拟合模型\ngb_gs = gb_gs.best_estimator_ # 最佳模型\ny_pred = gb_gs.predict(X_test) # 进行预测\nprint(\"GBDT测试准确率: {:.2f}%\".format(gb_gs.score(X_test, y_test)*100))\nprint(\"GBDT测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:06:41.790341Z","iopub.execute_input":"2021-08-04T14:06:41.790889Z","iopub.status.idle":"2021-08-04T14:06:53.928757Z","shell.execute_reply.started":"2021-08-04T14:06:41.790854Z","shell.execute_reply":"2021-08-04T14:06:53.927602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier # 导入XGB分类器\nxgb = XGBClassifier() # XGB分类器\n# 使用网格搜索优化参数\nxgb_param_grid = {'min_child_weight': [1, 5, 10],\n                  'gamma': [0.5, 1, 1.5, 2, 5],\n                  'subsample': [0.6, 0.8, 1.0],\n                  'colsample_bytree': [0.6, 0.8, 1.0],\n                  'max_depth': [3, 4, 5]}\nxgb_gs = GridSearchCV(xgb,param_grid = xgb_param_grid,  \n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\nxgb_gs.fit(X_train,y_train) # 拟合模型\nxgb_gs = xgb_gs.best_estimator_ # 最佳模型\ny_pred = xgb_gs.predict(X_test) # 进行预测\nprint(\"XGB测试准确率: {:.2f}%\".format(xgb_gs.score(X_test, y_test)*100))\nprint(\"XGB测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:07:39.776918Z","iopub.execute_input":"2021-08-04T14:07:39.777289Z","iopub.status.idle":"2021-08-04T14:23:41.37786Z","shell.execute_reply.started":"2021-08-04T14:07:39.77726Z","shell.execute_reply":"2021-08-04T14:23:41.375446Z"},"trusted":true},"execution_count":null,"outputs":[]}]}