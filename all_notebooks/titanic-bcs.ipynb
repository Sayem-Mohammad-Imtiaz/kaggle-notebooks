{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the train and test Data\ntest=pd.read_csv('../input/titanic/test.csv')\ntrain=pd.read_csv('/kaggle/input/titanic/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print top 5 rows\nprint('Top 5 Rows')\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print top 5 row of test data\nprint('Top 5 Rows')\ntest.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data set size\nprint(\"Train Data Set Size:\",train.shape)\nprint(\"Total no of data points in Train Data:\",train.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print Test dataset size\nprint(\"Test Data Set Size:\",test.shape)\nprint(\"Total no of data points in Test Data:\",test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_Survived_Distribution=train[\"Survived\"].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_Survived_Distribution.plot(kind='bar')\nplt.xlabel('Class')\nplt.ylabel('Data points per Class')\nplt.title('Distribution of yi in train data')\nplt.grid()\nplt.show()\nsorted_yi = np.argsort(-Train_Survived_Distribution.values)\nprint(sorted_yi )\nprint(Train_Survived_Distribution.values )\nfor i in sorted_yi:\n    print('Number of data points in class', i, ':',Train_Survived_Distribution.values[i], '(', np.round((Train_Survived_Distribution.values[i]/train.shape[0]*100), 3), '%)')\nprint('Observation:','Dataset is imbalanced Data')   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--'*10,\"Verify null values in Train Data set\",'--'*10) \nprint(train.isnull().sum())\nprint('--'*40)\nprint(' '*40)\nprint('--'*40)\nprint('--'*10,\"Verify null values in Test Data set\",'--'*10) \nprint(test.isnull().sum())\nprint('--'*40)\nprint('Observation:','Age, Cabin and Embarked features are  having Null values in Train Data')\nprint('Observation:','Age, Cabin and Fari features are  having Null values in Test Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_clean(data):\n    Total =data.isnull().sum().sort_values()\n    Percent=((data.isnull().sum()/(data.isnull().count())*100)).sort_values().round(2)\n    d1=pd.concat([Total,Percent],axis=1,keys=['Total','Percent'])\n    d1=d1[d1['Percent']>0]\n    fig=plt.subplots(figsize=(8,5))\n    fig=sns.barplot(d1.index,d1.Percent)\n    plt.ylabel(\"Percentage of  Missing values \",fontsize=15)\n    plt.xlabel(\"Features\",fontsize=15)\n    plt.title(\"Percentage Of Missing values in  Data\",fontsize=15)\n    return d1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clean(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clean(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cabin feature has more than 77% of   missing values in both Train and Test Dataset. So I can Remove the cabin feature "},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the Cabin variable in both datasets\ntrain.drop(['Cabin'],axis=1,inplace=True)\ntest.drop([\"Cabin\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will remove the PassengerId ,Name and Ticket, since i will be useless for our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"PassengerId\",\"Name\",\"Ticket\"],axis=1,inplace=True)\ntest.drop([\"PassengerId\",\"Name\",\"Ticket\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age feature has more than 17% missing values in both train and test data, so i have filling age fature with median"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'].fillna(train['Age'].mean(),inplace=True)\ntest['Age'].fillna(train['Age'].mean(),inplace=True)\ntest['Fare'].fillna(test['Fare'].mean(),inplace=True)\ntrain['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--'*10,\"Verify null values in Train Data set\",'--'*10) \nprint(train.isnull().sum())\nprint('--'*40)\nprint('--'*40)\nprint('--'*10,\"Verify null values in Test Data set\",'--'*10) \nprint(test.isnull().sum())\nprint('--'*40)\nprint('Observation:','No Null values in Train Data')\nprint('Observation:','No Null values in Test Data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering and EDA"},{"metadata":{},"cell_type":"markdown","source":"1. Sex Feature\n\nSex,What type of feature,it is?\n\nAns: Sex is Categorical variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_sex = train['Sex'].value_counts()\nprint(\"There are\", unique_sex.shape[0] ,\"different categories of sex feature in the train data\",)\nprint(unique_sex)\nsns.countplot(x='Sex',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_sex = test['Sex'].value_counts()\nprint(\"There are\", unique_sex.shape[0] ,\"different categories of sex feature in the test data\",)\nprint(unique_sex)\nsns.countplot(x='Sex',data=test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. How to featurize this Sex feature?\n\nAns:Using Get_dummies(), we can Featurize this variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.get_dummies(train,columns=['Sex'],prefix=['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.get_dummies(test, columns = [\"Sex\"],prefix=[\"Sex\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_embarked = test['Embarked'].value_counts()\nprint(\"There are\", unique_embarked.shape[0] ,\"different categories of Embarked feature in the test data\",)\nprint(unique_embarked)\nsns.countplot(x='Embarked',data=test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Embarked Feature\n\nEmbarked,What type of feature,it is?\n\nAns: Embarked is Categorical variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_embarked = train['Embarked'].value_counts()\nprint(\"There are\", unique_embarked.shape[0] ,\"different categories of Embarked feature in the train data\",)\nprint(unique_embarked)\nsns.countplot(x='Embarked',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.1 How to featurize this Embarked feature?\n\nAns:Using Get_dummies(), we can Featurize this variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.get_dummies(train,columns=['Embarked'],prefix=['Embarked'])\ntest=pd.get_dummies(test,columns=['Embarked'],prefix=['Embarked'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Age Feature \n\n   Age,What type of feature it is?\n   \n   ans: Age is  Continuous fature.\n   \nFor improve the accuracy purpose, Age variable values are divied into bins using cut method\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Age'].max())\nprint(train['Age'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test['Age'].max())\nprint(test['Age'].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.1 How to featurize this Embarked feature?\n\nAns:Using Get_dummies(), we can Featurize this variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age']=pd.cut(train['Age'],bins=[0,12,20,40,100],labels=['Childen','Teenage','Adilt','Elder'])\ntest['Age']=pd.cut(test['Age'],bins=[0,12,20,40,100],labels=['Children','Teenage','Adult','Elder'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_age=train.Age.value_counts()\nprint(\"There are\", unique_age.shape[0] ,\"different categories of age feature in the train data\")\nprint(unique_age)\nsns.countplot(x='Age',data=train)\nplt.title('Bins of Age feature in Train data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_age=test.Age.value_counts()\nprint(\"There are\", unique_age.shape[0] ,\"different categories of age feature in the test data\")\nprint(unique_age)\nsns.countplot(x='Age',data=test)\nplt.title('Bin of Age feature in Test data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.get_dummies(train,columns=['Age'],prefix=['Age'])\ntest=pd.get_dummies(test,columns=['Age'],prefix=['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Fare Feature \n\n   Fare,What type of feature it is?\n   \n   ans: Fare is  Continuous fature.\n   \nFor improve the accuracy purpose, Age variable values is divied into bins using cut method"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Fare'].min())\nprint(train['Fare'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test['Fare'].min())\nprint(test['Fare'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.1 How to featurize this Embarked feature?\n\nAns:Using Get_dummies(), we can Featurize this variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Fare']=pd.cut(train['Fare'],bins=[0,14.45,31,60,513],labels=['Low Fare','median Fare','Average Fare','high Fare'])\ntest['Fare']=  pd.cut(test['Fare'],bins=[0,14.45,31,60,513],labels=['Low Fare','median Fare','Average Fare','high Fare'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_fare=train.Fare.value_counts()\nprint(\"There are\", unique_fare.shape[0] ,\"different categories of Fare feature in the train data\")\nprint(unique_fare)\nsns.countplot(x='Fare',data=train)\nplt.title('Bin of Fare feature in Train data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_Fare=test.Fare.value_counts()\nprint(\"There are\", unique_Fare.shape[0] ,\"different categories of Fare feature in the test data\")\nprint(unique_age)\nsns.countplot(x='Fare',data=test)\nplt.title('Bin of Fare feature in Test data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.get_dummies(train,columns=['Fare'],prefix=['Fare'])\ntest=pd.get_dummies(test,columns=['Fare'],prefix=['Fare'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=train\nprint(\"Train Data Set Size:\",data.shape)\nprint(\"Total no of data points in Train Data:\",data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"features:\",data.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=data[\"Survived\"]\nX=data.drop(\"Survived\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom mlxtend.classifier import StackingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n#from sklearn.grid_search import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spliting  Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LogisticRegression()\nlr.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"turned_parameters=[{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrgscv=GridSearchCV(lr,turned_parameters,cv=10,scoring = 'accuracy')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrgscv.fit(X_train,Y_train)\npredict_val1=lrgscv.predict(X_test)\npredict_val=lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_score=cross_val_score(lr,X,Y,cv=10,scoring='accuracy')\npredictlr=cross_val_predict(lr,X,Y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('--------------The Accuracy of the model----------------------------')\nprint(\"Accuracy of Logistic Regression is :\",round(accuracy_score(Y_test,predict_val)*100,2),'%')\nprint(\"Cross validation score for Logistic Regression Accuracy is:\",round(lr_score.mean()*100,2),'%')\nprint(\"Grid Search CV score for Logistic Regression Accuracy is:\",round(accuracy_score(Y_test,predict_val1)*100,2),'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(Y,predictlr),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lrgscv.best_estimator_)\n#print(lrgscv.score(X,Y))\nprint(lrgscv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn=KNeighborsClassifier()\nknn.fit(X_train,Y_train)\nknnpredict=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_score=cross_val_score(knn,X,Y,cv=10,scoring='accuracy')\npredictknn=cross_val_predict(knn,X,Y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid={'n_neighbors':[3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51],'p':[1,2],\n           'weights': ['uniform', 'distance']}\nmodel = GridSearchCV(knn, param_grid, scoring = 'accuracy', cv=10)\nmodel.fit(X_train, Y_train)\nknngrcv=model.predict(X_test)\nprint(model.best_estimator_)\nprint(model.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--------------The Accuracy of the model----------------------------')\nprint(\"Accuracy of KNN is :\",round(accuracy_score(Y_test,knnpredict)*100,2),'%')\nprint(\"Cross validation score for KNN Accuracy is:\",round(knn_score.mean()*100,2),'%')\nprint(\"Grid Search CV score for KNN Accuracy is:\",round(accuracy_score(Y_test,knngrcv)*100,2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(Y,predictknn),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" SVM "},{"metadata":{"trusted":true},"cell_type":"code","source":"svc=SVC()\nsvcclf=svc.fit(X_train,Y_train)\nsvcpredict=svcclf.predict(X_test)\nsvcpredict1=svcclf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_score=cross_val_score(svc,X,Y,cv=10,scoring='accuracy')\npredictsvc=cross_val_predict(svc,X,Y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"turn_perameters={'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid','linear']}\nsvmclf=GridSearchCV(SVC(),turn_perameters,cv=10)\nsvmclf.fit(X_train,Y_train)\nsvmpredict=svmclf.predict(X_test)\nprint(svmclf.best_estimator_)\nprint(svmclf.best_score_)\nprint(svmclf.score(X_test, Y_test))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(Y,predictsvc),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb=GaussianNB()\nnb.fit(X_train,Y_train)\nnbclf=nb.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_score=cross_val_score(nb,X,Y,scoring='accuracy',cv=10)\npredictnb=cross_val_predict(nb,X,Y,cv=10)\n#print(nb.best_score_)\n#print(nb.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--------------------The Accuracy of the model--------------------------')\nprint(\"Accuracy of Naive Bayes is :\",round(accuracy_score(Y_test,nbclf)*100,2),'%')\nprint(\"Cross validation score for Naive Bayes is:\",round(nb_score.mean()*100,2),'%')\n#print(\"Best Cross validation score for SVM Accuracy is:\",round((nb.best_score_)*100,2),'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(Y,predictnb),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=DecisionTreeClassifier()\ndt.fit(X_train,Y_train)\ndtpredict=dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_score=cross_val_score(dt,X,Y,cv=10,scoring='accuracy')\npredictdt=cross_val_predict(dt,X,Y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--------------------The Accuracy of the model--------------------------')\nprint(\"Accuracy of Decision Tree is :\",round(accuracy_score(Y_test,dtpredict)*100,2),'%')\nprint(\"Cross validation score for Decision Tree is:\",round(dt_score.mean()*100,2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix(Y,predictdt),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfclf=RandomForestClassifier()\nrfclf.fit(X_train,Y_train)\nrfpredict=rfclf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_score=cross_val_score(rfclf,X,Y,cv=10,scoring='accuracy')\npredictdt=cross_val_predict(rfclf,X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,predictdt),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--------------------The Accuracy of the model--------------------------')\nprint(\"Accuracy of Random Forest  is :\",round(accuracy_score(Y_test,rfpredict)*100,2),'%')\nprint(\"Cross validation score for Random Forest is:\",round(rf_score.mean()*100,2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb=XGBClassifier()\nxgb.fit(X_train,Y_train)\nxgbpridect=xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_score=cross_val_score(xgb,X,Y,cv=10,scoring='accuracy')\npredictxgb=cross_val_predict(xgb,X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,predictxgb),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--------------------The Accuracy of the model--------------------------')\nprint(\"Accuracy of XGBoosting is :\",round(accuracy_score(Y_test,xgbpridect)*100,2),'%')\nprint(\"Cross validation score for XGBoosting is:\",round(xgb_score.mean()*100,2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Adaboosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"adbclf=AdaBoostClassifier()\nadbclf.fit(X_train,Y_train)\nadbpredict=adbclf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adb_score=cross_val_score(adbclf,X,Y,cv=10,scoring='accuracy')\npredictadbclf=cross_val_predict(adbclf,X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,predictadbclf),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--------------------The Accuracy of the model--------------------------')\nprint(\"Accuracy of Adaboosting is :\",round(accuracy_score(Y_test,adbpredict)*100,2),'%')\nprint(\"Cross validation score for Adaboosting  is:\",round(adb_score.mean()*100,2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbclf=GradientBoostingClassifier()\ngbclf.fit(X_train,Y_train)\ngbclfpredict=gbclf.predict(X_test)\ngbclfpredict1=gbclf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_score=cross_val_score(gbclf,X,Y,cv=10,scoring='accuracy')\npredictadbclf=cross_val_predict(gbclf,X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,predictadbclf),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--------------------The Accuracy of the model--------------------------')\nprint(\"Accuracy of Gradient Boosting is :\",round(accuracy_score(Y_test,gbclfpredict)*100,2),'%')\nprint(\"Cross validation score for Gradient Boosting is:\",round(gb_score.mean()*100,2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sclf=StackingClassifier(classifiers=[knn,rfclf,nb,svc,dt,xgb,adbclf,gbclf],meta_classifier=lr)\nfor clf, label in zip([knn,rfclf,nb,svc,dt,xgb,adbclf,gbclf,sclf],\n                      ['KNN',\n                       'Random Forest',\n                       'Naive Bayes',\n                       'SVM',\n                       'Decision Tree',\n                       'XGBoost',\n                       'Adaboosting',\n                       'GradientBoosting',\n                       'StackingClassifier']):\n    scores=cross_val_score(clf,X,Y,cv=10,scoring='accuracy')\n    print(\"Accuracy:%0.2f  [%s]\" %(scores.mean(),label))\n    \"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"StackingClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"sclf=StackingClassifier(classifiers=[knn,rfclf,nb,svc,dt,xgb,adbclf,gbclf],meta_classifier=lr)\nsclf.fit(X_train,Y_train)\nsclfpredict=sclf.predict(X_test)\nstck_score=cross_val_score(sclf,X,Y,cv=10,scoring='accuracy')\npredictadbclf=cross_val_predict(sclf,X,Y,cv=10)\nprint('--------------------The Accuracy of the model--------------------------')\nprint(\"Accuracy of Stacking is :\",round(accuracy_score(Y_test,sclfpredict)*100,2),'%')\nprint(\"Cross validation score for Stacking is:\",round(stck_score.mean()*100,2),'%')\n\nsns.heatmap(confusion_matrix(Y,predictadbclf),annot=True,fmt='3.0F')\nplt.title(\"Confusion Matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'AdaBoostClassifier', \n              'Gradient Decent', 'XGBoosting', \n              'Decision Tree','Stacking Classifier'],\n    'Score': [svc_score.mean(), knn_score.mean(), lr_score.mean(), \n              rf_score.mean(), nb_score.mean(), adb_score.mean(), \n              gb_score.mean(), xgb_score.mean(), dt_score.mean(),stck_score.mean()]})\nmodels.sort_values(by='Score',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'AdaBoostClassifier', \n              'Gradient Decent', 'XGBoosting', \n              'Decision Tree','Stacking Classifier'],\n    'Accuracy': [accuracy_score(Y_test,svcpredict), accuracy_score(Y_test,knnpredict),accuracy_score(Y_test,predict_val), \n              accuracy_score(Y_test,rfpredict), accuracy_score(Y_test,nbclf), accuracy_score(Y_test,adbpredict), \n              accuracy_score(Y_test,gbclfpredict), accuracy_score(Y_test,xgbpridect),accuracy_score(Y_test,dtpredict),accuracy_score(Y_test,sclfpredict)]})\nmodels.sort_values(by='Accuracy',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=pd.DataFrame(gbclfpredict1)\nsubmsdf=pd.read_csv('../input/titanic/gender_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submsdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pred.shape)\nprint(submsdf.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets=pd.concat([submsdf['PassengerId'],pred],axis=1)\ndatasets.columns=['PassengerId','Survived']\ndatasets.to_csv('resultdf3.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#d=pd.read_csv('C://Users//user//Desktop//resultdf3.csv')\n#print(d.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}