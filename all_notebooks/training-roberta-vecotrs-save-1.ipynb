{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (AutoModel,AutoConfig,\n                          AutoTokenizer,get_cosine_schedule_with_warmup)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:37:45.028245Z","iopub.execute_input":"2021-07-31T06:37:45.028612Z","iopub.status.idle":"2021-07-31T06:37:45.038235Z","shell.execute_reply.started":"2021-07-31T06:37:45.028583Z","shell.execute_reply":"2021-07-31T06:37:45.03719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROBERTA_PATH= 'roberta-base'\nclass LitModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7})\n        \n        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n        \n        \n        self.regressor = nn.Sequential(                       \n            nn.Linear(768*2, 2530)                        \n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)        \n        last_layer_hidden_states = roberta_output.hidden_states[-1]\n        \n        mean_pooling_embeddings = torch.mean(last_layer_hidden_states, 1)\n        max_pooling_embeddings,_ = torch.max(last_layer_hidden_states, 1)\n        mean_max_embeddings = torch.cat((mean_pooling_embeddings, max_pooling_embeddings), 1)\n        return mean_max_embeddings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-31T06:37:45.040188Z","iopub.execute_input":"2021-07-31T06:37:45.040865Z","iopub.status.idle":"2021-07-31T06:37:45.051443Z","shell.execute_reply.started":"2021-07-31T06:37:45.040828Z","shell.execute_reply":"2021-07-31T06:37:45.050259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LitModel()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T06:37:45.053608Z","iopub.execute_input":"2021-07-31T06:37:45.054253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state_dict = torch.load('../input/amzonchaleenge/title_weights/modellast.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(state_dict['model'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TOKENIZER = tokenizer = AutoTokenizer.from_pretrained('roberta-base')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess1(text):\n  text = text.split()\n  text = ' '.join(text)\n  text = text.strip()\n  return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer = TOKENIZER,max_len=150):\n        self.excerpt = df['TITLE'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        \n        encode1 = self.tokenizer(preprocess1(self.excerpt[idx]),\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                return_attention_mask=True,\n                                truncation=True)\n\n        \n        return encode1\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdf = pd.read_csv('../input/amzonchaleenge/raw_data/train.csv',escapechar='\\\\',quoting = csv.QUOTE_NONE,usecols = ['TITLE'])\ntestdf.dropna(inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = 100000\nend = 200000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdataset = CLRPDataset(testdf[start:end])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dl = DataLoader(testdataset,\n                      batch_size = 16,\n                       shuffle=False,\n                        num_workers = 4,\n                        pin_memory=True,\n                        drop_last=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_loop(valid_loader,model,device = DEVICE):\n        predictions = None\n        model.to(device)\n        model.eval()\n        for i,(inputs1) in tqdm(enumerate(valid_loader),total=len(valid_loader)):\n            with torch.no_grad():\n                inputs1 = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs1.items()}\n                outputs1 = model(**inputs1).detach().cpu().numpy()\n                if i == 0:\n                    predictions = outputs1\n                else:\n                    predictions = np.vstack((predictions,outputs1))\n        return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = valid_loop(valid_dl,model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(f'predictions_{start}_{end}.npy',predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}