{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom imblearn.over_sampling import ADASYN\n\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.model_selection import cross_val_predict,cross_validate\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import make_scorer\n\nfrom sklearn.pipeline import make_pipeline\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input raw data\ntelcom=pd.read_csv(\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking missing data\ntelcom['TotalCharges']=telcom['TotalCharges'].convert_objects(convert_numeric=True)\ntelcom[\"TotalCharges\"].dtypes\n#drop missing data\ntelcom.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find features and the values of target variable\nfeature_names=telcom.iloc[:,1:].columns\n#select values of target variable - 2-class categorical data\nlabels=telcom.iloc[:,20]\n\n#encoding target variable\nle=LabelEncoder()\nle.fit(labels)\nlabels=le.transform(labels)\nclass_names=le.classes_\ntelcom=telcom.iloc[:,1:-1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check independent features which data value in categorical type\nobj_features=telcom.select_dtypes(['object']).columns\ncategorical_features=[telcom.columns.get_loc(c) for c in obj_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoding categorical data of those features\ncategorical_names = {}\nfor feature in categorical_features:\n    le = LabelEncoder()\n    le.fit(telcom.iloc[:, feature])\n    telcom.iloc[:, feature] = le.transform(telcom.iloc[:, feature])\n    categorical_names[feature] = le.classes_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering : One-Hot-Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#one-hot-encoding on categorical_features\nencoder = OneHotEncoder(categorical_features=categorical_features)\nencoder.fit(telcom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set all data type to float\ntelcom=telcom.astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stratified CV - Spliting Traning/Testing sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=telcom\ny=labels\n\n#Split train/test sets of X and y\nnp.random.seed(1)\nsss=StratifiedShuffleSplit(n_splits=5, test_size=0.2,random_state=0)\nsss.get_n_splits(X,y)\n\n#Training/Testing sets in 5 folds\nfor train_index, test_index in sss.split(X, y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Oversampling training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ada= ADASYN()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model training & Performance evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_scores = []\nprecision_scores = []\nrecall_scores = []\nf1_scores = []\n\nfor train_index, test_index in sss.split(X, y):\n    X_train,X_test=X.iloc[train_index], X.iloc[test_index]\n    y_train,y_test=y[train_index], y[test_index]\n\n    ### One-hot-encoding training/testing data\n    encoded_train, encoded_test = encoder.transform(X_train), encoder.transform(X_test)\n    \n    ### Oversampling training sets\n    X_resample,y_resample=ada.fit_sample(encoded_train,y_train)\n    \n    ### Model training\n    lr=LogisticRegression()\n    lr.fit(X_resample, y_resample)\n    \n    ### Make Prediction\n    y_pred = lr.predict(encoded_test)\n    \n    ### Performance evaluation\n    accuracy_scores.append(accuracy_score(y_test, y_pred))\n    precision_scores.append(precision_score(y_test, y_pred))\n    recall_scores.append(recall_score(y_test, y_pred))\n    f1_scores.append(f1_score(y_test, y_pred))\n    \nprint(\"----------------- Performance Evaluation -----------------\")\nprint('Accuracy', np.mean(accuracy_scores))\nprint('Precision', np.mean(precision_scores))\nprint('Recall', np.mean(recall_scores))\nprint('F1-measure', np.mean(f1_scores)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_fn = lambda x: lr.predict_proba(encoder.transform(x)).astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LIME interpretability","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lime\nimport lime.lime_tabular\nfrom __future__ import print_function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#implement LIME interpretation\nexplainer = lime.lime_tabular.LimeTabularExplainer(\n    X_train.values,feature_names = feature_names,\n    class_names=class_names,categorical_features=categorical_features, \n    categorical_names=categorical_names, kernel_width=3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualise LIME interpretation\nnp.random.seed(1)\ni = int(np.random.randint(0,1407,size=1))\nexp = explainer.explain_instance(X_test.values[i], predict_fn, num_features=5)\nexp.show_in_notebook(show_all=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}