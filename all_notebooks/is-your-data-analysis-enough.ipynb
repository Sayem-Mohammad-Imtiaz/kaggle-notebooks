{"cells":[{"metadata":{},"cell_type":"markdown","source":"**There are a hell lot of things that one can do while analysing his or her data. Don't believe me? Just go through this notebook once and you will realise the extents to which one can go while analysing a data as short as 300 rows.**\n\n**Below is an analysis of a small data on Attrition of employees. It includes the following:**\n\n1. Data Preparation \n2. Exploratory data analysis\n3. Clustering to find patterns\n4. Frequent pattern mining\n5. Forecasting and Predictions"},{"metadata":{},"cell_type":"markdown","source":"# DATA PREPARATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data = pd.read_csv('../input/attritiondata/Attrition_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"location_clean = pd.read_csv('../input/attritiondata/location_clean.csv')\nlocation_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(main_data, location_clean, how= 'inner',left_on = 'S.No', right_on='id' )\ndata.drop('id',axis =1, inplace = True)\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert location_clean.shape[0] == data.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the columns into right datatypes and extracting data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.rename(columns = {'Engagement Score (% Satisfaction)':'sat_score'})\ndata['sat_score'] = data['sat_score'].apply(lambda x:x[:-1])\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sat_score'] = data['sat_score'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.where(data['Location'].isna())\n# data.loc[[48,111],:]\n# data.drop([48,111],axis = 0, inplace= True) #For now\n# data.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Use the below statement when modelling or when null values can create problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = data[data['doubtful']=='NO']\n# data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.where(data.isna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data.iloc[[  2,  23,  63, 193],:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The 4 admin locations have to be handled for districts"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Last Rating'] = data['Last Rating'].apply(lambda x: str(x))\n# data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_float(x):\n    try:\n        return float(x)\n    except ValueError as v:\n        return float(x.replace(' ',''))\ndata['Tenure'] = data['Tenure'].apply(to_float)\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\ndef converter(x):\n    try:\n        return datetime.strptime(x, '%d-%b-%y')\n    except:\n        return datetime.strptime(x, '%d-%m-%y')  # for these values in DOJ column '''05-07-10,02-09-10,01-08-11,12-03-04,05-07-10,,01-06-11,09-08-07,05-05-08,12-10-09,07-02-11'''\n\ndata['DOL_date'] = data['In Active Date'].apply(converter)\ndata['DOJ_date'] = data['DOJ'].apply(converter)\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['DOJ','In Active Date'], axis = 1, inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def safe_strip(x):\n    try:\n        return x.strip()\n    except AttributeError as e:\n#         print(x)\n        return x\n    \nfor col in data.columns:\n    if data[col].dtype == 'object':\n        data[col] = data[col].apply(safe_strip) ## Some values in the Designation column had extra spaces ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Designation')['Grade'].apply(lambda x: x.unique())\n### OR data[['Designation','Grade']].drop_duplicates().sort_values('Grade')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 1:1 relation between designation and grade. SO one can be dropped. Dropping Designation as it is easy to find order in Grade"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Zone'] = data['Zone'].apply(lambda x: x.lower()) ## CENTRAL and central, north and North, south and South pairs were present\ndata['Zone'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data['Marital Status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data['Education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Check \n1. S.No\n2. EmpID - To be dropped. Useless\n3. Emp Name - To be dropped. Useless*\n4. Designation - Stripped Extra space and then dropped - Has 1 to 1 with 'Grade'\n5. Grade - Has 1 to 1 with 'Designation'\n6. Attrition - To be dropped. Useless\n7. *Location ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ TO BE WORKED UPON*\n8. Tenure - Converted datatype. Fixed some values having space in between\n9. Gender \n10. Education\n11. Age\n12. Last Rating - changed dtype to object\n13. Monthly Income\n14. sat_score - Removed % sign and converted to int\n15. Marital Status\n16. Zone - Lower cased values\n17. Remarks \n18. In Active Date- dropped. Instead created DOL_date having datetime datatype\n19. DOJ - dropped . Instead created DOJ_date having datetime datatype."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Dropping EmpID, Emp Name as they are redundant in the presence of a S.No. \n\n> Attrition is always \"YES\"\n\n> Designation is redundant in presence of grade"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['EmpID','Emp Name','Attrition ','Designation'],axis =1 , inplace =True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['tenure_days'] = (data['DOL_date'] - data['DOJ_date']).apply(lambda x:x.days)\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.rename(columns = {'S.No':'id', 'Last Rating':'rating','Monthly Income':'income','Marital Status': 'marital_status'})\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = [col.lower() for col in data.columns]\n# data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['doubtful','location','changed'] ,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Use `corrected_location` instead of `location`\n\n> No need of `changed` as `location` column has been dropped\n\n> Leave `doubtful` in the dataset "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.to_csv('data_complete_location.csv', index= False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS"},{"metadata":{},"cell_type":"markdown","source":"### Univariate visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_col = [col for col in data.columns if data[col].dtype in ['int64','int32','float64'] and col not in ['id','tenure']]\nnumeric_col","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data[numeric_col].hist(figsize=(16, 8));","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"_, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 8))\ni = 0\nj = 0\nfor col in numeric_col:\n    _=sns.distplot(data[col], ax=axes[i][j]);\n    _=plt.xticks(rotation=90)\n    j+=1\n    if j==2:\n        i+=1\n        j=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 8))\ni = 0\nj = 0\nfor col in numeric_col:\n    _=sns.boxplot(data[col], ax=axes[i][j]);\n    _=plt.xticks(rotation=90)\n    j+=1\n    if j==2:\n        i+=1\n        j=0","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cat_cols = [col for col in data.columns if data[col].dtype == 'object']\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n_, axes = plt.subplots(nrows=5, ncols=2,sharey=True, figsize=(16, 24))\n# plt.subplot_tool() ## Works for interactive\nplt.subplots_adjust(hspace=0.8)\ni = 0\nj = 0\nfor col in cat_cols:\n    if col == 'location': continue\n    g=sns.countplot(x=col, data=data, ax=axes[i][j], order = list(data[col].value_counts().reset_index()['index']));\n    if col in  ['remarks','corrected_location','district','state']:\n        _=g.set_xticklabels(g.get_xticklabels(), rotation=90)\n#     _ = plt.xticks(rotation=90)\n    j+=1\n    if j==2:\n        i+=1\n        j=0\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multivariate visualization"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"corr_matrix = data[numeric_col].corr()\nsns.heatmap(corr_matrix, annot = True);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# `pairplot()` may become very slow with the SVG or retina format\n%config InlineBackend.figure_format = 'png'\nsns.pairplot(data[numeric_col]);\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_col","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, axes = plt.subplots(nrows=5, ncols=2,sharey=True, figsize=(16, 30))\nplt.subplots_adjust(hspace=0.8)\n\ni = 0\nj = 0\nfor col in cat_cols:\n    if col == 'location': continue\n    g=sns.boxplot(x=col,y='tenure_days', data=data, ax=axes[i][j]);\n    if col in  ['remarks','corrected_location','district','state']:\n        _=g.set_xticklabels(g.get_xticklabels(), rotation=90)\n#     _ = plt.xticks(rotation=90)\n    j+=1\n    if j==2:\n        i+=1\n        j=0\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# _, axes = plt.subplots(2, 4, sharey=True, figsize=(12, 8))\nplt.figure(figsize= (8,6))\nsns.boxplot(x='grade', y='income', data=data[data['income']<1e5], order = sorted(data['grade'].unique()));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CLUSTERING"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reset -f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline \nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/attritiondata/data_complete_location.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n# Filter data\nleft_emp =  data[['sat_score', 'rating']]\n# Create groups using K-means clustering.\n\nss= StandardScaler()\nleft_emp_scaled = ss.fit_transform(left_emp)\nleft_emp_scaled.shape\nkmeans = KMeans(n_clusters = 4, random_state = 10).fit(left_emp_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_emp['label'] = kmeans.labels_\n# Draw scatter plot\n_ = plt.scatter(left_emp['sat_score'], left_emp['rating'], c=left_emp['label'],cmap='Accent')\n_ = plt.xlabel('Satisfaction Level')\n_ = plt.ylabel('Last Evaluation')\n_ = plt.title('4 Clusters of employees who left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_emp =  data[['tenure', 'income']]\nleft_emp = left_emp[left_emp['income']<1e5]\n# Create groups using K-means clustering.\n\nss= StandardScaler()\nleft_emp_scaled = ss.fit_transform(left_emp)\nleft_emp_scaled.shape\nkmeans = KMeans(n_clusters =4 , random_state = 10).fit(left_emp_scaled)\n\nleft_emp['label'] = kmeans.labels_\n# Draw scatter plot\n_ = plt.scatter(left_emp['tenure'], left_emp['income'], c=left_emp['label'],cmap='Accent')\n_ = plt.xlabel('Tenure')\n_ = plt.ylabel('Income')\n_ = plt.title('4 Clusters of employees who left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_emp =  data[['age', 'income']]\nleft_emp = left_emp[left_emp['income']<1e5]\n# Create groups using K-means clustering.\n\nss= StandardScaler()\nleft_emp_scaled = ss.fit_transform(left_emp)\nleft_emp_scaled.shape\nkmeans = KMeans(n_clusters =6 , random_state = 10).fit(left_emp_scaled)\n\nleft_emp['label'] = kmeans.labels_\n# Draw scatter plot\n_=plt.scatter(left_emp['age'], left_emp['income'], c=left_emp['label'],cmap='Accent')\n_=plt.xlabel('Age')\n_=plt.ylabel('Income')\n_=plt.title('6 Clusters of employees who left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FREQUENT PATTERN MINING"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reset -f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline \nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/attritiondata/data_complete_location.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grade_int = {'E1':1,'E2':2,'M1':3,'M2':4,'M3':5,'M4':6,'CXO':7}\ndata['grade_int'] = data['grade'].apply(lambda x: grade_int[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_required =  ['grade','dol_date','doj_date','id','corrected_location','district']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_cats = [ col for col in data.columns if data[col].dtype=='object' and col not in not_required]\nselected_cats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_nums = [col for col in data.columns if col not in selected_cats+not_required]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"selected_nums","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Frequent Item Sets"},{"metadata":{},"cell_type":"markdown","source":"Some points to be noted:\n\n1. Income is dependent on the grade of the employee.\n2. Age and income are positively correlated\n3. Due to the above two points, only grade is considered for the frequent item sets calculation\n4. Tenure and sat_score are binned so as to be used for frequent itemset calculation purpose."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.distplot(data['tenure'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.distplot(data['sat_score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sat_binner(x):\n    return x//20 + 1 if not x%20 == 0 else x//20\ndata['sat_binned'] = data['sat_score'].apply(sat_binner).astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tenure_binner(x):\n    return x//2 + 1 if not x%2 == 0 else x//2\ndata['tenure_binned'] = data['tenure'].apply(tenure_binner).astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_for_frequent_items = ['grade','gender','education','rating','marital_status','zone','remarks','tenure_binned','sat_binned']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_fp = data[cols_for_frequent_items]\n# data_fp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_fp_enc = pd.get_dummies(data_fp, columns = data_fp.columns)\ndata_fp_enc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth', 100)\n# pd.set_option('max_rows',200)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from mlxtend.frequent_patterns import apriori\n\nfreq_pattern = apriori(data_fp_enc, min_support=0.20, use_colnames=True)\nfreq_pattern['length'] = freq_pattern['itemsets'].apply(lambda x: len(x) )\nfreq_pattern[freq_pattern['length']>=4].sort_values('support',ascending= False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fp2 = data[(data['gender']== 'Male') & (data['grade']=='E1') & (data['education'] =='Bachelors') & (data['tenure']<=2) ]\nfp2.groupby('remarks').size().sort_values(ascending = False)\n# fp2.groupby('zone').size().sort_values(ascending = False)\n# fp2.groupby('rating').size().sort_values(ascending = False)\n# fp2.groupby('sat_binned').size().sort_values(ascending = False)\n# fp2.groupby('marital_status').size().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interesting FP \nfp1 = data[(data['gender']== 'Male') & (data['grade']=='E1') & (data['education'] =='Bachelors') & (data['remarks']=='Issues with the Manager') ]\n\n# Not so interesting other features\n# fp1.groupby('marital_status').size().sort_values(ascending = False)\n# fp1.groupby('zone').size().sort_values(ascending = False)\n# fp1.groupby('rating').size().sort_values(ascending = False)\n# fp1.groupby('sat_binned').size().sort_values(ascending = False)\n# fp1.groupby('tenure_binned').size().sort_values(ascending = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Not very interesting\n# fp3 = data[(data['gender']== 'Male') & (data['grade']=='E1') & (data['education'] =='Bachelors') & (data['remarks']=='Issues with the Manager') &  (data['tenure']<=2)]\n# fp3.groupby('zone').size().sort_values(ascending = False)\n# fp3.groupby('rating').size().sort_values(ascending = False)\n# fp3.groupby('sat_binned').size().sort_values(ascending = False)\n# fp3.groupby('marital_status').size().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TENURE PREDICTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reset -f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\n# from sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.dummy import DummyRegressor\n# from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sqrt\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/attritiondata/data_complete_location.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_used = data.drop(['corrected_location','district','state','doj_date','dol_date','tenure_days'], axis =1)\ndata_pred = data[['id','grade','tenure','gender','education','age','rating','income','sat_score','marital_status',\\\n                 'zone','remarks']]\n# data_pred.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_pred.drop(['id','tenure'], axis =1)\ny = data_pred['tenure']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_cats = [col for col in X.columns if X[col].dtype == 'object']\nselected_nums = [col for col in X.columns if col  not in selected_cats]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.get_dummies(X, columns = selected_cats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = int(0.9*data_pred.shape[0])\ntrain_indices = list(range(train_samples))\nval_indices = list(range(train_samples, data_pred.shape[0]))\ntrain_X = X.loc[train_indices, : ]\ntrain_y = y.loc[train_indices]\nval_X = X.loc[val_indices, : ]\nval_y = y.loc[val_indices]\n\ntrain_X.shape\ntrain_y.shape\nval_X.shape\nval_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss= StandardScaler()\ntrain_X_scaled = pd.DataFrame(ss.fit_transform(train_X), columns = train_X.columns)\ntrain_y_logged = np.log1p(train_y)\nval_X_scaled = pd.DataFrame(ss.transform(val_X), columns = val_X.columns)\n# val_y = np.log1p(val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(model):\n    if model == DecisionTreeRegressor:\n        reg = model(random_state = 291)\n    else:\n        reg = model()\n    reg.fit(train_X_scaled, train_y_logged)\n    val_y_hat = np.expm1(reg.predict(val_X_scaled))\n    print(f'MAE: {mean_absolute_error(val_y_hat, val_y)}')\n    print(f'RMSE: {sqrt(mean_squared_error(val_y_hat, val_y))}')\n#     return sqrt(mean_squared_error(val_y_hat, val_y))\n    fig, ax = plt.subplots(1,2, figsize=(16,4))\n    \n    ax[0].plot(list(range(len(val_y))), val_y_hat, label= 'Predicted Tenure (in yrs)')\n    ax[0].plot(list(range(len(val_y))), val_y, label = 'Original  Tenure (in yrs)')\n    ax[0].legend(loc = 'best')\n    ax[0].set_title('Predictions')\n    \n    print(f'Using model : {model}')\n    if model in [Lasso, Ridge, LinearRegression]:\n        coeff_df = pd.DataFrame(reg.coef_, train_X_scaled.columns, columns=['Coefficient'])  \n\n    elif model in [XGBRegressor,DecisionTreeRegressor]:\n        coeff_df = pd.DataFrame(reg.feature_importances_, train_X_scaled.columns, columns=['Coefficient'])  \n        \n    else:\n        print(\"No feature importance graph for DummyRegressor\")\n        return \n    \n    coeff_df[\"abs\"] = coeff_df.Coefficient.apply(np.abs)\n    coeff_df = coeff_df.sort_values(by=\"abs\", ascending=False).drop(\"abs\", axis=1)\n    \n    ax[1].bar(coeff_df.index[:15],coeff_df['Coefficient'][:15])\n    _ = plt.xticks(rotation=90)\n    ax[1].set_title('Feature importance')\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fit_model(DummyRegressor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model(LinearRegression)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fit_model(DecisionTreeRegressor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## To visualize the Decision Tree - But the tree is too big\n\n# dt =DecisionTreeRegressor()\n# dt.fit(train_X_scaled, train_y_logged)\n# from sklearn.tree import export_graphviz\n# export_graphviz(dt, out_file ='tree.dot', \n#                feature_names =train_X_scaled.columns)  ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fit_model(XGBRegressor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_ensemble(model1, model2):\n    if model1 == DecisionTreeRegressor:\n        m1  = model1(random_state=291)\n    else:\n        m1 = model1()\n    m1.fit(train_X_scaled, train_y_logged)\n    m2 = model2()\n    m2.fit(train_X_scaled, train_y_logged)\n    val_y_hat = (np.expm1(m1.predict(val_X_scaled)) + np.expm1(m2.predict(val_X_scaled)))/2.0\n    print(f'MAE: {mean_absolute_error(val_y_hat, val_y)}')\n    print(f'RMSE: {sqrt(mean_squared_error(val_y_hat, val_y))}')\n    \n    fig, ax = plt.subplots(1,1)\n    \n    ax.plot(list(range(len(val_y))), val_y_hat, label= 'Predicted Tenure (in yrs)')\n    ax.plot(list(range(len(val_y))), val_y, label = 'Original  Tenure (in yrs)')\n    ax.legend(loc = 'best')\n    ax.set_title('Predictions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ensemble(LinearRegression, XGBRegressor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ensemble(DecisionTreeRegressor, XGBRegressor)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FORECAST COUNT"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reset -f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sqrt\nfrom scipy.stats import mode\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/attritiondata/data_complete_location.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[['dol_date']].copy()\nX['Count'] = 1\n# X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_used = data.drop(['corrected_location','district','state','doj_date','dol_date','tenure_days'], axis =1)\nX['dol_date'] = pd.to_datetime(X[\"dol_date\"], format=\"%Y-%m-%d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.set_index('dol_date', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_comp =  X.Count.resample('D').sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_comp[\"date\"] = X_comp[\"dol_date\"].apply(lambda x: x.day)\nX_comp[\"month\"] = X_comp[\"dol_date\"].apply(lambda x: x.month)\nX_comp[\"quarter\"] = X_comp[\"dol_date\"].apply(lambda x: x.quarter)\nX_comp[\"year\"] = X_comp[\"dol_date\"].apply(lambda x: x.year)\nX_comp[\"weekday\"] = X_comp[\"dol_date\"].apply(lambda x: x.dayofweek)\nX_comp[\"dayofyear\"] = X_comp[\"dol_date\"].apply(lambda x: x.dayofyear)\nX_comp[\"weekofyear\"] = X_comp[\"dol_date\"].apply(lambda x: x.weekofyear)\n# X_comp.head()\n# X_comp[\"day_count\"] = X_comp[\"dol_date\"].apply(lambda x: x.toordinal())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_comp['fired'] = X_comp['Count'].apply(lambda x: 1 if x>=1 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = X_comp['fired']\nX_comp.drop(['fired','Count','dol_date'],axis = 1, inplace =True)\n# X_comp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = int(0.9*X_comp.shape[0])\ntrain_indices = list(range(train_samples))\nval_indices = list(range(train_samples, X_comp.shape[0]))\ntrain_X = X_comp.loc[train_indices, : ]\ntrain_y = y.loc[train_indices]\nval_X = X_comp.loc[val_indices, : ]\nval_y = y.loc[val_indices]\n\ntrain_X.shape\ntrain_y.shape\nval_X.shape\nval_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss= StandardScaler()\ntrain_X_scaled = pd.DataFrame(ss.fit_transform(train_X), columns = train_X.columns)\n# train_y_logged = np.log1p(train_y)\nval_X_scaled = pd.DataFrame(ss.transform(val_X), columns = val_X.columns)\n# val_y = np.log1p(val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(model):\n    if model == DecisionTreeClassifier:\n        reg = model(random_state = 1)\n       \n    elif model == DummyClassifier:\n        reg = model(strategy = 'constant' ,constant=1)\n\n    elif model == XGBClassifier:\n        reg = model()\n#         base_score=0.5, booster='gbtree', colsample_bylevel=1,\n#               colsample_bytree=0.6, gamma=0.25, learning_rate=0.4,\n#               max_delta_step=0, max_depth=10, min_child_weight=1, missing=None,\n#               n_estimators=100, n_jobs=1, nthread=None,\n#               objective='binary:logistic', random_state=0, reg_alpha=0,\n#               reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n#               subsample=1\n    else:\n        reg = model()\n    reg.fit(train_X_scaled, train_y) #Changed var name\n    val_y_hat = reg.predict(val_X_scaled)\n    \n#     return f1_score(val_y_hat, val_y)\n    \n    print(f'F1: {f1_score(val_y_hat, val_y)}')\n    print(f'Accuracy: {accuracy_score(val_y_hat, val_y)}')\n    print(f'Precision: {precision_score(val_y_hat, val_y)}')\n    print(f'Recall: {recall_score(val_y_hat, val_y)}')\n\n    \n    fig, ax = plt.subplots(1,2, figsize=(16,4))\n    \n    ax[0].plot(list(range(len(val_y))), val_y_hat, label= 'Predicted Firing') #Removed exponentiation\n    ax[0].plot(list(range(len(val_y))), val_y, label = 'Data') #Removed exponentiation\n    ax[0].legend(loc = 'best')\n    ax[0].set_title('Predictions')\n    \n    print(f'Using model : {model}')\n    if model == LogisticRegression:\n        coeff_df = pd.DataFrame(reg.coef_[0], train_X_scaled.columns, columns=['Coefficient'])  \n\n    elif model in [XGBClassifier,DecisionTreeClassifier]:\n        coeff_df = pd.DataFrame(reg.feature_importances_, train_X_scaled.columns, columns=['Coefficient'])  \n        \n    else:\n        print(\"No feature importance graph for DummyRegressor\")\n        return \n    \n    coeff_df[\"abs\"] = coeff_df.Coefficient.apply(np.abs)\n    coeff_df = coeff_df.sort_values(by=\"abs\", ascending=False).drop(\"abs\", axis=1)\n    \n    ax[1].bar(coeff_df.index[:15],coeff_df['Coefficient'][:15])\n    _ = plt.xticks(rotation=90)\n    ax[1].set_title('Feature importance')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model(DummyClassifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model(LogisticRegression)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model(DecisionTreeClassifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model(XGBClassifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_ensemble(model1, model2, model3):\n    m1 = model1(random_state=11)\n    m1.fit(train_X_scaled, train_y)\n    m2 = model2()\n    m2.fit(train_X_scaled, train_y)\n    m3 = model3()\n    m3.fit(train_X_scaled, train_y)    \n    val_y_hat = mode([m1.predict(val_X_scaled),m2.predict(val_X_scaled), m3.predict(val_X_scaled)])[0][0]\n    \n    print(f'F1: {f1_score(val_y_hat, val_y)}')\n    print(f'Accuracy: {accuracy_score(val_y_hat, val_y)}')\n    print(f'Precision: {precision_score(val_y_hat, val_y)}')\n    print(f'Recall: {recall_score(val_y_hat, val_y)}')\n\n    \n    fig, ax = plt.subplots(1,1, figsize=(6,4))\n    \n    ax.plot(list(range(len(val_y))), val_y_hat, label= 'Predicted Firing') #Removed exponentiation\n    ax.plot(list(range(len(val_y))), val_y, label = 'Data') #Removed exponentiation\n    ax.legend(loc = 'best')\n    ax.set_title('Predictions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ensemble(DecisionTreeClassifier, XGBClassifier,LogisticRegression)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}