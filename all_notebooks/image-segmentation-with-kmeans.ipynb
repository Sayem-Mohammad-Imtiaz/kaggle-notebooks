{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Image Segementation with Kmeans"},{"metadata":{},"cell_type":"markdown","source":"## Applying Kmeans on a 256*256 greyscale image"},{"metadata":{},"cell_type":"markdown","source":"### Introducing K-means "},{"metadata":{},"cell_type":"markdown","source":"\n\nThe k-means algorithm searches for a pre-determined number of clusters within an unlabeled multidimensional dataset. It accomplishes this using a simple conception of what the optimal clustering looks like:\n\n    The \"cluster center\" is the arithmetic mean of all the points belonging to the cluster.\n    Each point is closer to its own cluster center than to other cluster centers.\n\nThose two assumptions are the basis of the k-means model. We will soon dive into exactly how the algorithm reaches this solution, but for now let's take a look at a simple dataset and see the k-means result.\n\nFirst, let's generate a two-dimensional dataset.\n\n***"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing important libraries** "},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.cluster import KMeans\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FIlepath to images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath =\"../input/greyscale-image/Image.jpg\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Displaying Image:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(filepath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <u>Algorithm :</u>\n\nŒö-means clustering algorithm inputs are the number of clusters Œö and the data set. Algorithm starts with initial estimates for the Œö centroids, which can either be randomly generated or randomly selected from the data set. The algorithm then iterates between two steps:\n\n1. <u>Data assigment step:</u>\n\nEach centroid defines one of the clusters. In this step, each data point based on the squared Euclidean distance is assigned to its nearest centroid. If ùëêùëñ\n\nis the collection of centroids in set C, then each data point x is assigned to a cluster based on\nminùëêùëñ‚ààùê∂ùëëùëñùë†ùë°(ùëêùëñ,ùë•)2\n\nwhere dist( ¬∑ ) is the standard (L2) Euclidean distance.\n\n2. <u>Centroid update step:</u>\n\nCentroids are recomputed by taking the mean of all data points assigned to that centroid's cluster.\n\nThe algorithm iterates between step one and two until a stopping criteria is met (no data points change clusters, the sum of the distances is minimized, or some maximum number of iterations is reached).\n\nThis algorithm may converge on a local optimum. Assessing more than one run of the algorithm with randomized starting centroids may give a better outcome.\n\n### <u>Choosing K</u>\n\nIf the true label is not known in advance, then K-Means clustering can be evaluated using Elbow Criterion , Silhouette Coefficient , cross-validation, information criteria, the information theoretic jump method, and the G-means algorithm.\n***"},{"metadata":{},"cell_type":"markdown","source":"### The objective of K-Means clustering is to minimize the sum of squared distances between all points and the cluster center."},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1104/1*riInbzp5CiuMOOq8rldQ7w.png)"},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"**Converting 3D image numpy array to 2D **\n\nour image array is converted in 2d so Kmeans can be performed anad its done with np.reshape."},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(filepath)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nr, g, b = cv2.split(img)\nr = r.flatten()\ng = g.flatten()\nb = b.flatten()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = Axes3D(fig)\nax.scatter(r, g, b)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The good news is that the k-means algorithm assigns the points to clusters very similarly to how we might assign them by eye. But you might wonder how this algorithm finds these clusters so quickly! After all, the number of possible combinations of cluster assignments is exponential in the number of data points‚Äîan exhaustive search would be very, very costly. Fortunately for us, such an exhaustive search is not necessary: instead, the typical approach to k-means involves an intuitive iterative approach known as expectation‚Äìmaximization."},{"metadata":{},"cell_type":"markdown","source":"**Reshaping np array in 2D to perform kmeans**"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorized = img.reshape((-1,3))\nvectorized = np.float32(vectorized)\nprint(vectorized.shape)\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Keeping K value 3**"},{"metadata":{"trusted":true},"cell_type":"code","source":"K=3\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_RANDOM_CENTERS)\nlabel = label.flatten()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reshaping 2D array to 3D array**"},{"metadata":{"trusted":true},"cell_type":"code","source":"center = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting Resultant Image **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(result_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"**Comparing Original and Segmented image**"},{"metadata":{"trusted":true},"cell_type":"code","source":"figure_size = 10\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(1, 2, 1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(1, 2, 2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"**With K values as 4**"},{"metadata":{"trusted":true},"cell_type":"code","source":"K=4\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_RANDOM_CENTERS)\nlabel = label.flatten()\n## Reshaping 2D array to 3D array\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure_size = 10\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(1, 2, 1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(1, 2, 2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"**With K values as 5**"},{"metadata":{"trusted":true},"cell_type":"code","source":"K=5\nattempts=10\nret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_RANDOM_CENTERS)\nlabel = label.flatten()\n    \n## Reshaping 2D array to 3D array\n\ncenter = np.uint8(center)\nres = center[label.flatten()]\nresult_image = res.reshape((img.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure_size = 10\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(1, 2, 1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(1, 2, 2),plt.imshow(result_image)\nplt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"**Identifying Edges in Image**"},{"metadata":{"trusted":true},"cell_type":"code","source":"edges = cv2.Canny(img,150,200)\nplt.figure(figsize=(figure_size,figure_size))\nplt.subplot(1,2,1),plt.imshow(img)\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(1,2,2),plt.imshow(edges,cmap = 'gray')\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":"**Using kmeans function from sklearn.cluster**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pic = np.float64(img/256)\nnsamples, nx, ny = pic.shape\npic1 = pic.reshape((nsamples,nx*ny))\nkmeans = KMeans(n_clusters=20, random_state=0).fit(pic1)\npic2show = kmeans.cluster_centers_[kmeans.labels_]\nplt.imshow(pic2show)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***"},{"metadata":{},"cell_type":"markdown","source":" ## Color to represent Cluster"},{"metadata":{},"cell_type":"markdown","source":"This section will find the dominating Color from the segmented Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread(filepath)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage = image.reshape((image.shape[0] * image.shape[1], 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cluster the pixel intensities\nclt = KMeans(n_clusters = 5)\nclt.fit(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Functions to grab dominating colors**\n\nfor K = 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"def centroid_histogram(clt):\n\t# grab the number of different clusters and create a histogram\n\t# based on the number of pixels assigned to each cluster\n\tnumLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n\t(hist, _) = np.histogram(clt.labels_, bins = numLabels)\n\t# normalize the histogram, such that it sums to one\n\thist = hist.astype(\"float\")\n\thist /= hist.sum()\n\t# return the histogram\n\treturn hist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_colors(hist, centroids):\n\t# initialize the bar chart representing the relative frequency\n\t# of each of the colors\n\tbar = np.zeros((50, 300, 3), dtype = \"uint8\")\n\tstartX = 0\n\t# loop over the percentage of each cluster and the color of\n\t# each cluster\n\tfor (percent, color) in zip(hist, centroids):\n\t\t# plot the relative percentage of each cluster\n\t\tendX = startX + (percent * 300)\n\t\tcv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n\t\t\tcolor.astype(\"uint8\").tolist(), -1)\n\t\tstartX = endX\n\t\n\t# return the bar chart\n\treturn bar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build a histogram of clusters and then create a figure\n# representing the number of pixels labeled to each color\nhist = centroid_histogram(clt)\nbar = plot_colors(hist, clt.cluster_centers_)\n# show our color bart\nplt.figure()\nplt.axis(\"off\")\nplt.imshow(bar)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}