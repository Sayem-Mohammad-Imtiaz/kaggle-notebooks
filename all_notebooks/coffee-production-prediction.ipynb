{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Coffee Production Prediction  \n\nGiven *data about coffee*, let's try to predict the **average production** of coffee in a given country.\n\nWe will use a random forest regression model to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_paths = [\n    '../input/ico-coffee-dataset-worldwide/domestic-consumption.csv',\n    '../input/ico-coffee-dataset-worldwide/exports-calendar-year.csv',\n    '../input/ico-coffee-dataset-worldwide/exports-crop-year.csv',\n    '../input/ico-coffee-dataset-worldwide/gross-opening-stocks.csv',\n    '../input/ico-coffee-dataset-worldwide/total-production.csv'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = [pd.read_csv(df_path) for df_path in df_paths]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_means(df):\n    df = df.copy()\n    countries = df[df.columns[0]]\n    means = df.mean(axis=1)\n    df = pd.concat([countries, means], axis=1)\n    df.columns = ['country', countries.name]\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_df(dfs):\n    \n    # Process all DataFrames\n    processed_dfs = []\n    \n    for df in dfs:\n        processed_dfs.append(get_means(df))\n        \n    # Merge DataFrames\n    df = processed_dfs[0]\n    \n    for i in range(1, len(processed_dfs)):\n        df = df.merge(processed_dfs[i], on='country')\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = make_df(dfs)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop country column\n    df = df.drop('country', axis=1)\n    \n    # Split df into X and y\n    y = df['total_production']\n    X = df.drop('total_production', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training/Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor()\nmodel.fit(X_train, y_train)\nprint(\"Model trained.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\n\nrmse = np.sqrt(np.mean((y_test - y_pred)**2))\nprint(\"RMSE: {:.2f}\".format(rmse))\n\nr2 = 1 - (np.sum((y_test - y_pred)**2) / np.sum((y_test - y_test.mean())**2))\nprint(\"R^2: {:.5f}\".format(r2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/nn5Z-qpCeEE"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}