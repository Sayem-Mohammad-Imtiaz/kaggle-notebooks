{"cells":[{"metadata":{"_uuid":"00391ce8-ad0c-474c-9940-e742abcbba89","_cell_guid":"1723713d-c264-44a4-a2fb-bafd1bc8e8b2","trusted":true},"cell_type":"markdown","source":"# **Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación.**\n## Base de datos: Diabetes"},{"metadata":{"_uuid":"99a8167a-91f1-4ad7-abcf-a1f2cb6e195c","_cell_guid":"97d1db31-3b29-409d-a42f-673c20d263ec","trusted":true},"cell_type":"markdown","source":"En primer lugar, cargamos la base de datos guardada como un fichero .csv y cargamos las principales librerias de python."},{"metadata":{"_uuid":"6cef9d29-4e9e-4967-9d29-79c936c75892","_cell_guid":"68966b15-0958-45ca-aa02-3bd1620701cf","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Representacion de datos\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5aebadb6-3cbb-4840-b764-b3b39cdf9000","_cell_guid":"5179b5c8-0a6c-4a37-a1b4-bbe4ae580116","trusted":true},"cell_type":"markdown","source":"Importamos el resto de librerias necesarias para realizar el análisis y un script que nos ayudará a mostrar este cuaderno de una forma más ordenada sin la necesidad de añadir funciones dentro de este."},{"metadata":{"_uuid":"4747f3bd-2d83-4f6e-9f24-dcd0f995b296","_cell_guid":"63642596-f45b-4f1f-a322-bf2ce41ce350","trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import preprocessing\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93ce6522-3128-4376-9777-6e017c9af8d4","_cell_guid":"6d6c8df7-cced-4688-a05c-c72503f42c36","trusted":true},"cell_type":"markdown","source":"Añadimos una semilla para que los procesos creados en el estudio sean repetibles y reproducibles. Vamos a utilizar la misma semilla que en el estudio \"iris\"."},{"metadata":{"_uuid":"d473400f-ff78-47b4-bb0d-32ba4fa4c40e","_cell_guid":"9a8fea8d-8803-444d-b230-c85c6b32325e","trusted":true},"cell_type":"code","source":"seed = 12737","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e51e6c0-5cb3-46d7-9931-b93d687e83cc","_cell_guid":"1d7c691e-a5c8-4698-91a2-447127b1a6bd","trusted":true},"cell_type":"markdown","source":"## Acceso y almacenamiento de datos.\n\nCargamos el conjunto de datos de diabetes, a través de la libreria de pandas."},{"metadata":{"_uuid":"84ac185d-2df7-4e18-b05c-f04275c3365d","_cell_guid":"6178a007-3393-4657-b770-2212c3786eab","trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\ntarget = 'Outcome'\n\ndata = utils.load_data(filepath, None, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos a imprimir por pantalla 5 ejemplos de nuestra base de datos de forma aleatoria, para que nuestra muestra imprimida no esté `sesgada` y ver como se estructura la información."},{"metadata":{"_uuid":"0eed4419-6e93-421f-a033-60b3ee5e2997","_cell_guid":"365b02e2-ba19-433b-839d-779e2f1b8765","trusted":true},"cell_type":"code","source":"data.sample(5,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestra base de datos tiene 9 columnas o variables:\n\n### Variables predictoras\n* `Pregnancies (Embarazos)`\n\n* `Glucose (Glucosa)`\n\n* `BloodPressure (Presión de sangre)`\n\n* `SkinThickness (Espesor de la piel)`\n\n* `Insulin (Insulina)`\n\n* `BMI (IMC)`\n\n* `DiabetesPedigreeFunction (Función de pedigrí de la diabetes)`\n\n* `Age (Edad)`\n\n### Variable clase\n* `Outcome (Resultado)`\n"},{"metadata":{},"cell_type":"markdown","source":"Dividimos la base de datos en las variables predictoras, guardadas en el atributo `X`. Y la variable clase en el atributo `y`."},{"metadata":{"_uuid":"00dcdce8-760a-4723-9760-e42828efc33b","_cell_guid":"ef914a75-5dcb-410b-980c-83a029a4c51a","trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos a comprobar que la división de la base de datos se ha realizado de forma correcta y tiene todas las variables predictoras."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos a separar el conjunto de datos en dos conjuntos diferentes: `Entrenamiento` y `test`.\n\nEste proceso llamado `houldout`, lo utilizamos para no sobreajustar el modelo de entrenamiento y validar de una forma más honesta los resultados dados por el modelo.\n\n* La muestra de entrenamiento será el 70% de la base de datos.\n* La muestra de test será el 30% de la base de datos."},{"metadata":{"_uuid":"43e12bff-b4fa-4d71-a107-1d8e8c0b4f85","_cell_guid":"b26e2927-e61e-4bc9-8a9a-48e4eb1fa7bf","trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2adf3dae-41a4-4c0b-9dd3-86ab5c582dfa","_cell_guid":"3addd0e7-a7ed-4bb1-a319-fb318f077dcb","trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análisis exploratorio de datos."},{"metadata":{},"cell_type":"markdown","source":"Con el siguiente codigo, vamos a mostar la información de todas las variables de nuestra base de datos para ayudarnos en nuestro estudio.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La variable clase `Outcome` en este estudio es una variable numérica entera, discreta con dos posibles valores: 0 y 1. Este valor indica si dada la instancia de la base de datos, el resultado de su diagnostico es positivo en diabetes.\n\nEl resto de variables, las predictoras, tambien son numéricas de tipo entero. Excepto `BMI` y `DiabetePedigreeFunction`, que son de tipo flotante."},{"metadata":{},"cell_type":"markdown","source":"## Visualización de los datos."},{"metadata":{},"cell_type":"markdown","source":"A partir de la información que ya conocemos de las variables, vamos a representar los datos en de diferentes formas. Esto lo haremos para realizar un análisis en profundidad.\n\nPrimero vamos a utilizar métodos `univariados`. Al analizar las variables por separados podemos estudiar si alguna de estas variables contiene datos ruidosos o `outliers`. También podemos observar de esta manera la distribución de valores de una variable, si una variable es uniforme no nos aportará mucha información ya que tendrá siempre el mismo valor. Mientras que, si nuestra distribución es gaussiana nos ayudará a la hora de realizar el estudio.\n\nAntes de nada, las variables de entrenamiento las unimos para tener una base de datos de entrenamiento completa."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A partir de un histograma podemos ver la densidad de ejemplos para distintos valores de una variable numérica. Tambíen nos permite conocer información de las variables por separado como hemos dicho anteriormente. La siguiente gráfica interactiva permite ver la distribución de cada variable por separado, pudiendo ver a simple vista valores ruidosos o la distribución de cada variable. En este caso, la gráfica lo utilizaremos para observar `outliers`."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar en las gráficas como hay variables que poseen valores nulos, en este caso estos valores nulos estan representados por un valor `0`. Ya que, muchos atributos no tienen sentido porque no se puede tener este valor, pero hay algunos atributos que tener valores a 0 si tienen sentido. Lo estudiaremos a continuación.\n\nVamos a estudiar los atributos y si tienen *outliers* por orden que aparecen en la gráfica.\n\n`Pregnancies`: Tiene algunso ejemplos en la base de datos que se aleja de la distribución de valores para este atributo. Esta variable al indicar los embarazos, tener valores tan altos no tiene sentido, lo cual manejaremos en el preprocesamiento.\n\n`Glucose`: Este atributo poseé dos ejemplos con valores a 0. Lo cuál es un valor erroneo, ya que se necesita una medida. Este valor es un valor nulo para nuestra base de datos. Estos valores nulos los controlaremos en el preprocesamiento.\n\n`BloodPressure`: Al igual que en Glucose también tiene valores a 0, a su vez tambíen hay muestras de datos que están alejados de la distribución normal de la variable.\n\n`SkinThickness`: Posee muchos ejemplos en la base de datos con un valor a 0 o nulo. Esto supondrá un problema para el score que nos darán los modelos. En estos casos si el `20%` de los valores del atributo son nulos, eliminaremos la variable completa, ya que no introduce conocimiento adicional.\n\n`Insulin`: Tienen muchos *outliers* que se alejan mucho de la distribución, también posee una gran cantidad de valores nulos. Es la variable con más valores a 0. Al igual que el anterior atributo, estudiaremos si la variable puede ser eliminada y en caso de que sea así lo haremos en el preprocesamiento.\n\n`BMI`: Otro atributo que posee valores nulos que tendremos que manejar en el preprocesamiento.\n\n`DiabetesPedigreeFunction`: Este atributo es similar a Insulin, tiene *outliers* muy alejados de la media de la distribución del atributo. Con unos pocos ejemplos de valores nulos.\n\n`Age`: Esta variable no supone muchos problemas con los *outliers*, teniendo muy pocos ejemplos de estos en la base de datos.\n\n"},{"metadata":{},"cell_type":"markdown","source":"Como hemos comentado anteriormente, hay variables con gran cantidad de valores nulos. Vamos a dar el porcentaje que supone estos valores y si es `mayor que el 20%`, eliminaremos completamente todo el atributo. Estas variables son `SkinThickness` e `Insulin`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"valor_nulo = 0\ndata_train['SkinThickness'].value_counts(normalize = True)[valor_nulo] * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para `SkinThickness` 29.24% de los valores del atributo son valores nulos, a 0. Entonces, esta variable la quitaremos de nuestra base de datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train['Insulin'].value_counts(normalize = True)[valor_nulo] * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para `Insulin` el 48.6% de los valores son nulos, por tanto esta variable contiene una gran cantidad de estos valores y será eliminada."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train['BloodPressure'].value_counts(normalize = True)[valor_nulo] * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, para la variable `BloodPressure` el 4.66% son valores nulos. Por tanto esta variable no será eliminada y realizaremos una imputación para dar un valor correcto a estos valores nulos."},{"metadata":{},"cell_type":"markdown","source":"A continuación, vamos a estudiar la distribución de cada atributo. Mediante la libreria `seaborn` y la función `displot` podemos conocer cada distribución de una forma gráfica y ver que atributos se acercan a una distribución gaussiana o normal.\n\nCon una función creada por nosotros, llamada `plot_distribution` y guardada en el script de `utils`, representaremos gráficamente la distribución de todas las variables para estudiarla de una forma más comoda. Ignorando los valores nulos y ruidosos que hemos visto en el anterior apartado."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution(data):\n    \n    #Busca el número de columnas mayor para que las gráficas se representen como una matriz\n    col = 0\n    for i in range(1,10):\n        if len(data.columns)%i == 0 and i != len(data.columns):\n            col = i\n    \n    x = (len(data.columns)//col)\n    if col == 1:\n        x,col = 1,len(data.columns) \n    fig, axes = plt.subplots(nrows=x, ncols=col, figsize=(15,15))\n    k = 0\n    print()\n    for i in range(0,x):\n        for j in range(0,col):\n            column = list(data)[k]\n            k+=1\n            sns.distplot(data[column],ax=axes[i,j])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_distribution(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aunque en las gráficas salgan las variables Insulin y SkinThickness, no las estudiaremos ya que estos atributos los elimaneremos de nuestra base de datos como hemos comentado anteriormente.\n\nEn las gráficas podemos observar distribuciones gaussianas o normales en forma de campana, estos atributos son: `BloodPressure`, `Glucose` y `BMI`.\n\nEl resto de atributos se asemejan también a una campana pero tienen valores que hacen que esa distribución cambie. Quitando `outliers` como en la variable `Pregnancies`, tendremos una distribución más gaussiana. Entonces, para este tipo de atributos necesitaremos un método para quitar estos valores atípicos."},{"metadata":{},"cell_type":"markdown","source":"Por último, para el análisis univariado, vamos a comprobar el número de casos diferentes para la variable clase. Comprobando si nuestra base de datos de entrenamiento esta `balanceada`."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Valores:\\n\",data_train['Outcome'].value_counts(), \"\\n\\nFrecuencia:\\n\",data_train['Outcome'].value_counts(normalize = True)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El número de ejemplos en nuestra base de datos de entrenamiento esta `desbalanceado`. El número de resultados que son `0` es de **350 ejemplos**, mientras que de resultado `1` es de **187 ejemplos**. Esto supone que el `65.18%` de nuestra variable clase, es de valor `0`."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estás estadísticas una vez realizado el preprocesamiento variarán, al quitar valores que hemos estudiado que resultarán un problema para la discretización y la creación de buenos modelos."},{"metadata":{},"cell_type":"markdown","source":"Una vez estudiadas las variables de forma individual, para completar el estudio de las variables, tenemos que ver las relaciones entre estas variables. Este estudio llamado `multievaluado`, nos muestra información imporante sobre el discretizado de las variables y su potencia discriminatoria. Tambíen, sobre los valores ruidosos que se pueden encontrar en una zona con gran cantidad de otros valores clase."},{"metadata":{"trusted":true},"cell_type":"code","source":"#utils.plot_pairplot(data_train.iloc[:,0:3],target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(utils.join_dataset(data_train.iloc[:,0:3], y_train), target='Outcome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(utils.join_dataset(X_train.iloc[:,5:9], y_train), target='Outcome')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estás gráficas nos dan una representación de los valores de `Outcome` para cada par de variables. Podemos sacar un valor de corte y las variables necesarias para discretizar una variable clase y tener un modelo correcto. Pero, al tener tantas variables la claridad de sacar a simple vista un resultado correcto se vuelve muy difícil."},{"metadata":{},"cell_type":"markdown","source":"## Preprocesamiento de datos."},{"metadata":{},"cell_type":"markdown","source":"El preprocesamiento de datos es la tarea más importante del proceso KDD. En este apartado realizaremos:\n\n* `Limpieza de datos`: Suavizaremos el ruido y eliminaremos datos problematicos\n* `Integración de datos`: Introduciremos datos donde sean nulos, se utilizará una imputación de los valores perdidos mediante un estimador.\n* `Transformación de datos`: Normalizaremos los datos.\n* `Reducción de datos`: Discretizaremos los datos si es necesario.\n\nPara esta tarea se utilizara un `pipeline` para no cometer una `fuga de datos` y no introducir datos del conjunto de entrenamiento donde se aprenderá el modelo en el conjunto de prueba donde los datos de este conjunto son `datos crudos`. Una vez elaborado este apartado se tendrá que validad el modelo entrenado."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import QuantileTransformer\n\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_colum = ['SkinThickness','Insulin']\ndef drop_column(X, columns = delete_colum):\n    return X.drop(columns, axis=1)\n#X_test = drop_column(X_test,delete_colum)\n#X_train = drop_column(X_train,delete_colum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train = X_train.drop(columns = ['SkinThickness','Insulin'])\n#X_test = X_test.drop(columns = ['SkinThickness','Insulin'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quantile_transformer = preprocessing.QuantileTransformer(n_quantiles = 10,output_distribution='normal',random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer_col = list(set(list(X)) - set(delete_colum) - set(['Pregnancies']))\nprint(imputer_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = make_column_transformer((KNNImputer(n_neighbors=3, weights=\"uniform\",missing_values=0), imputer_col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_distribution(X_imputer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Algoritmos de clasificación."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip = make_pipeline(FunctionTransformer(drop_column),imputer,discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(pip,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}