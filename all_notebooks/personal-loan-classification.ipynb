{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##importing required libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n##Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n##Performance metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, recall_score,accuracy_score, make_scorer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##reading the bank data\ndf1=pd.read_csv('/kaggle/input/personal-loan-modeling/Bank_Personal_Loan_Modelling.csv')\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the data we can say that the variables types are-\nNumeric: Age, Experience, Income, CCAvg, Mortgage\nCategorical: Family, Personal Loan, Securities Account, CD Account, Online, Education,Credit Card","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing ID column which is of no relevance\ndf1.drop(columns =['ID', 'ZIP Code'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()\ndf1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.isnull().sum()##checking missing values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values. lets proceed with EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Lets see the distribution of target column- Personal Loan\nprint(df1.groupby('Personal Loan').size())\nsns.countplot(df1['Personal Loan'],label=\"Count\")\nplt.title(\"Distribution of Target Variable\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Personal Loan is the feature we are going to predict. 0 means gave -ve response to the campaign, 1 means took personal loan as result of the campaign. We have to check what features influence 1. In the dataset we have only 480 (~9.6%), highly imbalance dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.subplot(2,3,1)\ndf1.groupby('Personal Loan')['Income'].mean().plot(kind='bar',title='Income')\nplt.subplot(2,3,2)\ndf1.groupby('Personal Loan')['CCAvg'].mean().plot(kind='bar', title='Average CC Spend')\nplt.subplot(2,3,3)\ndf1.groupby('Personal Loan')['Age'].mean().plot(kind='bar', title='Age')\nplt.subplot(2,3,4)\ndf1.groupby('Personal Loan')['Experience'].mean().plot(kind='bar', title='Experience')\nplt.subplot(2,3,5)\ndf1.groupby('Personal Loan')['Mortgage'].mean().plot(kind='bar', title='Mortagage')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Experience and Age mean are similar for personal Loan -ve and +ve\n* Higher income, cc spent and mortgage have responded +ve to loan","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df1.corr())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion: Age and experience are highly correlated, quite obviously. Income and CC average spent are also significantly correlated.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='Income',y='CCAvg',data=df1,fit_reg=False,hue='Personal Loan') \nsns.lmplot(x='Income',y='Mortgage',data=df1,fit_reg=False,hue='Personal Loan') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similar pattern we can see from this graph also, higher Income+ CC spent and higher Income+Mortgage have responded +ve to loan.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##Binning the age since mean is not giving any insight\nbin=[23,35,55,67]\ngroup=['Young','Middle','Old']\ndf1['Age_bin']=pd.cut(df1['Age'],bin,labels=group) #converting numeric into categorical\nage= pd.crosstab(df1['Age_bin'],df1['Personal Loan'])\nage.plot(kind='bar',stacked=True,title='Age Group')\nage.div(age.sum(1).astype(float),axis=0).plot(kind='bar',\n                                              stacked=True,title='% Age Group')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be inferred that the Applicant age does not affect the chances of buying the personal loan. So dropping the age_bin ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.drop(columns =['Age_bin'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding distribution of Categorical variable with respect to Personal Loan","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df1['Securities Account'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='Securities')\npd.crosstab(df1['CD Account'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='CD Account')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df1['Online'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='Online')\npd.crosstab(df1['CreditCard'],df1['Personal Loan']).plot(kind='bar',stacked=True,title='Credit Card')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Plotting family\nedu=pd.crosstab(df1['Family'],df1['Personal Loan'])\nedu.div(edu.sum(1).astype(float),axis=0).plot(kind='bar',\n                                              stacked=True,title='% Family')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Plotting education\nedu=pd.crosstab(df1['Education'],df1['Personal Loan'])\nedu.div(edu.sum(1).astype(float),axis=0).plot(kind='bar',\n                                              stacked=True,title='% Education')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary for EDA -\nSo  to  summarize  our  basic  EDA  we  can  conclude  the  below  strategy  for  the  bank  to  select  the  target audience\n* Higher Income more loan\n* Lower mortgage has more chances for personal loan. Exception-Exclude zero Mortgage candidates\n* Age and Experience do not much effect loan preference.\n* In all Education levels, maximum population located in 20 to 100 income range\n* Low Income and Low Mortgage-Less loan- New scheme for such peoples\n* Higher  income  and  higher  mortgage  have  better  conversion  ratio-Different  marketing  for  easy pickers\n* Higher Credit spend and higher Income-more chances of conversion\n* Good income but less Credit spend(Income 50k~100K, and CCavg<2500)- Bright spot to increase the loan \n* The distribution  of  No  personal  loan  compared  to  education  reveals  that  we  have  mostly  equal distribution of no-loan takers in all the 3 education levels. Higher eductaion has responding slighly more +ves but nor very big difference.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Model Building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##splitting the data into train-test in 80-20 ratio\nX_train, X_test, y_train, y_test = train_test_split(df1.loc[:, df1.columns != 'Personal Loan'], df1['Personal Loan'], \n                                                    stratify=df1['Personal Loan'], \n                                                    random_state=66, test_size =0.2)\nprint(\"Training Data: \",X_train.shape, y_train.shape)\nprint(\"Test Data: \",X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. CART Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building the model\nmodel_ct = DecisionTreeClassifier(criterion='gini',random_state=1)\nmodel_ct.fit(X_train,y_train) ## training the model\n## checking the accuracy of model on training/test data\nacc_ct=round(model_ct.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(model_ct.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_ct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Tuning the model\nmodel_t = DecisionTreeClassifier(random_state=1,max_depth=5)\nmodel_t.fit(X_train,y_train) ## training the model\n## checking the accuracy of model on test data\nacc_t=round(model_t.score(X_test, y_test)*100,2)\nprint(\"Accuracy on test data: \",acc_t)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The tuned model is giving better accuracy on test data, so taking this as final CART model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##Predicting on test data\n\npredictions_t = model_t.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Since the data is imbalance, we should not only rely on accuracy and check other metrics as well\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, predictions_t))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, predictions_t))\nprint('\\n')\nauc_t = round(roc_auc_score(y_test, predictions_t)*100,2)\nprint(\"AUC: \",  auc_t)\nrecall_t = round(recall_score(y_test, predictions_t)*100,2)\nprint(\"Recall: \",  recall_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Plotting the tree\nplt.figure(figsize=(25,10))\na= plot_tree(model_t, \n             feature_names=X_train.columns,\n             filled=True, \n              rounded=True, \n              fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Random Forest Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Building RF model with 101 tress\nrf = RandomForestClassifier(n_estimators=101, random_state=1)\nrf.fit(X_train, y_train)\n## checking the accuracy of model on training/test data\nacc_rf=round(rf.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Predicting on test data\npredictions_rf = rf.predict(X_test)\nauc_rf = round(roc_auc_score(y_test, predictions_rf)*100,2)\nprint(\"AUC: \",  auc_rf)\nrecall_rf = round(recall_score(y_test, predictions_rf)*100,2)\nprint(\"Recall: \",  recall_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To tune the model we'll use GridsearchCV function to find best hyperparameter","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'n_estimators': [101,201,251], 'max_features': [4,5,6,7], 'max_depth':[6,7,8]}\nrf1 = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, \n                   scoring=make_scorer(accuracy_score))\nrf1.fit(X_train, y_train)\nacc_rf1=round(rf1.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(rf1.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_rf1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best=rf1.best_params_\nprint(best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Building the model using best estimators from the result of GridSerachCV\nrf2 = RandomForestClassifier(max_depth=8, n_estimators=101, random_state=1,max_features=6)\nrf2.fit(X_train, y_train)\nacc_rf2=round(rf2.score(X_test, y_test)*100,2)\nprint(\"Accuracy on training set: {:.3f}\".format(rf1.score(X_train, y_train)))\nprint(\"Accuracy on test data: \",acc_rf2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Predicting on test data\npredictions_rf2 = rf2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(y_test, predictions_rf))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(y_test, predictions_rf))\nprint('\\n')\nauc_rf2 = round(roc_auc_score(y_test, predictions_rf)*100,2)\nprint(\"AUC: \",  auc_rf)\nrecall_rf2 = round(recall_score(y_test, predictions_rf)*100,2)\nprint(\"Recall: \",  recall_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureImportances = pd.Series(rf2.feature_importances_).sort_values(ascending=False)\n\nsns.barplot(x=round(featureImportances,4), y=X_train.columns, color='y')\nplt.xlabel('Features Importance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('---Comparison Of both Models---')\nprint('Cart Model Accuracy:',acc_t,',Auc:',auc_t,', Recall:',recall_t)\nprint('RF Model Accuracy:',acc_rf2,',Auc:',auc_rf2,', Recall:',recall_rf2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can conclude from the performance metrics comparison that Decision Tree is giving better value of Recall. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}