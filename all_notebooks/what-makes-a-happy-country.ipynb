{"nbformat":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","file_extension":".py","name":"python","mimetype":"text/x-python","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":1,"cells":[{"metadata":{"_cell_guid":"4b2db7d4-bf79-4690-aecb-b04c4d7c7f6f","_uuid":"e39eb2c89e9c65ce3e1c6030e1c4a1bbfaff5af5"},"cell_type":"markdown","source":"Let's import our data and take our target variable to be the happiness score."},{"metadata":{"_cell_guid":"2f30c7cd-a364-4efe-8258-5ccf8d9e146f","_uuid":"1943d807b29cb3434298559ef03418ac552a9de0"},"execution_count":null,"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#setting seaborn style plots\nsns.set()\n\n#importing data and showing sample\nyear = '2016'\ndf = pd.read_csv('../input/' + year + '.csv')\n\n#our target\nTARGET = df['Happiness Score']\n\n#happiest country\nprint(\"The happiest country for the year of \" + year + \" is: \" + df[df['Happiness Rank']==1]['Country'][0])\n","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"89340ac3-4390-47b9-aad0-a9fb6e093955","_uuid":"6519af19bd00b9f8bb672378606b70eb0f8f3207"},"cell_type":"markdown","source":"First, we define a function that will give us the cumulative distribution for our happiness score. Then we will plot it out with the 25th, 50th, and 75th percentiles marked by black diamonds."},{"metadata":{"_cell_guid":"92167395-b8dd-48e5-a85a-2bb1c048e510","collapsed":true,"_uuid":"e468cd21e8caec6bb11656e54a26c80a7ce62181"},"execution_count":null,"source":"def ecdf(data):\n    n = len(data)\n    x = np.sort(data)\n    y = np.arange(1,n+1)/n\n    return x,y\n\n#plotting ecdf and overlay percentiles\nx_ecdf, y_ecdf = ecdf(TARGET)\nplt.plot(x_ecdf,y_ecdf,marker='.',linestyle='none')\nplt.margins(0.02)\n\npercentiles = np.array([25,50,75])\nptiles = np.percentile(TARGET,percentiles)\nplt.plot(ptiles,percentiles/100,marker='D',linestyle='none', color='black')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"bde3a78d-ff69-45d2-9a25-caf71c77b136","_uuid":"19468244630065b26cb4565942cd89f2c7c7b874"},"cell_type":"markdown","source":"We can see that 75% of the happiness scores will fall below the x coordinate of the black diamond on the right of the plot."},{"metadata":{"_cell_guid":"d3ed0ef8-9425-4c4f-8217-09de80937822","_uuid":"645b348716d5b49a252da7cebac673b4739f4b0c"},"cell_type":"markdown","source":"Here, I will find all of the correlation strengths and print out the maximum."},{"metadata":{"_cell_guid":"c6cf8b59-2775-45f5-96ff-179f8fc9ae2f","collapsed":true,"_uuid":"2c37e2b00833ad52848292f30d193e2caf9522b0"},"execution_count":null,"source":"#find correlation coefficients\ndicts = {}\nkeys = list(df.columns[6:-1]) \nfor i in keys:\n    ind = i\n    x = df[ind]\n    y = TARGET\n    corr = np.corrcoef(x,y)[0,1]\n    dicts[i] = corr\nm = max(dicts.items(), key=lambda k: k[1])\nprint(\"Variable with maximum correlation to Happiness Score: \" + m[0])\nprint(\"============================================================================================\")\nprint(dicts)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"6271981a-47ce-4cfb-9df5-18f1d691c820","_uuid":"cc3c0cd5c3f9c0527bb443ce789ec3d8926b60e0"},"cell_type":"markdown","source":"Let's get some statistics on the influence percentage of each variable to the happiness score."},{"metadata":{"_cell_guid":"3d50c5f6-020c-4ae3-8b2b-e27227f26673","collapsed":true,"_uuid":"f168598b1085f593a49650d8c414fc4e693a22f6"},"execution_count":null,"source":"percentages_sub = df[keys]\npercentages = pd.DataFrame()\nfor i in percentages_sub.columns:\n    percentages[i + \" influence_pct\"] = percentages_sub[i]/TARGET\n    \nprint(percentages.describe())","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"42ff9862-5d2f-452b-8785-0db95f4ba619","_uuid":"830e8dfea44e6d003ab6f556058df8f22ecea990"},"cell_type":"markdown","source":"Let's plot out the varibale with maximum correlation to happiness score vs. the happiness score to get a visual on how correlated they are."},{"metadata":{"_cell_guid":"43829f27-1489-4665-9c9f-d307016ccbfc","collapsed":true,"_uuid":"18e8c996c819ffe43df42ccf84f5b0adc22d9ab6"},"execution_count":null,"source":"#plot to show correlation strength\nind = df[m[0]]\nplt.plot(ind,TARGET,marker='.',linestyle='none')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ba9c189c-d531-4568-870d-961c51567b35","_uuid":"4809ec7db9467a748d35fc127f2618746d04c15f"},"cell_type":"markdown","source":"Perhaps we can find a stronger correlation in the combined sum of two variables."},{"metadata":{"_cell_guid":"e031dd9a-fc66-46b8-b5c4-5fb1f11dbd87","collapsed":true,"_uuid":"7f798dc8cc0c1a3fb1dd7828fd01b91bceb88d34"},"execution_count":null,"source":"#What two combinations will produce a good correlation?\ntwo_cols = df[keys]\nnew_cols = pd.DataFrame()\nfor k in two_cols.columns:\n    for m in two_cols.columns:\n        if k != m:\n            new_cols[k+\"_and_\"+m] = two_cols[k] + two_cols[m]\n\ndicts = {}\nkeys1 = list(new_cols.columns) \nfor i in keys1:\n    x = new_cols[i]\n    y = TARGET\n    corr = np.corrcoef(x,y)[0,1]\n    dicts[i] = corr\nm = max(dicts.items(), key=lambda k: k[1])\nprint(m)","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3adef1eb-f1c9-4b01-9e8a-f273219521d7","_uuid":"19f647c0b35ab06d5eb70835ebdef05ab548ea41"},"cell_type":"markdown","source":"We now have a new variable with the strongest correlation with happiness score out of the set of all possible two column sums. Now, let's plot it out, to see if it looks any different."},{"metadata":{"_cell_guid":"f71f659a-cdce-48a5-baf5-388c3852bbeb","collapsed":true,"scrolled":true,"_uuid":"2db25bbf38cb66f83c029c7a744561d58f27005c"},"execution_count":null,"source":"ind = new_cols[m[0]]\nplt.plot(ind,TARGET,marker='.',linestyle='none')\nplt.show()","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"440294b0-1502-4850-917d-a5a6be889351","_uuid":"bc8a925c018faed7481bcdf02b1874e2f18fbb52"},"cell_type":"markdown","source":"I'm a big fan of beeswarm plots. Let's take a look at happiness score distributions per world region."},{"metadata":{"_cell_guid":"fc9c04b7-7e4f-4f03-970c-dbf745f3de9d","_uuid":"6b6647eaa2d0d167f528bfd77a5b194edb61e1ca"},"execution_count":null,"source":"df.Region = df.Region.astype('category')\nsns.swarmplot(x=df.Region, y=TARGET, data=df)\nplt.xticks(rotation=90)\nplt.show()\nprint(df[df['Region'] == 'Southeastern Asia'])","cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3774df45-c406-4ab5-b855-d875454f9361","collapsed":true,"_uuid":"70ff106608517a14d42c6bc79663fb32f9490dab"},"execution_count":null,"source":"","cell_type":"code","outputs":[]}]}