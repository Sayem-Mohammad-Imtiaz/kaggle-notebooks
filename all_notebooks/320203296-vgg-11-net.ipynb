{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## setting","metadata":{}},{"cell_type":"code","source":"SAMPLE_FILE_PATH = \"../input/facial-expression-recognition-challenge/icml_face_data.csv/icml_face_data.csv\"\n\n\nNUM_CLASSES = 7\n\nTRAIN_HDF5 = \"/kaggle/working/train.hdf5\"\nVAL_HDF5 = \"/kaggle/working/val.hdf5\"\nTEST_HDF5 = \"/kaggle/working/test.hdf5\"\n\nBATCH_SIZE = 128\nOUTPUT_PATH = \"/kaggle/working\"\n\nDATASET_MEAN_FILE = OUTPUT_PATH + \"/rgb_mean.json\"\n\nMODEL_FILE = OUTPUT_PATH + \"/model.h5\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EpochCheckpoint","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nimport os\n\n\nclass EpochCheckpoint(Callback):\n    def __init__(self,output_path,every=5,start_at=0):\n        super(Callback,self).__init__()\n\n        self.output_path = output_path\n        self.every = every\n        self.start_epoch = start_at\n\n\n    def on_epoch_end(self, epoch, logs={}):\n        if (self.start_epoch + 1)% self.every ==0:\n            p = os.path.sep.join([self.output_path,\n                                  \"epoch_{}.hdf5\".format(self.start_epoch + 1)])\n            self.model.save(p, overwrite = True)\n            self.start_epoch += 1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ImageToArrayPreprocessor","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import img_to_array\n\nclass ImageToArrayPreprocesor:\n    def __init__(self,data_format=None):\n        self.data_format = data_format\n\n    def preprocess(self,image):\n        return img_to_array(image, data_format=self.data_format)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HDF5DatasetWriter","metadata":{}},{"cell_type":"code","source":"import os\nimport h5py\n\n\nclass HDF5DatasetWriter:\n    def __init__(self, dims, output_path, data_key=\"images\", buf_size=1000):\n        if os.path.exists(output_path):\n            raise ValueError(\"您提供的输出文件{}已经存在，请手动删除\".format(output_path))\n        self.db = h5py.File(output_path, \"w\")\n        self.data = self.db.create_dataset(data_key, dims, dtype=\"float\")\n        self.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n\n        self.buf_size = buf_size\n        self.buffer = {\"data\": [], \"labels\": []}\n        self.idx = 0\n\n    def add(self, raw, label):\n        self.buffer[\"data\"].extend(raw)\n        self.buffer[\"labels\"].extend(label)\n        if len(self.buffer[\"data\"]) >= self.buf_size:\n            self.flush()\n\n    def flush(self):\n        i = self.idx + len(self.buffer[\"data\"])\n        self.data[self.idx:i] = self.buffer[\"data\"]\n        self.labels[self.idx:i] = self.buffer[\"labels\"]\n        self.idx = i\n        self.buffer = {\"data\": [], \"labels\": []}\n\n    def store_class_labels(self, class_labels):\n        dt = h5py.special_dtype(vlen=str)\n        label_dim = (len(class_labels),)\n        label_set = self.db.create_dataset(\"label_names\", label_dim, dtype=dt)\n        label_set[:] = class_labels\n\n    def close(self):\n        if len(self.buffer[\"data\"]) > 0:\n            self.flush()\n        self.db.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HDF5DatasetGenerator","metadata":{}},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nimport numpy as np\nimport h5py\n\n\nclass HDF5DatasetGenerator:\n    def __init__(self, db_file, batch_size, preprocessors=None, aug=None, binarize=True, classes=2):\n        self.batch_size = batch_size\n        # 数据预处理器列表\n        self.preprocessor = preprocessors\n        # 数据增强处理器列表\n        self.aug = aug\n        self.binarize = binarize\n        self.classes = classes\n        self.db = h5py.File(db_file,'r')\n        self.numImages = self.db[\"labels\"].shape[0]\n\n    def generator(self, passes=np.inf):\n        epochs = 0\n\n        while epochs < passes:\n            for i in np.arange(0, self.numImages, self.batch_size):\n                images = self.db[\"images\"][i:i + self.batch_size]\n                labels = self.db[\"labels\"][i:i + self.batch_size]\n\n                if self.binarize:\n                    labels = to_categorical(labels, self.classes)\n                if self.preprocessor is not None:\n                    processed_image = []\n                    for image in images:\n                        for p in self.preprocessor:\n                            image = p.preprocess(image)\n                        processed_image.append(image)\n                    images = np.array(processed_image)\n                if self.aug is not None:\n                    (images, labels) = next(self.aug.flow(images, labels, batch_size=self.batch_size))\n\n                    yield images, labels\n                epochs += 1\n\n    def close(self):\n        self.db.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TrainingMonitor","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import BaseLogger\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport json\nimport os\n\n\nclass TrainingMonitor(BaseLogger):\n    def __init__(self,fig_path,json_path=None, start_at =0):\n        super(TrainingMonitor, self).__init__()\n        self.history = {}\n        self.fig_path = fig_path\n        self.json_path = json_path\n        self.start_at = start_at\n\n    def on_train_begin(self, logs={}):\n        if self.json_path is not None:\n            if os.path.exists(self.json_path):\n                self.history = json.loads(open(self.json_path).read())\n\n                if self.start_at > 0:\n                    for k in self.history.keys():\n                        self.history[k] = self.history[k][:self.start_at]\n\n\n    def on_epoch_end(self, epoch, logs={}):\n        for (k,v) in logs.items():\n            log = self.history.get(k, [])\n            log.append(v)\n            self.history[k] =  log\n\n        if self.json_path is not None:\n            f = open(self.json_path, \"w\")\n            f.write(json.dumps(self.history))\n            f.close()\n\n\n        if len(self.history[\"loss\"]) >1:\n            N = np.arange(0, len(self.history[\"loss\"]))\n            plt.style.use(\"ggplot\")\n            plt.figure()\n            plt.plot(N, self.history[\"loss\"], label=\"train_loss\")\n            plt.plot(N, self.history[\"val_loss\"], label=\"val_loss\")\n            plt.plot(N, self.history[\"accuracy\"], label=\"train_acc\")\n            plt.plot(N, self.history[\"val_accuracy\"], label=\"val_acc\")\n            epochs = len(self.history[\"loss\"])\n            plt.title(\"Training Loss & Accuracy [Epoch {}]\".format(epochs))\n            plt.xlabel(\"Epoch #\")\n            plt.ylabel(\"Loss/Accuracy\")\n            plt.legend()\n            plt.savefig(self.fig_path)\n            plt.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## build_hdf5","metadata":{}},{"cell_type":"code","source":"import numpy as np\n# from utils.HDF5DatasetWriter import HDF5DatasetWriter\n# from config import setting\n\nprint(\"[信息] 加载csv格式数据集文件\")\n\nfile = open(SAMPLE_FILE_PATH)\nfile.__next__()#跳过第一行\n(train_images, train_label) = ([], [])\n(val_images, val_label) = ([], [])\n(test_images, test_label) = ([], [])\ncount_by_label_train = {}\ncount_by_label_val = {}\ncount_by_label_test = {}\nfor row in file:\n    (label, usage, image) = row.strip().split(\",\")\n    label = int(label)\n    image = np.array(image.split(\" \"), dtype=\"uint8\")\n    image = image.reshape((48, 48))\n\n    if usage == \"Training\":\n        train_images.append(image)\n        train_label.append(label)\n        count = count_by_label_train.get(label, 0)\n        count_by_label_train[label] = count + 1\n\n    elif usage == \"PublicTest\":\n        val_images.append(image)\n        val_label.append(label)\n        count = count_by_label_val.get(label, 0)\n        count_by_label_val[label] = count + 1\n\n    elif usage == \"PrivateTest\":\n        test_images.append(image)\n        test_label.append(label)\n        count = count_by_label_test.get(label, 0)\n        count_by_label_test[label] = count + 1\n\nfile.close()\nprint(\"[信息] 训练集样本数量：{}\".format(len(train_images)))\nprint(\"[信息] 校验集样本数量：{}\".format(len(val_images)))\nprint(\"[信息] 测试集样本数量：{}\".format(len(test_images)))\n#训练集样本分布\nprint(count_by_label_train)\n#校正集样本分布\nprint(count_by_label_val)\n#测试集样本分布\nprint(count_by_label_test)\n\ndatasets = [(train_images,train_label,TRAIN_HDF5),\n            (val_images,val_label,VAL_HDF5),\n            (test_images,test_label,TEST_HDF5)]\n\nfor (images,labels,outputPath) in datasets:\n    print(\"[信息]构建{}...\".format(outputPath))\n    writer = HDF5DatasetWriter((len(images),48,48),outputPath)\n\n    for (image,label) in zip(images,labels):\n        writer.add([image],[label])\n\n    writer.close()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## mini_vgg_13","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import backend\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Activation, BatchNormalization\n\n\nclass MiniVGG13Net():\n    @staticmethod\n    def build(width, height, channel, classes, reg=0.0002):\n        model = Sequential(name=\"MiniVGG13Net\")\n        shape = (width, height, channel)\n        channel_dimension = -1\n        if backend.image_data_format == \"channel first\":\n            shape = (channel, width, height)\n            channel_dimension = 1\n        # 第一卷积块\n        model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(BatchNormalization(axis=channel_dimension))\n        # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        # model.add(Dropout(0.35))\n\n        # 第二卷积块\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n        # model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(BatchNormalization(axis=channel_dimension))\n        # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        # model.add(Dropout(0.35))\n\n        # 第三卷积块\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n        # model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(BatchNormalization(axis=channel_dimension))\n        # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        # model.add(Dropout(0.35))\n\n        # 第四卷积块\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n\n        # model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n        # model.add(Activation(\"relu\"))\n        # model.add(BatchNormalization(axis=channel_dimension))\n        # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n        # model.add(Dropout(0.35))\n\n        # 第五卷积块\n        model.add(Conv2D(512,(3,3),padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D(pool_size=(2,2),padding=\"same\",strides=(1,1)))\n\n        # 第一全连接层\n        model.add(Flatten())\n        model.add(Dense(256, kernel_regularizer=l2(reg)))\n        # model.add(Dense(64, kernel_regularizer=l2(reg)))\n\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        # model.add(Dropout(0.35))\n        model.add(Dropout(0.5))\n        # 第二全连接层\n        model.add(Flatten())\n        model.add(Dense(128, kernel_regularizer=l2(reg)))\n        # model.add(Dense(64, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        # model.add(Dropout(0.35))\n        model.add(Dropout(0.5))\n        # 第三全连接层\n        model.add(Dense(classes, kernel_regularizer=l2(reg)))\n        model.add(Activation(\"softmax\"))\n\n        return model\n\n\nif __name__ == \"__main__\":\n    model = MiniVGG13Net.build(48, 48, 1, 7, reg=0.0002)\n    print(model.summary())\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## training","metadata":{}},{"cell_type":"code","source":"import matplotlib\n# from config import setting\n# from utils.ImageToArrayPreprocessor import ImageToArrayPreprocessor\n# from utils.TrainingMonitor import TrainingMonitor\n# from utils.HDF5DatasetGenerator import HDF5DatasetGenerator\n# from MiniVGG13 import MiniVGG13Net\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nimport os\nmatplotlib.use(\"Agg\")\n\ntrain_aug = ImageDataGenerator(rotation_range=10,\n                   zoom_range = 0.1,\n                   rescale=1 / 255.0,\n                   fill_mode=\"nearest\")\nval_aug = ImageDataGenerator(rescale=1/255.0)\n\niap = ImageToArrayPreprocesor()\n\ntrain_gen = HDF5DatasetGenerator(TRAIN_HDF5,\n                                 BATCH_SIZE,\n                                 aug=train_aug,\n                                 preprocessors=[iap],\n                                 classes=NUM_CLASSES)\nval_gen = HDF5DatasetGenerator(VAL_HDF5,\n                                 BATCH_SIZE,\n                                 aug=val_aug,\n                                 preprocessors = [iap],\n                                 classes=NUM_CLASSES)\n\nopt = Adam(lr = 1e-3)\nmodel = MiniVGG13Net.build(width=48,height=48,channel=1,classes=NUM_CLASSES)\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\njson_path = os.path.sep.join([OUTPUT_PATH, \"MiniVGG13.json\"])\nfig_path = os.path.sep.join([OUTPUT_PATH, \"{}.png\".format(os.getpid())])\ncallbacks = [TrainingMonitor(fig_path=fig_path,json_path=json_path)]\nmodel.fit_generator(train_gen.generator(),\n                    steps_per_epoch=train_gen.numImages//BATCH_SIZE,\n                    validation_data=val_gen.generator(),\n                    validation_steps=val_gen.numImages // BATCH_SIZE,\n                    epochs=50,\n                    max_queue_size=BATCH_SIZE*2,\n                    callbacks=callbacks,\n                    verbose=1)\nprint(\"[信息] 保存模型...\")\nmodel.save(MODEL_FILE,overwrite=True)\ntrain_gen.close()\nval_gen.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## evaluate\n","metadata":{}},{"cell_type":"code","source":"# from config import setting\n#from utils.HDF5DatasetGenerator import HDF5DatasetGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\n\ntestAug = ImageDataGenerator(rescale=1/255.0)\niap = ImageToArrayPreprocesor()\ntestGen = HDF5DatasetGenerator(TEST_HDF5,\n                               BATCH_SIZE,\n                               aug=testAug,\n                               preprocessors=[iap],\n                               classes=NUM_CLASSES)\nprint(\"[信息] 加载网络模型...\")\nmodel = load_model(MODEL_FILE)\n\n# 评估\n(loss, acc) = model.evaluate_generator(testGen.generator(),\n                                     steps=testGen.numImages//BATCH_SIZE,\n                                     max_queue_size=BATCH_SIZE*2)\nprint(\"[信息] 测试集准确率：{:.2f}%\".format(acc*100))\ntestGen.close()\n\n","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport imutils\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\nface_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\nmodel = load_model(\"./model.h5\")\n\nEMOTIONS = ['Angry', 'Disgust', 'Scared', 'Harry', 'Sad', 'Surprise', 'Neutral']\n\n# 开启摄像头\ncapture = cv2.VideoCapture(0)\n\n# 持续采集摄像头图像帧\nwhile True:\n    ret, frame = capture.read()\n    # 帧图像缩小并灰度化\n    #print(frame)\n    frame = imutils.resize(frame,width=300)\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # 画布\n    canvas = np.zeros((240,300,3),dtype=\"uint8\")\n\n    frameClone = frame.copy()\n\n    # 检测人脸\n    rects = face_detector.detectMultiScale(\n        gray,scaleFactor=1.1,\n        minNeighbors=5,\n        minSize=(30,30),\n        flags=cv2.CASCADE_SCALE_IMAGE)\n\n    if len(rects) > 0:\n        # 对检测到的多个人脸框降序排序\n        rect = sorted(rects, reverse=True,\n                      key=lambda x:(x[2]-x[0])*(x[3]-x[1]))[0]\n        (fX, fY, fW, fH) = rect\n        roi =  gray[fY:fY+fH,fX:fX+fW]\n        roi = cv2.resize(roi,(48,48))\n        roi = roi.astype(\"float\") / 255.0\n        roi = img_to_array(roi)\n        roi = np.expand_dims(roi,axis=0)\n\n        predicts = model.predict(roi)[0]\n        label = EMOTIONS[predicts.argmax()]\n        cv2.putText(frameClone,label,(fX,fY-10),\n                    cv2.FONT_HERSHEY_SIMPLEX,0.5,(0, 0, 255),1, cv2.LINE_AA)\n        cv2.rectangle(frameClone,(fX,fY),(fX+fW,fY+fH),\n                      (0,0,255),1,cv2.LINE_AA)\n        for (i,(emotion,prob)) in enumerate(zip(EMOTIONS,predicts)):\n            text = \"{}: {:.2f}%\".format(emotion,prob*100)\n            w = int (prob*300)\n            cv2.rectangle(canvas,(5,(i*32)+5),(5+w,(i*32)+32),(0,0,255),-1)\n            cv2.putText(\n                canvas,\n                text,\n                (10,(i*32)+23),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                0.5,\n                (255,255,255),\n                1,\n                cv2.LINE_AA\n            )\n    cv2.imshow('Emotion Detection', frameClone)\n    cv2.imshow(\"Result\",canvas)\n\n    if cv2.waitKey(1) == 27:\n        break\n\ncapture.release()\ncv2.destroyAllWindows()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}