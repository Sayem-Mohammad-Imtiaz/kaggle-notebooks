{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel contains the Model initialization and training scripts for classification systems created by Team KAFK(cosec) for Memotion Analysis 2020.\nPlease only use this kernel as **reference** since the results are not reproducible unless the hyper-parameters from the paper are used. If you are going to run this kernel, please run only one of the two systems at a time.\n\n1. System 1: Uses both text and image features.\n2. System 2: Uses only images.\n"},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"!git clone https://github.com/cozek/memotion2020-code\n!pip install --upgrade efficientnet-pytorch   \n!git clone https://github.com/huggingface/transformers\n!pip install transformers/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nnp.random.seed(42)\nimport re\nimport os\nimport sys\nsys.path.append('/kaggle/working/memotion2020-code/src/')\nimport pickle\nimport collections\n\nfrom PIL import ImageFile, Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport warnings  \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import Callable\nfrom tqdm import notebook\nimport importlib\nimport nltk\nimport datetime\nimport time\nfrom argparse import Namespace\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\ntorch.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ranger combo\nfrom radam.radam import RAdam\nfrom lookahead.optimizer import Lookahead","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaModel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import memotion_utils.general as general_utils\nimport memotion_utils.transformer.data as transformer_data_utils\nimport memotion_utils.transformer.general as transformer_general_utils\n\ngeneral_utils.set_seed_everywhere()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args = Namespace(\n        device = 'cuda' if torch.cuda.is_available() else 'cpu',\n        n_workers = 2,\n        date = datetime.datetime.now().strftime(\"%a_%d_%b_%Y/\"),\n        learning_rate = 0.0001,\n        num_epochs = 20,\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading the files"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"IMAGES_DIR = '/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images'\nimage_filenames = os.listdir(IMAGES_DIR)\nfile_extentions = [filename.split('.')[-1] for filename in image_filenames]\n\nimages_paths = [os.path.join(IMAGES_DIR,filename) for filename in image_filenames]\n\nREF_FILE = '/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/reference_df_pickle'\nLABELS_FILE = '/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels_pd_pickle'\n\nwith open(REF_FILE, 'rb') as handle:\n    reference_df_ = pickle.load(handle)\n\nwith open(LABELS_FILE, 'rb') as handle:\n    labels_pd_ = pickle.load(handle)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimage_formats = collections.Counter(file_extentions)\nprint(f'Num Images: {len(images_paths)}')\n\nprint('Image formats found: ', image_formats)\nimage_formats_df = pd.DataFrame.from_dict(image_formats, orient='index').reset_index()\nimage_formats_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_val_split(train_frac, df, id_col):\n    \"\"\"\n    Splits dataframe into train and val keeping percentage of\n    labels same in both splits.\n    Args:\n        train_frac: Fraction of samples to use for train\n        df: pd.DataFrame to split\n        id_col: Column that uniquely identifies every row.\n    Returns:\n        split_df\n    \"\"\"\n    val_frac = 1 - train_frac\n    assert val_frac + train_frac == 1\n    labels = set(df.label)\n    split_df = None\n    df = df.sample(frac=1) #shuffle df\n\n    for lbl in notebook.tqdm(labels, total = len(labels)):\n        lbl_df = df[df.label == lbl].copy()\n        temp_df_train = lbl_df.sample(frac=train_frac).copy()\n        temp_df_val = lbl_df[~lbl_df[id_col].isin(temp_df_train[id_col])].copy()\n        temp_df_train['split'] = 'train'\n        temp_df_val['split'] = 'val'\n        if not isinstance(split_df,pd.DataFrame):\n            split_df = temp_df_train.copy()\n            split_df = pd.concat([split_df, temp_df_val])\n        else:\n            split_df = pd.concat([split_df, temp_df_train, temp_df_val])\n    \n    assert len(split_df) == len(df)\n    return split_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task A : Sentiment Classification\n### Definition: : Given an Internet meme, the first task is to classify it as a positive, negative or neutral meme.\n\n- Negative and Very Negative => 2 \n- Positive and Very Positive => 1\n- Neutral => 0"},{"metadata":{},"cell_type":"markdown","source":"# System 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Negative and Very Negative => 2\n# Positive and Very Positive => 1\n# Neutral => 0\n\ntask_a_labels = {\n    'negative': 2 ,\n    'very_negative': 2,\n    'neutral' : 0,\n    'positive' : 1,\n    'very_positive': 1,\n}\n\ntask_a_labels_df = labels_pd_[['image_name','overall_sentiment']].copy()\ntask_a_labels_df['label'] = task_a_labels_df['overall_sentiment'].map(task_a_labels)\ntask_a_labels_df.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_a_split_df = get_train_val_split(\n    train_frac = 0.90,\n    df = task_a_labels_df,\n    id_col= 'image_name',\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_df = labels_pd_[['image_name','text_corrected']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = pd.merge(task_a_split_df,text_df, on='image_name')\ndel data_df['overall_sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RobertaPreprocessor():\n    def __init__(self,transformer_tokenizer,sentence_detector):\n        self.transformer_tokenizer = transformer_tokenizer\n        self.sentence_detector = sentence_detector\n        self.bos_token = transformer_tokenizer.bos_token\n        self.sep_token = ' ' + transformer_tokenizer.sep_token + ' '\n    def add_special_tokens(self, text):\n        text = str(text)\n        sentences = self.sentence_detector.tokenize(text)\n        eos_added_text  = self.sep_token.join(sentences) \n        return self.bos_token +' '+ eos_added_text + ' ' + self.transformer_tokenizer.sep_token","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python3 -c \"import nltk; nltk.download('punkt')\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roberta_tokenizer = tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\npunkt_sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')\nroberta_preproc = RobertaPreprocessor(roberta_tokenizer, punkt_sentence_detector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['text'] = data_df['text_corrected'].map(roberta_preproc.add_special_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SwishImplementation(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * torch.sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = torch.sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass MemoryEfficientSwish(nn.Module):\n    def forward(self, x):\n        return SwishImplementation.apply(x)\n    \n\nclass RobertaClasasificationHead(nn.Module):\n    \"\"\"Head for sentence-level classification tasks.\"\"\"\n\n    def __init__(self, config):\n        super().__init__()\n        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n        self.swish = MemoryEfficientSwish()\n        \n    def forward(self, features, **kwargs):\n        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n        x = self.dropout(x)\n        x = self.dense(x)\n        x = self.swish(x)\n        x = self.dropout(x)\n        x = self.out_proj(x)\n        return x\n    \nclass EffRoberta(nn.Module):\n    def __init__(\n        self,\n        roberta_model_name:str = 'distilroberta-base',\n        efficientnet_model_name:str = 'efficientnet-b4',\n        num_classes:int = 2,\n        effnet_advprop: bool = False,\n    ):\n        super().__init__()\n        self.roberta = RobertaModel.from_pretrained(\n            roberta_model_name,\n            num_labels = num_classes,\n        )\n        self.effnet = EfficientNet.from_pretrained(\n            'efficientnet-b4',\n            num_classes = num_classes,\n            advprop = effnet_advprop,\n        )\n        self.roberta_clf = RobertaClasasificationHead(self.roberta.config)\n        self.dropout = nn.Dropout( p=0.1, inplace=True)\n        self.fc1 = nn.Linear(2*num_classes,num_classes)\n        self.swish = MemoryEfficientSwish()\n        \n    def forward(self, indices, attn_mask, images):\n            roberta_out = self.roberta(\n                input_ids = indices, \n                attention_mask =  attn_mask, \n            )[0]\n            y_pred_roberta = self.roberta_clf(roberta_out)\n            \n            y_pred_effnet = self.effnet(images)\n            self.dropout(y_pred_effnet)\n            \n            combined_y_pred = torch.cat([y_pred_roberta,y_pred_effnet],dim=1)\n            combined_y_pred = self.swish(combined_y_pred)\n\n            return combined_y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"model = EffRoberta( num_classes = len(set(data_df.label)))\nmodel.to(args.device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SimpleVectorizer():\n    def __init__(self,tokenizer: Callable, max_seq_len: int):\n        \"\"\"\n        Args:\n            tokenizer (Callable): transformer tokenizer\n            max_seq_len (int): Maximum sequence lenght \n        \"\"\"\n        self.tokenizer = tokenizer\n        self._max_seq_len = max_seq_len\n\n    def vectorize(self,text :str):\n        encoded = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=False, #already added by preproc\n            max_length = self._max_seq_len,\n            pad_to_max_length = True,\n        )\n        ids =  np.array(encoded['input_ids'], dtype=np.int64)\n        attn = np.array(encoded['attention_mask'], dtype=np.int64)\n        \n        return ids, attn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MemotionDataset(Dataset):\n    def __init__(self, data_df: pd.DataFrame,tokenizer:Callable, max_seq_length=None):\n        \"\"\"\n        Args:\n            data_df (pandas.DataFrame): df containing the labels and text\n            tokenizer (tokenizer module for the transformer)\n        \"\"\"\n        self.images_dir = IMAGES_DIR\n        self.tokenizer = tokenizer\n        \n        if max_seq_length is None:\n            self._max_seq_length = self._get_max_len(data_df,tokenizer)\n        else:\n            self._max_seq_length = max_seq_length\n            \n        self.vectorizer = SimpleVectorizer(tokenizer, self._max_seq_length)\n        \n        self.data_df = data_df\n        \n        \n        self.train_df = self.data_df[self.data_df.split == 'train']\n        self.train_size = len(self.train_df)\n\n        self.val_df = self.data_df[self.data_df.split == 'val']\n        self.val_size = len(self.val_df)\n\n        \n        self._lookup_dict = {\n            'train': (self.train_df, self.train_size),\n            'val': (self.val_df, self.val_size),\n        }\n\n        self.set_split('train')\n\n    def _get_max_len(self,data_df: pd.DataFrame, tokenizer: Callable):\n        len_func = lambda x: len(self.tokenizer.encode_plus(x)['input_ids'])\n        max_len = data_df.text.map(len_func).max() \n        return max_len\n\n    def set_split(self, split=\"train\"):\n        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n        self._target_split = split\n        self._target_df, self._target_size = self._lookup_dict[split]\n        if split == 'val':\n            self.simple_vectorize = True\n    \n    def __len__(self):\n        return self._target_size\n    \n    def __getitem__(self, index):\n        \"\"\"the primary entry point method for PyTorch datasets\n        Args:\n            index (int): the index to the data point \n        Returns:\n            a dictionary holding the data point's features (x_data) and label (y_target)\n        \"\"\"\n        row = self._target_df.iloc[index]\n        img_name = row.image_name\n\n        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        \n        indices, attention_masks = self.vectorizer.vectorize(row.text)\n        \n        if self._target_split == 'train':\n            tfms = transforms.Compose([\n                transforms.RandomResizedCrop(224),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        else:\n            tfms = transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                normalize,\n            ])\n            \n        img_path = os.path.join(self.images_dir,img_name) \n        img = Image.open(img_path)\n        img = img.convert('RGB')\n        preproc_img = tfms(img)\n\n        label = row.label\n        \n        return {\n            'x_images': preproc_img,\n            'x_indices': indices,\n            'x_attn_mask': attention_masks,\n            'x_index': index,\n            'y_target': label,\n        }\n\n    def get_num_batches(self, batch_size):\n        \"\"\"Given a batch size, return the number of batches in the dataset\n        Args:\n            batch_size (int)\n        Returns:\n            number of batches in the dataset\n        \"\"\"\n        return len(self) // batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_batches(dataset, batch_size, shuffle=True,\n                     drop_last=False, device=\"cpu\", pinned_memory = False, n_workers = 0): \n    \"\"\"\n    A generator function which wraps the PyTorch DataLoader. It will \n      ensure each tensor is on the write device location.\n    \"\"\"\n    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n                            shuffle=shuffle, drop_last=drop_last,\n                            pin_memory= pinned_memory,\n                            num_workers = n_workers,\n                            )\n    \n    for data_dict in dataloader:\n        out_data_dict = {}\n        for key,val in data_dict.items():\n            if key != 'x_index':\n                out_data_dict[key] = data_dict[key].to(\n                    device, non_blocking= (True if pinned_memory else False) \n                )\n            else:\n                out_data_dict[key] = data_dict[key]\n                \n        yield out_data_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = MemotionDataset(\n    data_df,\n    roberta_tokenizer,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args.batch_size = 20\nargs.learning_rate = 2e-4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_func = nn.CrossEntropyLoss()\n\nprint(f'Using LR:{args.learning_rate}')\nbase_optimizer = RAdam(model.parameters(), lr = args.learning_rate)\noptimizer = Lookahead(optimizer = base_optimizer, k = 5, alpha=0.5 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = transformer_general_utils.EarlyStopping(patience=4)\ntrain_state = general_utils.make_train_state()\ntrain_state.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"epoch_bar = notebook.tqdm(\n    desc = 'training_routine',\n    total = args.num_epochs,\n    position=0,\n    leave = True,\n)\ndataset.set_split('train')\ntrain_bar = notebook.tqdm(\n    desc = 'split=train ',\n    total=dataset.get_num_batches(args.batch_size),\n    position=0,\n    leave=True,\n)\ndataset.set_split('val')\neval_bar = notebook.tqdm(\n    desc = 'split=eval',\n    total=dataset.get_num_batches(args.batch_size),\n    position=0,\n    leave=True,\n)\nfor epoch_index in range(args.num_epochs):\n    train_state['epoch_in'] = epoch_index\n\n    dataset.set_split('train')\n\n    batch_generator = generate_batches(\n        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n        device = args.device, drop_last=False,\n        pinned_memory = False, n_workers = 2, \n    )\n\n    running_loss = 0.0\n    running_acc = 0.0\n    running_f1 = 0.0\n    model.train()\n\n    train_bar.reset(\n        total=dataset.get_num_batches(args.batch_size),\n    )\n\n    for batch_index, batch_dict in enumerate(batch_generator):\n        optimizer.zero_grad()\n        y_pred = model(\n            indices = batch_dict['x_indices'],\n            attn_mask = batch_dict['x_attn_mask'],\n            images = batch_dict['x_images'],\n        )\n        \n        loss = loss_func(y_pred, batch_dict['y_target'])\n        loss.backward()\n        optimizer.step()\n                             \n        loss_t = loss.item()\n        running_loss += (loss_t - running_loss) / (batch_index + 1)\n                             \n        y_pred = y_pred.detach().cpu()\n        batch_dict['y_target'] = batch_dict['y_target'].cpu()\n        \n        acc_t = transformer_general_utils \\\n            .compute_accuracy(y_pred, batch_dict['y_target'])\n        \n        f1_t = transformer_general_utils \\\n            .compute_macro_f1(y_pred, batch_dict['y_target'])\n\n        train_state['batch_preds'].append(y_pred)\n        train_state['batch_targets'].append(batch_dict['y_target'])\n        train_state['batch_indexes'].append(batch_dict['x_index'])\n\n        running_acc += (acc_t - running_acc) / (batch_index + 1)\n        running_f1 += (f1_t - running_f1) / (batch_index + 1)\n\n        train_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n                             epoch=epoch_index)\n\n        train_bar.update()\n\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    train_state['train_accuracies'].append(running_acc)\n    train_state['train_losses'].append(running_loss)\n    \n    train_state['train_preds'].append(\n        torch.cat(train_state['batch_preds']).cpu()\n    )\n    train_state['train_targets'].append(\n        torch.cat(train_state['batch_targets']).cpu()\n    )\n    train_state['train_indexes'].append(\n        torch.cat(train_state['batch_indexes']).cpu()\n    )\n    train_f1 = transformer_general_utils \\\n                .compute_macro_f1(train_state['train_preds'][-1],\n                                  train_state['train_targets'][-1],\n                                 )\n                                 \n    train_state['train_f1s'].append(train_f1)\n    \n    train_state['batch_preds'] = []\n    train_state['batch_targets'] = []\n    train_state['batch_indexes'] = []\n    \n    \n    dataset.set_split('val')\n    batch_generator = generate_batches(\n        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n        device = args.device, drop_last=False,\n        pinned_memory = False, n_workers = 2, \n    )\n    eval_bar.reset(\n        total=dataset.get_num_batches(args.batch_size),\n    )\n    running_loss = 0.0\n    running_acc = 0.0\n    running_f1 = 0.0\n    \n    model.eval()\n    with torch.no_grad():\n        optimizer._backup_and_load_cache()\n        for batch_index, batch_dict in enumerate(batch_generator):\n            \n            y_pred = model(\n                indices = batch_dict['x_indices'],\n                attn_mask = batch_dict['x_attn_mask'],\n                images = batch_dict['x_images'],\n            )\n\n#             y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n\n            loss = loss_func(y_pred, batch_dict['y_target'])\n            loss_t = loss.item()\n            \n            running_loss += (loss_t - running_loss) / (batch_index + 1)\n            \n            y_pred = y_pred.detach().cpu()\n            \n            batch_dict['y_target'] = batch_dict['y_target'].cpu()\n            \n            acc_t = transformer_general_utils\\\n                .compute_accuracy(y_pred, batch_dict['y_target'])\n            f1_t = transformer_general_utils \\\n                .compute_macro_f1(y_pred, batch_dict['y_target'])\n\n            train_state['batch_preds'].append(y_pred.cpu())\n            train_state['batch_targets'].append(batch_dict['y_target'].cpu())\n            train_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n\n            running_acc += (acc_t - running_acc) / (batch_index + 1)\n            running_f1 += (f1_t - running_f1) / (batch_index + 1)\n            \n\n            eval_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n                                 epoch=epoch_index)\n            eval_bar.update()\n            \n    train_state['val_accuracies'].append(running_acc)\n    train_state['val_losses'].append(running_loss)\n    \n        \n    train_state['val_preds'].append(\n        torch.cat(train_state['batch_preds']).cpu()\n    )\n\n    train_state['val_targets'].append(\n        torch.cat(train_state['batch_targets']).cpu()\n    )\n    train_state['val_indexes'].append(\n        torch.cat(train_state['batch_indexes']).cpu()\n    )\n    val_f1 = transformer_general_utils \\\n                .compute_macro_f1(train_state['val_preds'][-1],\n                                  train_state['val_targets'][-1],\n                                 )\n                                 \n    train_state['val_f1s'].append(val_f1)\n    \n    train_state['batch_preds'] = []\n    train_state['batch_targets'] = []\n    train_state['batch_indexes'] = []\n    \n    early_stopping(val_f1, model)\n    optimizer._clear_and_load_backup()\n    epoch_bar.set_postfix( best_f1 = early_stopping.best_score, current = val_f1)\n    epoch_bar.update()    \n    \n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# System 2"},{"metadata":{},"cell_type":"markdown","source":"## Task B: Humor Classification\n### Definition : Given an Internet meme, the system has to identify the type of humor expressed. The categories are sarcastic, humorous, and offensive meme. If a meme does not fall under any of these categories, then it is marked as another meme. A meme can have more than one category.\n\nLabel Mapping:\n- Not humorous => 0 and Humorous (funny, very funny, hilarious) => 1\n- Not Sarcastic => 0 and Sarcastic (general, twisted meaning, very twisted) => 1\n- Not offensive => 0 and Offensive (slight, very offensive, hateful offensive) => 1\n- Not Motivational => 0 and Motivational => 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"print( f' Humor labels: {set(labels_pd_[\"humour\"])}')\nprint( f' Sarcasm labels: {set(labels_pd_[\"sarcasm\"])}')\nprint( f' Offensive labels: {set(labels_pd_[\"offensive\"])}')\nprint( f' Motivational labels: {set(labels_pd_[\"motivational\"])}')\n\n\nhumour_labels_dict = {'funny':1, 'hilarious':1, 'not_funny':0, 'very_funny':1}\nsarcasm_labels_dict = {'general':1, 'twisted_meaning':1, 'not_sarcastic':0, 'very_twisted':1}\nmotivational_labels_dict = { 'motivational':1, 'not_motivational':0 }\noffensive_labels_dict = { 'hateful_offensive':1, 'slight':1, 'not_offensive':0, 'very_offensive':1}\n\ntask_b_labels_df = labels_pd_.copy()\n\ntask_b_labels_df['humour'] = labels_pd_['humour'].map(humour_labels_dict)\ntask_b_labels_df['sarcasm'] = labels_pd_['sarcasm'].map(sarcasm_labels_dict)\ntask_b_labels_df['offensive'] = labels_pd_['offensive'].map(offensive_labels_dict)\ntask_b_labels_df['motivational'] = labels_pd_['motivational'].map(motivational_labels_dict)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sample Count of Task B"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(task_b_labels_df.humour.value_counts(),'\\n')\nprint(task_b_labels_df.sarcasm.value_counts(),'\\n')\nprint(task_b_labels_df.offensive.value_counts(),'\\n')\nprint(task_b_labels_df.motivational.value_counts(),'\\n')\n\nprint('Total:\\n',\n     pd.concat(\n        [\n            task_b_labels_df['humour'],\n            task_b_labels_df['sarcasm'],\n            task_b_labels_df['offensive'],\n            task_b_labels_df['motivational'],\n        ],\n        ignore_index= True,\n        axis = 0,\n    ).value_counts()      \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MemotionImageDataset(Dataset):\n    def __init__(self, data_df: pd.DataFrame , images_dir:str = None):\n        \"\"\"\n        Args:\n            data_df (pandas.DataFrame): df containing the labels and text\n            tokenizer (tokenizer module for the transformer)\n        \"\"\"\n\n        self.images_dir = IMAGES_DIR\n        \n        self.data_df = data_df\n        \n        self.train_df = self.data_df[self.data_df.split == 'train']\n        self.train_size = len(self.train_df)\n\n        self.val_df = self.data_df[self.data_df.split == 'val']\n        self.val_size = len(self.val_df)\n\n        \n        self._lookup_dict = {\n            'train': (self.train_df, self.train_size),\n            'val': (self.val_df, self.val_size),\n        }\n\n        self.set_split('train')\n\n    def set_split(self, split=\"train\"):\n        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n        self._target_split = split\n        self._target_df, self._target_size = self._lookup_dict[split]\n    \n    def __len__(self):\n        return self._target_size\n    \n    def __getitem__(self, index):\n        \"\"\"the primary entry point method for PyTorch datasets\n        Args:\n            index (int): the index to the data point \n        Returns:\n            a dictionary holding the data point's features (x_data) and label (y_target)\n        \"\"\"\n        row = self._target_df.iloc[index]\n        img_name = row.image_name\n\n        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        \n        if self._target_split == 'train':\n            tfms = transforms.Compose([\n                transforms.RandomResizedCrop(224),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ])\n        elif self._target_split =='val':\n            tfms = transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                normalize,\n            ])\n            \n        img_path = os.path.join(self.images_dir,img_name) \n        img = Image.open(img_path)\n        img = img.convert('RGB')\n        preproc_img = tfms(img)\n\n        label = row.label\n        \n        return {\n            'x_data': preproc_img,\n            'x_index': index,\n            'y_target': label\n        }\n\n    \n    def get_num_batches(self, batch_size):\n        \"\"\"Given a batch size, return the number of batches in the dataset\n        Args:\n            batch_size (int)\n        Returns:\n            number of batches in the dataset\n        \"\"\"\n        return len(self) // batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_image_batches(dataset, batch_size, shuffle=True,\n                     drop_last=False, device=\"cpu\", pinned_memory = False, n_workers = 0): \n    \"\"\"\n    A generator function which wraps the PyTorch DataLoader. It will \n      ensure each tensor is on the write device location.\n    \"\"\"\n    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n                            shuffle=shuffle, drop_last=drop_last,\n                            pin_memory= pinned_memory,\n                            num_workers = n_workers,\n                            )\n    \n    for data_dict in dataloader:\n        out_data_dict = {}\n        out_data_dict['x_data'] = data_dict['x_data'].to(\n            device, non_blocking= (True if pinned_memory else False) \n        )\n        out_data_dict['x_index'] = data_dict['x_index']\n        out_data_dict['y_target'] = data_dict['y_target'].to(\n            device, non_blocking= (True if pinned_memory else False) \n        )\n        yield out_data_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"humor_df = task_b_labels_df[['image_name','humour']].copy()\nhumor_df.rename(columns = {'humour':'label'}, inplace=True)\nhumor_df = get_train_val_split(0.90, humor_df,'image_name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"humor_df[humor_df.split == 'train'].label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"humor_df[humor_df.split == 'val'].label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model = EfficientNet.from_pretrained(\n    'efficientnet-b4',\n    num_classes = len(set(humor_df.label)),\n )\nmodel.to(args.device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = MemotionImageDataset(humor_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_func = nn.CrossEntropyLoss()\nprint(f'Using LR:{args.learning_rate}')\nbase_optimizer = RAdam(model.parameters(), lr = args.learning_rate)\noptimizer = Lookahead(optimizer = base_optimizer, k = 5, alpha=0.5 )\nearly_stopping = transformer_general_utils.EarlyStopping(patience=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args.batch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_state = general_utils.make_train_state()\ntrain_state.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_bar = notebook.tqdm(\n    desc = 'training_routine',\n    total = args.num_epochs,\n    position=0,\n    leave = True,\n)\ndataset.set_split('train')\ntrain_bar = notebook.tqdm(\n    desc = 'split=train ',\n    total=dataset.get_num_batches(args.batch_size),\n    position=0,\n    leave=True,\n)\ndataset.set_split('val')\neval_bar = notebook.tqdm(\n    desc = 'split=eval',\n    total=dataset.get_num_batches(args.batch_size),\n    position=0,\n    leave=True,\n)\nfor epoch_index in range(args.num_epochs):\n    train_state['epoch_in'] = epoch_index\n\n    dataset.set_split('train')\n\n    batch_generator = generate_image_batches(\n        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n        device = args.device, drop_last=False,\n        pinned_memory = False, n_workers = 2, \n    )\n\n    running_loss = 0.0\n    running_acc = 0.0\n    running_f1 = 0.0\n    model.train()\n\n    train_bar.reset(\n        total=dataset.get_num_batches(args.batch_size),\n    )\n\n    for batch_index, batch_dict in enumerate(batch_generator):\n        optimizer.zero_grad()\n        \n        y_pred = model(batch_dict['x_data'])\n        \n        y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n        \n        loss = loss_func(y_pred, batch_dict['y_target'])\n        loss.backward()\n        optimizer.step()\n                             \n        loss_t = loss.item()\n        running_loss += (loss_t - running_loss) / (batch_index + 1)\n                             \n        y_pred = y_pred.detach().cpu()\n        batch_dict['y_target'] = batch_dict['y_target'].cpu()\n        \n        acc_t = transformer_general_utils \\\n            .compute_accuracy(y_pred, batch_dict['y_target'])\n        \n        f1_t = transformer_general_utils \\\n            .compute_macro_f1(y_pred, batch_dict['y_target'])\n\n        train_state['batch_preds'].append(y_pred)\n        train_state['batch_targets'].append(batch_dict['y_target'])\n        train_state['batch_indexes'].append(batch_dict['x_index'])\n\n        running_acc += (acc_t - running_acc) / (batch_index + 1)\n        running_f1 += (f1_t - running_f1) / (batch_index + 1)\n\n        train_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n                             epoch=epoch_index)\n\n        train_bar.update()\n\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    train_state['train_accuracies'].append(running_acc)\n    train_state['train_losses'].append(running_loss)\n    \n    train_state['train_preds'].append(\n        torch.cat(train_state['batch_preds']).cpu()\n    )\n    train_state['train_targets'].append(\n        torch.cat(train_state['batch_targets']).cpu()\n    )\n    train_state['train_indexes'].append(\n        torch.cat(train_state['batch_indexes']).cpu()\n    )\n    train_f1 = transformer_general_utils \\\n                .compute_macro_f1(train_state['train_preds'][-1],\n                                  train_state['train_targets'][-1],\n                                 )\n                                 \n    train_state['train_f1s'].append(train_f1)\n    \n    train_state['batch_preds'] = []\n    train_state['batch_targets'] = []\n    train_state['batch_indexes'] = []\n    \n    \n    dataset.set_split('val')\n    batch_generator = generate_image_batches(\n        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n        device = args.device, drop_last=False,\n        pinned_memory = False, n_workers = 2, \n    )\n    eval_bar.reset(\n        total=dataset.get_num_batches(args.batch_size),\n    )\n    running_loss = 0.0\n    running_acc = 0.0\n    running_f1 = 0.0\n    \n    model.eval()\n    with torch.no_grad():\n        optimizer._backup_and_load_cache()\n        for batch_index, batch_dict in enumerate(batch_generator):\n            y_pred = model(batch_dict['x_data'])\n            y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n            loss = loss_func(y_pred, batch_dict['y_target'])\n            loss_t = loss.item()\n            running_loss += (loss_t - running_loss) / (batch_index + 1)\n            y_pred = y_pred.detach().cpu()\n            batch_dict['y_target'] = batch_dict['y_target'].cpu()\n            \n            acc_t = transformer_general_utils\\\n                .compute_accuracy(y_pred, batch_dict['y_target'])\n            f1_t = transformer_general_utils \\\n                .compute_macro_f1(y_pred, batch_dict['y_target'])\n\n            train_state['batch_preds'].append(y_pred.cpu())\n            train_state['batch_targets'].append(batch_dict['y_target'].cpu())\n            train_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n\n            running_acc += (acc_t - running_acc) / (batch_index + 1)\n            running_f1 += (f1_t - running_f1) / (batch_index + 1)\n            \n\n            eval_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n                                 epoch=epoch_index)\n            eval_bar.update()\n            \n    train_state['val_accuracies'].append(running_acc)\n    train_state['val_losses'].append(running_loss)\n    \n        \n    train_state['val_preds'].append(\n        torch.cat(train_state['batch_preds']).cpu()\n    )\n\n    train_state['val_targets'].append(\n        torch.cat(train_state['batch_targets']).cpu()\n    )\n    train_state['val_indexes'].append(\n        torch.cat(train_state['batch_indexes']).cpu()\n    )\n    val_f1 = transformer_general_utils \\\n                .compute_macro_f1(train_state['val_preds'][-1],\n                                  train_state['val_targets'][-1],\n                                 )\n                                 \n    train_state['val_f1s'].append(val_f1)\n    \n    train_state['batch_preds'] = []\n    train_state['batch_targets'] = []\n    train_state['batch_indexes'] = []\n    \n    scheduler.step(val_f1)\n    early_stopping(val_f1, model)\n    optimizer._clear_and_load_backup()\n    epoch_bar.set_postfix( best_f1 = early_stopping.best_score, current = val_f1)\n    epoch_bar.update()    \n    \n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break\n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}