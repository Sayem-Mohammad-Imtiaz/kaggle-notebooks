{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://i.imgur.com/WEqQ4Cn.png)\n\n# Índice\n* [Introducción](#introduccion)\n* [Explicación de Variables](#explicacion-variables)\n* [Visualización de Datos](#visualización-datos)\n    - [Conclusión](#conclusion-datos)\n    - [Análisis de Datos](#analisis-datos)\n* [Selección de Variables](#seleccion-variables)\n* [Normalización de los Datos](#normalizacion-datos) \n* [Clasificadores Vanilla](#clasificadores-vanilla)\n    - [Resultados](#resultados-vanilla)\n        + [Definición de Métricas](#metricas)\n* [Aplicando GridSearch + Cross Validation](#grid-search)\n    - [Clasificadores](#clasificadores-grid)\n    - [Resultados](#resultados-grid)\n* [Aplicando PCA + GridSearch + Cross Validation](#pca)\n    - [Implementando PCA de Scikit-Learn](#implementar-pca)\n    - [Clasificadores](#clasificadores-pca)\n    - [Resultados](#resultados-pca)\n* [Conclusión](#conclusion)\n    - [Tabla de Métricas](#tabla-metricas)\n* [Bibliografía](#bibliografia)\n\n<a id=\"introduccion\"></a>\n# Introducción\n\n## Contexto\n\nEl presente dataset trata sobre un videojuego del género MOBA (multijugador de arena de batalla en línea) denominado **\"League of Legends\"**, abreviado **\"LoL\"**, en donde se enfrentan **2 equipos**, uno azul y otro rojo, en un mapa que contiene **3 carriles y una jungla**, que se encuentra entre los mismos. Cada equipo posee **5 integrantes** y cada uno ocupa un rol particular dentro del mismo, siendo el objetivo el destruir el **\"nexo\"**, un edificio crítico, del otro equipo para ganar la partida.\n\n## Dataset\n\nEspecíficamente, este dataset contiene diferentes estadísticas de los **primeros 10 minutos** de juego de alrededor **10 mil partidas** de jugadores con **\"High Elo\"**, es decir, jugadores que alcanzaron un nivel alto dentro de la clasificación del juego. \n\n## Objetivo\n\nLa columna **'blueWins'** es el valor objetivo (el valor que estamos tratando de predecir). Un valor de 1 significa que el equipo azul ganó partida, por otro lado, un valor de 0 indica que el equipo azul perdió.","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# Importamos algunas librerías que vamos a utilizar a lo largo de este trabajo.\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Importamos el dataset previamente descrito.\npath = \"../input/league-of-legends-diamond-ranked-games-10-min\"\n\ndf = pd.read_csv(path + \"/high_diamond_ranked_10min.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como no nos va a servir para el análisis de los datos, eliminamos la siguiente columna:\n* **'gameId':** identificador único utilizado en la API del juego para acceder a los datos específicos de una partida.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Eliminamos la columna 'gameId'\ndf = df.drop('gameId',  axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez quitadas las columnas redundantes e innecesarias, una buena práctica es generar una matriz de correlación. Esta matriz nos permitirá conocer el grado de correlación que existe entre las diferentes variables que pueblan el dataset. Pero...\n\n### Qué significa esto? \n\nLa matriz de correlación muestra los **valores de correlación de Pearson**, que miden el grado de relación lineal entre cada par de elementos o variables. Los valores de correlación se pueden ubicar entre -1 y +1. Sin embargo, en la práctica, los elementos por lo general tienen correlaciones positivas. Si los dos elementos tienden a aumentar o disminuir al mismo tiempo, el valor de correlación es positivo.\n\n#### Interpretación\n\n**Se utiliza la matriz de correlación para evaluar la fuerza y dirección de la relación entre dos variables.** Un valor de correlación alto y positivo indica que los elementos miden la misma destreza o característica. Si los elementos no están altamente correlacionados, entonces los elementos pudieran medir diferentes características o no estar claramente definidos.\n\n### Aplicado a nuestro caso\n\nPor lo tanto, aplicaremos la matriz de correlación para observar que variables del dataset son candidatas a salir del modelo, ya que explican o miden las mismas características. Esto lo realizaremos con el siguiente código:","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nsns.heatmap(round(df.corr(),1), cmap=\"coolwarm\", annot=True, linewidths=.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusión de Matriz de Correlación\n\nComo podemos observar en la matriz, existen variables que están altamente correlacionadas, es decir, explican las mismas cosas. Por lo tanto, no ayudan a clasificar mejor, si no que muestran los mismos datos que otra columna. Esto ocurre, por ejemplo, con las columnas:\n* **\"RedKills\":** cantidad de asesinatos del equipo rojo.\n* **\"BlueDeaths\":** cantidad de muertes del equipo azul.\nLa cantidad de asesinatos del equipo rojo son la cantidad de muertes que tiene el equipo azul. Por lo tanto, lo acertado seria eliminar una columna, ya que una explica la otra.\n> _**Aclaración:** dentro del juego, un jugador puede morir sin haber sido asesinado por un miembro del otro equipo, es decir, no sumaría a la cantidad de kills, como por ejemplo, morir a causa de un **\"monstruo neutral\"**. Sin embargo, estamos hablando de partidas de **\"high elo\"**, en otras palabras, partidas con jugadores poseen un nivel muy alto de juego, por lo que es poco probable que ocurra. Cosas como estas deberian ser tomadas en cuenta para la selección de variables._\n\n<a id=\"explicacion-variables\"></a>\n# Explicación de Variables\n\n## Principales variables dentro del Juego\n\n### Experiencia\n\nDentro de **League of Legends** los jugadores utilizan a personajes, denominados **\"campeones\"**, los cuales poseen un nivel y determinadas habilidades y estadísticas. Un personaje puede subir de nivel obteniendo experiencia, y hacerlo le permite mejorar sus habilidades y stats, lo que le otorga una ventaja frente al enemigo.\n\n### Oro\n\nPor otro lado, tenemos el oro, que es único en la partida y se usa para comprar objetos. Estos últimos permiten a los personajes incrementar aún más sus estadísticas, así como obtener habilidades especiales.\n\n## Como obtenerlos?\n\nSe obtiene experiencia y oro asesinando o destruyendo diferentes objetos dentro del juego, como son:\n* **Creeps:** NPCs que pertenecen a ambos equipos. Dan oro cuando los jugadores los matan.\n* **Mostruos de Elite:** Monstruos con alto HP (Health Points) y daño que otorgan una bonificación masiva de oro, XP y estadísticas cuando son asesinados por un equipo, estos son:\n    * Dragones: Monstruo de élite que otorga bonificaciones al equipo cuando es asesinado. El 4to dragón asesinado por un equipo otorga una bonificación de estadísticas masivas. El 5to dragón (Elder Dragon) ofrece una gran ventaja para el equipo.\n    * Heraldos: Monstruo de élite que otorga bonificación de estadísticas cuando es asesinado por un jugador. Ayuda a empujar un carril y destruye estructuras.\n* **Jungle Creeps:** NPCs que no pertenecen a NINGÚN EQUIPO. Dan oro y experiencia cuando los jugadores los matan.\n* **Estructuras enemigas:** Se deben destruir para llegar al \"Nexo\" enemigo. Otorgan oro al ser destruidas. Estas estructuras son:\n    * Torres\n    * Inhibidores.\n* **Campeones enemigos:** personajes del juego utulizados por los miembros del equipo opuesto.\n* **Wards:** Elemento que un jugador puede poner en el mapa para revelar el área cercana. Muy útil para el control de mapas y objetivos, ya que la visibilidad se ve afectada por la **“niebla de guerra”.**\n\n<a id=\"visualización-datos\"></a>\n# Visualización de Datos\n\nPara ver de una manera más clara que variables contribuyen menos o mas a la victoria del equipo azul, podemos realizar diferentes gráficos y observar como están distribuidos los datos:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"data = df\nsns.set(font_scale=1.5)\n\nplt.figure(figsize=(20,20))\nsns.set_style(\"whitegrid\")\n\n# Cantidad de kills de cada equipo\nplt.subplot(321)\nsns.scatterplot(x='blueKills', y='redKills', hue='blueWins', data=data)\nplt.title('KILLS totales de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.grid(True)\n\n# Cantidad de asistencias de cada equipo\nplt.subplot(322)\nsns.scatterplot(x='blueAssists', y='redAssists', hue='blueWins', data=data)\nplt.title('ASISTENCIAS totales de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de oro de cada equipo\nplt.subplot(323)\nsns.scatterplot(x='blueTotalGold', y='redTotalGold', hue='blueWins', data=data)\nplt.title('ORO total de de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de experiencia de cada equipo\nplt.subplot(324)\nsns.scatterplot(x='blueTotalExperience', y='redTotalExperience', hue='blueWins', data=data)\nplt.title('EXPERIENCIA total de de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Cantidad total de Wards colocadas por cada equipo\nplt.subplot(325)\nsns.scatterplot(x='blueWardsPlaced', y='redWardsPlaced', hue='blueWins', data=data)\nplt.title('WARDs totales colocadas de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\n# Juntamos la cantidad total de minions por equipo\ndata['blueMinionsTotales'] = df['blueTotalMinionsKilled'] + df['blueTotalJungleMinionsKilled']\ndata['redMinionsTotales'] = df['redTotalMinionsKilled'] + df['redTotalJungleMinionsKilled']\n\n# Total de minions asesinados por cada equipo\nplt.subplot(326)\nsns.scatterplot(x='blueMinionsTotales', y='redMinionsTotales', hue='blueWins', data=data)\nplt.title('MINIONs totales asesinados de cada equipo')\nplt.xlabel('Equipo Azul')\nplt.ylabel('Equipo Rojo')\nplt.tight_layout(pad=1.5)\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion-datos\"></a>\n## Conclusión de visualización de datos\n\nDe los gráficos previamente visualizados podemos decir que:\n* A mayor cantidad de **kills** y **asistencias totales** se incrementan las posibilidades de ganar.\n* Esto también se verifica con la cantidad total de **experiencia** y **oro** por equipo, ya que a mayor cantidad de **kills** y **asistencias totales**, mayor cantidad de los primeros valores. La tendencia dice que mientras más **experiencia** y **oro** tenga un equipo, mayores serán sus posibilidades de ganar.\n* Las **wards** totales colocadas por equipo no parecen afectar tanto la posibilidad de que un equipo gane como las variables anteriores.\n* Lo mismo se repite con los **minions totales asesinados** por equipo.\n\n### Diferencias de Oro y Experiencia de un equipo\n\nPara ver de una manera más explícita como contribuyen la **experiencia** y el **oro** a la victoria de un equipo podemos graficar la diferencia de estos valores en cada equipo:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.set_style(\"whitegrid\")\n\n# Diferencia de experiencia y oro\nplt.subplot(311)\nsns.scatterplot(x='blueExperienceDiff', y='blueGoldDiff', hue='blueWins', data=data)\nplt.title('Diferencia de ORO y EXPERIENCIA ')\nplt.xlabel('Diferencia de Experiencia')\nplt.ylabel('Diferencia de Oro')\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"analisis-datos\"></a>\n## Análisis de Datos\n\n### Oro y Experiencia\n\nSiguiendo estas explicaciones, podemos deducir que:\n\n> _A mayor cantidad de **kills** y **asistencias**_ 🡲 _Mayor cantidad de oro y experiencia para el equipo_ \n\n> _A mayor cantidad de **oro** y **experiencia**_ 🡲 _Mayor ventaja sobre el equipo enemigo_ 🡲 _Mayor probabilidad de ganar la partida_\n\nPor lo tanto, podemos decir que el **oro** y la **experiencia** que posee un equipo respecto del otro, son variables **influyen enormemente** en las posibilidades de un equipo de ganar.  \n\n### Dragones y Heraldos\n\nComo se había descrito anteriormente, estos **monstruos de elite** otorgan **oro** y **experiencia** al equipo que los destruya, aunque también otorgan estadísticas permanentes que se van acumulando y potenciando a medida que el equipo destruya más, por lo que son un objetivo prioritario.\n\n> _A mayor cantidad de **dragones** y **heraldos** asesinados_ 🡲 _Mejores estadísticas para el equipo_ 🡲 _Mayor probabilidad de ganar la partida_\n\n### Torretas\n\nLas torretas, asi como los inhibidores, son estructuras criticas que el equipo debe destruir si quiere ganar la partida. Ademas de que otorgan **oro** y **experiencia**.\n\n### Wards\n\nComo se observaban en los gráficos de las variables, la cantidad de **wards** colocadas no tienen un impacto muy grande dentro de lo que son las probabilidades de un equipo de ganar.\n\n<a id=\"seleccion-variables\"></a>\n# Selección de Variables\n\nDadas las conclusiones obtenidas en el apartado de análisis de datos, luego de haber observado los gráficos, incluiremos las siguientes variables dentro del modelo, ya que son las que mas afectan las posibilidades de un equipo de ganar:\n* **Diferencia de Kills.**\n* **Diferencia de Asistencias.**\n* **Diferencia de Heraldos.**\n* **Diferencia de Dragones.**\n* **Diferencia de Torres Destruidas.**\n* **Diferencia de Oro.**\n* **Diferencia de Experiencia.**","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Generamos las columnas de datos que vamos a utilizar de acuerdo a lo propuesto anteriormente.\ndf['blueKillsDiff'] = df['blueKills'] - df['redKills']\ndf['blueAssistsDiff'] = df['blueAssists'] - df['redAssists']\ndf['blueHeraldsDiff'] = df['blueHeralds'] - df['redHeralds']\ndf['blueDragonsDiff'] = df['blueDragons'] - df['redDragons']\ndf['blueTowersDestroyedDiff'] = df['blueTowersDestroyed'] - df['redTowersDestroyed']\n\n# Asignamos las columnas previamente generadas en una tabla nueva lista para ser usada por los clasificadores.\nX = df[['blueKillsDiff', 'blueAssistsDiff', 'blueHeraldsDiff', 'blueDragonsDiff', \n        'blueTowersDestroyedDiff', 'blueGoldDiff', 'blueExperienceDiff']]\n\n# Asignamos la variable objetivo.\ny = df['blueWins']\n\n# Imprimimos la tabla\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"normalizacion-datos\"></a>\n# Normalización de los datos\n\nDado que existe una gran variación dentro del dataset en los valores que pueden tomar las diferentes variables, procederemos a normalizar los datos. Normalizar significa, en este caso, comprimir o extender los valores de la variable para que estén en un rango definido.\n\n## Escalado Estándar (Standard Scaler)\n\nEn este caso, utilizaremos el **Escalado Estándar**, en donde a cada dato se le resta la **media** de la variable y se le divide por la **desviación típica**, segun la siguiente formula:\n\n$$Xnormalized = \\frac{X - Xmean}{Xstddev}$$","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\nfrom prettytable import PrettyTable\n\n# Creamos la tabla que nos permitirá mostrar las métricas obtenidas.\nmetricas = PrettyTable()\nmetricas.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisión']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusión del trabajo.\nresultados = []\n\n# Normalizamos los datos\nX = StandardScaler().fit(X).transform(X)\n\n# Asignamos los valores de entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"clasificadores-vanilla\"></a>\n# Clasificadores Vanilla\n\nEn primer lugar, utilizaremos los siguientes clasificadores usando los parámetros que vienen por defecto:\n* Regresión Logística.\n* K-Nearest Neighbours.\n* Decision Tree.\n* Random Forest.\n\n## Regresión Logística\n\n### Definición\n\nEs un tipo de análisis de regresión utilizado para predecir el resultado de una variable categórica (una variable que puede adoptar un número limitado de categorías) en función de las variables independientes o predictoras. Es útil para modelar la probabilidad de un evento ocurriendo como función de otros factores. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Instanciamos el clasificador\nLR = LogisticRegression()\n\n# Hacemos fit a los datos y realizamos la predicción.\ny_pred = LR.fit(X_train, y_train).predict(X_test)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nLR_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Regresión Logística', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Nearest Neighbours\n\n### Definición\n\nEs un algoritmo usado como método de clasificación de elementos, basado en un entrenamiento mediante ejemplos cercanos en el espacio que existe entre estos.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# Instanciamos el clasificador\nKNN = KNeighborsClassifier()\n\n# Hacemos fit a los datos y realizamos la predicción.\ny_pred = KNN.fit(X_train, y_train).predict(X_test)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nKNN_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree\n\n### Definición\n\nDado un conjunto de datos, se fabrican diagramas de reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resolución de un problema.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Instanciamos el clasificador\nDT = DecisionTreeClassifier()\n\n# Hacemos fit a los datos y realizamos la predicción.\ny_pred = DT.fit(X_train, y_train).predict(X_test)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nDT_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Decision Tree', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest\n\n### Definición\n\nEs una combinación de árboles de decisión tal que cada árbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribución para cada uno de estos.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Instanciamos el clasificador\nRF = RandomForestClassifier()\n\n# Hacemos fit a los datos y realizamos la predicción.\ny_pred = RF.fit(X_train, y_train).predict(X_test)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nprecision = precision_score(y_test,y_pred)\nRF_confusion_matrix = confusion_matrix(y_test,y_pred)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas.add_row(['Random Forest', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resultados-vanilla\"></a>\n## Resultados\n\n<a id=\"metricas\"></a>\n### Métricas \n\n* **Accuracy (Exactitud):** Es el porcentaje total de elementos clasificados correctamente. Es la medida más directa de la calidad de los clasificadores. Es un valor entre 0 y 1. Cuanto más alto, mejor.\n\n* **Recall (Tasa de True Positive):** Es el número de elementos identificados correctamente como positivos del total de positivos verdaderos.\n\n* **Precision:** Es el número de elementos identificados correctamente como positivo de un total de elementos identificados como positivos.\n\n* **Confusion Matrix (Matriz de Confusión):** Es una tabla que describe el rendimiento de un modelo supervisado de Machine Learning en los datos de prueba, donde se desconocen los verdaderos valores.","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Imprimimos el título de la tabla.\nprint(\"Clasificadores Vanilla (Ordenados por Exactitud)\")\n\n# Ordenamos la tabla por la columna \"Exactitud\"\nmetricas.sortby = \"Exactitud\"\n\n# Colocamos las filas en orden descendiente.\nmetricas.reversesort = True\n\n# Imprimimos la tabla\nprint(metricas)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Matrices de Confusión","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\n# Ploteamos la matriz de confusión de la 'Regresión Logistica'\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresión Logistica')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusión de la 'K-Nearest Neighbours'\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusión de la 'Decision Tree'\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\n# Ploteamos la matriz de confusión de la 'Random Forest'\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"grid-search\"></a>\n# Aplicando GridSearch + Cross Validation\n\n## GridSearchCV\n\nEs una clase disponible en **scikit-learn** que permite evaluar y seleccionar de forma sistemática los parámetros de un modelo. Indicándole un modelo y los parámetros a probar, puede evaluar el rendimiento del primero en función de los segundos mediante validación cruzada. \n\n## Validación Cruzada\n\nAl hacer uso de esta tecnica, el conjunto de datos de entrenamiento se divide en grupos de igual tamaño. Una vez realizada la partición se procede a entrenar el modelo una vez por cada uno de los grupos. Utilizando todos los grupos menos el de la iteración para entrenar y este para validar los resultados. Como se aprecia en al siguiente imagen:\n\n![](https://www.analyticslane.com/wp-content/uploads/2018/07/validacion_cruzada.jpeg.webp)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importamos la clase de scikit-learn\nfrom sklearn.model_selection import GridSearchCV\n\n# Creamos la tabla que nos permitirá mostrar las métricas obtenidas.\nmetricas_grid_search = PrettyTable()\nmetricas_grid_search.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisión']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusión del trabajo.\nresultados_grid_search = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"clasificadores-grid\"></a>\n## Clasificadores\n\n### Regresión Logística","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'penalty': ['l1', 'l2'],\n               'C':[.001,.009,0.01,.09,1,2,3,4,5,7,10,25],\n               'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n               'fit_intercept' : [True, False]}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(LogisticRegression(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nLR_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Regresión Logística', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbours","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {\"n_neighbors\": [3, 4, 5, 6, 7],\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(KNeighborsClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nKNN_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_depth': np.arange(1, 21),\n               'min_samples_leaf': [1, 5, 10, 20, 50, 100]}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nDT_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Decision Tree', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_features': ['auto', 'sqrt', 'log2'],\n                'max_depth' : [4, 5, 6, 7, 8],\n                'criterion' :['gini', 'entropy']}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(RandomForestClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nRF_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_grid_search.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_grid_search.add_row(['Random Forest', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resultados-grid\"></a>\n## Resultados\n\n### Métricas","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Clasificadores con GridSearchCV (Ordenados por Exactitud)\")\nmetricas_grid_search.sortby = \"Exactitud\"\nmetricas_grid_search.reversesort = True\nprint(metricas_grid_search)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Matrices de Confusión","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresión Logistica')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"pca\"></a>\n# Aplicando PCA + GridSearch + Cross Validation\n\n## Análisis de Componentes Principales (PCA)\n\nEs una técnica de selección de características, que utiliza una transformación ortogonal para convertir un conjunto de observaciones de variables, posiblemente correlacionadas, en un conjunto más reducido de variables que ya no guardan correlación y que se conocen como **componentes principales**. \n\nAl realizar este análisis, intentamos buscar cuantos parámetros mínimos son necesarios para explicar una cantidad significativa de variación en los datos, es decir, valorar cuánta información nos podemos permitir descartar al eliminar ciertos parámetros y, de esta manera, obtener un modelo más rápido y eficiente. \n\nEn este caso, podemos deconstruir un conjunto de datos en:\n* **Autovectores:** es una dirección.\n* **Autovalores:**: es un número que representa el valor de la varianza en esa dirección.\n\nPor lo tanto, el componente principal será el autovector con mayor autovalor. En un conjunto de datos hay tantas parejas autovector/autovalor como dimensiones. \n\n### Aplicado a nuestro caso\n\nEn nuestro caso en específico, tenemos 7 dimensiones, dadas por cada uno de los features que hemos elegido previamente. Por lo que vamos a proceder a calcular los **autovalores** y **autovectores** de los datos, ver cuanta covarianza explica cada uno y, de esta manera, buscar reducir la dimensionalidad del conjunto de datos para obtener un modelo más rápido, eficiente y con la mínima perdida de información posible.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calculamos la matriz de covarianza\nmatriz_covarianza = np.cov(X.T)\n\n# Calculamos los autovalores y autovectores de la matriz\nauto_valores, auto_vectores = np.linalg.eig(matriz_covarianza)\n                                  \n# A partir de los autovalores, calculamos la varianza explicada individual y la acumulada\ntotal = sum(auto_valores)\nvarianza_explicada = [(i / total) * 100 for i in sorted(auto_valores, reverse=True)]\nvarianza_explicada_acumulada = np.cumsum(varianza_explicada)\n\n# Graficamos la varianza explicada por cada autovalor, y la acumulada\nplt.figure(figsize=(20,10))\n\nplt.bar(range(7), varianza_explicada, alpha=0.5, align='center',label='Varianza individual explicada', color='b')\nplt.step(range(7), varianza_explicada_acumulada, where='mid', linestyle='-', label='Varianza explicada acumulada', color='r')\nplt.ylabel('Varianza Explicada')\nplt.xlabel('Componentes Principales')\nplt.legend(loc='best')\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluación del Gráfico\n\nComo podemos advertir en el grafico anterior, las primeras 4 componentes explican, por lo menos, el 90% de la varianza de los datos. Por lo que procederemos a reducir la dimensionalidad de los datos utilizando estas 4 componentes.\n\n<a id=\"implementar-pca\"></a>\n## Implementando PCA de Scikit-Learn","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importamos la clase de scikit-learn\nfrom sklearn.decomposition import PCA\n\n# Creamos la tabla que nos permitirá mostrar las métricas obtenidas.\nmetricas_pca = PrettyTable()\nmetricas_pca.field_names = ['Clasificador', 'Exactitud', 'Recall', 'Precisión']\n\n# Guardaremos los resultados en un vector para ser mostrados en la conclusión del trabajo.\nresultados_pca = []\n\n# Instanciamos una clase de PCA indicandole que utilizaremos 4 componentes principales\npca = PCA(n_components = 4)\nX_PCA = pca.fit(X).transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"clasificadores-pca\"></a>\n## Clasificadores\n\n### Regresión Logística","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'penalty': ['l1', 'l2'],\n               'C':[.001,.009,0.01,.09,1,2,3,4,5,7,10,25],\n               'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n               'fit_intercept' : [True, False]}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(LogisticRegression(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nLR_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Regresión Logística', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbours","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {\"n_neighbors\": [3, 4, 5, 6, 7],\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(KNeighborsClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nKNN_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['K-Nearest Neighbours', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_depth': np.arange(1, 21),\n               'min_samples_leaf': [1, 5, 10, 20, 50, 100]}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nDT_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Decision Tree', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Colocamos los valores de parámetros que queremos que GridSearchCV pruebe por nosotros\ngrid_values = {'max_features': ['auto', 'sqrt', 'log2'],\n                'max_depth' : [4, 5, 6, 7, 8],\n                'criterion' :['gini', 'entropy']}\n\n# Instanciamos la clase con los parámetros previamente asignados\ngrid_clf_acc = GridSearchCV(RandomForestClassifier(), param_grid = grid_values, scoring = 'accuracy', verbose=False, n_jobs=-1)\n\n# Seleccionamos la tabla entera, ya que el método se encargará de realizar la técnica de Cross-Validation\ngrid_clf_acc.fit(X_PCA, y)\n\n# Imprimimos los mejores parámetros seleccionados por GridSearchCV\nprint(\"Parámetros elegidos: \" + str(grid_clf_acc.best_params_) + \"\\n\")\n\n# Predecimos los valores\ny_pred_acc = grid_clf_acc.predict(X_PCA)\n\n# Métricas de evaluación\nexactitud = accuracy_score(y,y_pred_acc)\nrecall = recall_score(y,y_pred_acc)\nprecision = precision_score(y,y_pred_acc)\nRF_confusion_matrix = confusion_matrix(y,y_pred_acc)\n\n# Anexamos los resultados para ser mostrados posteriormente\nresultados_pca.append(exactitud)\n\n# Formateamos los datos para mostrarlos como % en la tabla.\nexactitud = str(round(exactitud * 100, 2)) + \" %\"\nrecall = str(round(recall * 100, 2)) + \" %\"\nprecision = str(round(precision * 100, 2)) + \" %\"\n\nmetricas_pca.add_row(['Random Forest', exactitud, recall, precision])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resultados-pca\"></a>\n## Resultados\n\n### Métricas ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Clasificadores con PCA + GridSearch + Cross Validation (Ordenados por Exactitud)\")\nmetricas_pca.sortby = \"Exactitud\"\nmetricas_pca.reversesort = True\nprint(metricas_pca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Matrices de Confusión","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(221)\nsns.heatmap(LR_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Regresión Logistica')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(222)\nsns.heatmap(KNN_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('K-Nearest Neighbours')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(223)\nsns.heatmap(DT_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Decision Tree')\nplt.tight_layout(pad=1.5)\n\nplt.subplot(224)\nsns.heatmap(RF_confusion_matrix, cmap=\"coolwarm\", fmt=\".0f\",annot=True, linewidths=.5, annot_kws={\"size\": 16})\nplt.xlabel(\"Prediccion\")\nplt.ylabel(\"Verdadero\")\nplt.title('Random Forest')\nplt.tight_layout(pad=1.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion\"></a>\n# Conclusión","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nsns.set_style(\"whitegrid\")\n\nmodelos = [\"Regresión Logística\", \"K-Nearest Neighbours\", \"Decision Tree\", \"Random Forest\"]\ngrafico_resultados = pd.DataFrame({\"Puntuación\": resultados, \"Modelos\": modelos})\ngrafico_resultados_grid_search = pd.DataFrame({\"Puntuación\": resultados_grid_search, \"Modelos\": modelos})\ngrafico_resultados_pca = pd.DataFrame({\"Puntuación\": resultados_pca, \"Modelos\": modelos})\n\nplt.subplot(311)\nsns.barplot(\"Puntuación\", \"Modelos\", data = grafico_resultados)\nplt.ylabel(\"\")\nplt.title('Clasificadores Vanilla')\nplt.tight_layout(pad=2)\n\nplt.subplot(312)\nsns.barplot(\"Puntuación\", \"Modelos\", data = grafico_resultados_grid_search)\nplt.ylabel(\"\")\nplt.title('Clasificadores con GridSearch + Cross Validation')\nplt.tight_layout(pad=2)\n\nplt.subplot(313)\nsns.barplot(\"Puntuación\", \"Modelos\", data = grafico_resultados_pca)\nplt.title('Clasificadores con PCA + GridSearch + Cross Validation')\nplt.ylabel(\"\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observación de los Gráficos\n\nGracias a los graficos previos, podemos observar que:\n* La **Regresión Logística** tiene una mayor exactitud si lo comparamos al resto de clasificadores utilizando los parámetros por defecto.\n* Cuando aplicamos **Grid Search** y **PCA**, podemos observar que el algoritmo de **KNN** tiende a precedir mejor los resultados que el resto de los métodos.\n* Tambien podemos notar que los demás metodos, como son **Decision Tree** y **Random Forest**, que antes tenian un porcentaje de exactitud menor, han aumentado dicha metrica y se han colocado por encima del algoritmo que antes se encontraba liderando, es decir, la **Regresión Logística.**\n\n<a id=\"tabla-metricas\"></a>\n## Tabla de Métricas","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"metricas.sortby = \"Clasificador\"\nmetricas_grid_search.sortby = \"Clasificador\"\nmetricas_pca.sortby = \"Clasificador\"\n\nprint(\"Clasificadores Vanilla\")\nprint(metricas)\nprint(\"\")\nprint(\"Clasificadores con GridSearch + Cross Validation\")\nprint(metricas_grid_search)\nprint(\"\")\nprint(\"Clasificadores con PCA + GridSearch + Cross Validation\")\nprint(metricas_pca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"bibliografia\"></a>\n# Bibliografía\n\n## Uso de Herramientas y Clasificadores\n\n* [matplotlib](https://matplotlib.org/3.2.1/api/index.html)\n* [numpy](https://numpy.org/doc/1.18/reference/index.html)\n* [pandas](https://pandas.pydata.org/docs/reference/frame.html)\n* [seaborn](https://seaborn.pydata.org/api.html)\n* [scikit-learn](https://scikit-learn.org/stable/modules/classes.html)\n\n## Conceptos Teoricos\n* [Concepto y uso de GridSearchCV](https://www.analyticslane.com/2018/07/02/gridsearchcv/)\n* [Matriz de Correlación](https://support.minitab.com/es-mx/minitab/18/help-and-how-to/modeling-statistics/multivariate/how-to/item-analysis/interpret-the-results/all-statistics-and-graphs/)\n* [Matriz de Confusión](https://empresas.blogthinkbig.com/ml-a-tu-alcance-matriz-confusion/)\n* [GitHub de la cátedra](https://github.com/inteligenciafrvm/inteligenciafrvm)\n* [Normalización de los datos](https://empresas.blogthinkbig.com/precauciones-la-hora-de-normalizar/)\n* [Métricas de Clasificación](https://sitiobigdata.com/2019/01/19/machine-learning-metrica-clasificacion-parte-3/#)\n* [Análisis de Componentes Principales (PCA)](https://empresas.blogthinkbig.com/python-para-todos-que-es-el-pca/)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}