{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n## Bank Customer Churn Prediction\n\nIn this kernel I am going to make an Exploratory Data Analysis (EDA) on this dataset. Also I am going to make different predictive models and find out the best one with highest prediction accuracy.\n\n\n**Kernel Outlines:**\n\n*     Importing Necessary Packages\n*     Statistical Summary of the Dataset\n*     Dropping Irrelevant Features\n*     One Hot Encoding\n*     Data Visualization\n*     Detecting Outliers using Tukey Boxplot\n*     Hand written function for detecting and removing outliers\n*     Checking Correlation with Heatmap\n*     Different ML predictive models\n*         Gaussian Naive Bayes\n*         Logistic Regression\n*         Decision Tree\n*         Random Forest\n*         Extra Gradient Boosting Tree (XGBoost)\n*     Improve the Predictive Model\n*         Feature Scaling\n*         Over Sampling\n\n#### Importing Necessary Packages\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport keras\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(palette=\"Set2\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (accuracy_score, f1_score,average_precision_score, confusion_matrix,\n                             average_precision_score, precision_score, recall_score, roc_auc_score, )\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n\n\nfrom xgboost import XGBClassifier, plot_importance\nfrom imblearn.over_sampling import SMOTE\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read dataset\ndataset = pd.read_csv(\"/kaggle/input/deep-learning-az-ann/Churn_Modelling.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Gender\", data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking datatypes and null values\ndataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nDropping Irrelevant FeatureÂ¶\n\n`RowNumber`, `CustomerId` and `Surname` are irrelivant, so we drop those features.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(1, 3, figsize=(18, 6))\nplt.subplots_adjust(wspace=0.3)\nsns.countplot(x = \"NumOfProducts\", hue=\"Exited\", data = dataset, ax= ax[0])\nsns.countplot(x = \"HasCrCard\", hue=\"Exited\", data = dataset, ax = ax[1])\nsns.countplot(x = \"IsActiveMember\", hue=\"Exited\", data = dataset, ax = ax[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n**Customer with 3 or 4 products are higher chances to Churn\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(1, 3, figsize=(18, 6))\nplt.subplots_adjust(wspace=0.3)\nsns.swarmplot(x = \"NumOfProducts\", y = \"Age\", hue=\"Exited\", data = dataset, ax= ax[0])\nsns.swarmplot(x = \"HasCrCard\", y = \"Age\", data = dataset, hue=\"Exited\", ax = ax[1])\nsns.swarmplot(x = \"IsActiveMember\", y = \"Age\", hue=\"Exited\", data = dataset, ax = ax[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\ndataset[\"Geography\"] = encoder.fit_transform(dataset[\"Geography\"])\ndataset[\"Gender\"] = encoder.fit_transform(dataset[\"Gender\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Age\"].value_counts().plot.bar(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(dataset, hue=\"Exited\", aspect=3)\nfacet.map(sns.kdeplot,\"Age\",shade= True)\nfacet.set(xlim=(0, dataset[\"Age\"].max()))\nfacet.add_legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax =  plt.subplots(1, 2, figsize=(15, 7))\ncmap = sns.cubehelix_palette(light=1, as_cmap=True)\nsns.scatterplot(x = \"Age\", y = \"Balance\", hue = \"Exited\", cmap = cmap, sizes = (10, 200), data = dataset, ax=ax[0])\nsns.scatterplot(x = \"Age\", y = \"CreditScore\", hue = \"Exited\", cmap = cmap, sizes = (10, 200), data = dataset, ax=ax[1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n*         **40 to 70 years old customers are higher chances to churn**\n*         **Customer with CreditScore less then 400 are higher chances to churn**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.swarmplot(x=\"HasCrCard\",y = \"Age\", data=dataset, hue=\"Exited\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(dataset, hue=\"Exited\",aspect=3)\nfacet.map(sns.kdeplot,\"Balance\",shade= True)\nfacet.set(xlim=(0, dataset[\"Balance\"].max()))\nfacet.add_legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(1, 2, figsize=(15, 6))\nsns.scatterplot(x = \"Balance\", y = \"Age\", data = dataset, hue=\"Exited\", ax = ax[0])\nsns.scatterplot(x = \"Balance\", y = \"CreditScore\", data = dataset, hue=\"Exited\", ax = ax[1])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(dataset, hue=\"Exited\",aspect=3)\nfacet.map(sns.kdeplot,\"CreditScore\",shade= True)\nfacet.set(xlim=(0, dataset[\"CreditScore\"].max()))\nfacet.add_legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Detecting Outliers using Tukey Boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nbplot = dataset.boxplot(patch_artist=True)\nplt.xticks(rotation=90)       \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(11,8))\nsns.heatmap(dataset.corr(), annot=True, cmap=\"RdYlBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction with ML models:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.drop(\"Exited\", axis=1)\ny = dataset[\"Exited\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GaussianNB()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(pred,y_test )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = tree.DecisionTreeClassifier()\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(pred,y_test )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators = 200, random_state=200)\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(pred,y_test, color=\"red\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf  = XGBClassifier(max_depth = 10,random_state = 10, n_estimators=220, eval_metric = 'auc', min_child_weight = 3,\n                    colsample_bytree = 0.75, subsample= 0.9)\n\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\naccuracy_score(pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(pred,y_test, color=\"red\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler() \n\nbumpy_features = [\"CreditScore\", \"Age\", \"Balance\",'EstimatedSalary']\n\ndf_scaled = pd.DataFrame(data = X)\ndf_scaled[bumpy_features] = scaler.fit_transform(X[bumpy_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_scaled\nsm  = SMOTE(random_state=42)\nX_res, y_res = sm.fit_sample(X, y)\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size= 0.2, random_state=7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = XGBClassifier(max_depth = 12,random_state=7, n_estimators=100, eval_metric = 'auc', min_child_weight = 3,\n                    colsample_bytree = 0.75, subsample= 0.8)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1:\", f1_score(y_test, y_pred))\nprint(\"Area under precision (AUC) Recall:\", average_precision_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #Confusion Matrix\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting data into Train, DEV, test\nfrom sklearn.model_selection import train_test_split\ny=dataset.Exited # pulling values into another array so that we can drop\nX=dataset.drop(['Exited'],axis='columns')\nX_train, X_Dev, y_train, y_Dev = train_test_split(X,y,test_size=0.3,random_state=0,shuffle=False)\nX_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=0.2,random_state=0,shuffle=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#[Train] divide train data into categories , numerical and binary\n\nbinary_columns=[\"HasCrCard\",\"IsActiveMember\"]\nbinary_df=pd.DataFrame(X_train[binary_columns])\n\nnumerical_columns =[\"CreditScore\",\"Age\",\"Tenure\",\"Balance\",\"NumOfProducts\",\"EstimatedSalary\"]\nnumerical_df=pd.DataFrame(X_train[numerical_columns])\n\ncategory_columns=['Geography','Gender']\ncategory_df=pd.DataFrame(X_train[category_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#[TRAIN] Encode Categorical Data\n\ncategory_df['Geography'] = category_df['Geography'].astype('category')\ncategory_df['Gender'] = category_df['Gender'].astype('category')\ncategory_df_Final = pd.get_dummies(category_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#[TRAIN] feature scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nnumerical_df_train_mean=numerical_df.mean()\nnumerical_df_train_std=numerical_df.std(axis=0)\nnumerical_df_scale =pd.DataFrame(scaler.fit_transform(numerical_df),columns=numerical_columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# [TRAIN] Concatenate Columns\nX_train = pd.concat([numerical_df_scale, category_df_Final,binary_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#is there any NULL row ?\ndataset.isnull().any().any(), dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df = dataset.copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#customers churn \nchurn= dataset[dataset[\"Exited\"]==1]\n#customers retention\nretention = dataset[dataset[\"Exited\"]==0]\n\nprint (\"Total Churn          :\", len(churn))\nprint (\"Total Retention      :\", len(retention))\n## return total length \"size\"\ntotal= len(dataset)\nprint (\"Churn Rate           :\",round((float(len(churn)) / float(total))*100,2),\"%\" )\nprint (\"Retention Rate       :\",(float(len(retention)) / float(total))*100,\"%\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Churn By Gender\nfemale = churn[churn['Gender']=='Female']\nmale   = churn[churn['Gender']=='Male']\nprint (\"Feramle Churn     :\",round((float(len(female)) / float(len(churn)))*100,2),\"%\" )\nprint (\"Male Churn        :\",round((float(len(male)) / float(len(churn)))*100,2),\"%\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nX = dataset.drop(\"Exited\",axis = 1)\ny = dataset['Exited']\nsm  = SMOTE(random_state=42)\nX_res, y_res = sm.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size= 0.2, random_state=7)\nprint(\"The split of the under_sampled data is as follows\")\nprint(\"X_train: \", len(X_train))\nprint(\"X_test: \", len(X_test))\nprint(\"y_train: \", len(y_train))\nprint(\"y_test: \", len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\n\nmodel = xgb.XGBClassifier(max_depth = 12,random_state=7,n_estimators=100,eval_metric = 'auc' ,min_child_weight = 3\n                          ,colsample_bytree = 0.75, subsample= 0.8)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))\nprint(\"F1:\", f1_score(y_test, y_pred))\nprint(\"Area under precision Recall:\", average_precision_score(y_test, y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plot_confusion_matrix(conf_mat=cm)\nplt.title(\"The Confusion Matrix\")\nplt.ylabel(\"Actual\")\nplt.xlabel(\"Predicted\")\nplt.show()\nprint(\"The Accuracy is : \"+str((float(cm[1,1])+float(cm[0,0]))/(float(cm[0,0]) + float(cm[0,1])+float(cm[1,0]) + float(cm[1,1]))*100) + \"%\")\nprint(\"The Recall   is : \"+ str(float(cm[1,1])/(float(cm[1,0]) + float(cm[1,1]))*100) +\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}