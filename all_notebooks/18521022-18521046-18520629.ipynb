{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-05T04:52:35.242451Z","iopub.execute_input":"2021-06-05T04:52:35.242803Z","iopub.status.idle":"2021-06-05T04:52:35.255561Z","shell.execute_reply.started":"2021-06-05T04:52:35.242772Z","shell.execute_reply":"2021-06-05T04:52:35.254399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install findspark","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:35.791858Z","iopub.execute_input":"2021-06-05T04:52:35.792384Z","iopub.status.idle":"2021-06-05T04:52:42.477488Z","shell.execute_reply.started":"2021-06-05T04:52:35.792338Z","shell.execute_reply":"2021-06-05T04:52:42.476524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:42.481366Z","iopub.execute_input":"2021-06-05T04:52:42.481706Z","iopub.status.idle":"2021-06-05T04:52:49.068477Z","shell.execute_reply.started":"2021-06-05T04:52:42.48167Z","shell.execute_reply":"2021-06-05T04:52:49.067483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import findspark\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:49.072557Z","iopub.execute_input":"2021-06-05T04:52:49.072883Z","iopub.status.idle":"2021-06-05T04:52:49.077788Z","shell.execute_reply.started":"2021-06-05T04:52:49.07285Z","shell.execute_reply":"2021-06-05T04:52:49.076452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"pysparkML\").getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:49.08Z","iopub.execute_input":"2021-06-05T04:52:49.080539Z","iopub.status.idle":"2021-06-05T04:52:49.093447Z","shell.execute_reply.started":"2021-06-05T04:52:49.08049Z","shell.execute_reply":"2021-06-05T04:52:49.092422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = spark.read.csv('../input/car-acceptability-prediction/train.csv', inferSchema=True, header=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:49.094681Z","iopub.execute_input":"2021-06-05T04:52:49.094984Z","iopub.status.idle":"2021-06-05T04:52:49.233465Z","shell.execute_reply.started":"2021-06-05T04:52:49.09495Z","shell.execute_reply":"2021-06-05T04:52:49.232216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = spark.read.csv('../input/car-acceptability-prediction/test.csv', inferSchema=True, header=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:49.234873Z","iopub.execute_input":"2021-06-05T04:52:49.235234Z","iopub.status.idle":"2021-06-05T04:52:49.398302Z","shell.execute_reply.started":"2021-06-05T04:52:49.2352Z","shell.execute_reply":"2021-06-05T04:52:49.397299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer, OneHotEncoder, VectorAssembler,IndexToString\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator,BinaryClassificationEvaluator\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:49.399689Z","iopub.execute_input":"2021-06-05T04:52:49.400124Z","iopub.status.idle":"2021-06-05T04:52:49.40928Z","shell.execute_reply.started":"2021-06-05T04:52:49.400082Z","shell.execute_reply":"2021-06-05T04:52:49.408537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nlabelIndexer = StringIndexer(inputCol=\"acceptability\", outputCol=\"label_index\").fit(train)\ntrain = labelIndexer.transform(train)\n\n## transform other features into indexes\n\nbuying_Indexer = StringIndexer(inputCol=\"buying_price\", outputCol=\"buying_index\")\nmaint_Indexer = StringIndexer(inputCol=\"maintenance_price\", outputCol=\"maint_index\")\ndoors_Indexer = StringIndexer(inputCol=\"number_of_doors\", outputCol=\"doors_index\")\ncarry_Indexer = StringIndexer(inputCol=\"carry_capacity\", outputCol=\"carry_index\")\ntrunk_size_Indexer = StringIndexer(inputCol=\"trunk_size\", outputCol=\"trunk_size_index\")\nsafty_Indexer = StringIndexer(inputCol=\"safety\", outputCol=\"safety_index\")\n\nassembler = VectorAssembler( inputCols=[\"buying_index\", \"maint_index\", \"doors_index\",\"carry_index\", \"trunk_size_index\", \"safety_index\"], outputCol=\"features_index\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:49.411592Z","iopub.execute_input":"2021-06-05T04:52:49.412269Z","iopub.status.idle":"2021-06-05T04:52:49.643529Z","shell.execute_reply.started":"2021-06-05T04:52:49.412167Z","shell.execute_reply":"2021-06-05T04:52:49.642762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.ml.classification import RandomForestClassifier\n\n#model_DecisionTreeClassifier = DecisionTreeClassifier(labelCol= \"label_index\", featuresCol=\"features_index\")\nRandomForest_model = RandomForestClassifier(labelCol = \"label_index\", featuresCol=\"features_index\" ,  numTrees =256)\n    # Chain featurizers in a Pipeline\npipeline = Pipeline(stages=[ buying_Indexer ,maint_Indexer, doors_Indexer, carry_Indexer, trunk_size_Indexer, safty_Indexer, \n                            assembler,RandomForest_model])\n\nmodel = pipeline.fit(train)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:52:53.608508Z","iopub.execute_input":"2021-06-05T04:52:53.608872Z","iopub.status.idle":"2021-06-05T04:52:57.843866Z","shell.execute_reply.started":"2021-06-05T04:52:53.608831Z","shell.execute_reply":"2021-06-05T04:52:57.842861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#make predictions\npredictions = model.transform(test)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:53:10.378318Z","iopub.execute_input":"2021-06-05T04:53:10.378678Z","iopub.status.idle":"2021-06-05T04:53:10.498057Z","shell.execute_reply.started":"2021-06-05T04:53:10.378648Z","shell.execute_reply":"2021-06-05T04:53:10.497028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display\n#predictions.select(\"car_id\",\"buying_price\",\"maintenance_price\",\"number_of_doors\",\"carry_capacity\",\"trunk_size\",\"safety\",\"prediction\").show(10)\npredicted = predictions.select(\"car_id\",\"prediction\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:53:11.593656Z","iopub.execute_input":"2021-06-05T04:53:11.594037Z","iopub.status.idle":"2021-06-05T04:53:11.608502Z","shell.execute_reply.started":"2021-06-05T04:53:11.594004Z","shell.execute_reply":"2021-06-05T04:53:11.607297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted.show(20)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:53:12.735235Z","iopub.execute_input":"2021-06-05T04:53:12.735609Z","iopub.status.idle":"2021-06-05T04:53:12.918989Z","shell.execute_reply.started":"2021-06-05T04:53:12.735578Z","shell.execute_reply":"2021-06-05T04:53:12.918158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"acc =1 , unacc =0 good =2 vgood =3","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import regexp_replace\ndata = predicted.withColumn('prediction', regexp_replace('prediction', '1.0', 'acc')) \\\n         .withColumn('prediction', regexp_replace('prediction', '0.0', 'unacc')) \\\n         .withColumn('prediction', regexp_replace('prediction', '2.0', 'good')) \\\n         .withColumn('prediction', regexp_replace('prediction', '3.0', 'vgood')) \\\n         .withColumnRenamed(\"prediction\", \"acceptability\" ) \\\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:53:19.053344Z","iopub.execute_input":"2021-06-05T04:53:19.053692Z","iopub.status.idle":"2021-06-05T04:53:19.097553Z","shell.execute_reply.started":"2021-06-05T04:53:19.053662Z","shell.execute_reply":"2021-06-05T04:53:19.096473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.show(20)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:53:58.23396Z","iopub.execute_input":"2021-06-05T04:53:58.234377Z","iopub.status.idle":"2021-06-05T04:53:58.482893Z","shell.execute_reply.started":"2021-06-05T04:53:58.234342Z","shell.execute_reply":"2021-06-05T04:53:58.481929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.toPandas().to_csv('c.csv',index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:54:04.240755Z","iopub.execute_input":"2021-06-05T04:54:04.241113Z","iopub.status.idle":"2021-06-05T04:54:04.668714Z","shell.execute_reply.started":"2021-06-05T04:54:04.241082Z","shell.execute_reply":"2021-06-05T04:54:04.667736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}