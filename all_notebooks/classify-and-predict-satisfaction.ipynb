{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"1fd53130-0598-0482-a692-8561ff45b8e1"},"source":"**Import Dependencies and predict Satisfaction using Deep Neural Network Tensorflow with Softmax Cross Entropy**"},{"cell_type":"markdown","metadata":{"_cell_guid":"9562c339-e0d9-029f-1c5b-b2377cd2a2b4"},"source":"Below summary for the whole dataset in 2D space after apply Standard Scaler scikit into the dataset"},{"cell_type":"markdown","metadata":{"_cell_guid":"0809f60e-3e3e-a040-6b15-798383b1ea2a"},"source":"#### Predict Job Satisfaction using Deep Neural Network"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2473a0c-bcd5-b0df-03d0-b4c99312c4ae"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set(style=\"whitegrid\", palette=\"muted\")\ncurrent_palette = sns.color_palette()\n\nxrange = range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0139b845-c83a-9626-ad1b-a7324268b223"},"outputs":[],"source":"dataset = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nage = dataset.ix[:, 0]\nattrition = dataset.ix[:, 1]\n\ndataset.ix[:, 0] = attrition\ndataset.ix[:, 1] = age\n\ndataset = dataset.rename(columns = {'Age': 'Attrition', 'Attrition': 'Age'})\ndataset.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8183d34-deb8-ec1d-0721-32f07cd7cef8"},"outputs":[],"source":"from sklearn.manifold import TSNE\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nX = dataset.ix[:, 1:]\nY = dataset.ix[:, :1]\n\nlabels = np.unique(Y.values).tolist()\n\nY.ix[:, 0] = LabelEncoder().fit_transform(Y.ix[:, 0])\n\nfor i in xrange(X.shape[1]):\n    if str(type(X.ix[0, i])).find('str') > 0:\n        X.ix[:, i] = LabelEncoder().fit_transform(X.ix[:, i])\n\nX, _, Y, _ = train_test_split(X, Y, test_size=0.5)\n\nX.ix[:, :] = StandardScaler().fit_transform(X.ix[:, :])\n\ndata_visual = TSNE(n_components = 2).fit_transform(X.values)\n\nX.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b9edab6-070e-a338-2ab9-112d11a69d59"},"outputs":[],"source":"for i, _ in enumerate(np.unique(Y.values)):\n    plt.scatter(data_visual[Y.values[:, 0] == i, 0], data_visual[Y.values[:, 0] == i, 1], color = current_palette[i], label = labels[i])\n    \nplt.legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da98ff97-52d1-f40e-ed05-cd19a66b1ba5"},"outputs":[],"source":"dataset_copy = dataset[['Department', 'TotalWorkingYears', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole']]\n\ndataset_copy.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf25c980-b34c-d406-d5d8-661db12f40bb"},"outputs":[],"source":"dataset_copy = dataset_copy.ix[:200, :]\n\nplt.figure(figsize=(30,10))\n\ndepartment = pd.melt(dataset_copy, \"Department\", var_name=\"Working Variables\")\n\nswarm_plot = sns.swarmplot(x=\"Working Variables\", y=\"value\", hue=\"Department\", data=department)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd20ae2d-dd72-fb3a-f72a-16cfb9f2346d"},"outputs":[],"source":"fig = plt.figure(figsize=(20,10))\n\nhead_subplot = np.unique(dataset.ix[:, 4].values)\n\nhead_int_label = LabelEncoder().fit_transform(dataset['Department'])\n\nunique_head_int_label = np.unique(head_int_label)\n\nrows = ['DailyRate', 'EnvironmentSatisfaction', 'JobSatisfaction', 'MonthlyIncome', 'RelationshipSatisfaction']\n\nY = dataset['Age'].ix[:].values\n\nlabelset = LabelEncoder().fit_transform(dataset['Attrition'])\n\nlabels = dataset['Attrition'].unique()\n\nnum = 1\n\nfor i in xrange(len(head_subplot)):\n    for k in xrange(len(rows)):\n        plt.subplot(len(head_subplot), len(rows), num)\n\n        X = dataset[rows[k]].ix[:].values\n\n        X = X[head_int_label == unique_head_int_label[i]]\n        \n        Y_in = Y[head_int_label == unique_head_int_label[i]]\n        \n        labelset_filter = labelset[head_int_label == unique_head_int_label[i]]\n        \n        for no, text in enumerate(labels):\n            plt.scatter(X[labelset_filter == no], Y_in[labelset_filter == no], color = current_palette[no],\n                        label = labels[no])\n        plt.title(head_subplot[i])\n        plt.ylabel('Age')\n        plt.xlabel(rows[k])\n        plt.legend()\n        \n        num += 1\n        \nfig.tight_layout()        \nplt.show()     \n    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c8aa942-5c85-7c6a-8b1c-91ad86f43817"},"outputs":[],"source":"dataset = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\ndel dataset['Over18']\ndel dataset['OverTime']\n\n# 17th column and above\nX = dataset.ix[:, 17:].values\n\n# change marriage status into int\nX[:, 0] = LabelEncoder().fit_transform(X[:, 0])\n\nY = dataset['JobSatisfaction'].ix[:].values\n\ndef one_hot_label(x):\n    data = np.zeros((x.shape[0], np.unique(x).shape[0]), dtype = np.float32)\n    \n    for i in xrange(x.shape[0]):\n        data[0, x[i] - 1] = 1.0\n        \n    return data\n\nY = one_hot_label(Y)\n\nX = StandardScaler().fit_transform(X)\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a3ececc-e5cc-2492-c137-48e5c5babe51"},"outputs":[],"source":"import tensorflow as tf\n\nepoch = 100\nlearning_rate = 0.01\ndelta_penalty = 0.005\nprob_dropout = 0.5\n\nfirst_layer = 64\nsecond_layer = 128\nthird_layer = 64\n\nx_placeholder = tf.placeholder('float', [None, X.shape[1]])\ny_placeholder = tf.placeholder('float', [None, Y.shape[1]])\n\nweights = {\n    'first_weight' : tf.Variable(tf.random_normal([X.shape[1], first_layer])),\n    'second_weight' : tf.Variable(tf.random_normal([first_layer, second_layer])),\n    'third_weight' : tf.Variable(tf.random_normal([second_layer, third_layer])),\n    'fourth_weight' : tf.Variable(tf.random_normal([third_layer, Y.shape[1]])),\n}\n\nbiases = {\n    'first_bias' : tf.Variable(tf.random_normal([first_layer])),\n    'second_bias' : tf.Variable(tf.random_normal([second_layer])),\n    'third_bias' : tf.Variable(tf.random_normal([third_layer])),\n    'fourth_bias' : tf.Variable(tf.random_normal([Y.shape[1]])),\n}\n\nfirst_layer = tf.nn.relu(tf.add(tf.matmul(x_placeholder, weights['first_weight']), biases['first_bias']))\nfirst_layer = tf.nn.dropout(first_layer, prob_dropout)\n\nsecond_layer = tf.nn.relu(tf.add(tf.matmul(first_layer, weights['second_weight']), biases['second_bias']))\nsecond_layer = tf.nn.dropout(second_layer, prob_dropout)\n\nthird_layer = tf.nn.relu(tf.add(tf.matmul(second_layer, weights['third_weight']), biases['third_bias']))\nthird_layer = tf.nn.dropout(third_layer, prob_dropout)\n\nfourth_layer = tf.add(tf.matmul(third_layer, weights['fourth_weight']), biases['fourth_bias'])\n\nregularizers =  sum(map(lambda x: tf.nn.l2_loss(x), [value for _, value in weights.items()]))\n\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = fourth_layer, labels = y_placeholder)) + (delta_penalty * regularizers)\n\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\ncorrect_prediction = tf.equal(tf.argmax(fourth_layer, 1), tf.argmax(y_placeholder, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19c02c3b-4856-a04f-319a-b1b5c3e40a7d"},"outputs":[],"source":"import time\n\nsess = tf.InteractiveSession()\n    \nsess.run(tf.global_variables_initializer())\n\nfor i in xrange(epoch):\n    \n    last_time = time.time()\n    \n    acc,_, lost = sess.run([accuracy, optimizer, loss], feed_dict = {x_placeholder : x_train, y_placeholder : y_train})\n    \n    print (\"epoch: \", i + 1, \", loss: \", lost, \", seconds per epoch: \", time.time() - last_time)\n    print (\"total accuracy: \", acc)\n    "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}