{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this notebook \n\nIn this notebook we are going to explore the dataset in https://www.kaggle.com/sulianova/cardiovascular-disease-dataset .\nThe dataset maps the cardiac condition of several patients (70k). We are also going to try a logistic regression to predict\nif a given patient have a cardiovascular disease.\n\n# Table of contents\n\n* Importing and reading the data\n* Feature analysis\n* Cleaning the data\n* Exploratory data analysis\n* Logistic regression\n* Notes\n\n\n\nWhat is the plan?\n\nOf course we need to first read the data and see the basic information there. Then we can see the distribution of each feature in the data and compare the distributions between 'gender' =1 and =2 and 'cardio' =0 and =1, taking notes as we go.\nTo do the logistic regression we are going to use the sklearn package. "},{"metadata":{},"cell_type":"markdown","source":"# Importing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\n\ndata=pd.read_csv('../input/cardiovascular-disease-dataset/cardio_train.csv'\n                 ,sep=';'#';' separates the data\n                 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['age']=data['age']/365 #the date were in days\ndata.head()\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features:\n\n* Age | Objective Feature | age | int (days)\n* Height | Objective Feature | height | int (cm) |\n* Weight | Objective Feature | weight | float (kg) |\n* Gender | Objective Feature | gender | categorical code | 1 - women, 2 - men\n* Systolic blood pressure | Examination Feature | ap_hi | int |\n* Diastolic blood pressure | Examination Feature | ap_lo | int |\n* Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n* Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n* Smoking | Subjective Feature | smoke | binary |\n* Alcohol intake | Subjective Feature | alco | binary |\n* Physical activity | Subjective Feature | active | binary |\n* Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n\n\nAll of the dataset values were collected at the moment of medical examination.\n\n\nHere we can se some usefull information, like:\n* The mean age is 53.3 years and the youngest patient is almost 30 years old\n* The \"mean\" of gender is 1.3 (1 - women, 2 - men) which means there is more women in the dataset than men\n* The mean of the height is 164 cm\n* The mean of the weight is 74.2 kg \n* If the systolic and diastolic blood pressure are measured in mmHg, we shouldn't be getting negative minimum values, wich suggests some transcription errors. Also some values (visible from the data.head()) are beyond 120 mmHg for ap_hi and 80 mmHg for ap_lo , and that consitutes hypertension already.\n* The maximum value of ap_lo and ap_hi is way too high to make any sense, so we better clean the impossible values\n* The mean of smoke is 0.08, so few people in this dataset smokes, the same can be said for alcohol intake(0.05).\n* The mean of active is 0.8 so a lot of people do regular physical exercise\n* The mean of cardio is 0.499 so nearly half of the people in the dataset have some cardiovascular disease. This also means this dataset is balanced so we dont need to convert to a balanced dataset to do our machine learning algoritm."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"not a single value is missing(NaN)"},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['ap_hi']<0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it would make sense if the negative values are all transcription errors since all values are in range of acceptable pressures except for the signal. We can just convert these negative values to positive and keep in the dataset. The same can be said for the ap_lo since:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['ap_lo']<0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ap_lo']=data['ap_lo'].abs()\ndata['ap_hi']=data['ap_hi'].abs()\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets define the values acceptable for the pressures:\n* ap_hi have to be 10<ap_hi<220 \n* ap_lo tave to be 10<ap_lo<190"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.loc[data['ap_lo']>10]\ndata = data.loc[data['ap_lo']<190]\ndata = data.loc[data['ap_hi']>10]\ndata = data.loc[data['ap_hi']<220]\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We gave up little bit over a thousand values. Now we adjust the weight and drop the 'id' column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.loc[data['weight']>30]\ndata=data.drop(columns='id')\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis\nNow we need to look for diferences between populations. First lets see if anything changes between men and women."},{"metadata":{"trusted":true},"cell_type":"code","source":"datam = data[data['gender']==2]\ndataw = data[data['gender']==1]\n\n\nfig, axs = plt.subplots(2, 2,figsize=(10,10))\naxs[0, 0].hist(dataw['age'], bins=15,alpha=0.5,color='blue')\naxs[0, 0].hist(datam['age'], bins=15,alpha=0.5,color='green')\naxs[0, 0].legend(['women','men'])\naxs[0, 0].set_title('age')\naxs[0, 1].hist(dataw['height'],bins=15, alpha=0.5,color='blue')\naxs[0, 1].hist(datam['height'],bins=15, alpha=0.5,color='green')\naxs[0, 1].legend(['women','men'])\naxs[0, 1].set_title('height')\naxs[1, 0].hist(dataw['weight'],bins=15, alpha=0.5,color='blue')\naxs[1, 0].hist(datam['weight'],bins=15, alpha=0.5,color='green')\naxs[1, 0].legend(['women','men'])\naxs[1, 0].set_title('weight')\naxs[1, 1].hist(dataw['smoke'],bins=15, alpha=0.5,color='blue')\naxs[1, 1].hist(datam['smoke'],bins=15, alpha=0.5,color='green')\naxs[1, 1].legend(['women','men'])\naxs[1, 1].set_title('smoke')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see \n* The age distribution between men and women is nearly the same (there is just more women in the dataset)\n* Men in this dataset is higher on the average than women\n* The weight distribution is also the same for both men and women, and the gaussian have a skew to the right\n* There is more men that smoke even considering there is more women in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataw['weight'].skew(),\ndatam['weight'].skew()) # measure of skewness (>0:to the right ;=0 symmetrical ; <0 to the left)\n\nm = datam['smoke'].sum() / datam.size # proportion of men that smoke\nw = dataw['smoke'].sum() / dataw.size # proportion of women that smoke\n\nprint(w,m)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So men are 12 times more smokers than women in this dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, axs = plt.subplots(2, 2,figsize=(10,10))\naxs[0, 0].hist(dataw['ap_hi'], bins=12, alpha=0.5,color='blue')\naxs[0, 0].hist(datam['ap_hi'], bins=12, alpha=0.5,color='green')\naxs[0, 0].legend(['women','men'])\naxs[0, 0].set_title('ap_hi')\n\naxs[0, 1].hist(dataw['ap_lo'],bins=12, alpha=0.5,color='blue')\naxs[0, 1].hist(datam['ap_lo'],bins=12, alpha=0.5,color='green')\naxs[0, 1].legend(['women','men'])\naxs[0, 1].set_title('ap_lo')\n\naxs[1, 0].hist(dataw['cholesterol'],bins=4, alpha=0.5,color='blue')\naxs[1, 0].hist(datam['cholesterol'],bins=4, alpha=0.5,color='green')\naxs[1, 0].legend(['women','men'])\naxs[1, 0].set_title('cholesterol')\n\naxs[1, 1].hist(dataw['gluc'],bins=4, alpha=0.5,color='blue')\naxs[1, 1].hist(datam['gluc'],bins=4, alpha=0.5,color='green')\naxs[1, 1].legend(['women','men'])\naxs[1, 1].set_title('gluc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distributions for pressure, cholesterol and glucose are nearly the same for both men and women.Now the same for cardiovascular condition"},{"metadata":{"trusted":true},"cell_type":"code","source":"data0 = data[data['cardio']==0]\ndata1 = data[data['cardio']==1]\n\n\nfig, axs = plt.subplots(2, 2,figsize=(10,10))\naxs[0, 0].hist(data0['age'], bins=10, alpha=0.5,color='blue')\naxs[0, 0].hist(data1['age'], bins=10, alpha=0.5,color='green')\naxs[0, 0].legend(['healthy','cardio'])\naxs[0, 0].set_title('age')\naxs[0, 1].hist(data0['height'],bins=12, alpha=0.5,color='blue')\naxs[0, 1].hist(data1['height'],bins=12, alpha=0.5,color='green')\naxs[0, 1].legend(['healthy','cardio'])\naxs[0, 1].set_title('height')\naxs[1, 0].hist(data0['weight'],bins=15, alpha=0.5,color='blue')\naxs[1, 0].hist(data1['weight'],bins=15, alpha=0.5,color='green')\naxs[1, 0].legend(['healthy','cardio'])\naxs[1, 0].set_title('weight')\naxs[1, 1].hist(data0['smoke'],bins=3, alpha=0.5,color='blue')\naxs[1, 1].hist(data1['smoke'],bins=3, alpha=0.5,color='green')\naxs[1, 1].legend(['healthy','cardio'])\naxs[1, 1].set_title('smoke')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that age is a important factor to predict a cardiovascular disease. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 2,figsize=(10,10))\naxs[0, 0].hist(data0['ap_hi'], bins=12, alpha=0.5,color='blue')\naxs[0, 0].hist(data1['ap_hi'], bins=12, alpha=0.5,color='green')\naxs[0, 0].legend(['healthy','cardio'])\naxs[0, 0].set_title('ap_hi')\n\naxs[0, 1].hist(data0['ap_lo'],bins=12, alpha=0.5,color='blue')\naxs[0, 1].hist(data1['ap_lo'],bins=12, alpha=0.5,color='green')\naxs[0, 1].legend(['healthy','cardio'])\naxs[0, 1].set_title('ap_lo')\n\naxs[1, 0].hist(data0['cholesterol'],bins=4, alpha=0.5,color='blue')\naxs[1, 0].hist(data1['cholesterol'],bins=4, alpha=0.5,color='green')\naxs[1, 0].legend(['healthy','cardio'])\naxs[1, 0].set_title('cholesterol')\n\naxs[1, 1].hist(data0['gluc'],bins=4, alpha=0.5,color='blue')\naxs[1, 1].hist(data1['gluc'],bins=4, alpha=0.5,color='green')\naxs[1, 1].legend(['healthy','cardio'])\naxs[1, 1].set_title('gluc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can also indentify ap_hi, cholesterol and glucose as important factors"},{"metadata":{},"cell_type":"markdown","source":"The correlation matrix..."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nsns.heatmap(data.corr()).set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that age,weight,ap_hi,ap_lo,cholesterol and gluc have the biggest correlation value with cardio. Now we can train a model to predict if a patient have some cardiovascular disease. For this run we are going with a logistic regression strategy."},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression\n\nThe strategy here is to use the features : age,gender,height,weight,dyastolic and systolic pressures, cholesterol,glucose,smoke and active\n\nFor the training and validation, cross validation were used. 80% of the dataset were used to train and 20% to validade the model.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"log_data=[data['age'],data['gender'],data['height'],data['weight'],data['ap_hi'],data['ap_lo'],data['cholesterol'],data['gluc'],data['smoke'],data['active']]\nlog_data=np.array(log_data)\nlog_data=log_data.transpose()\ntrain_data,test_data,train_target,test_target = train_test_split(log_data, data['cardio'], test_size=0.2)\n\n\nlr = LogisticRegression().fit(train_data,train_target)\n\n\np=lr.score(test_data,test_target)\n\n\nprint(p)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Notes\n\nHere we explored a very superficial logistic regression. We could try neural networks, support vector machines etc.\nWe made some assumptions in the way and it would be nice to made them clear.\n\n\n\n* The systolic and dyastolic pressures (columns ap_hi and ap_lo) were measured in mmHg\n* The same pressures had sometimes negative values and other impossible ones (>1000). We made the assumptions that the negative ones were transcription errors. We dropped the super-large ones\n* We also assumed a minimum weight of 30kg to be valid, and that may not be true if dwarfism cases were in the dataset\n* We defined the acceptable intervals for the pressures to be 10<ap_hi<220 and 10<ap_lo<190, and this assumption was not based in any concrete reference (higher pressures may be possible)\n\n\nThis notebook was inspired by this work: https://www.kaggle.com/mnassrib/titanic-logistic-regression-with-python by Baligh Mnassri on the titanic dataset\n\n\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}