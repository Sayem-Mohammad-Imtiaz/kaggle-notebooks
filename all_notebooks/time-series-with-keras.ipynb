{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Time Series with RNN\n\n* **Objective** - In this notebook, I have outlined RNN methods and enhancements for time series prediction. \n* **Dataset** - We will use International Airline Passengers Dataset, which is a monthly capture of number of passengers flying in 1000s of people. \n* **Metric** - We will try out building following models and measure their performance using RMSE metric\n\n\n### Models\n1. Time Series with MLP as Regression\n2. Time Series with MLP using Window Method\n3. Time Series with LSTM\n4. Time Series with LSTM & Dropout \n5. Time Series with LSTM & precise LSTM Dropout \n6. Time Series with LSTM & CNNs","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## 0. Data Loadin' and Preppin'\n\n### Loading Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/international-airline-passengers/international-airline-passengers.csv').dropna()\ndf.columns = ['month','passengers']\nprint ('Shape of Dataset :', df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the Time Series","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(df.passengers)\nplt.ylabel('Passenger Count')\nplt.xlabel('Month')\nplt.title('Passenger Count (1000s) by Month')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_SIZE = int(df.shape[0]*0.7)\nprint ('TRAIN_SIZE :', TRAIN_SIZE)\ndata  = list(df.passengers.values)\ntrain = data[:TRAIN_SIZE]\ntest  = data[TRAIN_SIZE:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nplt.plot(train)\nplt.plot(len(train)+np.arange(len(test)), test)\nplt.ylabel('Passenger Count')\nplt.xlabel('Month')\nplt.title('Passenger Count (1000s) by Month')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. First Model - MLP Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_dataset(seq, traceback):\n    X,Y = [],[]\n    for i in range(len(seq) - traceback - 1):\n        X.append(seq[i:i+traceback])\n        Y.append(seq[i+traceback])\n    return np.array(X), np.array(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LOOK_BACK = 1\nX_train, y_train = generate_dataset(train, LOOK_BACK)\nX_test , y_test  = generate_dataset(test,  LOOK_BACK)\nfor i in range(5):\n    print (f'Input : {X_train[i]}, Output : {y_train[i]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\ndef model_mlp_reg():\n    model = Sequential([\n        Dense(10, input_dim = (LOOK_BACK), activation = 'relu'),\n        Dense(1)\n    ])\n    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_mlp_reg()\nmodel.summary()\n%time history = model.fit(X_train, y_train, epochs = 200, batch_size = 3, verbose = 0)\ntrain_results = model.evaluate(X_train, y_train, verbose = 0)\ntest_results  = model.evaluate(X_test,  y_test,  verbose = 0)\nprint (f'RMSE TRAIN : {round(np.sqrt(train_results), 2)}')\nprint (f'RMSE TEST  : {round(np.sqrt(test_results),  2)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting History","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title(\"Mean Squared Error Loss by Epoch\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating & Plotting Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_preds = model.predict(X_train)\ntest_preds  = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(train_preds, 'b')\nplt.plot(len(train_preds)+np.arange(len(test_preds))+1, test_preds, 'g')\nplt.plot(y_train, '--', color = '#808080')\nplt.plot(len(y_train)+np.arange(len(y_test))+1, y_test, '--', color = '#808080')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. MLP using window method\n\n### Generating Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LOOK_BACK = 3\nX_train, y_train = generate_dataset(train, LOOK_BACK)\nX_test , y_test  = generate_dataset(test,  LOOK_BACK)\nfor i in range(5):\n    print (f'Input : {X_train[i]}, Output : {y_train[i]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_mlp_reg()\nmodel.summary()\n%time history = model.fit(X_train, y_train, epochs = 200, batch_size = 1, verbose = 0)\ntrain_results = model.evaluate(X_train, y_train, verbose = 0)\ntest_results  = model.evaluate(X_test,  y_test,  verbose = 0)\nprint (f'RMSE TRAIN : {round(np.sqrt(train_results), 2)}')\nprint (f'RMSE TEST  : {round(np.sqrt(test_results),  2)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting History","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title(\"Mean Squared Error Loss by Epoch\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating & Plotting Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_preds = model.predict(X_train)\ntest_preds  = model.predict(X_test)\n\nplt.figure(figsize = (10,5))\nplt.plot(train_preds, 'b')\nplt.plot(len(train_preds)+np.arange(len(test_preds))+1, test_preds, 'g')\nplt.plot(y_train, '--', color = '#808080')\nplt.plot(len(y_train)+np.arange(len(y_test))+1, y_test, '--', color = '#808080')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. LSTM\nThe LSTM network expects the input data (X) to be provided with a specific array structure in\nthe form of: [samples, time steps, features].","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def PrepareLSTMDatasets(LOOK_BACK = 1):\n    from sklearn.preprocessing import MinMaxScaler\n\n    # scaling the dataset\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data = np.array(list(df.passengers.values))\n    data = scaler.fit_transform(data.reshape(-1,1)).reshape(-1)\n\n    # train test split\n    TRAIN_SIZE = int(df.shape[0]*0.7)\n    print ('TRAIN_SIZE :', TRAIN_SIZE)\n    train = data[:TRAIN_SIZE]\n    test  = data[TRAIN_SIZE:]\n\n    # training datasets\n    X_train, y_train = generate_dataset(train, LOOK_BACK)\n    X_test , y_test  = generate_dataset(test,  LOOK_BACK)\n    for i in range(5):\n        print (f'Input : {X_train[i]}, Output : {y_train[i]}')\n    \n    return X_train, X_test, y_train, y_test, scaler\n\nLOOK_BACK = 1\nX_train, X_test, y_train, y_test, scaler = PrepareLSTMDatasets(LOOK_BACK)\n\n# reshaping datasets for LSTM\nX_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\nX_test  = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM\ndef model_LSTM():\n    model = Sequential([\n        LSTM(5, input_dim = (LOOK_BACK)),\n        Dense(1)\n    ])\n    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_LSTM()\nmodel.summary()\n%time history = model.fit(X_train, y_train, epochs = 100, batch_size = 2, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting History","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title(\"Mean Squared Error Loss by Epoch\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating & Plotting Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_preds = scaler.inverse_transform(model.predict(X_train))\ntest_preds  = scaler.inverse_transform(model.predict(X_test))\ny_train     = scaler.inverse_transform(y_train.reshape(-1,1)) \ny_test      = scaler.inverse_transform(y_test.reshape(-1,1)) \n\nfrom sklearn.metrics import mean_squared_error\n\nprint (f'RMSE TRAIN : {round(np.sqrt(mean_squared_error(y_train, train_preds.reshape(-1))), 2)}')\nprint (f'RMSE TEST  : {round(np.sqrt(mean_squared_error(y_test,  test_preds.reshape(-1))),  2)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(train_preds, 'b')\nplt.plot(len(train_preds)+np.arange(len(test_preds))+1, test_preds, 'g')\nplt.plot(y_train, '--', color = '#808080')\nplt.plot(len(y_train)+np.arange(len(y_test))+1, y_test, '--', color = '#808080')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LSTM with Window Method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LOOK_BACK = 3\nX_train, X_test, y_train, y_test, scaler = PrepareLSTMDatasets(LOOK_BACK)\nprint ('X_train Shape :',X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_LSTM()\nmodel.summary()\n%time history = model.fit(X_train, y_train, epochs = 100, batch_size = 2, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting History","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title(\"Mean Squared Error Loss by Epoch\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating & Plotting Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_preds = scaler.inverse_transform(model.predict(X_train))\ntest_preds  = scaler.inverse_transform(model.predict(X_test))\ny_train     = scaler.inverse_transform(y_train.reshape(-1,1)) \ny_test      = scaler.inverse_transform(y_test.reshape(-1,1)) \n\nfrom sklearn.metrics import mean_squared_error\n\nprint (f'RMSE TRAIN : {round(np.sqrt(mean_squared_error(y_train, train_preds.reshape(-1))), 2)}')\nprint (f'RMSE TEST  : {round(np.sqrt(mean_squared_error(y_test,  test_preds.reshape(-1))),  2)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(train_preds, 'b')\nplt.plot(len(train_preds)+np.arange(len(test_preds))+1, test_preds, 'g')\nplt.plot(y_train, '--', color = '#808080')\nplt.plot(len(y_train)+np.arange(len(y_test))+1, y_test, '--', color = '#808080')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LSTM with Time Steps","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def PrepareLSTMDatasets(LOOK_BACK = 1):\n    from sklearn.preprocessing import MinMaxScaler\n\n    # scaling the dataset\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    data = np.array(list(df.passengers.values))\n    data = scaler.fit_transform(data.reshape(-1,1)).reshape(-1)\n\n    # train test split\n    TRAIN_SIZE = int(df.shape[0]*0.7)\n    print ('TRAIN_SIZE :', TRAIN_SIZE)\n    train = data[:TRAIN_SIZE]\n    test  = data[TRAIN_SIZE:]\n\n    # training datasets\n    X_train, y_train = generate_dataset(train, LOOK_BACK)\n    X_test , y_test  = generate_dataset(test,  LOOK_BACK)\n    for i in range(5):\n        print (f'Input : {X_train[i]}, Output : {y_train[i]}')\n    \n    return X_train, X_test, y_train, y_test, scaler\n\nLOOK_BACK = 3\nX_train, X_test, y_train, y_test, scaler = PrepareLSTMDatasets(LOOK_BACK)\n# reshaping datasets for LSTM\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1, ))\nX_test  = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\nprint ('X_train Shape :',X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_LSTM_TimeSteps():\n    model = Sequential([\n        LSTM(5, input_dim = (1)),\n        Dense(1)\n    ])\n    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n    return model\n\nmodel = model_LSTM_TimeSteps()\nmodel.summary()\n%time history = model.fit(X_train, y_train, epochs = 100, batch_size = 2, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting History","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title(\"Mean Squared Error Loss by Epoch\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generating & Plotting Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_preds = scaler.inverse_transform(model.predict(X_train))\ntest_preds  = scaler.inverse_transform(model.predict(X_test))\ny_train     = scaler.inverse_transform(y_train.reshape(-1,1)) \ny_test      = scaler.inverse_transform(y_test.reshape(-1,1)) \n\nfrom sklearn.metrics import mean_squared_error\n\nprint (f'RMSE TRAIN : {round(np.sqrt(mean_squared_error(y_train, train_preds.reshape(-1))), 2)}')\nprint (f'RMSE TEST  : {round(np.sqrt(mean_squared_error(y_test,  test_preds.reshape(-1))),  2)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(train_preds, 'b')\nplt.plot(len(train_preds)+np.arange(len(test_preds))+1, test_preds, 'g')\nplt.plot(y_train, '--', color = '#808080')\nplt.plot(len(y_train)+np.arange(len(y_test))+1, y_test, '--', color = '#808080')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}