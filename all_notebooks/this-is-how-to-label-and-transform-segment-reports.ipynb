{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segReport_df = pd.read_csv(\"../input/traffic-flow-data-in-ho-chi-minh-city-viet-nam/segment_reports.csv\", index_col=\"_id\", \n                            parse_dates=[\"updated_at\"])\nsegment_df = pd.read_csv(\"../input/traffic-flow-data-in-ho-chi-minh-city-viet-nam/segments.csv\", index_col=\"_id\",\n                         parse_dates=[\"created_at\", \"updated_at\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformation magic","metadata":{}},{"cell_type":"code","source":"from math import ceil\n\ndef transform_LOS(segment_id, velocity):\n    max_velocity = segment_df.loc[segment_id, \"max_velocity\"]\n    if max_velocity is None:\n        max_velocity = 50\n    \n    # Transform to label\n    labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n    threshold = 35\n    if max_velocity >= 70:\n        threshold = 45\n    elif max_velocity >= 60:\n        threshold = 40\n\n    t = max(threshold - velocity, 0)\n    return labels[min(ceil(t / 5), 5)]\n\ndef transform_report(row):\n    \"\"\"\n    @Params:\n        dt: Timestamp object of Pandas\n    @Return:\n        dict: {\"date\", \"period_{hour}_{00|30}\"}\n    \"\"\"\n    LOS = transform_LOS(row[\"segment_id\"], row[\"velocity\"])\n    dt = row[\"updated_at\"]\n    intervals = list(range(24))\n    h = dt.hour\n    m = \"00\" if dt.minute < 30 else \"30\"\n    p_name = f\"period_{h}_{m}\"\n    return dt.date(), dt.weekday(), p_name, LOS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Do it!","metadata":{}},{"cell_type":"code","source":"dates = []\nweekdays = []\np_names = []\nLOSes = []\n\nfor _, row in segReport_df.iterrows():\n    date, weekday, p_name, LOS = transform_report(row)\n    dates.append(date)\n    weekdays.append(weekday)\n    p_names.append(p_name)\n    LOSes.append(LOS)\n\nsegReport_df[\"date\"] = dates\nsegReport_df[\"weekday\"] = weekdays\nsegReport_df[\"period\"] = p_names\nsegReport_df[\"LOS\"] = LOSes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Divide into periods may cause a period has many LOS labels, so need to mitigate this by setting a major label","metadata":{}},{"cell_type":"code","source":"def major_voting(labels):\n    unique_labels = set(labels)\n    count_labels = [labels.count(label) for label in unique_labels]\n\n    sorted_labels = sorted(zip(unique_labels, count_labels), key=lambda x: x[1])\n    if len(sorted_labels) > 1 and sorted_labels[0][1] == sorted_labels[1][1]:\n        print(\"Oh no, many majors?\")\n    return sorted_labels[0][0]\n\ndef mean_voting(labels):\n    l = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n    values = {\"A\":0, \"B\":1, \"C\":2, \"D\":3, \"E\":4, \"F\":5}\n    mean = sum(values[label] for label in labels) / len(labels)\n    return l[min(round(mean), 5)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compress_LOS = segReport_df.groupby(by=[\"segment_id\", \"date\", \"weekday\", \"period\"])[\"LOS\"].apply(list)\ncompress_LOS = pd.DataFrame(compress_LOS).reset_index()\ncompress_LOS[\"LOS\"] = compress_LOS[\"LOS\"].apply(mean_voting)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now the data should be good (maybe)","metadata":{}},{"cell_type":"code","source":"compress_LOS","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}