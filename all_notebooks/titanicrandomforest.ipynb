{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import SVC, LinearSVC\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier # Scikit-learn KNeighbors Classifier\nfrom sklearn.tree import DecisionTreeClassifier # Scikit-learn Decision Tree Classifier\nfrom sklearn.model_selection import KFold # Scikit-learn K-Folds cross-validator\nfrom sklearn.model_selection import cross_val_score # evaluating cross-validator performance\n%matplotlib inline\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0) # KFold configuration\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting up visualisations\nsns.set_style(style='white') \nsns.set(rc={\n    'figure.figsize':(12,7), \n    'axes.facecolor': 'white',\n    'axes.grid': True, 'grid.color': '.9',\n    'axes.linewidth': 1.0,\n    'grid.linestyle': u'-'},font_scale=1.5)\ncustom_colors = [\"#3498db\", \"#95a5a6\",\"#34495e\", \"#2ecc71\", \"#e74c3c\"]\nsns.set_palette(custom_colors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading\ntrd = pd.read_csv('../input/titanic/train.csv')\ntsd = pd.read_csv('../input/titanic/test.csv')\n\ntd = pd.concat([trd, tsd], ignore_index=True, sort  = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#info\ntd.shape\ntd.info()\n\npd.DataFrame(td.isnull().sum()).plot.line().set_title(\"Number of missing values in the given features\")\ntd.isnull().sum()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td.nunique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(trd.Survived.value_counts(normalize=True) * 100).plot.barh().set_title(\"Training Data - Percentage of people survived and Deceased\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_pclass = trd.Pclass.value_counts().plot.pie().legend(labels=[\"Class 3\",\"Class 1\",\"Class 2\"], loc='center right', bbox_to_anchor=(2.25, 0.5)).set_title(\"Training Data - People travelling in different classes\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pclass_1_survivor_distribution = round((trd[trd.Pclass == 1].Survived == 1).value_counts()[1]/len(trd[trd.Pclass == 1]) * 100, 2)\npclass_2_survivor_distribution = round((trd[trd.Pclass == 2].Survived == 1).value_counts()[1]/len(trd[trd.Pclass == 2]) * 100, 2)\npclass_3_survivor_distribution = round((trd[trd.Pclass == 3].Survived == 1).value_counts()[1]/len(trd[trd.Pclass == 3]) * 100, 2)\npclass_perc_df = pd.DataFrame(\n    { \"Percentage Survived\":{\"Class 1\": pclass_1_survivor_distribution,\"Class 2\": pclass_2_survivor_distribution, \"Class 3\": pclass_3_survivor_distribution},  \n     \"Percentage Not Survived\":{\"Class 1\": 100-pclass_1_survivor_distribution,\"Class 2\": 100-pclass_2_survivor_distribution, \"Class 3\": 100-pclass_3_survivor_distribution}})\npclass_perc_df.plot.bar().set_title(\"Training Data - Percentage of people survived on the basis of class\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in [1,2,3]:    ## for 3 classes\n    trd.Age[trd.Pclass == x].plot(kind=\"kde\")\nplt.title(\"Age density in classes\")\nplt.legend((\"1st\",\"2nd\",\"3rd\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pclass_perc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_sex = (trd.Sex.value_counts(normalize = True) * 100).plot.bar()\nmale_pr = round((trd[trd.Sex == 'male'].Survived == 1).value_counts()[1]/len(trd.Sex) * 100, 2)\nfemale_pr = round((trd[trd.Sex == 'female'].Survived == 1).value_counts()[1]/len(trd.Sex) * 100, 2)\nsex_perc_df = pd.DataFrame(\n    { \"Percentage Survived\":{\"male\": male_pr,\"female\": female_pr},  \"Percentage Not Survived\":{\"male\": 100-male_pr,\"female\": 100-female_pr}})\nsex_perc_df.plot.barh().set_title(\"Percentage of male and female survived and Deceased\")\nfig_sex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(td.Age.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td['Age_Range'] = pd.cut(td.Age, [0, 10, 20, 30, 40, 50, 60,70,80])\nsns.countplot(x = \"Age_Range\", hue = \"Survived\", data = td, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(td['Age'].dropna(),color='darkgreen',bins=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td.SibSp.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.DataFrame()\nss['survived'] = trd.Survived\nss['sibling_spouse'] = pd.cut(trd.SibSp, [0, 1, 2, 3, 4, 5, 6,7,8], include_lowest = True)\n(ss.sibling_spouse.value_counts()).plot.area().set_title(\"Training Data - Number of siblings or spouses vs survival count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sns.countplot(x = \"sibling_spouse\", hue = \"survived\", data = ss, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"])\nx.set_title(\"Training Data - survival based on number of siblings or spouses\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(td.Parch.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pc = pd.DataFrame()\npc['survived'] = trd.Survived\npc['parents_children'] = pd.cut(trd.Parch, [0, 1, 2, 3, 4, 5, 6], include_lowest = True)\n(pc.parents_children.value_counts()).plot.area().set_title(\"Training Data - Number of parents/children and survival density\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sns.countplot(x = \"parents_children\", hue = \"survived\", data = pc, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"])\nx.set_title(\"Training Data - Survival based on number of parents/children\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td['Family'] = td.Parch + td.SibSp\ntd['Is_Alone'] = td.Family == 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td.Fare.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td['Fare_Category'] = pd.cut(td['Fare'], bins=[0,7.90,14.45,31.28,120], labels=['Low','Mid',\n                                                                                      'High_Mid','High'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sns.countplot(x = \"Fare_Category\", hue = \"Survived\", data = td, palette=[\"C1\", \"C0\"]).legend(labels = [\"Deceased\", \"Survived\"])\nx.set_title(\"Survival based on fare category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = sns.countplot(x = \"Embarked\", hue = \"Survived\", data = trd, palette=[\"C1\", \"C0\"])\np.set_xticklabels([\"Southampton\",\"Cherbourg\",\"Queenstown\"])\np.legend(labels = [\"Deceased\", \"Survived\"])\np.set_title(\"Training Data - Survival based on embarking point.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td.Embarked.fillna(td.Embarked.mode()[0], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td['Salutation'] = td.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip()) \ntd.Salutation.nunique()\nplt.tight_layout(pad=0)\nplt.show()\n\ntd.Salutation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grp = td.groupby(['Sex', 'Pclass'])  \ntd.Age = grp.Age.apply(lambda x: x.fillna(x.median()))\n\n#If still any row remains\ntd.Age.fillna(td.Age.median, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sal_df = pd.DataFrame({\n    \"Survived\":\n    td[td.Survived == 1].Salutation.value_counts(),\n    \"Total\":\n        td.Salutation.value_counts()\n})\ns = sal_df.plot.barh()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td.Cabin = td.Cabin.fillna('NA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td = pd.concat([td,pd.get_dummies(td.Cabin, prefix=\"Cabin\"),pd.get_dummies(td.Age_Range, prefix=\"Age_Range\"), pd.get_dummies(td.Embarked, prefix=\"Emb\", drop_first = True), pd.get_dummies(td.Salutation, prefix=\"Title\", drop_first = True),pd.get_dummies(td.Fare_Category, prefix=\"Fare\", drop_first = True), pd.get_dummies(td.Pclass, prefix=\"Class\", drop_first = True)], axis=1)\ntd['Sex'] = LabelEncoder().fit_transform(td['Sex'])\ntd['Is_Alone'] = LabelEncoder().fit_transform(td['Is_Alone'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"td.drop(['Pclass', 'Fare','Cabin', 'Fare_Category','Name','Salutation', 'Ticket','Embarked', 'Age_Range', 'SibSp', 'Parch', 'Age'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_to_be_predicted = td[td.Survived.isnull()]\nX_to_be_predicted = X_to_be_predicted.drop(['Survived'], axis = 1)\n\n#Training data\ntrain_data = td\ntrain_data = train_data.dropna()\nfeature_train = train_data['Survived']\nlabel_train  = train_data.drop(['Survived'], axis = 1)\ntrain_data.shape #891 x 28\n\n##Gaussian\nclf = GaussianNB()\nx_train, x_test, y_train, y_test = train_test_split(label_train, feature_train, test_size=0.2)\nclf.fit(x_train,  np.ravel(y_train))\nprint(\"NB Accuracy: \"+repr(round(clf.score(x_test, y_test) * 100, 2)) + \"%\")\nresult_rf=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\nprint('The cross validated score for GNB is:',round(result_rf.mean()*100,2))\ny_pred = cross_val_predict(clf,x_train,y_train,cv=10)\nsns.heatmap(confusion_matrix(y_train,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix for NB', y=1.05, size=15)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(criterion='entropy', \n                             n_estimators=700,\n                             min_samples_split=10,\n                             min_samples_leaf=1,\n                             max_features='auto',\n                             oob_score=True,\n                             random_state=1,\n                             n_jobs=-1)\nx_train, x_test, y_train, y_test = train_test_split(label_train, feature_train, test_size=0.2)\nclf.fit(x_train,  np.ravel(y_train))\nprint(\"RF Accuracy: \"+repr(round(clf.score(x_test, y_test) * 100, 2)) + \"%\")\n\nresult_rf=cross_val_score(clf,x_train,y_train,cv=10,scoring='accuracy')\nprint('The cross validated score for Random forest is:',round(result_rf.mean()*100,2))\ny_pred = cross_val_predict(clf,x_train,y_train,cv=10)\nsns.heatmap(confusion_matrix(y_train,y_pred),annot=True,fmt='3.0f',cmap=\"summer\")\nplt.title('Confusion_matrix for RF', y=1.05, size=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = clf.predict(X_to_be_predicted)\nsubmission = pd.DataFrame({'PassengerId':X_to_be_predicted.PassengerId,'Survived':result})\nsubmission.Survived = submission.Survived.astype(int)\nprint(submission.shape)\nfilename = 'Titanic Predictions.csv'\nsubmission.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}