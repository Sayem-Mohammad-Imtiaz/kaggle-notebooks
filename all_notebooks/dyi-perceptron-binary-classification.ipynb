{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Simple perceptron implementation and use\nThe aim of this kernel is to implement a perceptron to better understand how it works and test it out\n\nThe two most important part of the perceptron are:\n* The formula used for output calculation: $$ {y=\\ w}^Tx=\\sum_{j=1}^{m}{w_jx_j+w_0} $$\n* The formula used for weight updates: $$ \\mathrm{\\Delta}w_j^t=\\eta(r^t-y^t)x_j^t $$\n\n\nAlthough the learning factor can be gradually decresead to assure convergence, in my implementation it is a constant."},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nclass myPerceptron:\n\n    bias = 0\n    learning_factor = 0\n    inputs = []\n    labels = []\n    weights = []\n\n    def __init__(self, bias, learning_factor):\n        self.bias = bias\n        self.learning_factor = learning_factor\n\n    # helper methods ---------------------------------\n    \n    # given the deltas to be applied to the weights, weights += deltas\n    def refresh_weights(self, deltas):\n        for i in range(len(self.weights)):\n            self.weights[i] += deltas[i]\n    \n    # applies the threshold function to the weighted sums given\n    def classification(self, predictions):\n        classification = []\n        for p in predictions:\n            classification.append(self.threshold_function(p))\n        return classification\n    \n    # weighted sum (since we say that neurons fire, my perceptron fires too)\n    def fire(self, input):\n        y = self.bias\n        for i in range(len(input)):\n            y += input[i]*self.weights[i]\n        return y\n\n    def threshold_function(self, value):\n        if value > 0:\n            return 1\n        else: return 0\n\n    # / helper methods ---------------------------------\n        \n    def fit(self, X_train, y_train):\n        deltas = [0]*len(X_train[0]) # deltas represents the change that need to be made to the weights\n        \n        # if weights are not set, randomly generate them\n        if len(self.weights) == 0:\n            self.weights = [random.uniform(-.0001, .0001) for i in range(len(X_train[0]))]\n        \n        # calculating deltas as delta = learning_factor * (y_train - perceptron_prediction) * input\n        for i in range(0, len(X_train)):\n            for j in range(0, len(X_train[0])):\n                deltas[j] = (self.learning_factor * (y_train[i]-self.threshold_function(self.fire(X_train[i])))*X_train[i][j])\n        \n        # sum deltas to weights\n        self.refresh_weights(deltas)   \n       \n    def predict(self, x_test):\n        y = []\n        for i in x_test:\n            y.append(self.fire(i))\n        return self.classification(y)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing the data\nIn this section:\n* i limit the number of features and examples by hand \n* i encode the feature 'Date': instead of using full datetime, i use the day of the year\n* i encode the target feature 'RainTomorrow': 'No' = 0, 'Yes' = 1\n* i use minmax scaler to scale the features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndata = pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv', parse_dates=['Date'])\n\n# taking only a few years\ndata = data[data.Date > np.datetime64('2008-12-31')]\ndata = data[data.Date < np.datetime64('2012-01')]\n\n# taking data only for sydney\ndata = data[data.Location == 'Sydney']\n\n# keeping just a few features for semplicity\nfeatures = ['Date', 'Rainfall', 'Humidity3pm', 'RainTomorrow']\n\ndata = data[features]\n\ndata = data.dropna(axis=1, how='all')\ndata = data.dropna(axis=0, how='any')\n\n# date to day of the year\ndata['Date'] = data['Date'].apply(lambda x: pd.Timestamp(x).dayofyear)\n\n# classes label to 0-1\ndata['RainTomorrow'] = data['RainTomorrow'].apply(lambda x: 0 if x=='No' else 1)\n\n# trying out MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nstandardized_columns = ['Date', 'Rainfall', 'Humidity3pm']\nscaler = MinMaxScaler()\ndata[standardized_columns] = scaler.fit_transform(data[standardized_columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Taking a look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\nplt.rcParams['figure.figsize'] = [14, 10]\n\nplt.scatter(data.Humidity3pm, data.Rainfall, color=data['RainTomorrow'].apply(lambda x: 'Red' if x==0 else 'Blue'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing train and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = data[list(set(data.columns)-set(['RainTomorrow']))]\ny = data.RainTomorrow\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\nX_train = X_train.to_numpy()\nX_test = X_test.to_numpy()\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scikit-learn Perceptron\nFor comparison, i also use the sklearn.linear_model perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Perceptron\nclf = Perceptron(tol=1e-3, random_state=2252332)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\nsumm=0\nfor i in range(0, len(predictions)):\n    if predictions[i] != y_test[i]:\n        summ += 1\n\nprint('real error {}%'.format(summ/len(y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# My Perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"perc = myPerceptron(0, .01)\nperc.fit(X_train, y_train)\npredictions = perc.predict(X_test)\n\nsumm=0\nfor i in range(0, len(predictions)):\n    if predictions[i] != y_test[i]:\n        summ += 1\n\nprint('real error {}%'.format(summ/len(y_test)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results are close, however the naive implementation could use some improvement."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}