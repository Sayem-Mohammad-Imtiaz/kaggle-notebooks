{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Linear Regression on Advertising Dataset\n**A simple Linear Regression (LR) ML algorithm on the Advertising dataset from Kaggle. Made with numpy and pandas library from scratch with LR algorithms**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random as rnd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nDATASET_PATH = os.path.join(dirname, filename)\ndataset = pd.read_csv(DATASET_PATH)\nprint('\\nData(First 5 rows):')\nprint(dataset.head())\nprint('\\n Summary of Data:')\nprint(dataset.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the data\nfig, axs = plt.subplots(1, 3)\naxs[0].plot(dataset['TV'], dataset['Sales'], 'rx')\naxs[1].plot(dataset['Radio'], dataset['Sales'], 'rx')\naxs[2].plot(dataset['Newspaper'], dataset['Sales'], 'rx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot for better understanding\n# Sales and TV vary linearly\nplt.figure()\nplt.plot(dataset['TV'], dataset['Sales'], 'rx')\nplt.xlabel('TV')\nplt.ylabel('Sales')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# turn dataframe to numpy array for segregation of data\ndata = dataset.values\ndata = np.array([(data[:, 0]), (data[:, 3])])\ndata = np.transpose(data)\ntrain_x = []\ntrain_y = []\ncv_x = []\ncv_y = []\ntest_x = []\ntest_y = []\nfig = plt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters\ncv_ratio = 0.2\ntest_ratio = 0.2\nalpha = 0.000007\niters = 500\n# weight = 0.054\n# bias = 6.948\nweight = 0.1\nbias = 7\nlambda_r = 1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the data into train, cv, test sets\ndef split(data, cv_ratio, test_ratio):\n    # print(np.shape(data))\n    index_list = []\n    for i in range(int(cv_ratio * 100)):\n        index = rnd.randrange(0, len(data))\n        index_list.append(index)\n        cv_x.append(data[index, 0])\n        cv_y.append(data[index, 1])\n    data_n = np.delete(data, index_list, 0)\n    # print(np.shape(data_n))\n    index_list = []\n    for i in range(int(test_ratio * 100)):\n        index = rnd.randrange(0, len(data_n))\n        index_list.append(index)\n        test_x.append(data_n[index, 0])\n        test_y.append(data_n[index, 1])\n    data_nw = np.delete(data_n, index_list, 0)\n    # print(np.shape(data_nw))\n    for i in range(len(data_nw)):\n        train_x.append(data_nw[i, 0])\n        train_y.append(data_nw[i, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# call split functions and convert the arrays from lists to numpy arrays\nsplit(data, cv_ratio, test_ratio)\ntrain_x = np.array(train_x)\ntrain_y = np.array(train_y)\ncv_x = np.array(cv_x)\ncv_y = np.array(cv_y)\ntest_x = np.array(test_x)\ntest_y = np.array(test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating model\ndef model(x, y, flag):\n    cost_iter = []\n    m = len(x)\n    global weight\n    global bias\n    for i in range(iters):\n        y_pred = (x * weight) + bias\n        loss = y_pred - y\n        if flag == 1:\n            cost = ((sum(pow(loss, 2)) / (2 * m)) +\n                    ((lambda_r * pow(weight, 2)) / (2 * m)))\n        else:\n            cost = (sum(pow(loss, 2)) / (2 * m))\n        cost_iter.append(cost)\n        w_grad = (sum(np.multiply(loss, x))) / m\n        b_grad = (sum(loss)) / m\n        weight -= (alpha * w_grad)\n        bias = bias - (alpha * b_grad)\n\n    for i in range(iters):\n        plt.plot(i, cost_iter[i], 'rx')\n    plt.xlabel(\"No of iterations\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n    # if m == 20:\n    #     print(sum(cost_iter)/iters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_test(x, y):\n    m = len(x)\n    global weight\n    global bias\n    y_pred = (x * weight) + bias\n    loss = y_pred - y\n    cost = (sum(pow(loss, 2)) / (2 * m))\n    print('\\n Cost of test Set:', cost)\n    plt.plot(x, y, 'rx')\n    plt.plot(x, y_pred)\n    plt.show()\n    # print('Accuracy of model:', accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# traning model\nmodel(train_x, train_y, 0)\nmodel(cv_x, cv_y, 1)\n\n# test model\nmodel_test(test_x, test_y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}