{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Loaing Necessary Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, learning_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n\nfrom tensorflow.keras.preprocessing import image\n\nfrom PIL import ImageFile, ImageOps\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading Image Info from CSV and Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/memotion-dataset-7k/memotion_dataset_7k/labels.csv')\ndf.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\ndf = df.drop(columns = ['text_ocr'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned = df.copy()\ncleaned.dropna(inplace=True)\ncleaned.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image(dataframe):\n    \n    dataframe.dropna(inplace=True)\n    \n    width = 100\n    height = 100\n    X = []\n    path = '../input/memotion-dataset-7k/memotion_dataset_7k/images/'+dataframe['image_name']\n    \n    for i in tqdm(range(dataframe.shape[0])):\n        if i in [119, 4799, 6781, 6784, 6786]:\n            pass\n        else:\n            img = image.load_img(path[i],target_size=(width,height,3))\n            img = ImageOps.grayscale(img)\n            img = image.img_to_array(img)\n            img = img/255.0\n            X.append(img)\n\n    X = np.array(X)\n    X = X.reshape(X.shape[0], 100*100)\n    \n    rows_to_drop = ['image_120.jpg', 'image_4800.jpg', 'image_6782.jpg', 'image_6785.jpg', 'image_6787.jpg',\n                    'image_6988.jpg', 'image_6989.jpg', 'image_6990.png', 'image_6991.jpg', 'image_6992.jpg']\n    \n    for images in rows_to_drop:\n        dataframe.drop(dataframe[dataframe['image_name'] == images].index, inplace=True)\n        \n    text_data = CountVectorizer().fit_transform(dataframe['text_corrected'].values)\n    text_data = TfidfTransformer().fit_transform(text_data).toarray()\n    \n    features = np.hstack((X, text_data))\n    \n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = get_image(cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_target(dataframe):\n    target_A = dataframe.copy()['overall_sentiment']\n    target_A = pd.get_dummies(target_A)\n    \n    target_B = dataframe.copy()\n    target_B = target_B.replace({'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious':1},\n                        'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1},\n                        'offensive': {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1},\n                        'motivational': {'not_motivational': 0, 'motivational': 1}})\n    target_B = target_B.iloc[:,2:6]\n    \n    df1 = pd.get_dummies(cleaned['sarcasm'])\n    df2 = pd.get_dummies(cleaned['humour'])\n    df3 = pd.get_dummies(cleaned['offensive'])\n    df4 = pd.get_dummies(cleaned['offensive'])\n    frames = [df1, df2, df3, df4]\n    target_C = pd.concat(frames, axis=1)\n    \n    return target_A, target_B, target_C","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_A, target_B, target_C = create_target(cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, multilabel_confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n\nclasifier_A = MultiOutputClassifier(LogisticRegression(max_iter=10000)).fit(X_train, y_train)\n\nprediction = clasifier_A.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n\nclasifier_B = MultiOutputClassifier(LogisticRegression(max_iter=10000)).fit(X_train, y_train)\nprediction = clasifier_B.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n\nclasifier_C = MultiOutputClassifier(LogisticRegression(max_iter=10000)).fit(X_train, y_train)\nprediction = clasifier_C.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n\nclasifier_A = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\nprediction = clasifier_A.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n\nclasifier_B = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\nprediction = clasifier_B.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n\nclasifier_C = MultiOutputClassifier(RandomForestClassifier()).fit(X_train, y_train)\nprediction = clasifier_C.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_A.values, test_size = 0.2, stratify=target_A)\n\nclasifier_A = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\nprediction = clasifier_A.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_B.values, test_size = 0.2, stratify=target_B)\n\nclasifier_B = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\nprediction = clasifier_B.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target_C.values, test_size = 0.2, stratify=target_C)\n\nclasifier_C = MultiOutputClassifier(DecisionTreeClassifier()).fit(X_train, y_train)\nprediction = clasifier_C.predict(X_test)\n\nprint(f1_score(y_test, prediction, average='micro'))\nprint(f1_score(y_test, prediction, average='macro'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}