{"cells":[{"metadata":{"id":"2rg5iPLnj1SD"},"cell_type":"markdown","source":"**Importing Necessary Libraries**"},{"metadata":{"id":"TkCkvBYcCTQU","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom sklearn.neighbors import KNeighborsClassifier\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"I_bbSRGLLmlV"},"cell_type":"markdown","source":"# **NYPD SHOOTING INCIDENT DATA**\n\n---\n\n\n\n\n"},{"metadata":{"id":"tkR9WsFDfOHW"},"cell_type":"markdown","source":"**Objective**\n\nWe have leveraged the dataset to derive a solution to the following business questions:\n\n*   Trend in number of incidents in each precinct\n* Which Boroughs are more unsafe than others?\n\n*   Which age group and race account for the highest number of perpetrators?\n\n*   Which jurisdiction has observed the highest number of incidents?\n*   How many incidents resulted in murder?\n*   Which age group of victims are mostly targeted by perpetrators?\n*   Trend of the incidents reported from 2006 to 2019 - which year has observed the highest number of shooting incidents in New York?\n*   Predictive model to predict the age-group, sex, race of the victim and location of the incident\n*   Which is the best Predictive analytical method for the dataset?\n\n\n---\n\n\n\n\n\n"},{"metadata":{"id":"6Iv8r7NkA2lj"},"cell_type":"markdown","source":"**Importing Data**"},{"metadata":{"id":"5ta12OjdCTQc","trusted":true},"cell_type":"code","source":"#Creating a data frame and storing NYPD Shooting Incident Data\ndf = pd.read_csv('../input/nypd-shooting-history/NYPD_Shooting_Incident_Data__Historic_.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"M2TI38xYBBpG"},"cell_type":"markdown","source":"# **Section 1: DATA CLEANING**"},{"metadata":{"id":"w5mA4Rq1CTQc","outputId":"ef24bc24-01b1-41ab-ed9a-862f766b8c26","trusted":true},"cell_type":"code","source":"#Checking the number of columns present in the dataframe.\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"DoqslXkSCTQe","outputId":"03b81763-9727-42d1-f1e8-13366f992a32","trusted":true},"cell_type":"code","source":"#Checking the number of columns present with datatypes(with the help of info command).\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"OhpF3Yb7CTQe","outputId":"40280fff-c070-47a2-b754-78df72f43c44","trusted":true},"cell_type":"code","source":"#Getting an insight of dataframe withe help of head command.\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"eRkWjz6WkxAJ"},"cell_type":"markdown","source":"**Feature Engineering: Working with Null values and outliers**"},{"metadata":{"id":"DeQPsehqCTQe","outputId":"6a8bc7fa-14db-4bd8-b5ea-3643e09f7c96","trusted":true},"cell_type":"code","source":"#Checking the number of null values present in the data set. \ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"WwOzVzOeCTQf","outputId":"b4cc1474-0bc3-4cbf-99bd-1867d1c0cbda","trusted":true},"cell_type":"code","source":"#Now we are calculating the percentage of null values present in the data set(column wise).\nprint('Percentage of Null values with respect to columns in the dataset')\n100* df.isnull().sum()/len(df)","execution_count":null,"outputs":[]},{"metadata":{"id":"nOWcomSeCTQf","outputId":"b7bc5dc8-ea80-4d3f-e09f-f87f30ef8ffd","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'PERP_RACE' as it conatins null values. This function will return 'PERP_RACE' column with 0 null values.\ncol = 'PERP_RACE'\ndf[col].value_counts()\ns = df[col].value_counts(normalize=True)\nprint('Values present in the columns with percentage')\nprint(s)\nmissing = df[col].isnull()\ndf.loc[missing,col] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\nprint('Null values filled with appropriate data')\ndf[col].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"vYDHO_iPCTQg","outputId":"d0dc8fc1-b6e0-4a9a-e971-7a67618abcaa","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'PERP_AGE_GROUP' as it conatins null values. This function will return 'PERP_AGE_GROUP' column with 0 null values.\ncol = 'PERP_AGE_GROUP'\ndf[col].value_counts()\ns = df[col].value_counts(normalize=True)\nprint('Values present in the columns with percentage')\nprint(s)\nmissing = df[col].isnull()\ndf.loc[missing,col] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\nprint('Null values filled with appropriate data')\ndf[col].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"92JeUemICTQg","outputId":"5b03528d-5bef-48bd-be8f-e4808ee30566","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'PERP_AGE_GROUP' as it conatins oultier value(224). This function will return 'PERP_AGE_GROUP' column after removeing outlier value mentioned in the function.\n#val_rem(df,'PERP_AGE_GROUP','224')\ndf.drop(df.loc[df['PERP_AGE_GROUP']=='224'].index, inplace=True)\ndf['PERP_AGE_GROUP'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"4URBfmBcCTQg","outputId":"1013f16e-f5bb-4799-b3e1-5ceadb798de3","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'PERP_AGE_GROUP' as it conatins oultier value(940). This function will return 'PERP_AGE_GROUP' column after removeing outlier value mentioned in the function.\n#val_rem(df,'PERP_AGE_GROUP','940')\ndf.drop(df.loc[df['PERP_AGE_GROUP']=='940'].index, inplace=True)\ndf['PERP_AGE_GROUP'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"34Zk9cTJCTQh","outputId":"8ea5cc2a-d145-4e2a-cf08-ada3e9551348","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'PERP_AGE_GROUP' as it conatins oultier value(1020). This function will return 'PERP_AGE_GROUP' column after removeing outlier valu mentioned in the function.\n#val_rem(df,'PERP_AGE_GROUP','1020')\ndf.drop(df.loc[df['PERP_AGE_GROUP']=='1020'].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"uqyvx2qzCTQh","outputId":"e7c149b2-434b-459e-aa06-79af384d733f","trusted":true},"cell_type":"code","source":"#Types of values with counts present in 'PERP_SEX' column.\ndf['PERP_SEX'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"GJKEETBvCTQh","outputId":"cf3d8282-eb02-47ad-d327-556ae6e61991","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'PERP_SEX' as it conatins null values. This function will return 'PERP_SEX' column with 0 null values.\ncol = 'PERP_SEX'\ndf[col].value_counts()\ns = df[col].value_counts(normalize=True)\nprint('Values present in the columns with percentage')\nprint(s)\nmissing = df[col].isnull()\ndf.loc[missing,col] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\nprint('Null values filled with appropriate data')\ndf[col].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"9ISsK_bzCTQh","outputId":"7cdf0c3d-37df-4c59-90ce-400c2e97f377","trusted":true},"cell_type":"code","source":"#Types of values with counts present in 'LOCATION_DESC' column.\ndf['LOCATION_DESC'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"hvUUYf8ECTQi","outputId":"9e892d05-e78a-466c-883c-3a955bd70eb8","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'LOCATION_DESC' as it conatins null values. This function will return 'LOCATION_DESC' column with 0 null values.\ncol = 'LOCATION_DESC'\ndf[col].value_counts()\ns = df[col].value_counts(normalize=True)\nprint('Values present in the columns with percentage')\nprint(s)\nmissing = df[col].isnull()\ndf.loc[missing,col] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\nprint('Null values filled with appropriate data')\ndf[col].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"v-1t6eJjCTQi","outputId":"f2ab92dc-4eaf-43c6-eebc-6c4f0da2d916","trusted":true},"cell_type":"code","source":"#Checking the types of values present in 'JURISDICTION_CODE' column.\ndf['JURISDICTION_CODE'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"GrRXUIvpCTQi","outputId":"3a3fe8f5-5479-468f-c2a2-fbe395ef7603","trusted":true},"cell_type":"code","source":"#Passing dataframe-df and column name-'JURISDICTION_CODE' as it conatins null values. This function will return 'JURISDICTION_CODE' column with 0 null values.\ncol = 'JURISDICTION_CODE'\ndf[col].value_counts()\ns = df[col].value_counts(normalize=True)\nprint('Values present in the columns with percentage')\nprint(s)\nmissing = df[col].isnull()\ndf.loc[missing,col] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\nprint('Null values filled with appropriate data')\ndf[col].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"tR5uFaZMCTQi","outputId":"e55ba811-da30-428a-a664-db3c865c990c","trusted":true},"cell_type":"code","source":"#After working on serveral columns containing null values and outliers. Validating with isna() command to see if null values are still present in our data set or not.\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"5ee0Twz-B5xN"},"cell_type":"markdown","source":"# **Section 2: DESCRIPTIVE ANALYSIS**"},{"metadata":{"id":"sKHAN7BjFOVa"},"cell_type":"markdown","source":"Trend in the number of incidents in each precinct\n*   Total number of precincts â€“ 123\n*   Highest cases observed in precincts (40-80)"},{"metadata":{"id":"YM3vylkCZEpQ","outputId":"db2ca855-0604-48f7-8cdf-a7ae9c1638b5","trusted":true},"cell_type":"code","source":"def annot_plot(ax,w,h):                                    # function to add data to plot\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    for p in ax.patches:\n        ax.annotate('{0:.1f}'.format(p.get_height()), (p.get_x()+w, p.get_height()+h))\n\n# create a figure and axis \nfig, ax = plt.subplots() \n# count the occurrence of each class \ndata = df['PRECINCT'].value_counts() \n# get x and y data \npoints = data.index \nfrequency = data.values \n# create bar chart \nax.bar(points, frequency) \n# set title and labels \nax.set_title('NYPD Shooting Incident in each precinct') \nax.set_xlabel('PRECINCT') \nax.set_ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{"id":"Fl_8nIIZGMPP"},"cell_type":"markdown","source":"Visualizing the amount of incidents took place area wise\n\n\n*   As per the the visualization, the most number of shooting incidents have been reported in Brooklyn followed by Bronx, Queens, Manhattan and Staten Island respectively\n\n\n"},{"metadata":{"id":"AMB-CSpPCTQk","outputId":"83eb1903-ded6-43a7-e5c0-f17e11360904","trusted":true},"cell_type":"code","source":"group_boro=df.groupby('BORO')['INCIDENT_KEY'].count().sort_values(ascending=False)\n#Setting the figure size and limits.\nplt.subplots(figsize=(15,8))\nplt.ylim(0,10000,10000)\n#Creating a bar plot to show the result.\nax = group_boro.plot(kind='bar',fontsize=12,color='grey')\n#Defining axis labels and title for the graph.\nplt.xlabel('Places',fontsize=12)\nplt.ylabel('INCIDENT KEY',fontsize=12)\nplt.title('Incident count by Places',fontsize=12)\n#plotting the graph.\nannot_plot(ax,0.2,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"EZ8xAQLWFS6b"},"cell_type":"markdown","source":"Perpetrators by race and age group\n\n\n*   The visualization below highlights that maximum number of suspects belong to the race: black and age group: 18-24 followed by the race: White Hispanics and age group: 25-44\n"},{"metadata":{"id":"WSQXOg6uCTQj","outputId":"2a2b61ca-e106-40fb-ea9e-39ee0a37ccf5","trusted":true},"cell_type":"code","source":"def annot_plot(ax,w,h):                                    # function to add data to plot\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    for p in ax.patches:\n        ax.annotate('{0:.1f}'.format(p.get_height()), (p.get_x()+w, p.get_height()+h))\n\nplt.figure(figsize=(18,7))\n#Setting the limits for countplot shown below.\nplt.ylim(0,6000,6000)\n#Creating a countplot to show 'PERP_RACE' with hue-'PERP_AGE_GROUP'.\nax = sns.countplot('PERP_RACE',hue='PERP_AGE_GROUP',data=df,palette='Set2',)\nplt.xticks(rotation = 45, ha = 'right')\n#Placing the legend in the grapgh.\nplt.legend(bbox_to_anchor=(0.9, 0.8), loc=2, borderaxespad=0.)\n#ploting the graph.\nannot_plot(ax,0.02,1)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Ud-r_LNUFoZE"},"cell_type":"markdown","source":"Visualizing perpetrators by race for each age group\n\n\n*   The visualization below highlights that maximum number of suspects belong to the race: black and age group: 18-24 followed by the race: White Hispanics and age group: 25-44\n"},{"metadata":{"id":"kvJgn1swCTQj","outputId":"78e34773-c623-42bf-8ec6-35e1e6b80aa3","trusted":true},"cell_type":"code","source":"#Visualizing counts of each unique value present in 'PER_RACE' by grouping it age wise.\nage_group = df.groupby('PERP_AGE_GROUP')['PERP_RACE'].value_counts()\ngroups = age_group.groupby('PERP_AGE_GROUP')\nfig = plt.figure()\ncount = 1\n#Creating a for loop to plot different bar plots age wise.\nfor year, group in groups:\n    #adding subplots in the output.\n    ax = fig.add_subplot(6,3,count) \n    ax.set_title(year)\n    ax = group[year].plot.bar(figsize = (12,30), width = 0.8,color='orange')#creating bar plots\n    \n    count+=1;\n    #Defining labels for the axis peresnt in the grapgh.\n    plt.xlabel('')\n    plt.yticks([])\n    plt.ylabel('Count of PERP RACE')\n    \n    #Intializing a array and appending it with the height\n    total_of_year = []\n    for i in ax.patches:\n        total_of_year.append(i.get_height())\n    total = sum(total_of_year)\n    for i in ax.patches:\n        ax.text(round(i.get_x()+0.2,1),round(i.get_height()-1.5,1),s= round(i.get_height(),1),color=\"black\",fontweight='bold') #adding data labels (total value of spendings ) to the bars\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"J8L857Y5F2BL"},"cell_type":"markdown","source":"Visualizing the NYPD jurisdiction codes reported for every incident\n*   Most incidents were reported in the Jurisdiction code 0 (Patrol) followed by Jurisdiction 2 (Housing) and Jurisdiction 1 (Transit) respectively"},{"metadata":{"id":"j-hTT_I1CTQj","outputId":"61e5d46f-2cab-4e69-f98c-3f0b98e6a008","trusted":true},"cell_type":"code","source":"#Defining figure size and setting limits to the graphs.\nplt.figure(figsize=(16,7))\nplt.ylim(0,20000,20000)\n#Creating a countplot for 'JURISDICTION_CODE'. To show the count of distinct values present in the column.\nax = sns.countplot('JURISDICTION_CODE',data=df)\nannot_plot(ax,0.3,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"3QGOj-Y3GEMT"},"cell_type":"markdown","source":"Visualizing the jurisdiction codes reported per location for every incident\n\n\n*   Most incidents were reported in the Jurisdiction code 0 (Patrol)\n*   Highest number of incidents were reported in Brooklyn with the Jurisdiction code 0\n\n"},{"metadata":{"id":"cFHonluLCTQk","outputId":"4ee32f48-f820-499e-a157-89f1ba360b6a","trusted":true},"cell_type":"code","source":"#Setting the figure size and limits.\nplt.figure(figsize=(16,7))\nplt.ylim(0,8000,8000)\n#Creating a countplot for 'JURISDICTION_CODE' by area. To show the count of distinct values present in the column area wise.\nax = sns.countplot('JURISDICTION_CODE',hue='BORO',data=df,palette='Set2')\nannot_plot(ax,0.02,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"rNBzDcIMGUb8"},"cell_type":"markdown","source":"Visualizing the shooting incidents that resulted in murders\n\n\n*   Maximum number (17496) of incidents reported were not classified as murder as 4127 incidents resulted in murder\n"},{"metadata":{"id":"CQCARLhQCTQk","outputId":"dcc1713f-7e0d-42d4-ba43-2bb17c5b8c1f","trusted":true},"cell_type":"code","source":"#Setting the figure size and limits.\nplt.figure(figsize=(16,7))\nplt.ylim(0,20000,20000)\n#creating a count plot for 'STATISTICAL_MURDER_FLAG column. To show distict values present in the column.\nax = sns.countplot('STATISTICAL_MURDER_FLAG',data=df)\n#plotting the graph.\nannot_plot(ax,0.2,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"FVGTFSKnGlCK"},"cell_type":"markdown","source":"Analyzing the shooting incidents that resulted in murders - categorized by the suspect's age group\n*   Maximum number (17496) of incidents reported were not classified as murder\n*   Maximum number of suspects belong to the age group 18-24 in cases of the incident resulting in murder or otherwise\n"},{"metadata":{"id":"7oirexnJCTQk","outputId":"fbee3a4a-85c1-4abd-ff69-c7cba68ce130","trusted":true},"cell_type":"code","source":"#Setting the figure size and limits.\nplt.figure(figsize=(16,7))\nplt.ylim(0,8000,8000)\n#Visualizing column 'STATISTICAL_MURDER_FLAG' by hue='PERP_AGE_GROUP'. To show the count of unique values present in 'STATISTICAL_MURDER_FLAG' column by age group. \nax = sns.countplot('STATISTICAL_MURDER_FLAG',hue='PERP_AGE_GROUP',data=df,palette='Set1')\n#plotting the graph.\nannot_plot(ax,0.02,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9gORqPrCG0mA"},"cell_type":"markdown","source":"Visualizing the victims per their gender\n*   Black males are the most common victims followed by white hispanic males\n* American Indian/Alaskan Natives are the least common victims\n"},{"metadata":{"id":"LOMtXpReCTQl","outputId":"c2b97ce1-81b9-4bf8-f94b-dd9f9b78447b","trusted":true},"cell_type":"code","source":"#Defining palette and style for seaborn.\nsns.set_palette(\"GnBu_d\")\nsns.set_style('whitegrid')\n#Setting figure size and axis limits.\nplt.figure(figsize=(16,7))\nplt.yticks(fontsize = 10)\nplt.ylim(0,16000,16000)\n#creating count plot of values present in 'VIC_RACE' column with setting hue to 'VIC_SEX'. To show 'VIC_RACE' by 'VIC_SEX wise.\nax = sns.countplot('VIC_RACE',hue='VIC_SEX',data=df,palette='Set1')\nannot_plot(ax,0.02,1)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"sge-QwDWG-Vx"},"cell_type":"markdown","source":"Visualizing victims categorized by race for every age group\n\n\n*   Maximum number of victims belong to the age group: 18-24 followed by 25-44 and less than 18 respectively\n"},{"metadata":{"id":"zovVQdpuCTQl","outputId":"6e39dffa-26ea-45ef-ce81-99ebc4584e25","trusted":true},"cell_type":"code","source":"#Visualizing counts of each unique value present in 'VIC_RACE' by grouping it to 'VIC_AGE_GROUP'.\nvic_age = df.groupby('VIC_AGE_GROUP')['VIC_RACE'].value_counts()\ngroups = vic_age.groupby('VIC_AGE_GROUP')\nfig = plt.figure()\ncount = 1\n#Creating a for loop to plot different bar plots age wise.\nfor year, group in groups:\n    #Creating subplots to show the output.\n    ax = fig.add_subplot(6,3,count)\n    ax.set_title(year)\n    ax = group[year].plot.bar(figsize = (12,30), width = 0.8,color='indigo')#creating bar plots\n    \n    count+=1;\n    #Defining labels for the axis peresnt in the graph.\n    plt.xlabel('')\n    plt.yticks([])\n    plt.ylabel('Count of Victims(Race Wise)')\n    \n    \n    total_of_year = []\n    for i in ax.patches:\n        total_of_year.append(i.get_height())\n    total = sum(total_of_year)\n    for i in ax.patches:\n        ax.text(round(i.get_x()+0.2,1),round(i.get_height()-1.5,1),s= round(i.get_height(),1),color=\"black\",fontweight='bold') #adding data labels (total value of spendings ) to the bars\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"JrSCuU1wHOAm"},"cell_type":"markdown","source":"Visualizing victims categorized by gender for every age group\n\n*   The bar plots below highlight that Black males are the most common victims followed by White Hispanic males\n*   Maximum number of victims belong to the age group: 18-24 followed by 25-44 and less than 18 respectively\n\n"},{"metadata":{"id":"QUGZZOJgCTQl","outputId":"19a4cd8d-19e4-4ab8-8967-a40102942410","trusted":true},"cell_type":"code","source":"#Visualizing counts of each unique value present in 'VIC_RACE' by grouping it to 'VIC_AGE_GROUP'.\na = df.groupby('VIC_AGE_GROUP')['VIC_SEX'].value_counts()\ngroups = a.groupby('VIC_AGE_GROUP')\nfig = plt.figure()\ncount = 1\n#Creating a for loop to plot different bar plots sex wise.\nfor year, group in groups:\n    #Creating subplots to show the output.\n    ax = fig.add_subplot(6,3,count)\n    ax.set_title(year)\n    ax = group[year].plot.bar(figsize = (13,35), width = 0.8,color='Red')#creating bar plots\n    \n    count+=1;\n    #Defining labels for the axis present in the graph.\n    plt.xlabel('')\n    plt.yticks([])\n    plt.ylabel('Count of Victims(Sex Wise)')\n    \n    \n    total_of_year = []\n    for i in ax.patches:\n        total_of_year.append(i.get_height())\n    total = sum(total_of_year)\n    for i in ax.patches:\n        ax.text(round(i.get_x()+0.2,1),round(i.get_height()-1.5,1),s= round(i.get_height(),1),color=\"black\",fontweight='bold') #adding data labels (total value of spendings ) to the bars\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"CBKkFvtJCTQm","trusted":true},"cell_type":"code","source":"#Creating two new columns in the dataframe to store INCIDENT-YEAR & MONTH from the column 'OCCUR_DATE'.\ndf[\"INCIDENT_YEAR\"] = pd.DatetimeIndex(df[\"OCCUR_DATE\"]).year\ndf[\"INCIDENT_MONTH\"] = pd.DatetimeIndex(df[\"OCCUR_DATE\"]).month","execution_count":null,"outputs":[]},{"metadata":{"id":"_zIbAsplHcVd"},"cell_type":"markdown","source":"Count of incidents reported from 2006 to 2019\n*   The visualization below highlights that there has been a gradual decrease in the number of incidents reported since 2006\n\n\n"},{"metadata":{"id":"8f3iWFSzCTQm","outputId":"e953b92c-f142-4cf7-bfe5-3f8c480e5bfa","trusted":true},"cell_type":"code","source":"#Creating a plotly histogram graph to showcase the count of incident reported in the specific year and months\nfig = px.histogram(df, x=\"INCIDENT_YEAR\", color=\"INCIDENT_MONTH\", marginal=\"rug\",\n                   hover_data=df.columns)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"5amP3M_4JKup"},"cell_type":"markdown","source":"Trend of incidents reported from 2006 to 2019\n\n*   The visualization below highlights that there has been a gradual decrease in the number of incidents reported since 2006\n\n*   There has been instances of slight increase in the number of cases in 2009 to 2011 and 2013 to 2014 but the trend soon started decreasing gradually.\n\n"},{"metadata":{"id":"C14f0jO4CTQr","outputId":"d13e60a7-b9d4-4595-d471-f34a77fbf50e","trusted":true},"cell_type":"code","source":"#Creating a line grapgh to show the amount of incident occured year wise. This graph will help us to understand the current trends of incidents(whether its high or low).\ndf1 = df[['INCIDENT_YEAR','BORO','INCIDENT_KEY']] \ndf1 = df1.groupby('INCIDENT_YEAR')[['INCIDENT_KEY']].count().reset_index()\ndf2 = pd.melt(df1, id_vars=['INCIDENT_YEAR'], value_vars=['INCIDENT_KEY'])\nimport plotly.express as px\nfig = px.line(df2, x=\"INCIDENT_YEAR\", y=\"value\", color='variable', \n              title=f'ALL Incidents Reported')\nfig.update_layout(yaxis_range=[100,2500])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"k2kWXXzdCbO8"},"cell_type":"markdown","source":"# **PREDICTIVE ANALYSIS**"},{"metadata":{"id":"m6sge666CTQr","outputId":"1bd9bd65-fdfd-4d38-e9f8-38a5d5d92e96","trusted":true},"cell_type":"code","source":"#Importing Lable Encoder to work with categorical variable.\nfrom sklearn.preprocessing import LabelEncoder\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\ndf['BORO'] = labelencoder.fit_transform(df['BORO'])\ndf['VIC_RACE'] = labelencoder.fit_transform(df['VIC_RACE'])\ndf['VIC_SEX'] = labelencoder.fit_transform(df['VIC_SEX'])\ndf['PERP_SEX'] = labelencoder.fit_transform(df['PERP_SEX'])\ndf['PERP_RACE'] = labelencoder.fit_transform(df['PERP_RACE'])\ndf['STATISTICAL_MURDER_FLAG'] = labelencoder.fit_transform(df['STATISTICAL_MURDER_FLAG'])\ndf['VIC_AGE_GROUP'] = labelencoder.fit_transform(df['VIC_AGE_GROUP'])\ndf['PERP_AGE_GROUP'] = labelencoder.fit_transform(df['PERP_AGE_GROUP'])\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"LliBzAveDMnS"},"cell_type":"markdown","source":"**Predicting Victim Race**\n\n\n*   Analyzing the most common race to be targeted with hate crime\n*   The model has an accuracy of 73.8%\n\n"},{"metadata":{"id":"pn7rMI_ECTQs","trusted":true},"cell_type":"code","source":"#Importing train_test_split to split our data into train and test data. \nfrom sklearn.model_selection import train_test_split\n#Initializing varaible X and y before pasing it to train test split function.\nX = df.drop(['VIC_RACE','LOCATION_DESC','OCCUR_DATE','OCCUR_TIME','X_COORD_CD','Y_COORD_CD','Latitude','Longitude','Lon_Lat'],axis=1) #feature variable\ny = df['VIC_RACE'] #target variable","execution_count":null,"outputs":[]},{"metadata":{"id":"IkrdOXHkCTQs","outputId":"1640350c-2c48-48a8-baf5-ca41502ea400","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n#Importing Random Forest Classifier(ML model) to predict the outcomes.\nfrom sklearn.ensemble import RandomForestClassifier\n#Creating a object named rfc of RandomForestClassifier. \nrfc = RandomForestClassifier(n_estimators=600)\n#fitting the training data.\nrfc.fit(X_train,y_train)\n#Now we will pass our x test data in the model to predict the outcomes. We are storing the predictions of the model in a varable mentioned below.\npredictions = rfc.predict(X_test)\n#Importing the metrics and accuracy score to check the performance of our model.\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nprint(\"Random Forest Model accuracy(in %):\", metrics.accuracy_score(y_test, predictions)*100)","execution_count":null,"outputs":[]},{"metadata":{"id":"zAF2GydkDw3D"},"cell_type":"markdown","source":"**Predicting the Borough (Location)**\n\n*   Predicting the most unsafe borough\n*   The model has an accuracy of 100%\n\n"},{"metadata":{"id":"eGydGvqyIyHj","trusted":true},"cell_type":"code","source":"#Importing train_test_split to split our data into train and test data. \nfrom sklearn.model_selection import train_test_split\n#Initializing varaible X and y before pasing it to train test split function.\nX = df.drop(['BORO','LOCATION_DESC','OCCUR_DATE','OCCUR_TIME','X_COORD_CD','Y_COORD_CD','Latitude','Longitude','Lon_Lat'],axis=1)\ny = df['BORO']","execution_count":null,"outputs":[]},{"metadata":{"id":"IQ2GS0BOJKGe","outputId":"d7cab1ed-b467-43da-c00f-4778eaebb0f8","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n#Importing Random Forest Classifier(ML model) to predict the outcomes.\nfrom sklearn.ensemble import RandomForestClassifier\n#Creating a object named rfc of RandomForestClassifier. \nrfc = RandomForestClassifier(n_estimators=600)\n#fitting the training data.\nrfc.fit(X_train,y_train)\npredictions = rfc.predict(X_test)\n#Now we will pass our x test data in the model to predict the outcomes. We are storing the predictions of the model in a varable mentioned below.\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nprint(\"Random Forest Model accuracy(in %):\", metrics.accuracy_score(y_test, predictions)*100)","execution_count":null,"outputs":[]},{"metadata":{"id":"4DR6Ip_-EJy9"},"cell_type":"markdown","source":"**Predicting perpetrators's** **age**\n\n*   Prediction the most likely age group of suspect\n*   The model has an accuracy percentage of 41.7%\n\n"},{"metadata":{"id":"0uR5E7mUNqbc","trusted":true},"cell_type":"code","source":"#Importing train_test_split to split our data into train and test data. \nfrom sklearn.model_selection import train_test_split\n#Initializing varaible X and y before pasing it to train test split function.\nX = df.drop(['PERP_AGE_GROUP','LOCATION_DESC','OCCUR_DATE','OCCUR_TIME','X_COORD_CD','Y_COORD_CD','Latitude','Longitude','Lon_Lat'],axis=1) #defining feature variable\ny = df['PERP_AGE_GROUP'] #target variable","execution_count":null,"outputs":[]},{"metadata":{"id":"xY3-BqtCPM7Q","outputId":"9f0831ac-ba94-4f05-b82e-04309c13bfa0","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101) #importing test split function to segregate the data into training and test dataset\nfrom sklearn.ensemble import RandomForestClassifier \nrfc = RandomForestClassifier(n_estimators=600)\nrfc.fit(X_train,y_train) #using fit to train the model\npredictions = rfc.predict(X_test) #by using predict function we will predict the target variable based on our test set(X_test)\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nprint(\"Random Forest Model accuracy(in %):\", metrics.accuracy_score(y_test, predictions)*100) #Checking the predicitve accuracy of the model created.","execution_count":null,"outputs":[]},{"metadata":{"id":"H9VgeASSESCT"},"cell_type":"markdown","source":"**Predicting Victim's gender**\n\n\n*   Predicting the most unsafe gender in New York\n*   The model has an accuracy of 89.1%\n"},{"metadata":{"id":"KTPvbMueKw7G","trusted":true},"cell_type":"code","source":"#Importing train_test_split to split our data into train and test data. \nfrom sklearn.model_selection import train_test_split\n#Initializing varaible X and y before pasing it to train test split function.\nX = df.drop(['VIC_SEX','LOCATION_DESC','OCCUR_DATE','OCCUR_TIME','X_COORD_CD','Y_COORD_CD','Latitude','Longitude','Lon_Lat'],axis=1)\ny = df['VIC_SEX']","execution_count":null,"outputs":[]},{"metadata":{"id":"tev2BReGLGwY","outputId":"d82aa044-1f95-4288-efb1-61646ab79984","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n#Importing Random Forest Classifier(ML model) to predict the outcomes.\nfrom sklearn.ensemble import RandomForestClassifier\n#Creating a object named rfc of RandomForestClassifier. \nrfc = RandomForestClassifier(n_estimators=600)\n#fitting the training data.\nrfc.fit(X_train,y_train)\n#Now we will pass our x test data in the model to predict the outcomes. We are storing the predictions of the model in a varable mentioned below.\npredictions = rfc.predict(X_test)\n#Importing the metrics and accuracy score to check the performance of our model.\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nprint(\"Random Forest Model accuracy(in %):\", metrics.accuracy_score(y_test, predictions)*100)","execution_count":null,"outputs":[]},{"metadata":{"id":"CHXmNfkFEnk6"},"cell_type":"markdown","source":"# **KNN**"},{"metadata":{"id":"9BeAWdSXR5QO","outputId":"9c2c526e-6d0e-4342-8361-9e191fe8b4cb","trusted":true},"cell_type":"code","source":"# selecting the columns needed\nmydata = df[['INCIDENT_KEY','PRECINCT','JURISDICTION_CODE','X_COORD_CD']]\nmydata","execution_count":null,"outputs":[]},{"metadata":{"id":"OH6JfyZgbehH","outputId":"9dff58dc-3c63-4c0d-86db-c91958bf4223","trusted":true},"cell_type":"code","source":"#checking the data types of columns\nmydata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"oy9kTFNNdoru","trusted":true},"cell_type":"code","source":"#Initializing the varaibles X and y before applying it to train test split.\nX = mydata[mydata.columns[0:3]]\ny = mydata[['X_COORD_CD']]","execution_count":null,"outputs":[]},{"metadata":{"id":"UkHTHnrkdq6b","outputId":"bf28dd80-41d8-466a-878b-e99fbe23e1e0","trusted":true},"cell_type":"code","source":"#displaying values present in X varaible.\nX","execution_count":null,"outputs":[]},{"metadata":{"id":"8zwDCY-fdzqP","outputId":"2f7c6a8e-76fb-4484-ec3a-cf124631d4e2","trusted":true},"cell_type":"code","source":"#checking value of y varaible.\ny","execution_count":null,"outputs":[]},{"metadata":{"id":"z7QXUumrc7MC"},"cell_type":"markdown","source":"**KNN: n=3**\n\n*   For n=3, we got the score of 52.39 which is pretty less for a predictive model\n*We need to consider the method with the highest score to get the higher accuracy for the dataset\n\n\n"},{"metadata":{"id":"liw_utqKd1gR","outputId":"98bd7508-8394-4f26-a6d8-9f78a272c188","trusted":true},"cell_type":"code","source":"y.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"JhOzgN0FeAPO","outputId":"b17fb4c8-f1f4-462c-f582-a7712d23d16d","trusted":true},"cell_type":"code","source":"#creating a object of KNeighborsClassifier and fitting it with data. \nKNN = KNeighborsClassifier(n_neighbors=3)\nKNN.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"id":"gCKuD4hKeFd2","outputId":"72c3926a-3f1c-4e84-d454-83518716b6ec","trusted":true},"cell_type":"code","source":"#printing the value predicted by KNeighborsClassifier model.\nprint(KNN.predict([[201575314,103,0.0]]))","execution_count":null,"outputs":[]},{"metadata":{"id":"KtnZhM-3eXzH","outputId":"ef94e0ab-49fd-4826-fd43-38ff8a2bc369","trusted":true},"cell_type":"code","source":"#checking the score of the model.\nKNN_score = KNN.score(X, y)\nprint(KNN_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"4m51xODydp_l"},"cell_type":"markdown","source":"**KNN:n=4**\n* Here we have taken the n=4 to check if we get a greater score\n* The score of KNN when n=4 is around 43.7 which is lesser than the previous score\n* When we compare the both KNN scores we can choose n=3 over n=4 as it gives higher score\n\n"},{"metadata":{"id":"yetjUjOkeZ8l","outputId":"9c5799ae-c364-410f-c98c-84179566f3b9","trusted":true},"cell_type":"code","source":"#creating a object of KNeighborsClassifier with 4 neighbors and fitting it with data. \nKNN = KNeighborsClassifier(n_neighbors=4)\nKNN.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"id":"HvkuZne9edGi","outputId":"e0fc5adf-704c-46ce-c21e-b77b6cf4cca6","trusted":true},"cell_type":"code","source":"#printing the value predicted by KNeighborsClassifier model.\nprint(KNN.predict([[201755314,103,0.0]]))","execution_count":null,"outputs":[]},{"metadata":{"id":"venmWPdkekJ-","outputId":"71f90183-00b4-42f3-b6da-60a7fa391910","trusted":true},"cell_type":"code","source":"#checking the score of the model.\nKNN_score = KNN.score(X, y)\nprint(KNN_score)","execution_count":null,"outputs":[]},{"metadata":{"id":"1cz9rToyE5Z-"},"cell_type":"markdown","source":"# **DECISION TREE**"},{"metadata":{"id":"kpizzcAEdNeA"},"cell_type":"markdown","source":"\n\n*   When we applied the decision tree model on our dataset the score came up to 98.8%.\n\n*   The score is almost close to 100%, so this method is most desirable of all and we can eliminate the cost and effort by using this model on top of other models (in our case KNN)"},{"metadata":{"id":"aqiYaGlBenbH","trusted":true},"cell_type":"code","source":"# loading the library\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"id":"HaCcy-1Cep17","trusted":true},"cell_type":"code","source":"#creating a object of DecisionTreeClassifier. \ndtree = tree.DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"id":"l33orcnhetUw","trusted":true},"cell_type":"code","source":"#fitting it with data.\ntree_model = dtree.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"id":"gMV_hqLeevh4","outputId":"b063c0f6-13e0-4247-f38e-e01efc3f69b9","trusted":true},"cell_type":"code","source":"#printing the value predicted by Decision Tree model.\nprint(tree_model.predict([[201575314,103,0.0]]))","execution_count":null,"outputs":[]},{"metadata":{"id":"Vo-IL1Gie0nG","outputId":"748fe7a7-4860-4fdc-9016-8f3db51c4426","trusted":true},"cell_type":"code","source":"#checking the score of decision tree model object.\nDT_score = dtree.score(X, y)\nprint(DT_score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}