{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 30 days of ML","metadata":{}},{"cell_type":"code","source":"#Import libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-31T15:02:25.738475Z","iopub.execute_input":"2021-08-31T15:02:25.738841Z","iopub.status.idle":"2021-08-31T15:02:26.233655Z","shell.execute_reply.started":"2021-08-31T15:02:25.738761Z","shell.execute_reply":"2021-08-31T15:02:26.232528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KFolds\ntrain = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\ntest = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nprint(train.shape,test.shape)\n#add extra one columns\ntrain['kfold']=-1\n#Distributing the data 5 shares\nkfold = KFold(n_splits=10, shuffle= True, random_state = 42)\nfor fold, (train_indicies, valid_indicies) in enumerate(kfold.split(X=train)):\n    #print(fold,train_indicies,valid_indicies)\n    train.loc[valid_indicies,'kfold'] = fold\n\n    \nprint(train.kfold.value_counts()) #total data 300000 = kfold split :5 * 60000\n\n#output of train folds data\ntrain.to_csv(\"trainfold_10.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:02:26.235895Z","iopub.execute_input":"2021-08-31T15:02:26.236229Z","iopub.status.idle":"2021-08-31T15:02:39.715849Z","shell.execute_reply.started":"2021-08-31T15:02:26.2362Z","shell.execute_reply":"2021-08-31T15:02:39.714663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import KFold dataset\ndf = pd.read_csv(\"./trainfold_10.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n#preview the train data\nprint(df.shape,df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:02:39.718176Z","iopub.execute_input":"2021-08-31T15:02:39.718631Z","iopub.status.idle":"2021-08-31T15:02:42.746613Z","shell.execute_reply.started":"2021-08-31T15:02:39.718584Z","shell.execute_reply":"2021-08-31T15:02:42.745378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train diferents models","metadata":{}},{"cell_type":"code","source":"## pred_1\n\ndf = pd.read_csv(\"./trainfold_10.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(10):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.03628302216953097,\n        'reg_lambda': 0.0008746338866473539,\n        'reg_alpha': 23.13181079976304,\n        'subsample': 0.7875490025178415,\n        'colsample_bytree': 0.11807135201147481,\n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        n_jobs=4,\n        **params\n    )\n    \n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_1\"]\nsample_submission.to_csv(\"test_pred_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:02:42.748134Z","iopub.execute_input":"2021-08-31T15:02:42.748484Z","iopub.status.idle":"2021-08-31T16:38:37.874866Z","shell.execute_reply.started":"2021-08-31T15:02:42.74845Z","shell.execute_reply":"2021-08-31T16:38:37.873277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## pred_2\n\ndf = pd.read_csv(\"./trainfold_10.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(10):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    params = {\n        'learning_rate': 0.07853392035787837,\n        'reg_lambda': 1.7549293092194938e-05,\n        'reg_alpha': 14.68267919457715, \n        'subsample': 0.8031450486786944, \n        'colsample_bytree': 0.170759104940733, \n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        random_state=fold,\n        n_jobs=4,\n        n_estimators=5000,\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_2\"]\nsample_submission.to_csv(\"test_pred_2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:38:37.877283Z","iopub.execute_input":"2021-08-31T16:38:37.877933Z","iopub.status.idle":"2021-08-31T17:22:45.388865Z","shell.execute_reply.started":"2021-08-31T16:38:37.877882Z","shell.execute_reply":"2021-08-31T17:22:45.38754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## pred_3\n\ndf = pd.read_csv(\"./trainfold_10.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in train.columns if c not in (\"id\",\"target\",\"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\nnumerical_cols = [col for col in useful_features if 'cont' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nfor fold in range(10):\n    xtrain = df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n    \n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    #ordinal encode categorical colums and standardscaler is applied (mean0,sd=1)\n    ordinal_encoder = OrdinalEncoder()\n    \n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    #Model hyperparameter of XGboostRegressor\n    params = {\n        'learning_rate': 0.03628302216953097,\n        'subsample': 0.7875490025178,\n        'colsample_bytree': 0.11807135201147,\n        'max_depth': 3,\n        'booster': 'gbtree', \n        'reg_lambda': 0.0008746338866473539,\n        'reg_alpha': 23.13181079976304,\n        'random_state':40,\n        'n_estimators':10000\n        \n        \n    }\n    \n    model= XGBRegressor(**params)\n    \n    model.fit(xtrain,ytrain,early_stopping_rounds=300,eval_set=[(xvalid,yvalid)],verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid,preds_valid,squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"train_pred_3.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_3\"]\nsample_submission.to_csv(\"test_pred_3.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:22:45.390801Z","iopub.execute_input":"2021-08-31T17:22:45.391184Z","iopub.status.idle":"2021-08-31T18:55:25.420445Z","shell.execute_reply.started":"2021-08-31T17:22:45.391145Z","shell.execute_reply":"2021-08-31T18:55:25.418901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Blending models","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"./trainfold_10.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n\ndf1 = pd.read_csv('./train_pred_1.csv')\ndf1.columns = ['id', 'pred_1']\ndf2 = pd.read_csv('./train_pred_2.csv')\ndf2.columns = ['id', 'pred_2']\ndf3 = pd.read_csv('./train_pred_3.csv')\ndf3.columns = ['id', 'pred_3']\n\ndf_test1 = pd.read_csv('./test_pred_1.csv')\ndf_test1.columns = ['id', 'pred_1']\ndf_test2 = pd.read_csv('./test_pred_2.csv')\ndf_test2.columns = ['id', 'pred_2']\ndf_test3 = pd.read_csv('./test_pred_3.csv')\ndf_test3.columns = ['id', 'pred_3']\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:55:25.423248Z","iopub.execute_input":"2021-08-31T18:55:25.424391Z","iopub.status.idle":"2021-08-31T18:55:29.405198Z","shell.execute_reply.started":"2021-08-31T18:55:25.424123Z","shell.execute_reply":"2021-08-31T18:55:29.403662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:55:29.408726Z","iopub.execute_input":"2021-08-31T18:55:29.40918Z","iopub.status.idle":"2021-08-31T18:55:29.464874Z","shell.execute_reply.started":"2021-08-31T18:55:29.409145Z","shell.execute_reply":"2021-08-31T18:55:29.463574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(10):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n\n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.03,\n        'max_depth': 2\n    }\n    \n    model = XGBRegressor(\n        n_jobs=4,\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"level1_train_pred_1.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_1\"]\nsample_submission.to_csv(\"level1_test_pred_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:55:29.46721Z","iopub.execute_input":"2021-08-31T18:55:29.467708Z","iopub.status.idle":"2021-08-31T19:01:12.893428Z","shell.execute_reply.started":"2021-08-31T18:55:29.467658Z","shell.execute_reply":"2021-08-31T19:01:12.892545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(10):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = RandomForestRegressor(n_estimators=500, n_jobs=-1, max_depth=3)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"level1_train_pred_2.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_2\"]\nsample_submission.to_csv(\"level1_test_pred_2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T19:01:12.894604Z","iopub.execute_input":"2021-08-31T19:01:12.895073Z","iopub.status.idle":"2021-08-31T19:12:23.704502Z","shell.execute_reply.started":"2021-08-31T19:01:12.89504Z","shell.execute_reply":"2021-08-31T19:12:23.703363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(10):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = GradientBoostingRegressor(n_estimators=500, max_depth=3)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"level1_train_pred_3.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_3\"]\nsample_submission.to_csv(\"level1_test_pred_3.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T19:12:23.706553Z","iopub.execute_input":"2021-08-31T19:12:23.707058Z","iopub.status.idle":"2021-08-31T19:56:43.465627Z","shell.execute_reply.started":"2021-08-31T19:12:23.707004Z","shell.execute_reply":"2021-08-31T19:56:43.46424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacking models","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"./trainfold_10.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\ndf1 = pd.read_csv(\"level1_train_pred_1.csv\")\ndf2 = pd.read_csv(\"level1_train_pred_2.csv\")\ndf3 = pd.read_csv(\"level1_train_pred_3.csv\")\n\ndf_test1 = pd.read_csv(\"level1_test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"level1_test_pred_2.csv\")\ndf_test3 = pd.read_csv(\"level1_test_pred_3.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T19:56:43.467463Z","iopub.execute_input":"2021-08-31T19:56:43.467801Z","iopub.status.idle":"2021-08-31T19:56:47.912278Z","shell.execute_reply.started":"2021-08-31T19:56:43.467769Z","shell.execute_reply":"2021-08-31T19:56:47.911192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(10):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = LinearRegression()\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T19:56:47.913549Z","iopub.execute_input":"2021-08-31T19:56:47.914048Z","iopub.status.idle":"2021-08-31T19:56:50.001904Z","shell.execute_reply.started":"2021-08-31T19:56:47.913995Z","shell.execute_reply":"2021-08-31T19:56:50.000448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submissions","metadata":{}},{"cell_type":"code","source":"sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T19:56:50.008135Z","iopub.execute_input":"2021-08-31T19:56:50.011439Z","iopub.status.idle":"2021-08-31T19:56:50.796183Z","shell.execute_reply.started":"2021-08-31T19:56:50.011348Z","shell.execute_reply":"2021-08-31T19:56:50.795252Z"},"trusted":true},"execution_count":null,"outputs":[]}]}