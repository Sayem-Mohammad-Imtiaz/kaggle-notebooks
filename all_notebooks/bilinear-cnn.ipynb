{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport sys\nsys.path.append(\"../input/timm-pytorch-image-models/pytorch-image-models-master/\")\nimport timm\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms as T\nfrom sklearn.metrics import accuracy_score\n!mkdir images\ndef get_img(path):\n    im_bgr = cv2.imread(path)\n\n    im_rgb = im_bgr[:, :, ::-1]\n    #print(im_rgb)\n    return im_rgb\n\nimg = get_img('../input/plants114514/MK/D1/train/Class (1)/R_0Class1 (10).jpg')\nim_bgr = cv2.imread(\"../input/plants114514/MK/D1/train/Class (1)/R_0Class1 (10).jpg\")\ncv2.imwrite(\"./images/img.jpg\",im_bgr)\nplt.imshow(img)\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\nfrom pathlib import Path\nimport warnings \nwarnings.filterwarnings('ignore')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image preprocessing","metadata":{}},{"cell_type":"code","source":"\nimg = get_img('../input/plants114514/MK/D1/train/Class (1)/R_0Class1 (10).jpg')\nTrans_pose =Transpose(p=1)\nimg_out = Trans_pose.apply(img)\n\nHorizontal_Flip =HorizontalFlip(p=1)\nimg_out_Horizontal_Flip = Horizontal_Flip.apply(img)\n\nVerticalFlip1 =VerticalFlip(p=1)\nimg_out_VerticalFlip1 = VerticalFlip1.apply(img)\n\n\nVerticalFlip1 =VerticalFlip(p=1)\nimg_out_VerticalFlip1 = VerticalFlip1.apply(img)\n\n\n\nimg_out_ShiftScaleRotate = ShiftScaleRotate(p=1)(image=img)[\"image\"]\n\nNormalize1 = Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            )\n\nimg_out_Normalize1 = Normalize1.apply(img)\n\n!mkdir images\nplt.imshow(img_out)\nplt.show()\nplt.savefig(\"./images/img_out_transpose.png\")\nplt.imshow(img_out_Horizontal_Flip)\nplt.show()\nplt.savefig(\"./images/img_out_Horizontal_Flip.png\")\n\nplt.imshow(img_out_VerticalFlip1)\nplt.show()\nplt.savefig(\"./images/img_out_VerticalFlip1.png\")\n\nplt.imshow(img_out_ShiftScaleRotate)\n\nplt.show()\nplt.savefig(\"./images/img_out_ShiftScaleRotate.png\")\n\nplt.imshow(img_out_Normalize1)\nplt.show()\nplt.savefig(\"./images/img_out_Normalize1.png\")\nfrom pathlib import Path\nimg_root = Path('./images')\nimport zipfile\nwith zipfile.ZipFile('imgs.zip', 'w') as z:\n    for img_name in img_root.iterdir():\n        z.write(img_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Utils","metadata":{}},{"cell_type":"code","source":"def get_transforms(mode):\n    \n    if mode == 'train':\n        return Compose([\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif mode == 'val':\n        return Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    \n\nclass PLantDataSet(Dataset):\n    \n    def __init__(self, images, device, transform=None):\n        self.images = images\n        self.transform = transform\n    \n    def __len__(self):\n        return self.images.shape[0]\n    \n    def __getitem__(self, item):\n        img = cv2.imread(self.images.iloc[item, 0])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if self.transform is not None:\n            img = self.transform(image=img)\n        label = self.images.iloc[item, 1]\n        img = torch.tensor(img[\"image\"]).float().to(device)\n        label = torch.tensor(label).long().to(device)\n        return img, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Models","metadata":{}},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\n'''vgg make layers'''\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    layers += [nn.Conv2d(in_channels, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True)]\n    layers += [nn.MaxPool2d(kernel_size=3)]\n    return nn.Sequential(*layers)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\n\n\n\n\n\nclass Flatten(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n    \n    def forward(self, x):\n        return x.view(x.shape[0], -1)\n\n\nclass VGGNet(nn.Module):\n    \n    def __init__(self, num_classification, freeze=True):\n        super().__init__()\n        self.vgg = timm.create_model(\"vgg16\", pretrained=True)\n        self.vgg.head = nn.Identity()\n        if freeze:\n            for param in self.vgg.parameters():\n                param.requires_grad = False\n        self.classify = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1, 1)),\n            Flatten(),\n            nn.Linear(4096, num_classification))\n    \n    def forward(self, x):\n        x = self.vgg(x)\n        return self.classify(x)\n    \n    \nclass VGG16Bilinear(nn.Module):\n    def __init__(self, num_classification, freeze=False):\n        super().__init__()\n        vgg = timm.create_model(\"vgg16\", pretrained=True)\n        vgg.head = nn.Identity()\n        if freeze:\n            for param in vgg.parameters():\n                param.requires_grad = False\n        \n        self.cnn = nn.Sequential(vgg, nn.AdaptiveAvgPool2d((1, 1)), nn.Conv2d(4096, 64, 1), nn.ReLU())\n        x = torch.rand(1, 3, 256, 256)\n        _, c, h, w = self.cnn(x).shape\n        \n        if freeze:\n            for param in self.cnn.parameters():\n                param.requires_grad = False\n        \n        self.classifier = nn.Linear(c ** 2, num_classification)\n        \n    def forward(self, x):\n        x = self.cnn(x)\n        b, c, h, w = x.shape\n        x = torch.bmm(x.view(b, c, h * w), x.view(b, c, h * w).transpose(1, 2)).view(b, -1)\n        x = torch.nn.functional.normalize(torch.sign(x) * torch.sqrt(torch.abs(x) + 1e-10))\n        x = self.classifier(x)\n        return x\n\nclass VGG16Bilinear_impro(nn.Module):\n    def __init__(self, num_classification, freeze=False):\n        super().__init__()\n        vgg = timm.create_model(\"vgg16\", pretrained=True)\n        vgg.head = nn.Identity()\n        if freeze:\n            for param in vgg.parameters():\n                param.requires_grad = False\n        \n        self.cnn = nn.Sequential(vgg, nn.AdaptiveAvgPool2d((1, 1)), nn.Conv2d(4096, 64, 1), nn.ReLU())\n        x = torch.rand(1, 3, 256, 256)\n        _, c, h, w = self.cnn(x).shape\n        \n        if freeze:\n            for param in self.cnn.parameters():\n                param.requires_grad = False\n        \n        # self.classifier = nn.Linear(c ** 2, num_classification)\n        self.class1 = nn.Bilinear(64, 64, 4096)\n        self.class2 = nn.Linear(4096, num_classification)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        b, c, h, w = x.shape\n        x_= x.view(x.size(0), -1)\n        x_=self.class1(x_, x_)\n        x_=self.class2(x_)\n        \n        # x = torch.bmm(x.view(b, c, h * w), x.view(b, c, h * w).transpose(1, 2)).view(b, -1)\n        # x = torch.nn.functional.normalize(torch.sign(x) * torch.sqrt(torch.abs(x) + 1e-10))\n        # x = self.classifier(x)\n        return x_\n\n\n\nclass VGG16_Res18_Bilinear(nn.Module):\n\n    def __init__(self, num_classes=3):\n        super(VGG16_Res18_Bilinear, self).__init__()\n\n        '''resnet50'''\n        # resnet50\n        # block = BasicBlock\n        # layers = [2, 2, 2, 2]\n        # self.inplanes = 64\n        # self.features_A = nn.Sequential(\n        #     nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n        #               bias=False),\n        #     nn.BatchNorm2d(64),\n        #     nn.ReLU(inplace=True),\n        #     nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n        #     self._make_layer(block, 64, layers[0]),\n        #     self._make_layer(block, 128, layers[1], stride=2),\n        #     self._make_layer(block, 256, layers[2], stride=2),\n        #     self._make_layer(block, 512, layers[3], stride=2),\n        #     nn.AvgPool2d(7, stride=1),\n        # )\n        # for m in self.features_A.modules():\n        #     if isinstance(m, nn.Conv2d):\n        #         n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        #         m.weight.data.normal_(0, math.sqrt(2. / n))\n        #     elif isinstance(m, nn.BatchNorm2d):\n        #         m.weight.data.fill_(1)\n        #         m.bias.data.zero_()\n\n        # self.classif_alex = nn.Sequential(\n        #     nn.Dropout(),\n        #     nn.Linear(256 * 6 * 6, 1024),\n        #     nn.ReLU(inplace=True),\n        # )\n\n        '''vgg16 bn =True'''\n        cfg = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n        self.features_A = make_layers(cfg, batch_norm=True)\n        # self.classier_A =  nn.Sequential(\n        #     nn.Linear(512 * 3 * 3, 1024),\n        #     nn.ReLU(True),\n        #     nn.Dropout(),\n        #     nn.Linear(1024, 512),\n        #     nn.ReLU(True),\n        #     nn.Dropout(),\n        # )\n        self._initialize_weights(self.features_A)\n        # self._initialize_weights(self.classier_A)\n\n        '''resnet18'''\n        block = BasicBlock\n        layers = [2, 2, 2, 2]\n        self.inplanes = 64\n        self.features_B = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                      bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            self._make_layer(block, 64, layers[0]),\n            self._make_layer(block, 128, layers[1], stride=2),\n            self._make_layer(block, 256, layers[2], stride=2),\n            self._make_layer(block, 512, layers[3], stride=2),\n            # nn.AvgPool2d(7, stride=1),\n            nn.AdaptiveAvgPool2d((1,1)),\n        )\n        for m in self.features_B.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n        # self.classifier = nn.Sequential(\n        #     nn.Bilinear(1024, 512, 256),\n        #     nn.Linear(256, num_classes),\n        # )\n        self.class1 = nn.Bilinear(2048, 512, 256)\n        self.class2 = nn.Linear(256, num_classes)\n\n    '''resnet make layer'''\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    '''vgg init '''\n\n    def _initialize_weights(self, model):\n        for m in model.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        x_A = x.clone()\n        x_B = x.clone()\n        # print x_A.size()\n        # print x_B.size()\n        x_A = self.features_A(x_A)\n        # print x_A.size()\n        x_A = x_A.view(x_A.size(0), -1)\n        # x_A = self.classier_A(x_A)\n        # x_A = self.classif_alex(x_A)\n        # print x_A.size()\n        # print x_B.size()\n        x_B = self.features_B(x_B)\n        x_B = x_B.view(x_B.size(0), -1)\n        # print x_A.size()\n        # print x_B.size()\n        # x = self.classifier(x_A, x_B)\n        x = self.class1(x_A, x_B)\n        # x = torch.nn.functional.normalize(torch.sign(x) * torch.sqrt(torch.abs(x) + 1e-10))\n        x = self.class2(x)\n        return x\n\n\n\n    \n    \n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Prepare","metadata":{}},{"cell_type":"code","source":"from pathlib import Path    \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = []\nd1_train_path = Path(\"../input/plants114514/MK/D1/train\")\nfor d in d1_train_path.iterdir():\n    for f in d.glob(\"*.jpg\"):\n        train_images.append((str(f.absolute()), d.name))\ntrain_images = pd.DataFrame(train_images, columns=[\"path\", \"label\"])\n\ntest_images = []\nd1_test_path = Path(\"../input/plants114514/MK/D1/test\")\nfor d in d1_test_path.iterdir():\n    for f in d.glob(\"*.jpg\"):\n        test_images.append((str(f.absolute()), d.name))\ntest_images = pd.DataFrame(test_images, columns=[\"path\", \"label\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_enc = LabelEncoder().fit(train_images.label)\ntrain_images[\"label\"] = label_enc.transform(train_images[\"label\"])\ntest_images[\"label\"] = label_enc.transform(test_images[\"label\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Train","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, optimizer, loss_fn, data_loader):\n    losses = []\n    model.train()\n    for imgs, labels in data_loader:\n        preds = model(imgs)\n        loss = loss_fn(preds, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n    return np.mean(losses)\n\n\ndef eval_epoch(model, loss_fn, data_loader):\n    losses = []\n    acces = []\n    model.eval()\n    with torch.no_grad():\n        for imgs, labels in data_loader:\n            preds = model(imgs)\n            loss = loss_fn(preds, labels)\n            pred_labels = torch.argmax(preds, dim=1).cpu().numpy()\n            labels = labels.cpu().numpy()\n            acc = accuracy_score(pred_labels, labels)\n            losses.append(loss.item())\n            acces.append(acc)\n    return np.mean(losses), np.mean(acces)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\"\n#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"device:\",device)\nbatch_size = 128\nlr = 0.0001   ####only vgg16 use 0.003\nnum_classifications = 44\ntrain_transform = get_transforms(\"train\")\nvalid_transform = get_transforms(\"val\")\nloss_fn = nn.CrossEntropyLoss()\nnum_epochs = 2   ##实际使用时使用 100个 epoch\n#early_stopping = 5\nfrom tensorboardX import SummaryWriter\n\nwriter = SummaryWriter('BCNN')\n\nif num_epochs != 100:\n    print(\"当前num_epochs:\",num_epochs)\n    print(\"实际使用时请设置num_epochs为\",100)\nfold = StratifiedKFold(5)\ntest_set = PLantDataSet(test_images, device, valid_transform)\ntest_dl = DataLoader(test_set, batch_size=batch_size, shuffle=False)\nfor cv, (trn_idx, val_idx) in enumerate(fold.split(train_images.index, train_images.label)):\n    \n    model = VGGNet(num_classifications)\n#     model = VGG16Bilinear(num_classifications)\n    #model = VGG16Bilinear_impro(num_classifications)\n\n    #model = VGG16_Res18_Bilinear(num_classifications)\n\n    model.to(device)\n    optimizer = Adam(filter(lambda x: x.requires_grad, model.parameters()), lr)\n    best_acc = -float(\"inf\")\n    best_acc_epoch = 0\n    \n    trn = train_images.iloc[trn_idx].reset_index(drop=True)\n    val = train_images.iloc[val_idx].reset_index(drop=True)\n    trn_set = PLantDataSet(trn, device, train_transform)\n    val_set = PLantDataSet(val, device, valid_transform)\n    trn_dl = DataLoader(trn_set, batch_size=batch_size, shuffle=True)\n    val_dl = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n    \n    for epoch in range(num_epochs):\n        train_loss = train_epoch(model, optimizer, loss_fn, trn_dl)\n        val_loss, val_acc = eval_epoch(model, loss_fn, val_dl)\n        if cv == 0:\n            writer.add_scalar('Val/Loss', val_loss,epoch)\n            writer.add_scalar('Val/Acc',val_acc,epoch)\n        \n        print(f\"CV {cv+1} epoch {epoch} train loss {train_loss:.3f}, val loss {val_loss:.3f} acc {val_acc:.3f}\")\n        if val_acc > best_acc:\n            torch.save(model.state_dict(), f\"cv_vgg_{cv+1}_best.pth\")\n    print(f\"stop training, load best model epoch {epoch+1}\")\n    model.load_state_dict(torch.load(f\"cv_vgg_{cv+1}_best.pth\"))\n    test_loss, test_acc = eval_epoch(model, loss_fn, test_dl)\n    print(f\"cv {cv+1} test acc {test_acc:.3f}\")\n    writer.close()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip### 只需要运行一次 下载解压后就可以注释了\n# !unzip ngrok-stable-linux-amd64.zip\n#这个模块最终出现一个链接 点开就是正确率曲线 以及loss曲线\n# import os\n# import multiprocessing\n\n\n# pool = multiprocessing.Pool(processes = 10)\n# results_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n#                         for cmd in [\n#                         f\"tensorboard --logdir ./BCNN/ --host 0.0.0.0 --port 6006 &\",\n#                         \"./ngrok http 6006 &\"\n#                         ]]\n# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#####特征图\n\n\ndef draw_CAM(model, img_path, save_path, PATH=None,transform=None, visual_heatmap=False):\n    '''\n    绘制 Class Activation Map\n    :param model: 加载好权重的Pytorch model\n    :param img_path: 测试图片路径\n    :param save_path: CAM结果保存路径\n    :param transform: 输入图像预处理方法\n    :param visual_heatmap: 是否可视化原始heatmap（调用matplotlib）\n    :return:\n    '''\n    # 图像加载&预处理\n    # img = Image.open(img_path).convert('RGB')\n    img = cv2.imread(img_path)\n\n    # img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n\n    if transform:\n        img = transform(image=img)\n    print(model)\n    if PATH is not None:\n        model.load_state_dict(torch.load(PATH))\n    img = img[\"image\"].unsqueeze(0)\n \n    # 获取模型输出的feature/score\n    model.eval()\n\n    # output = model(img)\n\n    # print(model.cnn._modules['0'].features._modules['6'])\n    n=0\n    l=0\n    for ddd in model.children():###VGG\n\n        if n==8:\n            break\n        # for ddds in ddd:\n            \n\n        #     if n==8:\n        #         break\n            for ggg in ddds.features:\n                n+=1\n                if n==8:\n                    break\n                img=ggg(img)\n                print()\n#     for ddd in model.children():###BCNN\n\n#         if n==8:\n#             break\n#         for ddds in ddd:\n            \n\n#             if n==8:\n#                 break\n#             for ggg in ddds.features:\n#                 n+=1\n#                 if n==8:\n#                     break\n#                 img=ggg(img)\n#                 print()\n    features=img\n    # features = model.cnn._modules['0'].features._modules['6'](img)\n    # output = model(img)\n    # b, c, h, w = x.shape\n    # features = torch.bmm(x.view(b, c, h * w), x.view(b, c, h * w).transpose(1, 2))\n    # features_vec=features.view(b, -1)\n    # features_vec = torch.nn.functional.normalize(torch.sign(features_vec) * torch.sqrt(torch.abs(features_vec) + 1e-10))\n    # output = model.classifier(features_vec)\n    \n    heatmap = features[0][0].detach().numpy()\n\n \n    img = cv2.imread(img_path)  # 用cv2加载原始图像\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))  # 将热力图的大小调整为与原始图像相同\n    heatmap = np.uint8(255 * heatmap)  # 将热力图转换为RGB格式\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # 将热力图应用于原始图像\n    superimposed_img = heatmap * 0.4 + img  # 这里的0.4是热力图强度因子\n\n    cv2.imwrite(save_path, superimposed_img)  # 将图像保存到硬盘\n    plt.imshow(img)\n    plt.show()\nvalid_transform = get_transforms(\"val\")\nimg_path = \"../input/plants114514/MK/D1/train/Class (8)/R_270Class8 (4).jpg\"\nsave_path=\"./heat_map_vgg_d1.png\"\nPATH = \"./cv_vgg_1_best.pth\"\nPATH = None\n\ndevice = \"cuda\"\nmodel = VGGNet(44)\n# model.to(device)\ndraw_CAM(model, img_path, save_path, PATH,transform=valid_transform, visual_heatmap=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}