{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.utils import shuffle\nimport pandas as pd\nimport pickle\nfrom matplotlib.pyplot import MultipleLocator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\ntf.config.experimental_connect_to_cluster(resolver)\n# This is the TPU initialization code that has to be at the beginning.\ntf.tpu.experimental.initialize_tpu_system(resolver)\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy = tf.distribute.TPUStrategy(resolver)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(r'../input/blood-pressure-datasets/Train_Merge_Data.csv')\ntrain_dev = pd.read_csv(r'../input/ppg-dev/train_dev.csv')\n\nvalidation_data = pd.read_csv(r'../input/blood-pressure-datasets/Validation_Merge_Data.csv')\nvalidation_dev = pd.read_csv(r'../input/ppg-dev/validation_dev.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.concat([train_data,train_dev],axis=1)\nvalidation_data = pd.concat([validation_data,validation_dev],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = shuffle(train_data)\nvalidation_data = shuffle(validation_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_Sbp = train_data.iloc[:,610]\ntrain_label_Sbp = train_label_Sbp.values\n\ntrain_label_Dbp = train_data.iloc[:,611]\ntrain_label_Dbp = train_label_Dbp.values\n\ntrain_dev1 = train_data.iloc[:,662:1262]\ntrain_dev1 = train_dev1.values\n\ntrain_dev2 = train_data.iloc[:,1262:]\ntrain_dev2 = train_dev2.values\n\ntrain_data = train_data.iloc[:,:600]\ntrain_data = train_data.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_label_Sbp = validation_data.iloc[:,610]\nvalidation_label_Sbp = validation_label_Sbp.values\n\nvalidation_label_Dbp = validation_data.iloc[:,611]\nvalidation_label_Dbp = validation_label_Dbp.values\n\nvalidation_dev1 = validation_data.iloc[:,662:1262]\nvalidation_dev1 = validation_dev1.values\n\nvalidation_dev2 = validation_data.iloc[:,1262:]\nvalidation_dev2 = validation_dev2.values\n\nvalidation_data = validation_data.iloc[:,:600]\nvalidation_data = validation_data.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train_data_information:\")\nprint(train_data.shape)\nprint(train_dev1.shape)\nprint(train_dev2.shape)\nprint(train_label_Sbp.shape)\nprint(train_label_Dbp.shape)\nprint(\"validation_data_information:\")\nprint(validation_data.shape)\nprint(validation_dev1.shape)\nprint(validation_dev2.shape)\nprint(validation_label_Sbp.shape)\nprint(validation_label_Dbp.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------#\n#   激活函数 relu6\n#---------------------------------------#\ndef relu6(x):\n    return tf.keras.activations.relu(x, max_value=6)\n\n#---------------------------------------#\n#   利用relu函数乘上x模拟sigmoid\n#---------------------------------------#\ndef hard_swish(x):\n    return x * tf.keras.activations.relu(x + 3.0, max_value=6.0) / 6.0\n\n#---------------------------------------#\n#   通道注意力机制单元\n#   利用两次全连接算出每个通道的比重\n#   可以连接在任意特征层后面\n#---------------------------------------#\ndef squeeze(inputs):\n    input_channels = int(inputs.shape[-1])\n    \n    x = layers.GlobalAveragePooling1D()(inputs)\n\n    x = layers.Dense(int(input_channels/4))(x)\n    x = relu6(x)\n\n    x = layers.Dense(input_channels)(x)\n    x = hard_swish(x)\n\n    x = layers.Reshape((1, input_channels))(x)\n    #print(x)\n    #print(inputs)\n    x = layers.Multiply()([inputs, x])\n    return x\n\n#基础层下采样\ndef DownSampling(inputs,filters):\n    layer = layers.Conv1D(filters,3,padding='same')(inputs)\n    layer = layers.BatchNormalization()(layer)\n    layer = layers.Activation(tf.nn.relu)(layer)\n\n    layer = layers.Conv1D(filters,3,padding='same')(layer)\n    layer = layers.BatchNormalization()(layer)\n    layer = layers.Activation(tf.nn.relu)(layer)\n    \n    layer = layers.Conv1D(filters,3,padding='same')(layer)\n    layer = layers.BatchNormalization()(layer)\n    layer = layers.Activation(tf.nn.relu)(layer)\n\n    layer = layers.Conv1D(filters,3,padding='same')(layer)\n    layer = layers.BatchNormalization()(layer)\n    layer = layers.Activation(tf.nn.relu)(layer)\n    \n    pool = layers.MaxPooling1D(pool_size=2)(layer)\n    \n    return layer,pool\n\n#基础层上采样\ndef UpSampling(inputs,con_input,filters,need_zero=False):\n    \n    \n    up_layer = layers.UpSampling1D(size=2)(inputs)\n    \n    if need_zero==True:\n        up_layer = layers.ZeroPadding1D((0,1))(up_layer)\n    \n    layer = layers.Conv1D(filters,2,padding='same')(up_layer)\n    layer = layers.BatchNormalization()(layer)\n    layer = layers.Activation(tf.nn.relu)(layer)\n    \n    layer = layers.Concatenate(axis=2)([layer,con_input])\n    \n    layer = layers.Conv1D(filters,3,padding='same')(layer)\n    layer = layers.BatchNormalization()(layer)\n    layer = layers.Activation(tf.nn.relu)(layer)\n\n    layer = layers.Conv1D(filters,3,padding='same')(layer)\n    layer = layers.BatchNormalization()(layer)\n    output = layers.Activation(tf.nn.relu)(layer)\n    \n    return output\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    #双输入模型\n    inputs_1 = keras.Input(shape=(600,1),name='inputs_1')\n    inputs_dev1 = keras.Input(shape=(600,1),name='inputs_dev1')\n    inputs_dev2 = keras.Input(shape=(600,1),name='inputs_dev2')\n    \n    inputs = layers.Concatenate(axis=2)([inputs_1,inputs_dev1,inputs_dev2])\n    #下采样\n    layer1,pool1 = DownSampling(inputs,filters=64)\n    \n    \n    layer2,pool2 = DownSampling(pool1,filters=128)\n    \n        \n    layer3,pool3 = DownSampling(pool2,filters=256)\n    \n    \n    layer4,pool4 = DownSampling(pool3,filters=512)\n    \n    \n    #最后一层不需要Pooling\n    layer5,pool5 = DownSampling(pool4,filters=1024)\n   \n    #上采样\n    \n    #attention\n    layer4 = squeeze(layer4)\n    \n    layer44 = UpSampling(layer5,layer4,512,need_zero=True)\n    \n    #attention\n    layer3 = squeeze(layer3)\n                     \n    layer33 = UpSampling(layer44,layer3,256)\n    \n    #attention\n    layer2 = squeeze(layer2)\n    \n    layer22 = UpSampling(layer33,layer2,128)\n    \n    #attention\n    layer1 = squeeze(layer1)\n    \n    layer11 = UpSampling(layer22,layer1,64)\n\n    layer = layers.GlobalAveragePooling1D()(layer11)\n\n    outputs_sbp = layers.Dense(1,name='Sbp')(layer)\n    outputs_dbp = layers.Dense(1,name='Dbp')(layer)\n\n    model = keras.Model(inputs=[inputs_1,inputs_dev1,inputs_dev2],outputs=[outputs_sbp,outputs_dbp])\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"自定义评价指标模块\"\"\"\ndef standard_deviation(y_true, y_pred):\n    u = keras.backend.mean(y_pred-y_true)\n    return keras.backend.sqrt(keras.backend.mean(keras.backend.square((y_pred-y_true) - u)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"回调函数\"\"\"\n#保存迭代周期内最好的模型\ncheckpoint_filepath = r'./model_struction.h5'\nSave_epochs = 10 #迭代多少层保存一次模型\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    # save_weights_only=True,\n    monitor='val_Sbp_mean_absolute_error',\n    mode='min',\n    save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = create_model()\n    \n    model.compile(loss={'Sbp':\"mse\",'Dbp':\"mse\"}, optimizer=keras.optimizers.Adam(lr=0.0001),metrics=[tf.keras.metrics.MeanAbsoluteError(),standard_deviation])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = create_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"保存模型结构图片\"\"\"\ntf.keras.utils.plot_model(model, to_file=r'./model_graph.png', show_shapes=True, show_layer_names=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit({'inputs_1':train_data,'inputs_dev1':train_dev1,'inputs_dev2':train_dev2},{'Sbp':train_label_Sbp,'Dbp':train_label_Dbp},\n                    batch_size=128*8,\n                    epochs=500,\n                    callbacks=model_checkpoint_callback,\n                    validation_data=({'inputs_1':validation_data,'inputs_dev1':validation_dev1,'inputs_dev2':validation_dev2},{'Sbp':validation_label_Sbp,'Dbp':validation_label_Dbp})\n                    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(r'./last_model.h5.pickle', 'wb') as file_pi:\n \tpickle.dump(history.history, file_pi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}