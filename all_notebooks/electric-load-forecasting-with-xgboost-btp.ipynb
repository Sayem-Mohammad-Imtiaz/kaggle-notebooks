{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"import math #Mathematics module\nimport numpy as np # linear algebra in python\nimport pandas as pd # data processing\nimport seaborn as sns #statistical graphs in python\nimport matplotlib.pyplot as plt # graphs and plots\nimport xgboost as xgb #Extreme Gradient Boosting\nfrom sklearn.ensemble import ExtraTreesRegressor #AdaBoostRegressor, BaggingRegressor \nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, KFold, GridSearchCV, TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport warnings  \nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')\n\n\n\n\npjme_df = pd.read_csv('../input/electricload-forecasting/PJME_hourly.csv', parse_dates=[0], index_col=[0])\npjme_df = pjme_df.loc[~pjme_df.index.duplicated(keep='first')].sort_index().dropna()\n\n\n\ncity = 'New York'\nhumidity = pd.read_csv('../input/electricload-forecasting/humidity.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('humidity')\npressure = pd.read_csv('../input/electricload-forecasting/pressure.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('pressure')\ntemperature = pd.read_csv('../input/electricload-forecasting/temperature.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('temperature')\nwind_direction = pd.read_csv('../input/electricload-forecasting/wind_direction.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('wind_direction')\nwind_speed = pd.read_csv('../input/electricload-forecasting/wind_speed.csv', parse_dates=[0], index_col=[0])[city].dropna().rename('wind_speed')\n\n\nweather_df = pd.concat([temperature, humidity, pressure, wind_direction, wind_speed], axis=1).sort_index()\nweather_df = weather_df.loc[~weather_df.index.duplicated(keep='first')].sort_index().dropna()\nweather_df = weather_df.assign(pressure_log = weather_df.pressure.apply(np.log))\n\n\n\ncomb_df = pd.concat([pjme_df.loc[weather_df.index[0]:weather_df.index[-1]], weather_df], axis=1).sort_index().dropna()\n\n\n\nfig, axes = plt.subplots(nrows=4, ncols=1, figsize=(20,15))\naxes[0].set_title('PJME Power Consumption')\naxes[0].set_ylabel('Power(MW)')\ncomb_df.PJME_MW.plot(ax=axes[0])\n\naxes[1].set_title('Temperature')\naxes[1].set_ylabel('Temperature(K)')\ncomb_df.temperature.plot(ax=axes[1])\n\naxes[2].set_title('Pressure')\naxes[2].set_ylabel('Pressure')\ncomb_df.pressure.plot(ax=axes[2])\n\naxes[3].set_title('Pressure_log')\naxes[3].set_ylabel('Pressure_log')\ncomb_df.pressure_log.plot(ax=axes[3])\n\nplt.tight_layout()\nplt.show()\n\nfinal_df = (comb_df.assign( day_of_week = comb_df.index.dayofweek\n                            ,year = comb_df.index.year\n                            ,month = comb_df.index.month\n                            ,day = comb_df.index.day\n                            ,day_of_year = comb_df.index.dayofyear\n\n                            ,week = comb_df.index.week\n                            ,week_day = comb_df.index.weekday \n                            ,quarter = comb_df.index.quarter\n                            ,hour = comb_df.index.hour\n                            ,hour_x = np.sin(2.*np.pi*comb_df.index.hour/24.)\n                            ,hour_y = np.cos(2*np.pi*comb_df.index.hour/24.)\n                            ,day_of_year_x = np.sin(2.*np.pi*comb_df.index.dayofyear/365.)\n                            ,day_of_year_y = np.cos(2.*np.pi*comb_df.index.dayofyear/365.)\n\n                          )\n           )\n\n# df['hourfloat']=df.hour+df.minute/60.0\n# df['x']=np.sin(2.*np.pi*df.hourfloat/24.)\n# df['y']=np.cos(2.*np.pi*df.hourfloat/24.)\n\nlagged_df = final_df.copy()\n\n# Next day's load values.\nlagged_df['load_tomorrow'] = lagged_df['PJME_MW'].shift(-24)    \n\nfor day in range(8):\n    lagged_df['temperature_d' + str(day)] = lagged_df.temperature.shift(24*day)\n    lagged_df['wind_speed_d' + str(day)] = lagged_df.wind_speed.shift(24*day)\n    lagged_df['humidity_d' + str(day)] = lagged_df.humidity.shift(24*day)\n    lagged_df['pressure_log_d' + str(day)] = lagged_df.pressure_log.shift(24*day)\n\n    \n    \n    lagged_df['load_d' + str(day)] = lagged_df.PJME_MW.shift(24*day)\n\n     \nlagged_df = lagged_df.dropna()\n    \n\nlagged_df = lagged_df.drop(columns=['temperature', 'wind_speed', 'humidity', 'pressure', 'wind_direction', 'week_day','PJME_MW'])\n\nX = lagged_df.drop(columns=['load_tomorrow'])\ny = lagged_df['load_tomorrow']\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n\n\ndef plot_prediction(actual, prediction, start_date, end_date, title, prediction_label):\n    plt.figure(figsize=(20,5))\n    plt.title(title)\n    plt.plot(y_test.index, y_test, label='Actual')\n    plt.plot(y_test.index, prediction, label=prediction_label)\n    plt.ylabel('Power(MW)')\n    plt.xlabel('Datetime')\n    plt.legend()\n    plt.xlim(left= start_date, right=end_date)\n    plt.show()\n    \ndef subplot_prediction(actual, prediction,prediction_label):\n    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(20, 15))\n    \n    con_df = pd.concat([actual.rename('Actual'),pd.DataFrame(prediction, index=actual.index, columns=[prediction_label])], axis=1)\n    axes[0].set_title('Actual vs Prediction - One day')\n    axes[0].set_ylabel('Power(MW)')\n    axes[0].set_xlabel('Datetime')\n    con_df.plot(ax=axes[0])\n    axes[0].set_xlim(left=con_df.index[-24*1] , right=con_df.index[-1])\n    \n    axes[1].set_title('Actual vs Prediction - One week')\n    axes[1].set_ylabel('Power(MW)')\n    axes[1].set_xlabel('Datetime')\n    con_df.plot(ax=axes[1])\n    axes[1].set_xlim(left=actual.index[-24*7] , right=actual.index[-1])\n    \n    axes[2].set_title('Actual vs Prediction - One month')\n    axes[2].set_ylabel('Power(MW)')\n    axes[2].set_xlabel('Datetime')\n    con_df.plot(ax=axes[2])\n    axes[2].set_xlim(left=actual.index[-24*7*4] , right=actual.index[-1])\n    \n    plt.tight_layout()\n    plt.show()\n    \ndef plot_feature_importances( clf, X_train, y_train=None\n                             ,top_n=10, figsize=(10,18), print_table=False, title=\"Feature Importances\"):\n    feat_imp = pd.DataFrame({'importance':clf.feature_importances_})    \n    feat_imp['feature'] = X_train.columns\n    feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n    feat_imp = feat_imp.iloc[:top_n]\n    \n    feat_imp.sort_values(by='importance', inplace=True)\n    feat_imp = feat_imp.set_index('feature', drop=True)\n    feat_imp.plot.barh(title=title, figsize=figsize)\n    plt.xlabel('Feature Importance Score')\n    plt.show()\n    \n    if print_table:\n        from IPython.display import display\n        print(\"Top {} features in descending order of importance\".format(top_n))\n        display(feat_imp.sort_values(by='importance', ascending=False))\n        \n    return feat_imp\n\n\nreg = xgb.XGBRegressor(silent=True)\n\ntscv = TimeSeriesSplit(n_splits=5)\nscores = cross_val_score(reg, X.values, y.values, cv=tscv\n                         ,scoring='explained_variance'\n                        )\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() ))\nprint(scores)\n\n\nreg.fit(X_train,y_train)\nprediction = reg.predict(X_test)\n\n#_ = plot_feature_importances(reg, X_train, y_train, top_n=X_train.shape[1], title=reg.__class__.__name__, print_table=True)\n\n\ndef get_features(date, comb_df):\n    features = comb_df.loc[date]\n    features = (features.assign(\n                                day_of_week = features.index.dayofweek\n                                ,year = features.index.year\n                                ,month = features.index.month\n                                ,day = features.index.day\n                                ,day_of_year = features.index.dayofyear\n                                ,week = features.index.week\n#                                             ,week_day = features.index.weekday_name \n                                ,quarter = features.index.quarter\n                                ,hour = features.index.hour\n                                ,hour_x = np.sin(2.*np.pi*features.index.hour/24.)\n                                ,hour_y = np.cos(2*np.pi*features.index.hour/24.)\n                                ,day_of_year_x = np.sin(2.*np.pi*features.index.dayofyear/365.)\n                                ,day_of_year_y = np.cos(2.*np.pi*features.index.dayofyear/365.)\n                                \n                                ))\n    \n    for day in range(8):\n        features['temperature_d' + str(day)] = comb_df.temperature.shift(24*day)\n        features['wind_speed_d' + str(day)] = comb_df.wind_speed.shift(24*day)\n        features['humidity_d' + str(day)] = comb_df.humidity.shift(24*day)\n        features['pressure_log_d' + str(day)] = comb_df.pressure_log.shift(24*day)\n\n\n\n        features['load_d' + str(day)] = comb_df.PJME_MW.shift(24*day)\n\n    features = features.dropna()\n    \n    features = features.drop(columns=['temperature', 'wind_speed', 'humidity', 'pressure', 'wind_direction','PJME_MW'])\n\n    return features\n\n\n\ndate = input(\"Give a date between 2012-10-01 and 2017-10-27: \")\n\n\nprediction = reg.predict(get_features(date, comb_df))\nidx = comb_df.PJME_MW.loc[date].index \n\n\ndef plot_prediction_multistep(actual, prediction, start_date, title, prediction_label):\n    date_rng = pd.date_range(start=start_date, periods=24, freq='H')\n    plt.figure(figsize=(20,5))\n    plt.title(title)\n    plt.plot(actual.index, actual, label='Actual')\n    plt.plot(actual.index, prediction, label=prediction_label)\n    plt.ylabel('Power(MW)')\n    plt.xlabel('Datetime')\n    plt.legend()\n    plt.show()\n    \nplot_prediction_multistep(actual=comb_df.PJME_MW.loc[date],prediction=prediction, start_date=date, title='Multistep prediction - 24 hours a head',\n                prediction_label='ExtraTrees Regressor model prediction')\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}