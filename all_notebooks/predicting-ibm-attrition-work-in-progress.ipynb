{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f8af8392-dad4-b0e7-db43-83204cf2ec5e"},"source":"# Introduction #\nFinding the right people is indispensable for the success of any company. Hiring people does not only cost time _and_ money, but it also might set a company back in revenue for a while. Therefore, understanding why people join, stay or leave an organization is essential to maximizing the organization's success.\n\nI come from _R_ and this will be my first _Python_ notebook. **Exciting!** I think this is a very nice data set to try out some new ideas and get familiar with the syntax and functions.\n\nThis notebook will be structured as follows:\n\n 1. **Exploratory Data Analysis**\n 2. **Feature Engineering**\n 3. **Training Machine Learning Models**\n 4. **Assessing Models and Performance**\n\nLet's see what we can discover!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7accd2d7-0fa1-79f3-885d-0d834e79988b"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport seaborn.matrix as smatrix\nimport matplotlib.pyplot as plt"},{"cell_type":"markdown","metadata":{"_cell_guid":"cf3f0885-ee56-06a0-3fa8-bd0695b8e76d"},"source":"#1 | Exploratory Data Analysis#\nWe first load in the data and look at the head of the data set, to get an idea of what kind of variables we will be dealing with.\n\n##1.1 | Load and first look##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff7b9f14-ea74-ee2f-71bb-75cc19b40d7e"},"outputs":[],"source":"df = pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndf.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cbfec47c-ed54-f52c-fc75-f269b6207c9f"},"source":"We see right away what will be the _dependent variable_: **Attrition**. \n\nLet us quickly move forwards to check for some other important things: the completeness of the data set and the distribution of the variables. We might even get a quick idea in whether or not some variables might show a lot of correlation, which has implication for the training of our models in a later stage.\n\n##1.2 | Data Quality Assessment & Variable Distributions##\nWe will now quickly assess if we have any missing values (using `isnull` from _pandas_)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c74eaa0b-29dc-155e-27e6-516b1a7fa3c9"},"outputs":[],"source":"df.isnull().any()"},{"cell_type":"markdown","metadata":{"_cell_guid":"806067fa-5747-0cf9-dce8-5520aaf18b23"},"source":"Cool! Pristine data set. Now we'll have a look at the distributions. A Kernel Density Estimation (KDE) is our friend here."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c72c27fe-cebf-8711-4388-2e16998f940a"},"outputs":[],"source":"# Plot 1\nx = df['Age']\ny = df['DailyRate']\nsns.jointplot(x, y, kind=\"kde\");\n\n# Plot 2\nx = df['Age']\ny = df['DistanceFromHome']\nsns.jointplot(x, y, kind=\"kde\");\n\n# Plot 3\nx = df['Age']\ny = df['Education']\nsns.jointplot(x, y, kind=\"kde\");\n\n# Plot 4\nx = df['JobSatisfaction']\ny = df['DailyRate']\nsns.jointplot(x, y, kind=\"kde\");\n\n# Plot 5\nx = df['YearsAtCompany']\ny = df['DailyRate']\nsns.jointplot(x, y, kind=\"kde\");\n\n# Plot 6\nx = df['Education']\ny = df['DailyRate']\nsns.jointplot(x, y, kind=\"kde\");"},{"cell_type":"markdown","metadata":{"_cell_guid":"4a22f95f-8c72-c3be-7483-a9c437f3cd95"},"source":"We know have some first insights (such that working for a long time at the company, doesn't really seem to mean higher daily rates -- an eye-opener for me!). But of course, given the many variables, making a plot for every combination of two variables is way to much work. \n\nSo we'll need either a heatmap or some kind of correlogram here. I'll follow [these][1] instructions to come up with something nice.\n\n\n  [1]: http://www.marketcalls.in/python/nifty-returns-heatmap-generation-using-nsepy-seaborn.html"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34175e9b-2869-2438-ddc0-984482dbadd1"},"outputs":[],"source":"# Select only the numerical variables\nlist_numerical = ['Age','DailyRate','DistanceFromHome','Education','EmployeeNumber', \n                  'EnvironmentSatisfaction','HourlyRate','JobInvolvement','JobLevel', \n                  'JobSatisfaction','MonthlyIncome','MonthlyRate','NumCompaniesWorked',\n                  'PercentSalaryHike','PerformanceRating','RelationshipSatisfaction',\n                  'StockOptionLevel','TotalWorkingYears',\n                  'TrainingTimesLastYear','WorkLifeBalance','YearsAtCompany',\n                  'YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager']\n\ndata = df[list_numerical] # We can use data.head() to check if everything went correct\n\nfig, ax = plt.subplots()\n\n# Meh, doens't work out yet. Try on the whiteboard first\nsns.heatmap(data, cbar=False, squara=False,\n            robust=True, annot=True, fmt=\".1d\",\n            annot_kws={\"size\":8}, linewidths=0.5, \n            cmap=\"RdYlGn\", ax=ax)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}