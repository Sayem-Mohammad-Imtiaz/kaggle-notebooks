{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bank Turnover Dataset\n#### Can you predict if bank customers will turnover next cycle ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the libraries\nimport numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\", 100)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading Required Data\n\ndata_train = pd.read_csv(\"/kaggle/input/bank-customer-churn-modeling/Churn_Modelling.csv\",encoding=\"utf-8\", delimiter=',')\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Removing customerID and Row Number\n\ndata_train2 = data_train.drop(['RowNumber','CustomerId','Surname'],axis=1)\ndata_train2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets findout the distribution of Churn: Yes and Nos First\n\n# Good Practice: Always check if data set is balance or imbalance.\nsns.set_style('whitegrid')\nsns.countplot(x='Exited',data=data_train2,palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations: \n\n- This is imbalanced dataset, There are different ways to cater it, But for the sake of learning deep learning, We can ignore it for now. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## There are some outliers in Balance and Estimated Salry. 1. Balance (min to 25%) is 0; while Estimated salary is \n## 11.58 rupees as minimum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets see this through dist plot\n\nplt.hist(data_train2.EstimatedSalary, bins=5\n         , rwidth=0.8)\nplt.xlabel('EstimatedSalary')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(data_train2.EstimatedSalary, bins=7\n         , rwidth=0.8)\nplt.xlabel('EstimatedSalary')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use percentiles technique to detect and remove outliers\n\n\nMaxThershold = data_train2['EstimatedSalary'].quantile(0.999)\nMaxThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MinThershold = data_train2['EstimatedSalary'].quantile(0.015)\nMinThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train3 = data_train2[(data_train2.EstimatedSalary < MaxThershold) & (data_train2.EstimatedSalary > MinThershold)]\ndata_train3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"10000-9540","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Detecting outlier in Balance\n\n## Lets see this through dist plot\n\nplt.hist(data_train3.Balance, bins=5\n         , rwidth=0.8)\nplt.xlabel('Balance')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(data_train3.Balance, bins=7\n         , rwidth=0.8)\nplt.xlabel('Balance')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use percentiles technique to detect and remove outliers\n\n\nMaxThershold = data_train3.Balance.quantile(0.999)\nMaxThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MinThershold = data_train3.Balance.quantile(0.370)\nMinThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4 = data_train3[(data_train3.Balance < MaxThershold) & (data_train3.Balance > MinThershold)]\ndata_train4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets seperate all as numerical/Categorical\n# Findout Missing Value %age\n\nstatistics_of_data = []\nfor col in data_train4.columns:\n  statistics_of_data.append((col,\n                             data_train4[col].isnull().sum()*100/data_train4.shape[0],\n                             data_train4[col].dtype\n                             ))\nstats_df = pd.DataFrame(statistics_of_data, columns=['Feature', 'missing_val', 'type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_df.sort_values('missing_val', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##No missing Values Found","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Seperate out Numerical/Int Variables.\nnumerical_features = [feature for feature in data_train4.columns if data_train4[feature].dtypes != 'O' ]\nprint(len(numerical_features))\ndata_train4[numerical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature = [feature for feature in numerical_features if len(data_train4[feature].unique())<25]\nprint(len(discrete_feature))\ndiscrete_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Continous Features\n\n\ncontinous_feature = [feature for feature in numerical_features if feature not in discrete_feature]\nprint(\"Continuous feature Count {}\".format(len(continous_feature)))\ndata_train4[continous_feature].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_unique_col_values(df):\n    i=1\n    for column in df:\n        str = \"{i}. {a} column have {b} unique values\"\n        print(str.format(i=i,a=column,b=df[column].unique()))\n        i=i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_unique_col_values(data_train4[discrete_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets create visuals for comparison of continous/discrete and target vairable\n##Exited: 0 -> No,1 ->Yes\ntenure_churn_no = data_train4[data_train4.Exited==0].Tenure\ntenure_churn_yes = data_train4[data_train4.Exited==1].Tenure\n\nplt.xlabel(\"tenure\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets create visuals for comparison of continous/discrete and target vairable\n##Exited: 0 -> No,1 ->Yes\nAge_churn_no = data_train4[data_train4.Exited==0].Age\nAge_churn_yes = data_train4[data_train4.Exited==1].Age\n\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([Age_churn_yes, Age_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Exited: 0 -> No,1 ->Yes\nBalance_churn_no = data_train4[data_train4.Exited==0].Balance\nBalance_churn_yes = data_train4[data_train4.Exited==1].Balance\n\nplt.xlabel(\"Balance\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([Balance_churn_yes, Balance_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EstimatedSalary\n##Exited: 0 -> No,1 ->Yes\nEstimatedSalary_churn_no = data_train4[data_train4.Exited==0].EstimatedSalary\nEstimatedSalary_churn_yes = data_train4[data_train4.Exited==1].EstimatedSalary\n\nplt.xlabel(\"EstimatedSalary\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([EstimatedSalary_churn_yes, EstimatedSalary_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets seperate our categorical features so that we can add other transformation uopn them\ncategoricalVariable = [feature for feature in data_train4.columns if data_train3[feature].dtype == 'O' ]\nlen(categoricalVariable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4[categoricalVariable].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male->1, Female 0\ndata_train4['Gender'].replace({'Female':1,'Male':0},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets apply One hot encoding for categorical column Geography\n\ndata_train5 = pd.get_dummies(data=data_train4, columns=['Geography'])\ndata_train5.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train5.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train5.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Scaling of continous data\n\ncontinous_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Data Scaling -->>Continous data only\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata_train5[continous_feature] = scaler.fit_transform(data_train5[continous_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ij=1\nfor col in data_train5:\n    str = \"{ij}. {a} column have {b} unique values\"\n    print(str.format(ij = ij,a=col,b=data_train5[col].unique()))\n    ij=ij+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Train Test Split:::\n\nX = data_train5.drop('Exited',axis='columns')\ny = data_train5['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n### Now we are Builiding a Deep Learning Model (ANN) On keras/Tensorflow\n\n### Now we are Builiding a Deep Learning Model (ANN) On keras/Tensorflow With Hyperparameter Optimization through keras tuner\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow_addons import losses\nfrom sklearn.metrics import confusion_matrix , classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ArtificalNeuralNets(X_train, y_train, X_test, y_test, loss, weights):\n    model_ChurnPred = keras.Sequential([\n        keras.layers.Dense(12, input_shape=(12,), activation='relu'),\n        keras.layers.Dense(15, activation='relu'),\n        keras.layers.Dense(1, activation='sigmoid')\n    ])\n    \n    model_ChurnPred.compile(optimizer='adam',\n                            loss='binary_crossentropy',\n                            metrics=['accuracy'])\n    if weights == -1:\n        model_ChurnPred.fit(X_train, y_train, epochs=100)\n    else:\n        model_ChurnPred.fit(X_train, y_train, epochs=100, class_weight = weights)\n        \n    print(model_ChurnPred.evaluate(X_test, y_test))\n    y_preds = model_ChurnPred.predict(X_test)\n    y_preds = np.round(y_preds)\n    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n    return y_preds\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = ArtificalNeuralNets(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observations:::\nWe are having 0.90 and 0.58 F1 scores. For value 0 it is good that we have 0.90 score but for 1 we have pretty low \nrate that is 0.58; lets start with \"under sampling\" and visualize our results\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class count\ncount_class_0, count_class_1 = data_train5.Exited.value_counts()\n\nprint(count_class_1)\ncount_class_0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide by class\ndf_class_0 = data_train5[data_train5['Exited'] == 0]\ndf_class_1 = data_train5[data_train5['Exited'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Undersample 0-class and concat the DataFrames of both class\ndf_class_0_under = df_class_0.sample(count_class_1)\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Random under-sampling:')\nprint(df_test_under.Exited.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_test_under.drop('Exited',axis='columns')\ny = df_test_under['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of classes in training Data\ny_train.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = ArtificalNeuralNets(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check classification report above. f1-score for minority class 1 improved from 0.58 to 0.73. Score for class 0 reduced to 0.76 from 0.90 but that's ok. We have more generalized classifier which classifies both classes with similar prediction score"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Method2: Oversampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class_1 = data_train5[data_train5['Exited'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Oversample 1-class and concat the DataFrames of both classes\ndf_class_1_over = df_class_1.sample(count_class_0, replace=True)\ndf_class_1_over","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n\nprint('Random over-sampling:')\nprint(df_test_over.Exited.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_test_over.drop('Exited',axis='columns')\ny = df_test_over['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = keras.losses.BinaryCrossentropy()\nweights = -1\ny_preds = ArtificalNeuralNets(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check classification report above. f1-score for minority class 1 improved from 0.57 to 0.73. Score for class 0 reduced to 0.77 from 0.85 but that's ok. We have more generalized classifier which classifies both classes with similar prediction score"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Method3: SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_train5.drop('Exited',axis='columns')\ny = data_train5['Exited']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nsklearn.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import imblearn\nimblearn.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = SMOTE(sampling_strategy='minority')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_sm, y_sm = smote.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_sm.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of classes in training Data\n#y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_preds = ArtificalNeuralNets(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####################### ********** THE END ********************** ############################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}