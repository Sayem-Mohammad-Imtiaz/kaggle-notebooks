{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/crime-in-vancouver/crime.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.YEAR.value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # 2. Correlation Matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df.corr()\nplt.figure(figsize=(15, 15))\n\nplt.title(\"Correlation Graph\")\n\ncmap = sns.diverging_palette( 1000, 120, as_cmap=True)\nsns.heatmap(corr_matrix, annot=True, fmt='.2f',  linewidths=.8, cmap='coolwarm');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" * # 3. Data Processing\nPerform Feature Standerd Scalling"},{"metadata":{},"cell_type":"markdown","source":"Standardize features by removing the mean and scaling to unit variance\n\nThe standard score of a sample x is calculated as:\n\nz = (x - u) / s"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ns_sc = StandardScaler()\ncol_to_scale = ['YEAR', 'MONTH', 'DAY', 'MINUTE']\ndf[col_to_scale] = s_sc.fit_transform(df[col_to_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Applying machine learning algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score , classification_report\nimport seaborn as sns\nclasses=['healthy','Un-healthy']\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_train, pred) 100:.2f}%\")\n       # recall=recall_score(y_train, pred) \n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_train, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        sns.heatmap(confusion_matrix(y_test, pred), annot= True, cmap='YlGnBu',fmt = 'g')\n        print(classification_report(y_test,pred))\n        cm=(confusion_matrix(y_test,pred))\n       # ax.xaxis.set_label_position('top')\n        plt.tight_layout()\n        plt.title('Confusion matrix for Decision Tree Model', y = 1.1)\n        plt.ylabel('Actual label')\n        plt.xlabel('Predicted label')\n        plt.show()\n        total = sum(sum(cm))\n        acc = (cm[0, 0] + cm[1, 1]) / total\n        sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n        specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n       # print(cm)\n\n        FP = cm.sum(axis=0) - np.diag(cm)  \n        FN = cm.sum(axis=1) - np.diag(cm)\n        TP = np.diag(cm)\n        TN = cm.sum() - (FP + FN + TP)\n\n        FP = FP.astype(float)\n        FN = FN.astype(float)\n        TP = TP.astype(float)\n        TN = TN.astype(float)\n\n        # Sensitivity, hit rate, recall, or true positive rate\n        TPR = TP/(TP+FN)\n        print('Sensitivity (TPR) : ',TPR)\n        # Specificity or true negative rate\n        TNR = TN/(TN+FP) \n        print('Specificity (TNR) : ',TNR)\n        # Overall accuracy\n        print(\" Overall accuracy\")\n        ACC = (TP+TN)/(TP+FP+FN+TN)\n        print('Accuracy : ',ACC)\n        print(\"Accuracy: {:.4f}\".format(acc))\n        print(\"Average Sensitivity: {:.4f}\".format(sensitivity))\n        print(\"Average Specificity: {:.4f}\".format(specificity))\n        print('\\n')\n        \n        conf_matrix=cm\n        print(\"=========================================\")\n        # save confusion matrix and slice into four pieces\n        TP = conf_matrix[1][1]\n        TN = conf_matrix[0][0]\n        FP = conf_matrix[0][1]\n        FN = conf_matrix[1][0]\n        print('True Positives:', TP)\n        print('True Negatives:', TN)\n        print('False Positives:', FP)\n        print('False Negatives:', FN)\n\n        # calculate accuracy\n        conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n\n        # calculate mis-classification\n        conf_misclassification = 1- conf_accuracy\n\n        # calculate the sensitivity\n        conf_sensitivity = (TP / float(TP + FN))\n        # calculate the specificity\n        conf_specificity = (TN / float(TN + FP))\n\n        # calculate precision\n        conf_precision = (TN / float(TN + FP))\n        # calculate f_1 score\n        conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n        print('-'*50)\n        print(f'Accuracy: {round(conf_accuracy,2)}') \n        print(f'Mis-Classification: {round(conf_misclassification,2)}') \n        print(f'Sensitivity: {round(conf_sensitivity,2)}') \n        print(f'Specificity: {round(conf_specificity,2)}') \n        print(f'Precision: {round(conf_precision,2)}')\n        print(f'f_1 Score: {round(conf_f1,2)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function to plot ROC and Precision Recall Curve for combination of all models\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\ndef plotting(true,pred):\n    fig,ax=plt.subplots(1,2,figsize=(15,5))\n    precision,recall,threshold = precision_recall_curve(true,pred[:,1])\n    ax[0].plot(recall,precision,'g--')\n    ax[0].set_xlabel('Recall')\n    ax[0].set_ylabel('Precision')\n    ax[0].set_title(\"Average Precision Score : {}\".format(average_precision_score(true,pred[:,1])))\n    fpr,tpr,threshold = roc_curve(true,pred[:,1])\n    ax[1].plot(fpr,tpr)\n    ax[1].set_title(\"AUC Score is: {}\".format(auc(fpr,tpr)))\n    ax[1].plot([0,1],[0,1],'k--')\n    ax[1].set_xlabel('False Positive Rate')\n    ax[1].set_ylabel('True Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('YEAR', axis=1)\ny = df.YEAR\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. K-nearest neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_classifier = KNeighborsClassifier()\nknn_classifier.fit(X_train, y_train)\n\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. #  2. Decision Tree Classifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n\nsvm_model = SVC(kernel='rbf', gamma=0.1, C=1.0, probability=True)\nsvm_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(svm_model, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_model, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nNN=MLPClassifier(hidden_layer_sizes=(10,50),momentum=0.9,solver='sgd',random_state=42)\n               \nNN.fit(X_train, y_train)\n\nprint_score(NN, X_train, y_train, X_test, y_test, train=True)\nprint_score(NN, X_train, y_train, X_test, y_test, train=False) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}