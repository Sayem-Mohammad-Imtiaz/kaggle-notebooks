{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Zoo Animals Classification\n\n_Evaluating 13 different algorithms in Python_"},{"metadata":{},"cell_type":"markdown","source":"## Importação dos pacotes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importar pacotes necessários\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# definir parâmetros extras\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15, 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importar pacotes usados na seleção do modelo e na medição da precisão\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\n\n# importar os pacotes necessários para os algoritmos de classificação\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Carga dos dados de entrada"},{"metadata":{"trusted":true},"cell_type":"code","source":"# carregar arquivo de dados de treino\ndata = pd.read_csv('/kaggle/input/zoo-animal-classification/zoo.csv', index_col='animal_name')\n\n# mostrar alguns exemplos de registros\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# definir dados de entrada\n\nX = data.drop(['class_type'], axis=1) # tudo, exceto a coluna alvo\ny = data['class_type'] # apenas a coluna alvo\n\nprint('Forma dos dados originais:', X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treinamento dos modelos preditivos"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\ndef evaluate_model_cv(model, X=X, y=y):\n    start = datetime.now()\n    kfold = KFold(n_splits=10, random_state=42)\n    results = cross_val_score(model, X, y, cv=kfold,\n                              scoring='accuracy', verbose=1)\n    end = datetime.now()\n    elapsed = int((end - start).total_seconds() * 1000)\n    score = results.mean() * 100\n    stddev = results.std() * 100\n    print(model, '\\nCross-Validation Score: %.2f (+/- %.2f) [%5s ms]' % \\\n          (score, stddev, elapsed))\n    return score, stddev, elapsed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\ndef fine_tune_model(model, params, X=X, y=y):\n  print('\\nFine Tuning Model:')\n  print(model, \"\\nparams:\", params)\n  kfold = KFold(n_splits=10, random_state=42)\n  grid = GridSearchCV(estimator=model, param_grid=params,\n                      scoring='accuracy', cv=kfold, verbose=1)\n  grid.fit(X, y)\n  print('\\nGrid Score: %.2f %%' % (grid.best_score_ * 100))\n  print('Best Params:', grid.best_params_)\n  return grid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação e ajuste fino de cada modelo preditivo"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A) Logistic Regression\nmodel = LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto', max_iter=500, C=100)\n#TODO: testar LogisticRegression(multi_class='multinomial', solver='newton-cg')\nevaluate_model_cv(model)\n\nparams = {'solver':['liblinear', 'lbfgs'], 'C':np.logspace(-3,3,7)}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# B) Decision Tree\nmodel = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=11)\nevaluate_model_cv(model)\n\nparams = {'criterion':['gini','entropy'], 'max_depth':[3,5,7,11]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# C) K-Nearest Neighbours\nmodel = KNeighborsClassifier(n_neighbors=1)\nevaluate_model_cv(model)\n\nparams = {'n_neighbors':[1, 3, 5, 7, 9]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# D) Support Vector Machine (SVM)\nmodel = SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')\n# SVC(kernel='linear', C=1)\nevaluate_model_cv(model)\n\nparams = {'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100], 'kernel':['linear', 'rbf']}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# E) Random Forest\nmodel = RandomForestClassifier(random_state=42, max_features='auto', n_estimators=10)\nevaluate_model_cv(model)\n\nparams = {'n_estimators':[10, 50, 100, 500], 'max_features':['auto', 'sqrt', 'log2']}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# F) Stochastic Gradient Descent (SGD)\nmodel = SGDClassifier(random_state=42, max_iter=100, tol=0.1)\nevaluate_model_cv(model)\n\nparams = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# G) Perceptron\nmodel = Perceptron(random_state=42, max_iter=100, tol=0.01)\n# Perceptron(eta0=1, random_state=1)\nevaluate_model_cv(model)\n\nparams = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01, 0.001]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# H) Naïve Bayes\nmodel = GaussianNB(priors=None, var_smoothing=1e-08)\nevaluate_model_cv(model)\n\nparams = {'priors': [None], 'var_smoothing': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I) Linear SVM\nmodel = LinearSVC(random_state=42, max_iter=1000, C=10)\nevaluate_model_cv(model)\n\nparams = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# J) Ada Boost\nmodel = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), n_estimators=5)\nevaluate_model_cv(model)\n\nparams = {'n_estimators':[1,3,5,7,11]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K) Gradient Boosting\nmodel = GradientBoostingClassifier(random_state=42, max_depth=3)\nevaluate_model_cv(model)\n\n'''\nparams = {\n    \"learning_rate\":[0.01, 0.05, 0.1],\n    \"max_depth\":[3, 5, 7],\n    \"max_features\":[\"log2\", \"sqrt\"],\n    \"criterion\":[\"friedman_mse\", \"mae\"],\n    \"subsample\":[0.5, 0.75, 1.0],\n}\n'''\n\nparams = {'max_depth':[3, 5, 7]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# M) Multi-Layer Perceptron (MLP)\nmodel = MLPClassifier(random_state=42, solver='lbfgs', alpha=0.1, hidden_layer_sizes=(15,))\nevaluate_model_cv(model)\n\nparams = {'alpha':[1,0.1,0.01,0.001,0.0001,0]}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# N) Linear Discriminant Analysis (LDA)\nmodel = LinearDiscriminantAnalysis(solver='svd')\nevaluate_model_cv(model)\n\nparams = {'solver':['svd', 'lsqr']} #, 'eigen']}\n#fine_tune_model(model, params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparação final entre os algoritmos"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(('LR', LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto', max_iter=500, C=100)))\nmodels.append(('DT', DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=11)))\nmodels.append(('KNN', KNeighborsClassifier(n_neighbors=1)))\nmodels.append(('SVM', SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')))\nmodels.append(('RF', RandomForestClassifier(random_state=42, max_features='auto', n_estimators=10)))\nmodels.append(('SGD', SGDClassifier(random_state=42, max_iter=100, tol=0.1)))\nmodels.append(('NN', Perceptron(random_state=42, max_iter=100, tol=0.01)))\nmodels.append(('NB', GaussianNB(priors=None, var_smoothing=1e-08)))\nmodels.append(('LSVM', LinearSVC(random_state=42, max_iter=1000, C=10)))\nmodels.append(('ABDT', AdaBoostClassifier(DecisionTreeClassifier(random_state=42), n_estimators=5)))\nmodels.append(('GB', GradientBoostingClassifier(random_state=42, max_depth=3)))\nmodels.append(('MLP', MLPClassifier(random_state=42, solver='lbfgs', alpha=0.1, hidden_layer_sizes=(15,))))\nmodels.append(('LDA', LinearDiscriminantAnalysis(solver='svd')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nnames = []\nscores = []\nstddevs = []\ntimes = []\n\nfor name, model in models:\n    score, stddev, elapsed = evaluate_model_cv(model, X=X, y=y)\n    results.append((score, stddev))\n    names.append(name)\n    scores.append(score)\n    stddevs.append(stddev)\n    times.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxplot algorithm comparison\n#fig = plt.figure()\n#fig.suptitle('Algorithm Comparison')\n#ax = fig.add_subplot(111)\n#plt.boxplot(results)\n#ax.set_xticklabels(names)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### And the winner was..."},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df = pd.DataFrame({\n    'Model': names,\n    'Score': scores,\n    'Std Dev': stddevs,\n    'Time (ms)': times})\n\nresults_df.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}