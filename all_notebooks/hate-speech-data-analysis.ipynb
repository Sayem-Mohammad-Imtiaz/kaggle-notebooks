{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Dynamically Generated Hate Speech Data : Data Analysis of Performance**\n\n**About The Dataset**\n\nThe Dynamically Generated Hate Speech Dataset is provided in two tables.\n\nThe first table is the dataset of entries, with the entry ID, label, type, annotator ID, status, round, split, round model predictions and whether the model was fooled (model_wrong).\n\nThe second table is the targets of the hate, in a wide format. Because annotators could identify targets inductively, a large number were identified with only or two associated entries, often if they were intersectional characteristics. We combine all identities mentioned in fewer than 15 entries into an 'Other category'. This affects less than 1% of all the hateful entries, whilst reducing the number of target identities to 41. The two tables can be merged on the 'ID' variable.\n\n**Let's dive into notebook without further Ado!**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install contractions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport re\nimport contractions\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\nfrom nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\nfrom nltk.stem import WordNetLemmatizer \nlemmatizer = WordNetLemmatizer() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading the Dataset**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/dynamically-generated-hate-speech-dataset/2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns = ['Unnamed: 0'], axis = 1 , inplace = True)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['id'].dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Checking for NaN values**\n\nI am basically looking for NaN values to see how they might influence the analysis I'll perform.","metadata":{}},{"cell_type":"code","source":"for i in data.columns:\n    print(i,\":\",data[str(i)].isnull().sum()/data.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The values which are nan only make up 35% of the data , hence I am thinking of dropping them for now.","metadata":{}},{"cell_type":"code","source":"data.dropna(axis = 0,inplace = True)\nfor i in data.columns:\n    print(i,\":\",data[str(i)].isnull().sum()/data.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**\n\n\nGiven below are the headings to analysis of certain topics:\n\n**1.  All About Type  : Exploring Type Distribution**\n\n**2.  Model Evaluation on Labels**\n\n**3.  Text Properties and Relations With Other Variables**\n        \n       3.1 Word Clouds and More\n    \n       3.2 Lists of Common Words\n    \n**4.  Annotators and Model Wrong**\n\n**5.  Exploring Targets : Merging Tables**\n        \n       5.1 Target Distribution in Dataset\n       \n       5.2 Exploring Top Two Values\n      \n**6.  Visualizing Embeddings**","metadata":{}},{"cell_type":"markdown","source":"\n\n#  **All About Type**\n\nLet's check out the distribution of types in the dataset.","metadata":{}},{"cell_type":"code","source":"data.groupby('type').count()['id']","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['type'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(ncols = 3, figsize = (20,4) , dpi = 100)\n#plt.tight_layout()\n\ncolors = ['#66c2a5', '#fc8d62' , '#8da0cb' ,'#e78ac3' , '#a6d854' , '#ffd92f','#e5c494']\ndata['type'].value_counts().plot(kind = 'pie',ax = ax[0], labels = data['type'].value_counts().index , colors = colors)\nsns.countplot(x = 'type',data = data , ax = ax[1] , palette = 'Paired')\nsns.countplot(x = 'type' , data = data , hue = 'model_wrong', palette = 'Paired')\n\nfor i in range(3):\n    ax[i].set_ylabel('')\n    ax[i].tick_params(axis='x', labelsize=15 , rotation = 45)\n    ax[i].tick_params(axis='y', labelsize=15)\n\nax[0].set_title('Type Distribution in Data', fontsize=13)\nax[1].set_title('Type Count in Data', fontsize=13)\nax[2].set_title('Model Evaluation on Type', fontsize = 13)\n\nplt.show()\n","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above charts we can conclude the following about type :\n\n1.  None and Not Given are the types which are in maximum quantity. \n2.  Derogation follows them in the third place.\n3.  The Model was able to succesfully identify the label in the cases of sentences with types None and Derogation.\n4.  The Model was succesfully fooled maximum number of times by None and Not Given types. Since Not Given types is a mixture of other types, we cannot really point out the specific characterstic which might have resulted in this. ","metadata":{}},{"cell_type":"markdown","source":"# **Model Evaluation on Lables**\n\nLet's see how well the model performed on labels.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.countplot(x = 'label' , data = data, hue = 'model_wrong' , palette = 'Paired')\nplt.ylabel(\"\")\nplt.tick_params(axis = 'x',labelsize = 15)\nplt.tick_params(axis = 'y',labelsize = 15)\nplt.title(\"Model Evaluation on Label\" , fontsize = 15)\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While the model assigns correct labels nearly equal number of times in both cases of hate and not hate labels, when it comes to assigning a wrong label , it is more likely that that sentence would be a hate comment. This could possibly be because of the distribution of hate and not hate comments in dataset. Let's check that out.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.countplot(x = 'label' , data = data, palette = 'Paired')\nplt.ylabel(\"\")\nplt.tick_params(axis = 'x',labelsize = 15)\nplt.tick_params(axis = 'y',labelsize = 15)\nplt.title(\"Label Distribution\" , fontsize = 15)\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay , this is not something I was expecting. The countplot prior to this would ideally suggest more number of not hate sentences as compared to hate , but here the graph shows a completely different story. \n\nBookmarking this for now and will come back to it later.","metadata":{}},{"cell_type":"markdown","source":"# **Text Properties and Relations with Other Variables**\n\nLet's check the text properties and relations with other variables","metadata":{}},{"cell_type":"code","source":"def clean_txt(txt):\n        ##html code\n        TAG_RE = re.compile(r'<[^>]+>') \n        txt = TAG_RE.sub('', txt.lower())\n        ##emojis\n        txt=txt.encode(\"ascii\",\"ignore\")\n        txt=txt.decode()\n        ##numbers removing\n        txt=''.join(i for i in txt if not i.isdigit())\n        ##punctuation\n        txt = re.sub(r'[^\\w\\s]', ' ', txt) \n        ##stopwords\n        txt = ' '.join([i for i in txt.split() if not i in STOPWORDS])\n        ##removing certain sized words\n        txt=' '.join([i for i in txt.split() if len(i)>2])\n        ##contractions\n        txt=contractions.fix(txt)\n        ##stemmers\n        ##txt= stemmer.stem(txt)  should stemming be performed or lemmatization and why?\n        ##lemmatizer\n        txt=lemmatizer.lemmatize(txt)\n        return txt","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Clean Text'] = data['text'].apply(clean_txt)\ndata.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['model_wrong'] = data['model_wrong'].astype(\"string\")\ndata['model_wrong'].dtype","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = [ ]\nmodel_wrong = []\nlabel = []\nfor _,row in data.iterrows():\n    a = row['Clean Text'].split()\n    if(row['label'] == 'hate'):\n        label+=[0 for i in range(len(a))]\n    else:\n        label+=[1 for i in range(len(a))]\n    if(row['model_wrong'] == 'True'):\n        model_wrong+=[0 for i in range(len(a))]\n    else:\n        model_wrong+=[1 for i in range(len(a))]\n    vocab+=a\n    ","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_model_relation = pd.DataFrame({'Words': vocab , 'Model Wrong': model_wrong ,'Label': label })\n#vocab_model_relation.drop_duplicates(subset=['Words'],inplace=True)\nvocab_model_relation.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Word Clouds and More**\n\nWe are looking for possible keywords in our sentences which the model might have associated with a certain label while learning the kind of characterstics of words have, on making embeddings. ","metadata":{}},{"cell_type":"code","source":"words = vocab_model_relation[vocab_model_relation['Model Wrong'] == 1]['Words'].value_counts().index\nwords","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words2 = vocab_model_relation[vocab_model_relation['Model Wrong'] == 0]['Words'].value_counts().index\nwords2","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_words = list(set(words)&set(words2))\ncommon_words[:10]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = list(set(words).difference(set(common_words)))\nwords[:10]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words2 = list(set(words2).difference(set(common_words)))\nwords2[:10]","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\ndef wc(data,bgcolor,title):\n    plt.figure(figsize = (13,10))\n    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.title(title , fontsize = 20)\n    plt.imshow(wc)\n    plt.axis('off')\n\nwc(common_words,'black','Common Words')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These words are used in abundance in both hate and non hate sentences. Hence , for now we are assuming that they have an equal influence on both hate and non hate sentences for the model.","metadata":{}},{"cell_type":"code","source":"wc(words,'black','Unique Words For Which Predictions Were Wrong')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we remove the common words used , we get unique words for each category. The ones for which the model was wrong are shown above. \n","metadata":{}},{"cell_type":"code","source":"wc(words2,'black','Unique Words For Which Model Evaluted True')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again these words have both , what most of us call 'good' and 'bad' words. The context in which these words are used ends up determining whether the sentences is hateful or not.","metadata":{}},{"cell_type":"markdown","source":"## **Lists of Common Words**\n\nHere we are going to see the twenty most used words , their total number of occurences and how did the model perform when it encountered them.\nWe will also be checking whether our assumption that the common words have an equal influence on both hateful and not hateful sentences is correct or not.","metadata":{}},{"cell_type":"code","source":"fig , ax = plt.subplots(ncols = 2,figsize = (20,10) , dpi = 100)\n\nsns.barplot(y = vocab_model_relation[vocab_model_relation['Model Wrong'] == 0]['Words'].value_counts().index[0:20] , x = vocab_model_relation[vocab_model_relation['Model Wrong'] == 0]['Words'].value_counts().values[:20], ax = ax[0] , color = '#97d83e')\nsns.barplot(y = vocab_model_relation[vocab_model_relation['Model Wrong'] == 1]['Words'].value_counts().index[0:20] , x = vocab_model_relation[vocab_model_relation['Model Wrong'] == 1]['Words'].value_counts().values[:20], ax = ax[1] , color = '#e55063')\n\nfor i in range(2):\n    ax[i].tick_params(axis = 'x' , labelsize = 13)\n    ax[i].tick_params(axis = 'y' , labelsize = 13)\n\nax[0].set_title('Model Got Them Right')\nax[1].set_title('Model Got Them Wrong')\n","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above charts we can see that the top 5 words are same for both cases. While most words are common , if you look carefully , the count of these words is not. The frequency of words in usage is more when the model correctly assigns a label as compared to the ones in which it assigns them wrong.\n\nWe can also clearly see that sentences containing the words everyone, wrong and really are the words which do not make it to the top 20 usage of words in the Model Got them Wrong List.","metadata":{}},{"cell_type":"code","source":"fig , ax = plt.subplots(ncols = 2,figsize = (20,10) , dpi = 100)\n\nsns.barplot(y = vocab_model_relation[vocab_model_relation['Label'] == 0]['Words'].value_counts().index[0:20] , x = vocab_model_relation[vocab_model_relation['Label'] == 0]['Words'].value_counts().values[:20], ax = ax[0] , color = '#97d83e')\nsns.barplot(y = vocab_model_relation[vocab_model_relation['Label'] == 1]['Words'].value_counts().index[0:20] , x = vocab_model_relation[vocab_model_relation['Label'] == 1]['Words'].value_counts().values[:20], ax = ax[1] , color = '#e55063')\n\nfor i in range(2):\n    ax[i].tick_params(axis = 'x' , labelsize = 13)\n    ax[i].tick_params(axis = 'y' , labelsize = 13)\n\nax[0].set_title('Top 20 Words Used In Hate Comments')\nax[1].set_title('Top 20 Words Used In Non Hate Comments')\n","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# **Annotators and Model Wrong**","metadata":{}},{"cell_type":"code","source":"data['annotator'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors_false = ['grey' for i in data[data['model_wrong'] == 'False']['annotator'].value_counts().index]\ncolors_false[2] = '#dd5a5b'\ncolors_true = ['grey' for i in data[data['model_wrong'] == 'True']['annotator'].value_counts().index]\ncolors_true[1] = '#dd5a5b'","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig , ax = plt.subplots(ncols = 2,figsize = (20,10) , dpi = 100)\n\nsns.barplot(y = data[data['model_wrong'] == 'False']['annotator'].value_counts().index , x = data[data['model_wrong'] == 'False']['annotator'].value_counts().values, ax = ax[0] , palette = colors_false)\nsns.barplot(y = data[data['model_wrong'] == 'True']['annotator'].value_counts().index, x = data[data['model_wrong'] == 'True']['annotator'].value_counts().values, ax = ax[1] , palette = colors_true)\n\nfor i in range(2):\n    ax[i].tick_params(axis = 'x' , labelsize = 13)\n    ax[i].tick_params(axis = 'y' , labelsize = 13)\n    \nax[0].set_title('Model Got Them Right')\nax[1].set_title('Model Got Them Wrong')\n","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can clearly see from the above graph that the Model gets more sentences right , if the annotator lqlkttromx has assigned the label and it gets them wrong in the case the annotator is elgzzdd8tvb.\n\nHowever implying that this is a causal relationship between annotators and label assignment by model  would be wrong as there is a possiblity of other confounders being present. We would require a way to test the same before inferring that this is indeed a causal relationship. ","metadata":{}},{"cell_type":"markdown","source":"# **Exploring Targets**\n\nWe will now merge the tables and explore the targets.","metadata":{}},{"cell_type":"code","source":"new_data = pd.read_csv(\"/kaggle/input/dynamically-generated-hate-speech-dataset/2020-12-31-DynamicallyGeneratedHateDataset-targets-v0.1.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = []\nfor i in range(new_data.shape[0]):\n    try:\n        tags.append(list(new_data.iloc[i,:].index)[list(new_data.iloc[i,:].values).index(1)])\n    except:\n        tags.append('Nothing')\n    \nprint(tags[:2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m_data = data.merge(pd.DataFrame({'id':new_data['id'],'targets':tags}) , on = 'id' , how='inner')\nm_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m_data['label'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Target Distribution in Dataset**","metadata":{}},{"cell_type":"code","source":"colors = ['grey' for i in range(len(m_data['targets'].value_counts().index))] \ncolors[2] = '#dd5a5b'\ncolors[3] = '#97d83e'","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\n\nsns.countplot(y=m_data['targets'],order = m_data['targets'].value_counts().index, palette = colors)\nplt.tick_params(axis = 'y' , labelsize = 15)\nplt.tick_params(axis = 'x' , labelsize = 15)\nplt.ylabel('Targets')\nplt.xlabel('')\nplt.title(\"Target Distribution in Dataset\" , fontsize = 20)\nplt.xticks(rotation = 90)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the black community and women are the most targeted in the dataset we have.","metadata":{}},{"cell_type":"markdown","source":"## **Exploring The Top Two Values**\n\nI am kinda scared and concerned about the type of results which might show up. ","metadata":{}},{"cell_type":"markdown","source":"### **Sentences Targetting Black People**","metadata":{}},{"cell_type":"code","source":"words_black = [ ]\nlabels = []\nfor _,row in m_data[m_data['targets'] == 'bla'].iterrows():\n    a = row['Clean Text'].split()\n    if(row['label'] == 0):\n        labels+=[0 for i in range(len(a))]\n    else:\n        labels+=[1 for i in range(len(a))]\n    words_black+=a\n\nwords_black = pd.DataFrame({'Word':words_black , 'Label':labels})\nwords_black.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.countplot(words_black['Label'] , palette = 'Paired')\nplt.ylabel(\"\")\nplt.legend('Hate')\nplt.title('Total Sentences Labeled Hate and Not Hate' , fontsize = 15)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc(words_black['Word'].unique(),'black','Unique Words Found in Sentences Targetting Black People')","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well , this wordcloud , is just ugly. But I guess it is merely a reflection of the population of people chosen for this study.","metadata":{}},{"cell_type":"code","source":"words_black[words_black['Label'] == 1]['Word'].value_counts()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.barplot(y = words_black['Word'].value_counts()[:20].index , x = words_black['Word'].value_counts()[:20].values , color = '#97d83e')\nplt.title('Top 20 Words Appearing In Sentences Targetting The Black Community' , fontsize = 15)\nplt.xticks(rotation = 90)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Sentences Targetting Women**","metadata":{}},{"cell_type":"code","source":"words_women = [ ]\nlabels = []\nfor _,row in m_data[m_data['targets'] == 'wom'].iterrows():\n    a = row['Clean Text'].split()\n    if(row['label'] == 0):\n        labels+=[0 for i in range(len(a))]\n    else:\n        labels+=[1 for i in range(len(a))]\n    words_women+=a\n\nwords_women = pd.DataFrame({'Word':words_women , 'Label':labels})\nwords_women.head()","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.countplot(words_women['Label'] , palette = 'Paired')\nplt.ylabel(\"\")\nplt.legend('Hate')\nplt.title('Total Sentences Labeled Hate and Not Hate' , fontsize = 15)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wc(words_women['Word'].unique() , 'black' , 'Unique Words Found in Sentences Targetting Women')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is a true mixture of words.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.barplot(y = words_women['Word'].value_counts()[:30].index , x = words_women['Word'].value_counts()[:30].values , color = '#97d83e')\nplt.tick_params(axis = 'y', labelsize = 12)\nplt.title('Common Words Found in Sentences Targetting Women' , fontsize = 15)\nplt.xticks(rotation = 90)","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Visualizing Embeddings**\n\nNow this visualization might be inaccurate considering I am using Count Vectorizer and TFIDF to make embeddings and not what was probably used in the model. Still let's check it out!","metadata":{}},{"cell_type":"code","source":"label = {'hate':0 , 'nothate':1}\ndata['label'] = data['label'].map(label)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import TruncatedSVD,PCA\ndef cv(data):\n    count_vectorizer = CountVectorizer()\n\n    emb = count_vectorizer.fit_transform(data)\n\n    return emb, count_vectorizer\n\nlist_corpus = data[\"text\"].tolist()\nlist_labels = data[\"label\"].tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2)\n\nX_train_counts, count_vectorizer = cv(X_train)\nX_test_counts = count_vectorizer.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.patches as mpatches\ndef plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n        lsa = TruncatedSVD(n_components=2)\n        lsa.fit(test_data)\n        lsa_scores = lsa.transform(test_data)\n        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n        color_column = [color_mapper[label] for label in test_labels]\n        colors = ['orange','blue']\n        if plot:\n            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n            orange_patch = mpatches.Patch(color='orange', label='Hate')\n            blue_patch = mpatches.Patch(color='blue', label='Not Hate')\n            plt.legend(handles=[orange_patch, blue_patch], prop={'size': 30})\n\nfig = plt.figure(figsize=(12, 12))          \nplot_LSA(X_train_counts, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we cannot actually make out much of a difference. Let's use TFIDF vectorizer for the same and check.","metadata":{}},{"cell_type":"code","source":"def tfidf(data):\n    tfidf_vectorizer = TfidfVectorizer()\n\n    train = tfidf_vectorizer.fit_transform(data)\n\n    return train, tfidf_vectorizer\n\nX_train_tfidf, tfidf_vectorizer = tfidf(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 12))          \nplot_LSA(X_train_tfidf, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, that makes quite the difference.","metadata":{}},{"cell_type":"markdown","source":"Thank you for reading ! If you liked what I did , give me an upvote ! Saw something which could have been better or have a suggestion to make it better ? Leave a comment and I'll get back to you ASAP.\n\n# **References**\n\nBelow are some awesome notebooks where I discovered new ways to do EDA for NLP . Do check them out !!\n\n1. https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert\n2. https://www.kaggle.com/vbmokin/nlp-eda-bag-of-words-tf-idf-glove-bert\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}