{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom matplotlib.pylab import rcParams\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport keras.backend as K\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.models import load_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"you can download the dataset here  : [dataset](https://drive.google.com/file/d/1emopjfEkTt59jJoBH9L9bSdmlDC4AR87/view?usp=sharing)","metadata":{}},{"cell_type":"code","source":"april = pd.read_csv('../input/uber-pickups-in-new-york-city/uber-raw-data-apr14.csv')\nmay   = pd.read_csv('../input/uber-pickups-in-new-york-city/uber-raw-data-may14.csv')\njune  = pd.read_csv('../input/uber-pickups-in-new-york-city/uber-raw-data-jun14.csv')\njuly  = pd.read_csv('../input/uber-pickups-in-new-york-city/uber-raw-data-jul14.csv')\naug   = pd.read_csv('../input/uber-pickups-in-new-york-city/uber-raw-data-aug14.csv')\nsept  = pd.read_csv('../input/uber-pickups-in-new-york-city/uber-raw-data-sep14.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"april.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data =  april.append(may).append(june).append(july).append(aug).append(sept)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.Timestamp = pd.to_datetime(data['Date/Time'],format='%m/%d/%Y %H:%M:%S')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['date_only'] = data.Timestamp.dt.date\ndata['date'] = data.Timestamp\ndata['month'] = data.Timestamp.dt.month\ndata['dow_num'] = data.Timestamp.dt.dayofweek\ndata['dow_name'] = data.Timestamp.dt.day_name()\ndata['month_day_num'] = data.Timestamp.dt.day\ndata['hours'] = data.Timestamp.dt.hour\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Base'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('hours')['hours'].count().sort_values(ascending=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## peak days\n\ndata.groupby(pd.Grouper(key='dow_name')).count()\n\nuber_weekdays = data.pivot_table(index=['dow_num','dow_name'],values='Base', aggfunc='count')\nuber_weekdays.plot(kind='bar', figsize=(15,8))\nplt.ylabel('Total Trips')\nplt.xlabel('Day')\nplt.title('Trips by Week Day');\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can see ,there are more trips on thursdays and fridays","metadata":{}},{"cell_type":"code","source":"## peak hours \n\nuber_hour = data.pivot_table(index=['hours'], values='Base', aggfunc='count')\nuber_hour.plot(kind='bar', figsize=(8,6))\nplt.ylabel('Total Trips')\nplt.title('Trips by Hour');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can observe that more people take ride in the evening around 5pm","metadata":{}},{"cell_type":"code","source":"data.groupby(pd.Grouper(key='Base')).count()\n\nuber_monthdays = data.pivot_table(index=['Base'], values='date' ,\n                                  aggfunc='count')\nuber_monthdays.plot(kind='bar', figsize=(8,6))\nplt.ylabel('Total Trips')\nplt.title('Trips by Month Day');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting data","metadata":{}},{"cell_type":"code","source":"data.drop(['Lat','Lon'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data.groupby('date_only').count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tsf = x.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"all the columns have same value , because we jut counted number of trips for day . so the quantities are same for all <br/>\nLet's delete all the columns keeping one","metadata":{}},{"cell_type":"code","source":"x_tsf.drop(['Date/Time','Base','month','dow_num','dow_name','month_day_num','hours'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tsf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(0.9*len(x_tsf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ts = x[:][:165]                     #split is 90-10\ntest_ts = x[:][166:]\n#test_ts_d = uber_dates_d[:][166:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ts['date'].plot(kind='line',figsize=(15,8), title= 'Daily Trip', fontsize=12)\ntest_ts['date'].plot(figsize=(15,5), title= 'Daily Trip', fontsize=12)\nplt.ylabel('Total Trips')\nplt.xlabel('Month')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Holt's winter seasonal method","metadata":{}},{"cell_type":"code","source":"hat_avg = test_ts.copy()\nfit1 = ExponentialSmoothing(np.asarray(train_ts['date']) ,seasonal_periods=7 ,trend='add', seasonal='add',).fit()\nhat_avg['Holt_Winter'] = fit1.forecast(len(test_ts))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8),fontsize=12,label='train')\ntest_ts['date'].plot(figsize=(15,5),fontsize=12,label='test')\nplt.plot(hat_avg['Holt_Winter'], label='Holt_Winter')\nplt.legend(loc='best')\nplt.ylabel('Total Trips')\nplt.xlabel('Months')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.style.use('default')\nplt.figure(figsize = (16,8))\nsm.tsa.seasonal_decompose(train_ts['date'].values,freq=30).plot()\nresult = sm.tsa.stattools.adfuller(x_tsf['date'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hat_avg_1 = test_ts.copy()\n\nfit1 = Holt(np.asarray(train_ts['date'])).fit(smoothing_level = 0.3,smoothing_slope = 0.1)\nhat_avg_1['Holt_linear'] = fit1.forecast(len(test_ts))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8),fontsize=12,label='train')\ntest_ts['date'].plot(figsize=(15,5),fontsize=12,label='test')\nplt.plot(hat_avg_1['Holt_linear'], label='Holt_linear')\nplt.legend(loc='best')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  ARIMA","metadata":{}},{"cell_type":"code","source":"rcParams['figure.figsize']=(20,10)\nrolmean = x_tsf['date'].rolling(24).mean()\nrolstd = x_tsf['date'].rolling(24).std()\n        \n#Plot rolling Statistics\nx_tsf['date'].plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\n#.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nTrain_log = np.log(train_ts['date'])\nvalid_log = np.log(test_ts['date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"moving_avg = Train_log.rolling(24).mean()\nTrain_log.plot(kind='line',figsize=(15,8),fontsize=12, color = 'green', label='Training_log')\nmoving_avg.plot(figsize=(15,5),fontsize=12, color = 'blue', label='Moving_avg')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_log_moving_diff = Train_log - moving_avg\ntrain_log_moving_diff.dropna(inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nrolmean = train_log_moving_diff.rolling(24).mean()\nrolstd = train_log_moving_diff.rolling(24).std()\n\n#Plot rolling Statistics\ntrain_log_moving_diff.plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\nrolstd.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_log_diff = Train_log - Train_log.shift(1)\n\n\nrolmean = train_log_diff.rolling(24).mean()\nrolstd = train_log_diff.rolling(24).std()\n\n#Plot rolling Statistics\ntrain_log_diff.plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\nrolstd.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decomposition = seasonal_decompose(pd.DataFrame(Train_log)['date'].values, freq = 24)\nplt.style.use('default')\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,3))\nTrain_log.plot(kind='line', label = 'Original')\nplt.legend(loc = 'best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,9))\nplt.subplot(411)\nplt.plot(trend, label = 'Trend')\nplt.legend(loc = 'best')\nplt.subplot(412)\nplt.plot(seasonal, label = 'Seasonal')\nplt.legend(loc = 'best')\nplt.subplot(413)\nplt.plot(residual, label = 'Residuals')\nplt.legend(loc = 'best')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_log_decompose = pd.DataFrame(residual)\ntrain_log_decompose['date'] = Train_log.index\ntrain_log_decompose.set_index('date', inplace = True)\ntrain_log_decompose.dropna(inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rolmean = train_log_decompose[0].rolling(24).mean()\nrolstd = train_log_decompose[0].rolling(24).std()\n\n#Plot rolling Statistics\ntrain_log_decompose[0].plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\nrolstd.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\n\nlag_acf = acf(train_log_diff.dropna(), nlags = 25)\nlag_pacf = pacf(train_log_diff.dropna(), nlags = 25, method= \"ols\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ACF\nplt.figure(figsize = (15,5))\nplt.style.use(\"fivethirtyeight\")\nplt.plot(lag_acf)\nplt.axhline( y = 0, linestyle = \"--\", color = \"gray\")\nplt.axhline( y= -1.96/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.axhline(y = 1.96 /np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.title(\"Autocorrelation Function\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PACF\nplt.figure(figsize = (15,5))\nplt.plot(lag_pacf)\nplt.axhline(y = 0, linestyle = \"--\", color = \"gray\")\nplt.axhline(y = -1.96/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.axhline( y = 1.96/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.title(\"Partial Autocorrelation Function\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AR Model","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize = (15,6))\nmodel = ARIMA(Train_log, order = (2,1,0))  #here q value is zero since it is just AR Model\nresults_AR = model.fit(disp=-1)\ntrain_log_diff.dropna().plot(kind='line', label = \"Actual\")\nresults_AR.fittedvalues.plot(kind='line', color = 'red', label = 'Predictions')\nplt.legend(loc = 'upper right')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize = (16,8))\nmodel = ARIMA(Train_log, order = (2,1,1))\nresults_ARIMA = model.fit(disp=-1)\ntrain_log_diff.dropna().plot(kind='line',  label='Original')\nresults_ARIMA.fittedvalues.plot(kind='line', color='red', label='Predicted')\nplt.legend(loc='best')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ### to scale into original scale","metadata":{}},{"cell_type":"code","source":"\ndef check_prediction_diff(predict_diff, given_set):\n    predict_diff= predict_diff.cumsum().shift().fillna(0)\n    predict_base = pd.Series(np.ones(given_set.shape[0]) * np.log(given_set['date'])[0], index = given_set.index)\n    #predict_log = predict_base.add(predict_diff,fill_value=0)\n    predict = np.exp(predict_base)\n    \n    plt.plot(given_set['date'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['date']))/given_set.shape[0]))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_prediction_log(predict_log, given_set):\n    predict = np.exp(predict_log)\n    \n    plt.plot(given_set['date'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['date']))/given_set.shape[0]))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ARIMA_predict_diff=results_ARIMA.predict(len(train_ts))\nplt.figure(figsize = (16,8))\ncheck_prediction_diff(ARIMA_predict_diff, test_ts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RMSE more, should go for any other model ","metadata":{}},{"cell_type":"markdown","source":"## Exponential smoothening","metadata":{}},{"cell_type":"code","source":"hat_avg = test_ts.copy()\nfit2 = SimpleExpSmoothing(np.asarray(train_ts['date'])).fit(smoothing_level = 0.7,optimized = False)\nhat_avg['SES'] = fit2.forecast(len(test_ts))\nplt.figure(figsize =(15,8))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat_avg['SES'], label = 'Simple Exponential Smoothing',color='green')\nplt.legend(loc = 'best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hat=hat_avg['SES'].values.tolist()\nrmse = np.sqrt(mean_squared_error(test_ts['date'],hat))\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"better than AR model","metadata":{}},{"cell_type":"markdown","source":"## MA forecast with 10 observations","metadata":{}},{"cell_type":"code","source":"\nhat_avg = test_ts.copy()\nhat_avg['moving_average_forecast'] = train_ts['date'].rolling(10).mean().iloc[-1]\nplt.figure(figsize = (15,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat_avg['moving_average_forecast'], label = 'Moving Average Forecast with 10 Observations')\nplt.legend(loc = 'best')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MA forecast with 20 observations","metadata":{}},{"cell_type":"code","source":"hat_avg = test_ts.copy()\nhat_avg['moving_average_forecast'] = train_ts['date'].rolling(20).mean().iloc[-1]\nplt.figure(figsize = (15,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat_avg['moving_average_forecast'], label = 'Moving Average Forecast with 10 Observations')\nplt.legend(loc = 'best')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nrmse = np.sqrt(mean_squared_error(test_ts['date'], hat_avg['moving_average_forecast']))\nrmse\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hat = test_ts.copy()\nfit2 = SimpleExpSmoothing(np.asarray(train_ts['date'])).fit(smoothing_level = 0.8,optimized = False)\nhat['SES'] = fit2.forecast(len(test_ts))\nplt.figure(figsize =(15,8))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat['SES'], label = 'Simple Exponential Smoothing')\nplt.legend(loc = 'best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"error is till high.. let's see other model","metadata":{}},{"cell_type":"markdown","source":"## SARIMAX","metadata":{}},{"cell_type":"code","source":"def day_series_creator(dataframe):\n    \n    # Grouping by Date/Time to calculate number of trips\n    day_df = pd.Series(dataframe.groupby(['date']).size())\n    # setting Date/Time as index\n    day_df.index = pd.DatetimeIndex(day_df.index)\n    # Resampling to daily trips\n    day_df = day_df.resample('1D').apply(np.sum)\n    \n    return day_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"day_df_2014 = day_series_creator(data)\nday_df_2014.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initial_plots(time_series, num_lag):\n\n    #Original timeseries plot\n    plt.figure(1)\n    plt.plot(time_series)\n    plt.title('Original Uber data across time')\n    plt.figure(2)\n    plot_acf(time_series, lags = num_lag)\n    plt.title('Autocorrelation plot')\n    plot_pacf(time_series, lags = num_lag)\n    plt.title('Partial autocorrelation plot')\n    \n    plt.show()\n\n    \n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(day_df_2014)[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#plotting\ninitial_plots(day_df_2014, 45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting 30 observation\ninitial_plots(day_df_2014, 30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diff_series = day_df_2014.diff(periods=1)\n\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(adfuller(diff_series.dropna())[1],2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninitial_plots(diff_series.dropna(), 30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ANN ","metadata":{}},{"cell_type":"code","source":"uber_count=data.groupby(pd.Grouper(key='date')).count()\nprint(uber_count.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_count.drop(['Base','date_only','month','dow_num','dow_name','month_day_num','hours'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uber_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = uber_count[:][:234084]             #90% of 260093\ntest = uber_count[:][234085:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Date/Time'].plot(kind='area',figsize=(15,8), title= 'Hourly Trips', fontsize=14)\ntest['Date/Time'].plot(figsize=(15,5), title= 'Hourly Trips', fontsize=12)\nplt.ylabel('Total Trips')\nplt.xlabel('Month')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef test_stationary(timeseries):\n    \n    rolmean = timeseries.rolling(24).mean()\n    rolstd = timeseries.rolling(24).std()\n    \n    \n    #Plot rolling Statistics\n    act = plt.plot(timeseries, color = \"blue\", label = \"Actual\")\n    mean = plt.plot(rolmean, color = \"brown\", label = \"Rolling Mean\")\n    std = plt.plot(rolstd, color = \"black\", label = \"Rolling Std\")\n    plt.legend(loc = \"best\")\n    plt.title(\"Rolling Mean and Standard Deviation\")\n    plt.show(block = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rcParams['figure.figsize']=(20,10)\ntest_stationary(uber_count['Date/Time'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = MinMaxScaler()\ntrain_sc = sc.fit_transform(train)\ntest_sc = sc.transform(test)\n\nX_train = train_sc[:-1]\ny_train = train_sc[1:]\n\nX_test = test_sc[:-1]\ny_test = test_sc[1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nK.clear_session()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(9, input_dim=1, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nearly_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=1, callbacks=[early_stop], shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_ann = model.predict(X_test)\ny_train_pred_ann = model.predict(X_train)\nrmse = np.sqrt(mean_squared_error(y_train,y_train_pred_ann))\nprint(\"Train : {:0.3f}\".format(rmse))\n\nrmse = np.sqrt(mean_squared_error(y_test,y_pred_test_ann))\nprint(\"Test : {:0.3f}\".format(rmse))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_ANN = model.predict(X_test)\nplt.plot(y_test, label='True')\nplt.plot(y_pred_test_ANN, label='ANN')\nplt.title(\"ANN's_Prediction\")\nplt.xlabel('Observation')\nplt.ylabel('INR_Scaled')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nacc=metrics.r2_score(y_test,y_pred_test_ann)\nprint(\"Accuracy Score of Model: \",round(acc*100,2),'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nscore_ann= model.evaluate(X_test, y_test, batch_size=1)\nprint('ANN: %f'%score_ann)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}