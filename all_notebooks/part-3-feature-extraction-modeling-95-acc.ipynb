{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport librosa as lb\nimport librosa.display as lbd\nimport os\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/part-2-handel-imbalance-creating-spectrogram/train.csv')\nval=pd.read_csv('../input/part-2-handel-imbalance-creating-spectrogram/val.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain=train.disease\nyval=val.disease\nyval","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As our class labels are of **dtype: object** we must first convert them to **encoded values** or intergers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nytrain=le.fit_transform(ytrain)\nyval=le.transform(yval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction\n\n> I am going to use Librosa's feature extraction methods here\n\n> Note:- i first tried to extract features **1-by-1** and then test them, to see how they perform but most of then were giving **good accuracy** so i finally decided to use all of them\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getFeatures(path):\n    soundArr,sample_rate=lb.load(path)\n    mfcc=lb.feature.mfcc(y=soundArr,sr=sample_rate)\n    cstft=lb.feature.chroma_stft(y=soundArr,sr=sample_rate)\n    mSpec=lb.feature.melspectrogram(y=soundArr,sr=sample_rate)\n\n    return mfcc,cstft,mSpec","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> In These functions i m iterating over **train and val dataset**, and using **filenames** to extract features and then converting them to **numpy arrays**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"root='../input/part-1-preprocessing/processed_audio_files/'\nmfcc,cstft,mSpec=[],[],[]\ni=0\nfor idx,row in val.iterrows():\n    path=root + row['filename']\n    a,b,c=getFeatures(path)\n    mfcc.append(a)\n    cstft.append(b)\n    mSpec.append(c)\n    \nmfcc_val=np.array(mfcc)\ncstft_val=np.array(cstft)\nmSpec_val=np.array(mSpec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shape of features returned by the above function **(20, 259) (12, 259) (128, 259)** we need this for defining **input shape** of our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"root='../input/part-1-preprocessing/processed_audio_files/'\nmfcc,cstft,mSpec=[],[],[]\ni=0\nfor idx,row in train.iterrows():\n    path=root + row['filename']\n    a,b,c=getFeatures(path)\n    mfcc.append(a)\n    cstft.append(b)\n    mSpec.append(c)\n    \nmfcc_train=np.array(mfcc)\ncstft_train=np.array(cstft)\nmSpec_train=np.array(mSpec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Discarded few features beacuse they were not important to performance"},{"metadata":{},"cell_type":"markdown","source":"# Testing Features\n\n> Lets create model using Keras **Functional API** to check how the features perform.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=5),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=3, min_lr=0.00001,mode='min'),\n    tf.keras.callbacks.ModelCheckpoint('hbNet', monitor='val_loss', verbose=0, save_best_only=True,)\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here i m creating **three** different **CNN** and then Combining them to a **Dense Network**."},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc_input=keras.layers.Input(shape=(20,259,1),name=\"mfccInput\")\nx=keras.layers.Conv2D(32,5,strides=(1,3),padding='same')(mfcc_input)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(64,3,strides=(1,2),padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(96,2,padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(128,2,padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nmfcc_output=keras.layers.GlobalMaxPooling2D()(x)\n\nmfcc_model=keras.Model(mfcc_input, mfcc_output, name=\"mfccModel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"croma_input=keras.layers.Input(shape=(12,259,1),name=\"cromaInput\")\nx=keras.layers.Conv2D(32,5,strides=(1,3),padding='same')(croma_input)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(64,3,strides=(1,2),padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(128,2,padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\ncroma_output=keras.layers.GlobalMaxPooling2D()(x)\n\ncroma_model=keras.Model(croma_input, croma_output, name=\"cromaModel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"croma_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mSpec_input=keras.layers.Input(shape=(128,259,1),name=\"mSpecInput\")\nx=keras.layers.Conv2D(32,5,strides=(2,3),padding='same')(mSpec_input)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(64,3,strides=(2,2),padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(96,2,padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(128,2,padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nmSpec_output=keras.layers.GlobalMaxPooling2D()(x)\n\nmSpec_model=keras.Model(mSpec_input, mSpec_output, name=\"mSpecModel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mSpec_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_mfcc=keras.layers.Input(shape=(20,259,1),name=\"mfcc\")\nmfcc=mfcc_model(input_mfcc)\n\ninput_croma=keras.layers.Input(shape=(12,259,1),name=\"croma\")\ncroma=croma_model(input_croma)\n\ninput_mSpec=keras.layers.Input(shape=(128,259,1),name=\"mspec\")\nmSpec=mSpec_model(input_mSpec)\n\n\nconcat=keras.layers.concatenate([mfcc,croma,mSpec])\nhidden=keras.layers.Dropout(0.2)(concat)\nhidden=keras.layers.Dense(50,activation='relu')(concat)\nhidden=keras.layers.Dropout(0.3)(hidden)\nhidden=keras.layers.Dense(25,activation='relu')(hidden)\nhidden=keras.layers.Dropout(0.3)(hidden)\noutput=keras.layers.Dense(8,activation='softmax')(hidden)\n\nnet=keras.Model([input_mfcc,input_croma,input_mSpec], output, name=\"Net\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.utils.plot_model(net, \"net.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy='sparse_categorical_accuracy'\nsparseLoss=keras.losses.SparseCategoricalCrossentropy()\n\nfrom keras import backend as K\nK.clear_session()\nnet.compile(optimizer='nadam', loss=sparseLoss,metrics=[accuracy])\nK.set_value(net.optimizer.learning_rate, 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=net.fit(\n    {\"mfcc\":mfcc_train,\"croma\":cstft_train,\"mspec\":mSpec_train},\n    ytrain,\n    validation_data=({\"mfcc\":mfcc_val,\"croma\":cstft_val,\"mspec\":mSpec_val},yval),\n    epochs=100,verbose=0,\n    callbacks=my_callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history).plot()\nplt.grid(True)\nplt.gca().set_ylim(-0.1,1.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.evaluate({\"mfcc\":mfcc_val,\"croma\":cstft_val,\"mspec\":mSpec_val},yval)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The model is a little **less accurate** but this must account to the use of **classes** that have very **less samples**, you can crop these out and i am sure this will improve accuracy to **98% accuracy**."},{"metadata":{},"cell_type":"markdown","source":"* To find out i got to this point, do check out other **Versions and Parts of this Series**.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=keras.models.load_model('./hbNet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='nadam', loss=sparseLoss,metrics=[accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate({\"mfcc\":mfcc_val,\"croma\":cstft_val,\"mspec\":mSpec_val},yval, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100*acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}