{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Problem Statement: \nHow severe can an airplane accident be?\nFlying has been the go-to mode of travel for years now; it is timesaving, affordable, and extremely convenient. According to the FAA, 2,781,971 passengers fly every day in the US, as in June 2019. Passengers reckon that flying is very safe, considering strict inspections are conducted and security measures are taken to avoid and/or mitigate any mis happenings. However, there remain a few chances of unfortunate incidents.\nImagine you have got a project from leading airline. You are required to build Machine Learning models to anticipate and classify the severity of an airplane accident based on past incidents. With this, all airlines, even the entire aviation industry, can predict the severity of airplane accidents caused due to various factors and, correspondingly, have a plan of action to minimize the risk associated with them.\n\n### Data:\nThe dataset comprises 2 files (Data is shared in the same folder) : \n●\tTrain.csv: [10000 x 12 excluding the headers] contains Training data\n●\tTest.csv: [2500 x 11 excluding the headers] contains Test data\n#### Columns\tDescription\nAccident_ID\tunique id assigned to each row\nAccident_Type_Code\tthe type of accident (factor, not numeric)\nCabin_Temperature\tthe last recorded temperature before the incident, measured in degrees Fahrenheit\nTurbulence_In_gforces\tthe recorded/estimated turbulence experienced during the accident\nControl_Metric\tan estimation of how much control the pilot had during the incident given the factors at play\nTotal_Safety_Complaints\tnumber of complaints from mechanics prior to the accident\nDays_Since_Inspection\thow long the plane went without inspection before the incident\nSafety_Score\ta measure of how safe the plane was deemed to be\nViolations\tnumber of violations that the aircraft received during inspections\nSeverity\ta description (4 level factor) on the severity of the crash [Target]\n\n \n \n### Solution Approach:\n#### Libraries Used:\n•\tPandas for data manipulation\n•\tNumPy for performing mathematical operations on the data\n•\tMatplotlib, Seaborn and Scikitplot for visualization\n•\tSklearn for pre-processing and model building & evaluation\n#### Steps and Inferences:\n1.\tData was read and loaded into a DataFrame and first few records were visualized\n2.\tThe dataTypes were understood and we could infer the following\na.\tSafety_Score, Control_Metric, Turbulence_In_gforces, Cabin_Temprature, Max_Elevation and Adverse_Weather_Metric are continuous in nature\nb.\tSeverity, Days_Since_Inspection, Total_Safety_Compliants, Accident_Type_Code and Violations are Discreet categorical data\n3.\tThere were no null values present in the dataset\n4.\tFive point summary was performed on the continuous data and following were observed\na.\tMean of the following attributes are not in sync with the median which implies the presence of outliers\ni.\tTotal_Safety_Complaints\nii.\tViolations\niii.\tAdverse_Weather_Metric\n5.\tExploratory Data Analysis was performed starting with univariate analysis and following were observed\na.\tSafety score is normally distributed  and has few outliers\nb.\tControl_Metric is skewed to the left but normally distributed with outliers\nc.\tTurbulence_In_gForce is skewed to the left but normally distributed with outliers\nd.\tCabin_Temprature is skewed to the right but normally distributed with outliers\ne.\tMax_Elevation is t normally distributed with outliers\nf.\tAdverse_Weather_Metric is highly skewed to the right with huge number of outliers\ng.\tAverage Days_Since_Inspection is 13\nh.\tnumber of records with Total_Safety_Compliants as 0-10 is high\ni.\tAccident_Type_Code 5 has fewer number of records\nj.\t2 violations has the highest number of records\nk.\tThere is a slight class imbalance with 'Significant_Damage_And_Fatalities' group having fewer number of records\n6.\tMultivariate analysis were performed along with correlation matrix and below were the features with top correlations\nAccident_Type_Code  \tAdverse_Weather_Metric    \t0.739361\nSafety_Score        \tDays_Since_Inspection     \t0.685386\nControl_Metric      \tTurbulence_In_gforces     \t0.643285\n7.\tNumerical data was standardized using z-score\n8.\tRemoved all records with z-score greater and lesser than 3 and -3 respectively as the values are outliers\n9.\t493 records were removed as they were considered outliers\n10.\tLabel Encoding was performed on the Target Column\n11.\tBasic Feature Engineering was performed in the interest of time and lack of domain expertise to create new features\n12.\tIndependent features and Target columns were split as X and Y\n13.\tK-Fold cross-validation was performed to create multiple folds of  train and validation data\n14.\t2 Models were taken into consideration based on the data\na.\tGradient Boosting\nb.\tXG Boost\n15.\tXGBoost was considered as final model and RandomSearchCV was used for hyper-parameterization\n16.\tValidation set was evaluated and all metrics (F1, recall, precision and accuracy) was above 95%\n17.\tTest Set was also loaded and predicted with the model already built\n\n#### Things that can improve model performance (Not done in this analysis due to time constraints):\n1.\tThere was slight imbalance in the dataset which we can over-sample to get better model performance for all classes\n2.\tBy gaining domain expertise, we can create new features which the model can interpret better.\n3.\tTest Data outliers can be imputed to get better results\n4.\tStatistical inference testing can be done to improve feature selection\n5.\tFeature importance can be obtained and model can be retrained\n"},{"metadata":{},"cell_type":"markdown","source":"### Importing Necessary Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import multilabel_confusion_matrix\nimport scikitplot as skplt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading and understanding the data-set"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/airplane-accidents-severity-dataset/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking the head of the data-set"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### ● Acciedent_ID : This is the unique ID of the accident as recorded by the authorities\n##### ● Adverse_Weather_Metric : measured weather metric in the basis of the adverse events occured\n##### ● Violations: number of violations that the aircraft received during inspections\n##### ● Max_Elevation : maximim altitude the airplane has reached during the event\n##### ● Accident_Type_Code : Code of the accident classified by the authorities\n##### ● Cabin_Temperature: the last recorded temperature before the incident, measured in degrees Fahrenheit\n##### ● Turbulence_In_gforces :the recorded/estimated turbulence experienced during the accident\n##### ● Control_Metric : an estimation of how much control the pilot had during the incident given the factors at play\n##### ● Total_Safety_Complaints:number of complaints from mechanics prior to the accident\n##### ● Days_Since_Inspection:how long the plane went without inspection before the incident\n##### ● Safety_Score: a measure of how safe the plane was deemed to be"},{"metadata":{},"cell_type":"markdown","source":"#### Checking the data-types of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Safety_Score, Control_Metric,Turbulence_In_gforces,Cabin_Temprature,Max_Elevation,Adverse_Weather_Metric are continous in nature\n##### Severity, Days_Since_Inspection, Total_Safety_Compliants, Accident_Type_Code and Violations are Discreet categorical data"},{"metadata":{},"cell_type":"markdown","source":"#### Checking the information of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### There are 10000 records with 11 independent variables and 1 target variable"},{"metadata":{},"cell_type":"markdown","source":"#### Check for any null values in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"na_values=data.isna().sum()\nprint(na_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### To describe the data- Five point summary- Remove Accident ID as it does not help with analysis of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Accident_ID'],axis=1,inplace=True)\ndata.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Mean of the following attributes are not in sync with the median which implies the presence of outliers\n###### Total_Safety_Complaints, Violations, Adverse_Weather_Metric"},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analytics"},{"metadata":{},"cell_type":"markdown","source":"#### Uni-Variate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of continous data\n\n# Safety_Score, Control_Metric,Turbulence_In_gforce\n\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1\nplt.subplot(1,3,1)\nplt.title('Safety_Score')\nsns.distplot(data['Safety_Score'],color='red')\n\n#Subplot 2\nplt.subplot(1,3,2)\nplt.title('Control_Metric')\nsns.distplot(data['Control_Metric'],color='blue')\n\n#Subplot 3\nplt.subplot(1,3,3)\nplt.title('Turbulence_In_gforces')\nsns.distplot(data['Turbulence_In_gforces'],color='green')\n\n\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1- Boxplot\nplt.subplot(1,3,1)\nplt.title('Safety_Score')\nsns.boxplot(data['Safety_Score'],orient='horizondal',color='red')\n\n#Subplot 2\nplt.subplot(1,3,2)\nplt.title('Control_Metric')\nsns.boxplot(data['Control_Metric'],orient='horizondal',color='blue')\n\n#Subplot 3\nplt.subplot(1,3,3)\nplt.title('Turbulence_In_gforces')\nsns.boxplot(data['Turbulence_In_gforces'],orient='horizondal',color='green')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Safety score is normally distributed  and has few outliers\n##### Control_Metric is skewed to the left but normally distributed with outliers\n##### Turbulence_In_gForce is skewed to the left but normally distributed with outliers "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of continous data\n# Cabin_Temprature, Max_Elevation, Adverse_Weather_Metric\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1\nplt.subplot(1,3,1)\nplt.title('Cabin_Temperature')\nsns.distplot(data['Cabin_Temperature'],color='red')\n\n#Subplot 2\nplt.subplot(1,3,2)\nplt.title('Max_Elevation')\nsns.distplot(data['Max_Elevation'],color='blue')\n\n#Subplot 3\nplt.subplot(1,3,3)\nplt.title('Adverse_Weather_Metric')\nsns.distplot(data['Adverse_Weather_Metric'],color='green')\n\n\n\nplt.figure(figsize=(30,6))\n\n#Subplot 1- Boxplot\nplt.subplot(1,3,1)\nplt.title('Cabin_Temperature')\nsns.boxplot(data['Cabin_Temperature'],orient='horizondal',color='red')\n\n#Subplot 2\nplt.subplot(1,3,2)\nplt.title('Max_Elevation')\nsns.boxplot(data['Max_Elevation'],orient='horizondal',color='blue')\n\n#Subplot 3\nplt.subplot(1,3,3)\nplt.title('Adverse_Weather_Metric')\nsns.boxplot(data['Adverse_Weather_Metric'],orient='horizondal',color='green')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Cabin_Temprature is skewed to the right but normally distributed with outliers\n##### Max_Elevation is t normally distributed with outliers\n##### Adverse_Weather_Metric is highly skewed to the right with huge number of outliers "},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Days_Since_Inspection, Total_Safety_Compliant\nplt.figure(figsize=(30,6))\n\n#Subplot 1\nplt.subplot(1,2,1)\nplt.title('Days_Since_Inspection')\nsns.countplot(data['Days_Since_Inspection'],color='red')\n\n#Subplot 2\nplt.subplot(1,2,2)\nplt.title('Total_Safety_Complaints')\nsns.countplot(data['Total_Safety_Complaints'],color='blue')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Average Days_Since_Inspection is 13\n##### number of records with Total_Safety_Compliants as 0-10 is high"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accident_Type_Code and Violations\n\nplt.figure(figsize=(30,6))\n\n\n#Subplot 1\nplt.subplot(1,2,1)\nplt.title('Accident_Type_Code')\nsns.countplot(data['Accident_Type_Code'],color='red')\n\n#Subplot 2\nplt.subplot(1,2,2)\nplt.title('Violations')\nsns.countplot(data['Violations'],color='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#####  Accident_Type_Code 5 has fewer number of records\n##### 2 violations has the highest number of records"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,6))\n\nplt.title('Severity')\nsns.countplot(data['Severity'],color='red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### There is a slight class imbalance with 'Significant_Damage_And_Fatalities' group having fewer number of records"},{"metadata":{},"cell_type":"markdown","source":"#### Multi-variate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data,palette=\"Set2\", diag_kind=\"kde\", height=2.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation=data.corr()\ncorrelation.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()>0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()<-0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data.drop(['Severity'],axis=1)\ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=20):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Absolute Correlations\")\nprint(get_top_abs_correlations(df, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### These pairs of independent attibutes have good correlation"},{"metadata":{},"cell_type":"markdown","source":"#### Handle Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataNumericals = pd.DataFrame(data, columns =data.columns[data.dtypes == 'float64']) \ndataNumericals.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Applying z-score to scale the data and standardize the data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataNumericals=dataNumericals.apply(zscore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataNumericals.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Removing all records with z-score greater and lesser than 3 and -3 respectivley as the values are outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"floats = dataNumericals.columns[dataNumericals.dtypes == 'float64']\nfor columns in floats:\n    indexNames_larger = dataNumericals[dataNumericals[columns]>3].index\n    indexNames_lesser = dataNumericals[dataNumericals[columns]<-3].index\n    # Delete these row indexes from dataFrame\n    dataNumericals.drop(indexNames_larger , inplace=True)\n    dataNumericals.drop(indexNames_lesser , inplace=True)\n    data.drop(indexNames_larger , inplace=True)\n    data.drop(indexNames_lesser , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataNumericals.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 493 records were removed as they were considered outliers"},{"metadata":{},"cell_type":"markdown","source":"#### Merging the scaled columns back to the original dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(data.columns[data.dtypes == 'float64'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in dataNumericals.columns:\n    data[column]=dataNumericals[column]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Label Encoding the Target Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Severity'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder=LabelEncoder()\ndata['Severity']=encoder.fit_transform(data['Severity'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Total_Safety_Complaints'] = np.power(2, data['Total_Safety_Complaints'])\ndata['Days_Since_Inspection'] = np.power(2, data['Days_Since_Inspection'])\ndata['Safety_Score'] = np.power(2, data['Safety_Score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Splitting X-independent attributes and Y-dependent attributes and keeping the test set seperate\n#### Creating multiple cross-validation to reduce overfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.drop(['Severity'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=data['Severity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain_val,X_test,ytrain_val,Y_test=train_test_split(X,Y,test_size=0.2,random_state=22)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=10,random_state=2,shuffle=True)\nkf.get_n_splits(Xtrain_val)\nprint(kf)\n\n\nfor train_index, val_index in kf.split(Xtrain_val):\n    print(\"TRAIN:\", train_index, \"VALIDATION:\", val_index)\n    X_train, X_val = Xtrain_val.iloc[train_index], Xtrain_val.iloc[val_index]\n    y_train, y_val = ytrain_val.iloc[train_index], ytrain_val.iloc[val_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Building- Gradient Boosting classifier is used along with RandomSearch cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pipeline\npipe_GBR = Pipeline([('GBR', GradientBoostingClassifier())]) \n\n#Parameter-grid\nparam_grid = {'GBR__n_estimators': [50,100,150],'GBR__learning_rate':[0.1,0.2,0.5]} \n \n#Using RandomSearchCV\nRandom_GBR = RandomizedSearchCV( pipe_GBR , param_distributions=param_grid, cv= 5, n_iter=3) \n\n#Fitting the data in the model\nRandom_GBR.fit(X_train, y_train) \n\nprint(\" Best cross-validation score obtained is: {:.2f}\". format( Random_GBR.best_score_)) \nprint(\" Best parameters as part of Gridsearch is: \", Random_GBR.best_params_) \nprint(\" Train set score obtained is: {:.2f}\". format( Random_GBR.score( X_train, y_train)))\nprint(\" Validation set score obtained is: {:.2f}\". format( Random_GBR.score( X_val, y_val)))\nprint(\" Test set score obtained is: {:.2f}\". format( Random_GBR.score( X_test, Y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=Random_GBR.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score=metrics.accuracy_score(Y_test,y_pred)\npercision_score=metrics.precision_score(Y_test,y_pred,average='macro')\nrecall_score=metrics.recall_score(Y_test,y_pred,average='macro')\nf1_score=metrics.f1_score(Y_test,y_pred,average='macro')\nprint(\"The Accuracy of this model is {0:.2f}%\".format(accuracy_score*100))\nprint(\"The Percision of this model is {0:.2f}%\".format(percision_score*100))\nprint(\"The Recall score of this model is {0:.2f}%\".format(recall_score*100))\nprint(\"The f1 score of this model is {0:.2f}%\".format(f1_score*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Random_GBR.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_report=metrics.classification_report(Y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Building-XG Boosting classifier is used along with RandomSearch cross validation- Final Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pipeline\npipe_XGB = Pipeline([('XGB', XGBClassifier())]) \n\n#Parameter-grid\nparam_grid = {'XGB__learning_rate':[0.1,0.2,0.3],'XGB__max_depth' :[10,50,100], 'XGB__gamma':[0.1,0.3,0.5]} \n \n#Using RandomSearchCV\nRandom_XGB = RandomizedSearchCV( pipe_XGB , param_distributions=param_grid, cv= 5, n_iter=3) \n#Fitting the data in the model\nRandom_XGB.fit(X_train, y_train)\n\nprint(\" Best cross-validation score obtained is: {:.2f}\". format( Random_XGB.best_score_)) \nprint(\" Best parameters as part of Gridsearch is: \", Random_XGB.best_params_) \nprint(\" Train set score obtained is: {:.2f}\". format( Random_XGB.score( X_train, y_train)))\nprint(\" Validation set score obtained is: {:.2f}\". format( Random_XGB.score( X_val, y_val)))\nprint(\" Test set score obtained is: {:.2f}\". format( Random_XGB.score( X_test, Y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=Random_XGB.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test Evaluation Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score=metrics.accuracy_score(Y_test,y_pred)\npercision_score=metrics.precision_score(Y_test,y_pred,average='macro')\nrecall_score=metrics.recall_score(Y_test,y_pred,average='macro')\nf1_score=metrics.f1_score(Y_test,y_pred,average='macro')\nprint(\"The Accuracy of this model is {0:.2f}%\".format(accuracy_score*100))\nprint(\"The Percision of this model is {0:.2f}%\".format(percision_score*100))\nprint(\"The Recall score of this model is {0:.2f}%\".format(recall_score*100))\nprint(\"The f1 score of this model is {0:.2f}%\".format(f1_score*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Random_XGB.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_report=metrics.classification_report(Y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(Y_test,y_pred,figsize=(12,12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting the Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"testData=pd.read_csv(\"/kaggle/input/airplane-accidents-severity-dataset/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Pre-processing the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"testData.drop(['Accident_ID'],axis=1,inplace=True)\ntestData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testDataNumericals = pd.DataFrame(testData, columns =testData.columns[testData.dtypes == 'float64']) \ntestDataNumericals.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testDataNumericals=testDataNumericals.apply(zscore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData.drop(testData.columns[testData.dtypes == 'float64'],axis=1,inplace=True)\ntestData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in testDataNumericals.columns:\n    testData[column]=testDataNumericals[column]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData['Total_Safety_Complaints'] = np.power(2, testData['Total_Safety_Complaints'])\ntestData['Days_Since_Inspection'] = np.power(2, testData['Days_Since_Inspection'])\ntestData['Safety_Score'] = np.power(2, testData['Safety_Score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Predictions using Xtreme Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"testPredictions=Random_XGB.predict(testData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData['Severity']=encoder.inverse_transform(testPredictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalData=pd.read_csv(\"/kaggle/input/airplane-accidents-severity-dataset/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalData['Severity']=testData['Severity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalData.to_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}