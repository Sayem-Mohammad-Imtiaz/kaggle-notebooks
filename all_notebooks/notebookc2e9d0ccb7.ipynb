{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# from plotly import tools\n# import plotly.plotly as py\n# from plotly.offline import init_notebook_mode, iplot\n# init_notebook_mode(connected=True)\n# import plotly.graph_objs as go\n# import gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import os\n#print(os.listdir(\"../input\"))\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime, pytz\n#define a conversion function for the native timestamps in the csv file\ndef dateparse (time_in_secs):    \n    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n\n\ndata = pd.read_csv('/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv', parse_dates=[0], date_parser=dateparse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First thing is to fix the data for bars/candles where there are no trades. \n# Volume/trades are a single event so fill na's with zeroes for relevant fields...\ndata['Volume_(BTC)'].fillna(value=0, inplace=True)\ndata['Volume_(Currency)'].fillna(value=0, inplace=True)\ndata['Weighted_Price'].fillna(value=0, inplace=True)\n\n# next we need to fix the OHLC (open high low close) data which is a continuous timeseries so\n# lets fill forwards those values...\ndata['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create valid date range\nstart = datetime.datetime(2017, 1, 1, 0, 0, 0, 0, pytz.UTC)\nend = datetime.datetime(2020, 9, 14, 0, 0, 0, 0, pytz.UTC)\n\n# find rows between start and end time and find the first row (00:00 monday morning)\nweekly_rows = data[(data[\"Timestamp\"] >= start) & (data[\"Timestamp\"] <= end)].groupby([pd.Grouper(key=\"Timestamp\", freq=\"W-MON\")]).first().reset_index()\nweekly_rows.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly_rows.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(weekly_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install chart-studio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from chart_studio import tools\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We use Plotly to create the plots https://plot.ly/python/\ntrace1 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Open'].astype(float),\n    mode = 'lines',\n    name = 'Open'\n)\n\ntrace2 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Close'].astype(float),\n    mode = 'lines',\n    name = 'Close'\n)\ntrace3 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Weighted_Price'].astype(float),\n    mode = 'lines',\n    name = 'Weighted Avg'\n)\n\nlayout = dict(\n    title='Historical Bitcoin Prices (2015-2018) with the Slider ',\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                #change the count to desired amount of months.\n                dict(count=1,\n                     label='1m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=6,\n                     label='6m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=12,\n                     label='1y',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=36,\n                     label='3y',\n                     step='month',\n                     stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(\n            visible = True\n        ),\n        type='date'\n    )\n)\n\ndata = [trace1,trace2, trace3]\nfig = dict(data=data, layout=layout)\niplot(fig, filename = \"Time Series with Rangeslider\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Volume_(Currency)'].astype(float),\n    mode = 'lines',\n    name = 'Bitcoin Price (Open)'\n)\n\nlayout = dict(\n    title='Historical Bitcoin Volume (USD) (2015-2018) with the slider',\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1,\n                     label='1m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=6,\n                     label='6m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=12,\n                     label='1y',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=36,\n                     label='3y',\n                     step='month',\n                     stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(\n            visible = True\n        ),\n        type='date'\n    )\n)\n\ndata = [trace1]\nfig = dict(data=data, layout=layout)\niplot(fig, filename = \"Time Series with Rangeslider\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#BTC Volume vs USD visualization\ntrace = go.Scattergl(\n    y = weekly_rows['Volume_(BTC)'].astype(float),\n    x = weekly_rows['Weighted_Price'].astype(float),\n    mode = 'markers',\n    marker = dict(\n        color = '#FFBAD2',\n        line = dict(width = 1)\n    )\n)\nlayout = go.Layout(\n    title='BTC Volume v/s USD',\n    xaxis=dict(\n        title='Weighted Price',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='Volume BTC',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )))\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='compare_webgl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the dataset \ndata = pd.read_csv('/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv',parse_dates=[0], date_parser=dateparse) \ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data\nsplit_date = '25-Jun-2020'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data preprocess\ntraining_set = data_train.values\ntraining_set = np.reshape(training_set, (len(training_set), 1))\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\ntraining_set = sc.fit_transform(training_set)\nX_train = training_set[0:len(training_set)-1]\ny_train = training_set[1:len(training_set)]\nX_train = np.reshape(X_train, (len(X_train), 1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n_ = data.plot(style='', figsize=(15,5), color=color_pal[0], title='BTC Weighted_Price Price (USD) by Hours')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = data_test \\\n    .rename(columns={'Weighted_Price': 'Test Set'}) \\\n    .join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer') \\\n    .plot(figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours', style='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Importing the Keras libraries and packages\n# from keras.models import Sequential\n# from keras.layers import Dense\n# from keras.layers import LSTM\n# from keras.layers import Dropout\n# from keras.layers import Activation\n\n\n# model = Sequential()\n# model.add(LSTM(128,activation=\"sigmoid\",input_shape=(1,1)))\n# model.add(Dropout(0.2))\n# model.add(Dense(1))\n# model.compile(loss='mean_squared_error', optimizer='adam')\n# model.fit(X_train, y_train, epochs=100, batch_size=50, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_test['Weighted_Price'] = predicted_BTC_price\n# data_all = pd.concat([data_test, data_train], sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Plot the forecast with the actuals\n# f, ax = plt.subplots(1)\n# f.set_figheight(5)\n# f.set_figwidth(15)\n# _ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n#                                               style=['-','.'])\n# ax.set_xbound(lower='08-01-2018', upper='09-01-2018')\n# ax.set_ylim(0, 10000)\n# plot = plt.suptitle('August 2018 Forecast vs Actuals')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Plot the forecast with the actuals\n# f, ax = plt.subplots(1)\n# f.set_figheight(5)\n# f.set_figwidth(15)\n# _ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n#                                               style=['-','.'])\n# ax.set_xbound(lower='08-01-2018', upper='08-08-2018')\n# ax.set_ylim(0, 10000)\n# plot = plt.suptitle('First Week of August 2018 Forecast vs Actuals')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #calculate MSE and MAE\n# from sklearn.metrics import mean_squared_error, mean_absolute_error\n# mean_squared_error(y_true=data_test['Weighted_Price'],\n#                    y_pred=data_test['Weighted_Price_Prediction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean_absolute_error(y_true=data_test['Weighted_Price'],\n#                    y_pred=data_test['Weighted_Price_Prediction'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time Series forecasting using ARIMA\n\nARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data. This acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n\nAR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\nI: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\nMA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\nARIMA is one of the mostly used techniques for Time Series analysis. In Python, ARIMA based forecasting models can be created either using AutoARIMA(Pyramid ARIMA) or StatsModel . Here we will be using StatsModel as Kaggle do not support Pyramid ARIMA till now."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nimport statsmodels.api as sm\nimport warnings\nfrom itertools import product","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv',parse_dates=[0], date_parser=dateparse) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)\ndata['Volume_(BTC)'].fillna(method='ffill', inplace=True)\ndata['Volume_(Currency)'].fillna(method='ffill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[20,8])\nplt.title('BTC Weighted_Price Price (USD) by Hours')\nplt.plot(data.Weighted_Price, '-', label='By Hours')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='M')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[20,8])\nplt.title('BTC Weighted_Price Price (USD) by Months')\nplt.plot(data.Weighted_Price, '-', label='By Months')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decomposition = sm.tsa.seasonal_decompose(data.Weighted_Price)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nfig = plt.figure(figsize=(20,8))\n\nplt.subplot(411)\nplt.plot(data.Weighted_Price, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\n\nfig.suptitle('Decomposition of Prices Data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(data.Weighted_Price)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom matplotlib import pyplot\npyplot.figure(figsize=(20,8))\npyplot.subplot(211)\nplot_acf(data.Weighted_Price, ax=pyplot.gca(),lags=40)\npyplot.subplot(212)\nplot_pacf(data.Weighted_Price, ax=pyplot.gca(), lags=50)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initial approximation of parameters\nQs = range(0, 2)\nqs = range(0, 3)\nPs = range(0, 3)\nps = range(0, 3)\nD=1\nd=1\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)\n\n# Model Selection\nresults = []\nbest_aic = float(\"inf\")\nwarnings.filterwarnings('ignore')\nfor param in parameters_list:\n    try:\n        model=sm.tsa.statespace.SARIMAX(data.Weighted_Price, order=(param[0], d, param[1]), \n                                        seasonal_order=(param[2], D, param[3], 12),enforce_stationarity=False,\n                                            enforce_invertibility=False).fit(disp=-1)\n    except ValueError:\n        #print('wrong parameters:', param)\n        continue\n    aic = model.aic\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results.append([param, model.aic])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,8))\nbest_model.resid.plot()\nfig.suptitle('Residual Plot of the Best Model')\nprint(\"Dickey–Fuller test:: p=%f\" % sm.tsa.stattools.adfuller(best_model.resid)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_month2 = data[['Weighted_Price']]\nfuture = pd.DataFrame()\ndf_month2 = pd.concat([df_month2, future])\ndf_month2['forecast'] = best_model.predict(start=0, end=200)\nplt.figure(figsize=(15,7))\ndf_month2.Weighted_Price.plot()\ndf_month2.forecast.plot(color='r', ls='--', label='Predicted Weighted_Price')\nplt.legend()\nplt.title('Bitcoin Prices (USD) Predicted vs Actuals, by months')\nplt.ylabel('mean USD')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install dtale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import dtale\nimport plotly.express as px \nimport dtale.app as dtale_app\n\ndtale_app.USE_NGROK = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = dtale.show(data, ignore_duplicate=True)\nd.main_url()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime, pytz\n#define a conversion function for the native timestamps in the csv file\ndef dateparse (time_in_secs):    \n    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n\n\ndata = pd.read_csv('/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv', parse_dates=[0], date_parser=dateparse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First thing is to fix the data for bars/candles where there are no trades. \n# Volume/trades are a single event so fill na's with zeroes for relevant fields...\ndata['Volume_(BTC)'].fillna(value=0, inplace=True)\ndata['Volume_(Currency)'].fillna(value=0, inplace=True)\ndata['Weighted_Price'].fillna(value=0, inplace=True)\n\n# next we need to fix the OHLC (open high low close) data which is a continuous timeseries so\n# lets fill forwards those values...\ndata['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create valid date range\nstart = datetime.datetime(2012, 1, 1, 0, 0, 0, 0, pytz.UTC)\nend = datetime.datetime(2020, 11, 14, 0, 0, 0, 0, pytz.UTC)\n\n# find rows between start and end time and find the first row (00:00 monday morning)\nweekly_rows = data[(data[\"Timestamp\"] >= start) & (data[\"Timestamp\"] <= end)].groupby([pd.Grouper(key=\"Timestamp\", freq=\"M\")]).first().reset_index()\nweekly_rows.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly_rows.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del weekly_rows['Open']\ndel weekly_rows['High']\ndel weekly_rows['Low']\ndel weekly_rows['Close']\ndel weekly_rows['Volume_(BTC)']\ndel weekly_rows['Volume_(Currency)']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly_rows = weekly_rows.set_index(\"Timestamp\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simple Moving Average and Exponential Weighted Moving Average"},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly_rows['SMA 12'] = weekly_rows['Weighted_Price'].rolling(window=12).mean()\nweekly_rows['EWMA 12'] = weekly_rows['Weighted_Price'].ewm(span=12,adjust=False).mean()\nweekly_rows.plot(figsize=(15,8), lw=2, grid=True, legend=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.holtwinters import ExponentialSmoothing\n\nweekly_rows['DES 12'] = ExponentialSmoothing(weekly_rows['Weighted_Price'], trend='add', seasonal_periods=12).fit().fittedvalues.shift(-1)\nweekly_rows.plot(figsize=(15,8), lw=2, grid=True, legend=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly_rows['TES 12'] = ExponentialSmoothing(weekly_rows['Weighted_Price'],trend='add',seasonal='add',seasonal_periods=12).fit().fittedvalues\nweekly_rows.plot(figsize=(15,8), lw=2, grid=True, legend=True);\n# weekly_rows.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rolmean = weekly_rows.rolling(window=12).mean()\nprint(rolmean.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std = weekly_rows.rolling(window=12).std()\nprint(std.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot rolling statistics\noriginal_data = plt.plot(weekly_rows, color='blue',label='original data')\nmean = plt.plot(rolmean,color ='red',label='rolling mean')\nstd = plt.plot(std,color ='black',label='standard deviation')\nplt.title(\"mean, std & original data\")\nplt.xlabel(\"date\")\nplt.ylabel(\"value\")\nplt.legend()\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10,6\nplt.show(block =False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_logscale = np.log(weekly_rows)\n# logarithmic function is used to scale the data to a certain extent.\nplt.plot(data_logscale)\nplt.title(\"Log scale\")\nplt.xlabel(\"date\")\nplt.ylabel(\"value\")\nplt.legend()\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10,6\nplt.show(block =False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}