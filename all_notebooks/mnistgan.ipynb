{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.datasets import mnist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_shape = (28, 28, 1)\ntarget_size = (28, 28)\n\nepochs = 100\nbatch_size = 32\nlatent_variables = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to load the train_data\n\ndef get_data():\n    (X, _), (_, _) = mnist.load_data()\n    X = X.astype(np.float32)/255.\n    X = np.expand_dims(X, -1)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to show a data sample. \ndef show_data_sample(imgs, rows):\n    \n    fig, ax = plt.subplots(rows, rows, constrained_layout = True, figsize = (10, 10))\n    for i in range(rows):\n        for j in range(rows):\n            ax[i][j].imshow(imgs[j + 5*i,:,:,0], cmap = 'binary')\n            ax[i][j].axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generator Model\n\ndef generator_module(shape = latent_variables):\n    \n    model = models.Sequential()\n    model.add(layers.Dense(7*7*128, input_shape = [latent_variables]))\n    model.add(layers.LeakyReLU(alpha = 0.2))\n    \n    #Reshaping Layer. This is consequently upsampled to the target shape requirement\n    model.add(layers.Reshape((7, 7, 128)))\n    \n    model.add(layers.Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = 'same'))\n    model.add(layers.LeakyReLU(alpha = 0.2))\n    \n    model.add(layers.Conv2DTranspose(32, (5, 5), strides = (2, 2), padding = 'same'))\n    model.add(layers.LeakyReLU(alpha = 0.2))\n    \n    model.add(layers.Conv2DTranspose(1, (5, 5), strides = (1, 1), padding = 'same'))\n    model.add(layers.Activation('tanh'))\n    \n    #Tanh and Leaky Relu activations help prevent Mode Collapse\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Discriminator Model\n\ndef discriminator_module(shape = target_shape):\n    \n    model = models.Sequential()\n    \n    #Downsampling is done using Strided Convolutions, so that \n    #the model learns its own spatial downsampling\n    \n    model.add(layers.Conv2D(64, (3,3), strides = (2, 2), padding = 'same', input_shape = shape))\n    model.add(layers.LeakyReLU(alpha = 0.2))\n    \n    model.add(layers.Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'))\n    model.add(layers.LeakyReLU(alpha = 0.2))\n    \n    model.add(layers.Conv2D(256, (3, 3), strides = (2, 2), padding = 'same'))\n    model.add(layers.LeakyReLU(alpha = 0.2))\n    \n    #Final Dense Layers for classification\n    model.add(layers.Flatten())\n    model.add(layers.Dropout(0.4))                  #Dropout for regularization\n    model.add(layers.Dense(1, activation = 'sigmoid'))\n    \n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generates the required number random noise vectors of a fixed length\ndef get_random_space(num_features, num_samples):\n    \n    random_space = np.random.randn(num_features*num_samples)\n    random_space = random_space.reshape((num_samples, num_features))\n    return random_space","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Returns the required number of images from random index points from the source dataset\ndef get_real_images(source_dataset, num_samples):\n    \n    random_idx = np.random.randint(0, source_dataset.shape[0], num_samples)\n    real_data = source_dataset[random_idx]\n    return real_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Returns the required number of generated images \ndef get_fake_images(gen, num_features, num_samples):\n    \n    gen_input = get_random_space(num_features, num_samples)        #Random Noise vectors for generator\n    fake_data = gen.predict(gen_input)            #Generated Images\n    return fake_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to plot and save result after each epoch \ndef save_output(gen, epoch, seed):\n    imgs = gen.predict(seed)\n    \n    fig, ax = plt.subplots(5, 5, constrained_layout = True, figsize = (10, 10))\n    for i in range(5):\n        for j in range(5):\n            ax[i][j].imshow(imgs[j + 5*i,:,:,0], cmap = 'binary')\n            ax[i][j].axis('off')\n    plt.savefig('GenImg{:04d}'.format(epoch))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to train the DCGAN\ndef train_dcgan(gan, data, num_features = latent_variables, batch_size = batch_size, epochs = epochs):\n    \n    #Generator and Discriminator are attatched sequentially in the GAN, they can be extracted as follows\n    gen, disc = gan.layers\n    num_batches = int(data.shape[0]/batch_size)\n    \n    for epoch in range(epochs):\n        \n        for i in tqdm(range(num_batches), ascii = True, desc = 'Epoch {}/{}'.format(epoch + 1, epochs), ncols = 100):\n            \n            #Initially, the discriminator is frozen, so we unfreeze it for training\n            disc.trainable = True\n            \n            #Real Data samples are generated using the defined functions\n            #Labels are assigned as 1 for real images \n            X_real = get_real_images(data, batch_size)\n            y_real = np.ones((batch_size, 1))\n            \n            disc_loss_real, _ = disc.train_on_batch(X_real, y_real)\n            \n            #Fake Data samples are generated using the defined functions\n            #Labels are assigned as 0 for fake images\n            X_fake = get_fake_images(gen, num_features, batch_size)\n            y_fake = np.zeros((batch_size, 1))\n            \n            disc_loss_fake, _ = disc.train_on_batch(X_fake, y_fake)\n            \n            #To Train the generator, we freeze the discriminator and train the whole GAN\n            disc.trainable = False\n            \n            #Random noise is given as input to GAN\n            #As the Generator works opposite to the Discriminator, we invert the labels\n            #Fake samples are labeled as 1\n            X_gan = get_random_space(num_features, batch_size)\n            y_gan = np.ones((batch_size, 1))\n            \n            #GAN is trained on the created batch\n            gan_loss, gan_acc = gan.train_on_batch(X_gan, y_gan)\n            \n        seed = get_random_space(num_features, batch_size)\n        save_output(gen, epoch + 1, seed)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = get_data()\nshow_data_sample(data[:25], 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the GAN architecture\ngen = generator_module()\n\ndisc = discriminator_module()\ndisc.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\ndisc.trainable = False\n\ngan = models.Sequential([gen, disc])\ngan.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the GAN\ngan_trained = train_dcgan(gan, data, num_features = latent_variables, batch_size = batch_size, epochs = epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}