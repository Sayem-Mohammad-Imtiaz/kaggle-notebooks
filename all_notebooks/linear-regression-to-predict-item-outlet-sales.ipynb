{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BigMart Sales Prediction "},{"metadata":{},"cell_type":"markdown","source":"\n\n**BigMart Sales Prediction practice problem**\n\nWe have train (8523) and test (5681) data set, train data set has both input and output variable(s). We need to predict the sales for test data set.\n\n    1. Item_Identifier: Unique product ID\n\n    2. Item_Weight: Weight of product\n\n    3. Item_Fat_Content: Whether the product is low fat or not\n\n    4. Item_Visibility: The % of total display area of all products in a store allocated to the particular product\n\n    5. Item_Type: The category to which the product belongs\n\n    6. Item_MRP: Maximum Retail Price (list price) of the product\n\n    7. Outlet_Identifier: Unique store ID\n\n    8. Outlet_Establishment_Year: The year in which store was established\n\n    9. Outlet_Size: The size of the store in terms of ground area covered\n\n    10.Outlet_Location_Type: The type of city in which the store is located\n\n    11.Outlet_Type: Whether the outlet is just a grocery store or some sort of supermarket\n\n    12.Item_Outlet_Sales: Sales of the product in the particulat store. This is the outcome variable to be predicted.\n\n"},{"metadata":{},"cell_type":"markdown","source":"This is my first Notebook, I don't know whether its good or bad, but by the way all feedbacks/suggestions are welcome.  "},{"metadata":{},"cell_type":"markdown","source":"So, let's start with importing essential libraries,"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom sklearn import preprocessing  \nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom math import sqrt ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is because i am going to use Linear regression to predict 'Item_Outlet_Sales'"},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = linear_model.LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/bigmart-sales-data/Train.csv') ########### Reading training Data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/bigmart-sales-data/Test.csv')  ########### Reading testing Data ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merging training and testing data as one big dataset because it saves some trouble of making same changes in both 'Train' and 'Test' separetly.\nfor example : if i am imputing missing values in 'Train' by 'Most Frequent Value or Mode' then i will be using Mode in 'Test' as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['source'] = 'train'\ntest['source'] = 'test'\ntest['Item_Outlet_Sales'] = 0\ndata = pd.concat([train, test], sort = False)\nprint(train.shape, test.shape, data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"General Info : Datset consist of 7 categorical features, 5 numerical feature and 1 addition feature we just added to keep track of 'Train' and 'Test' data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"checking if there are missing values in our dataset, "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since 'Item_Weight' is a continues variable , I am using mean to fill missing values . Ofcourse we've got some other options too, such as median, mode etc. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Item_Weight']=data['Item_Weight'].fillna(data['Item_Weight'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am done with numbers, Let's see what graphs have to offer.\nclearly we have 3 'Outlet_Location_Type' among them Tier3 has more outlets but how does\nit add any value in Sales prediction. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.Outlet_Location_Type)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"similarly, 'Item_Weight' has minimal effect on 'Item_Otlet_Sales' "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data['Item_Weight'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(data.Outlet_Type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nsns.countplot(data.Outlet_Identifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nsns.countplot(data.Item_Type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Outlet_Size'] = data['Outlet_Size'].fillna(data['Outlet_Size'].value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Outlet_Size',y='Item_Outlet_Sales',data = data)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Item_Outlet_Sales',y='Item_Fat_Content',data = data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.boxplot(y='Item_Outlet_Sales',x='Outlet_Type',hue = 'Outlet_Location_Type',data = data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Item_Outlet_Sales'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['Item_Outlet_Sales'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"skewness :\",data['Item_Outlet_Sales'].skew())\nprint(\"kurtosis :\",data['Item_Outlet_Sales'].kurt())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Unique items in data set\ndata.apply(lambda x : len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nenc = OneHotEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = ['Item_Identifier','Item_Fat_Content','Item_Type','Outlet_Identifier','Outlet_Establishment_Year']\none = ['Outlet_Size','Outlet_Location_Type','Outlet_Type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in label:\n    data[col]=le.fit_transform(data[col]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in one:\n    data[col]=le.fit_transform(data[col]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(data):\n    grp = data.groupby('source')\n    test = grp.get_group('test')\n    train = grp.get_group('train')\n    train = train.drop('source',axis=1)\n    test = test.drop('source',axis=1)\n    Y = train.Item_Outlet_Sales\n    X = train.drop('Item_Outlet_Sales',axis=1)\n    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state = 42)\n    model = lm.fit(x_train, y_train)\n    predictions = lm.predict(x_test)\n    RMSE = sqrt((( y_test-predictions)**2).mean())\n    return RMSE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSE with raw data :',model(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr(method='pearson')##### Linear correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmv = ['Item_Identifier','Item_Weight','Item_Fat_Content','Item_Type','Outlet_Establishment_Year']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(rmv, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSE after reducing some features :',model(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_outlier(data,column):\n    Q3 = data[column].quantile(.75)\n    Q1 = data[column].quantile(.25)\n    IQR = Q3-Q1\n    data = data[~((data[column] < (Q1 - 1.5 * IQR)) |(data[column] > (Q3 + 1.5 * IQR)))]\n    return data\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_o =remove_outlier(data,'Outlet_Size')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_o","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSE after removing outliers :',model(data_o))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}