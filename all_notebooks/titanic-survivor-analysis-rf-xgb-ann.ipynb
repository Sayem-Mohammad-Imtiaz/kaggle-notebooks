{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Import libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas import Series, DataFrame\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import tree\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.preprocessing import LabelEncoder\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> import dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/titanic-machine-learning-from-disaster/train.csv')\ntest_df = pd.read_csv('../input/titanic-machine-learning-from-disaster/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**1.1 Overview**\n* PassengerId is the unique id of the row and it doesn't have any effect on target\n* Survived is the target variable we are trying to predict (0 or 1):\n    * 1 = Survived\n    * 0 = Not Survived\n* Pclass (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has 3 unique values (1, 2 or 3):\n    * 1 = Upper Class\n    * 2 = Middle Class\n    * 3 = Lower Class\n* Name, Sex and Age are self-explanatory\n* SibSp is the total number of the passengers' siblings and spouse\n* Parch is the total number of the passengers' parents and children\n* Ticket is the ticket number of the passenger\n* Fare is the passenger fare\n* Cabin is the cabin number of the passenger\n* Embarked is port of embarkation and it is a categorical feature which has 3 unique values (C, Q or S):\n    * C = Cherbourg\n    * Q = Queenstown\n    * S = Southampton","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info() # we only have 204 cabin info in the training set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"The training-set has 891 records and 11 features + the target variable (survived). 2 of the features are floats (Age, Fare), 5 are integers and 5 are objects. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"From the table above, we can note a few things. First of all, that we need to convert a lot of features into numeric ones later on, so that the machine learning algorithms can process them. Furthermore, we can see that the features have widely different ranges, that we will need to convert into roughly the same scale. We can also spot some more features, that contain missing values (NaN = not a number), that wee need to deal with.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info() #we only have 91 cabine info in the test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above we can see that 38% out of the training-set survived the Titanic. We can also see that the passenger ages range from 0.4 to 80. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\nApril 10, 1912 - The Titanic sets sail on its maiden voyage from Southampton, England, to New York. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Full dataset is needed for imputing missing values & also for pruning outliers\n\n#whole_df = pd.concat([train_df, test_df], axis=0, ignore_index=True, sort=True) #If True, do not use the index values along the concatenation axis.\n\nwhole_df = train_df.append(test_df,sort=False)\nwhole_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking number of columns of each data type for general EDA\nwhole_df.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.2 Numerical Variables**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(whole_df.select_dtypes(['int64','float64']).columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*1) Age*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Age'].hist(bins=70)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = sns.FacetGrid(whole_df, hue = 'Sex', aspect = 4)\nfig.map(sns.kdeplot, 'Age', shade = True)\n\noldest = train_df['Age'].max()\nfig.set(xlim = (0, oldest))\nfig.add_legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most passengers are within the age range between 15 and 40ish.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Age'].mean()  #get the mean age of all passengers, around 30yr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = sns.FacetGrid(whole_df, hue = 'Pclass', aspect = 4)\nfig.map(sns.kdeplot, 'Age', shade = True)\n\noldest = train_df['Age'].max()\nfig.set(xlim = (0, oldest))\nfig.add_legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"class 1 shows a normal distribution. However, class 2 and class 3 are skewed towards younger age.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We look at Age column and set Intevals on the ages and the map them to their categories as\n# (Children, Teen, Adult, Old)\ninterval = (0,2,4,10,19,35,60,100)\ncategories = ['Infant','Toddler','Kid','Teen','Young Adult','Adult','Senior']\nwhole_df['Age_cats'] = pd.cut(whole_df.Age, interval, labels = categories)\n\nax = sns.countplot(x = 'Age_cats',  data = whole_df, hue = 'Survived', palette = 'Set1')\n\nax.set(xlabel='Age Categorical', ylabel='Total',\n       title=\"Age Categorical Survival Distribution\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More infant and toddler survived than died. In kid group, number of kids died is almost the same as they survived. In the group of young adult and adult, far more people died than survived.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*2) Fare*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(whole_df.Fare)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.Fare.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fare of some tickets is ZERO. It is worth exploring further","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df.Fare == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks strange that so many tickets were sold at zero. It could be true or it could be the erros in the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use a pandas plotting method to plot the column 'Fare' for each value of 'Survived' on the same plot.\ntrain_df.groupby('Survived').Fare.hist(alpha=0.6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.swarmplot(x='Survived', y='Fare', data=train_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like fare is correlated with survival aboard the Titanic.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the DataFrame method .describe() to check out summary statistics of 'Fare' as a function of survival\ntrain_df.groupby('Survived').Fare.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Embarked feature has only 2 missing values, which can easily be filled. It will be much more tricky, to deal with the ‘Age’ feature, which has 177 missing values. The ‘Cabin’ feature needs further investigation, but it looks like that we might want to drop it from the dataset, since 77 % of it are missing.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n*3) PClass indicating the passenger class, totally 3 values*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Pclass', hue = 'Sex',data=whole_df, palette=\"Set2\") #Most of the males were in the 3rd class\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"most passengers were in PClass3.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(1,1, figsize = (12,10))\nax = sns.countplot(x = 'Pclass', data=train_df,hue = 'Survived', palette = 'Set1')\nax.set(title = 'Passenger status (Survived/Died) against Passenger Class', \n       xlabel = 'Passenger Class', ylabel = 'Total')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most victims were from the class 3.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"4) SibSp - Number of Sibling Spouse","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.SibSp.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Totally 891 passengers were travelling alone.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.boxplot(y = whole_df.SibSp, x = whole_df.Age_cats)\nplt.xticks(rotation=90)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.violinplot(y = whole_df.SibSp, x = whole_df.Age_cats,hue='Sex',\n                    data=whole_df, palette=\"Set3\",split=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Infant, toddler and kid tend to on board with their siblings.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*5) Parch - Parent and Child* parch: Number of Parents/Children Aboard*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.boxplot(y = whole_df.Parch, x = whole_df.Age_cats)\nplt.xticks(rotation=90)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.violinplot(y = whole_df.Parch, x = whole_df.Age_cats,hue='Sex',\n                    data=whole_df, palette=\"Set3\",split=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.3) Categorical Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(whole_df.select_dtypes(['object']).columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*1) Cabin*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"deck = whole_df['Cabin'].dropna()\ndeck.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_df = DataFrame(deck)\ncabin_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_df['Cabin'] = cabin_df['Cabin'].astype(str).str[0] \n#change the datatype to str and get the first letter\ncabin_df['Cabin'].unique()  #get all the unique values of column 'Cabin'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_df['Cabin'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is only 1 T in the whole dataset,so it looks like a outliner","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df['Cabin'].str.contains('T') == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_df = cabin_df[cabin_df.Cabin != 'T']\nsns.countplot('Cabin',data = cabin_df,palette = 'summer',order=['A','B','C','D','E','F','G'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Deck']= train_df['Cabin'].dropna().astype(str).str[0] \ntrain_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Deck\", hue=\"Survived\", col=\"Sex\",order=['A','B','C','D','E','F','G'],\n                data=train_df, kind=\"count\",\n                height=5, aspect=1.2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Women from Cabin A,B,D,F all survived. <br>\nAll women from Cabin A, B, D, F survived. <br>\nMore men than women survived in Cabin A.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"2) Sex","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sex\nsns.set(style=\"darkgrid\")\nsns.countplot(x='Sex', data=whole_df, palette=\"Set2\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x = 'Sex', data=train_df,hue = 'Survived', palette = 'Set1')\nax.set(title = 'Passenger status (Survived/Died) against Passenger Class', \n       xlabel = 'Passenger Sex', ylabel = 'Total')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More female than male survived.\nTill now, we can see that men in the 3rd class are likely not to survive in the wreck.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"3) Embarked","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Explore the feature of Embarked\nsns.countplot('Embarked',data = whole_df, hue = 'Pclass', order=['C','Q','S'], palette = 'husl')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Embarked\", hue=\"Survived\", col=\"Pclass\",\n                data=train_df, kind=\"count\",\n                height=5, aspect=1.2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most passengers embarked from Southampton port. <br>\nThose who embarked from Queenstown were all in Pclass3  <br>\nC = Cherbourg; Q = Queenstown; S = Southampton","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"'Name' and 'Ticket' will be analyzed in the next section","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It looks like passengers with the same name also have the same ticket number. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **2. Imputation of Missing Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Fare'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.isna().sum() \n# I am going to drop Cabin and Cabin_cats since they have to many missing data\n# drop Survivor, Child, Age_cats since we don't need them for further analysis\n#Fill in missing data for Age, Embarked and Fare","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1) Fill in missing data for Age column** <br>\nFirst, I am going to get the median age according to passengers' titles and then imputate the median age into the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.Name.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Title'] = whole_df.Name.str.extract(r'([A-Za-z]+)\\.', expand = False)\nwhole_df.Title.value_counts()\n#[a-zA-Z]+: a word consisting of only Latin characters with a length at least one\n#+: something repeating once or more","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df['Name'].astype(str).str.contains('Col\\.') == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df['Name'].astype(str).str.contains('Don\\.') == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df['Name'].astype(str).str.contains('Master') == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Common_Title = ['Mr','Miss','Mrs','Master']\nwhole_df['Title'].replace(['Ms','Mme','Mlle','Dona'],'Miss', inplace = True)\nwhole_df['Title'].replace(['Lady'],'Mrs', inplace = True)\nwhole_df['Title'].replace(['Sir','Rev','Capt','Col','Don','Major'],'Mr', inplace = True)\nwhole_df['Title'][~whole_df.Title.isin(Common_Title)] = 'Others'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am trying to identify the title in the 'Others' category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df['Title'] == 'Others']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among all doctors, only one is female and she was married, I am going to change her title to Mrs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.loc[796,'Title'] ='Mrs'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[(whole_df['Name'].str.contains('Dr\\.') == True) & (whole_df['Title'] == 'Others') ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[(whole_df['Name'].str.contains('Dr\\.') == True) & (whole_df['Title'] == 'Others') ].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.loc[[245, 317, 398, 632, 660, 766, 293],'Title'] ='Mr'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df['Title'] == 'Others']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I looked up from https://www.encyclopedia-titanica.org/, Reuchlin, Jonkheer. John George was married at that time, I am going to change his title to Mr and The Countess of Rothes (Lucy Noël Martha Dyer-Edwards) was also married at that time, I am going to change her title to Mrs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.loc[759,'Title'] ='Mrs'\nwhole_df.loc[822,'Title'] ='Mr'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df = whole_df[:len(train_df)]\n#test_df = whole_df[len(train_df):]\n#train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute mean per group and find index after sorting\nsorted_index = whole_df.groupby('Title')['Age'].mean().sort_values().index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Title', y = 'Age', data = whole_df, order=sorted_index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the median of Age in each title.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"AgeMedian_by_titles = whole_df.groupby('Title')['Age'].median()\nAgeMedian_by_titles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Impute the missing Age values according to the titles.\nfor title in AgeMedian_by_titles.index:\n    whole_df['Age'][(whole_df.Age.isnull()) & (whole_df.Title == title)] = AgeMedian_by_titles[title]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2) Fill in missing data for Fare column** <br>\nThere is one missing value in columns 'Fare' <br>\nWe will imputate the value by PClass or Ticket.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df.Fare.isnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.violinplot(x='Pclass', y = 'Fare', data = whole_df, hue='Sex',\n              palette=\"Set3\",split=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"med_fare = whole_df.groupby(['Pclass', 'Sex']).Fare.median()\n# Filling the missing value in Fare with the median Fare of 3rd class male passenger\nwhole_df['Fare'] = whole_df['Fare'].fillna(med_fare[3][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This male passenger was travelling alone in Pclass3. We can assume that Fare is related to the Sex and Pclass features. Median Fare value of a male with a third class ticket is a logical choice to fill the missing value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df.Fare == 0].sort_values('Ticket')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is high possibility that those ticket with fare of ZERO should not be ZERO. I am going to imputate median value to those tickets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"med_fare = whole_df.groupby(['Pclass', 'Sex']).Fare.median()\nmed_fare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[(whole_df.Fare == 0) & (whole_df.Pclass == 1)].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.loc[[263, 633, 806, 815, 822, 266, 372],'Fare'] = med_fare[1][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[(whole_df.Fare == 0) & (whole_df.Pclass == 2)].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.loc[[277, 413, 466, 481, 674, 732],'Fare'] = med_fare[2][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[(whole_df.Fare == 0) & (whole_df.Pclass == 3)].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.loc[[179, 271, 302, 597],'Fare'] = med_fare[3][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.Fare.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3) Fill in missing data for Embarked column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embarked\n#For the dataset, there are only 2 missing values in the training dataset \nwhole_df[whole_df['Embarked'].isnull()== True]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embarked is a categorical feature and there are only 2 missing values in whole data set. Both of those passengers are female, upper class and they have the same ticket number. This means that they know each other and embarked from the same port together. The mode Embarked value for an upper class female passenger is C (Cherbourg), but this doesn't necessarily mean that they embarked from that port.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"When I googled Stone, Mrs. George Nelson (Martha Evelyn), I found that she embarked from S (Southampton) with her maid Amelie Icard, on this page [Martha Evelyn Stone: Titanic Survivor](https://www.encyclopedia-titanica.org/titanic-survivor/martha-evelyn-stone.html).\n\nMrs Stone boarded the Titanic in Southampton on 10 April 1912 and was travelling in first class with her maid Amelie Icard. She occupied cabin B-28.\n\nMissing values in Embarked are filled with S with this information.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling the missing values in Embarked with S\nwhole_df['Embarked'] = whole_df['Embarked'].fillna('S')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4) Fill in missing data for Cabin column**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The large portion of the Cabin feature is missing and the feature itself can't be ignored completely because some the cabins might have higher survival rates. It turns out to be the first letter of the Cabin values are the decks in which the cabins are located. Those decks were mainly separated for one passenger class, but some of them were used by multiple passenger classes.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\nwhole_df['Deck'] = whole_df['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n\ndf_all_decks = whole_df.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n                                                                        'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()\n\ndef get_pclass_dist(df):\n    \n    # Creating a dictionary for every passenger class count in every deck\n    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n    decks = df.columns.levels[0]   \n    for deck in decks:\n        for pclass in range(1, 4):\n            try:\n                count = df[deck][pclass][0]\n                deck_counts[deck][pclass] = count \n            except KeyError:\n                deck_counts[deck][pclass] = 0\n                \n    df_decks = pd.DataFrame(deck_counts)    \n    deck_percentages = {}\n\n    # Creating a dictionary for every passenger class percentage in every deck\n    for col in df_decks.columns:\n        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n        \n    return deck_counts, deck_percentages\n\ndef display_pclass_dist(percentages):\n    \n    df_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85\n    pclass1 = df_percentages[0]\n    pclass2 = df_percentages[1]\n    pclass3 = df_percentages[2]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n\n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n    \n    plt.show()    \n\nall_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\ndisplay_pclass_dist(all_deck_per)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 100% of A, B and C decks are 1st class passengers\n* Deck D has 87% 1st class and 13% 2nd class passengers\n* Deck E has 83% 1st class, 10% 2nd class and 7% 3rd class passengers\n* Deck F has 62% 2nd class and 38% 3rd class passengers\n* 100% of G deck are 3rd class passengers\n* There is one person on the boat deck in T cabin and he is a 1st class passenger. T cabin passenger has the closest resemblance to A deck passengers so he is grouped with A deck\n* Passengers labeled as M are the missing values in Cabin feature. I don't think it is possible to find those passengers' real Deck so I decided to use M like a deck","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Passenger in the T deck is changed to A\nidx = whole_df[whole_df['Deck'] == 'T'].index\nwhole_df.loc[idx, 'Deck'] = 'A'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deck feature has high-cardinality right now so some of the values are grouped with each other based on their similarities.\n\n* A, B and C decks are labeled as ABC because all of them have only 1st class passengers\n* D and E decks are labeled as DE because both of them have similar passenger class distribution and same survival rate\n* F and G decks are labeled as FG because of the same reason above\n* M deck doesn't need to be grouped with other decks because it is very different from others and has the lowest survival rate.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Deck'] = whole_df['Deck'].replace(['A', 'B', 'C'], 'ABC')\nwhole_df['Deck'] = whole_df['Deck'].replace(['D', 'E'], 'DE')\nwhole_df['Deck'] = whole_df['Deck'].replace(['F', 'G'], 'FG')\n\nwhole_df['Deck'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop Cabin and Cabin_cats\nwhole_df = whole_df.drop(['Cabin','Age_cats'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**1) Family Size**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['FamilySize'] = whole_df.SibSp + whole_df.Parch + 1\nsns.countplot(whole_df.FamilySize)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Family size 1 dominates - most passengers were traveling alone.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In order to understand the relationship between family size and whether those passengers survived or not, the whole_df needs to be split into train_df and test_df","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(whole_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, whole_df['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Survival probability is worst for large families.Survival probability is worst for large families.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**2) Alone - whether the passenger was traveling alone or not**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Alone'] = whole_df.FamilySize.map(lambda x: 1 if x == 1 else 0)\nsns.countplot(whole_df.Alone)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Alone', y='Survived', data=whole_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is observed that travelling alone is less likely to survive (~30% vs ~50%).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Alone', hue='Sex', col= 'Survived',\n                data=whole_df, kind=\"count\",\n                height=5, aspect=1.2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For people who were not traveling alone, males are less likely to survive than females.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**3) Title**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Title', hue='Alone', col= 'Survived',\n                data=whole_df, kind=\"count\",\n                height=5, aspect=1.2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Title', y='Survived', data=whole_df)\nplt.show() #It is obviously that Title Mr. is much less likely to survive compared to others .","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4) Connected Survival**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It is naturally to think that family members would help each other out of the disaster. \nTo find out family groups, apart from surnames of passenges (there may be same surnames but different families), let’s also look at Ticket.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[['Name', 'Ticket']].sort_values('Name').head(20)\n#It appears that passengers with same surnames have the same Ticket names.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df[whole_df['Ticket']== 'LINE']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mr Johan Vilhelm Henrik Törnqvis and his fellow American Line employees (William Cahoone Johnson Jr., August (Alfred) Johnson, Lionel Leonard (Andrew Shannon), Alfred Carver and Thomas Storey) were given third class accommodation aboard ther Titanic to make the trip back to New York (ticket number 370160) where they could resume work. \nTheir ticket number is 370160","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Ticket'] = whole_df['Ticket'].str.replace('LINE', '370160',case = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['Surname'] = whole_df.Name.str.extract(r'([A-Za-z]+),', expand=False)\nwhole_df['Surname']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['TicNum'] = whole_df.Ticket.str.extract(r'([0-9]*$)', expand=False)\nwhole_df['TicNum']\n## *: zero or more (0+), e.g., [0-9]* matches zero or more digits. \n## . (dot): ANY ONE character except newline. Same as [^\\n]\n## \\d, \\D: ANY ONE digit/non-digit character. Digits are [0-9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['SurTix'] = whole_df['Surname'] + whole_df['TicNum']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df['IsFamily'] = whole_df.SurTix.duplicated(keep=False)*1\nsns.countplot(whole_df.IsFamily)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Around 1/3 of the passengers are travelling with families.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(col='IsFamily', x= 'Survived',\n                data=whole_df, kind=\"count\",\n                height=5, aspect=1.2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.sort_values('SurTix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the whole_df to training and test dataset\ntrain_df = whole_df[:len(train_df)] #train_df\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = whole_df[len(train_df):]\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = train_df.select_dtypes(include=[np.number]).corr()\nprint(correlation['Survived'].sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap of correlation of numeric features\nplt.figure(figsize=(25,14))\nplt.title('Correlation Between Numeric Features', size=15)\n\nsns.heatmap(correlation, square=True, vmax=0.8, cmap='coolwarm', linewidths=0.01,annot= True, annot_kws={\"size\": 8})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FamilySize and SibSp are strongly correlated (0.89) <br>\nFamilySize and Parch are strongly correlated (0.78) <br>\nI will drop SibSp and Parch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(['SibSp', 'Parch','FamilySize'], axis=1, inplace = True)\ntest_df.drop(['SibSp', 'Parch','FamilySize'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = train_df.select_dtypes(include=[np.number]).corr()\nplt.figure(figsize=(25,14))\nplt.title('Correlation Between Numeric Features', size=15)\n\nsns.heatmap(correlation, square=True, vmax=0.8, cmap='coolwarm', linewidths=0.01,annot= True, annot_kws={\"size\": 8})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Survived has positive relationship with Fare, IsFamily, and negative relationship with Alone and PClass.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4. Encoding Categorical Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"whole_df.dtypes.value_counts() #there are 9 categorical variables ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(whole_df.select_dtypes(['object']).columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will encode \n* Sex\n* Embarked\n* Title\n* Deck\n* and stop Name, Ticket,TicNum and SurTix\n* Also, I will put Age into different bins and encode those bins","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encode string to numbers for modelling.\n#Sex\ntrain_df['Sex_Code'] = train_df['Sex'].map({'female':1, 'male':0}).astype('int')\ntest_df['Sex_Code'] = test_df['Sex'].map({'female':1, 'male':0}).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embarked\ntrain_df['Embarked_Code'] = train_df['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype('int')\ntest_df['Embarked_Code'] = test_df['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Title\ntrain_df['Title_Code'] = train_df.Title.map({'Mr':0,'Others':1, 'Master':2,'Miss':3, 'Mrs':4}).astype('int')\ntest_df['Title_Code'] = test_df.Title.map({'Mr':0,'Others':1, 'Master':2,'Miss':3, 'Mrs':4}).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deck\ntrain_df['Deck_Code'] = train_df['Deck'].map({'M':0, 'ABC':1, 'DE':2,'FG':3}).astype('int')\ntest_df['Deck_Code'] = test_df['Deck'].map({'M':0, 'ABC':1, 'DE':2,'FG':3}).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age\ninterval = (0,2,4,10,19,35,60,100)\ncategories = ['Infant','Toddler','Kid','Teen','Young Adult','Adult','Senior']\ntrain_df['Age_category'] = pd.cut(train_df.Age, interval, labels = categories)\ntest_df['Age_category'] = pd.cut(test_df.Age, interval, labels = categories)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Age_category'] = train_df['Age_category'].map({'Infant':0,'Toddler':1,'Kid':2,\n                                                         'Teen':3,'Young Adult':4,'Adult':5,'Senior':6}).astype('int')\ntest_df['Age_category'] = test_df['Age_category'].map({'Infant':0,'Toddler':1,'Kid':2,\n                                                         'Teen':3,'Young Adult':4,'Adult':5,'Senior':6}).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the map function\n#def dummies(x,df):\n#    temp = pd.get_dummies(df[x], drop_first = True)\n#    df = pd.concat([df, temp], axis = 1)\n#    df.drop([x], axis = 1, inplace = True)\n#    return df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Feature Scaling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **6. Feature Selection**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop unused columns\nX_train = train_df.drop(['PassengerId', 'Name', 'Sex', 'Age','Ticket','Embarked',\n       'Title', 'Deck','Surname', 'TicNum','SurTix','Survived'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_df.drop(['PassengerId', 'Name', 'Sex', 'Age','Ticket','Embarked',\n       'Title', 'Deck','Surname', 'TicNum','SurTix','Survived'], axis=1)\nX_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Model 1: Random Forest**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=400, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importance\nmodel.fit(X_train,y_train)\nimportance = pd.DataFrame({'feature':X_train.columns, 'importance': np.round(model.feature_importances_,3)})\nimportance = importance.sort_values('importance', ascending=False).set_index('feature')\nimportance.plot(kind='bar', rot=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choose the top 6 important features for modelling (i.e. Fare, Age, Title_Code, Sex_Code and Pclass). Always keep minimal number of features to avoid over-fitting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final = ['Fare', 'Title_Code','Sex_Code','Pclass','Age_category','Deck_Code']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tune Random Forest model parameters\ngrid_param = {\n 'n_estimators': [10, 15, 20, 30,50,100,200,300,400,800],\n 'criterion':['gini', 'entropy'],\n 'min_samples_split': [2, 4, 10, 20],\n 'min_samples_leaf': [1,2,5],\n 'max_features':[\"sqrt\", \"auto\", \"log2\"],\n 'bootstrap': [True, False],\n}\ngd_sr = GridSearchCV(estimator=model,\n param_grid=grid_param,\n scoring='accuracy',\n cv=5,\n n_jobs=-1)\ngd_sr.fit(X_train[final], y_train)\nbest_parameters = gd_sr.best_params_\nprint(best_parameters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"n_estimators = number of trees in the foreset <br>\nmax_features = max number of features considered for splitting a node <br>\nmax_depth = max number of levels in each decision tree <br>\nmin_samples_split = min number of data points placed in a node before the node is split <br>\nmin_samples_leaf = min number of data points allowed in a leaf node <br>\nbootstrap = method for sampling data points (with or without replacement)<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set the model paramters after tunning.\nmodel = RandomForestClassifier(bootstrap=False,criterion= 'gini',  \n                               min_samples_leaf=5, min_samples_split=20,\n                               max_features='sqrt' , n_estimators=800, \n                               random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate the accuracy of prediction using 5-fold cross-validation.\nall_accuracies = cross_val_score(estimator=model, X=X_train[final], y=y_train, cv=10)\nall_accuracies\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy: %.3f stdev: %.2f' % (np.mean(np.abs(all_accuracies)), np.std(all_accuracies)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_df[final]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.fit(X_train[final],y_train)\nprediction = model.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': prediction.astype(int)})\noutput.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Model 2: XGBoost**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate XGB classifier - its hyperparameters are tuned through SkLearn Grid Search below\n\nXGBmodel = XGBClassifier(n_estimators=400, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(XGBmodel, X_train[final], y_train, cv=10, n_jobs=1, scoring='accuracy')\nXGBmodel.fit(X_train[final],y_train)\nprint(scores)\nprint('Accuracy: %.3f stdev: %.2f' % (np.mean(np.abs(scores)), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tune XGB classification model parameters\nxgbcParams = {\n    'max_depth': range (3, 10, 1),\n    'n_estimators': [100,200,300,400,800],\n    'learning_rate': [0.002, 0.006, 0.1, 0.01, 0.05],\n    'reg_lambda':[0,0.10, 0.50, 1],\n    'subsample': [0.3, 0.9],\n    'colsample_bytree': (0.5, 0.9),\n    'min_child_weight': [1, 2, 3, 4],\n}\ngrid_search = GridSearchCV(estimator=XGBmodel,\n    param_grid=xgbcParams,\n    scoring = 'accuracy',\n    n_jobs = 4,\n    cv = 5,\n    verbose=True\n)\ngrid_search.fit(X_train[final], y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_search.best_params_)\nprint(grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set the model paramters after tunning.\nXGBmodel = XGBClassifier(max_depth = 4,\n                       n_estimators=400, \n                       learning_rate=0.1, \n                       reg_lamda= 1, \n                       subsample =0.3 ,\n                       colsample_bytree =0.9 ,\n                       min_child_weight =3 ,\n                       random_state=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate the accuracy of prediction using 5-fold cross-validation.\nall_accuracies = cross_val_score(estimator=XGBmodel, X=X_train[final], y=y_train, cv=10)\nall_accuracies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy: %.3f stdev: %.2f' % (np.mean(np.abs(all_accuracies)), np.std(all_accuracies)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_df[final]\nXGBmodel.fit(X_train[final],y_train)\nprediction = XGBmodel.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': prediction.astype(int)})\noutput.to_csv('my_submission2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Model 3: ANN**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train2 = sc.fit_transform(X_train[final])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test2 = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_classifier(optimizer):\n    classifier = Sequential()\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 6))\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 500, batch_size = 36,optimizer = 'adam')\naccuracies = cross_val_score(estimator=classifier, X=X_train2, y=y_train, cv=10) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = accuracies.mean()\nvariance = accuracies.std()\nprint(mean)\nprint(variance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train2, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = (y_pred > 0.5)\ny_pred = y_pred.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n                          'Survived': y_pred[:,-1]}) \nsubmission = submission.to_csv(\"submission3.csv\", index=False)\nsubmission = pd.read_csv('submission3.csv')\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}