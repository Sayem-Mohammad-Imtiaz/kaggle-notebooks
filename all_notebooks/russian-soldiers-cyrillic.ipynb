{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-08T00:58:24.867129Z","iopub.execute_input":"2021-08-08T00:58:24.867563Z","iopub.status.idle":"2021-08-08T00:58:27.810921Z","shell.execute_reply.started":"2021-08-08T00:58:24.867471Z","shell.execute_reply":"2021-08-08T00:58:27.810087Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import utils\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n\nimport tensorflow as tf\n\nimport numpy as np\nimport pandas as pd\n\nimport nltk\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T01:11:02.167013Z","iopub.execute_input":"2021-08-08T01:11:02.167369Z","iopub.status.idle":"2021-08-08T01:11:09.760586Z","shell.execute_reply.started":"2021-08-08T01:11:02.167339Z","shell.execute_reply":"2021-08-08T01:11:09.759186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Codes by Erin Ward https://www.kaggle.com/eward96/derry-girls-new-script-generator","metadata":{}},{"cell_type":"code","source":"#Codes by Erin Ward https://www.kaggle.com/eward96/derry-girls-new-script-generator\n\ndef process(text):\n    with open (text, \"r\", encoding = \"ISO-8859-1\") as file:\n        data=file.readlines()\n        script = \"\"\n        for i in data:\n            i = i.lower().replace('\"', '').replace(\"\\n\", \" \\n \")\n            if i.strip() != \"\":\n                script += \"\".join(i).replace(\"\\n\",\" \\n \")\n        return script","metadata":{"execution":{"iopub.status.busy":"2021-08-08T01:09:08.909956Z","iopub.execute_input":"2021-08-08T01:09:08.910327Z","iopub.status.idle":"2021-08-08T01:09:08.916437Z","shell.execute_reply.started":"2021-08-08T01:09:08.910297Z","shell.execute_reply":"2021-08-08T01:09:08.915547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = process(\"../input/youtube-videos-comments-analysis/russian_soldiers.csv\") \nprint(df[0:2000])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T01:09:56.12661Z","iopub.execute_input":"2021-08-08T01:09:56.126971Z","iopub.status.idle":"2021-08-08T01:09:56.140946Z","shell.execute_reply.started":"2021-08-08T01:09:56.126941Z","shell.execute_reply":"2021-08-08T01:09:56.139791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Text_Data = df\n\ncharindex = list(set(Text_Data))\ncharindex.sort() \nprint(charindex)\n\nnp.save(\"charindex.npy\", charindex)\n\nprint(len(Text_Data))","metadata":{"execution":{"iopub.status.busy":"2021-08-08T01:10:18.553891Z","iopub.execute_input":"2021-08-08T01:10:18.554277Z","iopub.status.idle":"2021-08-08T01:10:18.561658Z","shell.execute_reply.started":"2021-08-08T01:10:18.554221Z","shell.execute_reply":"2021-08-08T01:10:18.560425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars_size = len(charindex)\nseq_len = 80\n\nx_train = []\ny_train = []\n\nfor i in range(0, len(Text_Data)-seq_len, 1 ): \n    X = Text_Data[i:i + seq_len]\n    Y = Text_Data[i + seq_len]\n    x_train.append([charindex.index(x) for x in X])\n    y_train.append(charindex.index(Y))\n\nx_train = np.reshape(x_train, (len(x_train), seq_len))\n\ny_train = utils.to_categorical(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T01:12:17.019417Z","iopub.execute_input":"2021-08-08T01:12:17.019942Z","iopub.status.idle":"2021-08-08T01:12:30.006288Z","shell.execute_reply.started":"2021-08-08T01:12:17.01991Z","shell.execute_reply":"2021-08-08T01:12:30.005211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LSTMs (Long Short Term Memory networks) are excellent for learning and generating text.üèª\n\ndef LSTM_model():\n    model = models.Sequential()\n    inp = layers.Input(shape=(seq_len, ))\n    x = layers.Embedding(chars_size, 80, trainable=False)(inp)\n    x = tf.compat.v1.keras.layers.CuDNNLSTM(1024, return_sequences=True,)(x)\n    x = tf.compat.v1.keras.layers.CuDNNLSTM(512, return_sequences=True,)(x)\n    x = tf.compat.v1.keras.layers.CuDNNLSTM(256,)(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(256, activation=\"elu\")(x)\n    x = layers.Dense(128, activation=\"elu\")(x)\n    x = layers.Dropout(0.2)(x)\n    outp = layers.Dense(chars_size, activation='softmax')(x)\n    \n    model = models.Model(inputs=inp, outputs=outp)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.0008),\n                  metrics=['accuracy']\n                 )\n\n    return model\n\nmodel = LSTM_model()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T01:12:52.477727Z","iopub.execute_input":"2021-08-08T01:12:52.478102Z","iopub.status.idle":"2021-08-08T01:12:54.548784Z","shell.execute_reply.started":"2021-08-08T01:12:52.478071Z","shell.execute_reply":"2021-08-08T01:12:54.547493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train,\n          batch_size=128,\n          epochs=3)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T01:13:11.670654Z","iopub.execute_input":"2021-08-08T01:13:11.671019Z","iopub.status.idle":"2021-08-08T01:13:14.390259Z","shell.execute_reply.started":"2021-08-08T01:13:11.670989Z","shell.execute_reply":"2021-08-08T01:13:14.388164Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Above error:  [[model/cu_dnnlstm/CudnnRNNV2]] [Op:__inference_train_function_3463]","metadata":{}},{"cell_type":"markdown","source":"#That's all for Now, since I don't know to fix it or even understand the language too.","metadata":{}}]}