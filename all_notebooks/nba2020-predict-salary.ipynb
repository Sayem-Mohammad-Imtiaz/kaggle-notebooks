{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Prediction NBA player's salary "},{"metadata":{},"cell_type":"markdown","source":"## Data analysis"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's read the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"raw_data = pd.read_csv('/kaggle/input/nba2k20-player-dataset/nba2k20-full.csv')\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"raw_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, data have many object data types. Need to preprocess it."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"raw_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, data has some NA values"},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cleaned_data = raw_data.copy()\ncleaned_data['jersey'] = cleaned_data['jersey'].apply(lambda x: int(x[1:])) # delete '#' symbol\ncleaned_data['team'] = cleaned_data['team'].fillna('no team')   # fill all n/a with 'no team' string\ncleaned_data['height'] = cleaned_data['height'].apply(lambda x: float(x[2+x.find('/'):])) # convert to meters\ncleaned_data['weight'] = cleaned_data['weight'].apply(lambda x: float(x[2+x.find('/'):-4])) # convert to kg\ncleaned_data['salary'] = cleaned_data['salary'].apply(lambda x: int(x[1:])) # delete '#' symbol\ncleaned_data['draft_round'] = cleaned_data['draft_round'].apply(lambda x: int(x) if x.isdigit() else 0)\ncleaned_data['draft_peak'] = cleaned_data['draft_peak'].apply(lambda x: int(x) if x.isdigit() else 0)\ncleaned_data['college'] = cleaned_data['college'].fillna('no college')\ncleaned_data['experience_years'] = 2020 - cleaned_data['draft_year']\ncleaned_data = cleaned_data.drop(['draft_year'], axis=1)\n\n# change bday on age\ncleaned_data['b_day'] = cleaned_data['b_day'].apply(lambda x: x[-2:])\ncleaned_data['b_day'] = cleaned_data['b_day'].apply(lambda x: int('20'+x) if x[0] == '0' else int('19'+x))\ncleaned_data['age'] = 2020 - cleaned_data['b_day']\ncleaned_data = cleaned_data.drop(['b_day'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cleaned_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I added two new columns - **'age'** and **'experience_years'**, which means age of player and years from his first draft. "},{"metadata":{},"cell_type":"markdown","source":"Let's encode **'team'**, **'position'**, **'country'**, **'college'**. We need to make from them categorical data."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"labelencoder = LabelEncoder()\ncleaned_data['position_cat'] = labelencoder.fit_transform(cleaned_data['position'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"labelencoder = LabelEncoder()\ncleaned_data['team_cat'] = labelencoder.fit_transform(cleaned_data['team'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"labelencoder = LabelEncoder()\ncleaned_data['country_cat'] = labelencoder.fit_transform(cleaned_data['country'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"labelencoder = LabelEncoder()\ncleaned_data['college_cat'] = labelencoder.fit_transform(cleaned_data['college'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cleaned_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Choosing and splitting data "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.heatmap(cleaned_data.corr(), annot=True, linewidths=0.5, linecolor='black', cmap='coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see on heatmap, good correlation with **salary** have **rating**, **experience_years**, **age** features. Also, I want to add **team_cat** and **draft_peak**."},{"metadata":{},"cell_type":"markdown","source":"Split our data on train/test sets with 20% for test set and normalize it"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"features = ['rating', 'draft_peak', 'experience_years', 'age', 'team_cat', 'country_cat', 'position_cat', 'draft_round']\nlabel = 'salary'\n\nx, y = cleaned_data[features], cleaned_data['salary']\n\nnormalizer = Normalizer().fit(x)\nx = normalizer.transform(x)\nx = np.array(x)\ny = np.array(y)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LinearRegression model"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"reg = LinearRegression()\nreg.fit(x_train, y_train)\n\nprint(\"error: \", np.sqrt(mean_squared_error(y_test, reg.predict(x_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBRegressor model"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"model = XGBRegressor( \n    n_estimators = 300,\n    learning_rate=0.04,\n    colsample_bytree=0.9, \n    min_child_weight=3,\n    objective='reg:squarederror',\n    max_depth = 2,\n    subsample = 0.63,\n    eta = 0.1,\n    seed=0)\n\nmodel.fit(\n    x_train, \n    y_train, \n    eval_metric=\"rmse\", \n    early_stopping_rounds=10,\n    eval_set=[(x_test,y_test)],\n    verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"error: \", np.sqrt(mean_squared_error(y_test, model.predict(x_test))))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tensorflow DNN"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def build_and_compile_model():\n    model = keras.Sequential([\n      layers.Dense(32, activation='relu'),\n      layers.Dense(1)])\n\n    model.compile(loss='mean_absolute_error',\n                optimizer=tf.keras.optimizers.Adam(0.001))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dnn_model = build_and_compile_model()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = dnn_model.fit(\n    x_train, y_train,\n    validation_split=0.2,\n    verbose=0, epochs=200, callbacks=[early_stop])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"error: \", np.sqrt(mean_squared_error(y_test, dnn_model.predict(x_test).flatten())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion"},{"metadata":{},"cell_type":"markdown","source":"XGBRegressor predicted better result than other models. However, $5.4 millions is big bad error anyway."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}