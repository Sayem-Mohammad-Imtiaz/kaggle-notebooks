{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Loaing Necessary Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.layers import Conv1D, Embedding, GlobalAveragePooling1D \nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.preprocessing import image\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading Image Info from CSV and Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/memotion-dataset-7k/memotion_dataset_7k/labels.csv')\ndf.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\ndf = df.drop(columns = ['text_ocr', 'overall_sentiment'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace({'humour': {'not_funny': 0, 'funny': 1, 'very_funny': 2, 'hilarious':3},\n            'sarcasm': {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 2, 'very_twisted': 3},\n            'offensive': {'not_offensive': 0, 'slight': 1, 'very_offensive': 2, 'hateful_offensive': 3},\n            'motivational': {'not_motivational': 0, 'motivational': 1}})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned = df.copy()\ncleaned.dropna(inplace=True)\ncleaned.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Loading Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"width = 100\nheight = 100\nX = []\nfor i in tqdm(range(cleaned.shape[0])):\n    if i in [119, 4799, 6781, 6784, 6786]:\n        pass\n    else:\n        path = '../input/memotion-dataset-7k/memotion_dataset_7k/images/'+cleaned['image_name'][i]\n        img = image.load_img(path,target_size=(width,height,3))\n        img = image.img_to_array(img)\n        img = img/255.0\n        X.append(img)\n        \nX = np.array(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping few rows to make shape consistent"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows_to_drop = ['image_120.jpg',\n              'image_4800.jpg',\n              'image_6782.jpg',\n              'image_6785.jpg',\n              'image_6787.jpg',\n              'image_6988.jpg',\n              'image_6989.jpg',\n              'image_6990.png',\n              'image_6991.jpg',\n              'image_6992.jpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images in rows_to_drop:\n    cleaned.drop(cleaned[cleaned['image_name'] == images].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = cleaned.iloc[:,2:]\ntarget.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomContrast([.5,2]),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n  tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)\n])\n\npreprocess_input = tf.keras.applications.resnet_v2.preprocess_input\n\nrescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i in range(9):\n  augmented_image = data_augmentation(X)\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(augmented_image[0])\n  plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Base Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model_1 = tf.keras.applications.ResNet50(input_shape=X[0].shape,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model_2 = tf.keras.applications.VGG16(input_shape=X[0].shape,\n                                               include_top=False,\n                                               weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model_1.trainable = False\nbase_model_2.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model for Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_model():\n    image_input = tf.keras.Input(shape=(150, 150, 3), name = 'image_input')\n    image_layers = data_augmentation(image_input)\n    image_layers = preprocess_input(image_layers)\n    layer_bm_1 = base_model_1(image_input, training=False)\n    dropout_layer = Dropout(0.2)(layer_bm_1)\n    layer_bm_1 = Conv2D(2048, kernel_size=2,padding='valid')(layer_bm_1)\n    dropout_layer = Dropout(0.3)(layer_bm_1)\n    layer_bm_1 = Dense(512)(dropout_layer)\n    dropout_layer = Dropout(0.5)(layer_bm_1)\n    layer_bm_2 = base_model_2(image_input, training=False)\n    dropout_layer = Dropout(0.4)(layer_bm_2)\n    layer_bm_2 = Dense(512)(layer_bm_2)\n    dropout_layer = Dropout(0.2)(layer_bm_2)\n    layers = tf.keras.layers.concatenate([layer_bm_1, layer_bm_2])\n    dropout_layer = Dropout(0.3)(layers)\n    image_layers = GlobalAveragePooling2D()(layers)\n    image_layers = Dropout(0.5, name = 'dropout_layer')(image_layers)\n    return image_input, image_layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_input, image_layers = image_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Standardization and Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def standardization(data):\n    data = data.apply(lambda x: x.lower())\n    data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n    data = data.apply(lambda x: re.sub(r'\\w*.com\\w*', '', x, flags=re.MULTILINE))\n    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n    return data\n\ncleaned['text_corrected'] = standardization(cleaned.text_corrected)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vectorizing Layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nvocab_size = 100000\nsequence_length = 100\n\nvectorize_layer = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode='int',\n    output_sequence_length=sequence_length)\n\ntext_ds = np.asarray(cleaned['text_corrected'])\nvectorize_layer.adapt(tf.convert_to_tensor(text_ds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(cleaned.text_corrected, target, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim=32\n\ndef text_model():\n    text_input = tf.keras.Input(shape=(None,), dtype=tf.string, name='text')\n    text_layers = vectorize_layer(text_input)\n    text_layers = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\")(text_layers)\n    dropout_layer = Dropout(0.3)(text_layers)\n    \n    text_layers = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, activation='relu', return_sequences=True))(text_layers)\n    dropout_layer = Dropout(0.4)(text_layers)\n    text_layers = tf.keras.layers.BatchNormalization()(text_layers)\n\n    text_layers = tf.keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(text_layers)\n    dropout_layer = Dropout(0.2)(text_layers)\n    text_layers = tf.keras.layers.GlobalMaxPooling1D()(text_layers)\n    dropout_layer = Dropout(0.5)(text_layers)\n    \n    text_layers = tf.keras.layers.Dense(2048, activation=\"relu\")(text_layers)\n    text_layers = tf.keras.layers.Dropout(0.2)(text_layers)\n    return text_input, text_layers\n\ntext_input, text_layers = text_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combining and Evaluating"},{"metadata":{},"cell_type":"markdown","source":"### Task A: Overall Sentiment"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(layer_1, layer_2, image_input, text_input):\n    concatenate = tf.keras.layers.concatenate([layer_1, layer_2], axis=1)\n    semi_final_layer = tf.keras.layers.Dense(2048, activation='relu')(concatenate)\n\n    prediction_layer_1 = tf.keras.layers.Dense(4, activation='softmax', name = 'humuor')\n    prediction_layer_2 = tf.keras.layers.Dense(4, activation='softmax', name = 'sarcasm')\n    prediction_layer_3 = tf.keras.layers.Dense(4, activation='softmax', name = 'offensive')\n    prediction_layer_4 = tf.keras.layers.Dense(2, activation='softmax', name = 'motivational')\n\n    output_1 = prediction_layer_1(semi_final_layer)\n    output_2 = prediction_layer_2(semi_final_layer)\n    output_3 = prediction_layer_3(semi_final_layer)\n    output_4 = prediction_layer_4(semi_final_layer)\n\n    model = tf.keras.Model(inputs = [image_input, text_input] , \n                           outputs = [output_1, output_2, output_3, output_4])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model(image_layers, text_layers, image_input, text_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n# Define the checkpoint directory to store the checkpoints\ncheckpoint_dir = './training_checkpoints'\n\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for decaying the learning rate.\n# You can define any decay function you need.\ndef decay(epoch):\n  if epoch < 5:\n    return 1e-3\n  elif epoch >= 5 and epoch < 15:\n    return 1e-4\n  else:\n    return 1e-5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Callback for printing the LR at the end of each epoch.\nclass PrintLR(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n                                                      model.optimizer.lr.numpy()))\n\ncallbacks = [\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n                                       save_weights_only=True),\n    tf.keras.callbacks.LearningRateScheduler(decay),\n    PrintLR()\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_learning_rate = 0.0001\nlosses = {\n      \"humuor\": \"sparse_categorical_crossentropy\", \n      \"sarcasm\": \"sparse_categorical_crossentropy\", \n      \"offensive\": \"sparse_categorical_crossentropy\", \n      \"motivational\": \"sparse_categorical_crossentropy\"\n}\nlossWeights = {\n      \"humuor\": 1.0, \n      \"sarcasm\": 1.0, \n      \"offensive\": 1.0, \n      \"motivational\": 1.0\n}\nmetrics = {\n      \"humuor\": \"sparse_categorical_accuracy\", \n      \"sarcasm\": \"sparse_categorical_accuracy\", \n      \"offensive\": \"sparse_categorical_accuracy\", \n      \"motivational\": \"sparse_categorical_accuracy\"\n}\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss = losses,\n              loss_weights= lossWeights,\n              metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x = {\"image_input\": X_train, \"text_input\": X_text_train},\n                    y = {\"sarcasm\": y_train.sarcasm, \n                         \"humuor\": y_train.humour, \n                         \"offensive\": y_train.offensive, \n                         \"motivational\": y_train.motivational},\n                    batch_size=32,\n                    epochs=30,\n                    validation_data=({\"image_input\": X_test, \"text_input\": X_text_test}, \n                                     {\"sarcasm\": y_test.sarcasm, \n                                      \"humuor\": y_test.humour, \n                                      \"offensive\": y_test.offensive, \n                                      \"motivational\": y_test.motivational}),\n                    callbacks=callbacks\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_history = pd.DataFrame(history.history)\ndf_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_history.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set(font_scale=1.2)\nfig, axes = plt.subplots(1,2, figsize=(16, 6))\nfig.tight_layout(pad=5.0)\n\naxes[0].plot(df_history.loss)\naxes[0].plot(df_history.humuor_loss)\naxes[0].plot(df_history.sarcasm_loss)\naxes[0].plot(df_history.offensive_loss)\naxes[0].plot(df_history.motivational_loss)\naxes[0].set_xlabel('Epochs')\naxes[0].set_ylabel('Losses')\naxes[0].set_title('Losses Per Epoch')\naxes[0].legend(['loss', 'val_loss'], loc='upper right')\n\naxes[1].plot(df_history.humuor_sparse_categorical_accuracy)\naxes[1].plot(df_history.sarcasm_sparse_categorical_accuracy)\naxes[1].plot(df_history.offensive_sparse_categorical_accuracy)\naxes[1].plot(df_history.motivational_sparse_categorical_accuracy)\naxes[1].set_xlabel('Epochs')\naxes[1].set_ylabel('Binary Accuracy')\naxes[1].set_title('Accuracy Per Epoch')\naxes[1].legend(['accuracy', 'val_accuracy'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate = model.evaluate(x = {\"image_input\": X_test, \"text_input\": X_text_test},\n                    y = {\"sarcasm\": y_test.sarcasm, \n                         \"humuor\": y_test.humour, \n                         \"offensive\": y_test.offensive, \n                         \"motivational\": y_test.motivational},\n                    batch_size=32,\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Evaluation Loss: \", evaluate[0])\nprint(\"Evaluation Loss on Humuor\", evaluate[1])\nprint(\"Evaluation Loss on Sarcasm\", evaluate[2])\nprint(\"Evaluation Loss on Offensive\", evaluate[3])\nprint(\"Evaluation Loss on Motivational\", evaluate[4])\nprint(\"Evaluation Accuracy on Humuor\", evaluate[5])\nprint(\"Evaluation Accuracy on Sarcasm\", evaluate[6])\nprint(\"Evaluation Accuracy on Offensive\", evaluate[7])\nprint(\"Evaluation Accuracy on Motivational\", evaluate[8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"humuor_pred = np.array(predictions[0])\nsarcasm_pred = np.array(predictions[1])\noffensive_pred = np.array(predictions[2])\nmotivational_pred = np.array(predictions[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,5, figsize=(20, 4))\nfig.tight_layout(pad=5.0)\n\n\nx = [0, 1, 2, 3]\n\naxes[0].imshow(X[1,:,:,:], aspect='auto')\n\naxes[1].bar(x, humuor_pred[1,:])\naxes[1].set_xlabel('Humuor Labels')\naxes[1].set_ylabel('Probanility')\naxes[1].set_title('Humuor Prob.')\naxes[1].set_xticks(x)\n\naxes[2].bar(x, sarcasm_pred[1,:])\naxes[2].set_xlabel('Sarcasm Labels')\naxes[2].set_ylabel('Probability')\naxes[2].set_title('Sarcasm Prob.')\naxes[2].set_xticks(x)\n\naxes[3].bar(x, offensive_pred[1,:])\naxes[3].set_xlabel('Offensive Labels')\naxes[3].set_ylabel('Probanility')\naxes[3].set_title('Offensive Prob.')\naxes[3].set_xticks(x)\n\naxes[4].bar([0, 1], motivational_pred[1,:])\naxes[4].set_xlabel('Motivational Labels')\naxes[4].set_ylabel('Probability')\naxes[4].set_title('Motivational Prob.')\naxes[4].set_xticks([0, 1])\nplt.show()\n\nprint(y_test.iloc[1,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"axes[0].imshow(X[100,:,:,:], aspect='auto')\n\naxes[1].bar(x, humuor_pred[100,:])\naxes[1].set_xlabel('Humuor Labels')\naxes[1].set_ylabel('Probanility')\naxes[1].set_title('Humuor Prob.')\naxes[1].set_xticks(x)\n\naxes[2].bar(x, sarcasm_pred[100,:])\naxes[2].set_xlabel('Sarcasm Labels')\naxes[2].set_ylabel('Probability')\naxes[2].set_title('Sarcasm Prob.')\naxes[2].set_xticks(x)\n\naxes[3].bar(x, offensive_pred[100,:])\naxes[3].set_xlabel('Offensive Labels')\naxes[3].set_ylabel('Probanility')\naxes[3].set_title('Offensive Prob.')\naxes[3].set_xticks(x)\n\naxes[4].bar([0, 1], motivational_pred[100,:])\naxes[4].set_xlabel('Motivational Labels')\naxes[4].set_ylabel('Probability')\naxes[4].set_title('Motivational Prob.')\naxes[4].set_xticks([0, 1])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}