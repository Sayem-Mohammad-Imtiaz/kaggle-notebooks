{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of unique values\ndf.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()/len(df)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We won't be using Title feature since it has a lot of missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Clothing ID', 'Title', 'Unnamed: 0'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are dropping these features because they hold very less significance to sentiment analysis of the review."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Review Text'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing the unwanted null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[~df['Review Text'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis and Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,6))\nsns.countplot(x = 'Age', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,6))\nsns.countplot(x = 'Rating', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,6))\nsns.countplot(x = 'Class Name', data = df)\nplt.xticks(rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dresses, Knits and Blouses are bought the most by women. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,6))\nsns.barplot(x ='Age',y= 'Positive Feedback Count',data = df, palette = 'viridis')\nplt.title('Age vs Positive Feedback', fontsize = 20)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's no noteable relation between Age and Positive Feedback, excluding some outliers.  \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,6))\nsns.distplot(df['Positive Feedback Count'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,6))\n\nsns.barplot(x ='Age',y= 'Rating',data = df, palette = 'viridis')\nplt.title('Age vs Rating', fontsize = 20)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's no noteable relation between Age and Rating, excluding some outliers. Same as Age vs Positive Feedback."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,10))\nsns.boxplot(x=\"Recommended IND\", y=\"Rating\", hue = \"Recommended IND\", data = df)\nplt.xlabel(\"3-G\", fontsize = 20)\nplt.ylabel(\"RAM\", fontsize = 20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here 1 means recommended. 0 means not recommended.\n\nWomen recommend a product if they rate it to be more than or equal to 3."},{"metadata":{},"cell_type":"markdown","source":"# Cleaning the text for visualization of polarity"},{"metadata":{},"cell_type":"markdown","source":"Removing all the punctuations from the review text."},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nstring.punctuation\ndef remove_punctuation(text):\n    no_punct=[words for words in text if words not in string.punctuation]\n    words_wo_punct=''.join(no_punct)\n    return words_wo_punct\ndf['Review Text']=df['Review Text'].apply(lambda x: remove_punctuation(x))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install TextBlob\nfrom textblob import *\n\ndf['polarity'] = df['Review Text'].map(lambda text: TextBlob(text).sentiment.polarity)\ndf['polarity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\npx.histogram(df, x = 'polarity',color=\"Rating\", opacity = 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,10))\nsns.boxplot(x=\"polarity\", y=\"Department Name\", hue = \"Recommended IND\", data = df)\nplt.xlabel(\"Polarity of the review\", fontsize = 20)\nplt.ylabel(\"Department Name\", fontsize = 20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot looks right because all **the polarities of \"not recommended\" are less than that of polarities of the \"recommended\".**"},{"metadata":{},"cell_type":"markdown","source":"# Reviews with positive polarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"example = df.loc[df.polarity == 1,['Review Text']].sample(3).values\nfor i in example:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reviews with neutral polarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"example = df.loc[df.polarity == 0.5,['Review Text']].sample(3).values\nfor i in example:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reviews with negative polarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"example = df.loc[df.polarity < 0,['Review Text']].sample(3).values\nfor i in example:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Polarity Pie-Chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"negative = (len(df.loc[df.polarity < 0, ['Review Text']].values)/len(df))*100\npositive = (len(df.loc[df.polarity > 0.5, ['Review Text']].values)/len(df))*100\nneutral = len(df.loc[df.polarity >0 ,['Review Text']].values) - len(df.loc[df.polarity >0.5 ,['Review Text']].values)\nneutral = neutral/len(df)*100\nplt.figure(figsize =(10, 7)) \nplt.pie([positive,negative,neutral], labels = ['Positive','Negative','Neutral']) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create N-grams"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ndef top_n_ngram(corpus,n = None,ngram = 1):\n    vec = CountVectorizer(stop_words = 'english',ngram_range=(ngram,ngram)).fit(corpus)\n    bag_of_words = vec.transform(corpus) #Have the count of  all the words for each review\n    sum_words = bag_of_words.sum(axis =0) #Calculates the count of all the word in the whole review\n    words_freq = [(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq,key = lambda x:x[1],reverse = True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Top 10 Unigrams"},{"metadata":{"trusted":true},"cell_type":"code","source":"common_words= top_n_ngram(df['Review Text'], 10,1)\ndata = pd.DataFrame(common_words, columns = ['ReviewText' , 'count'])\nplt.figure(figsize =(10,5))\ndata.groupby('ReviewText').sum()['count'].sort_values(ascending=False).plot(\nkind='bar', title='Top 10 unigrams in review after removing stop words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Top 20 Bigrams"},{"metadata":{"trusted":true},"cell_type":"code","source":"common_words = top_n_ngram(df['Review Text'], 20,2)\ndata = pd.DataFrame(common_words, columns = ['ReviewText' , 'count'])\nplt.figure(figsize =(10,5))\ndata.groupby('ReviewText').sum()['count'].sort_values(ascending=False).plot(\nkind='bar', title='Top 10 unigrams in review after removing stop words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Top 10 POS Tagging"},{"metadata":{"trusted":true},"cell_type":"code","source":"blob= TextBlob(str(df['Review Text']))\npos = pd.DataFrame(blob.tags,columns =['word','pos'])\npos1 = pos.pos.value_counts()[:20]\nplt.figure(figsize = (10,5))\npos1.plot(kind='bar',title ='Top 20 Part-of-speech taggings')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation of fetaures using Heatmaps "},{"metadata":{},"cell_type":"markdown","source":"Adding Review Length as a feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review_len'] = df['Review Text'].astype(str).apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['Recommended IND']\nX = df.drop(columns = 'Recommended IND')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(X.corr(), annot = True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's not a strong correleation between any of the features."},{"metadata":{},"cell_type":"markdown","source":"# Statistical Description"},{"metadata":{"trusted":true},"cell_type":"code","source":"class1 = []\nfor i in X.polarity:\n    if float(i)>=0.0:\n        class1.append(1)\n        \n    elif float(i)<0.0:\n        class1.append(0)\nX['sentiment'] = class1\n\nX.groupby(X['sentiment']).describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Bag Of Words Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of X: \" , X.shape)\nprint(\"Shape of y: \" , y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.index = np.arange(len(X))\ncorpus = []\nfrom tqdm import tqdm\nfor i in tqdm(range(len(X))):\n  review = re.sub('[^a-zA-Z]', ' ', X['Review Text'][i])\n  review = review.lower()\n  review = review.split()\n  ps = PorterStemmer()\n  all_stopwords = stopwords.words('english')\n  all_stopwords.remove('not')\n  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n  review = ' '.join(review)\n  corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n# wc= WordCloud(background_color=\"white\", random_state=1,stopwords=STOPWORDS, max_words = 2000, width =1000, height = 1500)\n# wc.generate(review)\n# plt.figure(figsize=[10,10])\n# plt.imshow(wc,interpolation=\"bilinear\")\n# plt.axis('off')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer as CV\ncv  = CV(max_features = 3000,ngram_range=(1,1))\nX_cv = cv.fit_transform(corpus).toarray()\ny = y.values\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_cv, y, test_size = 0.20, random_state = 0)\nfrom sklearn.naive_bayes import BernoulliNB\nclassifier = BernoulliNB()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nacc = accuracy_score(y_test, y_pred)\nprint(\"Accuracy of the classifier: \",acc)\nprint(\"Confusion matrix is :\\n\",metrics.confusion_matrix(y_test,y_pred))\nprint(\"Classification report: \\n\" ,metrics.classification_report(y_test,y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An accuracy score of 87.28% is pretty good."},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF Technique"},{"metadata":{},"cell_type":"markdown","source":"Term Frequency - Inverse Document Frequency is used to measure the originality of a word. It converts sentences to vectors(after tokenization, stemming/lemmatization). \n\nBag of Words technique doesn't provide us with the semantic meaning of the word, here TF-IDF comes in play as it provides us the semantic meaning of the word.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer as TV\ntv  = TV(ngram_range =(1,1),max_features = 3000)\nX_tv = tv.fit_transform(corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_tv, y, test_size = 0.20, random_state = 0)\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An accuracy of 83.55% from the TF-IDF technique, which is less than that of Bag of Words Technique."},{"metadata":{},"cell_type":"markdown","source":"# Deep Learning Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words = 3000)\ntokenizer.fit_on_texts(corpus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences = tokenizer.texts_to_sequences(corpus)\npadded = pad_sequences(sequences, padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_index = tokenizer.word_index\ncount = 0\nfor i,j in word_index.items():\n    if count == 11:\n        break\n    print(i,j)\n    count = count+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the Top 11 most frequent words."},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 64\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(3000, embedding_dim),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(6, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(padded,y,epochs= num_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_string = \"I Will tell my friends for sure\"\nsample = tokenizer.texts_to_sequences(sample_string)\npadded_sample = pad_sequences(sample, padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"padded_sample.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(padded_sample.T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's a 99.45% accuracy that this review will result in recommendation."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}