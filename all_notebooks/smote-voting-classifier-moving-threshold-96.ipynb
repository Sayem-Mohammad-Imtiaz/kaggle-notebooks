{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from IPython.display import display\n#import sweetviz as sv\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n\nfrom sklearn.model_selection import train_test_split, cross_val_score,  RepeatedStratifiedKFold,RandomizedSearchCV, GridSearchCV\n\n\nfrom sklearn.metrics import classification_report, roc_curve, confusion_matrix\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom collections import Counter\n\nfrom sklearn.impute import KNNImputer\n\n# modelos\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, \\\nVotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AED","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\ndf = df.drop(['id'], axis=1)\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## you can donwload this notebook, and instal SweetViz. Then, uncomment these lines for some cool data exploration.\n\n#analise = sv.analyze(df)\n#analise.show_html('analise.html', layout = 'vertical', scale =1.0);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.work_type.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['bmi']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(data = df[['age', 'avg_glucose_level','bmi']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Etapas de pr√©-processamento:\n- Input de missing values em 'bmi', utilizando knn imputer\n- O mesmo para smoking status unknown, mantendo a coluna 'stroke'(?)\n- Gender = 'other' replace 'female'\n- Escalonar as colunas ['age', 'avg_glucose_level','bmi']\n","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## bmi - KNNImputer","metadata":{}},{"cell_type":"code","source":"imputer = KNNImputer(n_neighbors = 6)\ndf['bmi'] = imputer.fit_transform(np.array(df['bmi']).reshape(-1,1))\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df['bmi'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## bmi groups","metadata":{}},{"cell_type":"code","source":"bmi_group = []\nfor bmi in df['bmi']:\n    if bmi < 17.0:\n        bmi_group.append(0)\n    \n    elif (bmi >= 17.0) & (bmi <= 18.49):\n        bmi_group.append(1)\n    \n    elif (bmi >= 18.50) & (bmi <= 24.99):\n        bmi_group.append(2)\n    \n    elif (bmi >= 25.0) & (bmi <= 29.99):\n        bmi_group.append(3)\n    \n    elif (bmi >= 30.0) & (bmi <= 34.99):\n        bmi_group.append(4)\n    \n    elif (bmi >= 35.0) & (bmi <= 39.99):\n        bmi_group.append(5)\n    \n    elif (bmi > 39.99):\n        bmi_group.append(6)\n    \ndf['bmi_group'] = bmi_group   \ndf = df.drop(['bmi'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## replace gender == 'other'","metadata":{}},{"cell_type":"code","source":"df['gender'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['gender'] = df['gender'].replace(to_replace='Other', value='Female')\ndf['gender'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rounding Age","metadata":{}},{"cell_type":"code","source":"df['age'] = df['age'].apply(lambda x: round(x))\ndf['age']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\ndf_scale = pd.DataFrame(scaler.fit_transform(df[['age', 'avg_glucose_level']]))\ndf_scale[['age', 'avg_glucose_level']] = df_scale\ndf_scale = df_scale[['age', 'avg_glucose_level']]\n\ndf.drop(columns = ['age', 'avg_glucose_level'], inplace=True)\ndf = pd.concat([df, df_scale], axis=1)\nsns.boxplot(data = df[['age', 'avg_glucose_level']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlations","metadata":{}},{"cell_type":"code","source":"df_temp = pd.get_dummies(df, drop_first = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(14,8))\nsns.heatmap(df_temp.corr(), annot = True, cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OneHot","metadata":{}},{"cell_type":"code","source":"ohe = OneHotEncoder(drop = 'first', sparse=False, handle_unknown = 'error')\ndf_t = pd.DataFrame(ohe.fit_transform(df.select_dtypes('object')))\n\ndf_t.columns = ohe.get_feature_names()\ndf_t.head(2)\ndf_t.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_n = df.drop(df.select_dtypes('object'), axis=1)\n\ndf = pd.concat([df_t, df_n], axis=1)\ndf.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing k_neighbors for SMOTE","metadata":{}},{"cell_type":"code","source":"k_values = [1, 2, 3, 4, 5, 6, 7]\nX = df.drop(['stroke'], axis=1)\ny = df.stroke\n\nk_scores = []\nfor k in k_values:\n    # define pipeline\n    rf = RandomForestClassifier()\n    over  = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n    steps = [('over', over), ('model', rf)]\n    \n    pipeline = Pipeline(steps=steps)\n    \n    # evaluate pipeline\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    \n    scores = cross_val_score(rf, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n    score = np.mean(scores)\n    k_scores.append((k, score))\n    print('> k=%d, Mean ROC AUC: %.3f' % (k, score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(k_scores, key=lambda tup: tup[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_k = sorted(k_scores, key=lambda tup: tup[1])[-1][0]\nbest_k","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"over  = SMOTE(k_neighbors=best_k)\n\nsteps = [('over', over)]\npipeline = Pipeline(steps=steps)\nX, y = pipeline.fit_resample(X, y)\ncounter = Counter(y)\nprint(counter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models + voting classifier","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify = y, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## random forest","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier()\n\nn_estimators = [100,500,700,1000]\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\ngrid =         {'n_estimators': n_estimators,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n#search_nc = GridSearchCV(estimator = pipeline, param_grid = grid, cv = 5, verbose=1, n_jobs=-1)\nsearch = RandomizedSearchCV(estimator = rf, param_distributions = grid, cv = 5, verbose=1, n_jobs=-1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search.fit(X_train, y_train)\npreds = search.predict(X_test)\nprint(classification_report(y_test, preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boost","metadata":{}},{"cell_type":"code","source":"gbr = GradientBoostingClassifier()\n\nparameters = {\n    \"loss\":[\"deviance\"],\n    \"learning_rate\": [0.01],#, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n    #\"min_samples_split\": [1,2,3],\n    \"min_samples_leaf\": [1,2,3],\n    'max_depth' : [None, 2,3,5,10],\n    #\"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n    \"n_estimators\":[100, 300, 500, 1000],\n    \"warm_start\" : [False, True]\n    \n    }\n#search_gbr = RandomizedSearchCV(estimator = gbr, param_distributions = parameters, cv = 5, verbose = 2, n_jobs = -1)\nsearch_gbr = RandomizedSearchCV(estimator = gbr,param_distributions = parameters, scoring = 'roc_auc',cv = 5, verbose = 2, n_jobs = -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extra trees\n","metadata":{}},{"cell_type":"code","source":"extra_trees = ExtraTreesClassifier()\nsearch_extra = RandomizedSearchCV(estimator = extra_trees,param_distributions = grid, scoring = 'roc_auc',cv = 5, verbose = 2, n_jobs = -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVC","metadata":{}},{"cell_type":"code","source":"svc = SVC()\nsvc_grid = {'kernel':['linear','rbf'], 'probability' : [True]}\nsearch_svc = RandomizedSearchCV(estimator = svc, param_distributions = svc_grid, scoring = 'roc_auc',cv = 5, verbose = 2, n_jobs = -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Knn Classifier","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier()\nparameters_KNN = {\n    'n_neighbors': (1,30, 1),\n    'leaf_size': (20,40,1),\n    'p': (1,2),\n    'weights': ('uniform', 'distance'),\n    'metric': ('minkowski', 'chebyshev')\n}\nsearch_knn = RandomizedSearchCV(estimator = knn, param_distributions = parameters_KNN, scoring = 'roc_auc',cv = 5, verbose = 2, n_jobs = -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Voting Classifier","metadata":{}},{"cell_type":"code","source":"X_test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voting_clf = VotingClassifier( estimators = [('rfr', search ),('gbr', search_gbr),('extra', search_extra),('svc', search_svc), ('knn', knn)], voting = 'soft')\nvoting_clf.fit(X_train, y_train);\npreds = voting_clf.predict(X_test)\nprint(classification_report(y_test, preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Moving Threshold","metadata":{}},{"cell_type":"code","source":"probas = voting_clf.predict_proba(X_test)\n#Gets class 1 probas\nprobas = probas[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, probas)\n\n# calculates g-mean for each threshold\ngmeans = (tpr * (1-fpr)) ** (1/2)\n# finds the index of the highest g-mean\nix = np.argmax(gmeans)\nbest_threshold = thresholds[ix]\nprint('Melhor Threshold = %f, G-Mean = %.3f' % (thresholds[ix], gmeans[ix]))\n\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill')\nplt.plot(fpr, tpr, marker='.', label='RFC')\nplt.scatter(fpr[ix], tpr[ix], marker = 'o', color = 'black', label = 'Best')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decisions = (probas >= best_threshold).astype(int)\nprint(classification_report(y_test, decisions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test, decisions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving Modules","metadata":{}},{"cell_type":"code","source":"import pickle\n# save the model\npickle.dump(voting_clf, open('modelo_voting_classifier.pkl', 'wb'))\n\n# save the scaler\npickle.dump(scaler, open('scaler.pkl', 'wb'))\n\npickle.dump(ohe, open('ohe.pkl', 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}