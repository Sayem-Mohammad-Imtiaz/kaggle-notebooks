{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport dask.dataframe as dd\nimport os\n# import sys11\nimport subprocess\n\nfrom six import string_types\n\n# Make sure you have all of these packages installed, e.g. via pip\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport scipy\nfrom skimage import io\nfrom scipy import ndimage\nfrom time import time\nfrom IPython.display import display\nimport random\nimport tqdm\n\n##model libraries\nimport logging\nimport warnings\n\nimport matplotlib.style as style\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom datetime import datetime\nfrom keras.preprocessing import image\nfrom PIL import Image\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.calibration import calibration_curve\nfrom tensorflow.keras import layers\nfrom keras.callbacks import ModelCheckpoint\nimport glob\n# from utils import *\n\nimport cv2\nwarnings.filterwarnings('ignore')\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"TF version:\", tf.__version__)\ntf.test.gpu_device_name()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Input Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"PLANET_KAGGLE_ROOT = os.path.abspath(\"/kaggle/input/planets-dataset/planet/planet/\")\nPLANET_KAGGLE_JPEG_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\nPLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_classes.csv')\nassert os.path.exists(PLANET_KAGGLE_ROOT)\nassert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\nassert os.path.exists(PLANET_KAGGLE_LABEL_CSV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\nprint(labels_df.shape)\nlabels_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add onehot features for every label\n# for label in label_list:\nlabels_df['tags'] = labels_df['tags'].apply(lambda x: x.split(' '))\n# Display head\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = labels_df.memory_usage(index=True).sum()\nprint(val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# translating image name to image path\nX = labels_df['image_name'].apply(lambda x : PLANET_KAGGLE_JPEG_DIR+'/'+x+'.jpg')\ny = labels_df['tags']\nX.head(), y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nobs = 8 # Maximum number of images to display\nncols = 4 # Number of columns in display\nnrows = nobs//ncols # Number of rows in display\n\nstyle.use(\"default\")\nplt.figure(figsize=(16,4*nrows))\nfor i in range(nrows*ncols):\n    ax = plt.subplot(nrows, ncols, i+1)\n    plt.imshow(Image.open(X[i]))\n    plt.title(y[i], size=10)\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y,test_size=0.1, random_state=42)\n\nprint(\"Labels:\")\nmlb = MultiLabelBinarizer()\nmlb.fit(y_train)\n\n# Loop over all labels and show them\nN_LABELS = len(mlb.classes_)\nfor (i, label) in enumerate(mlb.classes_):\n    print(\"{}. {}\".format(i, label))\n    \n# y_train_bin = mlb.transform(y_train)\n# y_val_bin = mlb.transform(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(3):\n#     print(X_train.iloc[i], y_train_bin[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Input Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"## ref:https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb\n\nIMG_SIZE = 300 # Specify height and width of image to match the input format of the model\nCHANNELS = 3 # Keep RGB color channels to match the input format of the model\n\ndef parse_function(filename, label):\n    \"\"\"Function that returns a tuple of normalized image array and labels array.\n    Args:\n        filename: string representing path to image\n        label: 0/1 one-dimensional array of size N_LABELS\n    \"\"\"\n    # Read an image from a file\n    image_string = tf.io.read_file(filename)\n    # Decode it into a dense vector\n    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n    # Resize it to fixed shape\n    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n    # Normalize it from [0, 255] to [0.0, 1.0]\n    image_normalized = image_resized / 255.0\n    return image_normalized, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 256 # Big enough to measure an F1-score\nAUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\nSHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n\ndef create_dataset(filenames, labels, is_training=True):\n    \"\"\"Load and parse dataset.\n    Args:\n        filenames: list of image paths\n        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n        is_training: boolean to indicate training mode\n    \"\"\"\n    \n    # Create a first dataset of file paths and labels\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    # Parse and preprocess observations in parallel\n    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n    \n    if is_training == True:\n        # This is a small dataset, only load it once, and keep it in memory.\n        dataset = dataset.cache()\n        # Shuffle the data each buffer size\n        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n        \n    # Batch the data for multiple steps\n    dataset = dataset.batch(BATCH_SIZE)\n    # Fetch batches in the background while the model is training.\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# train_ds = create_dataset(X_train, y_train_bin)\n# val_ds = create_dataset(X_val, y_val_bin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Model building (Transfer learning)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for batch in train_ds:\n#     print(model.predict(batch)[:1])\n#     break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## LOSS FUNCTION\n\ndef macro_soft_f1(y, y_hat):\n    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n    Use probability values instead of binary predictions.\n    \n    Args:\n        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        \n    Returns:\n        cost (scalar Tensor): value of the cost function for the batch\n    \"\"\"\n    y = tf.cast(y, tf.float32)\n    y_hat = tf.cast(y_hat, tf.float32)\n    tp = tf.reduce_sum(y_hat * y, axis=0)\n    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n    macro_cost = tf.reduce_mean(cost) # average on all labels\n    return macro_cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##metric function\n\ndef macro_f1(y, y_hat, thresh=0.5):\n    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n    \n    Args:\n        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        thresh: probability value above which we predict positive\n        \n    Returns:\n        macro_f1 (scalar Tensor): value of macro F1 for the batch\n    \"\"\"\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the extension and start TensorBoard\n\n%load_ext tensorboard\n%tensorboard --logdir '/kaggle/working/logs'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 1e-5 # Keep it small when transfer learning\nEPOCHS = 25\n\n# class KerasWrapper:\n#     def __init__(self, model, feat_mean, feat_std):\n#         self.model = model\n#         self.feat_mean = feat_mean\n#         self.feat_std = feat_std\n        \n#     def predict_proba(self, X):\n        \n#         preds = self.model.predict((X - self.feat_mean)/self.feat_std)\n#         return np.c_[preds, preds]\n        \ndef dask_read_and_incrementally_fit_keras(blocksize):\n    \n    # reading df with dask\n    df_train = dd.read_csv(PLANET_KAGGLE_LABEL_CSV, blocksize=blocksize)\n    \n    # The feature extractor accepts images of shape (224, 224, 3) and returns a 1280-length vector for each image.\n    feature_extractor_url = \"https://tfhub.dev/google/efficientnet/b3/feature-vector/1\"\n    height, width = 300,300\n    feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n                                         input_shape=(height,width,CHANNELS))\n    \n    # We should freeze the variables in the feature extractor layer, so that the training only modifies the new classification layers.\n    # Usually, it is a good practice when working with datasets that are very small compared to the orginal dataset the feature extractor was trained on.\n    feature_extractor_layer.trainable = False\n    \n    # creating keras model\n    model = tf.keras.Sequential([\n    feature_extractor_layer,\n    layers.Dense(1024, activation='relu', name='hidden_layer'),\n    layers.Dense(N_LABELS, activation='sigmoid', name='output')\n        ])\n\n    model.summary()\n    \n    model.compile(\n      optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n      loss=macro_soft_f1,\n      metrics=[macro_f1])\n    \n    filepath=\"/kaggle/working/model/planet_mobilenet_pretrained-{epoch:02d}-{loss:.4f}.hdf5\"\n    checkpoint = ModelCheckpoint(filepath, monitor='macro_f1', verbose=1, save_best_only=True, mode='max')\n    my_callbacks = [\n        tf.keras.callbacks.EarlyStopping(patience=8),\n        checkpoint,\n        tf.keras.callbacks.TensorBoard(log_dir='/kaggle/working/logs'),\n        ]\n\n    # loop for number of partitions\n    for i in range(df_train.npartitions):\n        \n        # getting one partition\n        part = df_train.get_partition(i).compute(scheduler='synchronous')\n        \n        part['tags'] = part['tags'].apply(lambda x: x.split(' '))\n        X = part['image_name'].apply(lambda x : PLANET_KAGGLE_JPEG_DIR+'/'+x+'.jpg')\n        y = part['tags']\n        X_train, X_val, y_train, y_val = train_test_split(X, y,test_size=0.2, random_state=42)\n        y_train_bin = mlb.transform(y_train)\n        y_val_bin = mlb.transform(y_val)\n\n        train_ds = create_dataset(X_train, y_train_bin)\n        val_ds = create_dataset(X_val, y_val_bin)\n        \n        # running partial fit\n        history = model.fit(train_ds,\n                    epochs=EPOCHS,\n                            validation_data=val_ds,\n                            callbacks=my_callbacks)\n    \n    return (model, history)\nval = labels_df.memory_usage(index=True).sum()\nprint(val)\nstart = time()\nmodel, mem_history_1 = dask_read_and_incrementally_fit_keras(blocksize=(val/4))\nprint('\\nTraining took {}'.format(time()-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_name = []\ntags = []\nimgs = glob.glob(\"/kaggle/input/planets-dataset/planet/planet/test-jpg/*.jpg\")\nimgs2 = glob.glob('../input/planets-dataset/test-jpg-additional/test-jpg-additional/*')\nimgs = imgs + imgs2\nfor img in tqdm.tqdm(imgs):\n# Read an image from a file\n    bgr_image = cv2.imread(img)\n    rgb_image = bgr_image[:, :, [2,1,0]]\n    # Resize it to fixed shape\n    image_resized = cv2.resize(rgb_image, (300, 300))\n    # Normalize it from [0, 255] to [0.0, 1.0]\n    image_normalized = image_resized / 255.0    \n    \n\n    img_name = (img.split('/')[-1]).split('.')[0]\n    image_name.append(img_name)\n#     y_sub = model.predict(image_normalized)\n    result = model.predict(image_normalized[np.newaxis,:])\n# result.shape\n    tags.append(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out = pd.DataFrame({'image_name':image_name,'tags':tags})\ndf_out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out['tags_v2'] = df_out['tags'].apply(lambda x : (x[0] >= 0.7)*1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"((df_out['tags_v2'].values)[0]).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remapping(x):\n    val2 = x*mlb.classes_\n    result = ''\n    for ele in val2:\n        if ele !='':\n            result=result+ele+' '\n    return result[:-1]\n        \ndf_out['tags_v3'] = df_out['tags_v2'].apply(lambda x : remapping(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out['tags'] = df_out['tags_v3']\ndf_out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df_out[['image_name','tags']]\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}