{"cells":[{"metadata":{},"cell_type":"markdown","source":"**** The following code presents my take on topic modelling using NMF. Any suggestions for improvement are welcome. Reference: https://github.com/fastai/course-nlp/blob/master/2-svd-nmf-topic-modeling.ipynb"},{"metadata":{},"cell_type":"markdown","source":"**Pros:**\nFaster to train than other models as it basically involves matrix multiplication\nBetter than SVD as we can define number of topics \n\n**Cons:**\nToo simple, not very precise in detection, hence not very accurate.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport scipy\nimport nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import decomposition\nfrom scipy import linalg\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\nfrom nltk.tokenize import word_tokenize\nnp.set_printoptions(suppress=True)\nfrom gensim.models.doc2vec import Doc2Vec ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#reading the data\ndf=pd.read_csv(\"../input/CORD-19-research-challenge/metadata.csv\",engine='python',error_bad_lines=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#observing the first 5 rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I am interested in the abstract section\ndf['abstract'] #512397 abstracts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing NaN values\ndf['abstract'].fillna('null',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# storing the abstracts in 'data'\ndata=np.array(df['abstract'])\nlen(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using CountVectoriser to convert text into matrix form \nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nvectorizer = CountVectorizer(stop_words='english',max_features=10000) # removing stop words\nvectors = vectorizer.fit_transform(data).todense() #converting into a dense vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding the vocab\nvocab = np.array(vectorizer.get_feature_names())\nprint(vocab.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show topics method to \nnum_top_words=10\n\ndef show_topics(a):\n    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n    topic_words = ([top_words(t) for t in a])\n    return [' '.join(t) for t in topic_words]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m,n=vectors.shape\nd=10 # setting the number of topics to 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = decomposition.NMF(n_components=d, random_state=1)\nW1 = clf.fit_transform(vectors)\nH1 = clf.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_topics(H1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting data into list format\nlist_data=data.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(list_data)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training the model on the corpus\n#applying Doc2Vec to convert document into its vector form. Reference: https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5\nmax_epochs = 50\nvec_size = 20\nalpha = 0.025\n\nmodel = Doc2Vec(size=vec_size,\n                alpha=alpha, \n                min_alpha=0.00025,\n                min_count=1,\n                dm =1)\n  \nmodel.build_vocab(tagged_data)\n\nfor epoch in range(max_epochs):\n    print('iteration {0}'.format(epoch))\n    model.train(tagged_data,\n                total_examples=model.corpus_count,\n                epochs=model.iter)\n    # decrease the learning rate\n    model.alpha -= 0.0002\n    # fix the learning rate, no decay\n    model.min_alpha = model.alpha\n    \nmodel.save(\"d2v.model\")\nprint(\"Model Saved\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loding the model again for future reference\nmodel= Doc2Vec.load(\"d2v.model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_data[4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding document closest to the topic\ndef find_topic(text):\n    topic_list=list(show_topics(H1))\n    distances=[]\n    test_data2=word_tokenize(list_data[n].lower())\n    v2=model.infer_vector(test_data2)\n    for i in range(len(topic_list)):\n        test_data1=word_tokenize(text)\n        v1=model.infer_vector(test_data1)\n        distances.append(scipy.spatial.distance.cosine(v1,v2))\n\n    min_ele = min(distances) \n    topic_no= [i for i, j in enumerate(distances) if j == min_ele] \n    print('The document probably belongs to category:',topic_no)    \n    print('The category is:',show_topics(H1)[topic_no[0]])\nfind_topic(list_data[4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_doc(topic):\n    distances=[]\n    topic_list=list(show_topics(H1))\n    test_data1=word_tokenize(topic_list[topic].lower())\n    v1=model.infer_vector(test_data1)\n    for i in range(len(list_data)):\n        test_data2=word_tokenize(list_data[i].lower())\n        v2=model.infer_vector(test_data2)\n        distances.append(scipy.spatial.distance.cosine(v1,v2))\n        min_ele = min(distances) \n    for j in range(len(distances)):\n        if distances[j]==min_ele:\n            doc_no=j\n    return(list_data[doc_no])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Topic 6 basically is related to articles that dig into the i guess as to how the virus functions \nprint('Topic 6:',show_topics(H1)[6])\ndoc=find_doc(6)\nprint('The document about topic 6 is:',doc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}