{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align ='center'> Bank Review/Complaint Analysis </h1>"},{"metadata":{},"cell_type":"markdown","source":"<h4><i>Central banks collecting information about customer satisfaction with the services provided by different banks. Also collects the information about the complaints.</i></h4>\n<ul>\n<li><i>Bank users give ratings and write reviews about the services on central bank websites. These reviews and ratings help banks evaluate services provided and take necessary action to improve customer service. While ratings are useful to convey the overall experience, they do not convey the context which led a reviewer to that experience.</i></li>\n<li><i>If we look at only the rating, it is difficult to guess why the user rated the service as 4 stars. However, after reading the review, it is not difficult to identify that the review talks about good 'service' and 'experience'.</i></li></ul>"},{"metadata":{},"cell_type":"markdown","source":"<h2>The objetive of the case study is to analyze customer reviews and predict customer satisfaction with the reviews.\n</h2>"},{"metadata":{},"cell_type":"markdown","source":"## Import necesssary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport string\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nimport nltk\nfrom nltk.corpus import wordnet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer = pd.read_csv('../input/bank-reviewcomplaint-analysis/BankReviews.csv', encoding='windows-1252' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Audit"},{"metadata":{"trusted":true},"cell_type":"code","source":"customer.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer['Stars'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.countplot(customer.Stars)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Analysis to find positive and negative reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = customer['Reviews']\nY = customer['Stars']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UDF to find sentiment polarity of the reviews\ndef sentiment_review(text):\n    analysis = TextBlob(text)\n    polarity_text = analysis.sentiment.polarity\n    if polarity_text > 0:\n        return 'Positive'\n    elif polarity_text == 0:\n        return 'Neutral'\n    else:\n        return 'Negative'  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating dictionary which will contain both the review and the sentiment of the review\nfinal_dictionary = []\nfor text in X:\n    dictionary_sentiment = {}\n    dictionary_sentiment['Review'] = text\n    dictionary_sentiment['Sentiment'] = sentiment_review(text)\n    final_dictionary.append(dictionary_sentiment)\nprint(final_dictionary[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding positive reviews\npositive_reviews = []\nfor review in final_dictionary:\n    if review['Sentiment'] =='Positive':\n        positive_reviews.append(review)\nprint(positive_reviews[:5])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding neutral reviews\nneutral_reviews = []\nfor review in final_dictionary:\n    if review['Sentiment'] =='Neutral':\n        neutral_reviews.append(review)\nprint(neutral_reviews[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding negative reviews\nnegative_reviews = []\nfor review in final_dictionary:\n    if review['Sentiment'] =='Negative':\n        negative_reviews.append(review)\nprint(negative_reviews[:5])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# counting number of positive,neutral and negative reviews\nreviews_count = pd.DataFrame([len(positive_reviews),len(neutral_reviews),len(negative_reviews)],index=['Positive','Neutral','Negative'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reviews_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reviews_count.plot(kind='bar')\nplt.ylabel('Reviews Count')   \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# printing first five positive reviews\ni=1\nfor review in positive_reviews[:5]:\n        print(i)\n        print(review['Review'])\n        print('******************************************************')\n        i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing first five negative reviews\ni=1\nfor review in negative_reviews[:5]:\n        print(i)\n        print(review['Review'])\n        print('******************************************************')\n        i+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding most frequently used Positive/ Negative words"},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# UDF to clean the reviews\ndef clean_text(text):\n    text = text.lower()\n    text = text.strip()\n    text = \"\".join([char for char in text if char not in string.punctuation])\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = customer['Reviews']\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying clean_text function defined above to remove punctuation, strip extra spaces and convert each word to lowercase\nX = X.apply(lambda y: clean_text(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Coverting reviews to tokens"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokens_vect = CountVectorizer(stop_words='english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_dtm = tokens_vect.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"tokens_vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"token_dtm.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"token_dtm.toarray().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(tokens_vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.DataFrame(token_dtm.toarray(),columns = tokens_vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(token_dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# creating a dataframe which shows the count of how many times a word is coming in the corpus\ncount_dtm_dataframe = pd.DataFrame(np.sum(token_dtm.toarray(),axis=0),tokens_vect.get_feature_names()).reset_index()\ncount_dtm_dataframe.columns =['Word','Count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"count_dtm_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#adding sentiment column which shows sentiment polarity of each word\nsentiment_word = []\nfor word in count_dtm_dataframe['Word']:\n    sentiment_word.append(sentiment_review(word))\ncount_dtm_dataframe['Sentiment'] = sentiment_word","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"count_dtm_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# separating positive words\npositive_words_df= count_dtm_dataframe.loc[count_dtm_dataframe['Sentiment']=='Positive',:].sort_values('Count',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"positive_words_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# plotting word cloud of 10 most frequently used positive words\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(positive_words_df.iloc[0:11,0]))\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# separating negative words\nnegative_words_df= count_dtm_dataframe.loc[count_dtm_dataframe['Sentiment']=='Negative',:].sort_values('Count',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"negative_words_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# plotting word cloud of 10 most frequently used positive words\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(negative_words_df.iloc[0:11,0]))\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Topic Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Splitting the data into train and test"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X,test_X,train_Y,test_Y = train_test_split(X,Y,random_state = 123, test_size = 0.2)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('No.of observations in train_X: ',len(train_X), '| No.of observations in test_X: ',len(test_X))\nprint('No.of observations in train_Y: ',len(train_Y), '| No.of observations in test_Y: ',len(test_Y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Feature Generation using DTM and TDM"},{"metadata":{},"cell_type":"markdown","source":"### Feature generation using DTM"},{"metadata":{"trusted":false},"cell_type":"code","source":"vect = CountVectorizer(strip_accents='unicode', stop_words='english', ngram_range=(1,1),min_df=0.001,max_df=0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X_fit = vect.fit(train_X)\ntrain_X_dtm = vect.transform(train_X)\ntest_X_dtm = vect.transform(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train_X_dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(test_X_dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('No.of features for are',len(vect.get_feature_names()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X_dtm_df = pd.DataFrame(train_X_dtm.toarray(),columns=vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X_dtm_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Finding how many times a tem is used in corpus\ntrain_dtm_freq = np.sum(train_X_dtm_df,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_dtm_freq.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature generation using TDM"},{"metadata":{"trusted":false},"cell_type":"code","source":"vect_tdm = TfidfVectorizer(strip_accents='unicode', stop_words='english', ngram_range=(1,1),min_df=0.001,max_df=0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X_tdm = vect_tdm.fit_transform(train_X)\ntest_X_tdm = vect.transform(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train_X_tdm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(test_X_tdm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vect_tdm.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('No.of features for are',len(vect_tdm.get_feature_names()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# creating dataframe to to see which features are present in the documents\ntrain_X_tdm_df = pd.DataFrame(train_X_tdm.toarray(),columns=vect_tdm.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X_tdm_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_X_tdm_df = pd.DataFrame(test_X_tdm.toarray(),columns=vect_tdm.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_X_tdm_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Finding how many times a term is used in test corpus\ntest_tdm_freq = np.sum(test_X_tdm_df,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_tdm_freq.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# train a LDA Model\nlda_model = LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=50)\nX_topics = lda_model.fit_transform(train_X_tdm)\ntopic_word = lda_model.components_ \nvocab = vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# view the topic models\ntop_words = 10\ntopic_summaries = []\nfor i, topic_dist in enumerate(topic_word):\n    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(top_words+1):-1]\n    topic_summaries.append(' '.join(topic_words))\n    print(topic_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# view the topic models\ntop_words = 10\ntopic_summaries = []\nfor i, topic_dist in enumerate(topic_word):\n    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(top_words+1):-1]\n    topic_summaries.append(' '.join(topic_words))\ntopic_summaries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Model"},{"metadata":{},"cell_type":"markdown","source":"### Building Model on DTM"},{"metadata":{"trusted":false},"cell_type":"code","source":"# building naive bayes model on DTM\nnaive_model = MultinomialNB()\nnaive_model.fit(train_X_dtm,train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predict_train = naive_model.predict(train_X_dtm)\npredict_test = naive_model.predict(test_X_dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(predict_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Accuracy on train: ',metrics.accuracy_score(train_Y,predict_train))\nprint('Accuracy on test: ',metrics.accuracy_score(test_Y,predict_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# predict probabilities on train and test\npredict_prob_train = naive_model.predict_proba(train_X_dtm)[:,1]\npredict_prob_test = naive_model.predict_proba(test_X_dtm)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('ROC_AUC score on train: ',metrics.roc_auc_score(train_Y,predict_prob_train))\nprint('ROC_AUC score on test: ',metrics.roc_auc_score(test_Y,predict_prob_test))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# confusion matrix on test \ncm_test = metrics.confusion_matrix(test_Y,predict_test,[5,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cm_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(cm_test,annot=True,xticklabels=[5,1],yticklabels=[5,1])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building Model on TDM"},{"metadata":{"trusted":false},"cell_type":"code","source":"# building naive bayes model on DTM\nnaive_model = MultinomialNB()\nnaive_model.fit(train_X_tdm,train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predict_train = naive_model.predict(train_X_tdm)\npredict_test = naive_model.predict(test_X_tdm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(predict_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Accuracy on train: ',metrics.accuracy_score(train_Y,predict_train))\nprint('Accuracy on test: ',metrics.accuracy_score(test_Y,predict_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# predict probabilities on train and test\npredict_prob_train = naive_model.predict_proba(train_X_tdm)[:,1]\npredict_prob_test = naive_model.predict_proba(test_X_tdm)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('ROC_AUC score on train: ',metrics.roc_auc_score(train_Y,predict_prob_train))\nprint('ROC_AUC score on test: ',metrics.roc_auc_score(test_Y,predict_prob_test))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# confusion matrix on test \ncm_test = metrics.confusion_matrix(test_Y,predict_test,[5,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cm_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(cm_test,annot=True,xticklabels=[5,1],yticklabels=[5,1])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Model showed better results using DTM values and using unigrams.</h3>"},{"metadata":{},"cell_type":"markdown","source":"## We were asked that we can ignore intent analysis as that is covered in topic modelling. Hence skipping that part."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}