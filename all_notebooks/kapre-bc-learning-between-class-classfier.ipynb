{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n%timeit\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time, random, sys, os\nimport sklearn.metrics\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nfrom torch.optim.lr_scheduler import _LRScheduler, ReduceLROnPlateau, CosineAnnealingLR\nfrom torch.utils.data.dataset import Dataset\nfrom math import cos, pi\nimport librosa\nfrom scipy.io import wavfile\nimport torch.nn.functional as F\nimport re\npd.options.display.max_rows = 500\npd.options.display.max_columns = 500\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# write label to a file\nimport json\nwith open('./mix_label_json_n6.json','a') as file:\n    file.write(json.dumps({}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file=open('./mix_label_json_n6.json','r+')\nfile.truncate(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file.read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set parameters\nNUM_FOLD = 4\nNUM_CLASS = 10\nSEED = 42\nNUM_EPOCH =10*5\nNUM_CYCLE = 10*5\nBATCH_SIZE = 32\nLR = [1e-1, 1e-8]\nFOLD_LIST = [1]\nCROP_LENGTH = 1000000\nFEATURE_PATH = '../input/urbansound8k'\nOUTPUT_DIR = \"./\"\n\ncudnn.benchmark = True\nstarttime = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BIRD_CODE={\n    'fold1':0,\n    'fold2':1,\n    'fold3':2,\n    'fold4':3\n}\nINV_BIRD_CODE={v:k for k,v in BIRD_CODE.items()}\nINV_BIRD_CODE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.io.wavfile import write\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_gain(sound, fs, min_db=-80.0, mode='RMSE'):\n    if fs <= 32000:\n        n_fft = 2048\n    elif fs <= 44100:\n        n_fft = 4096\n    else:\n        raise Exception('Invalid fs {}'.format(fs))\n    stride = n_fft // 2\n\n    gain = []\n    for i in range(0, len(sound) - n_fft + 1, stride):\n        if mode == 'RMSE':\n            g = np.mean(sound[i: i + n_fft] ** 2)\n        elif mode == 'A_weighting':\n            spec = np.fft.rfft(np.hanning(n_fft + 1)[:-1] * sound[i: i + n_fft])\n            power_spec = np.abs(spec) ** 2\n            a_weighted_spec = power_spec * np.power(10, a_weight(fs, n_fft) / 10)\n            g = np.sum(a_weighted_spec)\n        else:\n            raise Exception('Invalid mode {}'.format(mode))\n        gain.append(g)\n\n    gain = np.array(gain)\n    gain = np.maximum(gain, np.power(10, min_db / 10))\n    gain_db = 10 * np.log10(gain)\n\n    return gain_db\n\n\ndef mix(sound1, sound2, r, fs):\n    gain1 = np.max(compute_gain(sound1, fs))  # Decibel\n    gain2 = np.max(compute_gain(sound2, fs))\n    t = 1.0 / (1 + np.power(10, (gain1 - gain2) / 20.) * (1 - r) / r)\n    sound = ((sound1 * t + sound2 * (1 - t)) / np.sqrt(t ** 2 + (1 - t) ** 2))\n    sound = sound.astype(np.float32)\n\n    return sound\n\n\nclass WaveDataset(Dataset):\n    def __init__(self, X, y,\n                 crop=-1, crop_mode='original', padding=0,\n                 mixup=False, scaling=-1, gain=-1,\n                 fs=44100,\n                 ):\n        self.X = X\n        self.y = y\n        self.crop = crop\n        self.crop_mode = crop_mode\n        self.padding = padding\n        self.mixup = mixup\n        self.scaling = scaling\n        self.gain = gain\n        self.fs = fs\n        self.idx_cnt=0\n\n    def preprocess(self, sound):\n        for f in self.preprocess_funcs:\n            sound = f(sound)\n\n        return sound\n\n    def do_padding(self, snd):\n        snd_new = np.pad(snd, self.padding, 'constant')\n        return snd_new\n\n    def do_crop(self, snd):\n        if self.crop_mode=='random':\n            shift = np.random.randint(0, snd.shape[0] - self.crop)\n            snd_new = snd[shift:shift + self.crop]\n        else:\n            snd_new = snd\n        return snd_new\n\n    def do_gain(self, snd):\n        snd_new = snd * np.power(10, random.uniform(-self.gain, self.gain) / 20.0)\n        return snd_new\n\n    def do_scaling(self, snd, interpolate='Nearest'):\n        scale = np.power(self.scaling, random.uniform(-1, 1))\n        output_size = int(len(snd) * scale)\n        ref = np.arange(output_size) / scale\n        if interpolate == 'Linear':\n            ref1 = ref.astype(np.int32)\n            ref2 = np.minimum(ref1+1, len(snd)-1)\n            r = ref - ref1\n            snd_new = snd[ref1] * (1-r) + snd[ref2] * r\n        elif interpolate == 'Nearest':\n            snd_new = snd[ref.astype(np.int32)]\n        else:\n            raise Exception('Invalid interpolation mode {}'.format(interpolate))\n\n        return snd_new\n\n    def do_mixup(self, snd, label, alpha=1):\n        idx2 = np.random.randint(0, len(self.X))\n        snd2, _ = librosa.core.load(os.path.join(self.X, \"fold\"+str(self.y['fold'][idx2]), self.y['slice_file_name'][idx2]), res_type=\"kaiser_fast\")\n        label2 = np.zeros(10).astype(np.float32)\n        label2[BIRD_CODE[\"fold\"+str(self.y['fold'][idx2])]] = 1.0\n        if self.scaling!=-1:\n            snd2 = self.do_scaling(snd2)\n        snd2 = self.do_padding(snd2)\n        snd2 = self.do_crop(snd2)\n\n        rate = np.random.beta(alpha, alpha)\n        snd_new = mix(snd, snd, rate, self.fs)\n        label_new = label * rate + label2 * (1 - rate)\n        save_mixed_sound(label,label2,label_new,snd_new,self.idx_cnt)#save the mixed sound #######\n        self.idx_cnt=self.idx_cnt+1\n        return snd_new, label_new\n\n    def __getitem__(self, index):\n        snd, _ = librosa.core.load(os.path.join(self.X, \"fold\"+str(self.y['fold'][index]), self.y['slice_file_name'][index]), res_type=\"kaiser_fast\")\n        # print(snd.shape)\n        label = np.zeros(10).astype(np.float32)\n        label[BIRD_CODE[\"fold\"+str(self.y['fold'][index])]] = 1.0\n        if self.scaling!=-1:\n            snd = self.do_scaling(snd)\n        snd = self.do_padding(snd)\n        snd = self.do_crop(snd)\n        if self.mixup:\n            snd, label = self.do_mixup(snd, label)\n        if self.gain!=-1:\n            snd = self.do_gain(snd)\n        snd = snd.reshape([1, 1, -1]).astype(np.float32) / 32768.0\n        return snd, label\n\n    def __len__(self):\n        return len(self.X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_mixed_sound(label1,label2,label_new,snd_new,idx_cnt):\n        idx1=0\n        idx2=0\n        sum_idx=\"\"\n        for i in range(len(label1)):\n            if label1[i]>0:\n                idx1=i\n                break\n        for i in range(len(label2)):\n            if label2[i]>0:\n                idx2=i\n                break\n        if idx2>idx1:\n            sum_idx=str(idx2)+str(idx1)\n        else:\n            sum_idx=str(idx1)+str(idx2)\n        file_name='sound_mix'+'_'+str(random.randint(10000,20000))+\"_\"+str(random.randint(1,10000))+'.wav'\n        #print(file_name)\n        idx_cnt+=1\n        write('./'+file_name,44100,snd_new)\n        s=str(label_new)\n        s=s.split(\" \")\n        lb=[]\n        for a in s: \n            if len(a)>0:\n                a=(re.findall(r\"\\d*\\.\\d+|\\d+\",a)) # fetch label\n                if len(a)>0:\n                    if a[0]!=\"0\":\n                        lb.append(float(a[0]))\n                    else:\n                        lb.append(int(a[0]))\n                else:\n                    lb.append(0)\n        file_label={file_name:lb}\n       # df_mix.loc[idx_cnt]=[file_name,sum_idx]\n        with open('./mix_label_json_n6.json','a') as jsonf:\n            jsonf.write(json.dumps(file_label))\n       # print(\"file_name--\",file_name)\n       # print(\"new_label--\",label_new)\n\n        #print(\"error occur_saving mixed file\",e)\n      \n      \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _one_sample_positive_class_precisions(scores, truth):\n    \"\"\"Calculate precisions for each true class for a single sample.\n\n    Args:\n      scores: np.array of (num_classes,) giving the individual classifier scores.\n      truth: np.array of (num_classes,) bools indicating which classes are true.\n\n    Returns:\n      pos_class_indices: np.array of indices of the true classes for this sample.\n      pos_class_precisions: np.array of precisions corresponding to each of those\n        classes.\n    \"\"\"\n    num_classes = scores.shape[0]\n    pos_class_indices = np.flatnonzero(truth > 0)\n    # Only calculate precisions if there are some true classes.\n    if not len(pos_class_indices):\n        return pos_class_indices, np.zeros(0)\n    # Retrieval list of classes for this sample.\n    retrieved_classes = np.argsort(scores)[::-1]\n    # class_rankings[top_scoring_class_index] == 0 etc.\n    class_rankings = np.zeros(num_classes, dtype=np.int)\n    class_rankings[retrieved_classes] = range(num_classes)\n    # Which of these is a true label?\n    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n    retrieved_class_true[class_rankings[pos_class_indices]] = True\n    # Num hits for every truncated retrieval list.\n    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n    precision_at_hits = (\n            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n            (1 + class_rankings[pos_class_indices].astype(np.float)))\n    return pos_class_indices, precision_at_hits\n\n\n# All-in-one calculation of per-class lwlrap.\n\ndef calculate_per_class_lwlrap(truth, scores):\n    \"\"\"Calculate label-weighted label-ranking average precision.\n\n    Arguments:\n      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n        of presence of that class in that sample.\n      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n        test's real-valued score for each class for each sample.\n\n    Returns:\n      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n        class.\n      weight_per_class: np.array of (num_classes,) giving the prior of each\n        class within the truth labels.  Then the overall unbalanced lwlrap is\n        simply np.sum(per_class_lwlrap * weight_per_class)\n    \"\"\"\n    assert truth.shape == scores.shape\n    num_samples, num_classes = scores.shape\n    # Space to store a distinct precision value for each class on each sample.\n    # Only the classes that are true for each sample will be filled in.\n    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n    for sample_num in range(num_samples):\n        pos_class_indices, precision_at_hits = (\n            _one_sample_positive_class_precisions(scores[sample_num, :],\n                                                  truth[sample_num, :]))\n        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n            precision_at_hits)\n    labels_per_class = np.sum(truth > 0, axis=0)\n    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n    # Form average of each column, i.e. all the precisions assigned to labels in\n    # a particular class.\n    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n                        np.maximum(1, labels_per_class))\n    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n    #                = np.sum(per_class_lwlrap * weight_per_class)\n    return per_class_lwlrap, weight_per_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef cycle(iterable):\n    \"\"\"\n    convert dataloader to iterator\n    :param iterable:\n    :return:\n    \"\"\"\n    while True:\n        for x in iterable:\n            yield x\n\n\nclass CosineLR(_LRScheduler):\n    \"\"\"cosine annealing.\n    \"\"\"\n    def __init__(self, optimizer, step_size_min=1e-5, t0=100, tmult=2, curr_epoch=-1, last_epoch=-1):\n        self.step_size_min = step_size_min\n        self.t0 = t0\n        self.tmult = tmult\n        self.epochs_since_restart = curr_epoch\n        super(CosineLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        self.epochs_since_restart += 1\n\n        if self.epochs_since_restart > self.t0:\n            self.t0 *= self.tmult\n            self.epochs_since_restart = 0\n\n        lrs = [self.step_size_min + (\n                0.5 * (base_lr - self.step_size_min) * (1 + cos(self.epochs_since_restart * pi / self.t0)))\n               for base_lr in self.base_lrs]\n\n        return lrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvBnRelu(nn.Module):\n    def __init__(self, in_channel, out_channel, kernel_size, stride=1, padding=0, dilation=1, groups=1):\n        super(ConvBnRelu, self).__init__()\n        self.conv_bn_relu = nn.Sequential(\n            nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, dilation, groups, False),\n            nn.BatchNorm2d(out_channel),\n            nn.ReLU(True))\n\n    def forward(self, x):\n        return self.conv_bn_relu(x)\n\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.size()[0], -1)\n\n\nclass EnvNetv2(nn.Module):\n    def __init__(self, num_classes=1):\n        super(EnvNetv2, self).__init__()\n        self.conv1 = ConvBnRelu(1, 32, (1, 64), stride=(1, 2))\n        self.conv2 = ConvBnRelu(32, 64, (1, 16), stride=(1, 2))\n        self.conv3 = ConvBnRelu(1, 32, (8, 8))\n        self.conv4 = ConvBnRelu(32, 32, (8, 8))\n        self.conv5 = ConvBnRelu(32, 64, (1, 4))\n        self.conv6 = ConvBnRelu(64, 64, (1, 4))\n        self.conv7 = ConvBnRelu(64, 128, (1, 2))\n        self.conv8 = ConvBnRelu(128, 128, (1, 2))\n        self.conv9 = ConvBnRelu(128, 256, (1, 2))\n        self.conv10 = ConvBnRelu(256, 256, (1, 2))\n        self.maxpool1 = nn.MaxPool2d((1, 64), stride=(1, 64))\n        self.maxpool2 = nn.MaxPool2d((5, 3), stride=(5, 3))\n        self.maxpool3 = nn.MaxPool2d((1, 2), stride=(1, 2))\n        self.gmp = nn.AdaptiveMaxPool2d((10, 1))\n        self.flatten = Flatten()\n        self.last_linear1 = nn.Sequential(\n            nn.Linear(256 * 10, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Linear(1024, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(1024, num_classes),\n        )\n        self.last_linear2 = nn.Sequential(\n            nn.Linear(256 * 10, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.2),\n            nn.Linear(1024, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(1024, num_classes),\n        )\n\n    def forward(self, input):\n        h = self.conv1(input)\n        h = self.conv2(h)\n        h = self.maxpool1(h)\n        h = h.transpose(1, 2)\n        h = self.conv3(h)\n        h = self.conv4(h)\n        h = self.maxpool2(h)\n        h = self.conv5(h)\n        h = self.conv6(h)\n        h = self.maxpool3(h)\n        h = self.conv7(h)\n        h = self.conv8(h)\n        h = self.maxpool3(h)\n        h = self.conv9(h)\n        h = self.conv10(h)\n        h = self.gmp(h)\n        h = self.flatten(h)\n        h = self.last_linear1(h)\n        return h","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(train_loaders, model, optimizer, scheduler, epoch):\n    train_loader = train_loaders\n    kl_avr = AverageMeter()\n    bce_avr = AverageMeter()\n    lsigmoid = nn.LogSigmoid().cuda()\n    lsoftmax = nn.LogSoftmax(dim=1).cuda()\n    softmax = nn.Softmax(dim=1).cuda()\n    criterion_kl = nn.KLDivLoss().cuda()\n    criterion_bce = nn.BCEWithLogitsLoss().cuda()\n\n    # switch to train mode\n    model.train()\n\n    # training\n    preds = np.zeros([0, NUM_CLASS], np.float32)\n    y_true = np.zeros([0, NUM_CLASS], np.float32)\n    for i, (input, target) in enumerate(train_loader):\n        # get batches\n        input = torch.autograd.Variable(input.cuda())\n        target = torch.autograd.Variable(target.cuda())\n\n        # compute output\n        output = model(input)\n        kl = criterion_kl(lsoftmax(output), target)\n        bce = criterion_bce(output, target)\n        loss = bce\n        pred = softmax(output)\n        pred = pred.data.cpu().numpy()\n\n        # backprop\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step(metrics=loss)  # metrics=loss\n\n        # record log\n        kl_avr.update(kl.data, input.size(0))\n        bce_avr.update(bce.data, input.size(0))\n        preds = np.concatenate([preds, pred])\n        y_true = np.concatenate([y_true, target.data.cpu().numpy()])\n\n    # calc metric\n    per_class_lwlrap, weight_per_class = calculate_per_class_lwlrap(y_true, preds)\n    lwlrap = np.sum(per_class_lwlrap * weight_per_class)\n\n    return kl_avr.avg.item(), lwlrap, bce_avr.avg.item()\n\n\ndef validate(val_loader, model):\n    kl_avr = AverageMeter()\n    bce_avr = AverageMeter()\n    lsoftmax = nn.LogSoftmax(dim=1).cuda()\n    softmax = torch.nn.Softmax(dim=1).cuda()\n    criterion_kl = nn.KLDivLoss().cuda()\n    criterion_bce = nn.BCEWithLogitsLoss().cuda()\n\n    # switch to eval mode\n    model.eval()\n\n    # validate\n    preds = np.zeros([0, NUM_CLASS], np.float32)\n    y_true = np.zeros([0, NUM_CLASS], np.float32)\n    for i, (input, target) in enumerate(val_loader):\n        # get batches\n        input = torch.autograd.Variable(input.cuda())\n        target = torch.autograd.Variable(target.cuda())\n\n        # compute output\n        with torch.no_grad():\n            output = model(input)\n            kl = criterion_kl(lsoftmax(output), target)\n            bce = criterion_bce(output, target)\n            pred = softmax(output)\n            pred = pred.data.cpu().numpy()\n\n        # record log\n        kl_avr.update(kl.data, input.size(0))\n        bce_avr.update(bce.data, input.size(0))\n        preds = np.concatenate([preds, pred])\n        y_true = np.concatenate([y_true, target.data.cpu().numpy()])\n\n    # calc metric\n    per_class_lwlrap, weight_per_class = calculate_per_class_lwlrap(y_true, preds)\n    lwlrap = np.sum(per_class_lwlrap * weight_per_class)\n\n    return kl_avr.avg.item(), lwlrap, bce_avr.avg.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/urbansound8k/UrbanSound8K.csv\")\ndf_train['fold'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#filter_four_folder\ndf_train_fil=df_train[(df_train[\"fold\"]==1) | (df_train[\"fold\"]==2) | (df_train[\"fold\"]==3) |(df_train[\"fold\"]==4) ]\ndf_train_fil['fold'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_fil.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load table data\n#df_train = pd.read_csv(\"../input/birdsong-recognition/train.csv\")\n\n#     + pd.read_csv(\"../input/xeno-canto-bird-recordings-extended-a-m/train_extended.csv\")\n#     + pd.read_csv(\"../input/xeno-canto-bird-recordings-extended-n-z/train_extended.csv\")\n#df_test = pd.read_csv(\"../input/birdcall-check/test.csv\")\n#sub = pd.read_csv(\"../input/birdsong-recognition/sample_submission.csv\")\n\n# fold splitting\n#folds = list(KFold(n_splits=NUM_FOLD, shuffle=True, random_state=SEED).split(np.arange(len(df_train))))\nfolds = list(StratifiedKFold(n_splits=NUM_FOLD, shuffle=True, random_state=SEED).split(df_train_fil, df_train_fil[\"fold\"]))\n\n# Training\nlog_columns = ['epoch', 'kl', 'bce', 'lwlrap', 'val_kl', 'val_bce', 'val_lwlrap', 'time']\nfor fold, (ids_train_split, ids_valid_split) in enumerate(folds):\n    if fold+1 not in FOLD_LIST: continue\n    print(\"fold: {}\".format(fold + 1))\n    train_log = pd.DataFrame(columns=log_columns)\n\n    # build model\n    model = EnvNetv2(NUM_CLASS).cuda()\n\n    # prepare data loaders\n    df_train_fold = df_train_fil.iloc[ids_train_split].reset_index(drop=True)\n    dataset_train = WaveDataset(FEATURE_PATH, df_train_fold,\n                                crop=CROP_LENGTH, crop_mode='random', padding=CROP_LENGTH//2,\n                                mixup=True, scaling=1.25, gain=6\n                                )\n    train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE,\n                                shuffle=True, num_workers=1, pin_memory=True,\n                                )\n\n   # df_valid = df_train.iloc[ids_valid_split].reset_index(drop=True)\n   # dataset_valid = WaveDataset(FEATURE_PATH, df_valid, padding=CROP_LENGTH//2)\n   # valid_loader = DataLoader(dataset_valid, batch_size=1,\n                                #shuffle=False, num_workers=1, pin_memory=True,\n                               # )\n\n    # set optimizer and loss\n    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=LR[0], momentum = 0.9, nesterov = True)\n    # optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR[0])\n    # scheduler = CosineLR(optimizer, step_size_min=LR[1], t0=len(train_loader) * NUM_CYCLE, tmult=1)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold=0.0001, min_lr=0.00000001)\n    # scheduler = CosineAnnealingLR(optimizer, T_max=10)\n\n    # training\n    best_val = 999\n    for epoch in range(NUM_EPOCH):\n        # train for one epoch\n        kl, lwlrap, bce = train(train_loader, model, optimizer, scheduler, epoch)\n\n        # evaluate on validation set\n        #val_kl, val_lwlrap, val_bce = validate(valid_loader, model)\n\n        # print log\n        endtime = time.time() - starttime\n        print(\"Epoch: {}/{} \".format(epoch + 1, NUM_EPOCH) + \"KL: {:.4f} \".format(kl) + \"BCE: {:.4f} \".format(bce)  + \"LwLRAP: {:.4f} \".format(lwlrap) + \"sec: {:.1f}\".format(endtime))\n\n        # save log and weights\n       # train_log_epoch = pd.DataFrame(\n         #   [[epoch+1, kl, bce, lwlrap, val_kl, val_bce, val_lwlrap, endtime]], columns=log_columns)\n       # train_log = pd.concat([train_log, train_log_epoch])\n       # train_log.to_csv(\"{}/train_log_fold{}.csv\".format(OUTPUT_DIR, fold+1), index=False)\n      #  if (epoch+1)%NUM_CYCLE==0:\n      #      torch.save(model.state_dict(), \"{}/weight_fold_{}_epoch_{}.pth\".format(OUTPUT_DIR, fold+1, epoch+1))\n      #  if best_val > val_bce:\n       #     torch.save(model.state_dict(), \"{}/weight_fold_{}_epoch_best.pth\".format(OUTPUT_DIR, fold+1))\n        #    best_val = val_bce","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mix=pd.DataFrame(columns=[\"file_name\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" len(os.listdir('./'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ncnt=0\nfor file in os.listdir('./'):\n    if \"wav\" in file:\n        df_mix.loc[cnt]=[file]\n        cnt+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mix.to_csv('./urban_mix_sound_n6.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove silence noise\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf_m=pd.read_csv('../input/urban-mix-sound-n2/urban_mix_sound_n6.csv')\ndf_m.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pydub import AudioSegment\n\ndef detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):\n    '''\n    sound is a pydub.AudioSegment\n    silence_threshold in dB\n    chunk_size in ms\n\n    iterate over chunks until you find the first one with sound\n    '''\n    trim_ms = 0 # ms\n\n    assert chunk_size > 0 # to avoid infinite loop\n    while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n        trim_ms += chunk_size\n\n    return trim_ms\n\ndef remove_silence_sound(file_name):\n    sound = AudioSegment.from_file('../input/mix-sound-urban-n/'+file_name, format=\"wav\")\n    start_trim = detect_leading_silence(sound)\n    end_trim = detect_leading_silence(sound.reverse())\n    duration = len(sound)    \n    trimmed_sound = sound[start_trim:duration-end_trim]   \n    return trimmed_sound","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(df_m.shape[0]):\n    try:\n        file_name=df_m['file_name'][i]\n        trimmed_sound=remove_silence_sound(file_name)\n        trimmed_sound.export('./'+file_name,format=\"wav\")\n    except Exception as e:\n        print(\"Exception in writing sound file\",e)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\nsnd=IPython.display.Audio('./sound_mix-30-99710.wav')\nsnd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}