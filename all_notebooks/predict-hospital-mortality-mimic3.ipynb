{"cells":[{"metadata":{"_uuid":"a2674bc3a39801e35ebd9798fc97426238f3803b"},"cell_type":"markdown","source":"* The original data is from MIMIC3 - Multiparameter Intelligent Monitoring in Intensive Care (deidentified DB) available freely from https://physionet.org/\n* Each instance in the mldata.csv attached is one admission\n* Testing a theory I have, that one can predict Mortality just by the number of interactions betweeen patient and hospital per day, I've used the following features for the Mortality prediction as a Classification problem:\n* Age, Gender, Admission Type, Admission Source\n* Daily average number of: Labs, Micro labs, IV meds, Non-IV meds, Imaging Reports, Notes, Orders, Caregivers, Careunits, etc\n* The label is Hospital Mortality \n\nI've removed the LOS from the features as it may give a hint on the patient outcome as a leak from the future...\n\n* Random Forest vs NN on Accuracy, F1 score, ROC AUC"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# IMPORT modules\n# Turn GPU on\n\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport pprint\nfrom itertools import cycle, islice\nimport numpy as np\n\nfrom scipy.stats import multivariate_normal\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, ShuffleSplit\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc\nfrom sklearn.utils.fixes import signature\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load MIMIC2 data \n\ndata = pd.read_csv('../input/mimic3c/mimic3c.csv')\nprint(\"With id\", data.shape)\n\ndata_full = data.drop('hadm_id', 1)\nprint(\"No id\",data_full.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4caf0527fb3aa5e487ae32aa3ddc88e402c881ac"},"cell_type":"code","source":"print(data_full.shape)\ndata_full.info()\ndata_full.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3fb931ad0b44335da723ff4ba6b682282053bf3"},"cell_type":"code","source":"data_full.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"065cf6f19d234ee3c9eea768f3a011405f5c5353"},"cell_type":"code","source":"data_full.hist(bins=50, figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83ae9f774562dd67c07fc679b7e272b774022c0b"},"cell_type":"code","source":"age_histogram = data_full.hist(column='age', bins=20, range=[0, 100])\nfor ax in age_histogram.flatten():\n    ax.set_xlabel(\"Age\")\n    ax.set_ylabel(\"Num. of Patients\")\nplt.show()\ndata_full.groupby('ExpiredHospital').size().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e79fc43938776df54e39607ab4d29eb6747094c"},"cell_type":"code","source":"# Label = ExpiredHospital\ny = data_full['ExpiredHospital']\nX = data_full.drop('ExpiredHospital', 1)\n\nX = X.drop('LOSdays', 1)\nX = X.drop('LOSgroupNum', 1)\nX = X.drop('AdmitDiagnosis', 1)\nX = X.drop('AdmitProcedure', 1)\nX = X.drop('marital_status', 1)\nX = X.drop('ethnicity', 1)\nX = X.drop('religion', 1)\nX = X.drop('insurance', 1)\n\nprint(\"y - Labels\", y.shape)\nprint(\"X - No Label No id \", X.shape)\nprint(X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23cb75f78120552ed8c09d96d6782fd28c0e506f"},"cell_type":"code","source":"# Check that all X columns have no missing values\nX.info()\nX.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b7f84082dc76270304c1acad39d1316c5e6ecc4"},"cell_type":"code","source":"data_full.groupby('ExpiredHospital').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_type').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_location').size().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15b855d927a517112efc388fa3a1988e1a40faf6"},"cell_type":"code","source":"# MAP Text to Numerical Data with one-hot-encoding to convert categorical features to numerical\n\nprint(X.shape)\ncategorical_columns = [\n                    'gender',                     \n                    'admit_type',\n                    'admit_location'\n                      ]\nfor col in categorical_columns:\n    #if the original column is present replace it with a one-hot\n    if col in X.columns:\n        one_hot_encoded = pd.get_dummies(X[col])\n        X = X.drop(col, axis=1)\n        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n        \nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97df06fa752419a3aba9fbf4e3d5ab244e66e4e9"},"cell_type":"code","source":"print(X.columns)\n#print(X['VENTRICULOSTOMY          '])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8d57b4c62d89971e0f5660fec3771bb94bf4843f"},"cell_type":"code","source":"print(data_full.shape)\nprint(X.shape)\n\nXnotNorm = X.copy()\nprint('XnotNorm ', XnotNorm.shape)\n\n#yFI = data_full.expired_icu\nynotNorm = y.copy()\nprint('ynotNorm ', ynotNorm.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f96cd3de1cc5df7c0b9c295205a0069a3bf19cc"},"cell_type":"code","source":"# Normalize X\n\nx = XnotNorm.values #returns a numpy array\nscaler = preprocessing.StandardScaler()\nx_scaled = scaler.fit_transform(x)\nXNorm = pd.DataFrame(x_scaled, columns=XnotNorm.columns)\nprint(XNorm)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7abef1f1fd638d4134bf87154aec96debf2c20b"},"cell_type":"code","source":"# SPLIT into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.1, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9f1fc3a3335edd35204cb21a22ba3a04c357c4b"},"cell_type":"code","source":"# Test Models and evaluation metric\nseed = 7\nscoring = 'accuracy' \n\n# Spot Check Algorithms\nMymodels = []\n#Mymodels.append(('LogReg', LogisticRegression()))\nMymodels.append(('RandomForest', RandomForestClassifier()))\n#Mymodels.append(('SGDclassifier', SGDClassifier()))\n#Mymodels.append(('KNearestNeighbors', KNeighborsClassifier()))\n#Mymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n#Mymodels.append(('GaussianNB', GaussianNB()))\n#Mymodels.append(('SVM', SVC()))\n\n# Evaluate each model in turn\nresults = []\nnames = []\nfor name, model in Mymodels:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b9e6da5502d457ac515978f3cbd4bfa4baaaa03","trusted":true},"cell_type":"markdown","source":"# Optimize hyper params for one model\n\nmodel = RandomForestClassifier()\n\nparam_grid = [{},]\n\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(XNorm, y)\n\nprint(grid_search.best_estimator_)"},{"metadata":{"trusted":true,"_uuid":"26703de54f7966b326ecf447bf3a1ac85ee18370"},"cell_type":"code","source":"# Set the model according to above results\n\nmodel = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fab4d5af0f342cfcd0778a4352dfb7433b0c7a1"},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Error\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = 1-np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = 1-np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"658f2b60956f375c6db4488ff0562eff5b2e2203"},"cell_type":"code","source":"# LEARNING CURVES Train / Validation\n\ntitle = \"Learning Curves \"\ncv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\nplot_learning_curve(model, title, XNorm, y, cv=cv, n_jobs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deee22f15f456818d8689d72411fc74d8c6d4511"},"cell_type":"code","source":"# Model FINAL fit and evaluation on test\n\nmodel.fit(X_train, y_train)\nfinal_predictions = model.predict(X_test)\n\n#final_acc = accuracy(y_test, final_predictions)\n# Confusion matrix\n\nconf_mx = confusion_matrix(y_test, final_predictions)\n\nTN = conf_mx[0,0]\nFP = conf_mx[0,1]\nFN = conf_mx[1,0]\nTP = conf_mx[1,1]\n\nprint ('TN: ', TN)\nprint ('FP: ', FP)\nprint ('FN: ', FN)\nprint ('TP: ', TP)\n\nrecall = TP/(TP+FN)\nprecision = TP/(TP+FP)\n\nprint (recall, precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae95be8fd81bcf238dc2065f8193f16e36402d8b"},"cell_type":"code","source":"def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88c6fca77e49ef721c7d8f2ae6d7dc44f461ef8d"},"cell_type":"code","source":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = ['lived', 'died'],\n                      title        = \"Confusion Matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e54af3e768f47fa918b47c25bc5ce7cf85717a3c"},"cell_type":"code","source":"print ('precision ',round(precision_score(y_test, final_predictions),4))\nprint ('recall ',round(recall_score(y_test, final_predictions) ,4))\nprint ('accuracy ',round(accuracy_score(y_test, final_predictions),4))\nprint ('F1 score ',round(f1_score(y_test, final_predictions),4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d161527f1125fdaf8573e803f8ac9f4090f5dfad"},"cell_type":"code","source":"# FEATURE IMPORTANCE \n\ntrainFinalFI = XNorm\nyFinalFI = y\nmodel.fit(trainFinalFI,yFinalFI)\n\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model[FI_model[\"Feature Importance\"] > 0.01].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\nplt.xticks(rotation=90)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf27f4679fc2222012b6404a856ab2d3197a180"},"cell_type":"code","source":"# List of important features for model\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model=FI_model.sort_values('Feature Importance', ascending = False)\nprint(FI_model[FI_model[\"Feature Importance\"] > 0.0025])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69c75f297f1aa7e2d2aab8dd17321a750e7e65a1"},"cell_type":"code","source":"# AUC/ROC curves should be used when there are roughly equal numbers of observations for each class\n# Precision-Recall curves should be used when there is a moderate to large class imbalance\n\n# calculate AUC\nauc = roc_auc_score(y_test, final_predictions)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, final_predictions)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.title('AUC for ROC')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b208a76cc93c720092853a6d5fd4c7b7e5ce423"},"cell_type":"code","source":"# Modify the raw final_predictions - prediction probs into 0 and 1\n\nPreds = final_predictions.copy()\n#print(len(Preds))\n#print(Preds)\nPreds[ np.where( Preds >= 0.5 ) ] = 1\nPreds[ np.where( Preds < 0.5 ) ] = 0\n\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, Preds)\n# calculate F1 score\nf1 = f1_score(y_test, Preds)\nprint('f1=%.3f' % (f1))\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the roc curve for the model\nplt.plot(recall, precision, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"947306b39bf141fa1edc8ebc613fa7b5361004c2"},"cell_type":"markdown","source":"# NN"},{"metadata":{"trusted":true,"_uuid":"463d8b9dccc8291149f3de657d2033046b91a777"},"cell_type":"code","source":"# NN MODEL\n\n# Use of DROPOUT\nmodel = models.Sequential()\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(30,)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nprint(model.summary())\n\n# FIT / TRAIN model\n\nNumEpochs = 100\nBatchSize = 16\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-5), loss='binary_crossentropy', metrics=['binary_accuracy'])\nhistory = model.fit(X_train, y_train, epochs=NumEpochs, batch_size=BatchSize, validation_data=(X_test, y_test))\n\nresults = model.evaluate(X_test, y_test)\nprint(\"_\"*100)\nprint(\"Test Loss and Accuracy\")\nprint(\"results \", results)\nhistory_dict = history.history\nhistory_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2757fb20709664d149cd84ab4ab2e151fdf3243"},"cell_type":"code","source":"# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['binary_accuracy']\nval_acc_values = history_dict['val_binary_accuracy']\nepochs = range(1, (len(history_dict['binary_accuracy']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df20f87b1b047ea7721a0e3e9bd1add45f9b87ea"},"cell_type":"code","source":"# Final Fit / Predict\n\n# NOTE final_predictions is a list of probabilities\n#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n#history = model.fit(X_train, y_train, epochs=NumEpochs, batch_size=BatchSize)\n\nfinal_predictions = model.predict(X_test)\nfinal_predictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7525adae5ef7ef8a2f72910fc2b8eec057662aea"},"cell_type":"code","source":"# Modify the raw final_predictions - prediction probs into 0 and 1\n\nPreds = final_predictions.copy()\n#print(len(Preds))\n#print(Preds)\nPreds[ np.where( Preds >= 0.5 ) ] = 1\nPreds[ np.where( Preds < 0.5 ) ] = 0\n#print(Preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76c30cd9ac5e1c483bb1b6ff36adf6ee6e41fa13"},"cell_type":"code","source":"\n# Confusion matrix\n\nconf_mx = confusion_matrix(y_test, Preds)\n\nTN = conf_mx[0,0]\nFP = conf_mx[0,1]\nFN = conf_mx[1,0]\nTP = conf_mx[1,1]\n\nprint ('TN: ', TN)\nprint ('FP: ', FP)\nprint ('FN: ', FN)\nprint ('TP: ', TP)\n\nrecall = TP/(TP+FN)\nprecision = TP/(TP+FP)\n\nprint (recall, precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"576b5dd04669cbf7b3276dc13288b4c4060eb022"},"cell_type":"code","source":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = ['lived', 'died'],\n                      title        = \"Confusion Matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f915a9d0a4979953930d31b8d83bf07290eda8c"},"cell_type":"code","source":"print ('precision ',precision_score(y_test, Preds))\nprint ('recall ',recall_score(y_test, Preds) )\nprint ('accuracy ',accuracy_score(y_test, Preds))\nprint ('F1 score ',f1_score(y_test, Preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c2eb6bbf0e63aabfb71d19db269b72c58ed1726"},"cell_type":"code","source":"# AUC/ROC curves should be used when there are roughly equal numbers of observations for each class\n# Precision-Recall curves should be used when there is a moderate to large class imbalance\n\n# calculate AUC\nauc = roc_auc_score(y_test, Preds)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, Preds)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC ')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d01c37788928ba87dcc89ede9b2cd9d6b9525f34"},"cell_type":"code","source":"# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, Preds)\n# calculate F1 score\nf1 = f1_score(y_test, Preds)\n# calculate precision-recall AUC\n#auc = auc(recall, precision)\n# calculate average precision score\nap = average_precision_score(y_test, Preds)\nprint('f1=%.3f ap=%.3f' % (f1, ap))\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the roc curve for the model\nplt.plot(recall, precision, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}