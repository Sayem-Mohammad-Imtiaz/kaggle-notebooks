{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom nltk.tokenize import WordPunctTokenizer\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/nyc-jobs.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Post Until'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Post Until', 'Recruitment Contact'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.isna().values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Posting Date', 'Posting Updated', 'Process Date'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Average Salary'] = (df['Salary Range To'] + df['Salary Range From']) / 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Salary Range From'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Salary Range To'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Average Salary'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Log Avg Salary'] = np.log(df['Average Salary'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Log Avg Salary']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['Average Salary'])\n# plt.hist(df['Log1p Avg Salary'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Average Salary'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Log10 Avg Salary'] = np.log10(df['Average Salary'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['Log10 Avg Salary'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_cols = df[['Business Title', 'Minimum Qual Requirements', 'Preferred Skills', 'Preferred Skills']]\n# df['Minimum Qual Requirements'] = df['Minimum Qual Requirements'].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenize = WordPunctTokenizer()\n\nfor col in text_cols:\n    df[col] = list(map(' '.join, map(tokenizer.tokenize, map(str.lower, df[col].astype('str')))))\n# tokens = [tokenize.tokenize(word) for word in df['Minimum Qual Requirements']]\n# for word in df['Minimum Qual Requirements']:\n#     tokens.append(tokenize.tokenize(word))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = df[['Business Title', 'Minimum Qual Requirements', 'Preferred Skills', 'Preferred Skills', 'Log Avg Salary']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\ntoken_counts = Counter()\n# for col in df['Business Title']:\n#     token_counts.update(col.split())\n# for col in df['Minimum Qual Requirements']:\n#     token_counts.update(col.split())\nfor cols in text_cols:\n    for col in df[cols]:\n        token_counts.update(col.split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token_counts.most_common()[:100:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_accurence = 10\n\ntokens = {token for token, count in token_counts.items()\n             if count >= min_accurence}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocabulary_size = len(tokens)\nprint('Vocabulary size: ', vocabulary_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNK, PAD = 'UNK', 'PAD'\ntokens = [UNK, PAD] + sorted(tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from collections import defaultdict\n# D = defaultdict()\n# for i, s in enumerate(tokens):\n#      D[s].append(i)\ndict(((string, dict(i for i,w in enumerate(tokens) if w == string)) for string in tokens))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNK_IX, PAD_IX = str(map(D.get, [UNK, PAD]))\n\ndef as_matrix(sequences, max_len=None):\n    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n    if isinstance(sequences[0], str):\n        sequences = list(map(str.split, sequences))\n        \n    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n    \n    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n    for i,seq in enumerate(sequences):\n        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n        matrix[i, :len(row_ix)] = row_ix\n    \n    return matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Lines:\")\nprint('\\n'.join(df[\"Business Title\"][::1000].values), end='\\n\\n')\nprint(\"Matrix:\")\nprint(as_matrix(df[\"Business Title\"][::1000]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(as_matrix(df[\"Business Title\"][::1000]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PAD_IX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}