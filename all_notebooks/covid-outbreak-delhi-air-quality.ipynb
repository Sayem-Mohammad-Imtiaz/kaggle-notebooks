{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly\nplotly.offline.init_notebook_mode(connected=True)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:#DC143C; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% / 10% 40%\">Effect of lockdown amid COVID-19 pandemic on air quality of the megacity Delhi, India</h1>\n\nAuthors: Susanta Mahato, Swades Pal, and Krishna Gopal Ghosh\n\nSci Total Environ. 2020 Aug 15; 730: 139086. - Published online 2020 Apr 29.\nDOI: 10.1016/j.scitotenv.2020.139086 - PMCID: PMC7189867 - PMID: 32375105\n\n\"Amid the COVID-19 pandemic, a nationwide lockdown is imposed in India initially for three weeks from 24th March to 14th April 2020 and extended up to 3rd May 2020. Due to the forced restrictions, pollution level in cities across the country drastically slowed down just within few days which magnetize discussions regarding lockdown to be the effectual alternative measures to be implemented for controlling air pollution.\"\n\n\"The present article eventually worked on this direction to look upon the air quality scenario amidst the lockdown period scientifically with special reference to the megacity Delhi.\" \n\n\"The results demonstrated that during lockdown air quality is significantly improved. Among  pollutants, NO2 (−52.68%) and CO (−30.35%) level have also reduced during-lockdown phase.\"\n\n\"About 40% to 50% improvement in air quality is identified just after four days of commencing lockdown. Overall, the study is thought to be a useful supplement to the regulatory bodies since it showed the pollution source control can attenuate the air quality. Temporary such source control in a suitable time interval may heal the environment.\"\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7189867/\n\n","metadata":{}},{"cell_type":"markdown","source":"![](https://static.toiimg.com/img/74868916/Master.jpg)timesofindia.indiatimes.com","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/impact-of-covid19-outbreak-on-global-air-quality/CASE_DELHI.csv\")\nprint(df1.shape)\ndf1.head().style.set_properties(**{'background-color':'Aquamarine',\n                                     'color': 'purple'})","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/impact-of-covid19-outbreak-on-global-air-quality/NO2vO3_DELHI.csv\")\nprint(df.shape)\ndf.head().style.set_properties(**{'background-color':'BurlyWood',\n                                     'color': 'purple'})","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.read_csv(\"/kaggle/input/impact-of-covid19-outbreak-on-global-air-quality/CASE_Satellite.csv\")\nprint(df2.shape)\ndf2.head().style.set_properties(**{'background-color':'PaleGreen',\n                                     'color': 'purple'})","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(df, \n             x='yr', y='no2', color_discrete_sequence=['#D63230'],\n             title='NO2 in Delhi 2015-20', text='n_no2')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(df, x=\"yr\", y=\"no2\", color_discrete_sequence=['#2B3A67'], \n              title=\"NO2 in Delhi 2015-20\")\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(df,\n             values=\"yr\",\n             names=\"case\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Handling Missing Values","metadata":{}},{"cell_type":"code","source":"# categorical features with missing values\ncategorical_nan = [feature for feature in df.columns if df[feature].isna().sum()>0 and df[feature].dtypes=='O']\nprint(categorical_nan)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replacing missing values in categorical features\nfor feature in categorical_nan:\n    df[feature] = df[feature].fillna('None')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[categorical_nan].isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Label Encoding","metadata":{}},{"cell_type":"code","source":"#Code by Bizen https://www.kaggle.com/hiro5299834/tps-apr-2021-deebtables/notebook\n\nTARGET = 'n_no2' #Target could Not be float otherwise will result in valueError: Unknown label type: 'continuous'. Even after the encoding.\n\nlabel_cols = ['case']\nnumerical_cols = ['yr', 'mo', 'da', 'no2', 'o3mx8', 'starthr', 'n_o3']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Bizen https://www.kaggle.com/hiro5299834/tps-apr-2021-deebtables/notebook\n\nfrom sklearn.preprocessing import LabelEncoder\n\ndef label_encoder(c):\n    le = LabelEncoder()\n    return le.fit_transform(c)\n\nlabel_encoded_df = df[label_cols].apply(label_encoder)\nnumerical_df = df[numerical_cols]\ntarget_df = df[TARGET]\n\ndf = pd.concat([numerical_df, label_encoded_df, target_df], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Code by Napetrov https://www.kaggle.com/napetrov/tps04-svm-with-scikit-learn-intelex/notebook","metadata":{}},{"cell_type":"markdown","source":"#Installing scikit-learn-intelex\n\nPackage also available in conda - please refer to details https://github.com/intel/scikit-learn-intelex","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn-intelex --progress-bar off >> /tmp/pip_sklearnex.log","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport optuna","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_SEED = 2021\nPROBAS = True\nFOLDS = 5\nN_ESTIMATORS = 1000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Napetrov https://www.kaggle.com/napetrov/tps04-svm-with-scikit-learn-intelex/notebook\n\ndf_scaled = df.drop([TARGET], axis = 1).copy()\n\nscaler = StandardScaler()\nscaler.fit(df.drop([TARGET], axis = 1))\ndf_scaled = scaler.transform(df_scaled)\n\ndf_scaled = pd.DataFrame(df_scaled, columns=df.drop([TARGET], axis = 1).columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scaled.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Napetrov https://www.kaggle.com/napetrov/tps04-svm-with-scikit-learn-intelex/notebook\n\nX = df_scaled\ny = df[TARGET]\n\nprint (f'X:{X.shape} y: {y.shape} \\n')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = RANDOM_SEED)\nprint (f'X_train:{X_train.shape} y_train: {y_train.shape}')\nprint (f'X_test:{X_test.shape} y_test: {y_test.shape}')\n\ntest = df_scaled[len(df):]\nprint (f'test:{test.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Napetrov https://www.kaggle.com/napetrov/tps04-svm-with-scikit-learn-intelex/notebook\n\n%time\nsvc_kernel_rbf = SVC(kernel='rbf', random_state=0, C=1.3040348958661234, gamma=0.11195797734572176 )\nsvc_kernel_rbf.fit(X_train, y_train)\ny_pred = svc_kernel_rbf.predict(X_test)\naccuracy_score(y_pred, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\nfinal_pred = svc_kernel_rbf.predict(test)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Napetrov https://www.kaggle.com/napetrov/tps04-svm-with-scikit-learn-intelex/notebook\n\ndef objective(trial):\n    from sklearn.svm import SVC\n    params = {\n        'C': trial.suggest_loguniform('C', 0.1, 0.5),\n        'gamma': trial.suggest_categorical('gamma', [\"auto\"]),\n        'kernel': trial.suggest_categorical(\"kernel\", [\"rbf\"])\n    }\n\n    svc = SVC(**params)\n    svc.fit(X_train, y_train)\n    return svc.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Napetrov https://www.kaggle.com/napetrov/tps04-svm-with-scikit-learn-intelex/notebook\n\nstudy = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=123),\n                            direction=\"maximize\",\n                            pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=5, show_progress_bar=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Best Value: {study.best_trial.value}\")\nprint(f\"Best Params: {study.best_params}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Napetrov https://www.kaggle.com/napetrov/tps04-svm-with-scikit-learn-intelex/notebook\n\n%time\nn_folds = 5\nkf = KFold(n_splits=n_folds, shuffle=True, random_state=0)\ny_pred = np.zeros(test.shape[0])\n\nfor fold, (train_index, valid_index) in enumerate(kf.split(X, y)):\n    print(\"Running Fold {}\".format(fold + 1))\n    X_train, X_valid = pd.DataFrame(X.iloc[train_index]), pd.DataFrame(X.iloc[valid_index])\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    svc_kernel_rbf = SVC(**study.best_params)\n    svc_kernel_rbf.fit(X_train, y_train)\n    print(\"  Accuracy: {}\".format(accuracy_score(y_valid, svc_kernel_rbf.predict(X_valid))))\n    y_pred += svc_kernel_rbf.predict(test)\n\ny_pred /= n_folds\n\nprint(\"I'm so screwed!\")\nprint(\"Not Done yet!\")","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Maybe next time I can handle with scikit-learn-intelex. I was almost there.","metadata":{}}]}