{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Prostate cancer is the most common cancer in men in the UK. It usually develops slowly, so there may be no signs for many years. Symptoms of prostate cancer do not usually appear until the prostate is large enough to affect the tube that carries urine from the bladder out of the penis (urethra).\n\n## Information source: https://www.nhs.uk/conditions/prostate-cancer/"},{"metadata":{},"cell_type":"markdown","source":"### This dataset contains clinical information about 100 patients and 10 variables. Here we going to create a simple analysis of the data and test some traditional classifiers"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/prostate-cancer/Prostate_Cancer.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### No missing values found"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding the categorical variable found (diagnosis_result), wich is the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model = data.drop(['id'], axis=1)\ndata_model['diagnosis_result'] = data_model['diagnosis_result'].astype('category')\ndata_model['diagnosis_result'] = data_model['diagnosis_result'].cat.codes\ndata_model['diagnosis_result'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We're going to check the correlation between the features and the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = data_model.corr(method='pearson')\ncorrelations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 8))\nsb.heatmap(correlations, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The 3 most correlated are:\n* perimeter\n* area\n* compactness"},{"metadata":{},"cell_type":"markdown","source":"### Checking the relationship between them usnig swarmplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.swarmplot(x=data_model['diagnosis_result'],\n              y=data_model['perimeter'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.swarmplot(x=data_model['diagnosis_result'],\n              y=data_model['area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.swarmplot(x=data_model['diagnosis_result'],\n              y=data_model['compactness'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data_model.diagnosis_result\nX = data_model[['perimeter', 'area', 'compactness']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classes are slightly imbalanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model['diagnosis_result'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model['diagnosis_result'].value_counts().plot(kind='bar', title='Count (target)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's use 4 traditional classifiers:\n* Logistic Regression\n* SVM\n* Decision Tree\n* Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### * 10-fold cross-validation\n### * train test 80/20"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, KFold, train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\nkf = KFold(n_splits=10, random_state=0, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We're going to save the results in a dict"},{"metadata":{"trusted":true},"cell_type":"code","source":"results_dict = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C=0.5, random_state=1)\nmean_auc_lr = cross_val_score(lr, X_train, y_train, n_jobs=-1, cv=kf, scoring='roc_auc').mean()\nresults_dict['Logistic Regression'] = mean_auc_lr\nresults_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = svm.SVC()\nmean_auc_svm = cross_val_score(svm, X_train, y_train, n_jobs=-1, cv=kf, scoring='roc_auc').mean()\nresults_dict['SVM'] = mean_auc_svm\nresults_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeRegressor()\nmean_auc_dt = cross_val_score(dt, X_train, y_train, n_jobs=-1, cv=kf, scoring='roc_auc').mean()\nresults_dict['Decision Tree'] = mean_auc_dt\nresults_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = GaussianNB()\nmean_auc_nb = cross_val_score(nb, X_train, y_train, n_jobs=-1, cv=kf, scoring='roc_auc').mean()\nresults_dict['NB'] = mean_auc_nb\nresults_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = ['Logistic Regression', 'SVM', 'Decision Tree', 'NB']\ny = [results_dict['Logistic Regression'], results_dict['SVM'], results_dict['Decision Tree'], results_dict['NB']]\nplt.title(\"AUC comparison\")\nplt.ylabel(\"AUC\")\nplt.bar(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing with the method that achieved the highest AUC value"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import mean_absolute_error\nnb.fit(X_train, y_train)\npredicted = nb.predict(X_test)\nroc_auc = roc_auc_score(y_test, predicted)\nmae = mean_absolute_error(y_test, predicted)\n\nprint(\"Mean Absolute Error: {} | ROC AUC: {}\".format(mae, roc_auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Printing the confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(y_test, predicted)\nconfusion","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\ndisp = plot_confusion_matrix(nb, X_test, y_test,\n                                 display_labels=data_model['diagnosis_result'],\n                                 cmap=plt.cm.Blues)\n\ndisp.ax_.set_title(\"Confusion Matrix\")\ndisp.confusion_matrix\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In the medical domain, two measures are widely used: **Sensitivity** and **Specificity**. To calculate them we need:\n* True Positive (TP)\n* True Negative (TN)\n* False Positive (FP)\n* Flase Negative (FN)"},{"metadata":{"trusted":true},"cell_type":"code","source":"TP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensitivity = TP/(TP+FN)\nspecificity = TN/(TN+FP)\n\n\"Sensitivity: {} | Specifictity: {}\".format(sensitivity, specificity)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}