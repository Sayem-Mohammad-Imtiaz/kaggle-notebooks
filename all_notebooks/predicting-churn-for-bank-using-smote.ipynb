{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore',category=FutureWarning)\n# lib for modelling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score,roc_auc_score,roc_curve,confusion_matrix,classification_report\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.feature_selection import RFE\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport statsmodels.api as sm\n# import EDA library\nfrom pandas_profiling import ProfileReport","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the dataset \ndf=pd.read_csv('../input/predicting-churn-for-bank-customers/Churn_Modelling.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generating report for the data for the better visualization\nProfileReport(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets look for the column in data \ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data pre - processing\ndf.drop(['CustomerId','Surname'],axis=1,inplace=True) \n### let's drop few columns which won't contribute to the model as we have seen above in report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  one hot encoding for the column `Geo` \nGeography_dummies = pd.get_dummies(prefix='Geo',data=df,columns=['Geography'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding for the gender column  as its just male and female we have not done on hot as its nor ordinal data\nGender_dummies = Geography_dummies.replace(to_replace={'Gender': {'Female': 1,'Male':0}})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new = Gender_dummies\ndf_new.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Doing EDA for the dataset since pandas profiling had done our most of the work but still we need to work out\n# Check the distribution of y variable to see if it's a case of unbalanced class\n\nsns.countplot(y=df_new.Exited ,data=df_new)\nplt.xlabel(\"Count of each Target class\")\nplt.ylabel(\"Target classes\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the distribution of all the features\n\ndf_new.hist(figsize=(15,12),bins = 15)\nplt.title(\"Features Distribution\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We are not checking for the multicollinearity as we have already looked the same in profile report","metadata":{}},{"cell_type":"code","source":"# as we have seen that there is imbalanced in the dataset for the target hence we need to balance the data\n# Split the y variable series and x variables dataset\n\nX = df_new.drop(['Exited'],axis=1)\ny = df_new.Exited\nfrom imblearn.over_sampling import SMOTE\nsmt = SMOTE(random_state=0)\nX, y = smt.fit_resample(X, y)\nprint(X.shape)\nprint(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using power transfor to normalise the data\nfrom sklearn.preprocessing import PowerTransformer\npt=PowerTransformer()\nXpowertrain=pt.fit_transform(X_train)\nxpowertest=pt.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply logit model\nmodel=sm.Logit(y,sm.add_constant(X)).fit()\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# As per the model location gender has lesser pvalue but we can not drop it as per domain knowledge as we need it identify for the location and gender as a factor to churn","metadata":{}},{"cell_type":"code","source":"lr=LogisticRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr.fit(Xpowertrain,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr.score(Xpowertrain,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr.score(xpowertest,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting target values by using x_test and our model:\ny_pred = lr.predict(xpowertest)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model evalution metric","metadata":{}},{"cell_type":"code","source":"print ('Confusion Matrix :')\nprint(confusion_matrix(y_test, y_pred))\nprint('Accuracy Score :',accuracy_score(y_test, y_pred) )\nprint('Recall Score :',recall_score(y_test, y_pred) )\nprint('Precision Score :',precision_score(y_test, y_pred) )\nprint('Report : ')\nprint(classification_report(y_test, y_pred))\n\n      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC AUC curve\ny_pred_prob1 = lr.predict_proba(xpowertest)[:,1]\nfpr1 , tpr1, thresholds1 = roc_curve(y_test, y_pred_prob1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(fpr1, tpr1, label= \"Logistic Regression\")\nplt.legend()\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title('ROC-AUC curve')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}