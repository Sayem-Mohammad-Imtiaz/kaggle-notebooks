{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport random\nimport gc\nimport warnings\nimport joblib\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import KFold,cross_val_score,GridSearchCV,train_test_split\nfrom sklearn.ensemble import ExtraTreesRegressor, StackingRegressor\nfrom lightgbm import LGBMRegressor\n#from xgboost import XGBRegressor\n#from catboost import CatBoostRegressor\nplt.style.use('ggplot')\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.getcwd()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/car-price-prediction/CarPrice_Assignment.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [col for col in dataset.columns.tolist() if col not in ['price','car_ID']]\nnumerical_features = []\ncategorical_features = [] \ntarget = dataset.price\ndataset = dataset[features]\n\nfor col in features:\n    if dataset[col].dtype in ['int64', 'int32', 'float64', 'float32']:\n        numerical_features.append(col);\n    else:\n        categorical_features.append(col)\n        \nprint('There are {:} numerical features.'.format(len(numerical_features)))\nprint('There are {:} categorical features.'.format(len(categorical_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.CarName.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.loc[0,'CarName'].split(' ')[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CarName extract"},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in range(len(dataset)):\n    dataset.loc[item,'CarName'] = dataset.loc[item,'CarName'].split(' ')[0]\n    \ndataset[categorical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.CarName.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rare_name = ['isuzu','porsche','jaguar','chevrolet',\n             'alfa-romero','maxda','vw','renault',\n             'mercury','vokswagen','vokswagen','toyouta','Nissan','porcshce']\n\nfor item in range(len(dataset)):\n    if dataset.loc[item,'CarName'] in rare_name:\n        dataset.loc[item,'CarName'] = 'rare'\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[categorical_features].describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.get_dummies(dataset, columns=categorical_features)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add features"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['carvolume'] = dataset['carlength'] * dataset['carwidth'] * dataset['carheight']\ndataset['totalmpg'] = dataset['citympg'] + dataset['highwaympg']\nnumerical_features.append('carvolume')\nnumerical_features.append('totalmpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler,StandardScaler\n\ncategorical_features = [col for col in dataset.columns.tolist() if col not in numerical_features]\n\nscaler = StandardScaler()\nscaler = scaler.fit(dataset[numerical_features])\ndataset_scaler = scaler.transform(dataset[numerical_features])\ndataset_scaler = pd.DataFrame(dataset_scaler)\ndataset_scaler.columns = numerical_features\ndataset_scaler = pd.concat([dataset_scaler,dataset[categorical_features]], axis=1)\ndataset_scaler.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dataset_scaler.values\nfeatures.shape, target.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seeds = [42, 73, 111, 123, 2021]    \nSEED = seeds[0]\nNUM_TRAIN_SAMPLES = features.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)  \n    \ndef count_data_items(data):\n    return len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_params = {'bagging_fraction': 0.8, 'boosting_type': 'gbdt', \n              'colsample_bytree': None, 'feature_fraction': 0.7, \n              'lambda_l1': 2, \n              'lambda_l2': 2, \n              'learning_rate': 0.1, \n              'max_depth': -1, \n              'metrics': 'rmse', \n              'min_child_samples': None, \n              'min_child_weight': 15.586, \n              'min_data_in_leaf': 6, \n              'min_sum_hessian_in_leaf': None,\n              'n_estimators': 5000, \n              'num_leaves': 70,\n              'reg_alpha': None,\n              'reg_lambda': None, \n              'seed': 7, \n              'subsample': None,\n              'n_jobs' : 16,\n              'verbose': -1}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"oof train loop **with plabel**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_evaluate(folds = 5):\n    oof_targets = np.zeros(NUM_TRAIN_SAMPLES)\n    oof_predictions = np.zeros(NUM_TRAIN_SAMPLES)\n    previous_number_of_files = 0\n    total_number_of_files = 0\n    \n    seed_everything(SEED)\n    kfold = KFold(folds, shuffle=True, random_state=SEED)\n    \n    for fold, (trn_ind, val_ind) in enumerate(kfold.split(features, target)):\n        print('\\n')\n        print('-'*50)\n        print(f'Training fold {fold + 1} begin :')\n        \n        train_x, train_y = features[trn_ind], target[trn_ind]\n        val_x, val_y  = features[val_ind], target[val_ind]\n        \n        model = LGBMRegressor(**lgb_params)\n        model.fit(train_x, train_y, eval_set=(val_x, val_y), early_stopping_rounds=200, verbose=False)\n        gc.collect() \n        \n        # make pesudo label\n        pesudo_label = model.predict(val_x)\n        X_agg = np.concatenate([train_x,val_x],axis=0)\n        y_agg = np.concatenate([train_y,pesudo_label],axis=0)\n        # train again\n        model = LGBMRegressor(**lgb_params)\n        model.fit(X_agg, y_agg, eval_set=(val_x, val_y), early_stopping_rounds=200, verbose=False)\n        gc.collect() \n        \n        joblib.dump(model,f'./lgb_{fold}_PLabel.pkl')\n        \n        number_of_files = count_data_items(val_y)\n        total_number_of_files += number_of_files\n        oof_targets[previous_number_of_files:total_number_of_files] = val_y\n        probabilities = model.predict(val_x)\n        oof_predictions[previous_number_of_files:total_number_of_files] = probabilities\n        previous_number_of_files += number_of_files\n        \n        print('\\n')\n        print('-'*50)\n        fold_r2_score = r2_score(val_y, probabilities)\n        fold_rmse_score = np.sqrt(mean_squared_error(val_y, probabilities))\n        print(f'Our fold {fold + 1} rmse score validation is {fold_rmse_score}')\n        print(f'Our fold {fold + 1} r2 score validation is {fold_r2_score}')\n        \n    print('\\n')\n    print('-'*50)\n    oof_r2_score = r2_score(oof_targets, oof_predictions)\n    oof_rmse_score = np.sqrt(mean_squared_error(oof_targets, oof_predictions))\n    print(f'Our out of folds rmse score is {oof_rmse_score}')\n    print(f'Our out of folds r2 score is {oof_r2_score}')\n    \n    print('Saving out of folds to disk...')\n    target_columns = ['Tc']\n    prediction_columns = [col + ' Prob' for col in target_columns]\n    oof_targets_df = pd.DataFrame(oof_targets, columns=target_columns)\n    oof_predictions_df = pd.DataFrame(oof_predictions, columns=prediction_columns)\n    \n    oof_dataset = pd.concat([oof_targets_df, oof_predictions_df], axis=1)\n    oof_dataset.to_csv(f'./lgbm_oof_{SEED}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Train & prediction\ntrain_and_evaluate(folds = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\ndef PerformanceCalculator(trueVals, predVals, name):\n    plt.plot([0,0.001,0.01,1], [0,0.001,0.01,1], color = 'blue')\n    plt.scatter(trueVals, predVals, color = 'green')\n    er = mse(trueVals, predVals)\n    er = pow(er, 0.5)\n    er = int(er * 10000) / 10000\n    r2 = np.round(r2_score(trueVals, predVals),4)\n    plt.title('RMSE: ' + str(er) + ' for '+ name)\n    plt.plot([2500,50000], [2500,50000], '--', lw=2, c='r')\n    plt.xlim(2500,50000)\n    plt.ylim(2500,50000)\n    print('R2: ' + str(r2) + ' for '+ name)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_dataset = pd.read_csv(f'./lgbm_oof_{SEED}.csv')\noof_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PerformanceCalculator(oof_dataset.Tc, oof_dataset['Tc Prob'], 'LGBM single model')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}