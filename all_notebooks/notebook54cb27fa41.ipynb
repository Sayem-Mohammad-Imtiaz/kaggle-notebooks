{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#cloning indic nlp for hindi text tokenization, steps followed as a given in the tutorial\n\n!pip install indic-nlp-library","metadata":{"id":"K-nf7uOwaex-","outputId":"a022a32f-6967-4ae3-8a77-db67836abc06","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git","metadata":{"id":"kquiE7mu7FOs","outputId":"c31318aa-1321-4622-aee7-428494226668","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install Morfessor","metadata":{"id":"Gegl9icU7RUG","outputId":"78b9e79c-da69-4a9f-c2fb-6bc6d421a846","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nINDIC_NLP_RESOURCES=str(Path(\"./indic_nlp_resources\").resolve())","metadata":{"id":"C72MvefX7Va8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from indicnlp import common\ncommon.set_resources_path(INDIC_NLP_RESOURCES)","metadata":{"id":"Z_nRB12v7YfT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing required moules, no ml modules imported other than the mentikned one \n#also imported some basic utlity modules \n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport csv\nimport numpy as np\nimport math\n\nfrom itertools import chain\nimport json\n\nimport random\nimport time\nimport sys\n\nfrom collections import Counter\nfrom torch.utils.data import Dataset, DataLoader\n\nimport nltk\nnltk.download('punkt')\nfrom indicnlp.tokenize import indic_tokenize \n\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nen_detok = TreebankWordDetokenizer()\n\n","metadata":{"id":"mESlbAK67Ghd","outputId":"7bb96e36-8c3a-45fd-8bf0-eaf7c9559631","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#readin the data from data.csv file and seperating test and traing data seperately in 4 different files\n##also the lists are used to make data_class object for trainging and test time\n\n\n\nsrc_data = []\ntgt_data = []\nwith open('../input/hi2en-translation/train.csv') as csv_file:\n    csv_reader = csv.reader(csv_file, delimiter=',')\n    line_count = 0\n    for row in csv_reader:\n        if line_count == 0:\n            print(f'Column names are {\", \".join(row)}')\n            line_count += 1 #ignoring the first line as it do not contains relevant data\n        else:\n            src_data.append(row[1])\n            tgt_data.append(row[2])\n            # print(f'\\t{row[0]}\\t{row[1]}\\t{row[2]}')\n            line_count += 1\n    print(f'Processed {line_count} lines.')\n\norigninal_stdout = sys.stdout\n\n#splitting the data into a split of 8 is to 2 and printing to relevant files\n#seperated data for any future use if needed\n#currently only using training data for voacb genration used later for embedings\nleng = len(src_data)\nleng = math.ceil(leng*0.8)\n\nindex_array = list(range(len(src_data)))\n# np.random.shuffle(index_array)\n\nindex_train = index_array[:leng]\nindex_test = index_array[leng:]\n\nwith open('hi_train.txt', 'w') as f:\n    sys.stdout = f\n    for i in index_train:\n        txt = src_data[i]\n        print(f'{txt}')\n    sys.stdout = origninal_stdout\n\nwith open('eng_train.txt', 'w') as f:\n    sys.stdout = f\n    for i in index_train:\n        txt = tgt_data[i]\n        print(f'{txt}')\n    sys.stdout = origninal_stdout\n\nwith open('hi_test.txt', 'w') as f:\n    sys.stdout = f\n    for i in index_test:\n        txt = src_data[i]\n        print(f'{txt}')\n    sys.stdout = origninal_stdout\n\nwith open('eng_test.txt', 'w') as f:\n    sys.stdout = f\n    for i in index_test:\n        txt = tgt_data[i]\n        print(f'{txt}')\n    sys.stdout = origninal_stdout\n\n","metadata":{"id":"WKlUgLJF7p-V","outputId":"91e24c50-8285-41d1-a282-7823599392bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#utility fintion to pad sents to equal length\n#input list[list[str]] output :list[list[str]] but the output has all the inner list of same length\n#pading token used, ignored during  traing\n\ndef pad_sents(sents, pad_token):\n    sents_padded = []\n\n    \n    slen = []\n    for sent in sents:\n        slen.append(len(sent))\n    m_len = max(slen)\n    # print(f'{m_len}\\n')\n    for sent in sents:\n        # print(sent)\n        temp = sent\n        # print(temp)\n        for i in range(m_len-len(sent)):\n            temp.append(pad_token)\n        sents_padded.append(temp)\n\n\n\n    ### END YOUR CODE\n\n    return sents_padded\n","metadata":{"id":"h_FPn-Re8fPQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##this function read from the files created in the above step and return a tokenise list of list of str\n\ndef read_corpus(file_path, source):\n    if source == 'src':\n        data = []\n        for line in open(file_path):\n            sent = indic_tokenize.trivial_tokenize(line)\n            data.append(sent)\n        return data\n    else:\n        data = []\n        for line in open(file_path):\n            sent = nltk.word_tokenize(line)\n            # sent = ['<s>'] + sent + ['</s>']\n            data.append(sent)\n        return data","metadata":{"id":"U6ZeaFRa8tKr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this class is of vocab entry, we have two source and target\n##most of the function are of the sake of ease of use and dont serve any additional benefits\n\nclass VocabEntry(object):\n    def __init__(self, word2id=None):\n        if word2id:\n            self.word2id = word2id\n        else:\n            #some predefined words that are added manually\n            #if a dict is not already defined, define it and insert the words\n            self.word2id = dict()\n            self.word2id['<pad>'] = 0   # Pad Token\n            self.word2id['<s>'] = 1 # Start Token\n            self.word2id['</s>'] = 2    # End Token\n            self.word2id['<unk>'] = 3   # Unknown Token\n        self.unk_id = self.word2id['<unk>']  #we are storing the token of unknown words as when our data will not be able to recognise a word it will bw assigned to unk\n        self.id2word = {v: k for k, v in self.word2id.items()}  #returns the index of the word in the dictionary\n\n    def __getitem__(self, word):\n        return self.word2id.get(word, self.unk_id)  #if word not present return unk else index of the world\n\n    def __contains__(self, word):\n        return word in self.word2id  \n\n    def __setitem__(self, key, value):\n        raise ValueError('vocabulary is readonly')  #dict value can't be changed after initialisation\n\n    def __len__(self):\n        return len(self.word2id)  #len of dict\n\n    def __repr__(self):\n        return 'Vocabulary[size=%d]' % len(self)  #repr of dict when it is preinted\n\n    #add a new world in a dictionary, only if its not already present\n    def add(self, word):\n        if word not in self:\n            wid = self.word2id[word] = len(self)\n            self.id2word[wid] = word\n            return wid\n        else:\n            return self[word]\n\n    #convert a list of list of str or list of str into list of list on indices or list of indices resp\n    def words2indices(self, sents):\n        if type(sents[0]) == list:\n            return [[self[w] for w in s] for s in sents]\n        else:\n            return [self[w] for w in sents]\n    #convert list of index into words\n    def indices2words(self, word_ids):\n        return [self.id2word[w_id] for w_id in word_ids]\n\n    ##given a list of list of str convert it into a torch tensor with sents being padded and of the shape (mx_sec_length, batch_size, embedding_size)\n    def to_input_tensor(self, sents) -> torch.Tensor:\n        word_ids = self.words2indices(sents)\n        sents_t = pad_sents(word_ids, self['<pad>'])\n        sents_var = torch.tensor(sents_t, dtype=torch.long)\n        return torch.t(sents_var)\n\n    @staticmethod\n    def from_corpus(corpus, size, freq_cutoff=2):\n        vocab_entry = VocabEntry()\n        word_freq = Counter(chain(*corpus))\n        valid_words = [w for w, v in word_freq.items() if v >= freq_cutoff]\n        print('number of word types: {}, number of word types w/ frequency >= {}: {}'\n              .format(len(word_freq), freq_cutoff, len(valid_words)))\n        top_k_words = sorted(valid_words, key=lambda w: word_freq[w], reverse=True)[:size]\n        for word in top_k_words:\n            vocab_entry.add(word)\n        return vocab_entry\n","metadata":{"id":"RxMDgoDQ8Dkb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Vocab(object):\n    def __init__(self, src_vocab: VocabEntry, tgt_vocab: VocabEntry):\n        self.src = src_vocab\n        self.tgt = tgt_vocab\n\n    @staticmethod\n    def build(src_sents, tgt_sents, vocab_size, freq_cutoff) -> 'Vocab':\n        assert len(src_sents) == len(tgt_sents)\n\n        print('initialize source vocabulary ..')\n        src = VocabEntry.from_corpus(src_sents, vocab_size, freq_cutoff)\n\n        print('initialize target vocabulary ..')\n        tgt = VocabEntry.from_corpus(tgt_sents, vocab_size, freq_cutoff)\n\n        return Vocab(src, tgt)\n\n    def __repr__(self):\n        return 'Vocab(source %d words, target %d words)' % (len(self.src), len(self.tgt))\n\n","metadata":{"id":"42pEwiX883OQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src_sents = read_corpus('hi_train.txt', source='src')\ntgt_sents = read_corpus('eng_train.txt', source='tgt')\n","metadata":{"id":"CQzSoOds9fhE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" vocab_train = Vocab.build(src_sents, tgt_sents, 30000, 2)","metadata":{"id":"pfVPQkGE_OLU","outputId":"44d2ca96-9bb4-4fce-e7a6-f7b992e679bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vocab.save('vocab.json')","metadata":{"id":"BmEgoUjK_xRy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LangDataset(Dataset):\n    def __init__(self, tot):\n        # Initialize data, download, etc.\n        # read with numpy or pandastokenize(row[1]))\n        leng = len(src_data)\n        leng = math.ceil(leng*0.8)\n        if (tot=='train'):\n          self.src, self.tgt = src_data[:leng], tgt_data[:leng]        # print(f'ads')\n        if (tot=='test'):\n          self.src, self.tgt = src_data[leng:], tgt_data[leng:]\n\n        self.n_samples = len(self.src)\n\n    # support indexing such that dataset[i] can be used to get i-th sample\n    def __getitem__(self, index):\n        return self.src[index], self.tgt[index]\n\n    # we can call len(dataset) to return the size\n    def __len__(self):\n        return self.n_samples","metadata":{"id":"FvQ1mvLtAcii","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vocab_train = Vocab.load('vocab.json')\n\nprint(vocab_train)","metadata":{"id":"JcTBx8GHAwk8","outputId":"6499e633-70a4-4d08-b0d7-e38f927043a7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hid_dim,dropout):\n        super().__init__()\n\n        self.hid_dim = hid_dim\n        \n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        self.rnn = nn.LSTM(emb_dim, hid_dim, bidirectional = True)\n        self.h_proj = nn.Linear(hid_dim*2, hid_dim)\n        self.c_proj = nn.Linear(hid_dim*2, hid_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, src):\n        embedded = self.dropout(self.embedding(src))\n        outputs, (hidden, cell) = self.rnn(embedded)\n\n        hidden = self.h_proj(torch.cat((hidden[0], hidden[1]), 1))\n        cell =  self.c_proj(torch.cat((cell[0], cell[1]), 1))\n\n        #output (s, b, 2h) hidden-(1, b, h) cell - (1, b, h)\n        return outputs, (hidden.unsqueeze(0), cell.unsqueeze(0))\n","metadata":{"id":"1fnfHBEkBjGw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hid_dim):\n        super().__init__()\n        \n        self.com_proj = nn.Linear(hid_dim*3, hid_dim)\n        self.dropout = nn.Dropout(0.2)\n        \n        # self.v = nn.Linear(hid_dim, 1, bias = False)\n        \n    def forward(self, dec_state, encoder_outputs, encoder_outputs_proj):\n        \n        #hidden = [batch size, dec hid dim]\n        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n        \n        batch_size = encoder_outputs.shape[1]\n        src_len = encoder_outputs.shape[0]\n        \n        #repeat decoder hidden state src_len times\n        hidden, cell = dec_state\n        e_t =torch.bmm(encoder_outputs_proj, hidden.squeeze(0).unsqueeze(2)).squeeze(2)\n\n        alpha_t = F.softmax(e_t)\n        a_t = torch.bmm(alpha_t.unsqueeze(1), encoder_outputs).squeeze(1)#(b, 2h)\n\n        U_t = torch.cat((a_t, hidden.squeeze(0)), dim=1) #(b, 3h)\n        V_t = self.com_proj(U_t)\n        O_t = self.dropout(torch.tanh(V_t))\n\n        return O_t\n\n\n\n","metadata":{"id":"UzWn4310V83w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"l-ADFHvb3SCN","outputId":"48098872-4633-443e-9caf-c3583d3428d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hid_dim, enc_dropout, attention):\n        super().__init__()\n\n        self.output_dim = output_dim\n        self.attention = attention\n        self.hid_dim = hid_dim\n        \n\n        self.embedding = nn.Embedding(output_dim, emb_dim)\n        self.rnn = nn.LSTM(emb_dim, hid_dim)\n        self.fc_out = nn.Linear(hid_dim, output_dim)\n\n        self.att_proj = nn.Linear(2*hid_dim, hid_dim)\n        self.dropout1 = nn.Dropout(enc_dropout)\n\n    def forward(self, input, hidden, cell, encoder_outputs):\n        input = input.unsqueeze(0)\n        embedded = self.dropout1(self.embedding(input))\n\n        _, dec_state = self.rnn(embedded, (hidden, cell))\n        \n        # dec_state = (hidden.squeeze(0), cell.squeeze(0))\n        (hidden, cell) = dec_state\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        #enc_ot = (b, s, 2h)\n        encoder_outputs_proj = self.att_proj(encoder_outputs)\n        #enc_out = (b,s, h)\n\n        prediction = self.attention(dec_state, encoder_outputs, encoder_outputs_proj)\n        prediction_proj = self.fc_out(prediction)\n\n\n        \n        return prediction_proj, (hidden, cell)\n","metadata":{"id":"Er0u8gADBkuq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        assert encoder.hid_dim == decoder.hid_dim, \"Hid_dim should be same\"\n        \n    \n    def forward(self,src, trg, teacher_forcing_ratio = 0.5):\n        batch_size = trg.shape[1]\n        trg_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n\n        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n\n        encoder_outputs, (hidden, cell) = self.encoder(src)\n\n        input = trg[0,:]\n\n        for t in range(1, trg_len):\n            output, (hidden, cell) = self.decoder(input, hidden, cell, encoder_outputs)\n\n            outputs[t] = output\n\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n\n            input = trg[t] if teacher_force else top1\n        return outputs\n","metadata":{"id":"Xd_iSX79Bs6_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    for name, param in m.named_parameters():\n        nn.init.uniform_(param.data, -0.08, 0.08)\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"id":"PWIcdtKxBw24","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"pX5nB118B00X","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, iterator, optimizer, criterion, clip):\n    model.train()\n    epoch_loss = 0\n\n    for i, batch in enumerate(iterator):\n        if i%10 == 0:\n            print(f'{i}iteration')\n        # print(f'{i}iteration')\n        src, trg = batch\n        src = list(src) #convert to list of sentences\n        src = [[\"<s>\"] +indic_tokenize.trivial_tokenize(sent) + [\"</s>\"] for sent in src]\n        src = vocab_train.src.to_input_tensor(src).to(device)\n\n        trg = list(trg)\n        trg = [[\"<s>\"] + nltk.word_tokenize(sent) + [\"</s>\"] for sent in trg]\n        trg = vocab_train.tgt.to_input_tensor(trg).to(device)\n        # print(trg.shape)\n\n        optimizer.zero_grad()\n\n        output = model(src, trg)\n\n        # print(output.shape)\n        output_dim = output.shape[-1]\n\n        output = output[1:].view(-1, output_dim)\n        # print(output.shape)\n        trg = trg.contiguous()[1:].view(-1)\n        # print(trg.shape)\n\n        loss = criterion(output, trg)\n\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    return epoch_loss/len(iterator)","metadata":{"id":"vauyL6pkB9xd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n\n    model.eval()\n    epoch_loss = 0\n\n    with torch.no_grad():\n        for i, batch in enumerate(iterator):\n            if (i%20 == 0):\n                print(f'{i}iteration')\n            # print(f'{i}iteration')\n            src, trg = batch\n            src = list(src) #convert to list of sentences\n            src = [[\"<s>\"] + indic_tokenize.trivial_tokenize(sent) + [\"</s>\"] for sent in src]\n            src = vocab_train.src.to_input_tensor(src).to(device)\n\n            trg = list(trg)\n            trg = [[\"<s>\"] + nltk.word_tokenize(sent) + [\"</s>\"] for sent in trg]\n            trg = vocab_train.tgt.to_input_tensor(trg).to(device)\n            # print(trg.shape)\n            output = model(src, trg, 0)\n\n            a = output.argmax(2)\n            # print(a.shape)\n            a = torch.transpose(a, 0, 1)\n            # print(a.shape)\n            a = a.tolist()\n            for sent in a:\n                o_sent = vocab_train.tgt.indices2words(sent)\n\n            # print(a)\n\n            # print(output)\n\n\n            output_dim = output.shape[-1]\n\n            output = output[1:].view(-1, output_dim)\n\n            trg = trg.contiguous()[1:].view(-1)\n\n            loss = criterion(output, trg)\n\n            epoch_loss += loss.item()\n\n        return epoch_loss/len(iterator)","metadata":{"id":"zm7WmQuOCAEW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"rK05-sczCKgt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = LangDataset('train')\n\ntest_dataset = LangDataset('test')","metadata":{"id":"iIvRsRKiCM6z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16","metadata":{"id":"wNc56va5DP7d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset, batch_size= BATCH_SIZE)\ntest_loader = DataLoader(dataset= test_dataset, batch_size= BATCH_SIZE)\n","metadata":{"id":"8yUuB7OrDL3u","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(vocab_train.src)\nOUTPUT_DIM = len(vocab_train.tgt)\nENC_EMB_DIM = 256\nDEC_EMB_DIM = 256\nHID_DIM = 512\nN_LAYERS = 2\nENC_DROPOUT = 0.5\nDEC_DROPOUT = 0.5\n","metadata":{"id":"1AYvTiAVDVTr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\nattention = Attention(HID_DIM)\ndec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT, attention)\n\nmodel = Seq2Seq(enc, dec, device).to(device)\nprint(f'The model has {count_parameters(model):,} trainable parameters') \nTRG_PAD_IDX = vocab_train.tgt['<pad>']\n\ncriterion = nn.CrossEntropyLoss(ignore_index= TRG_PAD_IDX)\n\noptimizer = optim.Adam(model.parameters())","metadata":{"id":"kusZM-RODZi_","outputId":"dca307da-46c3-4aec-f7b1-cd7d3101d926","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 8\nCLIP = 1\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n\n    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, test_loader, criterion)\n\n    end_time = time.time()\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'model.pt')\n#         torch.save(model.state_dict(), './drive/MyDrive/nmt/model_att1.pt')\n\n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n\n","metadata":{"id":"B0iOrzJoDg_L","outputId":"3130f6ae-dd53-4b19-9095-daf008bfd66b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"Lo165gS_0TMq"}},{"cell_type":"code","source":"enc1 = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\nattention = Attention(HID_DIM)\ndec1 = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT, attention)\n\nmodel1 = Seq2Seq(enc1,dec1, device).to(device)\n\nmodel1.load_state_dict(torch.load('model.pt', map_location=device))\n\n# test_dataset = LangDataset('test.csv')\n\n# test_loader = DataLoader(dataset= test_dataset, batch_size= 8)\n# TRG_PAD_IDX = vocab_train.tgt['<pad>']\n# criterion = nn.CrossEntropyLoss(ignore_index= TRG_PAD_IDX)\n# test_loss = evaluate(model, test_loader, criterion)\n# print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\nsrc_data = []\nwith open('../input/eval-nmt-trans/testhindistatements.csv') as csv_file:\n    csv_reader = csv.reader(csv_file, delimiter=',')\n    line_count = 0\n    for row in csv_reader:\n        # print(row)\n        if(line_count == 0):\n            line_count += 1\n            continue\n        src_data.append(row[2])\n        line_count += 1\n\n    print(f'Processed {line_count} lines.')\n\nprint(len(src_data))\nl = 0\nf = open('answer.txt', 'a', encoding= \"utf8\")\nfor sent in src_data:\n    sent = [\"<s>\"] + indic_tokenize.trivial_tokenize(sent) + [\"</s>\"]\n    sent = vocab_train.src.words2indices(sent)\n    sent = torch.tensor(sent, dtype=torch.long).to(model1.device)\n    sent = sent.unsqueeze(1)\n    # print(sent.shape)\n    # sent = vocab_train.src.to_input_tensor(sent).to(device)\n    # print(sent)\n    batch_size = 1\n    trg_len = 30\n    trg_vocab_size = model1.decoder.output_dim\n\n    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(model1.device)\n\n    encoder_outputs, (hidden, cell) = model1.encoder(sent)\n\n    input = torch.tensor([1]).to(model1.device)\n\n    for t in range(trg_len):\n        output, (hidden, cell) = model1.decoder(input, hidden, cell, encoder_outputs)\n\n        outputs[t] = output\n\n        top1 = output.argmax(1)\n\n        input = top1\n    \n    word_vec = outputs.argmax(2) #teg*b*output_dim\n    word_vec = torch.transpose(word_vec, 0,1)\n    # print(word_vec.shape)\n    word_vec = torch.reshape(word_vec, (-1,))\n    # print(word_vec.shape)\n    # word_vec = list(word_vec)\n    # print(len(word_vec))\n    final_sent = []\n    for i in range(29):\n        # print(word_vec[i])\n        if ( word_vec[i].item() == 2):\n            break\n\n                \n        wrd = vocab_train.tgt.id2word[word_vec[i].item()]\n        final_sent.append(wrd)\n        \n    # f = open('final_out.txt', 'a', encoding= \"utf8\")\n    # f.write()\n    # print()\n    if (l < len(src_data)-1):\n        f.write(en_detok.detokenize(final_sent) + \"\\n\")\n\n    else:\n        f.write(en_detok.detokenize(final_sent) )\n    l += 1\nf.close()\n","metadata":{"id":"VGrD1INDBIbR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! nvidia-smi","metadata":{"id":"fSKkvdrMDRU7","trusted":true},"execution_count":null,"outputs":[]}]}