{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python"}},"nbformat":4,"cells":[{"metadata":{"_uuid":"ed11ca720bdc492ddf5988734a4821e4c4ac47f2","_cell_guid":"a58224bb-f399-4a9f-989c-879cc63786be"},"source":"# **HI-SEAS Solar Irradiance Prediction**\n\n## **Dataset**\nTaken from Space Apps 2017's \"You are my Sunshine\" challenge<sup>1</sup>, the dataset contains meteorological data from the HI-SEAS Habitat in Hawaii. In particular the dataset includes observations of:\n\n- Solar Irradiance (W/m<sup>2</sup>)\n- Temperature (&deg;F)\n- Barometric Pressure (Hg)\n- Humidity (%)\n- Wind Direction (&deg;)\n- Wind Speed (mph)\n- Sun Rise/Set Time\n\n## **Aim**\n To accurately model solar irradiance from other meteorological parameters contained within the dataset.\n\n1 - https://2017.spaceappschallenge.org/challenges/earth-and-us/you-are-my-sunshine/details","cell_type":"markdown"},{"metadata":{"_uuid":"51f68e1734395ece865c505aa0371b9bd4d57eb7","_cell_guid":"c1b10e6e-0a54-417a-9580-729ee336985a"},"source":"## **Importing Required Libraries**","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"fdc3417e1b0c2b7ffa32df5b4abf42ca5f22dafc","_cell_guid":"66f595a7-1509-4c7b-a044-05f441d3ba6d"},"outputs":[],"source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd","cell_type":"code","execution_count":1},{"metadata":{"collapsed":true,"_uuid":"a32fee6c6b1369900a9a86a295efca34263d9e05","_cell_guid":"bdebd704-f750-4cbb-a38e-1700c03ecb22"},"source":"## **Importing The Dataset**","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"7cb6e012eeb9cccc5fab8a584091dde370255604","_cell_guid":"7de6a386-4168-49dd-8d9b-487b7b9227a6"},"outputs":[],"source":"dataset = pd.read_csv('../input/SolarPrediction.csv')\ndataset = dataset.sort_values(['UNIXTime'], ascending = [True])\ndataset.head()","cell_type":"code","execution_count":2},{"metadata":{"collapsed":true,"_uuid":"40a0f4dd12316fdf2209d6af68723a2cbe8f2a93","_cell_guid":"0eca7994-586e-4ce4-8842-c0f225a81fd6"},"source":"## **Feature Engineering**\nFirst step upon importing the dataset was to convert time and date parameters into a more useful format and add some coloumns that may be useful for visualisation, modelling and analysis.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"6fde8e9d5800ad68dc04d61fd2562eeb6b7d2c9c","_cell_guid":"0687714e-cd94-4a50-9d29-43a33a857be8"},"outputs":[],"source":"from datetime import datetime\nfrom pytz import timezone\nimport pytz\nhawaii= timezone('Pacific/Honolulu')\ndataset.index =  pd.to_datetime(dataset['UNIXTime'], unit='s')\ndataset.index = dataset.index.tz_localize(pytz.utc).tz_convert(hawaii)\ndataset['MonthOfYear'] = dataset.index.strftime('%m').astype(int)\ndataset['DayOfYear'] = dataset.index.strftime('%j').astype(int)\ndataset['WeekOfYear'] = dataset.index.strftime('%U').astype(int)\ndataset['TimeOfDay(h)'] = dataset.index.hour\ndataset['TimeOfDay(m)'] = dataset.index.hour*60 + dataset.index.minute\ndataset['TimeOfDay(s)'] = dataset.index.hour*60*60 + dataset.index.minute*60 + dataset.index.second\ndataset['TimeSunRise'] = pd.to_datetime(dataset['TimeSunRise'], format='%H:%M:%S')\ndataset['TimeSunSet'] = pd.to_datetime(dataset['TimeSunSet'], format='%H:%M:%S')\ndataset['DayLength(s)'] = dataset['TimeSunSet'].dt.hour*60*60 \\\n                           + dataset['TimeSunSet'].dt.minute*60 \\\n                           + dataset['TimeSunSet'].dt.second \\\n                           - dataset['TimeSunRise'].dt.hour*60*60 \\\n                           - dataset['TimeSunRise'].dt.minute*60 \\\n                           - dataset['TimeSunRise'].dt.second\ndataset.drop(['Data','Time','TimeSunRise','TimeSunSet'], inplace=True, axis=1)\ndataset.head()","cell_type":"code","execution_count":3},{"metadata":{"_uuid":"0080cb5c64d7729dcc620c9f9fddcd3187952e6c","_cell_guid":"0af53d53-27bc-4ff0-a9a2-e45d94cc7956"},"source":"## **Feature Visualisation**\nNext, in order to get a better understanding of the data, hourly and monthly means of several variables were visualised using bar plots.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"89abee807e1b0f618dc0625fb8401d2ba0345418","_cell_guid":"70a29ddd-b792-43d6-b2d6-ac7dfcacbcac"},"outputs":[],"source":"grouped_m=dataset.groupby('MonthOfYear').mean().reset_index()\ngrouped_w=dataset.groupby('WeekOfYear').mean().reset_index()\ngrouped_d=dataset.groupby('DayOfYear').mean().reset_index()\ngrouped_h=dataset.groupby('TimeOfDay(h)').mean().reset_index()\n\nf, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, sharex='col', sharey='row', figsize=(14,12))\nax3.set_ylim(45,60)\nax5.set_ylim(30.36,30.46)\nax7.set_ylim(60,85)\n\nax1.set_title('Mean Radiation by Hour')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_h))\nrank = grouped_h['Radiation'].argsort().argsort() \ng = sns.barplot(x=\"TimeOfDay(h)\", y='Radiation', data=grouped_h, palette=np.array(pal[::-1])[rank], ax=ax1)\nax1.set_xlabel('')\n\nax2.set_title('Mean Radiation by Month')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_m))\nrank = grouped_m['Radiation'].argsort().argsort() \ng = sns.barplot(x=\"MonthOfYear\", y='Radiation', data=grouped_m, palette=np.array(pal[::-1])[rank], ax=ax2)\nax2.set_xlabel('')\n\nax3.set_title('Mean Temperature by Hour')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_h))\nrank = grouped_h['Temperature'].argsort().argsort() \ng = sns.barplot(x=\"TimeOfDay(h)\", y='Temperature', data=grouped_h, palette=np.array(pal[::-1])[rank], ax=ax3)\nax3.set_xlabel('')\n\nax4.set_title('Mean Temperature by Month')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_m))\nrank = grouped_m['Temperature'].argsort().argsort() \ng = sns.barplot(x=\"MonthOfYear\", y='Temperature', data=grouped_m, palette=np.array(pal[::-1])[rank], ax=ax4)\nax4.set_xlabel('')\n\nax5.set_title('Mean Pressure by Hour')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_h))\nrank = grouped_h['Pressure'].argsort().argsort() \ng = sns.barplot(x=\"TimeOfDay(h)\", y='Pressure', data=grouped_h, palette=np.array(pal[::-1])[rank], ax=ax5)\nax5.set_xlabel('')\n\nax6.set_title('Mean Pressure by Month')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_m))\nrank = grouped_m['Pressure'].argsort().argsort() \ng = sns.barplot(x=\"MonthOfYear\", y='Pressure', data=grouped_m, palette=np.array(pal[::-1])[rank], ax=ax6)\nax6.set_xlabel('')\n\nax7.set_title('Mean Humidity by Hour')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_h))\nrank = grouped_h['Humidity'].argsort().argsort() \ng = sns.barplot(x=\"TimeOfDay(h)\", y='Humidity', data=grouped_h, palette=np.array(pal[::-1])[rank], ax=ax7)\n\nax8.set_title('Mean Humidity by Month')\npal = sns.color_palette(\"YlOrRd_r\", len(grouped_m))\nrank = grouped_m['Humidity'].argsort().argsort() \ng = sns.barplot(x=\"MonthOfYear\", y='Humidity', data=grouped_m, palette=np.array(pal[::-1])[rank], ax=ax8)\n\nplt.show()","cell_type":"code","execution_count":13},{"metadata":{"_uuid":"5dfa600d87a6ad708e108ac212adffa0c958760a","_cell_guid":"ac944e13-a5ed-43dc-882f-06646024c3bc"},"source":"From the above plots, its clear that temperature has strong corellation with solar irradiance. Relationships between pressure/humidity and solar irradiance are less clear but it does appear that humidity has a negative correlation with solar irradiance, temperature and pressure.\n\nAs expected solar irradiance and temperature both peak at approximately 12:00. Additionally, monthly means of both solar irradiance and temperature appear to decrease as winter approaches, with the exception of a very slight increase in solar irradiance from September to October.","cell_type":"markdown"},{"metadata":{"_uuid":"e34535d7766b032834a45467a108da77b6055ade","_cell_guid":"021feea0-2935-4a33-a168-7e7231b9d87a"},"source":"## **Pearson Correlation**\nTo further help visualise any realtionships between the variables, a pearson correlation heatmap was plotted. \n\nFrom the plots in the previous section it is clear that solar irradiance does not have a linear correlation with time of day. Therefore, despite the strong realtionship between the two, 'TimeOfDay' columns were excluded from the heatmap. 'UNIXTime', 'MonthOfYear' and 'WeekOfYear' were also excluded because it is likely to more useful to use a combination of 'TimeOfDay' and 'DayOfYear' in training and prediction.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"1c4240a722b365f62c2ef2ebfc41e50881ba7bef","_cell_guid":"6c7e4ffc-6412-40eb-8054-8c580d5d049e"},"outputs":[],"source":"corrmat = dataset.drop(['TimeOfDay(h)', 'TimeOfDay(m)', 'TimeOfDay(s)', 'UNIXTime', 'MonthOfYear', 'WeekOfYear'], inplace=False, axis=1)\ncorrmat = corrmat.corr()\nf, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(corrmat, vmin=-.8, vmax=.8, square=True, cmap = 'coolwarm')\nplt.show()","cell_type":"code","execution_count":5},{"metadata":{"_uuid":"4a8711b71be665030cdabd03a42c9fbb09a10d57","_cell_guid":"7749f5e8-02a0-4cb2-8f8f-c2d3479670f2"},"source":"The correlation heatmap confirms the relationships suggested in the previous sections. It also suggests that the day of year will have a significantly weaker influence on solar irradiance compared to temperature.","cell_type":"markdown"},{"metadata":{"_uuid":"de1af0c83b421f1be5977b30e09790329f1b10f2","_cell_guid":"2cba2809-dfd8-45ef-9a04-340862293c88"},"source":"## **Separating the Independent and Dependent Variables**\nAll recorded meteorological variables, except solar irradiance, were included in the independent variables. 'DayOfYear' and 'TimeOfDay(s)' were selected to represent date and time. This would ensure no problems were encountered if predictions for another year were to be made.\n\nSolar Irradiance was of course set as the independent variable.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"94689e3f236c664a9c5af244ce2509dcfed6bd8e","_cell_guid":"f41f040b-59d3-4fac-9f78-39853f7add95"},"outputs":[],"source":"X = dataset[['Temperature', 'Pressure', 'Humidity', 'WindDirection(Degrees)', 'Speed', 'DayOfYear', 'TimeOfDay(s)']]\ny = dataset['Radiation']","cell_type":"code","execution_count":6},{"metadata":{"_uuid":"57bca891c48322b44957c3f723f570e181cee7c8","_cell_guid":"2dbe8f14-5e68-46f0-9bcc-7ecb3fc53b6b"},"source":"## **Splitting the Dataset**\nThe dataset was subsequently split into a training and test set, with an 80%, 20% split respectively.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"d151892b5a0670c52c13b3080965c9568409a2f2","_cell_guid":"2a5f4654-b705-419d-8c48-8644e45a5e2c"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","cell_type":"code","execution_count":7},{"metadata":{"_uuid":"5d954f636a4f0b65bab0b7fb9c276083d3ae052b","_cell_guid":"c6726164-be66-4f3c-93cf-a7777c6b8efe"},"source":"## **Feature Selection**\nAlthough linear regressors can be used to estimate the importance of different features, it was felt that in this situation, with relatively nonlinear data, that this method would not be suitable. Fortunately, sci-kit learn's decision tree based regressors contain a feature importance attribute. This attribute was used to perform a backwards elimination procedure, where the least important feature of the regressor was repeatedly removed and the r<sup>2</sup> scores, from cross validation, of each model were recorded.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"a6350b0cb4bfd731b388f50785f5cda46cafeb84","_cell_guid":"e3602c9c-b330-485a-bc16-2f05ccde444c"},"outputs":[],"source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nregressor = RandomForestRegressor(n_estimators = 100)\nregressor.fit(X_train, y_train)\nfeature_importances = regressor.feature_importances_\n\nX_train_opt = X_train.copy()\nremoved_columns = pd.DataFrame()\nmodels = []\nr2s_opt = []\n\nfor i in range(0,5):\n    least_important = np.argmin(feature_importances)\n    removed_columns = removed_columns.append(X_train_opt.pop(X_train_opt.columns[least_important]))\n    regressor.fit(X_train_opt, y_train)\n    feature_importances = regressor.feature_importances_\n    accuracies = cross_val_score(estimator = regressor,\n                                 X = X_train_opt,\n                                 y = y_train, cv = 5,\n                                 scoring = 'r2')\n    r2s_opt = np.append(r2s_opt, accuracies.mean())\n    models = np.append(models, \", \".join(list(X_train_opt)))\n    \nfeature_selection = pd.DataFrame({'Features':models,'r2 Score':r2s_opt})\nfeature_selection.head()","cell_type":"code","execution_count":8},{"metadata":{"_uuid":"172d647e0b042f28de28acf0ea36dc3e47ca5865","_cell_guid":"9deabf05-6d9d-4716-b788-6ae7636b1bb8"},"source":"From the dataframe output, it can be seen that model performance stays relatively constant until 'DayOfYear' is removed, leaving 'Temperature' and 'TimeOfDay(s)' as the only features. Without performing any parameter tuning it appears that the random forest regressor, fit to 'Temperature', 'TimeOfDay(s)' and 'DayOfYear' is able to acheive a r<sup>2</sup> score as high as 0.93.","cell_type":"markdown"},{"metadata":{"_uuid":"7192c5c9eb9997628fddcb31a9e03c5f276319d8","_cell_guid":"01aff242-81b4-487b-96e1-ba2a8e0df5b0"},"source":"## **Fitting the Regressor to the Key Features**\nGiven the result of the previous section the random forest regressor is trained using 'Temperature', 'TimeOfDay(s)' and 'DayOfYear'.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"6cd38aaa4f98c717de15a4065dba87e2362b5beb","_cell_guid":"7c73215e-2e47-4600-9c2a-e9b6139d6303"},"outputs":[],"source":"X_train_best = X_train[['Temperature', 'DayOfYear', 'TimeOfDay(s)']]\nX_test_best = X_test[['Temperature', 'DayOfYear', 'TimeOfDay(s)']]\nregressor.fit(X_train_best, y_train)","cell_type":"code","execution_count":9},{"metadata":{"_uuid":"7b8cc92d6e8854fca7956e5d7599db9587330816","_cell_guid":"2fd5ac6b-9916-4538-86b8-0cf3237a19c8"},"source":"## **Cross Validation**\nCross validation, with a greater number of folds, again shows an r<sup>2</sup> score of 0.93.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"facf4324e0bcbe6dc23fdddd50eb0fce8f0480b9","_cell_guid":"3a53f68b-f449-4121-889e-0f4a9b39829d"},"outputs":[],"source":"accuracies = cross_val_score(estimator = regressor, X = X_train_best,y = y_train, cv = 10, scoring = 'r2')\naccuracy = accuracies.mean()\nprint('r2 = {}'.format(accuracy))","cell_type":"code","execution_count":10},{"metadata":{"_uuid":"16d535b10a891dca264e504544b8df867b5635da","_cell_guid":"cd394f01-f942-4112-98b2-9a3eb324bdc9"},"source":"## **Predicting the Test Set**\nThe trained regressor is the used to predict and test set data, which was not involved in the training process. Explained variance, mean squared error and r<sup>2</sup> scores were output to evaluate the accuracy of the models predictions.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"263d9a2601b57e0af2cc514b9679208cef5f879c","_cell_guid":"2df933b3-7118-4fcf-bd1c-64f3ac9b26b4"},"outputs":[],"source":"from sklearn.metrics import explained_variance_score, mean_squared_error, r2_score\ny_pred = regressor.predict(X_test_best)\nexplained_variance_score = explained_variance_score(y_test, y_pred)\nmean_squared_error = mean_squared_error(y_test, y_pred)\nr_squared = r2_score(y_test, y_pred)\nprint('explained variance = {}'.format(explained_variance_score))\nprint('mse = {}'.format(mean_squared_error))\nprint('r2 = {}'.format(r_squared))","cell_type":"code","execution_count":11},{"metadata":{"_uuid":"5df773a84261b525b69e4166a26efcff2bd5ad01","_cell_guid":"f165f264-d380-40bd-b7bf-0750c14d6580"},"source":"The performance acheived when estimating the test set is very close to that found from cross validation, implying that the model is not overfit.","cell_type":"markdown"},{"metadata":{"_uuid":"5e8555236519359acf05698d7ba1fdd1a1384cf6","_cell_guid":"cdbdf103-c0b5-48f5-9ec7-74fe798194ae"},"source":"## **Visualising the Model**\nIn order to visualise the model, predictions were made for the entire dataset and an interactive plot created using the 'bokeh' library.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"48cc794951d20cd56d8e65935efc189130d14465","_cell_guid":"6af037a1-d9e9-46c9-b199-f56185123f7b"},"outputs":[],"source":"# Predicting for whole dataset\ndataset['y_pred'] = regressor.predict(dataset[['Temperature', 'DayOfYear', 'TimeOfDay(s)']])\n\n# Create Interactive Plot Using Bokeh\nfrom bokeh.plotting import figure, output_notebook, show\nfrom bokeh.models import Range1d\noutput_notebook() \n\np = figure(plot_width=800, \n           plot_height=400,\n           title=\"Solar Irradiance Predictions\",\n           x_axis_label='Date and Time',\n           y_axis_label='Solar Irradiance',\n           x_axis_type=\"datetime\")\np.x_range = Range1d(dataset.index[0], dataset.index[600])\np.y_range = Range1d(-100, 1800, bounds=(-100, 1800))\np.line(dataset.index, dataset['Radiation'], legend='Observed Solar Irradiance', line_width=1)\np.line(dataset.index, dataset['y_pred'], legend='Predicted Solar Irradiance', line_width=1, line_color=\"red\")\n\nshow(p, notebook_handle = True)","cell_type":"code","execution_count":12},{"metadata":{"_uuid":"0c81237d4149cee1f147a85bede0abf0aa8249f0","_cell_guid":"92ba1980-a91f-4acd-a535-996b346e1d13"},"source":"From the plot it can be see that the predictions closely match the observations.","cell_type":"markdown"},{"metadata":{"_uuid":"6721fe5c31eb704c9d81f52e3edeed7f1fa68dac","_cell_guid":"44f745aa-d97a-4228-8573-48a6aa0049fe"},"source":"## **Conclusion**\nThe variables most relevant to the prediction of solar irradiance were found to be temperature, time of day, and day of year. Training a random forest regressor with these three variables (with units of farenheit, seconds, and days respectively) produced a model that acheived a mean r<sup>2</sup> score of 0.93 when cross validation was performed. When comparing predictions to a test set, again, an r<sup>2</sup> score of approximately 0.93 was obtained.\n\nIt may be possible to tune the random forest regressor to obtain an even higher r<sup>2</sup> score but realisitically the model produced is unlikely to be any better at solar irradiance prediction, it will just fit the observations of one particular year extremely well. To create a more useful model, the regressor should be trained on data recorded over several years.\n\nSimilarly other types of regressors may perform better than the random forest regressor when trained on the same set of features, upon achieving such a high r<sup>2</sup> score with the random forest regressor little, thought was put into model selection.\n\nIf any one has any additional suggestions or comments please let me know :)","cell_type":"markdown"}],"nbformat_minor":1}