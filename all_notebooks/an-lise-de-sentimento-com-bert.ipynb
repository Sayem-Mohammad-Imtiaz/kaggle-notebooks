{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introdução\n\nOlá, já que este dataset é em português, vou fazer o markdown em português. Nesse notebook nós vamos prever o sentimento (positivo ou negativo) de um comentário no IMDB. Para tanto, faremos uso do poderoso BERT.\n\nO BERT é um modelo de linguagem baseado no Transformer. Ele é essencialmente o encoder do Transformer, e é muito adequado em casos onde você já tem a mensagem inteira para processar, o que é o caso da análise de sentimentos (mas não é o caso da geração de texto, por exemplo).\n\nVamos utilizar a implementação de Hugginface. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport os\nimport pickle\nfrom dataclasses import dataclass\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport torch\nimport torch.nn.functional as F\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data.dataset import Dataset\nfrom transformers import AdamW, BertForSequenceClassification, BertTokenizer\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm as tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lendo e entendendo os dados","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/imdb-ptbr/imdb-reviews-pt-br.csv', index_col=0)\ndata.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos ver a distribuição de classes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('sentiment').count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, o dataset está bem balanceado, o que nos conduz a utilizar acurácia como métrica.\n\nAgora vamos ver o comprimento dos comentários. Você pode definir o tamanho de sentença que quiser no BERT, mas o modelo pré-treinado vem com um tamanho pré-definido. No nosso caso vamos utilizar o modelo em português da Neural Mind, que tem 512 tokens de tamanho limite de sentença. Treinar um modelo do zero é muito caro e demorado, por isso é sempre bom partir de um modelo pré-treinado e fazer um fine-tuning. \n\nProvavelmente existe algum jeito de extender o modelo pré-treinado para um número maior de tokens. Mas, por simplicidade, eu simplesmente usei somente os comentários que tem até 512 tokens, que são a grande maioria. \n\nO gráfico a seguir mostra o comprimento da sentença. Note que é em caracteres, não em tokens.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text_pt'].apply(len).hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Treinamento\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Criando os splits\n\n90/5/5 splits","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dev_size = int(0.05*data.shape[0])\ntrain_dev, test = train_test_split(data, test_size=test_dev_size, random_state=42, stratify=data['sentiment'])\ntrain, dev = train_test_split(train_dev, test_size=test_dev_size, random_state=42, stratify=train_dev['sentiment'])\nprint('Training samples:', train.shape[0])\nprint('Dev samples:     ', dev.shape[0])\nprint('Test samples:    ', test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definindo a classe que vai carregar o nosso dataset\n\nEssa classe vai tokenizar os exemplos e fornecer os pares de inputs e labels para o modelo.\n\nEla também vai cuidar de criar um cache pra esse dataset, já que tokenizar é bem demorado","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass ImdbPt(Dataset):\n    ''' Loads IMDB-pt dataset. \n    \n    It will tokenize our inputs and cut-off those that exceed 512 tokens (the pretrained BERT limit)\n    '''\n    \n    def __init__(self, tokenizer, data, cachefile, rebuild=False):\n        if os.path.isfile(cachefile) and rebuild is False:\n            self.deserialize(cachefile)\n        else:\n            self.build(tokenizer, data)\n            self.serialize(cachefile)\n        \n    \n    def build(self, tokenizer, data):    \n        data = data.copy()\n    \n        tqdm.pandas()\n        data['tokenized'] = data['text_pt'].progress_apply(tokenizer.tokenize)\n        \n        data['input_ids'] = data['tokenized'].apply(\n            lambda tokens: tokenizer.build_inputs_with_special_tokens(\n                tokenizer.convert_tokens_to_ids(tokens)))\n        \n        data = data[data['input_ids'].apply(len)<512]\n        \n        data['labels'] = (data['sentiment'] == 'pos').astype(int)\n        \n        self.examples = data[['input_ids', 'labels']].to_dict('records')\n    \n    def __getitem__(self, i):\n        if isinstance(i, int):\n            return {key: torch.tensor(value) for key, value in self.examples[i].items()}\n        else:\n            return [{key: torch.tensor(value) for key, value in sample.items()} for sample in self.examples[i]]\n     \n    def __len__(self):\n        return len(self.examples)\n    \n    def serialize(self, cachefile):\n        with open(cachefile, 'wb') as file:\n            pickle.dump(self.examples, file)\n    \n    def deserialize(self, cachefile):\n        with open(cachefile, 'rb') as file:\n            self.examples = pickle.load(file)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definindo um colador de dados\n\nEssa função recebe um conjunto de exemplos e devolve um mini-batch para passar para rede, ou seja, ele junta os tensores dos exemplos em um batch, cuidando de fazer o padding. Também cuida de incluir uma attention_mask, que indica os tokens que não são padding para o modelo.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_collator(examples, tokenizer):\n    data = {}\n    data['input_ids'] = pad_sequence(\n            [ex['input_ids'] for ex in examples],\n            batch_first=True,\n            padding_value=tokenizer.pad_token_id)\n    data['labels'] = torch.tensor([ex['labels'] for ex in examples])\n    \n    attention_mask = torch.zeros(data['input_ids'].shape, dtype=torch.long)\n    attention_mask[data['input_ids'] != tokenizer.pad_token_id] = 1   \n    data['attention_mask'] = attention_mask\n    return data\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definindo o data loader\n\nEssa classe cuida de carregar o dataset, em mini-batches, para o treinamento da rede","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"@dataclass\nclass DataLoader:\n    dataset: ImdbPt\n    tokenizer: BertTokenizer\n    batch_size: int\n\n    def __iter__(self):\n        dataset = self.dataset\n        tokenizer = self.tokenizer\n        batch_size = self.batch_size\n        for start in range(0, len(dataset) - batch_size, batch_size):\n            yield data_collator(dataset[start: start+batch_size], tokenizer)\n\n    def __len__(self):\n        return math.ceil(len(self.dataset)/self.batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definindo função auxiliares","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def send_inputs_to_device(inputs, device):\n    return {key:tensor.to(device) for key, tensor in inputs.items()}\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparando os dados para o treino","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\ntrain_dataset = ImdbPt(tokenizer, train, '/kaggle/working/train.pkl')\ndev_dataset   = ImdbPt(tokenizer, dev,   '/kaggle/working/dev.pkl')\ntest_dataset  = ImdbPt(tokenizer, test,  '/kaggle/working/test.pkl')\nprint('Preserved: \\n\\t Train: {:.2f}% \\t Dev: {:.2f}% \\t Test: {:.2f}%'.format(\n    100 * len(train_dataset) / len(train), \n    100 * len(dev_dataset) / len(dev), \n    100 * len(test_dataset) / len(test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embora tenhamos tirado os exemplos com mais de 512, preservamos a grande maioria.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_dataset, tokenizer, 8)\ndev_loader = DataLoader(dev_dataset, tokenizer, 16)\ntest_loader = DataLoader(test_dataset, tokenizer, 16)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Carregando o modelo e otimizador\n\nAqui nós definimos uma coisa extra que é começar o modelo com a parte pré treinada do BERT congelada. Assim a gente permite aos pesos do layer de classificação se acomodarem antes de começar a fazer o fine-tune na rede toda.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\n    'neuralmind/bert-base-portuguese-cased')\nmodel.train()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr=5e-6)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9997)\n\n\nfor param in model.base_model.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treinando o modelo\n\nAqui vamos fazer a avaliação no devset a cada 200 passos. \nNo passo 800 vamos soltar os pesos do modelo base do BERT pra aprender.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"   \ndef evaluate(model, dev_loader, device):\n    with torch.no_grad():\n        model.eval()\n        dev_losses = []\n        tp, tn, fp, fn = [], [], [], []\n        for inputs in dev_loader:\n            inputs = send_inputs_to_device(inputs, device)\n            loss, scores = model(**inputs)[:2]\n            dev_losses.append(loss.cpu().item())\n\n            _, classification = torch.max(scores, 1)\n            labels = inputs['labels']\n            tp.append(((classification==1) & (labels==1)).sum().cpu().item())\n            tn.append(((classification==0) & (labels==0)).sum().cpu().item())\n            fp.append(((classification==1) & (labels==0)).sum().cpu().item())\n            fn.append(((classification==0) & (labels==1)).sum().cpu().item())\n\n        tp_s, tn_s, fp_s, fn_s = sum(tp), sum(tn), sum(fp), sum(fn)\n        print('Dev loss: {:.2f}; Acc: {:.2f}; tp: {}; tn: {}; fp: {}; fn: {}'.format( \n              np.mean(dev_losses), (tp_s+tn_s)/(tp_s+tn_s+fp_s+fn_s), tp_s, tn_s, fp_s, fn_s))\n\n        model.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_bar = tqdm_notebook(range(1))\nloss_acc = 0\nalpha = 0.95\nfor epoch in epoch_bar:\n    batch_bar = tqdm_notebook(enumerate(train_loader), desc=f'Epoch {epoch}', total=len(train_loader))\n    for idx, inputs in batch_bar:\n        if (epoch * len(train_loader) + idx) == 800:\n            for param in model.base_model.parameters():\n                param.requires_grad = True\n\n        inputs = send_inputs_to_device(inputs, device)\n        optimizer.zero_grad()\n        loss, logits = model(**inputs)[:2]\n        \n        loss.backward()\n        optimizer.step()\n        if epoch == 0 and idx == 0:\n            loss_acc = loss.cpu().item()\n        else:\n            loss_acc = loss_acc * alpha + (1-alpha) * loss.cpu().item()\n        batch_bar.set_postfix(loss=loss_acc)\n        if idx%200 == 0:\n            del inputs\n            del loss\n            evaluate(model, dev_loader, device)\n\n        scheduler.step()\n    os.makedirs('/kaggle/working/checkpoints/epoch'+str(epoch))\n    model.save_pretrained('/kaggle/working/checkpoints/epoch'+str(epoch))   \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validando o modelo\n\nAgora vamos verificar o desempenho no dev set. Vamos ver a curva ROC e tb qual o melhor threshold de classificação com respeito a nossa métrica escolhida, acurácia","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    pred = []\n    labels = []\n    for inputs in tqdm_notebook(dev_loader):\n        inputs = send_inputs_to_device(inputs, device)\n        _, scores = model(**inputs)[:2]\n        pred.append(F.softmax(scores, dim=1)[:, 1].cpu())\n        labels.append(inputs['labels'].cpu())\npred = torch.cat(pred).numpy()\nlabels = torch.cat(labels).numpy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(labels, pred, pos_label=1)\nroc_auc = metrics.auc(fpr, tpr)\n\nfig = px.scatter(\n    x=fpr, y=tpr, color=thresholds, \n    labels={'x': 'False positive rate', 'y': 'True positive rate'},\n    title='Curva ROC')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = []\nfor th in thresholds:\n    acc.append((~((pred > th) ^ (labels == 1))).sum()/len(labels))\n\nfig2 = px.scatter(\n    x=thresholds, y=acc, labels={'x': 'threshold', 'y': 'acurácia'}, \n    title='Acurácia em diferentes thresholds')\nfig2.show()  \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Avaliação final\n\nFinalmente vamos avaliar o modelo no conjunto de test com o threshold escolhido","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    pred = []\n    labels = []\n    for inputs in tqdm_notebook(test_loader):\n        inputs = send_inputs_to_device(inputs, device)\n        _, scores = model(**inputs)[:2]\n        pred.append(F.softmax(scores, dim=1)[:, 1].cpu())\n        labels.append(inputs['labels'].cpu())\npred = torch.cat(pred).numpy()\nlabels = torch.cat(labels).numpy()\n\nprint('Acc:', (~((pred > 0.67) ^ (labels == 1))).sum()/len(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusão\n\nNesse notebook mostramos como usar o BERT para fazer análise de sentimento. \nSe você gostou do notebook, não esquece de soltar o upvote. \n\nVlw!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}