{"cells":[{"metadata":{"_cell_guid":"5dd23c81-785f-4441-9539-4b7b427b89e7","_uuid":"6f331965c0fb126e54a7e94e0c5b7505830dbc74","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nimport string\nimport random\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport _pickle as pickle\nimport os.path\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.utils import shuffle\nfrom skimage import img_as_float\n\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9deaf1f1-1cbb-4dd6-89e3-1e00157fb5e1","collapsed":true,"_uuid":"65e2f8b97731a3948a7cee60a01842d2395eb24b","trusted":true},"cell_type":"code","source":"csv_file_path = '../input/handwritten_data_785.csv'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ed1b8371-5790-484c-9931-0356a73fd8be","_uuid":"ca29d7d22acdac086bcfb1ce58ff5b987ae2f38a","trusted":true},"cell_type":"code","source":"def normalize(image_data, a=0.00, b=1.00):\n    return a + (image_data - image_data.min()) * (b - a) / (image_data.max() - image_data.min())\n\ndef read_data(file_path):\n    labels = list()\n    images = list()\n    \n    with open(file_path) as csv_file:\n        reader = csv.reader(csv_file)\n        for row in reader:\n            labels.append(row[0])\n            image = np.array(row[1:], dtype=np.float32)\n            image = normalize(image)\n            images.append(image)\n        \n        return np.array(images, dtype=np.float32) , np.array(labels, dtype=np.float32)\nX, Y = read_data(csv_file_path)\n    \nprint('X shape: {}'.format(X.shape))\nprint('Y shape: {}'.format(Y.shape))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bf18ddd6-697b-47d7-8ee0-53fa8e845130","_uuid":"e8067f570f730779139293d1fca9d010bb2c2e6d","trusted":true},"cell_type":"code","source":"one_hot_enc = OneHotEncoder(sparse=False)\ny_one_hot = one_hot_enc.fit_transform(Y.reshape(-1, 1))\nprint('y_one_hot shape: {}'.format(y_one_hot.shape))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4d4c2824-031b-43fc-867f-eebd414a5d71","_uuid":"34c5695350e79836cdac6c4c31012284472cbff8","trusted":true},"cell_type":"code","source":"digit_to_letter_map = { k: v for k, v in enumerate(string.ascii_uppercase, 0)}\nn_classes = len(digit_to_letter_map)\nn_features = X.shape[1]\nprint(digit_to_letter_map)\nprint()\nprint('Features: {}'.format(n_features))\nprint('Classes: {}'.format(n_classes))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7fa19ba6-5c15-4a39-8db9-0cf2af9d9e07","_uuid":"e1a82cb6f32f33ac14bea7162ff340f65e548d9f","trusted":true},"cell_type":"code","source":"X_train, XX, y_train, yy = train_test_split(X, y_one_hot, test_size=0.4)\nX_valid, X_test, y_valid, y_test = train_test_split(XX, yy, test_size=0.6, shuffle=True)\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_valid shape: {}'.format(X_valid.shape))\nprint('y_valid shape: {}'.format(y_valid.shape))\nprint('X_test shape: {}'.format(X_test.shape))\nprint('y_test shape: {}'.format(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7f1cb5da-98e5-4850-b24c-311ff5bef1fe","_uuid":"500a06a17d946ea9813561eb4bd8e1c3d353c886","trusted":true},"cell_type":"code","source":"def plot_class_distribution(dataset, title):\n    plt.hist(np.argmax(dataset, axis=1))\n    plt.title(title)\n    plt.show()\n\nplot_class_distribution(y_train, 'Training classes distribution')\nplot_class_distribution(y_valid,'Validation classes distribution')\nplot_class_distribution(y_test, 'Test classes distribution')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bbddcbcb-ffe6-4b53-a0b5-09dd8301ce5c","_uuid":"47a1f80e02423e3cea05cccada3aedbcea85f756","trusted":true},"cell_type":"code","source":"def plot_image(image, title, cmap='gray'):\n    plt.imshow(image, cmap=cmap)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(title)\n    plt.show()\n\nn_samples = 5\nfor i in range(n_samples):\n    index = random.randint(0, X_train.shape[0])\n    image = X_train[index].reshape((28, 28))\n    title = digit_to_letter_map[np.argmax(y_train[index])]\n    plot_image(image, title)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7eeec997-78fb-490f-923a-51a893e1ed1d","collapsed":true,"_uuid":"d653f6d6f90dbd46efb2af3dd55ddf942d5c5573","trusted":true},"cell_type":"code","source":"def layer(x, weight_shape, bias_shape, scope, activation):\n    weight_stddev = (2.0 / weight_shape[0]) ** 0.5\n    weight_init = tf.random_normal_initializer(stddev=weight_stddev)\n    bias_init = tf.constant_initializer(value=0)\n    with tf.variable_scope(scope) as scope:\n        W = tf.get_variable('W', weight_shape, initializer=weight_init)\n        b = tf.get_variable('b', bias_shape, initializer=bias_init)\n        output = tf.matmul(x, W) + b\n        if activation == 'softmax':\n            return tf.nn.softmax(output)\n        if activation == 'relu':\n            return tf.nn.relu(output)\n        \n        return output","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f42eb28e-aaa6-423f-9530-4614d01c2d04","collapsed":true,"_uuid":"e5643871fda9b27ca3673ef8a94af6ab59c3901b","trusted":true},"cell_type":"code","source":"def network(x):\n    out1 = layer(x, [n_features, 128], [128], scope='layer1', activation='relu')\n    out2 = layer(out1, [128, 128], [128], scope='layer2', activation='relu')\n    output = layer(out2, [128, n_classes], [n_classes], scope='output', activation='softmax')\n    return output\n\ndef training(logits, labels, lr):\n    loss_op = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n    return optimizer.minimize(loss_op)\n\ndef evaluate(logits, labels):\n    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"87d21946-94c5-4914-bca6-5f923db9b513","collapsed":true,"_uuid":"2bfcf48ea677b8badf3ee480b109bbf290e836c7","trusted":true},"cell_type":"code","source":"learning_rate = 0.001\ntraining_epochs = 100\nbatch_size = 256\ndisplay_step = 10","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f908c7e1-a979-4879-bdcf-789832c469c9","_uuid":"9eff7083576394f3585607ec82221e0375415a85","trusted":true},"cell_type":"code","source":"features = tf.placeholder(tf.float32, [None, n_features])\nlabels = tf.placeholder(tf.float64, [None, n_classes])\n\nlogits = network(features)\neval_op = evaluate(logits, labels)\ntrain_op = training(logits, labels, lr=learning_rate)\ninit_op = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    sess.run(init_op)\n    for epoch in range(training_epochs):\n        for i in range(0, X_train.shape[0], batch_size):\n            batch_x, batch_y = X_train[i:i+batch_size], y_train[i:i+batch_size]\n            feed_dict = {features: batch_x, labels: batch_y}\n            sess.run(train_op, feed_dict=feed_dict)\n            \n        if epoch % display_step == 0:\n            valid_feed_dict = {features: X_valid, labels: y_valid}\n            train_feed_dict = {features: X_train, labels: y_train}\n            train_acc = sess.run(eval_op, feed_dict=train_feed_dict)\n            valid_acc = sess.run(eval_op, feed_dict=valid_feed_dict)\n            print('Epoch: {0}: Training accuracy: {1} Validation accuracy: {2}'.format(epoch, train_acc, valid_acc))\n            \n    print('Training complete')\n    \n    test_feed_dict = {features: X_test, labels: y_test}\n    test_acc = sess.run(eval_op, feed_dict=test_feed_dict)\n    print('Test accuracy: {}'.format(test_acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}