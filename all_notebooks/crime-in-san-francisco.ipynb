{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-08T19:04:04.965503Z","iopub.execute_input":"2021-08-08T19:04:04.965831Z","iopub.status.idle":"2021-08-08T19:04:04.981716Z","shell.execute_reply.started":"2021-08-08T19:04:04.965787Z","shell.execute_reply":"2021-08-08T19:04:04.980395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#In this competition we will analyse a dataset storing criminal records of the state of San Francisco spanning 12 years.\n#So let's get started!\n#First we will import the necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom lightgbm import LGBMClassifier\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:09.784584Z","iopub.execute_input":"2021-08-08T19:04:09.784935Z","iopub.status.idle":"2021-08-08T19:04:09.792121Z","shell.execute_reply.started":"2021-08-08T19:04:09.7849Z","shell.execute_reply":"2021-08-08T19:04:09.791166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the train and test dataset\ntrain=pd.read_csv('../input/sfcrime/train.csv/train.csv',parse_dates=['Dates'])\ntest=pd.read_csv('../input/sfcrime/test.csv/test.csv',parse_dates=['Dates'],index_col=['Id'])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:12.204735Z","iopub.execute_input":"2021-08-08T19:04:12.205117Z","iopub.status.idle":"2021-08-08T19:04:15.825485Z","shell.execute_reply.started":"2021-08-08T19:04:12.205086Z","shell.execute_reply":"2021-08-08T19:04:15.82463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check the dimensions of the input datasets to get an idea of their size.\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:18.584466Z","iopub.execute_input":"2021-08-08T19:04:18.58478Z","iopub.status.idle":"2021-08-08T19:04:18.590375Z","shell.execute_reply.started":"2021-08-08T19:04:18.584752Z","shell.execute_reply":"2021-08-08T19:04:18.58945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:20.464377Z","iopub.execute_input":"2021-08-08T19:04:20.464701Z","iopub.status.idle":"2021-08-08T19:04:20.469916Z","shell.execute_reply.started":"2021-08-08T19:04:20.46467Z","shell.execute_reply":"2021-08-08T19:04:20.468967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:22.444865Z","iopub.execute_input":"2021-08-08T19:04:22.445267Z","iopub.status.idle":"2021-08-08T19:04:22.476914Z","shell.execute_reply.started":"2021-08-08T19:04:22.445232Z","shell.execute_reply":"2021-08-08T19:04:22.476142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:25.2044Z","iopub.execute_input":"2021-08-08T19:04:25.204715Z","iopub.status.idle":"2021-08-08T19:04:25.218778Z","shell.execute_reply.started":"2021-08-08T19:04:25.204683Z","shell.execute_reply":"2021-08-08T19:04:25.217907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the datatypes of each column in the train dataset\ntrain.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:28.564367Z","iopub.execute_input":"2021-08-08T19:04:28.564678Z","iopub.status.idle":"2021-08-08T19:04:28.57396Z","shell.execute_reply.started":"2021-08-08T19:04:28.564649Z","shell.execute_reply":"2021-08-08T19:04:28.573041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we will do a generic cleaning of the dataset,i.e. replacing nulls, removing duplicates and modifying outliers.\n\n#Checking for null values\nprint(train.isnull().values.any())\n#Checking for duplicated rows\nprint(train.duplicated(keep='first').value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:31.969667Z","iopub.execute_input":"2021-08-08T19:04:31.970025Z","iopub.status.idle":"2021-08-08T19:04:33.055078Z","shell.execute_reply.started":"2021-08-08T19:04:31.969993Z","shell.execute_reply":"2021-08-08T19:04:33.054136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing duplicated rows from the train dataset\ntrain.drop_duplicates(inplace=True)\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:35.304447Z","iopub.execute_input":"2021-08-08T19:04:35.304773Z","iopub.status.idle":"2021-08-08T19:04:35.987747Z","shell.execute_reply.started":"2021-08-08T19:04:35.304744Z","shell.execute_reply":"2021-08-08T19:04:35.986691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now let's check out the columns X and Y, which seem to refer to longitude and latitude of crime scene respectively.\nprint(train[['X','Y']].describe())\nprint(test[['X','Y']].describe())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:38.564411Z","iopub.execute_input":"2021-08-08T19:04:38.564726Z","iopub.status.idle":"2021-08-08T19:04:38.695029Z","shell.execute_reply.started":"2021-08-08T19:04:38.564697Z","shell.execute_reply":"2021-08-08T19:04:38.694029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Something weird! The X column seems fine, but the Y column (latitude) has a max value of 90 degree (North Pole!)\n#These are clearly outliers and need to be dealt with.\n#Let's check out how many of such rows are present.\n#We choose the lower limit of Y as 38 bcoz upto 75% of Y's distribution, value is 37.78 (< 38).\nprint(train[['PdDistrict','X','Y']].loc[train['Y']>38])\nprint(test[['PdDistrict','X','Y']].loc[test['Y']>38])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:40.884533Z","iopub.execute_input":"2021-08-08T19:04:40.884872Z","iopub.status.idle":"2021-08-08T19:04:40.918506Z","shell.execute_reply.started":"2021-08-08T19:04:40.884839Z","shell.execute_reply":"2021-08-08T19:04:40.917617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Instead of removing these outliers (which would mean loss of valuable data), we will first replace them with NaNs and then\n#use SimpleImputer to replace these values with the average X,Y values for the corresponding district.\ntrain.replace({'X':-120.5,'Y':90.0},np.nan,inplace=True)\ntest.replace({'X':-120.5,'Y':90.0},np.nan,inplace=True)\nsimp=SimpleImputer(strategy='mean')\n\nfor dist in train['PdDistrict'].unique():\n    train.loc[train['PdDistrict']==dist,['X','Y']]=simp.fit_transform(train.loc[train['PdDistrict']==dist,['X','Y']])\n    test.loc[test['PdDistrict']==dist,['X','Y']]=simp.transform(test.loc[test['PdDistrict']==dist,['X','Y']])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:43.809528Z","iopub.execute_input":"2021-08-08T19:04:43.809857Z","iopub.status.idle":"2021-08-08T19:04:50.057524Z","shell.execute_reply.started":"2021-08-08T19:04:43.809819Z","shell.execute_reply":"2021-08-08T19:04:50.056666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's have a look at the timespan of this dataset.\ntrain['Dates'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:04:57.445568Z","iopub.execute_input":"2021-08-08T19:04:57.445939Z","iopub.status.idle":"2021-08-08T19:04:57.510965Z","shell.execute_reply.started":"2021-08-08T19:04:57.445904Z","shell.execute_reply":"2021-08-08T19:04:57.509992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the description of important categorical variables like Category, PdDistrict etc.\n#will give us some useful insights related to the data.\ntrain.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:05:00.654486Z","iopub.execute_input":"2021-08-08T19:05:00.654804Z","iopub.status.idle":"2021-08-08T19:05:02.359854Z","shell.execute_reply.started":"2021-08-08T19:05:00.654773Z","shell.execute_reply":"2021-08-08T19:05:02.358841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The previous table gave us the info about top categories of crime, day of the week with most crimes, \n#district with maximum crimes and many more...\n#Let's analyze them one by one.\n\n#First we will analyze crime by district with the help of a bar plot.\ndistcrime=train['PdDistrict'].value_counts().sort_values(ascending=False)\n\nplt.figure(figsize=(12,12))\nwith sns.axes_style('darkgrid'):\n    ax=sns.barplot(distcrime.values/(distcrime.values.sum())*100.0,distcrime.index,orient='h',palette='Blues_r')\n\nplt.title('Crime percentage by District')    \nplt.xlabel('Crime Percentage')\nplt.ylabel('District')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:05:05.204781Z","iopub.execute_input":"2021-08-08T19:05:05.205206Z","iopub.status.idle":"2021-08-08T19:05:05.721461Z","shell.execute_reply.started":"2021-08-08T19:05:05.20517Z","shell.execute_reply":"2021-08-08T19:05:05.720585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The previous plot clearly shows that Southern district has the worst record in overall crime incidents.\n#Now let's analyze crime by category.\ncatcrime=train['Category'].value_counts().sort_values(ascending=False)\n\nplt.figure(figsize=(12,12))\nwith sns.axes_style('darkgrid'):\n    ax=sns.barplot(catcrime.values/(catcrime.values.sum())*100.0, catcrime.index,orient='h',palette='Greens_r')\n    \nplt.xlabel('Crime Percentage')    \nplt.ylabel('Category')\nplt.title('Crime distribution by category')    ","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:05:10.264571Z","iopub.execute_input":"2021-08-08T19:05:10.264903Z","iopub.status.idle":"2021-08-08T19:05:11.134352Z","shell.execute_reply.started":"2021-08-08T19:05:10.264872Z","shell.execute_reply":"2021-08-08T19:05:11.133541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The previous plot clearly shows that Larceny/theft is the most common category of crime.\n#Now let's see which district records the most cases of theft.\n\ndf=train.groupby('Category').get_group('LARCENY/THEFT')\ntheft=df.sort_values('PdDistrict')['PdDistrict'].value_counts()\n\nplt.figure(figsize=(12,12))\nwith sns.axes_style('darkgrid'):\n    ax=sns.barplot(theft.values/(theft.values.sum())*100.0,theft.index,orient='h',palette='Reds_r')\n    \nplt.xlabel('Larceny/Theft Percentage')    \nplt.ylabel('District')\nplt.title('Theft percentage by district')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:05:14.629728Z","iopub.execute_input":"2021-08-08T19:05:14.630076Z","iopub.status.idle":"2021-08-08T19:05:15.311395Z","shell.execute_reply.started":"2021-08-08T19:05:14.630046Z","shell.execute_reply":"2021-08-08T19:05:15.31028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hence Southern is the district to look out for if you don't want your pockets picked :P\n#Now, finding crimes sorted by days of the week...\n\ncrimeday=train['DayOfWeek'].value_counts()\n\nwith sns.axes_style('darkgrid'):\n    ax=sns.barplot(crimeday.values/(crimeday.values.sum())*100.0,crimeday.index,orient='h',palette='Greens_r')\n    \nplt.xlabel('Crime Percentage')    \nplt.ylabel('Day of the Week')\nplt.title('Crime percentage by day of the week')    ","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:05:18.644675Z","iopub.execute_input":"2021-08-08T19:05:18.645026Z","iopub.status.idle":"2021-08-08T19:05:19.051265Z","shell.execute_reply.started":"2021-08-08T19:05:18.644995Z","shell.execute_reply":"2021-08-08T19:05:19.050415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now that we have done a decent amount of data visualization, \n#we will do some feature engineering to make the models work.\ndef feature_engineering(df):\n    df['n_days']=(df['Dates'] - df['Dates'].min()).apply(lambda x: x.days)\n    df['Day']=df['Dates'].dt.day\n    df['Month']=df['Dates'].dt.month\n    df['Year']=df['Dates'].dt.year\n    df['Hour']=df['Dates'].dt.hour\n    df['Minute']=df['Dates'].dt.minute\n    df['Block']=df['Address'].str.contains('Block',case=False).apply(lambda x:0 if x==False else 1)\n    df['Street']=df['Address'].str.contains('St', case=False).apply(lambda x:0 if x == False else 1)\n    df['X-Y']=df['X']-df['Y']\n    df['X+Y']=df['X']+df['Y']\n    \n    \nfeature_engineering(train)    \nfeature_engineering(test)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:05:21.904649Z","iopub.execute_input":"2021-08-08T19:05:21.905004Z","iopub.status.idle":"2021-08-08T19:05:51.075768Z","shell.execute_reply.started":"2021-08-08T19:05:21.904974Z","shell.execute_reply":"2021-08-08T19:05:51.07489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We will use the LabelEncoder to replace categorical variables with numerical values.\nle=LabelEncoder()\nle1=LabelEncoder()\n\ntrain['PdDistrict']=le.fit_transform(train['PdDistrict'])\ntest['PdDistrict']=le.transform(test['PdDistrict'])\n\ntrain['Category']=le1.fit_transform(train['Category'])\ny=train['Category']\n\ntrain['DayOfWeek']=le.fit_transform(train['DayOfWeek'])\ntest['DayOfWeek']=le.transform(test['DayOfWeek'])\n\ntrain.drop(columns=['Category','Dates','Descript','Resolution','Address'],inplace=True)\ntest.drop(columns=['Dates','Address'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T19:06:04.126234Z","iopub.execute_input":"2021-08-08T19:06:04.126548Z","iopub.status.idle":"2021-08-08T19:06:05.6532Z","shell.execute_reply.started":"2021-08-08T19:06:04.126518Z","shell.execute_reply":"2021-08-08T19:06:05.652305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finally, we will train the LGBMClassifier with train dataset and use it to \n#make predictions for the test dataset.\nlgb=LGBMClassifier(objective='multiclass',num_class=38,max_bin=465,max_delta_step=0.9,\n                   learning_rate=0.4,num_leaves=40,n_estimators=100)\nlgb.fit(train,y,categorical_feature=['DayOfWeek','PdDistrict'],eval_metric='logloss')\nprediction=lgb.predict_proba(test)\nsubm=pd.DataFrame(prediction, columns=le1.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), index=test.index)\nsubm.to_csv('submission.csv',index_label='Id')","metadata":{"execution":{"iopub.status.busy":"2021-08-08T18:55:09.664507Z","iopub.execute_input":"2021-08-08T18:55:09.66485Z"},"trusted":true},"execution_count":null,"outputs":[]}]}