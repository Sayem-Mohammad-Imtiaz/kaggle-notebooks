{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Summary of NoteBook\n### NoteBook consist of:\n#### 1. Load and  Explaore Dataset\n#### 2. Cleaning and Featue Engineering\n#### 3. Modelling and grid seach\n#### 4. Mistakes and Improvement (Please upvote if you found this notebook helpful )","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Problem\nA leading pet adoption agency is planning to create a virtual tour experience for their customers showcasing all animals that are available in their shelter. To enable this tour experience, you are required to build a Machine Learning model that determines type and breed of the animal based on its physical attributes and other factors.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Features Description\n<ul>\n<li>pet_id-\tUnique Pet Id </li>\n<li>issue_date-\tDate on which the pet was issued to the shelter </li>\n<li>listing_date-- Date when the pet arrived at the shelter\n<li>condition- Condition of the pet\n<li>color_type- color of the pet\n<li>length(m)- Length of the pet (in meter)\n<li>height(cm)- Height of the pet (in centimeter)\n<li>X1,X2- Anonymous columns\n<li>breed_category- Breed category of the pet (target variable)\n<li>pet_category- Category of the pet (target variable)\n    \n</ul>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Load Dataset and Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Importing libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score\n\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\n\n#from sklearn.ensemble import AdaBoostClassifier\n#from sklearn.linear_model import LogisticRegression\n#import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load CSV\n\ndata = pd.read_csv('/kaggle/input/hackerearth-pet-adoption-dataset/train.csv')\ntest = pd.read_csv('/kaggle/input/hackerearth-pet-adoption-hackathon-dataset/test.csv')\n\norigial=data.copy()\n\nprint('Train Data ---')\ndisplay(data.head(3))\nprint('Test Data ---')\ndisplay(data.tail(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## combine train and test data\n\ndata_com = pd.concat((data, test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Explore and clean Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## checking for null values\n\ndata_com.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## taking a look at some information about dataset\n\ndata_com.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## modify listing and issue date coloumn from object to datetime format\n\ndata_com.issue_date = pd.to_datetime(data_com.issue_date)\ndata_com.listing_date = pd.to_datetime(data_com.listing_date)\n\n## creating a new coloumn (time duration for delivery)\n\ndata_com['time_diff'] = data_com.listing_date - data_com.issue_date\ndata_com['time_diff'] = data_com.time_diff.dt.total_seconds()\n\n## applying log\n\ndata_com['time_diff'] = np.log1p(data_com['time_diff'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label encoding color_type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = ['color_type']\nfor c in col:\n    le = LabelEncoder()\n    data_com[c]=le.fit_transform(data_com[c])\n    \n## coverting height from cm to m\n\ndata_com['height'] = data_com['height(cm)']/100\ndata_com.drop(['height(cm)'], axis=1, inplace=True)\ndata_com.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## I found pet id to be useless as all the values are unique but some people \n## used it after splitting it ( ANSL_6 and 9903)\n\ndata_ = data_com.drop(['pet_id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Some new features which you can try \n\n#data_['L/H'] = np.round(data_['length(m)'] / data_['height'], 3)\n#data_['X1/X2'] = data_['X1'] / data_['X2']\n#data_ = data_com.drop(['pet_id'], axis=1)\n#data_['1'] = np.round(data_['length(m)'] * data_['height'], 3)\n#data_['2'] = np.round(data_['length(m)'] + data_['height'], 3)\n#data_['3'] = np.round(data_['length(m)'] - data_['height'], 3)\n#data_['4'] = data_['X1'] * data_['X2']\n#data_['5'] = data_['X1'] + data_['X2']\n#data_['6'] = data_['X1'] - data_['X2']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filling condtion with BY PREDICTING with XGBClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\ndata_condition_null = data_[data_.condition.isnull()==True]\ndata_condition_not_null = data_[data_.condition.isnull()==False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data_condition_not_null[['X1', 'X2', 'color_type', 'time_diff', 'length(m)', 'height']]\ny = data_condition_not_null['condition']\nto_predict = data_condition_null[['X1', 'X2', 'color_type', 'time_diff', 'length(m)', 'height']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_xg_fill = XGBClassifier()\nclf_xg_fill.fit(x,y)\nabc = clf_xg_fill.predict(to_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(abc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the missing sample are predicted as 2.0 but when i filled them with 2.0 accuracy goes down. So they can be filled with a new category (3.0)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Modelling ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Splitting Data into train and test and fiiling missing values\n\ntrain = data_[data_.pet_category.isnull()==False]\ntrain = train.fillna(3)\n\ntest_ = data_[data_.pet_category.isnull()==True]\ntest_.drop(['breed_category', 'pet_category'], axis=1,inplace=True)\n\nx = train[['X1', 'X2', 'color_type', 'condition', 'time_diff', 'length(m)', 'height']]\ny1 = train['pet_category']\ny2 = train['breed_category']\nx['condition'] = x['condition'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## APPROACH :\n\nThe idea here is to predict breed_category first and join it with train_data and train one more model and predict pet_category.<br>\n<br> **Model used:** Voting Classifier with CatBoostClassifer, RandomForestClassifer and XGBoost Classifier.<br>\nWe used RandomizedSearchCV for searching best parameters.<br>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### RandomizedSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## grid search for XGBClassifier\n\nparams = {'min_child_weight':[1,5,10],\n         'gamma':[0.5,1, 2, 5],\n         'max_depth':[3,5],\n         'subsample':[0.6, 1.0],\n         'learning_rate':[0.001,0.01,0.05,0.1],\n         'n_estimators':[100,300,500,700,900,1000]}\nxgb = XGBClassifier()\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_jobs=-1, cv=3, verbose=5)\nr_s = random_search.fit(x,y2)\nr_s.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## grid search for RandomForestClassifier\n\nparams = {'bootstrap':[True, False], \n         'max_depth':[10,30,50,70,90,100,None],\n         'max_features':['auto', 'sqrt'],\n         'min_samples_leaf':[1,2,4],\n         'min_samples_split':[2,5,10],\n         'n_estimators':[200,600,1000,1400,1800]}\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(rf, param_distributions=params, n_jobs=-1, verbose=3, cv=3)\nr_f = rf_random.fit(x,y2)\n\nr_f.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## grid search for CatBoostClassifier\n\ncat_features = ['X2', 'color_type', 'condition']\ngrid = {\n    'learning_rate': [0.05, 0.07, 0.09, 0.3],\n    'depth': [5, 6, 7],\n    'l2_leaf_reg': [1, 3, 5, 7, 9],\n    'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide']\n}\ntrain_pool = Pool(x, label=y2, cat_features=cat_features)\nmodel = CatBoostClassifier(\n        early_stopping_rounds=100,\n        has_time=True,\n        iterations=5000\n    )\n\nmodel.randomized_search(grid, X=train_pool)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Voting Classifer for predicting breed_category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['condition', 'color_type', 'X1']\nparams = {'depth': 7,\n          'l2_leaf_reg': 3,\n          'learning_rate': 0.07,\n          'grow_policy': 'SymmetricTree',\n         'cat_features': cat_features,\n         'verbose': 200,\n         'eval_metric': 'Accuracy'}\nxtrain, xtest, ytrain, ytest = train_test_split(x, y2, random_state=12)\n\nclf_rf = RandomForestClassifier(min_samples_leaf=2, n_estimators=200)\nclf_cat = CatBoostClassifier(**params)\nclf_xg =XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=5, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=3,\n              min_child_weight=5, missing=np.nan, monotone_constraints='()',\n              n_estimators=300, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, subsample=0.6,\n              tree_method='exact', validate_parameters=1, verbosity=None)\n\n#clf_lgb = lgb.LGBMClassifier()\n#clf_ad = AdaBoostClassifier()\n\nclf2 = VotingClassifier(estimators=[('rf', clf_rf), ('xgb', clf_xg),('cat', clf_cat)], voting='soft')\n\nclf2.fit(x,y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Adding bread_category to train_data\n\nx['breed_category'] = clf2.predict(x)\nx['breed_category'] = x['breed_category'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## grid search for RandomforestClassifier\n\nparams = {'bootstrap':[True, False], \n         'max_depth':[10,30,50,70,90,100,None],\n         'max_features':['auto', 'sqrt'],\n         'min_samples_leaf':[1,2,4],\n         'min_samples_split':[2,5,10],\n         'n_estimators':[200,600,1000,1400,1800]}\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(rf, param_distributions=params, n_jobs=-1, verbose=3, cv=3)\nr_f = rf_random.fit(x,y1)\nr_f.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## grid search for XGBClassifier\n\nparams = {'min_child_weight':[1,5,10],\n         'gamma':[0.5,1, 2, 5],\n         'max_depth':[3,5],\n         'subsample':[0.6, 1.0],\n         'learning_rate':[0.001,0.01,0.05,0.1],\n         'n_estimators':[100,300,500,700,900,1000]}\nxgb = XGBClassifier()\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_jobs=-1, cv=3, verbose=5)\nr_s = random_search.fit(x,y1)\nr_s.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## grid search for CatBoostClassifier\n\ncat_features = ['X2', 'color_type', 'condition', 'breed_category']\ngrid = {\n    'learning_rate': [0.05, 0.07, 0.09, 0.3],\n    'depth': [5, 6, 7],\n    'l2_leaf_reg': [1, 3, 5, 7, 9],\n    'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide']\n}\ntrain_pool = Pool(x, label=y1, cat_features=cat_features)\nmodel = CatBoostClassifier(\n        early_stopping_rounds=100,\n        has_time=True,\n        iterations=5000\n    )\n\nmodel.randomized_search(grid, X=train_pool)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Voting Classifier 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['condition', 'color_type', 'breed_category', \"X1\"]\nparams = {'depth': 6,\n         'l2_leaf_reg': 9,\n         'learning_rate': 0.07,\n         'grow_policy': 'Depthwise',\n         'cat_features': cat_features,\n         'verbose':200,\n         'eval_metric':'Accuracy'}\n\nxtrain, xtest, ytrain, ytest = train_test_split(x, y1, random_state=12)\n\nclf_rf = RandomForestClassifier(max_depth=90, min_samples_split=10, n_estimators=1800)\n\nclf_cat = CatBoostClassifier(**params)\n\nclf_xg = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=1, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=5,\n              min_child_weight=10, missing=np.nan, monotone_constraints='()',\n              n_estimators=300, n_jobs=0, num_parallel_tree=1,\n              objective='multi:softprob', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=None, subsample=1.0,\n              tree_method='exact', validate_parameters=1, verbosity=None)\n\n#clf_ad = AdaBoostClassifier()\n\n#clf_lgb = lgb.LGBMClassifier()\n\nclf1 = VotingClassifier(estimators=[('rf', clf_rf), ('xgb', clf_xg), ('cat', clf_cat)], voting='soft')\n\nclf1.fit(x,y1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ = test_.drop(['listing_date', 'issue_date'], axis=1)\ntest_ = test_.fillna(4)\n\ntest_[['X1', 'X2', 'color_type', 'condition', 'time_diff','length(m)',\n       'height']] = test_[['X1', 'X2', 'color_type', 'condition', 'length(m)', 'time_diff',\n       'height']]\ntest_.columns = ['X1', 'X2', 'color_type', 'condition', 'time_diff','length(m)',\n       'height']\ntest_['condition'] = test_['condition'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_['color_type'] = test_['color_type'].astype('int')\ntest_['X1'] = test_['X1'].astype('int')\ny2 = clf2.predict(test_)\ny2 = np.ravel(y2)\n\ntest_['breed_category'] = y2\ntest_['breed_category'] = test_['breed_category'].astype('int')\ny1 = clf1.predict(test_)\ny1 = np.ravel(y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = pd.DataFrame({'pet_id':test.pet_id, \n                         'breed_category':y2,\n                         'pet_category':y1})\ndataframe.breed_category = dataframe.breed_category.astype('int')\ndataframe.pet_category = dataframe.pet_category.astype('int')\n\n#dataframe.to_csv('submission/votingclassifier21.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mistakes and Improvement ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Lack of Data Visualization**: Using Data Visualization some hidden relationship among condtion, pet_category and breed_category can be seen. <br>\n**Lenght**: Lenght can not be zero, raplace it with median. <br>\n**CatBoost**: X2 and X1 column both should be used in Categorical Columns.<br>\n**time_diff**: Months and hours instead of second could be used. \n**new columns**: new columns can be created using X1, X2, length, height.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Please do comment for any suggestions, queries, errors. ThankYou !!!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}