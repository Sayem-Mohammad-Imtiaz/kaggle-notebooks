{"cells":[{"metadata":{"_uuid":"b42809c21a18d7b39977452e88b54fd00c58f9e7"},"cell_type":"markdown","source":"Check out corresponding Medium article:\n\n[Style Transfer - Styling Images with Convolutional Neural Networks](https://towardsdatascience.com/style-transfer-styling-images-with-convolutional-neural-networks-7d215b58f461)"},{"metadata":{"trusted":true,"_uuid":"9bab7d1fb54866d80f6fc3127ccf428772c5ab7d"},"cell_type":"code","source":"# Imports\nimport numpy as np\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nfrom keras import backend\nfrom keras.models import Model\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg16 import VGG16\n\nfrom scipy.optimize import fmin_l_bfgs_b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48f3a236922c8a1d85fdc6efd68669eaee8ff919"},"cell_type":"code","source":"# Hyperparams\nITERATIONS = 50\nCHANNELS = 3\nIMAGE_SIZE = 500\nIMAGE_WIDTH = IMAGE_SIZE\nIMAGE_HEIGHT = IMAGE_SIZE\nIMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\nCONTENT_WEIGHT = 0.02\nSTYLE_WEIGHT = 4.5\nTOTAL_VARIATION_WEIGHT = 0.995\nTOTAL_VARIATION_LOSS_FACTOR = 1.25","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f86b73d5096c14604fb0db7b4bf5f906248a5b6d"},"cell_type":"code","source":"# Paths\ninput_image_path = \"cai.jpg\"\nstyle_image_path = \"wu3.png\"\noutput_image_path = \"output.png\"\ncombined_image_path = \"combined.png\"\n\n# San Francisco\n#san_francisco_image_path = \"http://science.china.com.cn/images/attachement/png/site555/20151126/e89a8ffb139317c116544b.png\"\n\n# Warsaw by Tytus Brzozowski, http://t-b.pl\n#tytus_image_path = \"http://src.leju.com/imp/imp/deal/df/fe/5/bd92ef65cb531d8f2f2c26acae1_p24_mk24_s600X0.png\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1b8dfb7d3af18a821ff92199c7c77279f91e095"},"cell_type":"code","source":"#Input visualization \ninput_image = Image.open(\"../input/input.jpg\")\ninput_image = input_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\ninput_image.save(input_image_path)\ninput_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c67eef921eb800f15775b8570badbe5ac5b5b81b"},"cell_type":"code","source":"# Style visualization \nstyle_image = Image.open(\"../input/style.jpg\")\nstyle_image = style_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\nstyle_image.save(style_image_path)\nstyle_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01072f7aa15c4149fd5b342ae60e83f139b5487a"},"cell_type":"code","source":"# Data normalization and reshaping from RGB to BGR\ninput_image_array = np.asarray(input_image, dtype=\"float32\")\ninput_image_array = np.expand_dims(input_image_array, axis=0)\ninput_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\ninput_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\ninput_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\ninput_image_array = input_image_array[:, :, :, ::-1]\n\nstyle_image_array = np.asarray(style_image, dtype=\"float32\")\nstyle_image_array = np.expand_dims(style_image_array, axis=0)\nstyle_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\nstyle_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\nstyle_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\nstyle_image_array = style_image_array[:, :, :, ::-1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dce8666aa5d2dc12c5d3f5b7cd68430ba843281"},"cell_type":"code","source":"# Model\ninput_image = backend.variable(input_image_array)\nstyle_image = backend.variable(style_image_array)\ncombination_image = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_SIZE, 3))\n\ninput_tensor = backend.concatenate([input_image,style_image,combination_image], axis=0)\nmodel = VGG19(input_tensor=input_tensor, include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d21c94071256a83487f1b46c6d30b49d2dc3c106"},"cell_type":"code","source":"def content_loss(content, combination):\n    return backend.sum(backend.square(combination - content))\n\nlayers = dict([(layer.name, layer.output) for layer in model.layers])\n\ncontent_layer = 'block2_conv2'\nlayer_features = layers[content_layer]\ncontent_image_features = layer_features[0, :, :, :]\ncombination_features = layer_features[2, :, :, :]\n\nloss = backend.variable(0.)\nloss += CONTENT_WEIGHT * content_loss(content_image_features,\n                                      combination_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbdd51f95c99b24ef2f288d2cad8039803d80aca"},"cell_type":"code","source":"def gram_matrix(x):\n    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n    gram = backend.dot(features, backend.transpose(features))\n    return gram","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b50fc77d82eafcf9526532f21fe51e8238b8b6bc"},"cell_type":"code","source":"def compute_style_loss(style, combination):\n    style = gram_matrix(style)\n    combination = gram_matrix(combination)\n    size = IMAGE_HEIGHT * IMAGE_WIDTH\n    return backend.sum(backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n\nstyle_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\nfor layer_name in style_layers:\n    layer_features = layers[layer_name]\n    style_features = layer_features[1, :, :, :]\n    combination_features = layer_features[2, :, :, :]\n    style_loss = compute_style_loss(style_features, combination_features)\n    loss += (STYLE_WEIGHT / len(style_layers)) * style_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ddfe1d5a68fba2d70f85073dc467e3b99a2744f"},"cell_type":"code","source":"def total_variation_loss(x):\n    a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n    b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n    return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n\nloss += TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b38c32eeeb4aa935b9fb3f60909630b8922e7d87"},"cell_type":"code","source":"outputs = [loss]\noutputs += backend.gradients(loss, combination_image)\n\ndef evaluate_loss_and_gradients(x):\n    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n    outs = backend.function([combination_image], outputs)([x])\n    loss = outs[0]\n    gradients = outs[1].flatten().astype(\"float64\")\n    return loss, gradients\n\nclass Evaluator:\n\n    def loss(self, x):\n        loss, gradients = evaluate_loss_and_gradients(x)\n        self._gradients = gradients\n        return loss\n\n    def gradients(self, x):\n        return self._gradients\n\nevaluator = Evaluator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec471551faa64da16b96f110561db44e8d4ec249"},"cell_type":"code","source":"x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n\nfor i in range(ITERATIONS):\n    x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n    print(\"Iteration %d completed with loss %d\" % (i, loss))\n    \nx = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\nx = x[:, :, ::-1]\nx[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\nx[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\nx[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\nx = np.clip(x, 0, 255).astype(\"uint8\")\noutput_image = Image.fromarray(x)\noutput_image.save(output_image_path)\noutput_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dd55a5b31f84ca0a37e0314bb151d7fe7422be8"},"cell_type":"code","source":"# Visualizing combined results\ncombined = Image.new(\"RGB\", (IMAGE_WIDTH*3, IMAGE_HEIGHT))\nx_offset = 0\nfor image in map(Image.open, [input_image_path, style_image_path, output_image_path]):\n    combined.paste(image, (x_offset, 0))\n    x_offset += IMAGE_WIDTH\ncombined.save(combined_image_path)\ncombined","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}