{"cells":[{"metadata":{"papermill":{"duration":0.011937,"end_time":"2021-01-25T05:42:46.516126","exception":false,"start_time":"2021-01-25T05:42:46.504189","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Simple Time series LSTM \n\nLSTM (Long term Short Term memory)\n* **RNN (Recurrent Neural Network)** has problem about long term memory, **LSTM** has improvement about that\n* Our **Time series LSTM** is focusing on predicting passanger's count on next month, when **LSTM** gets passanger's count during before 12 months\n\n<hr>\n\nHow to use this notebook :\n\nThere is only minimum explanation\n\nThis notebook could be helpful for who want to see how code works right away\n\nPlease upvote if it was helpful !\n\n<hr>\n\n## Content\n1. [Libraries import](#one)\n2. [Prepare Data](#two)\n3. [Modeling](#three)\n4. [Training & Evaluation](#four)\n\n<hr>"},{"metadata":{"papermill":{"duration":0.008571,"end_time":"2021-01-25T05:42:46.534368","exception":false,"start_time":"2021-01-25T05:42:46.525797","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"one\"></a>\n# 1. Libraries import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-01-25T05:42:46.558571Z","iopub.status.busy":"2021-01-25T05:42:46.557929Z","iopub.status.idle":"2021-01-25T05:42:53.27459Z","shell.execute_reply":"2021-01-25T05:42:53.273811Z"},"papermill":{"duration":6.731171,"end_time":"2021-01-25T05:42:53.274726","exception":false,"start_time":"2021-01-25T05:42:46.543555","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom keras import models, layers\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is for visualization\n# we can skip this part (not important)\n\nclass skeras() :\n    def save_history_history(fname, history_history, fold=''):\n        np.save(os.path.join(fold, fname), history_history)\n\n\n    def load_history_history(fname, fold=''):\n        history_history = np.load(os.path.join(fold, fname)).item(0)\n        return history_history\n\n\n    def plot_acc(history, title=None):\n        # summarize history for accuracy\n        if not isinstance(history, dict):\n            history = history.history\n\n        plt.plot(history['acc'])\n        plt.plot(history['val_acc'])\n        if title is not None:\n            plt.title(title)\n        plt.ylabel('Accracy')\n        plt.xlabel('Epoch')\n        plt.legend(['Training data', 'Validation data'], loc=0)\n        # plt.show()\n\n\n    def plot_loss(history, title=None):\n        # summarize history for loss\n        if not isinstance(history, dict):\n            history = history.history\n\n        plt.plot(history['loss'])\n        plt.plot(history['val_loss'])\n        if title is not None:\n            plt.title(title)\n        plt.ylabel('Loss')\n        plt.xlabel('Epoch')\n        plt.legend(['Training data', 'Validation data'], loc=0)\n        # plt.show()\n\n\n    def plot_history(history):\n        plt.figure(figsize=(15, 5))\n        plt.subplot(1, 2, 1)\n        plot_acc(history)\n        plt.subplot(1, 2, 2)\n        plot_loss(history)\n\n\n    def plot_loss_acc(history):\n        plot_loss(history, '(a) Loss trajectory')\n        plt.show()            \n        plot_acc(history, '(b) Accracy trajectory')\n        plt.show()\n\n\n    def plot_acc_loss(history):\n        plot_acc(history, '(a) Accracy trajectory')\n        plt.show()\n        plot_loss(history, '(b) Loss trajectory')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.013497,"end_time":"2021-01-25T05:42:53.302435","exception":false,"start_time":"2021-01-25T05:42:53.288938","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"two\"></a>\n# 2. Prepare Data"},{"metadata":{},"cell_type":"markdown","source":"* We need to put **'international-airline-passengers.csv'** in our input data\n* 144 rows\n* Data has 2 columns (Month and passangers)\n* **Month** ex) 1949-01, **passangers** ex) 112"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-25T05:42:53.332746Z","iopub.status.busy":"2021-01-25T05:42:53.331954Z","iopub.status.idle":"2021-01-25T05:43:01.558978Z","shell.execute_reply":"2021-01-25T05:43:01.558407Z"},"papermill":{"duration":8.243537,"end_time":"2021-01-25T05:43:01.559085","exception":false,"start_time":"2021-01-25T05:42:53.315548","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"fname='../input/international-airline-passengers/international-airline-passengers.csv'\npd.read_csv(fname, engine='python', skipfooter=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bring our data as pandas dataframe\ndef load_data(fname='../input/international-airline-passengers/international-airline-passengers.csv'):\n        \n    # usecols=[1] means only passangers count\n    dataset = pd.read_csv(fname, usecols=[1], engine='python', skipfooter=3)        \n        \n    # we change data type from dataframe to 1-dimension numpy \n    data = dataset.values.reshape(-1)\n        \n    # check\n    plt.plot(data)\n    plt.xlabel('Time'); plt.ylabel('#Passengers')\n    plt.title('Original Data')\n    plt.show()\n\n    # data normalize (because LSTM learn 0~1 values)\n    data_dn = (data - np.mean(data)) / np.std(data) / 5\n    plt.plot(data_dn)\n    plt.xlabel('Time'); plt.ylabel('Normalized #Passengers')\n    plt.title('Normalized data by $E[]$ and $5\\sigma$')\n    plt.show()\n\n    return data_dn    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here is important**\n\nwe will make time series dataset\n\n* x = last 12 months passanger count     ex) 1(Jan) ~ 12(Dec)\n* y = right after x month                ex ) 13(1)(Jan)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# this function makes dataset for Using Rate of change about D months predict next month passanger count\ndef get_Xy(data, D=12):\n    # make X and y\n    X_l = []\n    y_l = []\n    N = len(data) # 144\n    assert N > D, \"N should be larger than D, where N is len(data)\"\n    for ii in range(N-D-1): # 0 ~ 131\n        X_l.append(data[ii:ii+D])\n        y_l.append(data[ii+D])\n    X = np.array(X_l)\n    X = X.reshape(X.shape[0], X.shape[1], 1)\n    y = np.array(y_l)\n    print(X.shape, y.shape)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(fname, usecols=[1], engine='python', skipfooter=3).values.reshape(-1)\n\n# we can check x = (131,12,1), y = (131)\nprint(get_Xy(data))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-25T05:43:01.638854Z","iopub.status.busy":"2021-01-25T05:43:01.637913Z","iopub.status.idle":"2021-01-25T05:43:01.642007Z","shell.execute_reply":"2021-01-25T05:43:01.641202Z"},"papermill":{"duration":0.032365,"end_time":"2021-01-25T05:43:01.642161","exception":false,"start_time":"2021-01-25T05:43:01.609796","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class Dataset:\n    \n    # initialize (data name & D (time-series length))\n    def __init__(self, fname='../input/international-airline-passengers/international-airline-passengers.csv', D=12):\n        data_dn = load_data(fname=fname)\n        X, y = get_Xy(data_dn, D=D)\n        X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)  \n        \n        # after initializing , we can see output when we use this class\n        self.X, self.y = X, y\n        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test   \n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.011165,"end_time":"2021-01-25T05:43:01.668278","exception":false,"start_time":"2021-01-25T05:43:01.657113","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"three\"></a>\n# 3. Modeliing"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-25T05:43:01.701916Z","iopub.status.busy":"2021-01-25T05:43:01.701078Z","iopub.status.idle":"2021-01-25T05:43:01.704136Z","shell.execute_reply":"2021-01-25T05:43:01.703331Z"},"papermill":{"duration":0.024677,"end_time":"2021-01-25T05:43:01.70426","exception":false,"start_time":"2021-01-25T05:43:01.679583","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def rnn_model(shape):\n    \n    # input (12,1)\n    m_x = layers.Input(shape=shape) #X.shape[1:]\n    \n    # hidden (10)\n    m_h = layers.LSTM(10)(m_x)\n    \n    # output (1)\n    m_y = layers.Dense(1)(m_h)\n    m = models.Model(m_x, m_y)\n    \n    # show me summary about model\n    m.compile('adam', 'mean_squared_error')\n    m.summary()\n    \n    return m","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.016736,"end_time":"2021-01-25T05:43:01.738565","exception":false,"start_time":"2021-01-25T05:43:01.721829","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a id=\"four\"></a>\n# 4. Training & Evaluation"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-25T05:43:01.776249Z","iopub.status.busy":"2021-01-25T05:43:01.775481Z","iopub.status.idle":"2021-01-25T05:43:01.784158Z","shell.execute_reply":"2021-01-25T05:43:01.784937Z"},"papermill":{"duration":0.029448,"end_time":"2021-01-25T05:43:01.785067","exception":false,"start_time":"2021-01-25T05:43:01.755619","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class Machine():\n    def __init__(self):\n        # bring data\n        self.data = Dataset()\n        \n        # input data size (12,1)\n        shape = self.data.X.shape[1:]\n        \n        # make LSTM model\n        self.model = rnn_model(shape)\n        \n    def run(self, epochs=400):\n        d = self.data\n        \n        # we made internal variables in Class Dataset()\n        X_train, X_test, y_train, y_test = d.X_train, d.X_test, d.y_train, d.y_test\n        X, y = d.X, d.y\n        \n        # training\n        m = self.model \n        h = m.fit(X_train, y_train, epochs=epochs, validation_data=[X_test, y_test], verbose=0)\n\n        # after training show us training curve\n        skeras.plot_loss(h)\n        plt.title('History of training')\n        plt.show()\n\n        # evaluate() show us training efficiency after training\n        yp = m.predict(X_test)\n        print('Loss:', m.evaluate(X_test, y_test))\n        \n        # make two graph for comparing\n        plt.plot(yp, label='Origial')\n        plt.plot(y_test, label='Prediction')\n        plt.legend(loc=0)\n        plt.title('Validation Results')\n        plt.show()\n        \n        #   upside         >>>>>>>>>>>>>      we cant find out Time series relationship\n        #-----------------------------------------------------------------------------------------------\n        #   downside       >>>>>>>>>>>>>      we use seaborn and pandas's dataframe to find Time series relationship\n        \n        yp = m.predict(X_test).reshape(-1)\n        print('Loss:', m.evaluate(X_test, y_test))  \n        print(yp.shape, y_test.shape)\n\n        df = pd.DataFrame()\n        df['Sample'] = list(range(len(y_test))) * 2\n        # Sample column's first = purpose order, second = predict order\n        df['Normalized #Passengers'] = np.concatenate([y_test, yp], axis=0)\n        df['Type'] = ['Original'] * len(y_test) + ['Prediction'] * len(yp)\n\n        plt.figure(figsize=(7, 5))\n        sns.barplot(x=\"Sample\", y=\"Normalized #Passengers\", hue=\"Type\", data=df)\n        plt.ylabel('Normalized #Passengers')\n        plt.show()\n        \n        yp = m.predict(X)\n        plt.plot(yp, label='Origial')\n        plt.plot(y, label='Prediction')\n        plt.legend(loc=0)\n        plt.title('All Results')\n        plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-25T05:43:01.82367Z","iopub.status.busy":"2021-01-25T05:43:01.822878Z","iopub.status.idle":"2021-01-25T05:51:06.636611Z","shell.execute_reply":"2021-01-25T05:51:06.635742Z"},"papermill":{"duration":484.834567,"end_time":"2021-01-25T05:51:06.636755","exception":false,"start_time":"2021-01-25T05:43:01.802188","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def main():        \n    machine = Machine() \n    machine.run(epochs=400)\n\nif __name__ == '__main__' :\n    main()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":1.392188,"end_time":"2021-01-25T05:51:09.30794","exception":false,"start_time":"2021-01-25T05:51:07.915752","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Reference\n* Coding chef 3 minute deep learning  - [ex5_1_lstm_imdb](https://github.com/jskDr/keraspp/blob/master/ex5_2_lstm_airplane.py)\n* [Simple LSTM](https://www.kaggle.com/gigunlee/beginner-simple-lstm)"},{"metadata":{"papermill":{"duration":1.383211,"end_time":"2021-01-25T05:51:12.087191","exception":false,"start_time":"2021-01-25T05:51:10.70398","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}