{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exploring accident data\nRoad safety continues to be a major developmental issue killing more than 1.35 mn globally as reported in the Global Status\nreport on Road Safety 2018, with 11% of casualities occuring only in India.\nI come form India and have first hand experience of frequent road accidents and related fatalities. In 2019, there were 151,113 accidents related deaths in 449,000 road accidents in India.\n\n##### That means, every one min aprox(70 sec) one road accident happens in India killing one person every three mins(200 sec).\n\n### This is huge.\n\nAs per WHO report, much of this can be prevented by timely treatment of accident victims. In that endeveaour, I am going to analyze the hospital coverage of accidents and see if new hospitals are required and at what locations, and if this can prevent some casualities.\nWhile I could not get geo tagged accidents data for India(perhaps they are not geo tagged yet), so I would be exploring this in for developed countries like United Kingdom, United States of America(later exploration) accidents/hospitals data.\n\nSource: https://morth.nic.in/sites/default/files/RA_Uploading.pdf"},{"metadata":{},"cell_type":"markdown","source":" This notebook is inspired from one of the exercises of kaggle geospatial course by Alexis. Good course, worth giving time\n \n https://www.kaggle.com/alexisbcook/proximity-analysis"},{"metadata":{},"cell_type":"markdown","source":"# Cluster Map visualization technique\n \nCluster Map, helps present dense pockets of data using single point. Each cluster is either relatively sized to or labelled with the number of points that have been grouped together.\n\nClusters are ideal in interactive maps where the user can drill down to see individual data points contained in a cluster. Cluster maps help reduce clutter when there are many overlapping data points in a small geography.\n\nIf we have very few data points to visualize, than ClusterMap should not be used and instead BubbleMap can be used.\n\nI want to visualize all the accidents heppening in UK/city on the country map and as accident counts will be in 10k+, bubble map would not be a feasible technique. As then bubbles would be cluttered too closely and would not provide any insight to the audiance.\n\nOther visualization technique, which can be used to represent this datasets are Choropleth, Hexagonal binning and Dot map.\n\nHowever, as there are very large no of accident data points, Dot Map would not be appropriate visualization technique.\n\nChoropleth maps need data binned on any geogrophical area, however, we do not have such representive binned data for this dataset.\n\nAnd so I am going to use cluster map visualization technique for this dataset.\n\n# Considerations for library selections\n\nAs mentioned earlier I wish to explore the accident data, and total number of accidents in a year in UK are approx 0.2 mn. While Altair has the default option of 5000 records. Though this can be still acheived by disabling the default option, this further has challenges in an interactive plot.\n\nI didnt wanted to used Matplotlib and Seaborn as I wanted to explore some thing new for this assignment as learning objective.\nAnother good option can be plotly, and this is really very popular and can be used for diverse use cases as well to cater large dataset.\nFor now I am going to explore folium and understand its uses and limitations and going to explore plotly later."},{"metadata":{},"cell_type":"markdown","source":"# Folium library\n\nFolium is widely used in geospatial data visualisation. It is built on top of Leaflet.js and can cover most of your mapping needs in Python with its great plugins.\n\nFolium builds on the data wrangling strengths of the Python ecosystem and the mapping strengths of the Leaflet.js library. Manipulate your data in Python, then visualize it in a Leaflet map via folium.\n\nGetting started with Folium is easy, and you can simply call Folium.Map to visualise base maps immediately. You can then add layers to visualise your data on the interactive base maps available in Folium.\n\nFolium is open source library built on open source\n\nhttps://python-visualization.github.io/folium/\n\n## Cluster Map\nEarlier I explored BubbleMap but found that having large amount of data points to visualize basically clutters the bubble points on the map and no insights can be extracted from such a visualization.\n\nThen on exploring further, I found, Cluster Map is good in way that it groups the closely related points and provides the counts. Also the cluster markers are shaded in a way to differetiate among smaller clusters to bigger clusters.\n\n\n# Installing Folium\n\n#### To install folium using pip, type the following command:\n\n$ pip install folium=0.0.0\n\n\n#### To install folium using conda, type the following command:\n\n$ conda install -c conda-forge folium=0.0.0"},{"metadata":{},"cell_type":"markdown","source":"## Importing libraries\n\nfollowing librries would be used for data cleaning and visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install geopy==1.22.0\n!pip install xlrd==1.2.0\n!pip install watermark\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport folium\nfrom folium import Marker, Circle, CircleMarker, Choropleth\nfrom folium.plugins import MarkerCluster, HeatMap\nfrom geopandas.tools import geocode\nfrom shapely.geometry import Point\nfrom multiprocessing import Pool\nfrom tqdm.notebook import tqdm, tqdm_notebook\nimport ipywidgets as widgets\nfrom ipywidgets import interact, fixed, interact_manual, interactive_output\nfrom IPython.display import display\nimport geopy\n\ntqdm_notebook.pandas()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Collecting and cleaning the data"},{"metadata":{},"cell_type":"markdown","source":"### Accidents data\nI wanted to analyze the road accidents and hospital coverage of them. While I wanted to do for India, in lack of geo tagged accidents data for India, I decided to go for UK/USA (being developed countries, they have highest level of digitisation and availability of free data).\nI could get the accidents data for United Kingdom from belo site:\n\nhttps://datashare.ed.ac.uk/handle/10283/2509?show=full\n\nThis contains the shapefile from year 2005 to 2010. Geospatial data in vector format are often stored in a shapefile format. \n\n--------------------------------------------------------------------------------------------------------------------------------\n\n#### Shapefiles: One Dataset - Many Files\nA shapefile is created by 3 or more files, all of which must retain the same NAME and be stored in the same file directory, in order for you to be able to work with them.\n\nShapefile Structure\nThere are 3 key files associated with any and all shapefiles:\n\n- .shp: the file that contains the geometry for all features.\n- .shx: the file that indexes the geometry.\n- .dbf: the file that stores feature attributes in a tabular format."},{"metadata":{},"cell_type":"markdown","source":"### Data loading\n\nFurther, as I am interested in hospital coverage of accidents, I would be removing some unwanted columns.\n\nFuther these files are stored year wise, so would be creating a function, which would take some parameters as initial path, fileprefix and year, so that even later year files can be integrated into notebook easily."},{"metadata":{},"cell_type":"markdown","source":"**Another technique, I am using for the first time is tqdm library.**\n\nIn this notebook we are dealing with around a million records and many a times these processing takes time. In the exploration times, its very difficult to know, whether it is being processed or there is some code issue.\n\nHaving the progressbar in these situations helps us in the exploration. It is easy to use,  involves very less overhead and prevents the blind condition in exploration in absence of progressbar for long running processes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_accident(path, accident_file, years):\n    ''' loading the accidents file\n    path - initial path of the file if outside of notebook path\n    accident_file - filename prefix, i.e. excluding year and extension\n    years - for which years data need to be loaded'''\n    columns = ['Accident_I', 'Longitude', 'Latitude','Date','geometry']\n\n    accidents_gdf = gpd.GeoDataFrame()\n    for year in tqdm(years):\n        filename = path + filenameprefix + str(year) + '.shp'\n        accident1 = gpd.read_file(filename) \n        accident1 = accident1[columns]\n        accident1['year'] = year\n        accident1['month'] = pd.to_datetime(accident1['Date'], format='%d/%m/%Y').dt.month_name().str.slice(stop=3)\n        geometry = [Point(xy) for xy in zip(accident1['Longitude'], accident1['Latitude'])]\n        crs = ('epsg:27700')\n        accident1_gdf = gpd.GeoDataFrame(accident1, crs=crs, geometry=geometry) \n        accidents_gdf = pd.concat([accidents_gdf, accident1_gdf], ignore_index=True)  \n    return(accidents_gdf)\n\ndef read_internediate_data(filename):\n    df = pd.read_csv(filename)\n    df_gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n    df_gdf = df_gdf.set_crs('epsg:27700').drop(columns='Unnamed: 0')\n    return(df_gdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I could not get the whole raw data loaded at Kaggle, have made, pre-processed data available \n# and can be accessed and worked here. So either you can work with raw data locally or pre-processed \n# data, at Kaggle.\npath = 'input/'\nyears = [2005, 2006, 2007, 2009, 2010]\nfilenameprefix = 'GB_Accidents'\n\n# accidents_gdf = data_load.load_accident(path, filenameprefix, years)\n# print('Number of records in the file: %d' %accidents_gdf.shape[0])\n# print('Number of columns in the file: %d' %accidents_gdf.shape[1])\n# Save the intermediate work\n# accidents_gdf.to_csv('output/intermediate_work/accidents_gdf')\n# accidents_gdf.head(5)\n\naccidents_gdf = read_internediate_data('../input/gb-accidents/accidents_gdf.csv')\naccidents_gdf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For people, wanting to work directly on the data, without downloading and processing the raw data, I am providing the processed data "},{"metadata":{},"cell_type":"markdown","source":"## Hospitals data\n\nI needed geo tagged hospitals data for my analysis purpose. However, had hard time getting the geo tagged hospitals data for UK. And so decided to go-with below dataset which I found to be pretty comprehensive and geocode the data myself using geopandas.\n\nhttps://data.gov.uk/dataset/f4420d1c-043a-42bc-afbc-4c0f7d3f1620/hospitals"},{"metadata":{},"cell_type":"markdown","source":"### Functions for loading and Cleaning Hospital data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This hospital data is in excel sheet and that too in old excel(97-2003) format. Luckily pandas to rescue. \n# Using the 'xlrd' engine same red_excel method can be used to read excel file.\ndef old_excel_load(path, filename, sheet_name):\n    ''' Loads the hospitals data for United Kingdom\n    path - initial path of the file if outside of notebook folder\n    filename - filename of the hospital data\n    sheet_no - sheet no of the hospital data file \n                data file contains multiple sheets and data we are interested is in second sheet'''\n    filename = path + filename\n    df = pd.read_excel(filename, sheet_name=sheet_name, engine='xlrd')\n    return(df)\n\n# Now time to write some function to do cleaning/scrubbing\n# Remove unwanted columns, or hospitals which are closed long back and where Town name is not in the record\n# As we need Town name to geo tag the all hospitals\ndef hospital_clean(df):\n    ''' cleans and takes subset of the hospital data required for analysis\n    df - initial loaded dataframe of hospital data'''\n    data = df.copy()\n    hosp_cols = ['HOSPITAL', 'Present Name of Hospital','Closure Date', 'Town', 'County: Post 1996']\n    data = data[hosp_cols]\n    data.columns = ['HOSPITAL', 'Hospital_Name','Closure_Date', 'Town', 'Current_County']\n    data = data[(data['Closure_Date'].isna() & (~data['Town'].isna()))].drop(columns='Closure_Date')\n    return(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Funcitons for data preperation - geocoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now any city in UK, we want to explore, we need lat,long information for the city\n# This function, will do the job\ndef city_geocoder(city):\n    ''' geocodes the city, which we want to explore\n    city - name of the city you wish to explore'''\n    try:\n        result = geocode(city, provider='nominatim').geometry.iloc[0] \n        return(result)\n    except:\n        return None\n\n# This dataset does not contain geospatial information of the hospitals, however, this can be generated using\n# \"geocode\" library of geopandass    \ndef my_geocoder(city):\n    ''' gecodes a provided town/city name create three columns values Latitude,Longitude and geometry\n        city - town/city name of the hospital\n        '''\n    try:\n        result = geocode(city, provider='nominatim')\n        point = result.geometry.iloc[0] \n        return(pd.Series({'Latitude': point.y, 'Longitude': point.x, 'geometry': point}))\n    except:\n        return None\n    \n# Now that we have a geocode function to generate geocode, lets geo tag all the hospitals in our data    \ndef hospital_geocode(df):\n    ''' geocodes all the town names in the hospital dataframe and and drops any rows for which geocoding was unsuccessfull\n    df - clened hospital dataframe containing town name column'''\n    df.loc[:, ['Latitude', 'Longitude', 'geometry']] = df.progress_apply(lambda x: my_geocoder(x['Town']), axis=1)\n    df = df[~df['geometry'].isna()].reset_index(drop=True)\n    crs = ('epsg:27700')\n    df = gpd.GeoDataFrame(df, crs=crs, geometry=df.geometry)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data loading and cleaning / preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"# I could not get the whole raw data loaded at Kaggle, have made, pre-processed data available \n# and can be accessed and worked here. So either you can work with raw data locally or pre-processed \n# data, at Kaggle.\npath = '../input/gb-hospitals/'\nhosp_filename = 'hospital-records.xls'\n\n# hospitals = data_load.old_excel_load(path, hosp_filename, sheet_name=1)\n# hospitals_clean = data_clean.hospital_clean(hospitals)\n# hospitals_gdf = data_clean.hospital_geocode(hospitals_clean)\n\n# print('Number of records in the file: %d' %hospitals_gdf.shape[0])\n# print('Number of columns in the file: %d' %hospitals_gdf.shape[1])\n# hospitals_gdf.head(3)\n# Saving intermediate work in csv file\n# hospitals_gdf.to_csv('hospitals_gdf')\n\nhospitals_gdf = read_internediate_data('../input/gbhospitals/hospitals_gdf.csv')\nhospitals_gdf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of records successfully geocoded %d' %hospitals_gdf.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### Data pre-processing\n \n Measuring distance in three dimentional space is not same as measuring in two dimentional space.\n Also because of sphere shape of the earth, even three dimentional distances doesnt hold good. So there are different \n coordinate reference systems created to suite different tasks like equal area/distance and also for different geographical continents. "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# As we are working on UK data and found that EPSG:3035 is created for Europian regions\ndef change_crs_for_region(hospitals, epsg):\n    '''changes coordinate reference system of both the input datasets\n    hospitals - hospital dataset dataframe\n    epsg - coordinate reference system, to which we want to change'''\n    df = hospitals.set_crs(epsg=epsg)\n    return(df)\n\nhospitals_gdf = change_crs_for_region(hospitals_gdf, 27700)\n# Saving  the intermediate work to csv files \n# accidents_gdf.to_csv('output/intermediate_work/accidents_gdf')\n# hospitals_gdf.to_csv('output/intermediate_work/hospitals_gdf')\naccidents_gdf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize the accident data(MarkerCluster)"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Lets see how BubbleMap fares for this dataset. I will plot only 5000 records, throgh datase\ndef visualize_data(city, accident):\n    '''visulize data through bubble map'''\n    point = city_geocoder(city)\n    if not point:\n        print('Please check the city/county name, Thank You.')\n        return\n\n    m_1 = folium.Map(location=[point.y, point.x], tiles='OpenStreetMap', zoom_start=10)\n    for idx, row in accident[:5000].iterrows(): \n        Marker([row['Latitude'], row['Longitude']]).add_to(m_1)\n    return(m_1)\n\nvisualize_data('London', accidents_gdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As can be seen above, BubbleMap is certainly not suited for this dataset. Even with 5000 records, its get clutterd up and  \n# doesnt offer any insight about the data\n# Now see whether ClusterMap is good for this use case\ndef visualize_data_mc(city, year, accident):\n    '''visualize accidents through cluster map\n    city - city name for which, you want to plot the data\n    year - year(2005-2010), for which you want to plot accidents\n    accident - dataframe name for accidents data'''\n    point = city_geocoder(city)\n    if not point:\n        print('Please check the city/county name, Thank You.')\n        return\n\n    accident = accident.copy()\n    accident = accident[accident.year == year]\n    m_1 = folium.Map(location=[point.y, point.x], tiles='OpenStreetMap', zoom_start=10)\n\n    mc = MarkerCluster()\n    for idx, row in accident.iterrows():\n        mc.add_child(Marker([row['Latitude'], row['Longitude']]))\n\n    m_1.add_child(mc)\n    return(m_1)\n\nvisualize_data_mc('London', 2010, accidents_gdf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is good, now we can clerly see, there are around 8990 accidents in London. And we can also see the number of accidents in nearby cities. Best part of this is that, this is interactive map. So we can zoom more, if we want and drill down further as required.\n\nAlso notice that how color shade of cluster is corresponding to count of accidents at that cluster point."},{"metadata":{},"cell_type":"markdown","source":"#### Lets add some widgets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now that we see that ClusterMap is good for this use case, let add some widgets and give contorl to users.\n# Here I am adding widgets for city name and year for which data can be explored.\ntext_city = widgets.Text(options='London')\n\ninteract_manual(visualize_data_mc, city=text_city, year=(2005,2010), accident=fixed(accidents_gdf));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that I have added, manual control in interactive widgets. This is very much required.\nBecause dataset is huge, in continuous update mode, it simply keep on trying to plot, while user is trying to adjust inputs.\n\nAdding, manual control, gives control to run in user's hands for better experience."},{"metadata":{},"cell_type":"markdown","source":"### Visualize the Hospitals\n\nDefault behaviour of the MarkerCluster is to show Green shade for smaller count clusters while to show red shade for bigger number cluster. \nHowever, this would not make sense in case of hospitals. \n\nTown/city which is covered by more hospitals is better prepared to handle accidents and so bigger hospital count should be shown in Green shade and lower hospital(worse prepared to handle accidents), should be shown in red shade.\n\n**For this reason, I have customized the code for MarkerCluster**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_data_mcgroup(city, hospitals):\n    '''visualize hospital data in MarkerCluster\n    city - name of the city\n    hospitals - dataframe for hospital data'''\n    point = city_geocoder(city)\n    if not point:\n        print('Please check the city/county name, Thank You.')\n        return\n    \n    m_1 = folium.Map(location=[point.y, point.x], zoom_start=8)\n    mc = MarkerCluster()\n    #Create a variable to store your javascript function (written as a string), which adjusts the default css functionality\n    #The below are the attributes that I needed for my project, but they can be whatever is needed for you\n    icon_create_function = \"\"\"\n        function(cluster) {\n        var childCount = cluster.getChildCount(); \n        var c = ' marker-cluster-';\n\n        if (childCount < 50) {\n            c += 'large';\n        } else if (childCount < 300) {\n            c += 'medium';\n        } else {\n            c += 'small';\n        }\n        \n        return new L.DivIcon({ html: '<div><span>' + childCount + '</span></div>', className: 'marker-cluster' + c, iconSize: new L.Point(40, 40) });\n        }\n        \"\"\"\n    #Create the marker cluster group, which organizes all the gps points put into it\n    mcg = MarkerCluster(name='Cluster Icons', icon_create_function=icon_create_function)\n    for idx, row in hospitals.iterrows():\n        mcg.add_child(Marker([row['Latitude'], row['Longitude']]))\n\n    m_1.add_child(mcg)\n    return(m_1)\n# I have taken this MarkerClusyter customization code verbatim from stackoverflow\n# Link : https://stackoverflow.com/questions/55657858/is-it-possible-to-change-the-default-colors-used-in-a-folium-marker-cluster-map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lets visalize the hospital data"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_city = widgets.Text(options='London')\ninteract_manual(visualize_data_mcgroup, city=text_city, hospitals=fixed(hospitals_gdf));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I ran it for Leeds, and we can clearly see, Leeds has 25 hospitals."},{"metadata":{},"cell_type":"markdown","source":"### When was the closest hospital more than 10 kms away?\n\nNow say, if 10 kms is a buffer zone, inside which victims can be transported easily and saved.\nThen lets find out the number of cases, when closest hospital was more than 10 kms away."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_buffer(hospital, km_range):\n    '''creates a buffer zone of provided km range\n    hospital - dataframe containing hospital data\n    km_range - range in kms, of which buffer needs to be created '''\n    x_km_buffer = hospital.geometry.buffer(km_range / 100)\n    my_union = x_km_buffer.geometry.unary_union\n    return(my_union)\n\ndef outside_buffer_range(buffer, accidents, year, month):\n    '''finds the accidents which occurred outside buffer zone\n    buffer - buffer zone dataframe created\n    accidents - dataframe of accidents records'''\n    accidents = accidents[(accidents['year'] == year) & (accidents['month'] == month)]\n    outside_range = accidents[~accidents['geometry'].progress_apply(lambda x: buffer.contains(x))]\n    return(outside_range)    \n\nhospital_buffer = create_buffer(hospitals_gdf, 10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"outside_range = outside_buffer_range(hospital_buffer, accidents_gdf, 2010, 'May')\nprint(\"Number of accidents outside of 10 km buffer range for year(2010) for month('May'): %d\" %outside_range.shape[0])\noutside_range.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_record_count = len(accidents_gdf[(accidents_gdf['year'] == 2010) \n                                       & (accidents_gdf['month'] == 'May')])\n\npercentage = round(len(outside_range) * 100 / total_record_count, 2)\nprint('Percentage of accidents, which occurred outside of hospitls coverage is: %.2f' %percentage)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make a recommender\n\nWhen accidents occurs in distant locaitons, it becomes even more vital that injured persons are taken to nearest available hospital.\n\nWith this in mind, we create a recommender that:\n\n- takes the location of the accident in one crs system\n\n- finds the closest hospitals(where distance calculations are done in epsg:27700), and\n\n- returns the name of the closest hospital."},{"metadata":{"trusted":true},"cell_type":"code","source":"# hospitals_gdf = hospitals_gdf.reset_index()\ndef best_hospital(accident_loc):\n    '''returns the best hospital in terms of closest to accident site\n    accident_loc - point(latitude and longitude) of the accident location'''\n    idxmin = hospitals_gdf.geometry.distance(accident_loc).idxmin()\n    hosp_name = hospitals_gdf.iloc[idxmin].Hospital_Name\n#     hosp_dist = hospitals_gdf.geometry.distance(accident_loc).min() * 100\n    return(hosp_name)\n\nbest_hospital(outside_range.geometry.iloc[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Which hospitals are in the highest demand?\n\nConsidering hospitals only in outside_range DataFrame, which hospitals is most recommended?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def top_ten_hospitals(df):\n    top_10_hospitals = df.geometry.progress_apply(best_hospital).value_counts().sort_values(ascending=False).reset_index().iloc[:10, :]\n    top_10_hospitals.columns = ['hospital_name', 'demand_count']\n    return(top_10_hospitals)\n\ntop_hospitals = top_ten_hospitals(outside_range)\ntop_hospitals","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These hospitals are in high demand attending to accident cases in their buffer zone of 10 kms and attending to cases where they are the nearest hospitals outside range.\n\nManagement needs to ensure that these hospitals have the needed infrastructure and people to support the demand to reduce fatalaties.\n\nAlso new locations need to be identified which may reduce the burden on these high demand hospitals."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"%load_ext watermark\n%watermark -v -m -p pandas,numpy,ipywidgets,folium,geopandas,geopy,tqdm,xlrd","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}