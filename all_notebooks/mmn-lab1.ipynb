{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn import preprocessing\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndata = pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")\nprint(\"volume of the data set = {}\".format(data.shape))\nprint(data.head())\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_columns = ['bedrooms', 'bathrooms', 'floors','grade', 'sqft_living', 'sqft_lot', 'sqft_living15', 'sqft_lot15', 'yr_built']\noutput_columns = ['price']\nrelevant_data = data[input_columns+output_columns] #cound add year innovated - year built\nprint(\"Input parametrs: 'bedrooms', 'bathrooms', 'floors','grade', 'sqft_living', 'sqft_lot', 'sqft_living15', 'sqft_lot15', 'yr_built'\") #[FIXTHIS]\nprint(\"Output parametr: \\'price\\'\")\nrelevant_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if True in pd.isnull(relevant_data):\n    print(\"something missing\")\nelse:\n    print(\"nothing is missing\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(relevant_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on amount of bedrooms:\")\nsns.scatterplot(x=relevant_data.bedrooms, y=relevant_data.price)\n#anomaly detected: over 30 bedrooms doesnt seem sane","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# eliminating anomaly\nprint(\"anomaly row:\")\nprint(relevant_data[relevant_data.bedrooms>30])\nrelevant_data = relevant_data.drop([relevant_data[relevant_data.bedrooms>30].index[0]], inplace = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on amount of bathrooms:\")\nsns.scatterplot(relevant_data.bathrooms, relevant_data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on amount of floors:\")\nsns.scatterplot(relevant_data.floors, relevant_data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on grade:\")\nsns.scatterplot(relevant_data.grade, relevant_data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on sqft_living:\")\nsns.scatterplot(relevant_data.sqft_living, relevant_data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on sqft_lot:\")\nsns.scatterplot(relevant_data.sqft_lot, relevant_data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on sqft_living15:\")\nsns.scatterplot(relevant_data.sqft_living15, relevant_data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on sqft_lot15:\")\nsns.scatterplot(relevant_data.sqft_lot15, relevant_data.price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Visualising dependency of price on yr_built:\")\nsns.scatterplot(relevant_data.yr_built, relevant_data.price)\ninput_columns.remove(\"yr_built\")\nrelevant_data = relevant_data.drop(columns = \"yr_built\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Заметим, что от года постройки цена зависит как-то сомнительно: старые дома, построенные в первой половине 20 ст. выставлены на продажу по солидным ценам, сравнимым по порядку с ценами новых домов. Только лишь немногие дома новые(1980+) дома заментно отличаются по цене.\nПо этому уберираем цену из признаков, по которым строим модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"#spliting to test/train \ntrain_data, test_data = train_test_split(relevant_data, test_size = 0.5, random_state = 666)\nprint(\"train data set:\\n{}\".format(train_data))\nprint(\"test data set:\\n{}\".format(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Normalizer\n#Normalize data, [maybe use StandardScaler]\n#transformer = preprocessing.Normalizer().fit(train_data)\n# #MinMaxScaler\n# transformer = preprocessing.MinMaxScaler().fit(train_data)\n# scaled_train_data, scaled_test_data = transformer.transform(train_data), transformer.transform(test_data)\n\nprint(np.arange(scaled_train_data.shape[1]-1))\nprint(scaled_train_data.shape)\nprint(scaled_train_data)\nprint(scaled_train_data[:, np.arange(scaled_train_data.shape[1]-1)])\n\ntrain_data_x = scaled_train_data[:, np.arange(scaled_train_data.shape[1]-1)]\ntrain_data_y = scaled_train_data[:,-1].reshape(-1, 1)\ntest_data_x = scaled_test_data[:, np.arange(scaled_test_data.shape[1]-1)]\ntest_data_y = scaled_test_data[:,-1].reshape(-1, 1)\nprint(scaled_train_data[-1])\nprint(train_data_x.shape)\nprint(train_data_y.shape)\n#train_data_x, train_data_y, test_data_x, test_data_y = transformer.transform(train_data[input_columns]), transformer.transform(train_data.price.values.reshape(-1, 1)), transformer.transform(test_data[input_columns]),transformer.transform(test_data.price.values.reshape(-1, 1))\n#train_data_x, train_data_y, test_data_x, test_data_y = train_data[input_columns], train_data.price, test_data[input_columns], test_data.price\nprint(\"train data set x :\\n{}\".format(train_data_x))\nprint(\"train data set y :\\n{}\".format(train_data_y))\nprint(\"test data set x :\\n{}\".format(test_data_x))\nprint(\"test data set y :\\n{}\".format(test_data_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lasso\nlasso_model = linear_model.Lasso(alpha = 0.000001, normalize = False, max_iter = 10000000, tol = 0.00000001)\nlasso_model.fit(train_data_x, train_data_y)\nlasso_results = lasso_model.predict(test_data_x)\nprint(\"LASSO results:\")\nprint(\"train accuracy = {}\".format(lasso_model.score(train_data_x, train_data_y)))\nprint(\"test accuracy = {}\".format(lasso_model.score(test_data_x, test_data_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ridge\nridge_model = linear_model.Ridge(alpha = 0.000001, normalize = False, max_iter = 10000000, tol = 0.00000001)\nridge_model.fit(train_data_x, train_data_y)\nridge_results = ridge_model.predict(test_data_x)\nprint(\"Ridge results:\")\nprint(\"train accuracy = {}\".format(ridge_model.score(train_data_x, train_data_y)))\nprint(\"test accuracy = {}\".format(ridge_model.score(test_data_x, test_data_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#elasticNet\nelasticNet_model = linear_model.ElasticNet(alpha = 0.000001, normalize = False, max_iter = 10000000, tol = 0.00000001)\nelasticNet_model.fit(train_data_x, train_data_y)\nelasticNet_results = elasticNet_model.predict(test_data_x)\nprint(\"ElasticNet results:\")\nprint(\"train accuracy = {}\".format(ridge_model.score(train_data_x, train_data_y)))\nprint(\"test accuracy = {}\".format(ridge_model.score(test_data_x, test_data_y)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что все 3 метода генерируют модели с приблизительно одинаковой точностью предсказывания. Можно сделать вывод, что модель система недоопределена(нужно больше данных или меньше параметров)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}