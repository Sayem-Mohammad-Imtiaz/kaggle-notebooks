{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom keras.applications import ResNet50, VGG16\nfrom keras.optimizers import Adam\n\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\nimport os\nfrom tqdm import tqdm\n\nimport time\n\nfrom os import listdir\nimport csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/planets-dataset/planet/planet/train_classes.csv\")\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting unique labels\nlabel_list = {}\nsplit = df['tags'].map(lambda x: x.split(' '))\nfor labels in split.values:\n    for label in labels:\n        label_list[label] = label_list[label] + 1 if label in label_list else 0\n\nprint(\"There are {} unique labels in our dataset\".format(len(label_list)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a plot of label occurance against label names. This would let us know which label appears the most in our dataset.\nplt.figure(figsize=(18, 6))\nplt.title('Classes')\nidxs = range(len(label_list.values()))\nplt.xticks(idxs, label_list.keys(), rotation=-45)\nplt.bar(idxs, label_list.values());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's have a look at some images in our dataset\nplt.rc('axes', grid = True)\n\n_, ax = plt.subplots(1, 3, figsize=(20, 20))\nrandom_img = np.random.randint(0,len(df) - 3)\nfor i , (file, label) in enumerate(df[random_img:random_img + 3].values):\n    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(file))\n    ax[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i].set_title('{} - {}'.format(file, label))\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## spliting our data into train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlabel_collection = split.values\nlabels = list(set([y for x in label_collection for y in x]))\n\ndef load_data(df, labels, resize):\n    X_train = []\n    y_train = []\n\n    label_map = {l: i for i, l in enumerate(labels)}\n    inv_label_map = {i: l for l, i in label_map.items()}\n\n    for f, tags in df.values:\n        img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n        targets = np.zeros(17)\n        for t in tags.split(' '):\n            targets[label_map[t]] = 1\n\n        X_train.append(cv2.resize(img,resize))\n        y_train.append(targets)\n        \n    y_train = np.array(y_train, np.uint8)\n    X_train = np.array(X_train, np.float16) / 255.\n\n    return X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = load_data(df, labels, resize=(64, 64))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = 80%, test = 20% of df\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state = 33)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"def f_beta_score(y_true, y_pred):\n    beta_squared = 4\n\n    tp = K.sum(y_true * y_pred) + K.epsilon()\n    fp = K.sum(y_pred) - tp\n    fn = K.sum(y_true) - tp\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    result = (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### CNN\nmodel = Sequential()\nmodel.add(Conv2D(8, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(64, 64, 3)))\nmodel.add(Conv2D(8, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(17, activation='sigmoid')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f_beta_score])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting our model on X_train and y_train\nmodel_fit = model.fit(\n    X_train, y_train,\n    batch_size=64,\n    epochs=5,\n    verbose=1,\n    validation_data=(X_val, y_val)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating Fbeta Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\ny_pred = model.predict(X_val, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cutoff = 0.45                             # decide on a cutoff limit\ny_pred_classes = np.zeros_like(y_pred)    # initialise a matrix full with zeros\ny_pred_classes[y_pred > cutoff] = 1       # add a 1 if the cutoff was breached\n\ny_test_classes = np.zeros_like(y_pred)\ny_test_classes[y_val > cutoff] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting our fbeta score\nscore = fbeta_score(y_test_classes, y_pred_classes, average=\"samples\", beta=0.5)\n\nprint(\"F beta score: \", score)\nprint(\"Error: %.2f%%\" % (100 - score * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display learning curve\ndef learning_curve(model_fit, key='acc', ylim=(0.8, 1.01)):\n    plt.figure(figsize=(12,6))\n    plt.plot(model_fit.history[key])\n    plt.plot(model_fit.history['val_' + key])\n    plt.title('Learning Curve')\n    plt.ylabel(key.title())\n    plt.xlabel('Epoch')\n    plt.ylim(ylim)\n    plt.legend(['train', 'test'], loc='best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_curve(model_fit, key='loss', ylim=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Setting up our test folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make dir to hold all our files from test-jpg folder and test-jpg-additional\nos.mkdir(\"./test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from distutils.dir_util import copy_tree\n\nsrc1 = \"../input/planets-dataset/test-jpg-additional/test-jpg-additional\"\nsrc2 = \"../input/planets-dataset/planet/planet/test-jpg\"\nto = \"./test\"\n\ncopy_tree(src2, to)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking if there a total of 61191 files in our folder\nprint(len(listdir(\"./test\")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# kaggle submission\nX_test = []\nsubmission = []\nfor file in listdir('./test'):\n    filename = file.split('.')[0]\n    \n    img = cv2.imread('./test/{}.jpg'.format(filename))\n    targets = np.zeros(17)\n    \n    X_test.append(cv2.resize(img, (64, 64)))\n    submission.append(filename)\n\nX_test = np.array(X_test, np.float16) / 255\n\ny_test = model.predict(X_test, batch_size=64)\n\nwith open('understanding_the_amazon_from_space_final.csv', 'w', newline='') as csvfile:\n    csv_writer = csv.writer(csvfile, delimiter=',',\n                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n    csv_writer.writerow(('image_name', 'tags'))\n    for i, image in enumerate(submission):\n        csv_writer.writerow((image, ' '.join(np.array(labels)[y_test[i] > 0.45])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}