{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2,os,glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n\n# Flickr image captions data from kaggle (https://www.kaggle.com/hsankesara/flickr-image-dataset)\n\npath = '../input/flickr-image-dataset/flickr30k_images/flickr30k_images/flickr30k_images/*'\ny_data,X_data,X_labels = [],[],[]\nfor img in glob.glob(path):\n    if '.csv' not in img:\n        image = cv2.resize(cv2.imread(img,cv2.IMREAD_GRAYSCALE), (200, 200))\n        X_data.append([np.array(image),img.split('/')[-1]])\n        X_labels.append(img.split('/')[-1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"y_data = pd.read_csv('../input/flickr-image-dataset/flickr30k_images/flickr30k_images/results.csv', delimiter='|')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_data[y_data['image_name']==X_data[0][1]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Text processing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_corresponding = []\nfor each in X_labels:\n    captions = np.array(y_data[y_data['image_name']==each][' comment'])\n    y_corresponding.append(captions)\n    \nprint(X_labels[0])\nprint(y_corresponding[0]) #y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef clean(text):\n    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split()).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_clean = []\nfor each in y_corresponding:\n    y_each = []\n    for text in each:\n        try:\n            y_each.append(clean(text))\n        except Exception as e:\n            print(e)\n            pass\n    y_clean.append(y_each)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_clean[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_data[0][0]) #X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(y_data)\nvocab = np.array(df[' comment'])\nprint(len(vocab))\nvocab = [str(each) for each in vocab] # one array of all sentences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_text = clean(' '.join(str(v) for v in vocab))\nprint(clean_text[:100]) # one continuous string of all words\nprint(len(set(clean_text.split(' '))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\nfrom keras import models\n\nmodelvgg = VGG16(weights='imagenet',include_top=True)\nmodelvgg.layers.pop() # remove last layer of predictions\nmodelvgg = models.Model(inputs=modelvgg.inputs, outputs=modelvgg.layers[-1].output)\nmodelvgg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelvgg.compile(loss='categorical_crossentropy', optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words=18300) # max num of words\ntokenizer.fit_on_texts(vocab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yfit_data = []\nyfit_data = [tokenizer.texts_to_sequences(each) for each in y_clean]\n\nprint(y_clean[0])\nprint(yfit_data[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(yfit_data),len(X_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X_data, yfit_data, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist = modelvgg.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, verbose=2, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}