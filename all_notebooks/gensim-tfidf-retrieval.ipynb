{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## TFIDF based retrial using gensim\n\nThis notebook defines the **gensim-based document retrieval method based on tf-idf similarity score** (between corpus documents and the query string).\n\n1. Cleanup / preprocess \n2. Define dictionary\n3. Transform corpus - Bag of Worgs\n4. Learn tfidf vectors for corpus\n5. Sparse matrix indexing for similarity scoring\n6. Retrieve top N document for the given query string","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os, sys","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\nfrom gensim import corpora\nfrom gensim.parsing import strip_tags, strip_numeric, \\\n    strip_multiple_whitespaces, stem_text, strip_punctuation, \\\n    remove_stopwords, preprocess_string\nimport pprint\nimport re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get the dataset as text corpus","metadata":{}},{"cell_type":"code","source":"# get all the news group docs\ndata = fetch_20newsgroups(subset='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collect all text documents as list\ntext_docs = data['data']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess the text corpus","metadata":{}},{"cell_type":"code","source":"# preprocess using gensim.parsing\n# ref: https://www.kaggle.com/venkatkrishnan/gensim-text-mining-techniques\ntransform_to_lower = lambda s: s.lower()\n\nremove_single_char = lambda s: re.sub(r'\\s+\\w{1}\\s+', '', s)\n\n# Filters to be executed in pipeline\nCLEAN_FILTERS = [strip_tags,\n                strip_numeric,\n                strip_punctuation, \n                strip_multiple_whitespaces, \n                transform_to_lower,\n                remove_stopwords,\n                remove_single_char]\n\n# Method does the filtering of all the unrelevant text elements\ndef cleaning_pipe(document):\n    # Invoking gensim.parsing.preprocess_string method with set of filters\n    processed_words = preprocess_string(document, CLEAN_FILTERS)\n    \n    return processed_words\nprint(cleaning_pipe(text_docs[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define corpus dictionary","metadata":{}},{"cell_type":"code","source":"def create_dictionary(docs):\n    'create dictionary of words in preprocessed corpus'\n    pdocs = [cleaning_pipe(doc) for doc in docs]\n    dictionary = corpora.Dictionary(pdocs)\n    dictionary.save('newsgroup.dict')\n    return dictionary,pdocs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dictionary, pdocs = create_dictionary(text_docs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dictionary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- dictionary is huge in size (177k unique words - 177k dimensions) but gensim will be able to manage it efficiently.","metadata":{}},{"cell_type":"markdown","source":"### Transform any sample document as per the known dictionary","metadata":{}},{"cell_type":"code","source":"new_doc = \"Human computer interaction\"\nnew_vec = dictionary.doc2bow(cleaning_pipe(new_doc))\nprint(new_vec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transform complete corpus as BoW","metadata":{}},{"cell_type":"code","source":"bow_corpus = [dictionary.doc2bow(text) for text in pdocs]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit the tfidf model a.k.a tfidf vectorizer","metadata":{}},{"cell_type":"code","source":"from gensim import models\n\n# train the model\ntfidf = models.TfidfModel(bow_corpus)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform any new document as tfidf vector\nwords = cleaning_pipe(\"want to sell bike\")\nprint(tfidf[dictionary.doc2bow(words)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sparse matrix indexing for similarity scoring","metadata":{}},{"cell_type":"code","source":"# index the tfidf vector of corpus as sparse matrix\nfrom gensim import similarities\nindex = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=len(dictionary))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Retrieve top N document for the given query string","metadata":{}},{"cell_type":"code","source":"def get_closest_n(query, n):\n    '''get the top matching docs as per cosine similarity\n    between tfidf vector of query and all docs'''\n    query_document = cleaning_pipe(query)\n    query_bow = dictionary.doc2bow(query_document)\n    sims = index[tfidf[query_bow]]\n    top_idx = sims.argsort()[-1*n:][::-1]\n    return [text_docs[i] for i in top_idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for d in get_closest_n(\"how to sell my broken aeroplane\",2):\n    print(d)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}