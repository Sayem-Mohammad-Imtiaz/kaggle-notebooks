{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font size=5 > <p style=\"color:purple\"> Which Factors Influence the Price of Health Insurance?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/zTnvOcb.jpg\" width=\"800\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size='2'>Many factors that affect how much you pay for health insurance are not within your control. Nonetheless, it's good to have an understanding of what they are. Here are some factors that affect how much health insurance premiums cost\n\n* **age:** age of primary beneficiary\n\n* **sex:** insurance contractor gender, female, male\n\n* **bmi:** Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n\n* **children:** Number of children covered by health insurance / Number of dependents\n\n* **smoker:** Smoking\n\n* **region:** the beneficiary's residential area in the US, northeast, southeast, southwest, northwest","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=5><p style=\"color:purple\"> EDA and Visualizations ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/insurance.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>We have 0 missing values which is very good.\nNow let's do EDA with some cool graphs :) First we'll see how the charges are distributed according to given factors ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='whitegrid')\nf, ax = plt.subplots(1,1, figsize=(12, 8))\nax = sns.distplot(df['charges'], kde = True, color = 'c')\nplt.title('Distribution of Charges')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>This distribution is right-skewed. To make it closer to normal we can apply natural log ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(12, 8))\nax = sns.distplot(np.log10(df['charges']), kde = True, color = 'r' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=2> Now let's look at the charges by region","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"charges = df['charges'].groupby(df.region).sum().sort_values(ascending = True)\nf, ax = plt.subplots(1, 1, figsize=(8, 6))\nax = sns.barplot(charges.head(), charges.head().index, palette='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>So overall the highest medical charges are in the Southeast and the lowest are in the Southwest. Taking into account certain factors (sex, smoking, having children) let's see how it changes by region ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(12, 8))\nax = sns.barplot(x='region', y='charges', hue='sex', data=df, palette='cool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,1, figsize=(12,8))\nax = sns.barplot(x = 'region', y = 'charges',\n                 hue='smoker', data=df, palette='Reds_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(12, 8))\nax = sns.barplot(x='region', y='charges', hue='children', data=df, palette='Set1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>As we can see from these barplots the highest charges due to smoking are still in the Southeast but the lowest are in the Northeast. People in the Southwest generally smoke more than people in the Northeast, but people in the Northeast have higher charges by gender than in the Southwest and Northwest overall. And people with children tend to have higher medical costs overall as well","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>Now let's analyze the medical charges by age, bmi and children according to the smoking factor ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.lmplot(x = 'age', y = 'charges', data=df, hue='smoker', palette='Set1')\nax = sns.lmplot(x = 'bmi', y = 'charges', data=df, hue='smoker', palette='Set2')\nax = sns.lmplot(x = 'children', y = 'charges', data=df, hue='smoker', palette='Set3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>Smoking has the highest impact on medical costs, even though the costs are growing with age, bmi and children. Also people who have children generally smoke less, which the following violinplots shows too","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(10, 10))\nax = sns.violinplot(x = 'children', y = 'charges', data=df,\n                 orient='v', hue='smoker', palette='inferno')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Converting objects labels into categorical\ndf[['sex', 'smoker', 'region']] = df[['sex', 'smoker', 'region']].astype('category')\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Converting category labels into numerical using LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\nlabel.fit(df.sex.drop_duplicates())\ndf.sex = label.transform(df.sex)\nlabel.fit(df.smoker.drop_duplicates())\ndf.smoker = label.transform(df.smoker)\nlabel.fit(df.region.drop_duplicates())\ndf.region = label.transform(df.region)\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(10, 10))\nax = sns.heatmap(df.corr(), annot=True, cmap='cool')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>No correlation, except with the smoking ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=5><p style=\"color:purple\"> Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split as holdout\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nx = df.drop(['charges'], axis = 1)\ny = df['charges']\nx_train, x_test, y_train, y_test = holdout(x, y, test_size=0.2, random_state=0)\nLin_reg = LinearRegression()\nLin_reg.fit(x_train, y_train)\nprint(Lin_reg.intercept_)\nprint(Lin_reg.coef_)\nprint(Lin_reg.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font>The result we got is good enough, but we can try to improve it a bit by reducing unimportant features later","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=5><p style=\"color:purple\">Ridge Regression ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nRidge = Ridge(alpha=0.5)\nRidge.fit(x_train, y_train)\nprint(Ridge.intercept_)\nprint(Ridge.coef_)\nprint(Ridge.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=5><p style=\"color:purple\"> Lasso Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nLasso = Lasso(alpha=0.2, fit_intercept=True, normalize=False, precompute=False, max_iter=1000,\n              tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\nLasso.fit(x_train, y_train)\nprint(Lasso.intercept_)\nprint(Lasso.coef_)\nprint(Lasso.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=5><p style=\"color:purple\"> Random Forest Regressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor as rfr\nx = df.drop(['charges'], axis=1)\ny = df.charges\nRfr = rfr(n_estimators = 100, criterion = 'mse',\n                              random_state = 1,\n                              n_jobs = -1)\nRfr.fit(x_train,y_train)\nx_train_pred = Rfr.predict(x_train)\nx_test_pred = Rfr.predict(x_test)\n\nprint('MSE train data: %.3f, MSE test data: %.3f' % \n      (metrics.mean_squared_error(x_train_pred, y_train),\n       metrics.mean_squared_error(x_test_pred, y_test)))\nprint('R2 train data: %.3f, R2 test data: %.3f' % \n      (metrics.r2_score(y_train,x_train_pred, y_train),\n       metrics.r2_score(y_test,x_test_pred, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\n\nplt.scatter(x_train_pred, x_train_pred - y_train,\n          c = 'gray', marker = 'o', s = 35, alpha = 0.5,\n          label = 'Train data')\nplt.scatter(x_test_pred, x_test_pred - y_test,\n          c = 'blue', marker = 'o', s = 35, alpha = 0.7,\n          label = 'Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.legend(loc = 'upper right')\nplt.hlines(y = 0, xmin = 0, xmax = 60000, lw = 2, color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Feature importance ranking\\n\\n')\nimportances = Rfr.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in Rfr.estimators_],axis=0)\nindices = np.argsort(importances)[::-1]\nvariables = ['age', 'sex', 'bmi', 'children','smoker', 'region']\nimportance_list = []\nfor f in range(x.shape[1]):\n    variable = variables[indices[f]]\n    importance_list.append(variable)\n    print(\"%d.%s(%f)\" % (f + 1, variable, importances[indices[f]]))\n\n# Plot the feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(importance_list, importances[indices],\n       color=\"y\", yerr=std[indices], align=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=5><p style=\"color:purple\"> Polynomial Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nx = df.drop(['charges', 'sex', 'region'], axis = 1)\ny = df.charges\npol = PolynomialFeatures (degree = 2)\nx_pol = pol.fit_transform(x)\nx_train, x_test, y_train, y_test = holdout(x_pol, y, test_size=0.2, random_state=0)\nPol_reg = LinearRegression()\nPol_reg.fit(x_train, y_train)\ny_train_pred = Pol_reg.predict(x_train)\ny_test_pred = Pol_reg.predict(x_test)\nprint(Pol_reg.intercept_)\nprint(Pol_reg.coef_)\nprint(Pol_reg.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size='2' font >Awesome! :)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##Evaluating the performance of the algorithm\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_test_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_test_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Predicting the charges\ny_test_pred = Pol_reg.predict(x_test)\n##Comparing the actual output values with the predicted values\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_pred})\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=2> **Conclusion:** like we previously noticed **smoking** is the greatest factor that affects medical cost charges, then it's **bmi** and **age**. **Polynomial Regression** turned out to be the best model","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}