{"cells":[{"metadata":{"papermill":{"duration":0.131628,"end_time":"2020-11-06T19:39:49.335347","exception":false,"start_time":"2020-11-06T19:39:49.203719","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n\n### Minería de Datos: Curso académico 2020-2021\n\n* Ángel Torres del Álamo\n* José Ángel Royo López"},{"metadata":{"papermill":{"duration":0.125361,"end_time":"2020-11-06T19:39:49.588887","exception":false,"start_time":"2020-11-06T19:39:49.463526","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 1. Introducción"},{"metadata":{},"cell_type":"markdown","source":"En esta primera práctica vamos a realizar dos estudios utilizando los dataset `Diabetes` y `Wisconsin`. Para cada estudio se cargarán los datos, después se realizará un análisis exploratorio de datos mediante gráficas y estadísticos para obtener información que nos permita realizar un buen preprocesamiento de datos y aprender y evaluar varios modelos para estos conjuntos de datos. Para realizar esto se utilizará la librería `sklearn`, con la que nos iremos familiarizando para el desarrollo de las prácticas posteriores."},{"metadata":{"papermill":{"duration":0.127887,"end_time":"2020-11-06T19:39:49.846385","exception":false,"start_time":"2020-11-06T19:39:49.718498","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En primer lugar vamos a cargar librerias de python necesarias para realizar el estudio de forma comoda y correcta, con datos y gráficas que permitan sacar conclusiones. Tambíen utilizaremos el script realizado por `Juan Carlos Alfaro Jiménez` con otras funciones creadas por nosotros en el mismo archivo, que nos ayudará a hacer más legible el estudio."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-11-06T19:39:50.11561Z","iopub.status.busy":"2020-11-06T19:39:50.114756Z","iopub.status.idle":"2020-11-06T19:39:54.326364Z","shell.execute_reply":"2020-11-06T19:39:54.325584Z"},"papermill":{"duration":4.353493,"end_time":"2020-11-06T19:39:54.32651","exception":false,"start_time":"2020-11-06T19:39:49.973017","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import KNNImputer\n#from sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline\nfrom imblearn import FunctionSampler\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.123315,"end_time":"2020-11-06T19:39:54.576158","exception":false,"start_time":"2020-11-06T19:39:54.452843","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 2. Dataset Diabetes"},{"metadata":{"papermill":{"duration":0.123979,"end_time":"2020-11-06T19:39:54.824967","exception":false,"start_time":"2020-11-06T19:39:54.700988","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Para este primer Dataset, vamos a tener un base de datos clínicos sobre resultados de la enfermedad de la diabetes y valores médicos relacionados con esta enfermedad."},{"metadata":{"papermill":{"duration":0.129896,"end_time":"2020-11-06T19:39:55.081688","exception":false,"start_time":"2020-11-06T19:39:54.951792","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a establecer una semilla para este estudio, para que los resultados que se muestran sean reproducibles y repetibles."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:55.338536Z","iopub.status.busy":"2020-11-06T19:39:55.337475Z","iopub.status.idle":"2020-11-06T19:39:55.340875Z","shell.execute_reply":"2020-11-06T19:39:55.340121Z"},"papermill":{"duration":0.132977,"end_time":"2020-11-06T19:39:55.341009","exception":false,"start_time":"2020-11-06T19:39:55.208032","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.123628,"end_time":"2020-11-06T19:39:55.588029","exception":false,"start_time":"2020-11-06T19:39:55.464401","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 2.1. Acceso y almacenamiento de datos"},{"metadata":{"papermill":{"duration":0.122601,"end_time":"2020-11-06T19:39:55.834176","exception":false,"start_time":"2020-11-06T19:39:55.711575","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Cargamos el conjunto de datos de diabetes, a través de la libreria de pandas."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:56.095528Z","iopub.status.busy":"2020-11-06T19:39:56.094642Z","iopub.status.idle":"2020-11-06T19:39:56.11424Z","shell.execute_reply":"2020-11-06T19:39:56.113374Z"},"papermill":{"duration":0.156161,"end_time":"2020-11-06T19:39:56.114384","exception":false,"start_time":"2020-11-06T19:39:55.958223","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\nfilepath = \"../input/pimaindiansdiabetesdatabase/diabetes.csv\"\ntarget = 'Outcome'\n\ndata = utils.load_data(filepath, None, target)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.122942,"end_time":"2020-11-06T19:39:56.366219","exception":false,"start_time":"2020-11-06T19:39:56.243277","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a imprimir por pantalla 5 ejemplos de nuestra base de datos de forma aleatoria, para que nuestra muestra imprimida no esté `sesgada` y ver como se estructura la información."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:56.635986Z","iopub.status.busy":"2020-11-06T19:39:56.635134Z","iopub.status.idle":"2020-11-06T19:39:56.647327Z","shell.execute_reply":"2020-11-06T19:39:56.646439Z"},"papermill":{"duration":0.156516,"end_time":"2020-11-06T19:39:56.647466","exception":false,"start_time":"2020-11-06T19:39:56.49095","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data.sample(5,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.12828,"end_time":"2020-11-06T19:39:56.902306","exception":false,"start_time":"2020-11-06T19:39:56.774026","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Nuestra base de datos tiene 9 columnas o variables:\n\n#### Variables predictoras\n* `Pregnancies (Embarazos)`\n\n* `Glucose (Glucosa)`\n\n* `BloodPressure (Presión de sangre)`\n\n* `SkinThickness (Espesor de la piel)`\n\n* `Insulin (Insulina)`\n\n* `BMI (IMC)`\n\n* `DiabetesPedigreeFunction (Función de pedigrí de la diabetes)`\n\n* `Age (Edad)`\n\n#### Variable clase\n* `Outcome (Resultado)`\n"},{"metadata":{"papermill":{"duration":0.125887,"end_time":"2020-11-06T19:39:57.157555","exception":false,"start_time":"2020-11-06T19:39:57.031668","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Dividimos la base de datos en las variables predictoras, guardadas en el atributo `X`. Y la variable clase en el atributo `y`."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:57.465658Z","iopub.status.busy":"2020-11-06T19:39:57.464513Z","iopub.status.idle":"2020-11-06T19:39:57.468184Z","shell.execute_reply":"2020-11-06T19:39:57.467558Z"},"papermill":{"duration":0.133762,"end_time":"2020-11-06T19:39:57.468328","exception":false,"start_time":"2020-11-06T19:39:57.334566","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.125169,"end_time":"2020-11-06T19:39:57.718235","exception":false,"start_time":"2020-11-06T19:39:57.593066","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a comprobar que la división de la base de datos se ha realizado de forma correcta y tiene todas las variables predictoras."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:57.987249Z","iopub.status.busy":"2020-11-06T19:39:57.986064Z","iopub.status.idle":"2020-11-06T19:39:57.99147Z","shell.execute_reply":"2020-11-06T19:39:57.990707Z"},"papermill":{"duration":0.148022,"end_time":"2020-11-06T19:39:57.991607","exception":false,"start_time":"2020-11-06T19:39:57.843585","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:58.25474Z","iopub.status.busy":"2020-11-06T19:39:58.253789Z","iopub.status.idle":"2020-11-06T19:39:58.258737Z","shell.execute_reply":"2020-11-06T19:39:58.258128Z"},"papermill":{"duration":0.13871,"end_time":"2020-11-06T19:39:58.258877","exception":false,"start_time":"2020-11-06T19:39:58.120167","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"y.cat.categories","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.125356,"end_time":"2020-11-06T19:39:58.510074","exception":false,"start_time":"2020-11-06T19:39:58.384718","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a separar el conjunto de datos en dos conjuntos diferentes: `Entrenamiento` y `test`.\n\nEste proceso llamado `houldout`, lo utilizamos para no sobreajustar el modelo de entrenamiento y validar de una forma más honesta los resultados dados por el modelo.\n\n* La muestra de entrenamiento será el 70% de la base de datos.\n* La muestra de test será el 30% de la base de datos."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:58.770901Z","iopub.status.busy":"2020-11-06T19:39:58.769984Z","iopub.status.idle":"2020-11-06T19:39:58.778938Z","shell.execute_reply":"2020-11-06T19:39:58.778161Z"},"papermill":{"duration":0.141869,"end_time":"2020-11-06T19:39:58.779087","exception":false,"start_time":"2020-11-06T19:39:58.637218","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.130764,"end_time":"2020-11-06T19:39:59.036932","exception":false,"start_time":"2020-11-06T19:39:58.906168","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Haciendo una muestra de la base de datos nueva de entrenamiento, vemos como es diferente a la muestra realizada anteriormente."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:39:59.31036Z","iopub.status.busy":"2020-11-06T19:39:59.309288Z","iopub.status.idle":"2020-11-06T19:39:59.315069Z","shell.execute_reply":"2020-11-06T19:39:59.313886Z"},"papermill":{"duration":0.152217,"end_time":"2020-11-06T19:39:59.315208","exception":false,"start_time":"2020-11-06T19:39:59.162991","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.126768,"end_time":"2020-11-06T19:39:59.568353","exception":false,"start_time":"2020-11-06T19:39:59.441585","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 2.2. Análisis exploratorio"},{"metadata":{"papermill":{"duration":0.129132,"end_time":"2020-11-06T19:39:59.824505","exception":false,"start_time":"2020-11-06T19:39:59.695373","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En este apartado, vamos a estudiar las diferentes variables que tenemos en nuestra base de datos. Así como los tipos de valores que tienen y los diferentes valores que pueden conseguir.  "},{"metadata":{"papermill":{"duration":0.129848,"end_time":"2020-11-06T19:40:00.080856","exception":false,"start_time":"2020-11-06T19:39:59.951008","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Con el siguiente codigo, vamos a mostar la información de todas las variables de nuestra base de datos para ayudarnos en nuestro estudio.\n"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:00.352255Z","iopub.status.busy":"2020-11-06T19:40:00.351266Z","iopub.status.idle":"2020-11-06T19:40:00.356191Z","shell.execute_reply":"2020-11-06T19:40:00.355219Z"},"papermill":{"duration":0.14744,"end_time":"2020-11-06T19:40:00.356371","exception":false,"start_time":"2020-11-06T19:40:00.208931","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.128419,"end_time":"2020-11-06T19:40:00.613949","exception":false,"start_time":"2020-11-06T19:40:00.48553","status":"completed"},"tags":[]},"cell_type":"markdown","source":"La variable clase `Outcome` en este estudio es una variable numérica entera, discreta con dos posibles valores: 0 y 1. Este valor indica si dada la instancia de la base de datos, el resultado de su diagnostico es positivo en diabetes.\n\nEl resto de variables, las predictoras, tambien son numéricas de tipo entero. Excepto `BMI` y `DiabetePedigreeFunction`, que son de tipo flotante."},{"metadata":{"papermill":{"duration":0.128316,"end_time":"2020-11-06T19:40:00.87115","exception":false,"start_time":"2020-11-06T19:40:00.742834","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### 2.2.1 Visualización de los datos"},{"metadata":{"papermill":{"duration":0.131652,"end_time":"2020-11-06T19:40:01.133762","exception":false,"start_time":"2020-11-06T19:40:01.00211","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Una vez conocidos los tipos de variables que tenemos vamos a estudiar los datos de las varaibles con más exactitud y sacar conclusiones razonables para la creación de un buen modelo.\n\nPrimero vamos a unir en una única base de datos, todo el conocimiento de entrenamiento que hemos obtenido anteriormente mediante el houldout de la base de datos completa."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:01.411387Z","iopub.status.busy":"2020-11-06T19:40:01.410402Z","iopub.status.idle":"2020-11-06T19:40:01.414438Z","shell.execute_reply":"2020-11-06T19:40:01.415082Z"},"papermill":{"duration":0.149992,"end_time":"2020-11-06T19:40:01.415277","exception":false,"start_time":"2020-11-06T19:40:01.265285","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.127163,"end_time":"2020-11-06T19:40:01.66977","exception":false,"start_time":"2020-11-06T19:40:01.542607","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Primero vamos a utilizar un estudio `univariado`. Al analizar las variables por separados podemos estudiar si alguna de estas variables contiene datos ruidosos o `outliers`. También podemos observar de esta manera la distribución de valores de una variable, si una variable es uniforme no nos aportará mucha información ya que tendrá siempre el mismo valor. Mientras que, si nuestra distribución es gaussiana nos ayudará a la hora de realizar el estudio."},{"metadata":{"papermill":{"duration":0.125665,"end_time":"2020-11-06T19:40:01.92339","exception":false,"start_time":"2020-11-06T19:40:01.797725","status":"completed"},"tags":[]},"cell_type":"markdown","source":"A partir de un histograma podemos ver la densidad de ejemplos para distintos valores de una variable numérica. Tambíen nos permite conocer información de las variables por separado como hemos dicho anteriormente. La siguiente gráfica interactiva permite ver la distribución de cada variable por separado, pudiendo ver a simple vista valores ruidosos o la distribución de cada variable. En este caso, la gráfica lo utilizaremos para observar `outliers`."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:02.203054Z","iopub.status.busy":"2020-11-06T19:40:02.201984Z","iopub.status.idle":"2020-11-06T19:40:03.466593Z","shell.execute_reply":"2020-11-06T19:40:03.467245Z"},"papermill":{"duration":1.40364,"end_time":"2020-11-06T19:40:03.467408","exception":false,"start_time":"2020-11-06T19:40:02.063768","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.14922,"end_time":"2020-11-06T19:40:03.769295","exception":false,"start_time":"2020-11-06T19:40:03.620075","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos observar en las gráficas como hay variables que poseen valores nulos, en este caso estos valores nulos estan representados por un valor `0`. Ya que, muchos atributos no tienen sentido porque no se puede tener este valor, pero hay algunos atributos que tener valores a 0 si tienen sentido. Lo estudiaremos a continuación.\n\nVamos a estudiar los atributos y si tienen *outliers* por orden que aparecen en la gráfica.\n\n`Pregnancies`: Tiene algunso ejemplos en la base de datos que se aleja de la distribución de valores para este atributo. Esta variable al indicar los embarazos, tener valores tan altos como 14 embarazos, no tiene sentido. Aunque, como los casos son tan menores no se tendrán en cuenta.\n\n`Glucose`: Este atributo poseé dos ejemplos con valores a 0. Lo cuál es un valor erroneo, ya que se necesita una medida. Este valor es un valor nulo para nuestra base de datos. Estos valores nulos los controlaremos en el preprocesamiento.\n\n`BloodPressure`: Al igual que en Glucose también tiene valores a 0, a su vez tambíen hay muestras de datos que están alejados de la distribución normal de la variable.\n\n`SkinThickness`: Posee muchos ejemplos en la base de datos con un valor a 0 o nulo. Esto supondrá un problema para el score que nos darán los modelos. En estos casos si el `20%` de los valores del atributo son nulos, eliminaremos la variable completa, ya que no introduce conocimiento adicional.\n\n`Insulin`: Tienen muchos *outliers* que se alejan mucho de la distribución, también posee una gran cantidad de valores nulos. Es la variable con más valores a 0. Al igual que el anterior atributo, estudiaremos si la variable puede ser eliminada y en caso de que sea así lo haremos en el preprocesamiento.\n\n`BMI`: Otro atributo que posee valores nulos que tendremos que manejar en el preprocesamiento.\n\n`DiabetesPedigreeFunction`: Este atributo es similar a Insulin, tiene *outliers* muy alejados de la media de la distribución del atributo, aunque al ser tan pocos los casos no se eliminarán y es posible que estos outliers puedan ayudar a tener un modelo más preciso.\n\n`Age`: Esta variable no supone muchos problemas con los *outliers*, teniendo muy pocos ejemplos de estos en la base de datos."},{"metadata":{"papermill":{"duration":0.153489,"end_time":"2020-11-06T19:40:04.072992","exception":false,"start_time":"2020-11-06T19:40:03.919503","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Como hemos comentado anteriormente, hay variables con gran cantidad de valores nulos. Vamos a dar el porcentaje que supone estos valores y si es `mayor que el 20%`, eliminaremos completamente todo el atributo. Estas variables son `SkinThickness` e `Insulin`. "},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:04.401553Z","iopub.status.busy":"2020-11-06T19:40:04.400531Z","iopub.status.idle":"2020-11-06T19:40:04.425982Z","shell.execute_reply":"2020-11-06T19:40:04.425165Z"},"papermill":{"duration":0.189384,"end_time":"2020-11-06T19:40:04.42612","exception":false,"start_time":"2020-11-06T19:40:04.236736","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"valor_nulo = 0\ndata_train['SkinThickness'].value_counts(normalize = True)[valor_nulo] * 100","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.155898,"end_time":"2020-11-06T19:40:04.734558","exception":false,"start_time":"2020-11-06T19:40:04.57866","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Para `SkinThickness`, el 29.24% de los valores del atributo son valores nulos, a 0. Entonces, esta variable la quitaremos de nuestra base de datos."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:05.057713Z","iopub.status.busy":"2020-11-06T19:40:05.056504Z","iopub.status.idle":"2020-11-06T19:40:05.061542Z","shell.execute_reply":"2020-11-06T19:40:05.060803Z"},"papermill":{"duration":0.172483,"end_time":"2020-11-06T19:40:05.061721","exception":false,"start_time":"2020-11-06T19:40:04.889238","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train['Insulin'].value_counts(normalize = True)[valor_nulo] * 100","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.151896,"end_time":"2020-11-06T19:40:05.368311","exception":false,"start_time":"2020-11-06T19:40:05.216415","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Para `Insulin`, el 48.6% de los valores son nulos, por tanto esta variable contiene una gran cantidad de estos valores y será eliminada."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:05.681876Z","iopub.status.busy":"2020-11-06T19:40:05.680918Z","iopub.status.idle":"2020-11-06T19:40:05.68599Z","shell.execute_reply":"2020-11-06T19:40:05.685179Z"},"papermill":{"duration":0.166224,"end_time":"2020-11-06T19:40:05.68614","exception":false,"start_time":"2020-11-06T19:40:05.519916","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train['BloodPressure'].value_counts(normalize = True)[valor_nulo] * 100","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.158491,"end_time":"2020-11-06T19:40:06.002922","exception":false,"start_time":"2020-11-06T19:40:05.844431","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Por último, para la variable `BloodPressure`, el 4.66% son valores nulos. Por tanto esta variable no será eliminada y realizaremos una imputación para dar un valor correcto a estos valores nulos en el preprocesamiento."},{"metadata":{"papermill":{"duration":0.157435,"end_time":"2020-11-06T19:40:06.313801","exception":false,"start_time":"2020-11-06T19:40:06.156366","status":"completed"},"tags":[]},"cell_type":"markdown","source":"A continuación, vamos a estudiar la distribución de cada atributo. Podemos conocer cada distribución de una forma gráfica y ver que atributos se acercan a una distribución gaussiana o normal.\n\nCon una función creada por nosotros, llamada `plot_distribution` y guardada en el script de `utils`, representaremos gráficamente la distribución de todas las variables para estudiarla de una forma más comoda. Ignorando los valores nulos y ruidosos que hemos visto en el anterior apartado."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:06.628576Z","iopub.status.busy":"2020-11-06T19:40:06.627492Z","iopub.status.idle":"2020-11-06T19:40:06.630878Z","shell.execute_reply":"2020-11-06T19:40:06.631478Z"},"papermill":{"duration":0.162515,"end_time":"2020-11-06T19:40:06.631667","exception":false,"start_time":"2020-11-06T19:40:06.469152","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_distribution(data_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.152677,"end_time":"2020-11-06T19:40:06.935149","exception":false,"start_time":"2020-11-06T19:40:06.782472","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Aunque en las gráficas salgan las variables Insulin y SkinThickness, no las estudiaremos ya que estos atributos los elimaneremos de nuestra base de datos como hemos comentado anteriormente. Iremos estudiando cada variable una por una, ya que a simple vista no podemos distinguir nada.\n\nEn las gráficas podemos observar distribuciones gaussianas o normales en forma de campana, estos atributos son: `BloodPressure`, `Glucose` y `BMI`."},{"metadata":{"papermill":{"duration":0.154332,"end_time":"2020-11-06T19:40:07.248274","exception":false,"start_time":"2020-11-06T19:40:07.093942","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Por último, para el análisis univariado, vamos a comprobar el número de casos diferentes para la variable clase. Comprobando si nuestra base de datos de entrenamiento esta `balanceada`."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:07.583271Z","iopub.status.busy":"2020-11-06T19:40:07.582244Z","iopub.status.idle":"2020-11-06T19:40:07.657528Z","shell.execute_reply":"2020-11-06T19:40:07.656915Z"},"papermill":{"duration":0.258484,"end_time":"2020-11-06T19:40:07.657691","exception":false,"start_time":"2020-11-06T19:40:07.399207","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:07.987929Z","iopub.status.busy":"2020-11-06T19:40:07.986832Z","iopub.status.idle":"2020-11-06T19:40:07.992582Z","shell.execute_reply":"2020-11-06T19:40:07.993457Z"},"papermill":{"duration":0.178237,"end_time":"2020-11-06T19:40:07.993693","exception":false,"start_time":"2020-11-06T19:40:07.815456","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(\"Valores:\\n\",data_train['Outcome'].value_counts(), \"\\n\\nFrecuencia:\\n\",data_train['Outcome'].value_counts(normalize = True)*100)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.160558,"end_time":"2020-11-06T19:40:08.317689","exception":false,"start_time":"2020-11-06T19:40:08.157131","status":"completed"},"tags":[]},"cell_type":"markdown","source":"El número de ejemplos en nuestra base de datos de entrenamiento esta `desbalanceado`. El número de resultados que son `0` es de **350 ejemplos**, mientras que de resultado `1` es de **187 ejemplos**. Esto supone que el `65.18%` de nuestra variable clase, es de valor `0`.\n\nEs normal que en una base de datos medicos, tengamos más ejemplos de pacientes que no tengan una enfermedad dada. La mayoría de pacientes que se hacen revisiones no tendrán la enfermedad que estamos estudiando. Por tanto, es normal que este tipo de base de datos esten desbalanceadas."},{"metadata":{"papermill":{"duration":0.164374,"end_time":"2020-11-06T19:40:08.643958","exception":false,"start_time":"2020-11-06T19:40:08.479584","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Una vez estudiadas las variables de forma individual, para completar el estudio de las variables, tenemos que ver las relaciones entre estas variables. Este estudio llamado `multievaluado`, nos muestra información imporante sobre el discretizado de las variables y su potencia discriminatoria. Tambíen, sobre los valores ruidosos que se pueden encontrar en una zona con gran cantidad de otros valores clase.\n\nPara este estudio se van a eliminar las variables `Insulin` y `SkinThickness` ya que no nos aportan información."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:08.974086Z","iopub.status.busy":"2020-11-06T19:40:08.973035Z","iopub.status.idle":"2020-11-06T19:40:09.141726Z","shell.execute_reply":"2020-11-06T19:40:09.142343Z"},"papermill":{"duration":0.338552,"end_time":"2020-11-06T19:40:09.142507","exception":false,"start_time":"2020-11-06T19:40:08.803955","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train[data_train.columns.difference(['Insulin','SkinThickness'])], target='Outcome')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.177223,"end_time":"2020-11-06T19:40:09.502235","exception":false,"start_time":"2020-11-06T19:40:09.325012","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Estás gráficas nos dan una representación de los valores de `Outcome` para cada par de variables. Podemos sacar un valor de corte y las variables necesarias para discretizar una variable clase y tener un modelo correcto.\n\nComo se observa en las gráficas, los pares de variables no nos dan una discretización muy definida. Los valores de `Outcome` se superponen en los valores que vemos. Aunque, `Glucose` es la única variable que nos puede dar un potencial discriminatorio en valores altos de este atributo. Pero, contiene muchos valores ruidosos que dificultan un resultado preciso en el modelo final.\n\nEntonces, como solo vemos un corte claro, la discretización se realizará mediante unicamente 2 intervalos en el caso de un modelo con discretización. Como tampoco se muestra un corte claro también se probará con un modelo sin discretizar."},{"metadata":{"papermill":{"duration":0.184803,"end_time":"2020-11-06T19:40:09.866998","exception":false,"start_time":"2020-11-06T19:40:09.682195","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 2.3. Preprocesamiento de datos"},{"metadata":{"papermill":{"duration":0.179875,"end_time":"2020-11-06T19:40:10.229818","exception":false,"start_time":"2020-11-06T19:40:10.049943","status":"completed"},"tags":[]},"cell_type":"markdown","source":"El preprocesamiento de datos es la tarea más importante del proceso KDD. En este apartado realizaremos:\n\n* `Limpieza de datos`\n* `Integración de datos`\n* `Transformación de datos`\n* `Reducción de datos`\n\nPara esta tarea se utilizara un `pipeline` para no cometer una `fuga de datos` y no introducir datos del conjunto de entrenamiento donde se aprenderá el modelo en el conjunto de prueba donde los datos de este conjunto son `datos crudos`. Una vez elaborado este apartado se tendrá que validad el modelo entrenado."},{"metadata":{"papermill":{"duration":0.182015,"end_time":"2020-11-06T19:40:10.593927","exception":false,"start_time":"2020-11-06T19:40:10.411912","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En primer lugar, quitaremos las columnas `SkinThickness` e `Insulin` mediante una función que le añadiremos al pipeline. Es necesario añadirla al pipeline, ya que al quitar columnas también es necesario quitarlas en la partición de test al igual que en la de entrenamiento."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:10.956629Z","iopub.status.busy":"2020-11-06T19:40:10.955573Z","iopub.status.idle":"2020-11-06T19:40:10.959105Z","shell.execute_reply":"2020-11-06T19:40:10.958346Z"},"papermill":{"duration":0.188303,"end_time":"2020-11-06T19:40:10.959233","exception":false,"start_time":"2020-11-06T19:40:10.77093","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"delete_colum = ['SkinThickness','Insulin']\ndel_col = FunctionTransformer(utils.drop_column,kw_args={'columns':delete_colum})","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.18621,"end_time":"2020-11-06T19:40:11.338945","exception":false,"start_time":"2020-11-06T19:40:11.152735","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Estas columnas borradas ya no las tendremos en cuenta para los siguientes pasos que añadiremos al pipeline. Entonces, lo siguiente que realizamos es la `imputación` de los valores nulos. Estos valores que en nuestra base de datos están a `0`, serán reemplazados por valores con el algortimo de k-NN. Siendo k=5, para tener menos oportunidad de empate y tener valores más razonables para cada instancia de la base de datos al comprobar con 5 vecinos. Dado que para `Pregnancies` los valores a 0 si tienen sentido, tambíen quitaremos esta columna para la imputación."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:11.709497Z","iopub.status.busy":"2020-11-06T19:40:11.708531Z","iopub.status.idle":"2020-11-06T19:40:11.713033Z","shell.execute_reply":"2020-11-06T19:40:11.712219Z"},"papermill":{"duration":0.190333,"end_time":"2020-11-06T19:40:11.713177","exception":false,"start_time":"2020-11-06T19:40:11.522844","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"imputer_col = list(set(list(X)) - set(delete_colum) - set(['Pregnancies']))\nprint(imputer_col)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.190435,"end_time":"2020-11-06T19:40:12.08902","exception":false,"start_time":"2020-11-06T19:40:11.898585","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Estas son las columnas donde se hará la imputación y mediante *make_column_transformer* y el algoritmo imputador de k-NN, lo ejecutamos para las columnas que hemos indicado. Creando una función imputador que pasaremos al pipeline."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:12.454583Z","iopub.status.busy":"2020-11-06T19:40:12.45342Z","iopub.status.idle":"2020-11-06T19:40:12.456331Z","shell.execute_reply":"2020-11-06T19:40:12.456891Z"},"papermill":{"duration":0.188836,"end_time":"2020-11-06T19:40:12.457061","exception":false,"start_time":"2020-11-06T19:40:12.268225","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"imputer = make_column_transformer((KNNImputer(n_neighbors=5, weights=\"uniform\",missing_values=0), imputer_col))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.18643,"end_time":"2020-11-06T19:40:13.200143","exception":false,"start_time":"2020-11-06T19:40:13.013713","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Utilizamos un discretizado en 2 particiones de forma uniforme. Según lo estudiado en el análisis es la mejor forma que tenemos para sacar buenos resultados."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:13.612263Z","iopub.status.busy":"2020-11-06T19:40:13.61147Z","iopub.status.idle":"2020-11-06T19:40:13.614183Z","shell.execute_reply":"2020-11-06T19:40:13.614874Z"},"papermill":{"duration":0.188055,"end_time":"2020-11-06T19:40:13.61505","exception":false,"start_time":"2020-11-06T19:40:13.426995","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.184667,"end_time":"2020-11-06T19:40:12.825271","exception":false,"start_time":"2020-11-06T19:40:12.640604","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 2.4. Algoritmos de clasificación"},{"metadata":{"papermill":{"duration":0.213594,"end_time":"2020-11-06T19:40:14.016411","exception":false,"start_time":"2020-11-06T19:40:13.802817","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Creamos un modelo 0-R para comparar con el resto de modelos."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:14.388096Z","iopub.status.busy":"2020-11-06T19:40:14.38696Z","iopub.status.idle":"2020-11-06T19:40:14.390592Z","shell.execute_reply":"2020-11-06T19:40:14.389916Z"},"papermill":{"duration":0.189604,"end_time":"2020-11-06T19:40:14.3908","exception":false,"start_time":"2020-11-06T19:40:14.201196","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.178199,"end_time":"2020-11-06T19:40:14.748544","exception":false,"start_time":"2020-11-06T19:40:14.570345","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Creamos también un modelo de árbol de decisión que utilizaremos para comparar los resultados con nuestro pipeline creado. Como hemos dicho anteriormete la discretización puede causar que el modelo empeore ya que no hay un valor exacto por donde tendriamos una discretización visible, por tanto no crearemos un modelo de arbol discretizado fuera de nuestro pipeline."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:15.125828Z","iopub.status.busy":"2020-11-06T19:40:15.124947Z","iopub.status.idle":"2020-11-06T19:40:15.128699Z","shell.execute_reply":"2020-11-06T19:40:15.127956Z"},"papermill":{"duration":0.20093,"end_time":"2020-11-06T19:40:15.128847","exception":false,"start_time":"2020-11-06T19:40:14.927917","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.182367,"end_time":"2020-11-06T19:40:15.49547","exception":false,"start_time":"2020-11-06T19:40:15.313103","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Y por último, creamos el pipeline con las funciones vistas y creadas en el preprocesamiento: la función de quitado de columnas, el imputador para los valores nulos mediante k-NN, el discretizador y el modelo de árbol de decisión."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:15.864454Z","iopub.status.busy":"2020-11-06T19:40:15.863119Z","iopub.status.idle":"2020-11-06T19:40:15.866859Z","shell.execute_reply":"2020-11-06T19:40:15.867451Z"},"papermill":{"duration":0.191019,"end_time":"2020-11-06T19:40:15.867651","exception":false,"start_time":"2020-11-06T19:40:15.676632","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"discretize_pip = make_pipeline(del_col,imputer,discretizer,tree_model)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:16.243819Z","iopub.status.busy":"2020-11-06T19:40:16.243021Z","iopub.status.idle":"2020-11-06T19:40:16.246242Z","shell.execute_reply":"2020-11-06T19:40:16.245405Z"},"papermill":{"duration":0.189936,"end_time":"2020-11-06T19:40:16.24638","exception":false,"start_time":"2020-11-06T19:40:16.056444","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"pip = make_pipeline(del_col,imputer,tree_model)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.17759,"end_time":"2020-11-06T19:40:16.605599","exception":false,"start_time":"2020-11-06T19:40:16.428009","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 2.5. Evaluación de modelos"},{"metadata":{"papermill":{"duration":0.180798,"end_time":"2020-11-06T19:40:16.964189","exception":false,"start_time":"2020-11-06T19:40:16.783391","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Una vez creados todos los modelos, mediante la función `evaluate` del script `utils` "},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:17.336535Z","iopub.status.busy":"2020-11-06T19:40:17.335533Z","iopub.status.idle":"2020-11-06T19:40:17.59513Z","shell.execute_reply":"2020-11-06T19:40:17.594322Z"},"papermill":{"duration":0.448008,"end_time":"2020-11-06T19:40:17.59527","exception":false,"start_time":"2020-11-06T19:40:17.147262","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.183289,"end_time":"2020-11-06T19:40:17.958411","exception":false,"start_time":"2020-11-06T19:40:17.775122","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Acertando todos los valores de negativos de la base de datos tenemos la distribución de negativos en esta como valor de precisión."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:18.332514Z","iopub.status.busy":"2020-11-06T19:40:18.331648Z","iopub.status.idle":"2020-11-06T19:40:18.52453Z","shell.execute_reply":"2020-11-06T19:40:18.523693Z"},"papermill":{"duration":0.381412,"end_time":"2020-11-06T19:40:18.524725","exception":false,"start_time":"2020-11-06T19:40:18.143313","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.181717,"end_time":"2020-11-06T19:40:18.889427","exception":false,"start_time":"2020-11-06T19:40:18.70771","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Con un árbol de decisión mejoramos un poco la precisión obtenida, pudiendo esta vez predecir verdaderos positivos."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:19.276765Z","iopub.status.busy":"2020-11-06T19:40:19.275678Z","iopub.status.idle":"2020-11-06T19:40:19.495258Z","shell.execute_reply":"2020-11-06T19:40:19.495855Z"},"papermill":{"duration":0.419638,"end_time":"2020-11-06T19:40:19.496047","exception":false,"start_time":"2020-11-06T19:40:19.076409","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate(pip,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.188873,"end_time":"2020-11-06T19:40:19.867362","exception":false,"start_time":"2020-11-06T19:40:19.678489","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Con la creación del pipeline que imputa valores nulos y elimina columnas que no aportan información, la precisión del modelo mejora, no muy significativamente. En este caso el algortimo utilizado es solamente el árbol de decisión."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:20.252071Z","iopub.status.busy":"2020-11-06T19:40:20.251127Z","iopub.status.idle":"2020-11-06T19:40:20.473207Z","shell.execute_reply":"2020-11-06T19:40:20.472415Z"},"papermill":{"duration":0.42065,"end_time":"2020-11-06T19:40:20.473341","exception":false,"start_time":"2020-11-06T19:40:20.052691","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_pip,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.183965,"end_time":"2020-11-06T19:40:20.842345","exception":false,"start_time":"2020-11-06T19:40:20.65838","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Como observamos, la diferencia de precisión entre el modelo discretizado y sin discretizar es muy pequeña con tan solo un valor de diferencia en la predicción. Por tanto, escogemos como modelo el pipeline discretizado creado para seguir con la evaluación."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:21.265572Z","iopub.status.busy":"2020-11-06T19:40:21.264513Z","iopub.status.idle":"2020-11-06T19:40:21.268067Z","shell.execute_reply":"2020-11-06T19:40:21.267049Z"},"papermill":{"duration":0.214062,"end_time":"2020-11-06T19:40:21.268236","exception":false,"start_time":"2020-11-06T19:40:21.054174","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"FP = 38  # False Positive\nTP = 53  # True Positive\n\nFN = 28  # False Negative\nTN = 112 # True Negative","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.188932,"end_time":"2020-11-06T19:40:21.654962","exception":false,"start_time":"2020-11-06T19:40:21.46603","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Tasa de falsos positivos: $$\\frac{FP}{N} = \\frac{FP}{FP + TN}$$\n\n$$FP \\rightarrow Número\\ de\\ Falsos\\ Positivos$$\n$$N \\rightarrow Número\\ de\\ Negativos = FP + TN$$\n$$TN \\rightarrow Número\\ de\\ Verdaderos\\ Negativos$$"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:22.0544Z","iopub.status.busy":"2020-11-06T19:40:22.053388Z","iopub.status.idle":"2020-11-06T19:40:22.057409Z","shell.execute_reply":"2020-11-06T19:40:22.058107Z"},"papermill":{"duration":0.211614,"end_time":"2020-11-06T19:40:22.058269","exception":false,"start_time":"2020-11-06T19:40:21.846655","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"fp_rate= (FP)/(FP+TN)\nprint(\"Tasa de Falsos Positivos: \",fp_rate)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.189432,"end_time":"2020-11-06T19:40:22.440128","exception":false,"start_time":"2020-11-06T19:40:22.250696","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Tasa de falsos negativos: $$\\frac{FN}{P} = \\frac{FN}{FN + TP}$$\n\n$$FN \\rightarrow Número\\ de\\ Falsos\\ Negativos$$\n$$P \\rightarrow Número\\ de\\ Positivos = FN + TP$$\n$$TP \\rightarrow Número\\ de\\ Verdaderos\\ Positivos$$"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:22.820273Z","iopub.status.busy":"2020-11-06T19:40:22.81926Z","iopub.status.idle":"2020-11-06T19:40:22.823312Z","shell.execute_reply":"2020-11-06T19:40:22.824358Z"},"papermill":{"duration":0.196196,"end_time":"2020-11-06T19:40:22.82458","exception":false,"start_time":"2020-11-06T19:40:22.628384","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"fn_rate = (FN)/(FN+TP)\nprint(\"Tasa de Falsos Negativos: \",fn_rate)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.186403,"end_time":"2020-11-06T19:40:23.197278","exception":false,"start_time":"2020-11-06T19:40:23.010875","status":"completed"},"tags":[]},"cell_type":"markdown","source":"La tasa de falsos negativos es muy considerable, ya que esta al ser un `34.57%` 1 de cada 3 personas aproximadamente, siendo diabeticas, darán un resultado negativo.\n\nPor otro lado, la tasa de falsos positivos es del `25.33%`, entonces 1 de cada 4 personas aproximadamente, darán positivo en diabetes sin ser una persona diabética. \n\nEn este caso no tenemos ninguna decisión firme sobre la validez del modelo, ya que los ratios son altos y no podemos decantarnos por poner un ratio de FP o FN por encima del otro. Ya que, tener un diabético y no medicarlo es muy malo para ese paciente. Por otro lado, que una paciente no sea diabético y ponerle un tratamiento de una persona diabética como puede ser inyectarse insulina, puede acarrearle problemas de salud, aunque sea algo más beneficioso que el anterior."},{"metadata":{"papermill":{"duration":0.186368,"end_time":"2020-11-06T19:40:23.570906","exception":false,"start_time":"2020-11-06T19:40:23.384538","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Al realizar una evaluación del modelo y no tener claro si es un buen modelo o no mediante el estudio de la precisión o de la tasa de FP y FN, vamos a realizar una última evaluación que nos dará mayor claridad al problema dado. Vamos a ver estudiar si mediante el análisis de la `curva ROC` y el valor de `AUC`, que permite decidir a simple vista si un modelo es bueno. Nos permitirá analizar una relación de coste/beneficio "},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:23.950767Z","iopub.status.busy":"2020-11-06T19:40:23.949561Z","iopub.status.idle":"2020-11-06T19:40:24.095385Z","shell.execute_reply":"2020-11-06T19:40:24.094605Z"},"papermill":{"duration":0.343289,"end_time":"2020-11-06T19:40:24.09552","exception":false,"start_time":"2020-11-06T19:40:23.752231","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate_roc(discretize_pip,\n    X_train, y_train,\n    X_test,  y_test )","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.194043,"end_time":"2020-11-06T19:40:24.485457","exception":false,"start_time":"2020-11-06T19:40:24.291414","status":"completed"},"tags":[]},"cell_type":"markdown","source":"La curva ROC que nos produce nuestro modelo esta por encima de la línea diagonal (en la gráfica representada como una línea de puntos). Todo modelo que cumpla que esta condición, será un modelo mejor cuanto la curva más se acerque al punto que formaría con `(x=0,y=1)`,  Por tanto, a primera vista nuestro modelo es bueno al tener un ratio de Verdaderos Positivos más alto que de el ratio de Falsos Positivos. Cuanto más se máximice el valor de AUC (área bajo la curva), nuestro modelo será mejor. En este caso al tener un valor AUC de `0.7156` y visto que nuestra precisión del modelo no es muy alta y ningun modelo de los evaluados se acerca a una estimación mas exacta, este valor será de lo más alto que podemos conseguir. \n\nPor tanto, nuestro modelo entrenado será un buen modelo predictivo para el diagnostico de la diabetes."},{"metadata":{"papermill":{"duration":0.215264,"end_time":"2020-11-06T19:40:24.936098","exception":false,"start_time":"2020-11-06T19:40:24.720834","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# 3. Dataset Wisconsin"},{"metadata":{"papermill":{"duration":0.199534,"end_time":"2020-11-06T19:40:25.33884","exception":false,"start_time":"2020-11-06T19:40:25.139306","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Antes de empezar con el estudio de este dataset, al igual que en el dataset anterior, vamos a establecer una semilla para que los resultados obtenidos sean reproducibles."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:25.75122Z","iopub.status.busy":"2020-11-06T19:40:25.750291Z","iopub.status.idle":"2020-11-06T19:40:25.753817Z","shell.execute_reply":"2020-11-06T19:40:25.753204Z"},"papermill":{"duration":0.208664,"end_time":"2020-11-06T19:40:25.753959","exception":false,"start_time":"2020-11-06T19:40:25.545295","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"seed = 27913","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.20537,"end_time":"2020-11-06T19:40:26.158605","exception":false,"start_time":"2020-11-06T19:40:25.953235","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3.1. Acceso y almacenamiento de datos"},{"metadata":{"papermill":{"duration":0.200288,"end_time":"2020-11-06T19:40:26.558027","exception":false,"start_time":"2020-11-06T19:40:26.357739","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Primero vamos a cargar el conjunto de datos con el que trabajaremos en esta parte de la práctica. Se trata del conjunto de datos `wisconsin`.\n\nLos datos se encuentran almacenados en un fichero `.csv`, en el cada cada fila del fichero representa a una instancia, y en cada fila los datos están separados por coma, representando cada uno de estos datos separados por coma a una variable de nuestro problema.\n\nPara cargar los datos en la libreta utilizaremos la función que se nos ha proporcionado. A esta función hay que indicarle cual es la variable, es decir, cual es la variable que queremos predecir. Para ello accedemos a [wisconsin](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data) donde podemos descargar el conjunto de datos `wisconsin` con el que vamos a trabajar y podemos ver que la variable `diagnosis` (diagnóstico) es la variable clase."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:26.960985Z","iopub.status.busy":"2020-11-06T19:40:26.960114Z","iopub.status.idle":"2020-11-06T19:40:26.974656Z","shell.execute_reply":"2020-11-06T19:40:26.973538Z"},"papermill":{"duration":0.219423,"end_time":"2020-11-06T19:40:26.9749","exception":false,"start_time":"2020-11-06T19:40:26.755477","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"filepath = \"../input/wisconsin/wisconsin.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.201447,"end_time":"2020-11-06T19:40:27.381996","exception":false,"start_time":"2020-11-06T19:40:27.180549","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a mostrar algunas instancias para comprobar que se han cargado los datos correctamente. Mostraremos algunas al azar para evitar obtener una muestra sesgada que no represente al conjunto de datos."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:27.809864Z","iopub.status.busy":"2020-11-06T19:40:27.80898Z","iopub.status.idle":"2020-11-06T19:40:27.813404Z","shell.execute_reply":"2020-11-06T19:40:27.814109Z"},"papermill":{"duration":0.233077,"end_time":"2020-11-06T19:40:27.814287","exception":false,"start_time":"2020-11-06T19:40:27.58121","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.201022,"end_time":"2020-11-06T19:40:28.218105","exception":false,"start_time":"2020-11-06T19:40:28.017083","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Una vez tenemos los datos cargados correctamente vamos a dividir la base de datos en la variable clase `diagnosis` (`y`) y las variables predictoras (`X`)."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:28.620073Z","iopub.status.busy":"2020-11-06T19:40:28.619042Z","iopub.status.idle":"2020-11-06T19:40:28.622445Z","shell.execute_reply":"2020-11-06T19:40:28.621782Z"},"papermill":{"duration":0.207881,"end_time":"2020-11-06T19:40:28.622601","exception":false,"start_time":"2020-11-06T19:40:28.41472","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=target)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.195798,"end_time":"2020-11-06T19:40:29.021215","exception":false,"start_time":"2020-11-06T19:40:28.825417","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a comprobar de la misma forma que antes que se han separado las variables correctamente."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:29.442985Z","iopub.status.busy":"2020-11-06T19:40:29.441658Z","iopub.status.idle":"2020-11-06T19:40:29.44736Z","shell.execute_reply":"2020-11-06T19:40:29.446628Z"},"papermill":{"duration":0.230364,"end_time":"2020-11-06T19:40:29.447486","exception":false,"start_time":"2020-11-06T19:40:29.217122","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:29.849261Z","iopub.status.busy":"2020-11-06T19:40:29.848174Z","iopub.status.idle":"2020-11-06T19:40:29.853288Z","shell.execute_reply":"2020-11-06T19:40:29.852653Z"},"papermill":{"duration":0.211293,"end_time":"2020-11-06T19:40:29.853415","exception":false,"start_time":"2020-11-06T19:40:29.642122","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.198689,"end_time":"2020-11-06T19:40:30.252178","exception":false,"start_time":"2020-11-06T19:40:30.053489","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Ahora vamos a dividir los datos en datos de entrenamiento y datos de prueba para evitar usar un conjunto de los datos (el conjunto de test) en el entrenamiento de los modelos. Tampoco lo usaremos en ninguna de las etapas anteriores al entrenamiento. Esto lo realizamos para evitar un sobreajuste a los datos que tenemos, así el modelo aprenderá de los datos de entrenamiento, pero al no conocer los datos de prueba no puede ajustarse a ellos y generalizará mejor con datos nuevos, y estos los podremos usar para evaluar el modelo.\n\nEstos datos de prueba serán usados exclusivamente para evaluar los modelos obtenidos."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:30.651944Z","iopub.status.busy":"2020-11-06T19:40:30.649374Z","iopub.status.idle":"2020-11-06T19:40:30.655486Z","shell.execute_reply":"2020-11-06T19:40:30.654715Z"},"papermill":{"duration":0.208995,"end_time":"2020-11-06T19:40:30.655635","exception":false,"start_time":"2020-11-06T19:40:30.44664","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_size = 0.7 # 70 % entrenamiento y 30 % de los datos test\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.208082,"end_time":"2020-11-06T19:40:31.060553","exception":false,"start_time":"2020-11-06T19:40:30.852471","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Con esto ya tenemos los datos almacenados correctamente y podemos empezar con la siguiente fase del proceso."},{"metadata":{"papermill":{"duration":0.193426,"end_time":"2020-11-06T19:40:31.450989","exception":false,"start_time":"2020-11-06T19:40:31.257563","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3.2. Análisis exploratorio"},{"metadata":{"papermill":{"duration":0.192501,"end_time":"2020-11-06T19:40:31.838407","exception":false,"start_time":"2020-11-06T19:40:31.645906","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Ahora vamos a realizar un análisis exploratorio para observar como se comporta el conjunto de datos que tenemos, observando sus variables y la relación que tengan entre ellas y con la variable clase. Para ello analizaremos nuestro problema con el objetivo de obtener información relevante que nos sirva de utilidad para realizar un buen preprocesamiento de datos.\n\nIndicar que este análisis exploratorio se realizará solo sobre los datos de entrenamiento, para no ajustarnos a los datos de prueba (evitarndo una ***fuga de datos***).\n\nPrimero vamos a empezar viendo el número de casos y de variables que tenemos en nuestros datos de entrenamiento."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:32.283199Z","iopub.status.busy":"2020-11-06T19:40:32.282189Z","iopub.status.idle":"2020-11-06T19:40:32.286212Z","shell.execute_reply":"2020-11-06T19:40:32.2869Z"},"papermill":{"duration":0.205702,"end_time":"2020-11-06T19:40:32.28707","exception":false,"start_time":"2020-11-06T19:40:32.081368","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.196443,"end_time":"2020-11-06T19:40:32.678561","exception":false,"start_time":"2020-11-06T19:40:32.482118","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos ver que tenemos 398 casos, y 32 variables en nuestros datos de entrenamiento, teniendo la variable clase y 31 variables predictoras.\n\nAhora vamos a ver de forma general como son las variables predictoras, es decir, si son variables discretas o continuas."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:33.081649Z","iopub.status.busy":"2020-11-06T19:40:33.080693Z","iopub.status.idle":"2020-11-06T19:40:33.084495Z","shell.execute_reply":"2020-11-06T19:40:33.085147Z"},"papermill":{"duration":0.213801,"end_time":"2020-11-06T19:40:33.085316","exception":false,"start_time":"2020-11-06T19:40:32.871515","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.194425,"end_time":"2020-11-06T19:40:33.478946","exception":false,"start_time":"2020-11-06T19:40:33.284521","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos ver que todas las variables predictoras son numéricas (`float64`), esto quiere decir que son variables continuas ya que se representan mediante valores numéricos. También podemos ver que ninguna de las variables predictoras, excepto la última, tiene algún valor null, por lo que todos sus valores son conocidos.\n\nLa última variable predictora, llamada `Unnamed: 32`, se trata de una variable corrupta que tiene todos los valores ***perdidos***, es decir, todos sus valores valen `null`. Esto se debe a la última coma que aparece en la cabecera del fichero `csv` del que hemos cargado los datos. Esa coma provoca que se espere una variable después de la coma, pero como no hay ninguna la renombra a unnamed, y como no se le asigna ningún valor a esa variable, todos sus valores son perdidos (`null`).\n\nDado que esto es un error del fichero del que hemos obtenido los datos, y esta variable no aporta nada, la vamos a eliminar de los datos de prueba y de entrenamiento antes de seguir con el análisis exploratorio."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:33.8862Z","iopub.status.busy":"2020-11-06T19:40:33.879333Z","iopub.status.idle":"2020-11-06T19:40:33.89046Z","shell.execute_reply":"2020-11-06T19:40:33.889603Z"},"papermill":{"duration":0.215242,"end_time":"2020-11-06T19:40:33.890597","exception":false,"start_time":"2020-11-06T19:40:33.675355","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(\"Unnamed: 32\", axis=1)\nX_test = X_test.drop(\"Unnamed: 32\", axis=1)\n\nX_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.198593,"end_time":"2020-11-06T19:40:34.290436","exception":false,"start_time":"2020-11-06T19:40:34.091843","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Ahora que hemos eliminado esta variable corrupta podemos ver que tenemos 30 variables predictoras. Estas variables predictoras aportan información acerca de las células, midiendo su:\n* radius (radio)\n* texture (textura)\n* perimeter (perímetro)\n* area (área)\n* smoothness (suavidad)\n* compactness (compacidad)\n* concavity (concavidad)\n* concave points (puntos cóncavos)\n* symmetry (simetría)\n* fractal dimmension (dimensión fractal)\n\n\nAhora vamos a ver la información de la variable clase."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:34.692944Z","iopub.status.busy":"2020-11-06T19:40:34.69177Z","iopub.status.idle":"2020-11-06T19:40:34.696687Z","shell.execute_reply":"2020-11-06T19:40:34.695956Z"},"papermill":{"duration":0.211209,"end_time":"2020-11-06T19:40:34.696814","exception":false,"start_time":"2020-11-06T19:40:34.485605","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.200629,"end_time":"2020-11-06T19:40:35.095384","exception":false,"start_time":"2020-11-06T19:40:34.894755","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos ver que la variable clase es discreta, estando formada por dos estados distintos que son ***B*** y ***M***. A grandes rasgos hemos podido ver que tenemos 30 variables predictoras para predecir si la variable objetivo (`diagnosis`) es B `benigno` o M `maligno`."},{"metadata":{"papermill":{"duration":0.195996,"end_time":"2020-11-06T19:40:35.4948","exception":false,"start_time":"2020-11-06T19:40:35.298804","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Análisis univariado"},{"metadata":{"papermill":{"duration":0.220562,"end_time":"2020-11-06T19:40:35.919086","exception":false,"start_time":"2020-11-06T19:40:35.698524","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a empezar viendo como de repartidas están las categorías de la variable clase realizando un análisis univariado.\n\nPara ello primero vamos a generar una variable `data_train` que contenga solo los datos de entrenamiento, uniendo las variables predictoras y la objetivo para evitar obtener información en las gráficas de los datos de prueba."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:36.333108Z","iopub.status.busy":"2020-11-06T19:40:36.331084Z","iopub.status.idle":"2020-11-06T19:40:36.336816Z","shell.execute_reply":"2020-11-06T19:40:36.336167Z"},"papermill":{"duration":0.210376,"end_time":"2020-11-06T19:40:36.33695","exception":false,"start_time":"2020-11-06T19:40:36.126574","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.205204,"end_time":"2020-11-06T19:40:36.743775","exception":false,"start_time":"2020-11-06T19:40:36.538571","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Para empezar con el análisis univariado vamos a generar un gráfico para ver como de repartidas están las variables categóricas que tenemos, que en este caso la única variable categórica que tenemos es la variable clase."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:37.179643Z","iopub.status.busy":"2020-11-06T19:40:37.178852Z","iopub.status.idle":"2020-11-06T19:40:37.247657Z","shell.execute_reply":"2020-11-06T19:40:37.248311Z"},"papermill":{"duration":0.304977,"end_time":"2020-11-06T19:40:37.248484","exception":false,"start_time":"2020-11-06T19:40:36.943507","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.206002,"end_time":"2020-11-06T19:40:37.660395","exception":false,"start_time":"2020-11-06T19:40:37.454393","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos ver que la etiqueta B es casi el doble de frecuente que la etiqueta M, por lo que tenemos una muestra desbalanceada, ya que no hay la misma proporción de las dos etiquetas.\n\nSi multiplicamos el tanto por ciento que nos muestra la gráfica por la cantidad total de casos de prueba que tenemos (398), obtenemos la cantidad exacta de casos de cada etiqueta.\n\n$$B = 0.6281407 * 398 = 250$$\n\n$$M = 0.3718593 * 398 = 148$$\n\nPodemos comprobar si esto es cierto utilizando el método `describe`."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:38.139223Z","iopub.status.busy":"2020-11-06T19:40:38.138178Z","iopub.status.idle":"2020-11-06T19:40:38.144715Z","shell.execute_reply":"2020-11-06T19:40:38.143706Z"},"papermill":{"duration":0.261908,"end_time":"2020-11-06T19:40:38.144901","exception":false,"start_time":"2020-11-06T19:40:37.882993","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.204985,"end_time":"2020-11-06T19:40:38.562091","exception":false,"start_time":"2020-11-06T19:40:38.357106","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Acabamos de comprobar que la información obtenida a partir de los porcentajes de la gráfica es la correcta, teniendo efectivamente 250 casos de la categoría B, y el resto ($398-250 = 148$) de la categoría M.\n\nPara seguir con este análisis univariado vamos a generar unos histogramas e intentar sacar la máxima información posible de las variables predictoras (recordemos que todas las variables predictoras de nuestro problema son numéricas)."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:38.987483Z","iopub.status.busy":"2020-11-06T19:40:38.985922Z","iopub.status.idle":"2020-11-06T19:40:38.989418Z","shell.execute_reply":"2020-11-06T19:40:38.990517Z"},"papermill":{"duration":0.223853,"end_time":"2020-11-06T19:40:38.990929","exception":false,"start_time":"2020-11-06T19:40:38.767076","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#utils.plot_distribution(data_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.209199,"end_time":"2020-11-06T19:40:39.411785","exception":false,"start_time":"2020-11-06T19:40:39.202586","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Con estos gráficos se puede ver de una forma sencilla las distribuciones que siguen todas las variables numéricas que tenemos.\n\nSi vamos observando todas las variables podemos ver que muchas siguen una distribución normal, en la que la mayoría de los casos están muy cerca de la media, y según nos alejamos de la media se va reduciendo la cantidad de casos por cada valor.\n\nAunque la otra mitad de las variables, como `area_mean` o `concavity_mean`, siguen una distribución asimétrica positiva, es decir, que la mayoría de los casos se encuentran a la izquierda de la media, y según avanzamos a la derecha hay muchos menos casos. Podemos ver que no hay ninguna variable que siga una distribución asimétrica negativa (la mayoría de los casos se centran a la derecha de la media), siguiendo todas las variables una ***distribución normal*** o ***asimétrica positiva***. \n\nDestacar que ninguna variable sigue una ***distribución uniforme*** por lo que no podemos intuir que alguna variable en concreto sea inútil para la clasificación, por lo que de momento no podemos pensar en eliminar ninguna variable en el preprocesamiento, pues a priori, por su distribución vemos que todas pueden aportar algo de información."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:39.834446Z","iopub.status.busy":"2020-11-06T19:40:39.833365Z","iopub.status.idle":"2020-11-06T19:40:40.305409Z","shell.execute_reply":"2020-11-06T19:40:40.306078Z"},"papermill":{"duration":0.687255,"end_time":"2020-11-06T19:40:40.306241","exception":false,"start_time":"2020-11-06T19:40:39.618986","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.26849,"end_time":"2020-11-06T19:40:40.839432","exception":false,"start_time":"2020-11-06T19:40:40.570942","status":"completed"},"tags":[]},"cell_type":"markdown","source":"A partir de este histograma se pueden sacar muchas conclusiones individuales sobre cada variable. Se pueden ver los tipos de distribuciones que sigue cada variable, aunque esto ya lo hemos visto de forma más sencilla en el gráfico anterior.\n\nCon este histograma que es de mayor tamaño lo usaremos para detectar ***outlier***.\n\nPara la variable `area_se` tenemos que casi todos sus valores están entre el 0 y el 180, teniendo algún caso suelto por el 200, y dos casos con un valor de 500. Como podemos ver estos casos están totalmente alejados del resto, por lo que son datos anómalos.\n\nPara la variable `fractal_dimension_worst` podemos observar lo mismo. Sigue una distribución normal, donde sus valores van entre el 0.00 y el 0.15, alcanzando la cima de la normal en el 0.08, y tiene un valor superior al 0.2, siendo éste un dato anómalo, estando muy alejado del resto de valores que se encuentran por debajo del 0.15.\n\nAunque es una forma correcta de obtener información de cada variable, puede llegar a ser costoso ya que al haber tantas variables predictoras hay que mirar muchos histogramas. Otra forma de obtener este tipo de información es observando valores estadísticos de cada variable, como la media, desviación típica, el máximo..."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:41.403742Z","iopub.status.busy":"2020-11-06T19:40:41.401374Z","iopub.status.idle":"2020-11-06T19:40:41.499095Z","shell.execute_reply":"2020-11-06T19:40:41.498398Z"},"papermill":{"duration":0.37976,"end_time":"2020-11-06T19:40:41.499226","exception":false,"start_time":"2020-11-06T19:40:41.119466","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.267899,"end_time":"2020-11-06T19:40:42.034755","exception":false,"start_time":"2020-11-06T19:40:41.766856","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos ver que a partir de los 8 valores que se nos proporciona para cada variable numérica podemos obtener gran parte de información. Aunque al tener 30 variables no nos muestran todas las columnas de la tabla (cada columna representa a una variable), por lo que para que sea más visual vamos a dividir esta tabla en 3 (teniendo 10 columnas por tabla)."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:42.652429Z","iopub.status.busy":"2020-11-06T19:40:42.649115Z","iopub.status.idle":"2020-11-06T19:40:42.691664Z","shell.execute_reply":"2020-11-06T19:40:42.69097Z"},"papermill":{"duration":0.388814,"end_time":"2020-11-06T19:40:42.691808","exception":false,"start_time":"2020-11-06T19:40:42.302994","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train.iloc[:,0:10].describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.272781,"end_time":"2020-11-06T19:40:43.23829","exception":false,"start_time":"2020-11-06T19:40:42.965509","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Ahora es mucho más fácil obtener información porque de un vistazo estamos viendo las características individuales de 10 variables predictoras.\n\nPor ejemplo para `area_mean` podemos ver que tiene una desviación típica muy elevada (360), por lo que podemos deducir que sus valores están alejados de la media. Si esto lo comprobamos con el histograma correspondiente vemos que hay muchos valores muy superiores a la media. Y si además nos fijamos en que el valor máximo es 2501, y lo comparamos con el tercer cuartil, que su valor es 802, nos damos cuenta de que hemos detectado un outlier (y si lo comprobamos con el histograma podemos detectar que hay más de un outlier).\n\nCon la variable `texture_mean` podemos detectar de la misma forma la presencia de un outlier, ya que el máximo valor es 39 y por la desviación típica (que tiene un valor muy bajo) podemos ver que los valores están cerca de la media, y la media vale 19, por lo que deducimos que 39 es muy distinto del resto de valores."},{"metadata":{"papermill":{"duration":0.269887,"end_time":"2020-11-06T19:40:43.776129","exception":false,"start_time":"2020-11-06T19:40:43.506242","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En resumen, mirando los estadísticos y los histogramas de estas 10 variables podemos ver que las variables que presentan algún outlier son:\n* `texture_mean` tiene uno.\n* `area_mean` tiene dos.\n* `smoothness_mean` tiene uno."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:44.326747Z","iopub.status.busy":"2020-11-06T19:40:44.324768Z","iopub.status.idle":"2020-11-06T19:40:44.364743Z","shell.execute_reply":"2020-11-06T19:40:44.36393Z"},"papermill":{"duration":0.319825,"end_time":"2020-11-06T19:40:44.364878","exception":false,"start_time":"2020-11-06T19:40:44.045053","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train.iloc[:,10:20].describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.271744,"end_time":"2020-11-06T19:40:44.906863","exception":false,"start_time":"2020-11-06T19:40:44.635119","status":"completed"},"tags":[]},"cell_type":"markdown","source":"De la misma forma podemos detectar outliers, por ejemplo para `compactness_se` el caso máximo vale 0.1354 y la media y el tercer cuartil valen 0.0257 y 0.0324, por lo que tenemos un outlier. \n\nEn el atributo `concavity_se` hay un claro outlier ya que la diferencia entre el tercer cuartil y el máximo es mucho mayor que en el otro caso. Teniendo un máximo de 0.396 y un tercer cuartil de 0.04255."},{"metadata":{"papermill":{"duration":0.266494,"end_time":"2020-11-06T19:40:45.448791","exception":false,"start_time":"2020-11-06T19:40:45.182297","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En resumen, mirando los estadísticos y los histogramas de estas 10 variables podemos ver las variables que presentan algún outlier, que en este caso son muchas más que antes:\n* `radius_se` tiene dos.\n* `texture_se` tiene uno.\n* `perimeter_se` tiene dos.\n* `area_se` tiene dos.\n* `smoothness_se` tiene uno.\n* `compactness_se` tiene uno.\n* `concavity_se` tiene dos.\n* `concave points_se` tiene uno.\n* `simmetry_se` tiene uno.\n* `fractal_dimension_se` tiene cuatro."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:46.016928Z","iopub.status.busy":"2020-11-06T19:40:46.015446Z","iopub.status.idle":"2020-11-06T19:40:46.059396Z","shell.execute_reply":"2020-11-06T19:40:46.058631Z"},"papermill":{"duration":0.340712,"end_time":"2020-11-06T19:40:46.059532","exception":false,"start_time":"2020-11-06T19:40:45.71882","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_train.iloc[:,20:30].describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.26557,"end_time":"2020-11-06T19:40:46.594352","exception":false,"start_time":"2020-11-06T19:40:46.328782","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Hemos comprado que efectivamente a partir de estos valores podemos observar lo mismo que con los histogramas anteriores. Por ejemplo, antes observamos que la variable `fractal_dimension_worst` tenía un outlier. Pues ahora con estos valores al observar que la media es 0.083971 y el tercer cuartil es 0.91865 (que son valores muy parecidos), y el máximo es 0.2075 que es muy superior al tercer cuartil, podemos ver que este valor se trata de un outlier (lo mismo que con el histograma)."},{"metadata":{"papermill":{"duration":0.310515,"end_time":"2020-11-06T19:40:47.175021","exception":false,"start_time":"2020-11-06T19:40:46.864506","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En resumen, mirando los estadísticos y los histogramas de estas 10 variables podemos ver que las variables que presentan algún outlier son:\n* `area_worst` tiene uno.\n* `concavity_worst` tiene dos.\n* `simmetry_worst` tiene uno.\n* `fractal_dimension_worst` tiene dos."},{"metadata":{"papermill":{"duration":0.26833,"end_time":"2020-11-06T19:40:47.709072","exception":false,"start_time":"2020-11-06T19:40:47.440742","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Análisis multivariado"},{"metadata":{"papermill":{"duration":0.319639,"end_time":"2020-11-06T19:40:48.293574","exception":false,"start_time":"2020-11-06T19:40:47.973935","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Después de realizar el análisis univariado donde hemos detectado varios outlier, y hemos comprobado que ninguna variable sigue una distribución uniforme, vamos a realizar un análisis multivariado que nos puede ayudar a ver las relaciones que hay entre varias variables.\n\nEn concreto vamos a mostrar unos gráficos que muestran la relación entre pares de variables. Tenemos el problema de que al tener 30 variables predictoras nos van a salir cientos de gráficas, siendo imposible para nosotros obtener información de ahí.\n\nLa alternativa que vamos a realizar es dividir a las variables predictoras en grupos, e intentar buscar alguna relación entre las variables de dentro de un mismo grupo. En este caso podemos extraer 3 grupos de variables, ya que se pueden dividir en variables que miden `mean`, `standard_error` and `worst`, igual que hicimos en el análisis univariado."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:48.859414Z","iopub.status.busy":"2020-11-06T19:40:48.858637Z","iopub.status.idle":"2020-11-06T19:40:48.96617Z","shell.execute_reply":"2020-11-06T19:40:48.966824Z"},"papermill":{"duration":0.40556,"end_time":"2020-11-06T19:40:48.967002","exception":false,"start_time":"2020-11-06T19:40:48.561442","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(utils.join_dataset(data_train.iloc[:,0:10], y_train), target=target)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.296303,"end_time":"2020-11-06T19:40:49.573592","exception":false,"start_time":"2020-11-06T19:40:49.277289","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En este gráfico algo que se puede ver es que hay variables como `symmetry_mean`, `fractal_dimension_mean` o `smoothness_mean` que parece que son independientes de la variable clase, es decir, el valor de esas variables por lo que se ve en el gráfico no influyen en el valor de la clase. Este es un dato importante porque estas variables que parece que no aportan información se pueden eliminar de los datos y no tenerlas en cuenta para en el entrenamiento.\n\nEsto se haría en el preprocesamiento, aunque en este caso como estamos trabajando con árboles de decisión que son muy buenos clasificadores, esto no influiría mucho en el rendimiento obtenido por el clasificador porque nunca seleccionaría estas variables para clasificar.\n\nAun así las vamos a eliminar para reducir el coste computacional, ya que tenemos demasiadas variables en este problema en concreto."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:50.173936Z","iopub.status.busy":"2020-11-06T19:40:50.172747Z","iopub.status.idle":"2020-11-06T19:40:50.176694Z","shell.execute_reply":"2020-11-06T19:40:50.175908Z"},"papermill":{"duration":0.305381,"end_time":"2020-11-06T19:40:50.176844","exception":false,"start_time":"2020-11-06T19:40:49.871463","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Almacenamos los nombre de las variables mean que vamos a eliminar\ncolumn_rm_mean = [\"smoothness_mean\", \"symmetry_mean\", \"fractal_dimension_mean\"]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:50.790883Z","iopub.status.busy":"2020-11-06T19:40:50.789199Z","iopub.status.idle":"2020-11-06T19:40:50.899935Z","shell.execute_reply":"2020-11-06T19:40:50.900548Z"},"papermill":{"duration":0.431329,"end_time":"2020-11-06T19:40:50.900731","exception":false,"start_time":"2020-11-06T19:40:50.469402","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(utils.join_dataset(data_train.iloc[:,10:20], y_train), target=target)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.320437,"end_time":"2020-11-06T19:40:51.546253","exception":false,"start_time":"2020-11-06T19:40:51.225816","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En esta ocasión podemos ver otras variables que no influyen en la variable clase, estas son: `texture_se`, `smoothness_se`, `symmetry_se` y `fractal_dimension_se`."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:52.201333Z","iopub.status.busy":"2020-11-06T19:40:52.200269Z","iopub.status.idle":"2020-11-06T19:40:52.204048Z","shell.execute_reply":"2020-11-06T19:40:52.203298Z"},"papermill":{"duration":0.332385,"end_time":"2020-11-06T19:40:52.204185","exception":false,"start_time":"2020-11-06T19:40:51.8718","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Almacenamos los nombre de las variables se que vamos a eliminar\ncolumn_rm_se = [\"texture_se\", \"smoothness_se\", \"symmetry_se\", \"fractal_dimension_se\"]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:52.909505Z","iopub.status.busy":"2020-11-06T19:40:52.893468Z","iopub.status.idle":"2020-11-06T19:40:53.013744Z","shell.execute_reply":"2020-11-06T19:40:53.014806Z"},"papermill":{"duration":0.490607,"end_time":"2020-11-06T19:40:53.015054","exception":false,"start_time":"2020-11-06T19:40:52.524447","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(utils.join_dataset(data_train.iloc[:,20:30], y_train), target=target)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.398306,"end_time":"2020-11-06T19:40:53.774464","exception":false,"start_time":"2020-11-06T19:40:53.376158","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vemos que las variables `symetry_worst` y `fractal_dimension_worst` no influyen en la variable clase."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:54.481589Z","iopub.status.busy":"2020-11-06T19:40:54.480495Z","iopub.status.idle":"2020-11-06T19:40:54.484088Z","shell.execute_reply":"2020-11-06T19:40:54.483438Z"},"papermill":{"duration":0.352364,"end_time":"2020-11-06T19:40:54.484216","exception":false,"start_time":"2020-11-06T19:40:54.131852","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Almacenamos los nombre de las variables worst que vamos a eliminar\ncolumn_rm_worst = [\"symmetry_worst\", \"fractal_dimension_worst\"]","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.354138,"end_time":"2020-11-06T19:40:55.1831","exception":false,"start_time":"2020-11-06T19:40:54.828962","status":"completed"},"tags":[]},"cell_type":"markdown","source":"A lo largo de este análisis multivariado podemos ver también que algunas variables podrían funcionar mejor si se discretizaran en dos intervalos, por ejemplo para `perimeter_worst` podemos ver que si dividimos por el valor 100 (más o menos) la mayoría de los valores menores pertenecen al valor de la clase `B` y los superiores a la `M`.\n\nEn otras variables como las tres áreas (`area_mean`, `area_se` y `area_worst`) ocurre lo mismo se puede dividir en dos intervalos.\n\nAsí que otra conclusión que hemos sacado de este análisis multivariado es que en el preprocesamiento se podría realizar un discretizado de las variables en dos intervalos. Se ve claro que se puede aprender un mejor modelo si discretizamos las variables, pero no vemos tan claro el tipo de discretizado (si sería mejor discretizar por anchura o por frecuencia).\n\nPara ver que tipo de discretizado podría funcionar mejor podríamos realizar una validación de modelos, pero como no es el objetivo de esta práctica, vamos a elegir discretizar por igual anchura, que parece que puede funcionar bien.\n\nYa que si elegimos discretizar por igual frecuencia, al tener una muestra desbalanceada, en el mejor de los casos tendríamos un intervalo con todos sus casos con el valor de la clase `B` y en el otro intervalo habría casos con valor `B` y `M`, dado que hay muchas mas instancias cuyo valor de la clase es `B`, que `M`."},{"metadata":{"papermill":{"duration":0.349233,"end_time":"2020-11-06T19:40:55.881562","exception":false,"start_time":"2020-11-06T19:40:55.532329","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3.3. Preprocesamiento de datos"},{"metadata":{"papermill":{"duration":0.349001,"end_time":"2020-11-06T19:40:56.593439","exception":false,"start_time":"2020-11-06T19:40:56.244438","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Después de terminar el análisis exploratorio de datos, vamos a intentar preparar los datos a partir de las conclusiones que hemos obtenido para obtener modelo mejor entrenado.\n\nPrimero observamos que no tenemos valores perdidos ya que eliminamos la variable corrupta que se había generado por culpa del fichero, y el resto de valores predictoras no tenían ningún valor perdido."},{"metadata":{"papermill":{"duration":0.362159,"end_time":"2020-11-06T19:40:57.310202","exception":false,"start_time":"2020-11-06T19:40:56.948043","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a utilizar el concepto de pipeline para hacer las transformaciones que realicemos en el preprocesamiento. Como tendríamos que aplicar las transformaciones en los datos dos veces (una para los datos de entrenamiento, y otra para los de prueba), crearemos un pipeline indicando las transformaciones que queremos hacerle a los datos, y este pipeline se encargará de hacerlas."},{"metadata":{"papermill":{"duration":0.381554,"end_time":"2020-11-06T19:40:58.047316","exception":false,"start_time":"2020-11-06T19:40:57.665762","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Eliminación variables"},{"metadata":{"papermill":{"duration":0.35443,"end_time":"2020-11-06T19:40:58.752139","exception":false,"start_time":"2020-11-06T19:40:58.397709","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Como vimos en el análisis multivariado hay algunas variables que parece que son independientes de la variable clase. Vamos para ello a eliminarlas de los datos, porque aunque los árboles sean muy buenos clasificadores y no se obtengan demasiadas mejores, si que van a reducir el coste computacional ya que 30 variables predictoras como tenemos son muchas.\n\nPrimero vamos a visualizar las variables que dijimos que íbamos a quitar."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:40:59.512556Z","iopub.status.busy":"2020-11-06T19:40:59.511515Z","iopub.status.idle":"2020-11-06T19:40:59.515967Z","shell.execute_reply":"2020-11-06T19:40:59.516504Z"},"papermill":{"duration":0.35945,"end_time":"2020-11-06T19:40:59.516688","exception":false,"start_time":"2020-11-06T19:40:59.157238","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"column_rm = column_rm_mean + column_rm_se + column_rm_worst\ncolumn_rm","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.349206,"end_time":"2020-11-06T19:41:00.213609","exception":false,"start_time":"2020-11-06T19:40:59.864403","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Ahora utilizaremos una función que se encargará de eliminar estas variables predictores, para aplicar esta función en el pipeline.\n\nPara realizar esto utilizaremos `FunctionTransformer` de `Scikit-learn` que nos permite pasarle como parámetro una función, y aplicar esta función en el pipeline a los datos. También le indicaremos que la función recibirá como parámetro a una lista con los nombres de las variables a eliminar."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:00.922577Z","iopub.status.busy":"2020-11-06T19:41:00.921747Z","iopub.status.idle":"2020-11-06T19:41:00.927549Z","shell.execute_reply":"2020-11-06T19:41:00.928238Z"},"papermill":{"duration":0.370314,"end_time":"2020-11-06T19:41:00.928436","exception":false,"start_time":"2020-11-06T19:41:00.558122","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"drop_col = FunctionTransformer(utils.drop_column, kw_args={'columns':column_rm})","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.346288,"end_time":"2020-11-06T19:41:01.643927","exception":false,"start_time":"2020-11-06T19:41:01.297639","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Eliminación de outlier"},{"metadata":{"papermill":{"duration":0.351853,"end_time":"2020-11-06T19:41:02.345199","exception":false,"start_time":"2020-11-06T19:41:01.993346","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En el análisis univariado detectamos la presencia de algunos outlier, que como no detectamos muchos, el tratamiento de los outlier que vamos a hacer es eliminarlos. Para ello eliminaremos la instancia entera en la que haya algún outlier.\n\nPara ello utilizaremos `FunctionSampler` de `imblearn` al que le pasaremos como parámetro una función que hemos definido llamada `outlier_rejection`. Indicar que `imblearn` es compatible con `Scikit` por lo que se puede crear un pipeline con este módulo y los de `Scikit`."},{"metadata":{"papermill":{"duration":0.350918,"end_time":"2020-11-06T19:41:03.042817","exception":false,"start_time":"2020-11-06T19:41:02.691899","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Esta función la hemos incluido en el archivo utils y se encarga de eliminar los outlier que detecte en los datos que le pasemos como parámetro (recibirá la X y la y). Para que el resultado pueda ser reproducible, le pasamos como parámetro una semilla."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:03.757576Z","iopub.status.busy":"2020-11-06T19:41:03.756501Z","iopub.status.idle":"2020-11-06T19:41:03.7595Z","shell.execute_reply":"2020-11-06T19:41:03.75876Z"},"papermill":{"duration":0.359237,"end_time":"2020-11-06T19:41:03.75966","exception":false,"start_time":"2020-11-06T19:41:03.400423","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"outlier_rm = FunctionSampler(func=utils.outlier_rejection, kw_args={'seed':seed})","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.352491,"end_time":"2020-11-06T19:41:04.465513","exception":false,"start_time":"2020-11-06T19:41:04.113022","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Discretización"},{"metadata":{"papermill":{"duration":0.395571,"end_time":"2020-11-06T19:41:05.210692","exception":false,"start_time":"2020-11-06T19:41:04.815121","status":"completed"},"tags":[]},"cell_type":"markdown","source":"En el análisis multivariado vimos que el clasificador podría funcionar mejor si discretizamos las variables en dos intervalos. Vimos que el tipo de discretizado que podiamos aplicarle sería igual anchura, ya que al tener una muestra desbalanceado que tiene dos categorías, funcionaría mal el discretizado por igual frecuencia.\n\nUtilizando el módulo de `Scikit` `KBinsDiscretizer` definiremos la transformación a aplicar en el pipeline, indicandole mediante hiperparámetros que discretice en dos intervalos por igual frecuencia."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:05.915637Z","iopub.status.busy":"2020-11-06T19:41:05.914486Z","iopub.status.idle":"2020-11-06T19:41:05.918026Z","shell.execute_reply":"2020-11-06T19:41:05.917246Z"},"papermill":{"duration":0.357849,"end_time":"2020-11-06T19:41:05.918164","exception":false,"start_time":"2020-11-06T19:41:05.560315","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.352681,"end_time":"2020-11-06T19:41:06.655973","exception":false,"start_time":"2020-11-06T19:41:06.303292","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3.4. Algoritmos de clasificación"},{"metadata":{"papermill":{"duration":0.345965,"end_time":"2020-11-06T19:41:07.352981","exception":false,"start_time":"2020-11-06T19:41:07.007016","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Igual que con el otro dataset de `diabetes` de la parte anterior, en esta parte de la práctica vamos a trabajar exclusivamente con los algoritmos de clasificación ***Zero-R***, que es el clasificador más básico, prediciendo todos los valores igual (como el valor más abundante de la clase). Este clasificador lo utilizaremos para compararlo con el otro clasificador que vamos a usar, que es ***algoritmo CART***, y observar las mejoras en los resultados que obtendremos con los clasificadores generados."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:08.059391Z","iopub.status.busy":"2020-11-06T19:41:08.058281Z","iopub.status.idle":"2020-11-06T19:41:08.061474Z","shell.execute_reply":"2020-11-06T19:41:08.060759Z"},"papermill":{"duration":0.361827,"end_time":"2020-11-06T19:41:08.061601","exception":false,"start_time":"2020-11-06T19:41:07.699774","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:08.760489Z","iopub.status.busy":"2020-11-06T19:41:08.759486Z","iopub.status.idle":"2020-11-06T19:41:08.76365Z","shell.execute_reply":"2020-11-06T19:41:08.762478Z"},"papermill":{"duration":0.354984,"end_time":"2020-11-06T19:41:08.763854","exception":false,"start_time":"2020-11-06T19:41:08.40887","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.349839,"end_time":"2020-11-06T19:41:09.487483","exception":false,"start_time":"2020-11-06T19:41:09.137644","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Una vez que hemos definido los clasificadores que vamos a usar, podemos definir el pipeline que se encargará de aplicar las tres transformaciones que hemos definido previamente sobre el conjunto de datos.\n\nPara ello usamos la función `make_pipeline` y le pasamos como parámetros los transformadores."},{"metadata":{"papermill":{"duration":0.35239,"end_time":"2020-11-06T19:41:10.190334","exception":false,"start_time":"2020-11-06T19:41:09.837944","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Vamos a entrenar dos modelos, uno sin discretizar y otro con discretizado. Para ello crearemos dos pipeline, uno que aplica todo el preprocesado que hemos indicado antes, pero sin aplicar el discretizado, y otro que si que aplica el discretizado."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:10.886475Z","iopub.status.busy":"2020-11-06T19:41:10.885349Z","iopub.status.idle":"2020-11-06T19:41:10.888912Z","shell.execute_reply":"2020-11-06T19:41:10.888123Z"},"papermill":{"duration":0.355803,"end_time":"2020-11-06T19:41:10.889087","exception":false,"start_time":"2020-11-06T19:41:10.533284","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"prep_tree_model = make_pipeline(drop_col, outlier_rm, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:11.646381Z","iopub.status.busy":"2020-11-06T19:41:11.645082Z","iopub.status.idle":"2020-11-06T19:41:11.649224Z","shell.execute_reply":"2020-11-06T19:41:11.648543Z"},"papermill":{"duration":0.407317,"end_time":"2020-11-06T19:41:11.649361","exception":false,"start_time":"2020-11-06T19:41:11.242044","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"prep_tree_model_discretizer = make_pipeline(drop_col, outlier_rm, discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.349168,"end_time":"2020-11-06T19:41:12.352105","exception":false,"start_time":"2020-11-06T19:41:12.002937","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3.5. Evaluación de modelos"},{"metadata":{"papermill":{"duration":0.351206,"end_time":"2020-11-06T19:41:13.049858","exception":false,"start_time":"2020-11-06T19:41:12.698652","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Ahora que ya hemos definido los algoritmos y el pipeline podemos entrenar los modelos y evaluarlos. \n\nVamos a empezar evaluando el modelo obtenido con el Zero-R que es el más básico."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:13.755419Z","iopub.status.busy":"2020-11-06T19:41:13.752765Z","iopub.status.idle":"2020-11-06T19:41:13.935931Z","shell.execute_reply":"2020-11-06T19:41:13.935048Z"},"papermill":{"duration":0.536874,"end_time":"2020-11-06T19:41:13.936077","exception":false,"start_time":"2020-11-06T19:41:13.399203","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.34426,"end_time":"2020-11-06T19:41:14.641969","exception":false,"start_time":"2020-11-06T19:41:14.297709","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos ver que ha obtenido una precisión del 62,573% clasificando todos los casos como ***B***. Ha obtenido un 62% de precisión porque como se vio en el análisis exploratorio la muestra estaba desbalanceada, esto quiere decir que había más cantidad de casos con un valor de `B` que casos con un valor de `M`.\n\nAdemás, el problema de este modelo es que siempre va a predecir como `B`, fallando siempre que el resultado correcto sea `M`. Y probablemente es más importante predecir como `M` y que la predicción correcta fuese `B` que fallar la predicción al reves, no teniendo el mismo coste al fallar la predicción. Por esto un modelo de este tipo en algún problema médico no nos interesa, ya que lo que de verdad queremos es descubrir cuando el cáncer es maligno (siendo más importante descubrir cuando es maligno que cuando es benigno)."},{"metadata":{"papermill":{"duration":0.347844,"end_time":"2020-11-06T19:41:15.340704","exception":false,"start_time":"2020-11-06T19:41:14.99286","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Ahora vamos a evaluar al árbol de clasificación pero sin discretizar."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:16.060869Z","iopub.status.busy":"2020-11-06T19:41:16.057315Z","iopub.status.idle":"2020-11-06T19:41:16.642288Z","shell.execute_reply":"2020-11-06T19:41:16.641373Z"},"papermill":{"duration":0.945952,"end_time":"2020-11-06T19:41:16.642431","exception":false,"start_time":"2020-11-06T19:41:15.696479","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate(prep_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.357318,"end_time":"2020-11-06T19:41:17.348725","exception":false,"start_time":"2020-11-06T19:41:16.991407","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Podemos ver que se ha obtenido una buena precisión, siendo esta del 87 %, fallando solo 18 casos de los 121 que ha predicho como benignos y eran malignos. Y ha fallado 4 casos de los 50 que ha predicho como malingos y eran benignos. \n\nPodemos ver que son buenos resultados, aunque vamos a ir más allá y dado que tenemos problema médico (se está predicieno sobre el cáncer), vamos a realizar una evaluación sensible al coste, aplicando un coste distinto según el fallo.\n\nDado que es un fallo mucho más grave tener a una persona que posee un cáncer maligno, y decirle que es benigno, a este fallo en la predicción le asignaremos un coste de 100. Mientras que si tenemos a una persona con un cáncer benigno y le decimos que es maligno le daremos un coste de 10. Así le estamos dando 10 veces más importancia al primer tipo de fallo.\n\nTendríamos una matriz de coste:"},{"metadata":{"papermill":{"duration":0.350287,"end_time":"2020-11-06T19:41:18.093226","exception":false,"start_time":"2020-11-06T19:41:17.742939","status":"completed"},"tags":[]},"cell_type":"markdown","source":"|      |   |    Coste      |   |   |\n|------|---|----------|---|---|\n|      | **B** |     0    | 10 |   |\n| **Real**| **M** |    100   | 0 |   |\n|      |   |     **B**    | **M** |   |\n|      |   | **Predicho**   |   |"},{"metadata":{"papermill":{"duration":0.346596,"end_time":"2020-11-06T19:41:18.791231","exception":false,"start_time":"2020-11-06T19:41:18.444635","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Si aplicaramos esta matriz de coste a los resultados predichos por el modelo tendríamos.\n\n$$Coste = 0*103 + 10*4 + 100*18 + 0*46 = 1840$$\n\nHemos tenido un coste un poco elevado relacionado con la precisión obtenida del modelo porque se han obtenido más casos predichos como benignos, que en realidad eran malignos que al reves. En este tipo de modelos nos interesaría reducir la cantidad de estos casos, aunque nos cueste aumentar (un poco) los casos predichos como malignos, pero que su valor real sea benigno."},{"metadata":{"papermill":{"duration":0.352912,"end_time":"2020-11-06T19:41:19.500853","exception":false,"start_time":"2020-11-06T19:41:19.147941","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Por último vamos a evaluar al modelo discretizado."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-06T19:41:20.252524Z","iopub.status.busy":"2020-11-06T19:41:20.251249Z","iopub.status.idle":"2020-11-06T19:41:20.837862Z","shell.execute_reply":"2020-11-06T19:41:20.838432Z"},"papermill":{"duration":0.969524,"end_time":"2020-11-06T19:41:20.838629","exception":false,"start_time":"2020-11-06T19:41:19.869105","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"utils.evaluate(prep_tree_model_discretizer,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.345714,"end_time":"2020-11-06T19:41:21.534147","exception":false,"start_time":"2020-11-06T19:41:21.188433","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Como era de esperar este modelo ha obtenido una mayor precisión, casi del 93%, afirmando que igual que vimos en el análisis multivariado, si discretizábamos a las variables en dos intervalos se podían obtener mejores resultados.\n\nAhora utilizando la misma matriz de coste que se definió para calcular el coste del modelo anterior, vamos a ver cuanto se ha reducido el coste en este modelo.\n$$Coste = 0*105 + 10*2 + 100*10 + 0*54 = 1020$$\n\nTambién hemos obtenido una gran mejora en el coste (antes teníamos 1840, y se ha reducido casi a la mitad) ya que se han reducido los casos predichos como benignos pero que en realidad eran malignos, que para este problema en concreto es muy importante reducir este tipo de casos."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}