{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\nimport os\nprint(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n#%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nfrom scipy.signal import argrelmin\nwarnings.simplefilter('ignore')\nsns.set(rc={'figure.figsize' : (22, 10)})\nsns.set_style(\"darkgrid\", {'axes.grid' : True})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createKernel(kernelSize, sigma, theta):\n    \"create anisotropic filter kernel according to given parameters\"\n    assert kernelSize % 2 # must be odd size\n    halfSize = kernelSize // 2\n\n    kernel = np.zeros([kernelSize, kernelSize])\n    sigmaX = sigma\n    sigmaY = sigma * theta\n\n    for i in range(kernelSize):\n        for j in range(kernelSize):\n            x = i - halfSize\n            y = j - halfSize\n\n            expTerm = np.exp(-x**2 / (2 * sigmaX) - y**2 / (2 * sigmaY))\n            xTerm = (x**2 - sigmaX**2) / (2 * math.pi * sigmaX**5 * sigmaY)\n            yTerm = (y**2 - sigmaY**2) / (2 * math.pi * sigmaY**5 * sigmaX)\n\n            kernel[i, j] = (xTerm + yTerm) * expTerm\n\n    kernel = kernel / np.sum(kernel)\n    return kernel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_text_to_lines(text, blanks):\n    x1 = 0\n    y = 0\n    lines = []\n    for i, blank in enumerate(blanks):\n        x2 = blank\n        #print(\"x1=\", x1, \", x2=\", x2, \", Diff= \", x2-x1)\n        line = text[:, x1:x2]\n        lines.append((line,x1,x2))\n        x1 = blank\n    return lines\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def smooth(x, window_len=40, window='hanning'):\n#     if x.ndim != 1:\n#         raise ValueError(\"smooth only accepts 1 dimension arrays.\") \n    if x.size < window_len:\n        raise ValueError(\"Input vector needs to be bigger than window size.\") \n    if window_len<3:\n        return x\n    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\") \n    s = np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n    #print(len(s))\n    if window == 'flat': #moving average\n        w = np.ones(window_len,'d')\n    else:\n        w = eval('np.'+window+'(window_len)')\n\n    y = np.convolve(w/w.sum(),s,mode='valid')\n    return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_lines(lines_arr, orient='vertical'):\n    plt.figure(figsize=(30, 30))\n    if not orient in ['vertical', 'horizontal']:\n        raise ValueError(\"Orientation is on of 'vertical', 'horizontal', defaul = 'vertical'\") \n    if orient == 'vertical': \n        for i, l in enumerate(lines_arr):\n            line = l[0]\n            plt.subplot(5, 10, i+1)  # A grid of 2 rows x 10 columns\n            plt.axis('off')\n            plt.title(\"Line #{0}\".format(i))\n            _ = plt.imshow(line, cmap='gray', interpolation = 'bicubic')\n            plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    else:\n            for i, l in enumerate(lines_arr):\n                line = l[0]\n                plt.subplot(90, 1, i+1)  # A grid of 90 rows x 1 columns\n                plt.axis('off')\n                plt.title(\"Line #{0}\".format(i))\n                _ = plt.imshow(line, cmap='gray', interpolation = 'bicubic')\n                plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def applySummFunctin(img):\n    res = np.sum(img, axis = 0)    #  summ elements in columns\n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(img):\n    (m, s) = cv2.meanStdDev(img)\n    m = m[0][0]\n    s = s[0][0]\n    img = img - m\n    img = img / s if s>0 else img\n    return img","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def showImg(img, cmap=None):\n    plt.imshow(img, cmap=cmap, interpolation = 'bicubic')\n    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transpose_lines(lines):\n    res = []\n    for l in lines:\n        line = np.transpose(l[0])\n        res.append((line,l[1],l[2]))\n    return res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lineSegmentation(image, show=False, smoothness = 50, kernelSize=11, sigma=4, theta=1.5):\n    #25, 0.8, 3.5\n    #img = np.arange(16).reshape((4,4))\n    imgFiltered1 = cv2.filter2D(image, -1, createKernel(kernelSize, sigma, theta), borderType=cv2.BORDER_REPLICATE)\n    img4 = normalize(imgFiltered1)\n    (m, s) = cv2.meanStdDev(imgFiltered1)\n    summ = applySummFunctin(img4)\n    #windows=['flat', 'hanning', 'hamming', 'bartlett', 'blackman']\n    smoothed = smooth(summ, smoothness)\n    mins = argrelmin(smoothed, order=2)\n    arr_mins = np.array(mins)\n    found_lines = crop_text_to_lines(img4, arr_mins[0])\n    #sess = tf.Session()\n    #found_lines_arr = []\n    #with sess.as_default():\n    #    for i in range(len(found_lines)-1):\n    #        found_lines_arr.append(tf.expand_dims(found_lines[i], -1).eval())\n    if show:\n        res_lines = transpose_lines(found_lines)\n        display_lines(res_lines, 'horizontal')\n    return found_lines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wordSegmentation(image, show=False, smoothness = 45, kernelSize=19, sigma=9, theta=7, minArea=0):\n    #img = np.arange(16).reshape((4,4))\n    img = np.transpose(image)\n    imgFiltered1 = cv2.filter2D(img, -1, createKernel(kernelSize, sigma, theta), borderType=cv2.BORDER_REPLICATE)\n    img4 = normalize(imgFiltered1)\n    (m, s) = cv2.meanStdDev(imgFiltered1)\n    summ = applySummFunctin(img4)\n    #windows=['flat', 'hanning', 'hamming', 'bartlett', 'blackman']\n    smoothed = smooth(summ, smoothness)\n    mins = argrelmin(smoothed, order=2)\n    arr_mins = np.array(mins)\n    found_lines = crop_text_to_lines(img4, arr_mins[0])\n    #sess = tf.Session()\n    found_lines_arr = []\n    res_lines = []\n    #with sess.as_default():\n    for i in range(len(found_lines)-1):\n        res_lines.append(found_lines[i])\n         #found_lines_arr.append(tf.expand_dims(found_lines[i], -1).eval())\n    if show:\n        #res_lines = transpose_lines(found_lines)\n        display_lines(res_lines)\n    return res_lines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def analyse_image(N_of_questions, filename):\n    img = cv2.imread(filename)\n    plt.imshow(img)\n    img = cv2.resize(img, (1200, 1600))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    images = []\n    i=0\n    for im in lineSegmentation(img):\n        j=0\n        to_plot = []\n        for word in wordSegmentation(im[0]):\n            to_plot.append((word[0],0,0))\n            images.append((word[0],word[1],im[1],word[2],im[2]))\n            j+=1\n            if j==3:\n                #display_lines(to_plot)\n                break\n        if i==N_of_questions+1:\n                break\n        i+=1\n    return images\n    \nanalyse_image(10,'../input/test-liceum/IMG_20210106_171519.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/encripyed-cyryllics-latin/ino.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport cv2\n\n\n\nimport torch.nn as nn\nfrom torch.nn.functional import relu, sigmoid\n\nclass mach1(nn.Module):\n    def __init__(self):\n        super(mach1, self).__init__()\n        self.conv0 = nn.Conv2d(3, 28, 3)\n        self.fc0 = nn.ReLU()\n        self.conv1 = nn.Conv2d(28, 14, 3)\n        #self.drop1 = nn.Dropout2d(0.1)\n        self.pool1 = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(14*12*12,136)\n        self.fc2 = nn.Linear(136,101)\n        self.fc3 = nn.Linear(101,101)\n        self.fc4 = nn.LogSoftmax(dim=1)\n    def forward(self, x):\n        x = self.conv0(x)\n        x = self.fc0(x)\n        x = self.conv1(x)\n        #x = self.drop1(x)\n        x = self.pool1(x)\n        x = x.view(-1,14*12*12)\n        x = sigmoid(self.fc1(x))\n        x = sigmoid(self.fc2(x))\n        x = sigmoid(self.fc3(x))\n        x = self.fc4(x)\n        return x\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = mach1()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.autograd import Variable\n\ndef int_to_vector(x):\n    answer = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n                      0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n    answer[x]=1\n    return answer\n\n\nX = df[[\"files\"]]\ny = df[\"ecription\"].values#.apply(int_to_vector).values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\n#def loss_fn(x,y):\n#    return -torch.dot(x.view(-1),y.view(-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\nbatch_size = X.shape[0]\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n#SGD(model.parameters(), lr=0.42, momentum=0.9)\n\n\nfor e in range(2001):\n    print(e,end=\" \")\n    for batch in range(X.shape[0]//batch_size):\n        X_batch = []\n        for filename in X.values[batch*batch_size:min((batch+1)*batch_size, X.shape[0])]:\n            path = '../input/encripyed-cyryllics-latin/encdata/encdata/'+filename[0]\n            img = cv2.imread(path)\n            img = cv2.resize(img, (28,28))\n            img = normalize(img)\n            X_batch.append(np.rollaxis(img, axis=2, start=0))\n            \n        y_batch = y[batch*batch_size:min((batch+1)*batch_size, X.shape[0])] \n        X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch)\n        \n        X_train = Variable(torch.from_numpy(np.array(X_train)).float())\n        X_test = Variable(torch.from_numpy(np.array(X_test)).float())\n        y_train = Variable(torch.from_numpy(np.array(y_train.tolist())).float())\n        y_test = Variable(torch.from_numpy(np.array(y_test.tolist())).float())\n        \n        out = model(X_train)\n        y_train = y_train.long()\n        loss = loss_fn(out,y_train)\n        losses.append(loss.detach())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if(e % 25 == 0):\n            preds_test = model(X_test)\n            y_test = y_test.long()\n            loss_test = loss_fn(preds_test, y_test)\n            s1 = torch.tensor([1]*len(y_test)).float()\n            s2 = (torch.abs(y_test-torch.argmax(preds_test,dim=1))>0).float()\n            print(\"acc:\", torch.mean(s1-s2))\n            print('Epoch:{0}, Error-Loss:{1}'.format(e, loss.item()))\n            print('Epoch:{0}, Error-Test-Loss:{1}'.format(e , loss.item()))\n            print('------------------------------------------------------')\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\nbatch_size = X.shape[0]\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n#SGD(model.parameters(), lr=0.42, momentum=0.9)\n\nfor e in range(2001):\n    print(e,end=\" \")\n    for batch in range(X.shape[0]//batch_size):\n        X_batch = []\n        for filename in X.values[batch*batch_size:min((batch+1)*batch_size, X.shape[0])]:\n            path = '../input/encripyed-cyryllics-latin/encdata/encdata/'+filename[0]\n            img = cv2.imread(path)\n            img = cv2.resize(img, (28,28))\n            img = normalize(img)\n            X_batch.append(np.rollaxis(img, axis=2, start=0))\n            \n        y_batch = y[batch*batch_size:min((batch+1)*batch_size, X.shape[0])] \n        X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch)\n        \n        X_train = Variable(torch.from_numpy(np.array(X_train)).float())\n        X_test = Variable(torch.from_numpy(np.array(X_test)).float())\n        y_train = Variable(torch.from_numpy(np.array(y_train.tolist())).float())\n        y_test = Variable(torch.from_numpy(np.array(y_test.tolist())).float())\n        \n        out = model(X_train)\n        y_train = y_train.long()\n        loss = loss_fn(out,y_train)\n        losses.append(loss.detach())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if(e % 25 == 0):\n            preds_test = model(X_test)\n            y_test = y_test.long()\n            loss_test = loss_fn(preds_test, y_test)\n            s1 = torch.tensor([1]*len(y_test)).float()\n            s2 = (torch.abs(y_test-torch.argmax(preds_test,dim=1))>0).float()\n            print(\"acc:\", torch.mean(s1-s2))\n            print('Epoch:{0}, Error-Loss:{1}'.format(e, loss.item()))\n            print('Epoch:{0}, Error-Test-Loss:{1}'.format(e , loss.item()))\n            print('------------------------------------------------------')\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n#SGD(model.parameters(), lr=0.42, momentum=0.9)\n\n\nbatch_size = X.shape[0]\n\n\nfor e in range(2001):\n    print(e,end=\" \")\n    for batch in range(X.shape[0]//batch_size):\n        X_batch = []\n        for filename in X.values[batch*batch_size:min((batch+1)*batch_size, X.shape[0])]:\n            path = '../input/encripyed-cyryllics-latin/encdata/encdata/'+filename[0]\n            img = cv2.imread(path)\n            img = cv2.resize(img, (28,28))\n            img = normalize(img)\n            X_batch.append(np.rollaxis(img, axis=2, start=0))\n            \n        y_batch = y[batch*batch_size:min((batch+1)*batch_size, X.shape[0])] \n        X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch)\n        \n        X_train = Variable(torch.from_numpy(np.array(X_train)).float())\n        X_test = Variable(torch.from_numpy(np.array(X_test)).float())\n        y_train = Variable(torch.from_numpy(np.array(y_train.tolist())).float())\n        y_test = Variable(torch.from_numpy(np.array(y_test.tolist())).float())\n        \n        out = model(X_train)\n        y_train = y_train.long()\n        loss = loss_fn(out,y_train)\n        losses.append(loss.detach())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if(e % 25 == 0):\n            preds_test = model(X_test)\n            y_test = y_test.long()\n            loss_test = loss_fn(preds_test, y_test)\n            s1 = torch.tensor([1]*len(y_test)).float()\n            s2 = (torch.abs(y_test-torch.argmax(preds_test,dim=1))>0).float()\n            print(\"acc:\", torch.mean(s1-s2))\n            print('Epoch:{0}, Error-Loss:{1}'.format(e, loss.item()))\n            print('Epoch:{0}, Error-Test-Loss:{1}'.format(e , loss.item()))\n            print('------------------------------------------------------')\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n#SGD(model.parameters(), lr=0.42, momentum=0.9)\n\nbatch_size = X.shape[0]\n\n\n\nfor e in range(2001):\n    print(e,end=\" \")\n    for batch in range(X.shape[0]//batch_size):\n        X_batch = []\n        for filename in X.values[batch*batch_size:min((batch+1)*batch_size, X.shape[0])]:\n            path = '../input/encripyed-cyryllics-latin/encdata/encdata/'+filename[0]\n            img = cv2.imread(path)\n            img = cv2.resize(img, (28,28))\n            img = normalize(img)\n            X_batch.append(np.rollaxis(img, axis=2, start=0))\n            \n        y_batch = y[batch*batch_size:min((batch+1)*batch_size, X.shape[0])] \n        X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch)\n        \n        X_train = Variable(torch.from_numpy(np.array(X_train)).float())\n        X_test = Variable(torch.from_numpy(np.array(X_test)).float())\n        y_train = Variable(torch.from_numpy(np.array(y_train.tolist())).float())\n        y_test = Variable(torch.from_numpy(np.array(y_test.tolist())).float())\n        \n        out = model(X_train)\n        y_train = y_train.long()\n        loss = loss_fn(out,y_train)\n        losses.append(loss.detach())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if(e % 25 == 0):\n            preds_test = model(X_test)\n            y_test = y_test.long()\n            loss_test = loss_fn(preds_test, y_test)\n            s1 = torch.tensor([1]*len(y_test)).float()\n            s2 = (torch.abs(y_test-torch.argmax(preds_test,dim=1))>0).float()\n            print(\"acc:\", torch.mean(s1-s2))\n            print('Epoch:{0}, Error-Loss:{1}'.format(e, loss.item()))\n            print('Epoch:{0}, Error-Test-Loss:{1}'.format(e , loss.item()))\n            print('------------------------------------------------------')\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.parameters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), \"model.d\")\ntorch.save(model, \"model.m\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(losses)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder = {0:\" \", 1:\"1\", 2:\"2\", 3:\"3\", 4:\"4\",\n           5:\"5\", 6:\"6\", 7:\"7\", 8:\"8\", 9:\"9\",\n          10:\"а\", 11:\"б\", 12:\"в\", 13:\"г\",\n          14:\"д\", 15:\"е\", 16:\"ж\", 17:\"з\",\n          18:\"и\", 19:\"к\", 20:\"л\", 21:\"м\",\n          22:\"н\", 23:\"о\", 24:\"п\", 25:\"р\",\n          26:\"с\", 27:\"т\", 28:\"у\", 29:\"ф\",\n          30:\"х\", 31:\"ц\", 32:\"ч\", 33:\"ш\",\n          34:\"щ\", 35:\"ь\", 36:\"ы\", 37:\"ъ\",\n          38:\"э\", 39:\"ю\", 40:\"я\"}\n\ndef make_answer(num_of_questions, filename):\n    image = cv2.imread(filename)\n    image = cv2.resize(image, (1200, 1600))\n    draw1 = image.copy()\n    draw2 = image.copy()\n    blocks = analyse_image(10,filename)\n    i=0\n    answer = []\n    for seg in blocks:\n        #print(seg)\n        img = image[seg[1]:seg[3],seg[2]:seg[4],:]\n        plt.imshow(img)\n        plt.show()\n        break\n        draw1 = cv2.rectangle(draw1, (seg[4],seg[3]), (seg[2],seg[1]), (255,0,0), 3)       \n        img = normalize(img)\n        img = cv2.resize(img, (28,28))\n        img = np.rollaxis(img, axis=2, start=0)\n        img = torch.tensor([img]).float()\n        answer.append(model(img).tolist()[0])\n    res = torch.tensor(answer)\n    counter = num_of_questions\n    answer = {}\n    while counter > 0:\n        most_relevant = torch.argmax(torch.sum(torch.max(res)==res,dim=1))\n        seg = blocks[most_relevant]\n        draw2 = cv2.rectangle(draw2, (seg[3],seg[4]), (seg[1],seg[2]), (255,0,0), 3)\n        answer[int(most_relevant)]=decoder[int(torch.argmax(res[most_relevant,:]))]\n        res = torch.cat((res[:most_relevant,:], res[min(most_relevant+1,res.shape[0]):,:]), dim=0)\n        counter -= 1\n    plt.imshow(draw1)\n    plt.show()\n    plt.imshow(draw2)\n    plt.show()\n    return answer\n\nfilename = '../input/test-liceum/IMG_20210106_171526.jpg'\nmake_answer(10,filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = {2:\"b\",1:\"a\"}\nprint(a.keys())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}