{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\nimport json\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\n\n# --- setup ---\npd.set_option('max_columns', 50)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"json_file = os.path.join(\"/kaggle/input/coco-text-data-train-2014/cocotext.v2\", \"cocotext.v2.json\")\nwith open(json_file) as f:\n    imgs_anns = json.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ntorch.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install detectron2 -f \\\n  https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You may need to restart your runtime prior to this, to let your installation take effect\n# Some basic setup\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nfrom detectron2 import model_zoo\n\n# import some common detectron2 utilities\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,10))\nim = cv2.imread(\"/kaggle/input/coco-text-data-train-2014/train2014/train2014/COCO_train2014_000000483569.jpg\")\nplt.imshow(im)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_info={}\nfor idx in imgs_anns['imgs']:\n    if imgs_anns['imgs'][idx]['set']=='train':\n        image_info[idx]=imgs_anns['imgs'][idx]['file_name']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_info2={}\nfor idx in imgs_anns['anns']:\n    k=str(imgs_anns['anns'][idx]['image_id'])\n    if k in image_info:\n        if k not in image_info2:\n            image_info2[k]=[{'file_name':image_info[k]}]\n            image_info2[k].append(imgs_anns['anns'][idx])\n        else:\n            image_info2[k].append(imgs_anns['anns'][idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.structures import BoxMode\n\ndef get_cvpr_dicts(img_dir,imgs_anns,type1):\n    dataset_dicts = []\n    for idx in imgs_anns:\n        record = {}\n        \n        filename = os.path.join(img_dir, imgs_anns[idx][0][\"file_name\"])\n        height, width = cv2.imread(filename).shape[:2]\n        \n        record[\"file_name\"] = filename\n        record[\"image_id\"] = idx\n        record[\"height\"] = height\n        record[\"width\"] = width\n      \n        annos = imgs_anns[idx][1:]\n        objs = []\n        for anno in annos:\n            bbox=anno['bbox']\n            x1=bbox[0]\n            y1=bbox[1]\n            x2=bbox[0]+bbox[2]\n            y2=bbox[1]+bbox[3]\n            poly = anno['mask']\n\n            obj = {\n              \"bbox\": [x1, y1, x2, y2],\n              \"bbox_mode\": BoxMode.XYXY_ABS,\n              \"segmentation\": [poly],\n              \"category_id\": 0,\n            }\n            objs.append(obj)\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for d in [\"train\"]:\n    DatasetCatalog.register(\"cvpr_\"+d, lambda d=d: get_cvpr_dicts(\"/kaggle/input/coco-text-data-train-2014/train2014/train2014/\",image_info2,d))\n    MetadataCatalog.get(\"cvpr_\"+d).set(thing_classes=[\"text\"])\ncvpr_metadata = MetadataCatalog.get(\"cvpr_train\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_indexes=list(range(len(image_info2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\ndataset_dicts = get_cvpr_dicts(\"/kaggle/input/coco-text-data-train-2014/train2014/train2014/\",image_info2,\"train\")\nfig, axes = plt.subplots(3, 1, figsize=(30, 30))\naxes = axes.flatten()\nfor index, anom_ind in enumerate(training_indexes[:3]):\n    ax = axes[index]\n    d = dataset_dicts[anom_ind]\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=cvpr_metadata, scale=1.2)\n    out = visualizer.draw_dataset_dict(d)\n    ax.imshow(out.get_image()[:, :, ::-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\n\ncfg = get_cfg()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"cvpr_train\",)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\ncfg.SOLVER.MAX_ITER = 2000   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\ncfg.SOLVER.STEPS = []        # do not decay learning rate\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata_annotations=pd.read_csv(\"/kaggle/input/cvpr-pricing-challenge/annotations.csv\")\nunique_images=list(data_annotations['img_name'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_indexes=list(range(len(unique_images)))\nfrom detectron2.utils.visualizer import ColorMode\nfig, axes = plt.subplots(3, 1, figsize=(60, 60))\naxes = axes.flatten()\nfor index, anom_ind in enumerate(random.sample(testing_indexes, 3)):\n    ax = axes[index]\n    d = unique_images[anom_ind]\n    img = cv2.imread(\"/kaggle/input/cvpr-pricing-challenge/images/\"+d)\n    outputs = predictor(img)\n    v = Visualizer(img[:, :, ::-1],\n                   MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), \n                   scale=1.2, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    ax.imshow(out.get_image()[:, :, ::-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}