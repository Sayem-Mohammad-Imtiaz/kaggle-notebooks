{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Model Deployment using Streamlit on Heroku\n\n### Want to build an End-to-End project using Machine Learning, this Notebook will help you do so!\n\n[Link to GitHub Repo](https://github.com/Lokeshrathi/Deploying-a-Machine-Learning-Model)\n\n[Link to My WebPage](https://heart-disease-ml-app.herokuapp.com/)"},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning and Exploration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style('whitegrid')\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score,confusion_matrix,recall_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\nfrom xgboost import XGBClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- age- in years\n- sex-(1 = male; 0 = female)\n- cp- chest pain type\n- trestbps- resting blood pressure (in mm Hg on admission to the hospital)\n- chol- serum cholestoral in mg/dl\n- fbs-(fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n- restecg-resting electrocardiographic results\n- thalach-maximum heart rate achieved\n- exang-exercise induced angina (1 = yes; 0 = no)\n- oldpeak-ST depression induced by exercise relative to rest\n- slope-the slope of the peak exercise ST segment\n- ca-number of major vessels (0-3) colored by flourosopy\n- thal- 3 = normal; 6 = fixed defect; 7 = reversable defect\n- target- 1 or 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ca'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),annot=True,cmap='YlGnBu',fmt='.2f',linewidths=2)\n#No much of correlation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['age'],color='Red',hist_kws={'alpha':1,\"linewidth\": 2},\n             kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"})\n#Most people age is from 40 to 60","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(24,12))\nplt.subplot(1, 3, 1)\nage_bins = [10,20,30,40,50,70,80]\ndf['age_bins'] = pd.cut(df['age'],bins = age_bins, duplicates='drop')\ng1 = sns.countplot(data= df, x= 'age_bins',hue='target',palette='plasma',linewidth=3)\ng1.set_title(\"Age vs Heart Disease\")\n\n\nplt.subplot(1, 3, 2)\ncho_bins = [100,150,200,250,300,350,400,450]\ndf['bin_chol']=pd.cut(df['chol'], bins=cho_bins)\ng2=sns.countplot(x='bin_chol',data=df,hue='target',palette='plasma',linewidth=3)\ng2.set_title(\"Cholestoral vs Heart Disease\")\n\n\nplt.subplot(1, 3, 3)\nthal_bins = [60,80,100,120,140,160,180,200,220]\ndf['bin_thal']=pd.cut(df['thalach'], bins=thal_bins)\ng3=sns.countplot(x='bin_thal',data=df,hue='target',palette='plasma',linewidth=3)\ng3.set_title(\"Thal vs Heart Disease\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sns.distplot(df['target'],kde= True)\ndf['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## we can see that our independent variable is Balanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conversion to categorical variables\ndf['sex']=df['sex'].astype('category')\ndf['cp']=df['cp'].astype('category')\ndf['fbs']=df['fbs'].astype('category')\ndf['restecg']=df['restecg'].astype('category')\ndf['exang']=df['exang'].astype('category')\ndf['slope']=df['slope'].astype('category')\ndf['ca']=df['ca'].astype('category')\ndf['thal']=df['thal'].astype('category')\ndf['target']=df['target'].astype('category')\ndf.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = df.corr()\nplt.figure(figsize=(12,10))\nsns.heatmap(correlation,annot=True,cmap = 'Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df, drop_first = True) ## Converting the categorical features so that the model learns in a better way\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('target_1', axis = 1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\naccuracy = accuracy_score(y_test,pred)\nclassification = classification_report(y_test,pred)\nconfusion_ = confusion_matrix(y_test,pred)\nprint(accuracy, classification,confusion_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\npenalty = ['l1','l2']\nC = np.logspace(0, 4, 10)\nhyperparameters = dict(C=C, penalty=penalty)\nh_logmodel = GridSearchCV(lr, hyperparameters, cv=6, verbose=0)\nbest_logmodel=h_logmodel.fit(x_train,y_train)\nprint('Best Penalty:', best_logmodel.best_estimator_.get_params()['penalty'])\nprint('Best C:', best_logmodel.best_estimator_.get_params()['C'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr1 = LogisticRegression(penalty='l2',C = 1.0)\nlr1.fit(x_train,y_train)\npred = lr1.predict(x_test)\naccuracy = accuracy_score(y_test,pred)\nclassification = classification_report(y_test,pred)\nconfusion_ = confusion_matrix(y_test,pred)\nprint(accuracy)\nprint(confusion_)\nprint(classification)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use Pickle to save your model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\npickle.dump(lr1,open('heart.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_price(age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldspeak,slope,ca,thal):    \n\n    x = np.zeros(40)\n    x[0] = age\n    x[1] = sex\n    x[2] = cp\n    x[3] = trestbps\n    x[4] = chol\n    x[5] = fbs\n    x[6] = restecg\n    x[7] = thalach\n    x[8] = exang\n    x[9] = oldspeak\n    x[10] = slope\n    x[11] = ca\n    x[12] = thal\n\n    #if loc_index >= 0:\n        #   x[loc_index] = 1\n\n    return lr.predict([x])[0]\n\npredict_price(54,0,2,108,267,0,0,167,0,0.0,2,0,2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle_in = open('heart.pkl','rb')\nclf = pickle.load(pickle_in)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visit this [GitHub Link](https://github.com/Lokeshrathi/Deploying-a-Machine-Learning-Model) for Deployment of the Model on Heroku\n\n### Also pin down your doubts, if you have any!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}