{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-25T16:00:44.212147Z","iopub.execute_input":"2021-08-25T16:00:44.212846Z","iopub.status.idle":"2021-08-25T16:02:03.91287Z","shell.execute_reply.started":"2021-08-25T16:00:44.21272Z","shell.execute_reply":"2021-08-25T16:02:03.911219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\n\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport transformers\nfrom transformers import AdamW, T5Tokenizer, T5ForConditionalGeneration\n\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:03.918886Z","iopub.execute_input":"2021-08-25T16:02:03.91935Z","iopub.status.idle":"2021-08-25T16:02:11.704956Z","shell.execute_reply.started":"2021-08-25T16:02:03.919301Z","shell.execute_reply":"2021-08-25T16:02:11.703844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    \n    MAX_LEN_I = 448\n    MAX_LEN_O = 224\n    TRAIN_BATCH_SIZE = 16\n    VALID_BATCH_SIZE = 8\n    EPOCHS = 13\n    MODEL_PATH = \"T5-base-TPU.pth\"\n    TRAINING_FILE = '../input/table-to-text-generation-dataset-google-totto/totto_data/tablesWithTag.csv'\n    TOKENIZER = transformers.T5Tokenizer.from_pretrained('t5-base',do_lower_case =True)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:11.707318Z","iopub.execute_input":"2021-08-25T16:02:11.70774Z","iopub.status.idle":"2021-08-25T16:02:13.41949Z","shell.execute_reply.started":"2021-08-25T16:02:11.707686Z","shell.execute_reply":"2021-08-25T16:02:13.418212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"special_tokens_dict = {'pad_token': '<pad>', 'bos_token': '<bos>', 'eos_token': '<eos>', \n                       'additional_special_tokens': ['<PAGESTART>', '<PAGEEND>', '<SECTIONSTART>', '<SECTIONEND>',\n                                                     '<TABLESTART>','<TABLEEND>','<CELLSTART>','<CELLEND>','<COLHEADERSTART>',\n                                                     '<COLHEADEREND>','<ROWHEADERSTART>','<ROWHEADEREND>']}\n\nnum_added_toks = config.TOKENIZER.add_special_tokens(special_tokens_dict)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:13.421073Z","iopub.execute_input":"2021-08-25T16:02:13.421415Z","iopub.status.idle":"2021-08-25T16:02:13.429537Z","shell.execute_reply.started":"2021-08-25T16:02:13.421383Z","shell.execute_reply":"2021-08-25T16:02:13.428012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(config.TRAINING_FILE)\ntrain_df, val_df=train_test_split(df, test_size=0.1)\ntrain_df=train_df.reset_index(drop=True)\nval_df=val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:13.431044Z","iopub.execute_input":"2021-08-25T16:02:13.431471Z","iopub.status.idle":"2021-08-25T16:02:16.298751Z","shell.execute_reply.started":"2021-08-25T16:02:13.431433Z","shell.execute_reply":"2021-08-25T16:02:16.297801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class tottoDataset(Dataset):\n  def __init__(self,df,tokenizer):\n    self.sentence=df['sentence']\n    self.table=df['table']\n    self.tokenizer=tokenizer\n\n  def __len__(self):\n    return len(self.sentence)\n  \n  def __getitem__(self,idx):\n    inp=(self.table[idx]+'</s>').replace(\"<page_title>\", \"<PAGESTART>\").replace(\"</page_title>\", \"<PAGEEND>\") \\\n                                    .replace(\"<section_title>\", \"<SECTIONSTART>\").replace(\"</section_title>\", \"<SECTIONEND>\") \\\n                                    .replace(\"<table>\", \"<TABLESTART>\").replace(\"</table>\", \"<TABLEEND>\") \\\n                                    .replace(\"<cell>\", \"<CELLSTART>\").replace(\"</cell>\", \"<CELLEND>\") \\\n                                    .replace(\"<col_header>\", \"<COLHEADERSTART>\").replace(\"</col_header>\", \"<COLHEADEREND>\") \\\n                                    .replace(\"<row_header>\", \"<ROWHEADERSTART>\").replace(\"</row_header>\", \"<ROWHEADEREND>\")\n    out=self.sentence[idx]+'</s>'\n    inp_tokens=self.tokenizer.encode_plus(inp, padding=\"max_length\", max_length=config.MAX_LEN_I, truncation=True)\n    out_tokens=self.tokenizer.encode_plus(out, padding=\"max_length\", max_length=config.MAX_LEN_O, truncation=True)\n    inp_id=inp_tokens.input_ids\n    out_id=out_tokens.input_ids\n    inp_mask=inp_tokens.attention_mask\n    out_mask=out_tokens.attention_mask\n    labels=out_tokens.input_ids.copy()\n    labels=[-100  if x==self.tokenizer.pad_token_id else x for x in labels]\n\n    return {\n        \"table_text\":inp,\n        \"sentence\":out,\n        \"input_ids\":torch.tensor(inp_id, dtype=torch.long),\n        \"input_attention_mask\":torch.tensor(inp_mask, dtype=torch.long),\n        \"decoder_input_ids\":torch.tensor(out_id, dtype=torch.long),\n        \"decoder_attention_mask\":torch.tensor(out_mask, dtype=torch.long),\n        \"labels\":torch.tensor(labels, dtype=torch.long)\n    }","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:16.300083Z","iopub.execute_input":"2021-08-25T16:02:16.300394Z","iopub.status.idle":"2021-08-25T16:02:16.315745Z","shell.execute_reply.started":"2021-08-25T16:02:16.300365Z","shell.execute_reply":"2021-08-25T16:02:16.313657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!export XLA_USE_BF16=1","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:16.317408Z","iopub.execute_input":"2021-08-25T16:02:16.317757Z","iopub.status.idle":"2021-08-25T16:02:17.08411Z","shell.execute_reply.started":"2021-08-25T16:02:16.317727Z","shell.execute_reply":"2021-08-25T16:02:17.082429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(dataloader, model, optimizer, device, scheduler, epoch, num_epoch, num_steps):\n    model.train()\n    for i, batch in enumerate(dataloader):\n        input_ids=batch['input_ids'].to(device)\n        labels=batch['labels'].to(device)\n        \n        outputs=model(input_ids=input_ids,\n                     labels=labels)\n        \n        loss=outputs.loss\n        loss.backward()\n        \n        xm.optimizer_step(optimizer)\n        \n        if scheduler is not None:\n            scheduler.step()\n            \n        if(i%800==0):\n            print(f\"Epoch: {epoch+1}/{num_epoch} Batch {i+1}/{num_steps} Loss:{loss.item()} Time Taken:{time.asctime()}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:17.087808Z","iopub.execute_input":"2021-08-25T16:02:17.088374Z","iopub.status.idle":"2021-08-25T16:02:17.096696Z","shell.execute_reply.started":"2021-08-25T16:02:17.088314Z","shell.execute_reply":"2021-08-25T16:02:17.095627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(dataloader, model, device, size):\n    model.eval()\n    loss=0\n    with torch.no_grad():\n        for i, batch in enumerate(dataloader):\n            input_ids=batch[\"input_ids\"].to(device)\n            labels=batch[\"labels\"].to(device)\n            \n            outputs=model(input_ids=input_ids,\n                         labels=labels)\n            \n            loss+=outputs.loss.item()\n    print(f\"Val Loss:{loss/size}\")\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:17.098268Z","iopub.execute_input":"2021-08-25T16:02:17.098632Z","iopub.status.idle":"2021-08-25T16:02:17.113665Z","shell.execute_reply.started":"2021-08-25T16:02:17.098596Z","shell.execute_reply":"2021-08-25T16:02:17.112745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\nmodel.encoder.resize_token_embeddings(len(config.TOKENIZER))\nmodel.decoder.resize_token_embeddings(len(config.TOKENIZER))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:02:17.114909Z","iopub.execute_input":"2021-08-25T16:02:17.115261Z","iopub.status.idle":"2021-08-25T16:04:41.455343Z","shell.execute_reply.started":"2021-08-25T16:02:17.115222Z","shell.execute_reply":"2021-08-25T16:04:41.454178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _run():\n    train_dataset=tottoDataset(train_df, config.TOKENIZER)\n    valid_dataset=tottoDataset(val_df, config.TOKENIZER)\n    \n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n          train_dataset,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=True)\n\n    train_data_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=config.TRAIN_BATCH_SIZE,\n        sampler=train_sampler,\n        drop_last=True,\n        num_workers=4\n    )\n    \n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n          valid_dataset,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=False)\n\n    valid_data_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=config.VALID_BATCH_SIZE,\n        sampler=valid_sampler,\n        drop_last=False,\n        num_workers=4\n    )\n    \n    device = xm.xla_device()\n    model.to(device)\n    \n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n    ]\n    \n    lr = 0.4 * 1e-5 * xm.xrt_world_size()\n\n    num_train_steps = int(len(train_dataset) / config.TRAIN_BATCH_SIZE / xm.xrt_world_size() * config.EPOCHS)\n    optimizer = AdamW(optimizer_parameters, lr=lr)\n    \n    best_loss=1e9\n    \n    for epoch in range(config.EPOCHS):\n        para_loader = pl.ParallelLoader(train_data_loader, [device])\n        train_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler=None, epoch=epoch, num_epoch=config.EPOCHS, num_steps=num_train_steps)\n        \n        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n        loss = eval_fn(para_loader.per_device_loader(device), model, device, len(valid_dataset))\n        \n        if loss<best_loss:\n            xm.save(model.state_dict(),config.MODEL_PATH)\n            best_loss=loss","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:04:41.457009Z","iopub.execute_input":"2021-08-25T16:04:41.457368Z","iopub.status.idle":"2021-08-25T16:04:41.473109Z","shell.execute_reply.started":"2021-08-25T16:04:41.457335Z","shell.execute_reply":"2021-08-25T16:04:41.471916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _mp_fn(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = _run()\n\nFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T16:04:41.474468Z","iopub.execute_input":"2021-08-25T16:04:41.475136Z","iopub.status.idle":"2021-08-25T16:15:52.80232Z","shell.execute_reply.started":"2021-08-25T16:04:41.475065Z","shell.execute_reply":"2021-08-25T16:15:52.799762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}