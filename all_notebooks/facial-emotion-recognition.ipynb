{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Facial expression for emotion detection has always been an easy task for humans, but achieving the same task with a computer algorithm is quite challenging. With the recent advancement in computer vision and machine learning, it is possible to detect emotions from images.\n\n### In this project we use a technique called facial emotion recognition using convolutional neural networks **(FERC)**\n\n### The FERC is based on two-part :-\n### 1. convolutional neural network (CNN): The first-part removes the background from the picture, \n### 2. The second part concentrates on the facial feature vector extraction","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"## General Libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\n## Deep Learning Libraries\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.preprocessing.image import load_img, img_to_array","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:23:07.428984Z","iopub.execute_input":"2021-06-22T05:23:07.429475Z","iopub.status.idle":"2021-06-22T05:23:14.323366Z","shell.execute_reply.started":"2021-06-22T05:23:07.429376Z","shell.execute_reply":"2021-06-22T05:23:14.322206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/facialexpressionrecognition/fer2013.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:08.979016Z","iopub.execute_input":"2021-06-22T05:30:08.979513Z","iopub.status.idle":"2021-06-22T05:30:14.680245Z","shell.execute_reply.started":"2021-06-22T05:30:08.979479Z","shell.execute_reply":"2021-06-22T05:30:14.679233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:32.169637Z","iopub.execute_input":"2021-06-22T05:30:32.170024Z","iopub.status.idle":"2021-06-22T05:30:32.182553Z","shell.execute_reply.started":"2021-06-22T05:30:32.169992Z","shell.execute_reply":"2021-06-22T05:30:32.18105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## shape of the dataset\n\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:32.27898Z","iopub.execute_input":"2021-06-22T05:30:32.279318Z","iopub.status.idle":"2021-06-22T05:30:32.286391Z","shell.execute_reply.started":"2021-06-22T05:30:32.279289Z","shell.execute_reply":"2021-06-22T05:30:32.284747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## checking for null values\n\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:32.289261Z","iopub.execute_input":"2021-06-22T05:30:32.289848Z","iopub.status.idle":"2021-06-22T05:30:32.31376Z","shell.execute_reply.started":"2021-06-22T05:30:32.289801Z","shell.execute_reply":"2021-06-22T05:30:32.312456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, in the dataset there is not any missing values.","metadata":{}},{"cell_type":"markdown","source":"# count of each classes","metadata":{}},{"cell_type":"code","source":"df['emotion'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:02:39.462434Z","iopub.execute_input":"2021-06-22T06:02:39.462823Z","iopub.status.idle":"2021-06-22T06:02:39.473774Z","shell.execute_reply.started":"2021-06-22T06:02:39.462792Z","shell.execute_reply":"2021-06-22T06:02:39.472291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Path of input Data","metadata":{}},{"cell_type":"code","source":"train_data_dir = '../input/emotion-detection-fer/train'\nvalidation_data_dir = '../input/emotion-detection-fer/test'","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:32.31669Z","iopub.execute_input":"2021-06-22T05:30:32.317195Z","iopub.status.idle":"2021-06-22T05:30:32.322545Z","shell.execute_reply.started":"2021-06-22T05:30:32.317151Z","shell.execute_reply":"2021-06-22T05:30:32.320807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying Images","metadata":{}},{"cell_type":"code","source":"# size of the image: 48*48 pixels\npicture_size = 48\n\n# input path for the images\nfolder_path = \"../input/emotion-detection-fer/train\"\n\nexpression = 'sad'\n\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+ '/' +expression+\"/\"+\n                  os.listdir(folder_path+ '/' + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:32.32498Z","iopub.execute_input":"2021-06-22T05:30:32.325728Z","iopub.status.idle":"2021-06-22T05:30:34.028296Z","shell.execute_reply.started":"2021-06-22T05:30:32.325521Z","shell.execute_reply":"2021-06-22T05:30:34.027145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training and Validation Data","metadata":{}},{"cell_type":"code","source":"## Defining different classes of emotion\nnum_classes = 7\n\n## Define image size\nimg_rows,img_cols = 48,48\n\n## Deifne the batch\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:34.029684Z","iopub.execute_input":"2021-06-22T05:30:34.030098Z","iopub.status.idle":"2021-06-22T05:30:34.035853Z","shell.execute_reply.started":"2021-06-22T05:30:34.030036Z","shell.execute_reply":"2021-06-22T05:30:34.034393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n\t\t\t\t\trescale=1./255,\n\t\t\t\t\trotation_range=30,\n\t\t\t\t\tshear_range=0.3,\n\t\t\t\t\tzoom_range=0.3,\n\t\t\t\t\twidth_shift_range=0.4,\n\t\t\t\t\theight_shift_range=0.4,\n\t\t\t\t\thorizontal_flip=True,\n\t\t\t\t\tfill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n\t\t\t\t\ttrain_data_dir,\n\t\t\t\t\tcolor_mode='grayscale',\n\t\t\t\t\ttarget_size=(img_rows,img_cols),\n\t\t\t\t\tbatch_size=batch_size,\n\t\t\t\t\tclass_mode='categorical',\n\t\t\t\t\tshuffle=True)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n\t\t\t\t\t\t\tvalidation_data_dir,\n\t\t\t\t\t\t\tcolor_mode='grayscale',\n\t\t\t\t\t\t\ttarget_size=(img_rows,img_cols),\n\t\t\t\t\t\t\tbatch_size=batch_size,\n\t\t\t\t\t\t\tclass_mode='categorical',\n\t\t\t\t\t\t\tshuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:30:34.037792Z","iopub.execute_input":"2021-06-22T05:30:34.038335Z","iopub.status.idle":"2021-06-22T05:31:11.611542Z","shell.execute_reply.started":"2021-06-22T05:30:34.038294Z","shell.execute_reply":"2021-06-22T05:31:11.610482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"\nmodel = Sequential()\n\n# Block-1\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-2 \n\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-3\n\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-4 \n\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-5\n\nmodel.add(Flatten())\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block-6\n\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block-7\n\nmodel.add(Dense(num_classes,kernel_initializer='he_normal'))\nmodel.add(Activation('softmax'))\n\nprint(model.summary())\n\nfrom keras.optimizers import RMSprop,SGD,Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint('Emotion_little_vgg.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,checkpoint,reduce_lr]\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])\n\nnb_train_samples = 24320\nnb_validation_samples = 3072\nepochs=40\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-22T05:31:11.613308Z","iopub.execute_input":"2021-06-22T05:31:11.613786Z","iopub.status.idle":"2021-06-22T05:31:14.486618Z","shell.execute_reply.started":"2021-06-22T05:31:11.613745Z","shell.execute_reply":"2021-06-22T05:31:14.485592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit_generator(\n                train_generator,\n                steps_per_epoch=nb_train_samples//batch_size,\n                epochs=epochs,\n                callbacks=callbacks,\n                validation_data=validation_generator,\n                validation_steps=nb_validation_samples//batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:31:14.488362Z","iopub.execute_input":"2021-06-22T05:31:14.488861Z","iopub.status.idle":"2021-06-22T06:00:07.059071Z","shell.execute_reply.started":"2021-06-22T05:31:14.488817Z","shell.execute_reply":"2021-06-22T06:00:07.057974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy and Performance","metadata":{}},{"cell_type":"code","source":"plt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T06:00:07.063653Z","iopub.execute_input":"2021-06-22T06:00:07.06397Z","iopub.status.idle":"2021-06-22T06:00:07.484227Z","shell.execute_reply.started":"2021-06-22T06:00:07.063939Z","shell.execute_reply":"2021-06-22T06:00:07.48301Z"},"trusted":true},"execution_count":null,"outputs":[]}]}