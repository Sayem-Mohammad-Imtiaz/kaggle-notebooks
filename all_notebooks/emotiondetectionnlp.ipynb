{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ntext_emotion = pd.read_csv(\"../input/text_emotion.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_emotion.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_emotion = text_emotion.drop('author', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_emotion.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dropping rows with other emotion labels**"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_emotion = text_emotion.drop(text_emotion[text_emotion.sentiment == 'anger'].index)\ntext_emotion = text_emotion.drop(text_emotion[text_emotion.sentiment == 'boredom'].index)\ntext_emotion = text_emotion.drop(text_emotion[text_emotion.sentiment == 'enthusiasm'].index)\ntext_emotion = text_emotion.drop(text_emotion[text_emotion.sentiment == 'empty'].index)\ntext_emotion = text_emotion.drop(text_emotion[text_emotion.sentiment == 'worry'].index)\ntext_emotion = text_emotion.drop(text_emotion[text_emotion.sentiment == 'fun'].index)\ntext_emotion = text_emotion.drop(text_emotion[text_emotion.sentiment == 'relief'].index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making all letters lowercase\ntext_emotion['content'] = text_emotion['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_emotion.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Punctuation, Symbols\ntext_emotion['content'] = text_emotion['content'].str.replace('[^\\w\\s]',' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Stop Words using NLTK\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\ntext_emotion['content'] = text_emotion['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_emotion.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lemmatisation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import Word\ntext_emotion['content'] = text_emotion['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Correcting Letter Repetitions\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef de_repeat(text):\n    pattern = re.compile(r\"(.)\\1{2,}\")\n    return pattern.sub(r\"\\1\\1\", text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_emotion['content'] = text_emotion['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code to find the top 10,000 rarest words appearing in the data\nfreq = pd.Series(' '.join(text_emotion['content']).split()).value_counts()[-10000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing all those rarely appearing words from the data\nfreq = list(freq.index)\ntext_emotion['content'] = text_emotion['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Extraction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding output labels 'happiness' as '0' , 'hate' as '1' , 'love' as '2' , 'neutral' as '3' , 'sadness' as '4' , 'surprise' as '5' ,  'worry' as '6' \nfrom sklearn import preprocessing\nlbl_enc = preprocessing.LabelEncoder()\ny = lbl_enc.fit_transform(text_emotion.sentiment.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting into training and testing data in 90:10 ratio\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(text_emotion.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Term Frequency-Inverse Document Frequency (TF-IDF)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting TF-IDF parameters\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_tfidf = tfidf.fit_transform(X_train)\nX_val_tfidf = tfidf.fit_transform(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting Count Vectors Parameters\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer(analyzer='word')\ncount_vect.fit(text_emotion['content'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_count =  count_vect.transform(X_train)\nX_val_count =  count_vect.transform(X_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training Models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 1: Multinomial Naive Bayes Classifier\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train_tfidf, y_train)\ny_pred = nb.predict(X_val_tfidf)\nprint('naive bayes TF-IDF accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 2: Linear SVM\nfrom sklearn.linear_model import SGDClassifier\nlsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\nlsvm.fit(X_train_tfidf, y_train)\ny_pred = lsvm.predict(X_val_tfidf)\nprint('svm using tfidf accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 3: logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=1)\nlogreg.fit(X_train_tfidf, y_train)\ny_pred = logreg.predict(X_val_tfidf)\nprint('log reg tfidf accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 4: Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=500)\nrf.fit(X_train_tfidf, y_train)\ny_pred = rf.predict(X_val_tfidf)\nprint('random forest tfidf accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**count vectors features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 1: Multinomial Naive Bayes Classifier\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train_count, y_train)\ny_pred = nb.predict(X_val_count)\nprint('naive bayes count vectors accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 2: Linear SVM\nfrom sklearn.linear_model import SGDClassifier\nlsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\nlsvm.fit(X_train_count, y_train)\ny_pred = lsvm.predict(X_val_count)\nprint('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 3: Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=1)\nlogreg.fit(X_train_count, y_train)\ny_pred = logreg.predict(X_val_count)\nprint('log reg count vectors accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 4: Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=500)\nrf.fit(X_train_count, y_train)\ny_pred = rf.predict(X_val_count)\nprint('random forest with count vectors accuracy %s' % accuracy_score(y_pred, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = pd.DataFrame(['I am very happy today! The atmosphere looks cheerful',\n                       'His death broke my heart. It was a sad day',\n                      'I am very happy today!',\n                      'cant fall asleep',\n                      'Happy Mothers Day All my love',\n                      'please to meet you',\n                      'she is crying'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets[0] = tweets[0].str.replace('[^\\w\\s]',' ')\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\ntweets[0] = tweets[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import Word\ntweets[0] = tweets[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting Count Vectors feature from our tweets\ntweet_count = count_vect.transform(tweets[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_pred = logreg.predict(tweet_count)\nprint(tweet_pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}