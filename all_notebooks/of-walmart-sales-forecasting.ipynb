{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align:center;font-size:48pt;color:#f1faee; text-shadow: 0px 0px 8px #101010;\">Walmart Sales Forecasting</h1>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/3o85xBiolEFwFtOw3C/giphy.gif\" width=\"800\" height=\"300\">","metadata":{}},{"cell_type":"code","source":"#Import Important libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nimport plotly.express as px\nfrom fbprophet.plot import plot_plotly, plot_components_plotly\nfrom fbprophet import Prophet\nfrom statsmodels.tsa.seasonal import seasonal_decompose as sd\nimport plotly.graph_objects as go\nimport statsmodels.api as sm\nimport statsmodels.tsa.api as smt\nimport missingno as msno\nfrom sklearn.model_selection import TimeSeriesSplit, train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom datetime import timedelta\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load our data\n\nfeatures = pd.read_csv(\"../input/walmart-sales-prediction/features.csv\", parse_dates=['Date'])\nstores = pd.read_csv(\"../input/walmart-sales-prediction/stores.csv\")\ntrain = pd.read_csv(\"../input/walmart-sales-prediction/train.csv\", parse_dates=['Date'])\ntest = pd.read_csv(\"../input/walmart-sales-prediction/test.csv\", parse_dates=['Date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first 3 rows\n\nprint(features.head(3))\nprint('\\n')\nprint(stores.head(3))\nprint('\\n')\nprint(train.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the dataset shape\n\nprint(features.shape)\nprint(stores.shape) \nprint(train.shape)\nprint(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBRegressor \n\nxgb = XGBRegresssor()\nxgb.fit(X_train_standard, y_train)\n\nplotLMResults(xgb, X_train_standard, X_test_standard)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# stores","metadata":{}},{"cell_type":"code","source":"# Stores Time series\nsts = train.groupby([\"Store\",\"Date\"])[\"Weekly_Sales\"].sum().reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display top rows\nsts.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vsts = sts.groupby([\"Store\"])[\"Weekly_Sales\"].agg([\"sum\",\"mean\"]).reset_index()\nfig = px.bar(vsts, x='Store', y='sum',\n             hover_data=['Store', 'sum', 'mean'], color='mean',\n             labels={'sum':'Weekly Sales'}, height=400)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Walmart weekly sales by Store and Date(Using Plotly)\nfig = go.Figure()\nfor s in sts.Store.unique():\n    fig.add_trace(\n        go.Scatter(\n            x=sts[sts.Store==s].Date,\n            y=sts[sts.Store==s].Weekly_Sales,\n            name=\"Store_\"+str(s)\n        ))\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The highest sales were on Dec/24 and Dec/23, these are thanksgiving holidays.","metadata":{}},{"cell_type":"code","source":"l_sts = pd.DataFrame()\nfor s in sts.Store.unique():\n    df = pd.DataFrame(sts[sts.Store==s])\n    for i in range(26, 54):\n        df[f\"l{i}\"] = df.Weekly_Sales.shift(i)\n    df.dropna(inplace=True)    \n    l_sts = l_sts.append(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_sts = l_sts.set_index(\"Date\")\nl_sts.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sts_train_test_split(l_sts, test_size):\n    train_set = pd.concat([l_sts[l_sts.Store==s].iloc[:-int(test_size*len(l_sts[l_sts.Store==1]))+1] for s in l_sts.Store.unique()])\n    test_set = pd.concat([l_sts[l_sts.Store==s].iloc[-int(test_size*len(l_sts[l_sts.Store==1]))+1:] for s in l_sts.Store.unique()])\n    \n    y_train = train_set.Weekly_Sales\n    X_train = train_set.drop(['Weekly_Sales'], axis=1)\n    \n    y_test = test_set.Weekly_Sales\n    X_test = test_set.drop(['Weekly_Sales'], axis=1)\n    return X_train, X_test, y_train, y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = sts_train_test_split(l_sts, test_size=0.2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standard_scaler = StandardScaler()\nX_train_standard = pd.DataFrame(standard_scaler.fit_transform(X_train)).set_index(X_train.index)\nX_test_standard =  pd.DataFrame(standard_scaler.transform(X_test)).set_index(X_test.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBRegressor()\nxgb.fit(X_train_standard, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = xgb.predict(X_test_standard)\nmatest = X_test.copy()\nmatest[\"Pred_Sales\"] = pred\nmatest[\"Actual_Sales\"] = y_test\nmatest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfor s in range(1,5):\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Pred_Sales,\n            name=\"Store_\"+str(s)+\"_pred\"\n        ))\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Actual_Sales,\n            name=\"Store_\"+str(s)+\"_actual\",\n            line = dict(shape = 'linear', color = 'rgb(255, 12, 24)', width=0.7, dash = 'dash')\n        ))\nerror = mean_absolute_percentage_error(pred, y_test)\nfig.update_layout(\n    title=f\"Mean Absolute Percentage Error: {error:.2f}%\",\n    xaxis_title=\"weeks\",\n    yaxis_title=\"sales\",\n    yaxis_tickprefix = '$',\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"RebeccaPurple\"\n    ))\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store = tdf.groupby([\"Store\",\"Size\",\"Type\"])[\"Weekly_Sales\"].sum().reset_index()\n\n\nfig = px.bar(store, x='Store', y=\"Weekly_Sales\",\n             hover_data=['Store', 'Weekly_Sales'], color='Type',height=400, title=\"Weekly_Sales by Store Type\")\nfig.show()\n\n\nfig = px.bar(store, x='Store', y=\"Weekly_Sales\",\n             hover_data=['Store', 'Size'], color='Size', height=400, title=\"Weekly_Sales by Store Size\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lxgb_sts = pd.DataFrame()\nfor s in sts.Store.unique():\n    df = pd.DataFrame(sts[sts.Store==s]).set_index(\"Date\")\n    for i in range(26, 54):\n        df[f\"l{i}\"] = df.Weekly_Sales.shift(i)\n    \n    df.dropna(inplace=True)    \n    lxgb_sts = lxgb_sts.append(df)\n    \nfor i in range(0,12):\n        lxgb_sts[f\"h{i}\"] = lxgb_sts.index.map(lambda x: holidays[x-timedelta(weeks=i)])\n        lxgb_sts[f\"t{i}\"] = lxgb_sts.index.map(lambda x: temperature[x-timedelta(weeks=i)])\n        lxgb_sts[f\"f{i}\"] = lxgb_sts.index.map(lambda x: fuel_price[x-timedelta(weeks=i)])\n        \nlxgb_sts[\"Size\"] = lxgb_sts.Store.map(lambda x: store[store.Store==x][\"Size\"].item())\nlxgb_sts[\"Type\"] = lxgb_sts.Store.map(lambda x: store[store.Store==x][\"Type\"].item()).astype('category').cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = sts_train_test_split(lxgb_sts, test_size=0.2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standard_scaler = StandardScaler()\nX_train_standard = pd.DataFrame(standard_scaler.fit_transform(X_train)).set_index(X_train.index)\nX_test_standard =  pd.DataFrame(standard_scaler.transform(X_test)).set_index(X_test.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBRegressor()\nxgb.fit(X_train_standard, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = xgb.predict(X_test_standard)\nmatest = X_test.copy()\nmatest[\"Pred_Sales\"] = pred\nmatest[\"Actual_Sales\"] = y_test\nmatest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfor s in range(1,5):\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Pred_Sales,\n            name=\"Store_\"+str(s)+\"_pred\"\n        ))\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Actual_Sales,\n            name=\"Store_\"+str(s)+\"_actual\",\n            line = dict(shape = 'linear', color = 'rgb(255, 12, 24)', width=0.7, dash = 'dash')\n        ))\nerror = mean_absolute_percentage_error(pred, y_test)\nfig.update_layout(\n    title=f\"Mean Absolute Percentage Error: {error:.2f}%\",\n    xaxis_title=\"weeks\",\n    yaxis_title=\"sales\",\n    yaxis_tickprefix = '$',\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"RebeccaPurple\"\n    ))\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}