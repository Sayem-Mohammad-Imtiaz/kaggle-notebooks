{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing Necessary Library","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport textwrap\n\n%matplotlib inline\nplt.rcParams['figure.figsize']=10,6\nplt.rcParams['axes.grid']=True\nplt.gray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the Data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"des = pd.read_csv('/kaggle/input/chai-time-data-science/Description.csv')\nepsd = pd.read_csv('/kaggle/input/chai-time-data-science/Episodes.csv')\nytb = pd.read_csv('/kaggle/input/chai-time-data-science/YouTube Thumbnail Types.csv')\nanchor = pd.read_csv('/kaggle/input/chai-time-data-science/Anchor Thumbnail Types.csv')\n\nprint('Description_shape...'+str(des.shape))\nprint('Episode_shape...'+str(epsd.shape))\nprint('Youtube_shape...'+str(ytb.shape))\nprint('Thumbail_shape...'+str(anchor.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the Description and Episode tabel","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"des.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we are checking the porfile report the episode the table\n- From the profile report we can get the whole summary of the data such as missing value,interation ,correlation etc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas_profiling import ProfileReport\nprof = ProfileReport(epsd)\nprof.to_file(output_file='Episode.html')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prof","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can clearly see the distribution,correlation missing etc for episode data set\n- this will help us in understanding the overview of the dataset of we are going to work","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Necessary funtions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Genersting the pie chart\ndef pie_chart(df,col,path):\n  label = df[col].value_counts().index.tolist()\n  fig = plt.figure(figsize=(10,6))\n  ax = (df[col].value_counts()*100.0 /len(df))\\\n  .plot.pie(startangle=90,autopct='%.1f%%', labels =label, fontsize=12)                                                                           \n  ax.set_title('% '+str(col))\n  # plt.savefig(path+str(col1)+'.png')\n  plt.show()\n\n# Relation between categorical variable\ndef categorical_summarized(path,dataframe, x=None, y=None, hue=None,palette='Set1', verbose=True):\n    '''\n    Helper function that gives a quick summary of a given column of categorical data\n    Arguments\n    =========\n    dataframe: pandas dataframe\n    x: str. horizontal axis to plot the labels of categorical data, y would be the count\n    y: str. vertical axis to plot the labels of categorical data, x would be the count\n    hue: str. if you want to compare it another variable (usually the target variable)\n    palette: array-like. Colour of the plot\n    Returns\n    =======\n    Quick Stats of the data and also the count plot\n    '''\n    if x == None:\n        column_interested = y\n    else:\n        column_interested = x\n    series = dataframe[column_interested]\n    print(series.describe())\n    print('mode: ', series.mode())\n    if verbose:\n        print('='*80)\n        print(series.value_counts())\n\n    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)\n    plt.xlabel(str(x),Weight='bold',fontsize=12)\n    plt.ylabel(\"Count\",weight='bold',fontsize=12)\n    if x== None:\n        plt.title('Relation_between'+str(y)+'_'+'and'+'_'+str(hue))\n#         g= plt.savefig(path+str(y)+'_'+str(hue)+'.png')\n        labels = dataframe[column_interested].value_counts().index.tolist()\n        labels.sort()\n        labels=[textwrap.fill(text,10) for text in labels]\n        pos = np.arange(len(labels)) \n        plt.yticks(pos, labels)\n    else:\n        plt.title('Relation_between'+'_'+str(x)+'_'+'and'+'_'+str(hue),weight='bold',fontsize=14)\n#         g= plt.savefig(path+str(x)+'_'+str(hue)+'.png')\n        labels = dataframe[column_interested].value_counts().index.tolist()\n        labels.sort()\n        labels=[textwrap.fill(text,10) for text in labels]\n        pos = np.arange(len(labels)) \n        plt.xticks(pos, labels)\n        plt.legend(loc='upper right')\n    plt.show()\n\n # This helper fucntion help to find relation between categorical and numerical variable and visualize stack chart   \ndef stack_plot_sum(df,x_axis,y_axis,hue,title,path):\n  t1 = df.groupby([x_axis,hue])[[y_axis]].count().add_prefix('sum_of_').reset_index()\n  t2 = t1.pivot(x_axis,hue,'sum_of_'+y_axis)\n  ax = t2.plot(kind='bar',stacked=True)\n  plt.xticks(rotation=90)\n#   ax.legend([\"Not_Fraud\", \"Fraud\"])\n  plt.xlabel(str(x_axis),fontweight =\"bold\",fontsize=14)\n  plt.ylabel('Frequency',fontweight =\"bold\",fontsize=14)\n  plt.title(title,fontweight =\"bold\",fontsize=16)\n  # plt.savefig(path+title+'.png')\n  plt.show()\n\n    \n# Relation between the categorical variable    \ndef rel_cat(df,x_axis,y_axis,path,stacked=None):\n    temp =pd.crosstab(df[x_axis],df[y_axis])\n    temp.plot(kind='bar',stacked=stacked,grid=False)\n    plt.xlabel(str(x_axis),weight='bold',fontsize=12)\n    plt.ylabel(str(y_axis),weight='bold',fontsize=12)\n    plt.title(str(x_axis)+'_'+'and'+'_'+str(y_axis),weight='bold',fontsize=14)\n    plt.xticks(rotation=0,fontsize=12)\n    plt.yticks(fontsize=12)\n    labels = df[x_axis].value_counts().index.tolist()\n    labels.sort()\n    labels=[textwrap.fill(text,10) for text in labels]\n    pos = np.arange(len(labels)) \n    plt.xticks(pos, labels)\n#     plt.legend()\n#     plt.savefig(path+str(x_axis)+'_'+'and'+'_'+str(y_axis)+'.jpg')    \n    plt.show()\n    \n\n# Helper fucntion helps to find the relation between the categorical and numerical variable\ndef rel_num_cat(df,x_axis,y_axis,palette,path):\n    t =df.groupby([x_axis])[y_axis].sum().reset_index()\n    heroes = t.sort_values(by=y_axis,ascending=False)[:20].reset_index(drop=True)\n#     heroes\n\n    fig,ax = plt.subplots(figsize=(18,6))\n    g= sns.barplot(x=heroes['heroes'],y=heroes[y_axis],data=heroes,ax=ax,palette=palette)\n    plt.xlabel(str(x_axis),weight='bold',fontsize=12)\n    plt.ylabel(str(y_axis),weight='bold',fontsize=12)\n    plt.title('Number of '+str(y_axis)+'_'+'for_each'+'_'+str(x_axis),weight='bold',fontsize=14)\n    plt.xticks(rotation=0)\n    for index, row in heroes.iterrows():\n        g.text(row.name,row[1], round(row[1]), color='black', ha=\"center\")\n    labels = heroes[x_axis].tolist()\n    # labels.sort()\n    labels=[textwrap.fill(text,10) for text in labels]\n    pos = np.arange(len(labels)) \n    plt.xticks(pos, labels)\n#     plt.savefig('Number of '+str(y_axis)+ 'for each'+ str(x_axis)+'.jpg')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We can seet the datastype of each variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Distribution of the Heroes based on Gender","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pie_chart(epsd,'heroes_gender',8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Here male heroes are much more the female ML heroes*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Distribution of category ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pie_chart(epsd,'category',8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Here Kaggle and Industry covers more than 75% of the category","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Distribuition of the Flavour tea used in the eahc Episodes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pie_chart(epsd,'flavour_of_tea',8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Ginger Chai,Masala chai,Sulemani Chai,Herbal chai and Kesar Rose chai are mostly used in the Episodes> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.set_style(\"white\")\nsns.countplot(y=epsd['heroes_nationality'],data=epsd,palette='winter')\nplt.xlabel('Count',weight='bold',fontsize=12)\nplt.ylabel('Heros_Nationality',weight='bold',fontsize=12)\nplt.title('Count of Heros from different Nationality',weight='bold',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most ML Heroes are from India,USA,Canada,Germany,Russia and France","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10,6))\nsns.countplot(y=epsd['recording_time'],data=epsd,palette='winter_r',ax=ax)\nplt.xlabel('Count',weight='bold',fontsize=12)\nplt.ylabel('Recording_time',weight='bold',fontsize=12)\nplt.title('Count of recoding time',weight='bold',fontsize=14)\nfor p in ax.patches:\n    width = p.get_width()\n    ax.text(width+1.,\n            p.get_y()+p.get_height()/3. + 0.2,\n            '{:1.2f}'.format(width),\n            ha=\"center\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Most of the Recordings the happen at Night","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"c_palette = ['tab:blue', 'tab:orange','tab:green','tab:red']\ncategorical_summarized(8,epsd,x='category',hue='heroes_gender',palette='winter')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is showing that CTDS  dosen't have female Kaggler and it having very less count of female in other category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_cat(epsd,'flavour_of_tea','recording_time',8,stacked=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kesar Rose Chai are mostly have in the night and on the other hand, masala tea are have during the morning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=18,6\nrel_cat(epsd,'heroes_nationality','category',8,stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=18,6\ncategorical_summarized(8,epsd,x='flavour_of_tea',hue='heroes_gender',palette='winter')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ginger tea , Apple Cinnamon, Masala Chai, Paan Rose Green Tea are mostly have by Males Heroes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_summarized(8,epsd,x='flavour_of_tea',hue='category',palette='Blues_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ginger tea are mostly have by the Kaggler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"t =epsd.groupby(['heroes'])['youtube_subscribers'].sum().reset_index()\nheroes = t.sort_values(by='youtube_subscribers',ascending=False)[:10].reset_index(drop=True)\nheroes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t =epsd.groupby(['heroes'])['youtube_subscribers'].sum().reset_index()\nheroes = t.sort_values(by='youtube_subscribers',ascending=False)[:20].reset_index(drop=True)\nheroes\n\nfig,ax = plt.subplots(figsize=(18,6))\ng= sns.barplot(x=heroes['heroes'],y=heroes['youtube_subscribers'],data=heroes,ax=ax,palette='Blues_r')\nplt.xlabel('Heros',weight='bold',fontsize=12)\nplt.ylabel('youtube_subscribers',weight='bold',fontsize=12)\nplt.title('Number of Subscribers for each Heroes',weight='bold',fontsize=14)\nplt.xticks(rotation=0)\nfor index, row in heroes.iterrows():\n    g.text(row.name,row.youtube_subscribers, round(row.youtube_subscribers), color='black', ha=\"center\")\nlabels = heroes['heroes'].tolist()\n# labels.sort()\nlabels=[textwrap.fill(text,10) for text in labels]\npos = np.arange(len(labels)) \nplt.xticks(pos, labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Showing the top 20 kaggler having subscribers and \n> Jeremy Howard having most number of subscribers than other\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=10,6\nrel_cat(epsd,'recording_time','category',8,stacked=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Industry having most of ther recording at night where as the Kagglers having recording at afternoon, Evening, Morning and Night","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=18,6\ncategorical_summarized(8,epsd,x='recording_time',hue='category',palette='BuPu_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = epsd['episode_id']\ny= epsd['episode_duration']\n\n# Color palette\nblue, = sns.color_palette(\"muted\", 1)\n\n# Make the plot\nfig,ax = plt.subplots(figsize=(24,8))\nax.plot(x, y, color=blue, lw=3)\nax.fill_between(x, 0, y, alpha=.3)\nax.set(xlim=(0, len(x)-1), ylim=(0, None), xticks=x)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','spotify_starts','winter',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','anchor_plays','brg',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','youtube_likes','hsv',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','youtube_watch_hours','gnuplot',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_epd = epsd\ndata_epd['avg_duration']=  data_epd['youtube_watch_hours']*60/ data_epd['youtube_views']\nrel_num_cat(data_epd,'heroes','avg_duration','twilight_shifted',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','youtube_nonimpression_views','Blues_r',8)\n# Jeremy Howard and Parul having  youtube non impression views","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','youtube_impression_views','winter',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','youtube_dislikes','Spectral',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_num_cat(epsd,'heroes','youtube_subscribers','Spectral',8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t1 = epsd.groupby(['episode_name','category'])[['youtube_ctr']].sum().add_prefix('sum_of_').reset_index()\nt1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,6))\nsns.lineplot(x='episode_name',y='sum_of_youtube_ctr',hue='category',data=t1)\nplt.xticks(rotation=90)\nplt.show()\n\n# Episode wise category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsd['spotify_listeners'].plot()\nepsd['apple_listeners'].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets Work on description dataset so that we can get some information ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"des.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nimport re\n# Tutorial about Python regular expressions: https://pymotw.com/2/re/ import string\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport random\nimport string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\ndef text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(tokenized_text)\n    return combined_text\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying the cleaning function to both Descriptions datasets\ndes['text_clean'] = des['description'].apply(str).apply(lambda x: text_preprocessing(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyzing Text statistics\n\ndes['text_len'] = des['text_clean'].astype(str).apply(len)\ndes['text_word_count'] = des['text_clean'].apply(lambda x: len(str(x).split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=10,6\nsns.distplot(des['text_len'],color='red')\nplt.xlabel('text_len',weight='bold',fontsize=12)\nplt.ylabel('Count',weight='bold',fontsize=12)\nplt.title('Distribution of description',weight='bold',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#source of code : https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d\ndef get_top_n_words(corpus, n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of top unigrams\ndes_unigrams = get_top_n_words(des['text_clean'],20)\n\ndf1 = pd.DataFrame(des_unigrams, columns = ['Text' , 'count'])\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).plot(kind='barh',color='g')\nplt.ylabel('words',weight='bold',fontsize=12)\nplt.xlabel('Counts',weight='bold',fontsize=12)\nplt.title('Top 20 unigrams in description text',weight='bold',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_n_gram(corpus,ngram_range,n=None):\n    vec = CountVectorizer(ngram_range=ngram_range,stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of top Bigrams\ndes_bigrams = get_top_n_gram(des['text_clean'],(2,2),20)\n\ndf1 = pd.DataFrame(des_bigrams, columns = ['Text' , 'count'])\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).plot(kind='barh',color='r',alpha=0.5)\nplt.ylabel('words',weight='bold',fontsize=12)\nplt.xlabel('Counts',weight='bold',fontsize=12)\nplt.title('Top 20 bigrams in description text',weight='bold',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution of top Trigrams\ndes_trigrams = get_top_n_gram(des['text_clean'],(3,3),20)\n\ndf1 = pd.DataFrame(des_trigrams, columns = ['Text' , 'count'])\ndf1.groupby('Text').sum()['count'].sort_values(ascending=True).plot(kind='barh',color='b',alpha=0.5)\nplt.ylabel('words',weight='bold',fontsize=12)\nplt.xlabel('Counts',weight='bold',fontsize=12)\nplt.title('Top 20 trigrams in description text',weight='bold',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#source of code : https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d\ndef get_top_n_words(corpus, n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_words_in_description_text = get_top_n_words(des['text_clean'])\n\np1 = [x[0] for x in top_words_in_description_text[:20]]\np2 = [x[1] for x in top_words_in_description_text[:20]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top Descriptions word\nsns.barplot(x=p2,y=p1,palette='winter')\n# plt.xticks(rotation=45)\nplt.yticks(fontsize=12)\nplt.ylabel('Words',weight='bold',fontsize=12)\nplt.xlabel('Counts',weight='bold',fontsize=12)\nplt.title('Top 20 description Words',weight='bold',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nfig,ax = plt.subplots(figsize=[40,30])\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(des['text_clean']))\nax.imshow(wordcloud1)\nax.axis('off')\nax.set_title('Descriptions text',fontsize=20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reference: https://www.kaggle.com/parulpandey/how-to-explore-the-ctds-show-data,\n           https://www.kaggle.com/vpkprasanna/insights-on-chai-time-data-science","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}