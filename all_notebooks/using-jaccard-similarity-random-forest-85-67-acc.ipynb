{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement","metadata":{}},{"cell_type":"markdown","source":"1. We are given a dataset consisting of two csv files train_bodies.csv which contains the set of news articles bodies,while train-stances.csv resembles the articles for each of these bodies being identified using the body id.\n\n2. After training from these samples we need to detect whether the given headline agrees,disagrees,discusses,unrelated with the body id\n","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport numpy as np\n\nfrom nltk.corpus import stopwords\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset","metadata":{}},{"cell_type":"code","source":"DATASET_PATH = \"../input/fake-news-challenge/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(DATASET_PATH))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**train_bodies.csv** contains body id and article body for training  \n**train_stances.csv** contains headlines corresponding to body id and associated labelled stance with it\n","metadata":{}},{"cell_type":"code","source":"train_bodies = pd.read_csv(os.path.join(DATASET_PATH,'train_bodies.csv'))\ntrain_bodies.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The number of rows ',train_bodies.shape[0])\nprint('The number of columns',train_bodies.shape[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_bodies.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_stance = pd.read_csv(os.path.join(DATASET_PATH,'train_stances.csv'))\ntrain_stance.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The number of rows ',train_stance.shape[0])\nprint('The number of columns',train_stance.shape[1])","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_stance.info()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the output signifies that each body id is associated to multiple headlines\ntrain_stance['Body ID'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset understanding \n\n1. The train_bodies contain the entries for the body id and associated article Body\n2. The train_stances contain the entries for the headlines associated with the particular body id and its labelled stance\n3. One body present in train_bodies can have multiple associated headlines present in train_stances and it's corresponding stance label\n4. 1683 :- Number of article Body present\n5. 49972 number of total headlines present for the 1683 different article body","metadata":{}},{"cell_type":"markdown","source":"# Combining the CSV\n\nI am preparing a final csv in each row will correspond to a unique entry\ni.e each row will correspond to a unique combination of headline,bodyid and article body \n\nThe above is needed for making simplicity in further data preparation steps we need to execute\n","metadata":{}},{"cell_type":"code","source":"#Run commented code to combine the two csv file{train_bodies.csv,train_stances.csv} into data_combined.csv file\nfrom tqdm.notebook import tqdm\ncount=0\nfor i in tqdm(range(train_stance.shape[0])):\n    for j in range(train_bodies.shape[0]):\n        if train_bodies.loc[j,'Body ID']==train_stance.loc[i,'Body ID']:\n            train_stance.loc[i,'articleBody'] = train_bodies.loc[j,'articleBody']\n#     if i%100==0:\n#         count+=1\n#         print(count,end=' ')\n\ntrain_stance.to_csv('data_combined.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('data_combined.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['stance_cat'] = data['Stance'].map({'agree':0,'disagree':1,'discuss':2,'unrelated':3}).astype(int)\ndata['Stance'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"stopwords_english = set(stopwords.words('english'))\ndata['Headline'] = data.Headline.apply(lambda x:str(x))\ndata.loc[:,'Headline'] = data['Headline'].apply(lambda x : str.lower(x))\ndata.loc[:,'Headline'] = data['Headline'].apply(lambda x:' '.join(re.findall('[\\w]+',x)))\ndata.loc[:,'articleBody'] = data['articleBody'].apply(lambda x : str.lower(x))\ndata.loc[:,'articleBody'] = data['articleBody'].apply(lambda x:' '.join(re.findall('[\\w]+',x)))\n\n\ndef remove_stopwords(s):\n    return ' '.join(word for word in s.split() if word not in stopwords_english)\n\ndata['Headline'] = data['Headline'].apply(lambda x:remove_stopwords(x))\ndata['articleBody'] = data['articleBody'].apply(lambda x:str(x))\ndata['articleBody'] = data['articleBody'].apply(lambda x:remove_stopwords(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline Model For Two Class","metadata":{}},{"cell_type":"markdown","source":"### Creating the two class dataset of related/unrelated\n\n\nFor a baseline classification we are simplifying the classification problem to a two class classification by first taking only strong divergent classes related/unrelated ","metadata":{}},{"cell_type":"code","source":"data['stance_base'] = data.loc[data.loc[:,'Stance']=='unrelated','Stance']\ndata['stance_base'] = data['stance_base'].fillna(\"related\")\nprint(data['stance_base'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard_similarity(list1, list2):\n    s1 = set(list1)\n    s2 = set(list2)\n    return len(s1.intersection(s2)) / len(s1.union(s2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_jaccard_similarity(data):\n    count=0\n    for i in tqdm(range(data.shape[0])):\n        jaccard_lis=[];eps=0.001\n        sentence = data.loc[i,'articleBody'].split('.') #per sentence scorer\n        for j in range(len(sentence)):\n            jaccard_lis.append(jaccard_similarity(data.loc[i,'Headline'].split(' '),sentence[j].split(' ')))\n        max_jaccard_similarity = max(jaccard_lis)\n        avg_jaccard_similarity = sum(jaccard_lis)/len(jaccard_lis)\n        min_jaccard_similarity = min(jaccard_lis)\n        data.loc[i,'jaccard_similarity'] = (max_jaccard_similarity+min_jaccard_similarity)/(max_jaccard_similarity-min_jaccard_similarity+eps)\n#         if i%1000==0:\n#             count+=1\n#             print(\"Processed {0} Headlines\".format(count*1000))\nadd_jaccard_similarity(data)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classifying Two Classes Related/Unrelated\n\n","metadata":{}},{"cell_type":"code","source":"data['stance_base'].value_counts()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing Data for Classification","metadata":{}},{"cell_type":"code","source":"x = data.iloc[:,-1]\ny = data['stance_base']\n\n\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1)\n\nrg = RandomForestClassifier(n_estimators=100,n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('X Training shape',xtrain.shape)\nprint('Y Training shape',ytrain.shape)\nxtrain = xtrain.values.reshape(-1,1)\nxtest = xtest.values.reshape(-1,1)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rg.fit(xtrain,ytrain)\nypred = rg.predict(xtest)\n\nprint('Accuracy score on two class agree and disagree ',accuracy_score(ypred,ytest))\n\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(ypred,ytest)\nprint('Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(ypred,ytest,average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(ypred,ytest,average='weighted')\nprint('Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(ypred,ytest,average='weighted')\nprint('F1 score: %f' % f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Four Class Classification\n\nWe are now doing the four class classification into categories \n\n1. unrelated  \n2. discuss  \n3. agree  \n4. disagree  \n","metadata":{}},{"cell_type":"code","source":"data['Stance'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data.iloc[:,-1]\ny = data['Stance']\n\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1)\n\nrg = RandomForestClassifier(n_estimators=100,n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('X Training shape',xtrain.shape)\nprint('Y Training shape',ytrain.shape)\nxtrain = xtrain.values.reshape(-1,1)\nxtest = xtest.values.reshape(-1,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rg.fit(xtrain,ytrain)\nypred = rg.predict(xtest)\n\n\n# print('Accuracy score on Four class {agree,disagree,discuss,unrelated}',accuracy_score(ypred,ytest))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(ypred,ytest)\nprint('Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(ypred,ytest,average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(ypred,ytest,average='weighted')\nprint('Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(ypred,ytest,average='weighted')\nprint('F1 score: %f' % f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Please upvote the notebook if you found it usefull**  \nThanks ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}