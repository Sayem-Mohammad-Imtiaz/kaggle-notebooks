{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Melanoma Classification\n\nKaggle Competition Page: www.kaggle.com/c/siim-isic-melanoma-classification/overview\n","metadata":{"id":"XvBDTao8djYJ"}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">  \n<b> Imports.  </b>\n</div>","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom pathlib import Path\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.applications.nasnet import NASNetMobile, NASNetLarge\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,GlobalAveragePooling2D,AveragePooling2D\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, date\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\nimport json\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, confusion_matrix\nimport itertools\nfrom tqdm import tqdm\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nprint(\"IMPORTS DONE\")","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-10T09:46:16.137713Z","iopub.execute_input":"2021-09-10T09:46:16.138108Z","iopub.status.idle":"2021-09-10T09:46:20.787365Z","shell.execute_reply.started":"2021-09-10T09:46:16.138019Z","shell.execute_reply":"2021-09-10T09:46:20.78561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">  \n<b> Functions.  </b>\n</div>","metadata":{}},{"cell_type":"code","source":"def check_image(path_to_images, fileName):\n    absolutePath = path_to_images + fileName + IMAGE_TYPE\n    img_file = Path(absolutePath)\n    if img_file.is_file():\n        return absolutePath\n    return False\n\ndef load_data(path_to_images, csv_path, mode):\n    print(\"Loading \" + mode)\n    data = pd.read_csv(csv_path)\n    data['image_path'] = data['image_name'].apply(lambda img_name: check_image(path_to_images, img_name))\n    data = data[data['image_path'] != False]\n    print(\"valid rows in \" + mode, data.shape[0])\n    return data\n\ndef getTrainData(img_pixels):\n    if img_pixels == 224:\n        global train_224_backup\n        if train_224_backup is not None:\n            return train_224_backup.copy()\n    elif img_pixels == 331:\n        global train_331_backup\n        if train_331_backup is not None:\n            return train_331_backup.copy()\n    else:\n        raise \n    path_to_images = BASE_PATH_TO_IMAGES + str(img_pixels) + \"/train/\"\n    csv_path = os.path.join(BASE_INPUT_PATH, \"train.csv\")\n    data = load_data(path_to_images, csv_path, \"train\")\n    \n    if img_pixels == 224:\n        train_224_backup = data.copy()\n    elif img_pixels == 331:\n        train_331_backup = data.copy()\n    return data\n    \ndef getTestData(img_pixels):\n    if img_pixels == 224:\n        global test_224_backup\n        if test_224_backup is not None:\n            return test_224_backup.copy()\n    elif img_pixels == 331:\n        global test_331_backup\n        if test_331_backup is not None:\n            return test_331_backup.copy()\n    else:\n        raise \n    path_to_images = BASE_PATH_TO_IMAGES + str(img_pixels) + \"/test/\"\n    csv_path = os.path.join(BASE_INPUT_PATH, \"test.csv\")\n    data = load_data(path_to_images, csv_path, \"test\")\n    \n    if img_pixels == 224:\n        test_224_backup = data.copy()\n    elif img_pixels == 331:\n        test_331_backup = data.copy()\n    return data\n\ndef doUndersampling(dataset, balance = 1):\n#     print(dataset[dataset.target == POSITIVE_CLASS].shape, \"positive in dataset\")\n#     print(dataset[dataset.target == NEGATIVE_CLASS].shape, \"negative in dataset\")\n    p_inds = dataset[dataset.target == POSITIVE_CLASS].index.tolist()\n    np_inds = dataset[dataset.target == NEGATIVE_CLASS].index.tolist()\n    sample_size = int(balance * len(p_inds))\n    np_sample = random.sample(np_inds, sample_size) if sample_size < len(np_inds) else np_inds\n    returndataset = dataset.loc[p_inds + np_sample]\n#     print(returndataset[returndataset.target == POSITIVE_CLASS].shape, \"positive after under\")\n#     print(returndataset[returndataset.target == NEGATIVE_CLASS].shape, \"negative after under\")\n    return returndataset\n    \ndef trainTestPatientCheck(train,test):\n    ids_train = set(train.patient_id.values)\n    ids_test = set(test.patient_id.values)\n    patient_overlap = list(ids_train.intersection(ids_test))\n    n_overlap = len(patient_overlap)\n\n\ndef timestamp_and_experimentId(model_name, do_undersampling, prepro, prepro_rotation, prepro_blur, prepro_brightness, prepro_zoom, batch_size, epochs, base_model_trainable):\n    timestamp = str(date.today()) + \"_\" + str(datetime.now().strftime(\"%H:%M:%S\"))\n    experiment_id = model_name + (\"_Under\" if do_undersampling else \"_CW\") + (\"_PreFlips\" if prepro else \"\") + (\"Rot\" if prepro_rotation else \"\") + (\"Bright\" if prepro_brightness else \"\")\n    experiment_id = experiment_id + (\"Blur\" if prepro_blur else \"\") + (\"Zoom\" if prepro_zoom else \"\")\n    experiment_id = experiment_id +\"_\"+ str(batch_size) + \"B_\" + str(epochs) + \"E_\" + (\"FineTuning\" if base_model_trainable else \"Extractor\")\n    try:\n        os.makedirs(experiment_id)\n        open(\"./\" +experiment_id+\"/\" + timestamp, 'w').close()\n    except FileExistsError:\n        pass\n    return (timestamp, experiment_id)\n    \n\ndef create_splits(df, test_size, classToPredict):\n    train_data, val_data = train_test_split(df,  test_size = test_size, random_state = SEED, stratify = df[classToPredict])\n    return train_data, val_data\n\ndef preprocess_rotation(image):\n    if bool(random.getrandbits(1)):\n        image = np.rot90(image, np.random.choice([-1, 1, 2]))\n    return image\n\ndef preprocess_blur(image):\n    if bool(random.getrandbits(1)):\n        image = cv2.blur(image,(3,3))\n    return image\n\ndef preprocess_both(image):\n    if bool(random.getrandbits(1)):\n        image = np.rot90(image, np.random.choice([-1, 1, 2]))\n    if bool(random.getrandbits(1)):\n        image = cv2.blur(image,(3,3))\n    return image\n \ndef get_training_gen(df, prepro, prepro_brightness, prepro_zoom, prepro_rotation, prepro_blur, batch_size, img_size, doShuffle = True):\n    if not prepro:\n        train_idg = ImageDataGenerator(rescale=1. / 255.0)\n    else:    \n        brightnessRange = [0.75,1] if prepro_brightness else None\n        zoomRange = [0.75,1] if prepro_zoom else 0.0\n        if(prepro_rotation and prepro_blur):\n            prepro_function = preprocess_both\n        elif prepro_rotation:\n            prepro_function = preprocess_rotation\n        elif prepro_blur:\n            prepro_function = preprocess_blur\n        else:\n            prepro_function = None\n        train_idg = ImageDataGenerator(\n            rescale = 1 / 255.0,\n            horizontal_flip = True,\n            vertical_flip = True,\n            brightness_range = brightnessRange,\n            zoom_range = zoomRange,\n            preprocessing_function=prepro_function\n        )\n\n    train_gen = train_idg.flow_from_dataframe(\n        seed=SEED,\n        dataframe=df,\n        directory=None,\n        x_col='image_path',\n        y_col='target',\n        class_mode=CLASS_MODE,\n        shuffle=doShuffle,\n        target_size=img_size,\n        batch_size=batch_size,\n        validate_filenames = False\n    )\n\n    return train_gen\n\ndef get_validation_gen(df, batch_size, img_size):\n    val_idg = ImageDataGenerator(rescale=1. / 255.0)\n    val_gen = val_idg.flow_from_dataframe(\n        seed=SEED,\n        dataframe=df,\n        directory=None,\n        x_col='image_path',\n        y_col='target',\n        class_mode=CLASS_MODE,\n        shuffle=False,\n        target_size=img_size,\n        batch_size=batch_size,\n        validate_filenames = False\n    )\n\n    return val_gen\n\ndef create_model(base_model, base_model_trainable, model_name):\n    model_length = len(base_model.layers)\n    trainable_layers = 100\n    end_index = model_length if (not base_model_trainable) else (int(model_length-trainable_layers) if model_length>50 else 0)\n    for layer in base_model.layers[0:end_index]:\n        layer.trainable = False\n    model = Sequential()\n    model.add(base_model)\n    if model_name == \"nasnetlarge\":\n        model.add(GlobalAveragePooling2D())\n    else:\n        model.add(AveragePooling2D((2), name='avg_pool'))\n        model.add(layers.Flatten())\n    model.add(layers.Dense(64, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform()))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Dense(16, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform()))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Dense(OUTPUT_NEURONS, activation='sigmoid', kernel_initializer=tf.keras.initializers.GlorotUniform()))\n    return model\n\ndef earlyStoppingPatienteCalculator(do_undersampling, base_model_trainable):\n    argument = (not do_undersampling) + base_model_trainable\n    switcher = {\n        0: 15,\n        1: 10,\n        2: 7\n    }\n    return switcher.get(argument, \"Invalid data for early stopping\")\n\ndef save_history(history, timestamp, base_output_path):\n    f = plt.figure()\n    f.set_figwidth(15)\n    f.add_subplot(1, 2, 1)\n    plt.plot(history['val_loss'], label='val loss')\n    plt.plot(history['loss'], label='train loss')\n    plt.legend()\n    plt.title(\"Model Loss\")\n    f.add_subplot(1, 2, 2)\n    plt.plot(history['val_accuracy'], label='val accuracy')\n    plt.plot(history['accuracy'], label='train accuracy')\n    plt.legend()\n    plt.title(\"Model Accuracy\")\n    if SAVE_OUTPUT:\n        length = len(history[\"loss\"])-1\n        metrics = [\"loss\", \"accuracy\",\"auc\",\"val_loss\", \"val_accuracy\",\"val_auc\"]\n        f = open(base_output_path + \"2finalResults.txt\", \"a\")\n        for metric in metrics:\n            metricValue = round(history[metric][length],4)\n            f.write(metric + \":\" + str(metricValue) + (\"\\n\\n\" if metric == \"auc\" else \"\\n\"))\n        f.close()\n        plt.savefig(base_output_path + \"2history.png\")\n        with open(base_output_path + \"2history.json\", 'w') as f:\n            json.dump(history, f)\n            \ndef plot_auc(y_true_classes, y_pred_probs, base_output_path):\n    fpr, tpr, thresholds = roc_curve(y_true_classes, y_pred_probs, pos_label=1)\n    fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % ('Target', auc(fpr, tpr)))\n    c_ax.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    plt.savefig(base_output_path + \"5auc.png\")\n\n\ndef calc_f1(prec, recall):\n    return 2*(prec*recall)/(prec+recall) if recall and prec else 0\n\ndef plot_confusion_matrix(cm, labels, base_output_path):\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(labels))\n    plt.xticks(tick_marks, labels, rotation=55)\n    plt.yticks(tick_marks, labels)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    if SAVE_OUTPUT:\n        plt.savefig(base_output_path + \"4confMatrix.png\")\n        \n        \n\ndef createSubmissionFile(model, dataset, img_size, filePath):\n    data=[]\n    rangeValue = dataset.shape[0] if not fast_run else 50\n    for i in tqdm(range(rangeValue)):\n        image_path = dataset.iloc[i].image_path\n        image_name = dataset.iloc[i].image_name\n        img = tf.keras.preprocessing.image.load_img(image_path, target_size=img_size)\n        img = tf.keras.preprocessing.image.img_to_array(img)\n        img = img / 255\n        img_array = tf.expand_dims(img, 0)\n        pred = model.predict(img_array)\n        y_pred_prob = round(pred[0][0],4)\n        data.append([image_name, y_pred_prob])\n    sub_df = pd.DataFrame(data, columns = ['image_name', 'target']) \n    sub_df.to_csv(filePath, index=False)\n    sub_df.head()\n\ndef clearWD():\n    import os\n    import glob\n    import shutil\n\n    files = glob.glob('/kaggle/working/*')\n    for f in files:\n        try:\n            os.remove(f)\n        except:\n            shutil.rmtree(f)\nprint(\"ALL FUNCTIONS LOADED\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:46:20.78901Z","iopub.execute_input":"2021-09-10T09:46:20.789391Z","iopub.status.idle":"2021-09-10T09:46:20.844023Z","shell.execute_reply.started":"2021-09-10T09:46:20.78935Z","shell.execute_reply":"2021-09-10T09:46:20.843044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">  \n<b> Experiment Function.  </b>\n</div>","metadata":{}},{"cell_type":"code","source":"def evaluateExperiment(fast_run, model_name, do_undersampling, prepro, prepro_brightness, prepro_zoom, prepro_rotation, prepro_blur, batch_size, epochs, base_model_trainable, base_model, learning_rate):\n    (timestamp, experiment_id) = timestamp_and_experimentId(model_name, do_undersampling, prepro, prepro_rotation, prepro_blur, prepro_brightness, prepro_zoom, batch_size, epochs, base_model_trainable)\n    base_output = \"./\" +experiment_id+\"/\"\n    base_output_path = base_output + experiment_id + \"-\"\n    img_pixels = modelpixels[model_name]\n    img_size = (img_pixels, img_pixels)\n\n    OPTIMIZER = Adam(lr=learning_rate) #Dejar esto que es el que mejor funcionar\n    LOSS = 'binary_crossentropy'\n    METRICS = [\n        'accuracy', \n        'AUC'\n    ] \n    \n    train = getTrainData(img_pixels)\n    test = getTestData(img_pixels)\n    \n    if(IS_CLASS_MODE_BINARY):\n        train['target'] = train['target'].apply(str)\n    if do_undersampling:\n#         print(\"DOING UNDERSAMPLING\")\n        balance = 1\n    else:\n#         print(\"NO UNDERSAMPLING (un poco solo)\")\n        balance = 10\n    train = doUndersampling(train, balance)\n\n\n    trainTestPatientCheck(train, test)\n    \n\n    if SAVE_OUTPUT:\n        train_gen = get_training_gen(train, prepro, prepro_brightness, prepro_zoom, prepro_rotation, prepro_blur, batch_size, img_size, doShuffle=False)\n        t_x, t_y = next(train_gen)\n        fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n        for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n            c_ax.imshow(c_x, cmap = 'bone')\n            if c_y == \"1\": \n                c_ax.set_title(str(c_y) + \"-MALIGNANT\")\n            else:\n                c_ax.set_title(str(c_y) + \"-BENIGN\")\n            c_ax.axis('off')\n        plt.savefig(base_output_path + \"1dataAug.png\")\n\n\n    model = create_model(base_model, base_model_trainable, model_name)\n\n    callback_list = []\n    esPatience = earlyStoppingPatienteCalculator(do_undersampling, base_model_trainable)\n    stop_early = EarlyStopping(monitor='val_auc', mode='max', patience=esPatience)\n    callback_list.append(stop_early)\n\n    if SAVE_OUTPUT:\n        weight_path = base_output_path + \"3model.hdf5\"\n        checkpoint = ModelCheckpoint(\n            weight_path,\n            save_weights_only=True,\n            verbose=VERBOSE_LEVEL,\n            save_best_only=True,\n            monitor='val_auc',\n            overwrite=True,\n            mode='max',\n        )\n        callback_list.append(checkpoint)\n\n    train_df, val_df = create_splits(train, 0.2, 'target')\n#     print(\"rows in train_df\", train_df.shape[0])\n#     print(\"rows in val_df\", val_df.shape[0])\n\n    train_gen = get_training_gen(train_df, prepro, prepro_brightness, prepro_zoom, prepro_rotation, prepro_blur, batch_size, img_size)\n    val_gen = get_validation_gen(val_df, batch_size, img_size)\n    valX, valY = val_gen.next()\n\n#     print(\"Calculating class weights\")\n    testY = np.array(train_df['target'])\n    class_weights_computed = class_weight.compute_class_weight('balanced',np.unique(testY), testY)\n    class_weights = dict(enumerate(class_weights_computed))\n#     print(\"class_weights: \" + str(class_weights))\n    print(\"earlyStopPatience\", esPatience)\n    \n# #     print(\"CLASSMODE:\", CLASS_MODE)\n# #     print(\"do_undersampling\", do_undersampling)\n# #     print(\"batch_size: \", batch_size)\n# #     print(\"epochs: \", epochs)\n# #     print(\"prepro_rotation\", prepro_rotation)\n# #     print(\"prepro_blur\", prepro_blur)\n\n    \n    model.compile(loss=LOSS,metrics=METRICS,optimizer=OPTIMIZER,)\n\n    if fast_run:\n        epochs = 3\n    print(experiment_id)\n    history = model.fit(\n        train_gen,\n        epochs=epochs, \n        class_weight = class_weights,\n        verbose=VERBOSE_LEVEL,\n        callbacks=callback_list, \n        validation_data=(valX, valY),\n    )\n    \n    \n#     valPath = base_output + \"testingVal.csv\"\n#     createSubmissionFile(model, val_df, img_size, valPath)\n\n    save_history(history.history, timestamp, base_output_path)\n\n    y_true_classes = [] # true labels\n    y_pred_classes = [] # predictions\n    y_pred_probs = [] # predictions probabilities\n    rangeValue = val_df.shape[0] if not fast_run else 50\n    for i in range(rangeValue):\n        y_real = val_df.iloc[i].target\n        y_real_int = int(y_real)\n        image_path = val_df.iloc[i].image_path\n        img = tf.keras.preprocessing.image.load_img(image_path, target_size=img_size)\n        img = tf.keras.preprocessing.image.img_to_array(img)\n        img = img / 255\n        img_array = tf.expand_dims(img, 0)\n        y_pred = model.predict(img_array)\n        y_pred_prob = round(y_pred[0][0],4)\n        y_pred_class = int(round(y_pred_prob, 0))\n        #print(\"Real: \", y_real, \"-> pred: \", y_pred_prob, \"class\", y_pred_class)\n        y_true_classes.append(y_real_int)\n        y_pred_classes.append(y_pred_class)\n        y_pred_probs.append(y_pred_prob)\n        \n\n    plot_auc(y_true_classes, y_pred_probs, base_output_path)\n\n    precision, recall, thresholds = precision_recall_curve(y_true_classes, y_pred_probs)\n    f1score = [calc_f1(precision[i],recall[i]) for i in range(len(thresholds))]\n    idx = np.argmax(f1score)\n    precision = round(precision[idx], 4)\n    recall = round(recall[idx], 4)\n    threshold = round(thresholds[idx], 4)\n    f1score = round(f1score[idx], 4)\n\n#     print('Precision:', precision)\n#     print('Recall:', recall)\n#     print('Threshold:', threshold)\n#     print('F1 Score:', f1score)\n\n    cm_plot_label =['benign', 'malignant']\n    plot_confusion_matrix(confusion_matrix(y_true_classes, y_pred_classes), cm_plot_label, base_output_path)\n    image_path = test.iloc[0].image_path\n    # Show a prediction for a random image\n    image_path = test.sample().iloc[0].image_path\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=img_size)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = img / 255\n    img_array = tf.expand_dims(img, 0)\n\n    pred = model.predict(img_array)\n    prediction = round(pred[0][0],2)\n#     print(\"Chance of being malignant: {:.2f} %\".format(prediction))\n\n    finding = \"Diagnosis: BENIGN\"\n    if not prediction < 0.5:\n        finding = \"Diagnosis: MALIGNANT\"\n\n    x = plt.figure(figsize=(5,5))\n    x = plt.imshow(img)\n    x = plt.title(finding)\n    x = plt.axis(\"off\")\n\n    if SAVE_OUTPUT:\n        # save the model to a json file\n        model_json = model.to_json()\n        with open(base_output_path + \"3model.json\", \"w\") as json_file:\n            json_file.write(model_json)\n        subPath = base_output + \"submission.csv\"\n        createSubmissionFile(model, test, img_size, subPath)\n\n    shutil.make_archive(\"/kaggle/working/\" + experiment_id, 'zip', \"/kaggle/working/\" + experiment_id)\n    shutil.rmtree('/kaggle/working/' + experiment_id)\nprint(\"EVALUATE EXPERIMENT LOADED\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:46:20.845953Z","iopub.execute_input":"2021-09-10T09:46:20.846319Z","iopub.status.idle":"2021-09-10T09:46:20.875304Z","shell.execute_reply.started":"2021-09-10T09:46:20.846281Z","shell.execute_reply":"2021-09-10T09:46:20.872876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\">  \n    <b> Variables globales</b>\n</div>","metadata":{}},{"cell_type":"code","source":"#Variables y cosas globales de verdad\nSEED = 1\nOUTPUT_NEURONS = 1\nVERBOSE_LEVEL = 2\nCLASS_MODE = \"binary\"\n# \"raw\" evitarlo y \"categorical\" debería de ser igual pero al ser onehot pues también evitarlo en principio\nIS_CLASS_MODE_BINARY = CLASS_MODE == \"binary\"\nPOSITIVE_CLASS = \"1\" if IS_CLASS_MODE_BINARY else 1\nNEGATIVE_CLASS = \"0\" if IS_CLASS_MODE_BINARY else 0\n\n\nBASE_INPUT_PATH = '/kaggle/input/tfmmelanomapreprocessed'\nBASE_PATH_TO_IMAGES = '/kaggle/input/tfmmelanomapreprocessed/dataset/jpeg'\nIMAGE_TYPE = \".jpg\"\n\nmodelpixels = {\"vgg16\" : 224, \"densenet121\":224, \"nasnetmobile\":224, \"nasnetlarge\":331, \"inceptionresnetv2\":224}\nINPUT_224_SHAPE = (224, 224, 3)\nINPUT_331_SHAPE = (331, 331, 3)\ndef getVGG16():\n    return VGG16(input_shape=INPUT_224_SHAPE,include_top=False,weights='imagenet')\ndef getDenseNet121():\n    return DenseNet121(input_shape=INPUT_224_SHAPE,include_top=False,weights='imagenet')\ndef getNASNetMobile():\n    return NASNetMobile(input_shape=INPUT_224_SHAPE,include_top=False,weights='imagenet')\ndef getNASNetLarge():\n    return NASNetLarge(input_shape=INPUT_331_SHAPE,include_top=False,weights='imagenet')\ndef getInceptionResNetV2():\n    return InceptionResNetV2(input_shape=INPUT_224_SHAPE,include_top=False,weights='imagenet')\nallmodelsfunc = {\"vgg16\" : getVGG16, \"densenet121\":getDenseNet121, \"nasnetmobile\":getNASNetMobile, \"nasnetlarge\":getNASNetLarge, \"inceptionresnetv2\":getInceptionResNetV2}\n\n#TODO MIRAR\ntrain_224_backup = train_224_backup.copy() if (\"train_224_backup\" in globals() and train_224_backup is not None) else None\ntest_224_backup = test_224_backup.copy() if (\"test_224_backup\" in globals() and test_224_backup is not None) else None\ntrain_331_backup = train_331_backup.copy() if (\"train_331_backup\" in globals() and train_331_backup is not None) else None\ntest_331_backup = test_331_backup.copy() if (\"test_331_backup\" in globals() and test_331_backup is not None) else None\n    \n# Tensorflow execution optimizations\n# Source: https://www.tensorflow.org/guide/mixed_precision & https://www.tensorflow.org/xla\nMIXED_PRECISION = True\nXLA_ACCELERATE = True\nGPUS = 0\n\nGPUS = len(tf.config.experimental.list_physical_devices('GPU'))\nif GPUS == 0:\n    DEVICE = 'CPU'\n#     raise RuntimeError('Running on CPU')\nelse:\n    DEVICE = 'GPU'\n    if MIXED_PRECISION:\n        from tensorflow.keras.mixed_precision import experimental as mixed_precision\n        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n        mixed_precision.set_policy(policy)\n#         print('Mixed precision enabled')\n    if XLA_ACCELERATE:\n        tf.config.optimizer.set_jit(True)\n#         print('Accelerated Linear Algebra enabled')\n\n# print(\"Tensorflow version \" + tf.__version__)\n\n\n# print(\"Set seeds\")\nrandom.seed(SEED)\nnp.random.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nos.environ['TF_KERAS'] = str(SEED)\nos.environ['TF_DETERMINISTIC_OPS'] = str(SEED)\nos.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:46:20.87763Z","iopub.execute_input":"2021-09-10T09:46:20.87799Z","iopub.status.idle":"2021-09-10T09:46:22.852376Z","shell.execute_reply.started":"2021-09-10T09:46:20.877954Z","shell.execute_reply":"2021-09-10T09:46:22.851494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\">  \n    <b> Configuración del experimento</b>\n</div>","metadata":{}},{"cell_type":"code","source":"#\"vgg16\",\"densenet121\", \"nasnetmobile\", \"nasnetlarge\", \"inceptionresnetv2\"\nmodelsfunc = dict((k, allmodelsfunc[k]) for k in [\"vgg16\",\"densenet121\", \"nasnetmobile\", \"nasnetlarge\", \"inceptionresnetv2\"])\n\n\nSAVE_OUTPUT = False\nfast_run = False\n# fast_run = True\n\ndo_undersamplings = [True,False]\nbase_model_trainables = [False,True]\npreprocesses = [True]\nprepro_rotation = True\nprepro_blur = True\nprepro_brightness = True\nprepro_zoom = True\n\nfor model_name in modelsfunc.keys():\n    for preprocess in preprocesses:\n        prepro_rotation = prepro_rotation and preprocess\n        prepro_blur = prepro_blur and preprocess\n        prepro_brightness = prepro_brightness and preprocess\n        prepro_zoom = prepro_zoom and preprocess\n        for do_undersampling in do_undersamplings:\n            for base_model_trainable in base_model_trainables:\n                print(\"\\n\\n=========================================\" + model_name + \"=========================================\")\n                base_model = modelsfunc[model_name]()\n                batch_size = 16 if do_undersampling else (32 if not base_model_trainable else 64)\n                epochs = 20 if do_undersampling else 40\n                learning_rate = 1e-4 if not base_model_trainable else 1e-5\n                \n                epochs = 1\n                \n                evaluateExperiment(fast_run, model_name, do_undersampling, preprocess, prepro_brightness, prepro_zoom, prepro_rotation, prepro_blur, \n                                   batch_size, epochs, base_model_trainable, base_model, learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T09:46:22.855586Z","iopub.execute_input":"2021-09-10T09:46:22.855848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clearWD()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}