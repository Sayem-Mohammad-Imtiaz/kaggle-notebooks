{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/students-performance-in-exams/StudentsPerformance.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['test preparation course']=[1 if each=='completed' else 0  for each in data['test preparation course']]\ndata['lunch']=[1 if each=='standard' else 0  for each in data['lunch']]\ndata['gender']=[1 if each=='male' else 0  for each in data['gender']]\ndata['race/ethnicity']=[0 if each=='group A' else 1 if each=='group B'  else 2 if each=='group C'  else 3 if each=='group D'  else 4 for each in data['race/ethnicity']]\ndata['parental level of education']=[0 if each==\"some high school\" else 1 if each==\"high school\"  else 2 if each=='some college'  else 3 if each==\"associate's degree\"  else 4 if each ==\"bachelor's degree\" else 5 for each in data['parental level of education']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,5,1):\n    g=sns.factorplot(x=data.columns[i],y='gender',data=data,kind='bar',size=6)\n    g.set_ylabels('Gender')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data.drop('gender', axis=1)\ny=data.gender","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=(x-np.min(x))/(np.max(x)-np.min(x))\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=pd.get_dummies(x,columns=['race/ethnicity'], prefix='race')\nx=pd.get_dummies(x,columns=['parental level of education'], prefix='pl')\nx=pd.get_dummies(x,columns=['lunch'], prefix='lunch')\nx=pd.get_dummies(x,columns=['test preparation course'], prefix='course')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold,GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state=42\nclassifier =[DecisionTreeClassifier(random_state=random_state),\n             SVC(random_state=random_state),\n             RandomForestClassifier(random_state=random_state),\n             LogisticRegression(random_state=random_state),\n             KNeighborsClassifier()]\ndt_param_grid={'min_samples_split': range(10,500,20),\n               'max_depth': range(1,20,2)}\n\nsvc_param_grid={'kernel': ['rbf'],\n                'gamma': [0.001,0.01,0.1,1],\n                'C':[1,10,50,100,200,300,500,1000]}\nrf_param_grid={'max_features':[1,3,10],\n               'min_samples_split':[2,3,10],\n               'min_samples_leaf':[1,3,10],\n               'bootstrap':[False],\n               'n_estimators':[100,300],\n               'criterion':['gini']}\n\nlogreg_param_grid={'C': np.logspace(-3,3,7),\n                   'penalty':['l1','l2']}\n\nknn_param_grid={'n_neighbors':np.linspace(1,19,10, dtype=int ).tolist(),\n                'weights': ['uniform','distance'],\n                'metric' : ['euclidean','manhattan']}\n\n\nclassifier_param=[dt_param_grid,\n                  svc_param_grid,\n                  rf_param_grid,\n                  logreg_param_grid,\n                  knn_param_grid]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_result=[]\nbest_estimators=[]\nfor i in range(len(classifier)):\n    clf=GridSearchCV(classifier[i],param_grid=classifier_param[i],cv=StratifiedKFold(n_splits=10),scoring='accuracy',n_jobs=-1,verbose=1)\n    clf.fit(x_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncv_result=pd.DataFrame({'Cross Validation Means':cv_result,'ML_Models':['DecisionTreeClassifier','SVM',\n                                                                         'RandomForestClassifier',\n                                                                         'LogisticRegression',\n                                                                         'KNeighborsClassifier']})\ng=sns.barplot('Cross Validation Means','ML_Models',data=cv_result)\ng.set_xlabel('Mean Accuracy')\ng.set_title('Cross Validation Scores')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC=VotingClassifier(estimators=[\n                                     ('rfc',best_estimators[2]),\n                                     ('lr',best_estimators[3])],\n                                    voting='soft',n_jobs=-1)\n\nvotingC=votingC.fit(x_train,y_train)\nprint('accuracy score',accuracy_score(votingC.predict(x_test),y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gender=pd.Series(votingC.predict(x),name='gender').astype(int)\nresults = pd.concat([test_gender],axis=1)\nresults.to_csv('test.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gender","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}