{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**First step towards any data science project is to importing dataset into the environment.**\n\nwe read the csv files using pandas **read_csv** method\n[](http://)","metadata":{}},{"cell_type":"code","source":"# Reading data set\ncovid_cases = pd.read_csv('/kaggle/input/covid19-in-india/covid_19_india.csv')\ncovid_vaccine = pd.read_csv('/kaggle/input/covid19-in-india/covid_vaccine_statewise.csv')\ncovid_testing = pd.read_csv('/kaggle/input/covid19-in-india/StatewiseTestingDetails.csv')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_cases.columns\ncovid_cases.head(10)\ncovid_cases.isna().sum()\ncovid_cases.dtypes\ncovid_cases.Date.unique()[:5]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Coverting object type to Date\nNow that we know that our date column isn't being recognized as a date, it's time to convert it so that it is recognized as a date. This is called \"parsing dates\" because we're taking in a string and identifying its component parts.\n\nWe can pandas what the format of our dates are with a guide called as \"strftime directive\", which you can find more information on at this link. The basic idea is that you need to point out which parts of the date are where and what punctuation is between them. There are lots of possible parts of a date, but the most common are %d for day, %m for month, %y for a two-digit year and %Y for a four digit year.\n\nSome examples:\n\n* 1/17/07 has the format \"%m/%d/%y\"\n* 17-1-2007 has the format \"%d-%m-%Y\"\n\nLooking back up at the head of the date column in the landslides dataset, we can see that it's in the format \"month/day/two-digit year\", so we can use the same syntax as the first example to parse in our dates:","metadata":{}},{"cell_type":"code","source":"covid_cases['date_parsed'] = pd.to_datetime(covid_cases.Date , format =\"%Y-%m-%d\")\ncovid_cases.dtypes\ncovid_cases.date_parsed.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_cases['days']= covid_cases.date_parsed - min(covid_cases.date_parsed)\ncovid_cases.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}