{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#d0 = pd.read_csv('./mnist_train.csv')\ntrain = pd.read_csv(\"../input/mnist-digit-recognizer/train.csv\")\nprint(train.head(5)) # print first five rows of d0.\ntrain.shape\n# save the labels into a variable l.\nl = train['label']\nprint(l.shape)\n# Drop the label feature and store the pixel data in d.\nd = train.drop(\"label\",axis=1)\nprint(d.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# display or plot a number.\nplt.figure(figsize=(7,7))\nidx = 1\n\ngrid_data = d.iloc[idx].as_matrix().reshape(28,28)  # reshape from 1d to 2d pixel array\nplt.imshow(grid_data, interpolation = \"none\", cmap = \"gray\")\nplt.show()\n\nprint(l[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pick first 15K data-points to work on for time-effeciency.\n#Excercise: Perform the same analysis on all of 42K data-points.\n\nlabel = l.head(15000)\ndata = d.head(15000)\n\nprint(\"the shape of sample data = \", data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sample for Standardscaler example:\n    \nfrom sklearn.preprocessing import StandardScaler\ndata_tes = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n\nscaler = StandardScaler().fit_transform(data_tes)\nprint(data_tes)\nprint(scaler)\n#scaler.mean(axis=0)\nscaler.std(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data-preprocessing: Standardizing the data\n\nfrom sklearn.preprocessing import StandardScaler\nstandardized_data = StandardScaler().fit_transform(data)\nprint(standardized_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the co-variance matrix which is : A^T * A\nsample_data = standardized_data\n\n# matrix multiplication using numpy\ncovar_matrix = np.matmul(sample_data.T , sample_data)\n\nprint ( \"The shape of variance matrix = \", covar_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding the top two eigen-values and corresponding eigen-vectors \n# for projecting onto a 2-Dim space.\n\nfrom scipy.linalg import eigh \n\n# the parameter 'eigvals' is defined (low value to heigh value) \n# eigh function will return the eigen values in asending order\n# this code generates only the top 2 (782 and 783) eigenvalues.\nvalues, vectors = eigh(covar_matrix, eigvals=(782,783))\n\nprint(\"Shape of eigen vectors = \",vectors.shape)\n# converting the eigen vectors into (2,d) shape for easyness of further computations\nvectors = vectors.T\n\nprint(\"Updated shape of eigen vectors = \",vectors.shape)\n# here the vectors[1] represent the eigen vector corresponding 1st principal eigen vector\n# here the vectors[0] represent the eigen vector corresponding 2nd principal eigen vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# projecting the original data sample on the plane \n#formed by two principal eigen vectors by vector-vector multiplication.\n\nimport matplotlib.pyplot as plt\nnew_coordinates = np.matmul(vectors, sample_data.T)\nprint (\" resultanat new data points' shape \", vectors.shape, \"X\", sample_data.T.shape,\" = \", new_coordinates.shape)\n\n\nimport pandas as pd\n\n# appending label to the 2d projected data\nnew_coordinates = np.vstack((new_coordinates, label)).T\n\n# creating a new data frame for ploting the labeled points.\ndataframe = pd.DataFrame(data=new_coordinates, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\nprint(dataframe.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting the 2d data points with seaborn\nimport seaborn as sns\n\nsns.FacetGrid(dataframe,hue = 'label', size = 6).map(plt.scatter,\"1st_principal\", \"2nd_principal\").add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import decomposition\npca = decomposition.PCA()\npca\n\npca.n_components=2\npca_data = pca.fit_transform(sample_data)\nprint(\"shape of PCA_reduced.shape=\",pca_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_data1 = np.vstack((pca_data.T,label.T)).T\npca_data1\npca_data2 = pd.DataFrame(pca_data1,columns=(\"1st_principal\", \"2nd_principal\",\"label\"))\npca_data2\n\nsns.FacetGrid(pca_data2,hue='label',size=6).map(plt.scatter,\"1st_principal\", \"2nd_principal\").add_legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the Dataset\ntrain_test = pd.read_csv(\"../input/mnist-digit-recognizer/train.csv\")\ntrain_test.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extracting the Data and label part of the dataset(before sampling)\nl_tes = train_test['label']\nd_tes = train_test.drop('label',axis=1)\nl_tes\nd_tes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sampling the data(30k)\nl_samp =  l_tes.head(30000)\nd_samp = d_tes.head(30000)\nd_samp.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalization of the sample data\nfrom sklearn.preprocessing import StandardScaler\n\nd_stnd = StandardScaler().fit_transform(d_samp)\n\n#finding the covanrance using matrix multiplication\nmat_dst = np.matmul(d_stnd,d_stnd.T)\nmat_dst.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding the hiehest eigen value and eighen vectors\nfrom scipy.linalg import eigh\n\nvalues, vectors = eigh(mat_dst,eigvals = (782,783))\nvectors.shape()\nvectors = vectors.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_co = np.matmul(vectors,d_samp.T)\nd_samp.shape()\n\n#appending a label to the 2d projected data\nnew_col = pd.vstack((new_co,l_samp)).T\n\n#Creating a new dataframe out of array new_col\nnew_codf = pd.DataFrame(new_col,columns=(\"1st_principal\", \"2nd_principal\",\"label\"))\n\nsns.FacetGrid(new_codf,hue='label',size =6).map(plt.scatter,\"1st_principal\", \"2nd_principal\").add_legend()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}