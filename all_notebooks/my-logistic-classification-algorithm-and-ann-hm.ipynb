{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/voice.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"665e298353f035aa7caa4a6b8d6a9da638e6c7b4"},"cell_type":"markdown","source":"# EDA\n"},{"metadata":{"trusted":true,"_uuid":"1f1df73ed8d7d6a2dfe6d90470a612f5246839ef"},"cell_type":"code","source":"data.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2651fcb37e23e27e3e8e12f24354d23718ceeefa"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd1a1842129fc71294fff0aca759198f01a00894"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40a9bf1355842db247981ed474d891259336a492"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1f244d88892a756a68a12a37dc9972b42d61974"},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7009040965c9e077bda8c8ec0c8149c04d104a8a"},"cell_type":"markdown","source":"Pre Processing the data"},{"metadata":{"trusted":true,"_uuid":"d7f4cb74f741b8afdde2fc6c70a04e5b0afb9a39"},"cell_type":"code","source":"#correlation map\nf,ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b194e4cde70c52ab15c8faf75721b7b24ecd4475"},"cell_type":"code","source":"data.label=[0 if each==\"female\" else 1 for each in data.label]\n#print(data.info()) #2 adet classimiz oldu 1 erkek 0 bayan\n\ny=data.label.values\nx_data=data.drop([\"label\"],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d88014b947f5cbe7d427442debeb1756af259930"},"cell_type":"code","source":"#%% normalization\n# (x-max)/(max-min)\nx=(x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data)).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86620513a8c0b20db1db5345c4319c55d0da4355"},"cell_type":"code","source":"#%% train test and split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n\nx_train=x_train.T\nx_test=x_test.T\ny_train=y_train.T\ny_test=y_test.T\n\nprint(\"x train : \",x_train.shape)\nprint(\"x test : \",x_test.shape)\nprint(\"y train : \",y_train.shape)\nprint(\"y test : \",y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c43c99c6b9730a18a81e9662c35dc69cf5a1afbf"},"cell_type":"code","source":"#%% parameter initialize and sigmoid function\n#dimension=20\ndef initialize_weights_and_bias(dimension):\n    w=np.full((dimension,1),0.01)\n    b=0.0 \n    return w,b\n\ndef sigmoid(z):\n    y_head=1/(1+np.exp(-z))\n    return y_head\n#print(sigmoid(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00af2900f33bbce1d7883f296697819236371235"},"cell_type":"code","source":"#%%\ndef forward_backward_propagation(w,b,x_train,y_train):\n    #forward propagation\n    z=np.dot(w.T,x_train)+b\n    y_head=sigmoid(z)\n    loss=-y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n    cost=(np.sum(loss))/x_train.shape[1]\n    #backward propagation\n    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n    gradients={\"derivative_weight\":derivative_weight,\"derivative_bias\":derivative_bias}\n    return cost,gradients","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e297b01a7a0aab93500d7c804f58355b9681a64"},"cell_type":"code","source":"#%%Updating(Learning) parameters\ndef update(w,b,x_train,y_train,learning_rate,number_of_iterarion):\n    cost_list=[]\n    cost_list2=[]\n    index=[]\n    \n    for i in range(number_of_iterarion):\n        cost,gradients=forward_backward_propagation(w,b,x_train,y_train)\n        cost_list.append(cost)\n        #lets update\n        w=w-learning_rate*gradients[\"derivative_weight\"]\n        b=b-learning_rate*gradients[\"derivative_bias\"]\n        if i%10 ==0:\n            cost_list2.append(cost)\n            index.append(i)#grafik için bunları aldık\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n            \n    #we update(learn) parameters weights and bias\n    parameters={\"weight\":w,\"bias\":b}\n    plt.plot(index,cost_list2)\n    plt.xticks(index,rotation=\"vertical\")\n    plt.xlabel(\"Number of Iterarrion\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n    return parameters,gradients,cost_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8c111478438caab073c2ed0cc6e00a875c2f295"},"cell_type":"code","source":"#%%\n# prediction\ndef predict(w,b,x_test):\n    # x_test is a input for forward propagation\n    z = sigmoid(np.dot(w.T,x_test)+b)\n    Y_prediction = np.zeros((1,x_test.shape[1]))\n    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n    for i in range(z.shape[1]):\n        if z[0,i]<= 0.5:\n            Y_prediction[0,i] = 0\n        else:\n            Y_prediction[0,i] = 1\n\n    return Y_prediction\n# predict(parameters[\"weight\"],parameters[\"bias\"],x_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24baa0ca503a5e79c2635ee75965c3a97343aedf"},"cell_type":"code","source":"#%%\ndef logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n    # initialize\n    dimension =  x_train.shape[0]  # that is 20\n    w,b = initialize_weights_and_bias(dimension)\n    # do not change learning rate\n    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n    \n    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n\n    # Print train/test Errors\n    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de0f63a4d0e3fa2b4c69ab6cbc512efefcbd50b7"},"cell_type":"code","source":"logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 300)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37aeaac8e48115ee046a01d2b703ecb986a6e9ea"},"cell_type":"markdown","source":"## sklearn with lr\n\n"},{"metadata":{"trusted":true,"_uuid":"b1448527a2f5c71dcac5f3e7ea3a66c15e2304e5"},"cell_type":"code","source":"algo_score_list=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7503d6a32544cdad5f7b466207f217c54180269e"},"cell_type":"code","source":"#%% sklearn with lr\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(x_train.T,y_train.T)\nprint(\"test accuracy {}\".format(lr.score(x_test.T,y_test.T)))\nalgo_score_list.append([\"logistic reg\",lr.score(x_test.T,y_test.T)])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd3e64f13b97c94f69f295debc8e5a6228a5e7c8"},"cell_type":"markdown","source":"# KNN implemantion\n"},{"metadata":{"trusted":true,"_uuid":"8bb6a9618d97af08a2d47339ca3eb9d0da403bc5"},"cell_type":"code","source":"#%% sklearn with knn\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train.T,y_train.T)\nprediction = knn.predict(x_test.T)\n#print('Prediction: {}'.format(prediction))\nprint('With KNN (K=3) accuracy is: ',knn.score(x_test.T,y_test.T)) # accuracy\ny_pred=knn.predict(x_test.T)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86ae86c8db1513e118af2f33adc55984d7a1dbe7"},"cell_type":"code","source":"#find best k value\nscore_list=[]\nfor each in range(1,15):\n    knn2=KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(x_train.T,y_train.T)\n    score_list.append(knn2.score(x_test.T,y_test.T))\n# plot\nplt.plot(range(1,15),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"score\")\nplt.show()\n\n#you will see k=8 best \nalgo_score_list.append([\"knn\",knn2.score(x_test.T,y_test.T)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f94f4ddfea4fbc499e76ce82865eca96d4d4390"},"cell_type":"markdown","source":"# SVM "},{"metadata":{"trusted":true,"_uuid":"4362e36a8f88c80b8dc15c1112001a54bca400d0"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm=SVC(random_state=1)\nsvm.fit(x_train.T,y_train.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d48ffe285bcd24e6d5c1e074ee09160f28397b51"},"cell_type":"code","source":"print(\"pring accuracy of svm algo:\",svm.score(x_test.T,y_test.T))\nalgo_score_list.append([\"svm\",svm.score(x_test.T,y_test.T)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13fec2875aa81ad6deefcf22c9ad678a678b4999"},"cell_type":"markdown","source":"# Navie Bayes"},{"metadata":{"trusted":true,"_uuid":"4356718b6ff203bdb0e0a763bbe5dd1887e748c1"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train.T,y_train.T)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dece72c99498fdf7a51d4e60ad4563d02e7d9203"},"cell_type":"code","source":"print(\"print accuracy of naive bayes algo:\",nb.score(x_test.T,y_test.T))\nalgo_score_list.append([\"naive bayes\",nb.score(x_test.T,y_test.T)])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ac450af3c5c99f4e6c020cb8175a470a978be52"},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true,"_uuid":"7ce32917d420edddcac463da4b8aecf9ba0ef978"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train.T,y_train.T)\n\nprint(\"Tree score:\",dt.score(x_test.T,y_test.T))\nalgo_score_list.append([\"decision tree\",dt.score(x_test.T,y_test.T)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e27e77c7490dc7b991375a1f7175315878ac273b"},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true,"_uuid":"a09ebafbe170c9e2b571c2c1f6b68641f598af34"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier(n_estimators=100,random_state=1)\nrf.fit(x_train.T,y_train.T)\nprint(\"Random forest score:\",rf.score(x_test.T,y_test.T))\nalgo_score_list.append([\"random forest\",rf.score(x_test.T,y_test.T)])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2044792867383aa4edaa097fabf0c896caaf2097"},"cell_type":"code","source":"algo_score_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecd3c972ac8d16e82e4d3cf11381fb28a0d14a63"},"cell_type":"code","source":"algo_score_List=np.array(algo_score_list)\nalgo_score_List","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4a11224145b1a184added95fb60ce9ab3a2bd4d"},"cell_type":"code","source":"\nalgo_score_sorted_list = algo_score_List[algo_score_List[:,1].argsort()]\nalgoritma_isimleri=algo_score_sorted_list[:,0]\nalgoritma_skorlari=algo_score_sorted_list[:,1]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82191011c1ec6a79bc22d0b75459b3c385ed7017"},"cell_type":"code","source":"# Plot\nx=algoritma_isimleri\ny=algoritma_skorlari\nplt.figure(figsize=(7,7))\nplt.scatter(x, y,alpha=0.5)\nplt.grid()\nplt.title('Alghoritm Performance')\nplt.xlabel('Alghoritm')\nplt.ylabel('Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81384f8077151ea15e11ff18f55bdfea656f445c"},"cell_type":"code","source":"#%% confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test.T,y_pred)\n\n\n# %% cm visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f70da95d98ef2bd09dbfb7b94df67f6f14e8da5a"},"cell_type":"markdown","source":"# ANN implantation section"},{"metadata":{"trusted":true,"_uuid":"2329537684a90ca8bfcfcc344e63295bc7c8c7bd"},"cell_type":"code","source":"x_train=x_train.T\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e3d195316b67b005215e74ad44df367e8dd2279"},"cell_type":"code","source":"y_train.reshape(2534,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a45f89a540c56bf37321929206a85f67a7720f33"},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbc393df2a066688c39120bfb2daeedfc1d12454"},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ea7de9c000284dee2a7d36c365278a2cba1cbd0f"},"cell_type":"code","source":"# Evaluating the ANN\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\ndef build_classifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 20))\n    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\naccuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train.T, cv = 3)\nmean = accuracies.mean()\nvariance = accuracies.std()\nprint(\"Accuracy mean: \"+ str(mean))\nprint(\"Accuracy variance: \"+ str(variance))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d781e72c4be92fcbfa50543f07a6ea101645c39b"},"cell_type":"markdown","source":"# CONCLUSİON \n* En iyi algoritma knn olarak seçilmesi gerekir.Bu veri seti için Komşuluk yöntemiyle en iyi sonucu elde etmiş oluruz\n* İlginç şekilde bayan ve erkek hata sayıları eşit çıktı.Ama algoritma erkek değerleri için daha iyi tahmin üretir\n* Best option is knn algorithm\n* Interestingly, the female and male error numbers are equal. But the algorithm produces better estimates for male values\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}