{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-14T12:11:28.679594Z","iopub.execute_input":"2021-07-14T12:11:28.679991Z","iopub.status.idle":"2021-07-14T12:11:28.68939Z","shell.execute_reply.started":"2021-07-14T12:11:28.679941Z","shell.execute_reply":"2021-07-14T12:11:28.688299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ks_table_summary(prediction,actual,bin):\n    #prediction is [:,1] of predicted probability column\n    #prob = pd.DataFrame(prediction)\n#   prob = prob.reset_index()\n    prob = prediction\n    target = actual\n#   target = pd.DataFrame(actual)\n#   target = target.reset_index()\n#   target = target.iloc[:,~0]\n    \n    qv = prob.quantile(np.linspace(0.0,1.0,num=bin),interpolation = 'linear')\n    prob_bins = pd.cut(prob,list(sorted(set(qv))),include_lowest = True)\n    df = pd.concat([prob_bins,prob,target],axis = 1)\n    df.columns = ['prob_bins','prob','target']\n    \n    grp = df.groupby('prob_bins')\n    account = grp['target'].count().astype('float')\n    event = grp['target'].sum().astype('float')\n    non_event = account-event \n    actual_non_event_rate = 1-grp['target'].mean().astype('float')\n    actual_event_rate = grp['target'].mean().astype('float')\n    grp = df.groupby('prob_bins')\n    min_score = grp['prob'].min().astype('float')\n    max_score = grp['prob'].max().astype('float')\n    pred_event_rate = grp['prob'].mean().astype('float')\n    \n    ks_tab = pd.concat([account,non_event,event,actual_non_event_rate,actual_event_rate,min_score,max_score,pred_event_rate],axis = 1)\n    ks_tab.columns = ['account','non_event','event','actual_non_event_rate','actual_event_rate','min_score','max_score','pred_event_rate']\n    \n    ks_tab['pred_event'] = ks_tab['account']*ks_tab['pred_event_rate']\n    ks_tab['pred_event'] = ks_tab['pred_event'].astype('int')\n    ks_tab['non_event_capture_rate'] = ks_tab['non_event']/ks_tab['non_event'].sum()\n    ks_tab['event_capture_rate'] = ks_tab['event']/ks_tab['event'].sum()\n    \n    cum_list1 = []\n    cum_list2 = []\n    lst = list(ks_tab['event_capture_rate'])\n    length = len(lst)\n    cum_list1 = [sum(lst[(length - x - 1):length]) for x in range(0,length)]\n    lst = list(ks_tab['non_event_capture_rate'])\n    cum_list2 = [sum(lst[(length - x - 1):length]) for x in range(0,length)]\n    cum_list1.reverse()\n    cum_list2.reverse()\n    ks_tab['event_cum_capture_rate'] = cum_list1\n    ks_tab['non_event_cum_capture_rate'] = cum_list2\n    ks_tab['KS_Stat'] = ks_tab['event_cum_capture_rate']-ks_tab['non_event_cum_capture_rate']\n    ks_tab['KS_Stat'] = np.round(ks_tab['KS_Stat'].astype(float),3)\n    \n    return ks_tab","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:51.755025Z","iopub.execute_input":"2021-07-14T12:11:51.755619Z","iopub.status.idle":"2021-07-14T12:11:51.771937Z","shell.execute_reply.started":"2021-07-14T12:11:51.755569Z","shell.execute_reply":"2021-07-14T12:11:51.770676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"https://raw.githubusercontent.com/deepanshu88/data/master/data.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:52.887125Z","iopub.execute_input":"2021-07-14T12:11:52.887497Z","iopub.status.idle":"2021-07-14T12:11:52.999698Z","shell.execute_reply.started":"2021-07-14T12:11:52.887465Z","shell.execute_reply":"2021-07-14T12:11:52.998963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ks_table_summary(df['p'],df['y'],11)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:53.89445Z","iopub.execute_input":"2021-07-14T12:11:53.895086Z","iopub.status.idle":"2021-07-14T12:11:53.956048Z","shell.execute_reply.started":"2021-07-14T12:11:53.895032Z","shell.execute_reply":"2021-07-14T12:11:53.955138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**One Sampe Kolmogorov-Smirnov Test**\n\nThe one-sample Kolmogorov-Smirnov test is used to test whether a sample comes from a specific distribution. We can use this procedure to determine whether a sample comes from a population that is normally distributed ","metadata":{}},{"cell_type":"markdown","source":"Null hypothesis assumes that the numbers are uniformly distributed between 0-1.","metadata":{}},{"cell_type":"code","source":"from scipy.stats import kstest\nimport random\nactual = np.random.randint(0,100,size = 100)\nx = kstest(actual, \"uniform\")   \nprint(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:14:33.555176Z","iopub.execute_input":"2021-07-14T12:14:33.555561Z","iopub.status.idle":"2021-07-14T12:14:33.563896Z","shell.execute_reply.started":"2021-07-14T12:14:33.555528Z","shell.execute_reply":"2021-07-14T12:14:33.562622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Null hypothesis assumes that the numbers are Normally distributed\nfrom scipy.stats import kstest\nimport random\nactual = np.random.randint(0,100,size = 100)\nx = kstest(actual, \"norm\")   \nprint(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:14:49.690309Z","iopub.execute_input":"2021-07-14T12:14:49.690688Z","iopub.status.idle":"2021-07-14T12:14:49.698989Z","shell.execute_reply.started":"2021-07-14T12:14:49.690655Z","shell.execute_reply":"2021-07-14T12:14:49.697675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Two-Sample Kolmogorov-Smirnov Test**\n\nThe null hypothesis is H0: both samples come from a population with the same distribution. ","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ks_2samp\ndf = pd.read_csv(\"https://raw.githubusercontent.com/deepanshu88/data/master/data.csv\")\nks_2samp(df.loc[df.y==0,\"p\"], df.loc[df.y==1,\"p\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:16:07.250588Z","iopub.execute_input":"2021-07-14T12:16:07.250949Z","iopub.status.idle":"2021-07-14T12:16:07.541084Z","shell.execute_reply.started":"2021-07-14T12:16:07.250916Z","shell.execute_reply":"2021-07-14T12:16:07.540069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It returns KS score 0.6033 and p-value less than 0.01 which means we can reject the null hypothesis and concluding distribution of events and non-events is different.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}