{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## PIMA INDIANS DIABETES | EXPLORATORY DATA ANALYSIS | MODEL BUILDING","metadata":{}},{"cell_type":"markdown","source":"## What is Diabetes?\nDiabetes is a medical condition which a significant percentage of population has to undergo. It impairs the bodyâ€™s ability to process blood glucose, otherwise known as blood sugar. In the absence of careful attention, highly diabetic condition can increase risk to complicated health problems such as stroke, heart disease etc. \n\n## Dataset and Objective\nThe datasets here consists of several medical predictor variables and a variable indicating diabetes condition (i.e. positively diagnosed or not). Our objective with the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\n\nThe columns of dataset are:\n1. Pregnancies - Number of times pregnant\n2. Glucose - Plasma glucose concentration a 2 hours in an oral glucose tolerance\n3. BloodPressure - Diastolic blood pressure (mm Hg)\n4. SkinThickness - Triceps skin fold thickness (mm)\n5. Insulin - 2 Hour serum insulin (mu U/ml)\n6. BMI - Body mass index (weight in kg/(height in m)^2)\n7. DiabetesPedigreeFunction - Diabetes pedigree function (indicates likelihood of diabetes based on family history)\n8. Age -  Age (years)\n9. Outcome - Class variable (0 or 1), 1 for diabetic and 0 for non diabetic","metadata":{}},{"cell_type":"markdown","source":"## Let's Start","metadata":{}},{"cell_type":"markdown","source":"### **1. Import Required Libraries and Load Dataset**","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# To filter warning by ignoring\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:18.671776Z","iopub.execute_input":"2021-06-04T12:36:18.672361Z","iopub.status.idle":"2021-06-04T12:36:18.684065Z","shell.execute_reply.started":"2021-06-04T12:36:18.672317Z","shell.execute_reply":"2021-06-04T12:36:18.683358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndiabetes_df = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:19.749221Z","iopub.execute_input":"2021-06-04T12:36:19.749804Z","iopub.status.idle":"2021-06-04T12:36:19.766505Z","shell.execute_reply.started":"2021-06-04T12:36:19.749757Z","shell.execute_reply":"2021-06-04T12:36:19.765568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **2. Data Preparation and Cleaning**","metadata":{}},{"cell_type":"markdown","source":"The real word datasets normally required preparation and cleaning before performing any analysis and the same is carried out in this section. As a first step, we will have a quick look at the data as a pandas dataframe.","metadata":{}},{"cell_type":"code","source":"# View the data as dataframe\ndiabetes_df","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:26.851021Z","iopub.execute_input":"2021-06-04T12:36:26.851391Z","iopub.status.idle":"2021-06-04T12:36:26.878405Z","shell.execute_reply.started":"2021-06-04T12:36:26.851355Z","shell.execute_reply":"2021-06-04T12:36:26.876724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So this is our data it has 768 rows and 9 columns. Now we need more information about the dataframe including the data types and columns, non-null values etc and we can use the following method.","metadata":{}},{"cell_type":"code","source":"# To check more information of data\ndiabetes_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:31.969854Z","iopub.execute_input":"2021-06-04T12:36:31.970221Z","iopub.status.idle":"2021-06-04T12:36:31.986604Z","shell.execute_reply.started":"2021-06-04T12:36:31.970189Z","shell.execute_reply":"2021-06-04T12:36:31.98545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The whole 768 rows of dataset have all non-null entries. Also all columns have either integer of float values. Now we will check the Outcome column's distribution. ","metadata":{}},{"cell_type":"code","source":"# To check distribution of target class\nsns.countplot(diabetes_df['Outcome']);","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:37.081421Z","iopub.execute_input":"2021-06-04T12:36:37.081769Z","iopub.status.idle":"2021-06-04T12:36:37.207674Z","shell.execute_reply.started":"2021-06-04T12:36:37.08174Z","shell.execute_reply":"2021-06-04T12:36:37.206641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is some considerable difference between positive and negative examples (but not skewed), this is to be taken care of later while splitting examples for training and testing. Its time to look at individual columns and get an idea about central tendency, dispersion etc of them.","metadata":{}},{"cell_type":"code","source":"# To get information regarding distributions of values in columns\ndiabetes_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:41.36429Z","iopub.execute_input":"2021-06-04T12:36:41.364634Z","iopub.status.idle":"2021-06-04T12:36:41.40601Z","shell.execute_reply.started":"2021-06-04T12:36:41.364605Z","shell.execute_reply":"2021-06-04T12:36:41.405184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that columns other than Age has minimum value of '0'. And these are to be handled. To better understand how values are distributed we can plot histograms for columns.","metadata":{}},{"cell_type":"code","source":"# Getting names of columns into cols, will be useful in plotting\ncols = diabetes_df.columns\nprint(cols)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:47.487535Z","iopub.execute_input":"2021-06-04T12:36:47.487879Z","iopub.status.idle":"2021-06-04T12:36:47.493682Z","shell.execute_reply.started":"2021-06-04T12:36:47.487849Z","shell.execute_reply":"2021-06-04T12:36:47.49237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting histograms for different column values:\nfig, axes = plt.subplots(3,3, figsize=(10,10), gridspec_kw = dict(hspace=0.5, wspace=0.6))\nfig.suptitle('Frequency plot for different column values')\nfor col, az in zip(cols, axes.flat):\n    sns.histplot(diabetes_df[col], ax = az)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:36:52.709815Z","iopub.execute_input":"2021-06-04T12:36:52.710194Z","iopub.status.idle":"2021-06-04T12:36:54.161839Z","shell.execute_reply.started":"2021-06-04T12:36:52.710162Z","shell.execute_reply":"2021-06-04T12:36:54.160915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We list some of observation from above plots:\n* It can be observed that many '0' values appear for columns Glucose, Insulin, BloodPressure and BMI. \n* Also we can observe a SkinThickness value close to 100, which is an unlikely.\n* The columns Pregnancies, DiabetesPedigreeFunction and Age looks fine. \n* Although Number of pregnancies above 10 is also observed, this is to be cross checked with age.\n\nTo be more clear of zero entries we will count the number of zeros in each column.","metadata":{}},{"cell_type":"code","source":"#To check the zero entries for each column\n(diabetes_df[cols]== 0).sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:37:01.630013Z","iopub.execute_input":"2021-06-04T12:37:01.630381Z","iopub.status.idle":"2021-06-04T12:37:01.639556Z","shell.execute_reply.started":"2021-06-04T12:37:01.630347Z","shell.execute_reply":"2021-06-04T12:37:01.638874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can assume that the missing values are replaced with zeros in the data collection stage considering huge share of zeros. \n\nThinking of handling these zero entries, since there are very large number of '0' for columns SkinThickness and Insulin, dropping of rows is not a good idea since we have only 768 rows of data. \n\nSo we are ready to do the following data handling tasks.\n1. Deal with entries equal to zero in columns Glucose, BloodPressure, SkinThickness, Insulin and BMI.\n2. Replace the unlikely SkinThickness value close to 100.\n3. Check and correct wrong entries in Pregnancies column if any.","metadata":{}},{"cell_type":"markdown","source":"### Task 1\nFirst we replace all zero entries of above mentioned columns with np.NaN. And then replace them with mean or median of column with the helps of histogram plots we have already plotted.","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:22:06.139014Z","iopub.execute_input":"2021-06-04T08:22:06.139396Z","iopub.status.idle":"2021-06-04T08:22:06.143568Z","shell.execute_reply.started":"2021-06-04T08:22:06.139358Z","shell.execute_reply":"2021-06-04T08:22:06.142567Z"}}},{"cell_type":"code","source":"#replacing zero values with np.NaN\ndiabetes_df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.NaN)\n(diabetes_df[cols]== 0).sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:37:05.372161Z","iopub.execute_input":"2021-06-04T12:37:05.372764Z","iopub.status.idle":"2021-06-04T12:37:05.387696Z","shell.execute_reply.started":"2021-06-04T12:37:05.372728Z","shell.execute_reply":"2021-06-04T12:37:05.386684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The zero values are now replacced from the required colums.\n\nBy looking at the histogram plots one can conclude that BloodPressure and BMI have somewhat symmetric plots and Glucose, SkinThickness and Insulin have skewed plots. So we will now replace the missing values for BloodPressure and BMI with **mean** and Glucose, SkinThickness and Insulin with **median**.\n","metadata":{}},{"cell_type":"code","source":"#Replacing missing values\ndiabetes_df['BloodPressure'] = diabetes_df['BloodPressure'].fillna(diabetes_df['BloodPressure'].mean())\ndiabetes_df['BMI'] = diabetes_df['BMI'].fillna(diabetes_df['BMI'].mean())\ndiabetes_df['Glucose'] = diabetes_df['Glucose'].fillna(diabetes_df['Glucose'].median())\ndiabetes_df['SkinThickness'] = diabetes_df['SkinThickness'].fillna(diabetes_df['SkinThickness'].median())\ndiabetes_df['Insulin'] = diabetes_df['Insulin'].fillna(diabetes_df['Insulin'].median())","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:37:10.316976Z","iopub.execute_input":"2021-06-04T12:37:10.31732Z","iopub.status.idle":"2021-06-04T12:37:10.328713Z","shell.execute_reply.started":"2021-06-04T12:37:10.31729Z","shell.execute_reply":"2021-06-04T12:37:10.327724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Task 2","metadata":{}},{"cell_type":"markdown","source":"Let's find out the index of high value entry in SkinThickness and replace it with median.","metadata":{}},{"cell_type":"code","source":"# To find the corresponding row\ndiabetes_df[diabetes_df['SkinThickness'] > 90]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:37:15.030328Z","iopub.execute_input":"2021-06-04T12:37:15.030706Z","iopub.status.idle":"2021-06-04T12:37:15.045463Z","shell.execute_reply.started":"2021-06-04T12:37:15.030672Z","shell.execute_reply":"2021-06-04T12:37:15.044414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace wrong entry with median\ndiabetes_df['SkinThickness'].loc[579] = diabetes_df['SkinThickness'].median()\ndiabetes_df.loc[579]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:37:18.637377Z","iopub.execute_input":"2021-06-04T12:37:18.637727Z","iopub.status.idle":"2021-06-04T12:37:18.648903Z","shell.execute_reply.started":"2021-06-04T12:37:18.637697Z","shell.execute_reply":"2021-06-04T12:37:18.648092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Task 3","metadata":{}},{"cell_type":"markdown","source":"Let's check the number of rows having more than 10 pregnancies and less than 30 age.","metadata":{}},{"cell_type":"code","source":"# Checking for number of pregnancies vs age for more than 10 values\ndiabetes_df[(diabetes_df['Pregnancies'] > 10) & (diabetes_df['Age'] < 30)].shape","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:37:22.755207Z","iopub.execute_input":"2021-06-04T12:37:22.755703Z","iopub.status.idle":"2021-06-04T12:37:22.76321Z","shell.execute_reply.started":"2021-06-04T12:37:22.75567Z","shell.execute_reply":"2021-06-04T12:37:22.762561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No entries with more than 10 pregnancies for age below 30. So the number of pregnancies column is error free. We have no task to complete here.","metadata":{}},{"cell_type":"markdown","source":"Once again we will look at the distribution of values in columns to see effect of our updating.","metadata":{}},{"cell_type":"code","source":"# To get information regarding distributions of values in columns\ndiabetes_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:37:27.309766Z","iopub.execute_input":"2021-06-04T12:37:27.310287Z","iopub.status.idle":"2021-06-04T12:37:27.349245Z","shell.execute_reply.started":"2021-06-04T12:37:27.310244Z","shell.execute_reply":"2021-06-04T12:37:27.348578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the column minimum values have changed.","metadata":{"execution":{"iopub.status.busy":"2021-06-04T10:24:22.191361Z","iopub.execute_input":"2021-06-04T10:24:22.191731Z","iopub.status.idle":"2021-06-04T10:24:22.197444Z","shell.execute_reply.started":"2021-06-04T10:24:22.1917Z","shell.execute_reply":"2021-06-04T10:24:22.196075Z"}}},{"cell_type":"markdown","source":"### **3. Exploratory Data Analysis**","metadata":{}},{"cell_type":"markdown","source":"Now we will look at pair plots and try to get some insights.","metadata":{}},{"cell_type":"code","source":"#Pair plots\nsns.pairplot(diabetes_df, hue = 'Outcome', height = 2);","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:39:12.66994Z","iopub.execute_input":"2021-06-04T12:39:12.670518Z","iopub.status.idle":"2021-06-04T12:39:30.185754Z","shell.execute_reply.started":"2021-06-04T12:39:12.670485Z","shell.execute_reply":"2021-06-04T12:39:30.184025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the pair plots we can observe few things: \n* Higher glucose level, higher BMI and greater age have more associated with positive diabetic. \n* Effects are much evident in case of glucose level. \n* The diabetisPredictionFunctionVariable is not showing any high influeces on diabetes chances.\n\nNow if we look at the correlation.","metadata":{}},{"cell_type":"code","source":"#plotting heatmap for correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(diabetes_df.corr(), square=True, linewidths=.5, annot=True, cbar=False);","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:41:57.435429Z","iopub.execute_input":"2021-06-04T12:41:57.435797Z","iopub.status.idle":"2021-06-04T12:41:58.30795Z","shell.execute_reply.started":"2021-06-04T12:41:57.43576Z","shell.execute_reply":"2021-06-04T12:41:58.306895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the plot we have observed a maximum correlation of 0.56 only and looking at values, we can conclude that the variables are weekly correlated.","metadata":{}},{"cell_type":"markdown","source":"### **4. Building Models**","metadata":{}},{"cell_type":"markdown","source":"### 4.1. Data Splitting","metadata":{}},{"cell_type":"markdown","source":"The examples are to be split into training and test set keeping thier relative class frequencies approximately same. For this we need set `stratify` as `y` in `train_test_split`. We can use our test data to evaluate performance of our Machine Learning models. Here 25% of data is taken as test examples.","metadata":{}},{"cell_type":"code","source":"# To split data into training and test sets\nfrom sklearn.model_selection import train_test_split\n\nX = diabetes_df.drop('Outcome', axis = 1) #drop target column to get X\ny = diabetes_df['Outcome'] #target column is y\n\nX_train, X_test, y_train,  y_test = train_test_split(X, y, test_size = 0.25, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:46:22.448121Z","iopub.execute_input":"2021-06-04T12:46:22.448497Z","iopub.status.idle":"2021-06-04T12:46:22.459407Z","shell.execute_reply.started":"2021-06-04T12:46:22.448463Z","shell.execute_reply":"2021-06-04T12:46:22.458477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('X_train shape : ', X_train.shape)\nprint('y_train shape : ', y_train.shape)\nprint('X_test shape  : ', X_test.shape)\nprint('y_test shape  : ', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:46:23.230768Z","iopub.execute_input":"2021-06-04T12:46:23.231351Z","iopub.status.idle":"2021-06-04T12:46:23.238438Z","shell.execute_reply.started":"2021-06-04T12:46:23.231301Z","shell.execute_reply":"2021-06-04T12:46:23.237094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2. Feature Scaling ","metadata":{}},{"cell_type":"markdown","source":"Since our eight features are having quite different ranges, we need to do feature scaling. This will ensure that during training of our model more weight is not given to features having higher values. \nHere we will use StandardScaler which standardize features by removing the mean and scaling to them to unit variance.\ni.e. rescale them to distribution of 0 mean and 1 standard deviation.","metadata":{}},{"cell_type":"code","source":"# Feature scaling\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:46:28.272665Z","iopub.execute_input":"2021-06-04T12:46:28.27303Z","iopub.status.idle":"2021-06-04T12:46:28.287153Z","shell.execute_reply.started":"2021-06-04T12:46:28.272999Z","shell.execute_reply":"2021-06-04T12:46:28.286172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3. Logistic Regression Model","metadata":{}},{"cell_type":"code","source":"# Import metrics to check performance of models\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:45:49.328416Z","iopub.execute_input":"2021-06-04T12:45:49.328786Z","iopub.status.idle":"2021-06-04T12:45:49.333158Z","shell.execute_reply.started":"2021-06-04T12:45:49.328753Z","shell.execute_reply":"2021-06-04T12:45:49.332094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\n\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\nprint('Accuracy : ' + '{:.2f}'.format(accuracy_score(y_test, y_pred)*100) +\" %\")\nprint('F1 score : ' + '{:.2f}'.format(f1_score(y_test, y_pred)))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:46:33.709464Z","iopub.execute_input":"2021-06-04T12:46:33.709829Z","iopub.status.idle":"2021-06-04T12:46:33.732719Z","shell.execute_reply.started":"2021-06-04T12:46:33.709797Z","shell.execute_reply":"2021-06-04T12:46:33.731306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.4. Support Vector Machines Model","metadata":{}},{"cell_type":"markdown","source":"Support vector machines (SVMs) are a particularly powerful and flexible class of supervised algorithms for classification. They work well with high-dimensional data in finding a decision boundary. Now we will use it on our data.","metadata":{}},{"cell_type":"code","source":"#Support vector machines\nfrom sklearn.svm import SVC\n\nsvc = SVC(kernel = 'rbf')\n\nsvc.fit(X_train, y_train)\n\ny_pred = svc.predict(X_test)\n\nprint('Accuracy : ' + '{:.2f}'.format(accuracy_score(y_test, y_pred)*100) +\" %\")\nprint('F1 score : ' + '{:.2f}'.format(f1_score(y_test, y_pred)))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:46:38.203473Z","iopub.execute_input":"2021-06-04T12:46:38.203821Z","iopub.status.idle":"2021-06-04T12:46:38.238308Z","shell.execute_reply.started":"2021-06-04T12:46:38.20379Z","shell.execute_reply":"2021-06-04T12:46:38.237161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.5. Random Forest Classifier Model","metadata":{}},{"cell_type":"markdown","source":"Random Forest uses multiple decision trees for prediction. These decision trees trained with randomly selected subset of training set and gives their prediction on test set. By majority vote Random Forest combines these predictions and give model prediction. ","metadata":{}},{"cell_type":"code","source":"#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\n\nrfc.fit(X_train, y_train)\n\ny_pred = rfc.predict(X_test)\n\nprint('Accuracy : ' + '{:.2f}'.format(accuracy_score(y_test, y_pred)*100) +\" %\")\nprint('F1 score : ' + '{:.2f}'.format(f1_score(y_test, y_pred)))\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:46:56.71366Z","iopub.execute_input":"2021-06-04T12:46:56.714023Z","iopub.status.idle":"2021-06-04T12:46:56.970841Z","shell.execute_reply.started":"2021-06-04T12:46:56.713992Z","shell.execute_reply":"2021-06-04T12:46:56.969695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **5. Conclusion**","metadata":{}},{"cell_type":"markdown","source":"* By looking at pair plot we found that higher glucose level much likely for women with diabetic condition. \n* Likelihood of diabetes based on family history was not evident from plots.\n* Performance of three algorithms namely Logistic Regression, Support vector Machines, Random Forest on the dataset is shown.\n* Based on requirement we need to select performance metric for models. That is if we do not want to miss any positive diagnosis we may require higher precision on positive cases.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}