{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nglove_dir = '../input/glove6b100dtxt/glove.6B.100d.txt'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"embedding_index = {}\nf = open(glove_dir)\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coef = np.asarray(values[1:], dtype='float32')\n    embedding_index[word] = coef\nf.close()\nprint(len(embedding_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a33aee4fbe947e6ab84ae60766196ddb873d79fa"},"cell_type":"code","source":"data_dir = '../input/hate-speech-dataset/hate_speech.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24aae96b1bdf93db94ad16e1faddf282f16a88ec"},"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35757a34b1f14faa068a5c11909b138ca2b08144"},"cell_type":"code","source":"texts = np.array(data['post'])\nlabels = np.array(data['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"863756da8d71fb43dc0d9b1f56d18d458338d6b6"},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nmaxlen = 100\nsamples = texts.shape[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"879f23c6a0780d30fda2a7a79651edd3cddc66ba"},"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\nword_index = tokenizer.word_index\nprint(sequences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e689715be20ef6100c753c74f30963740d0e685e"},"cell_type":"code","source":"data = pad_sequences(sequences, maxlen)\nprint(data.shape)\nprint(labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"62bb0b4ec949d287898979f59d446d5136557268"},"cell_type":"code","source":"x_train = data[:7925]\ny_train = labels[:7925]\n\nx_val = data[7925:8925]\ny_val = labels[7925:8925]\n\nx_test = data[8925:]\ny_test = labels[8925:]\n\nprint(x_train.shape)\nprint(x_val.shape)\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad10c9cbcb25a85884fbdd8f3e37c0f2790a4a49"},"cell_type":"code","source":"embedding_dim = 100\nembedding_matrix = np.zeros((1+len(word_index), embedding_dim))\n\nfor word, i in word_index.items():\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41ea2f339910056ce3a1f475f1b3c3c067df6d00"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense,CuDNNLSTM\n\nmodel = Sequential()\nmodel.add(Embedding(1+len(word_index), embedding_dim, input_length=maxlen))\nmodel.add(CuDNNLSTM(maxlen))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61dad2f33b9bac9f62633f7a5b6eb3eafd75bbf7"},"cell_type":"code","source":"model.layers[0].set_weights([embedding_matrix])\nmodel.layers[0].trainable = False\n\nprint(x_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b9a7e27268dd8e7495c2ce42fe1082f8fedf176"},"cell_type":"code","source":"model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\nhistory = model.fit(x_train,y_train,epochs=10,batch_size=32,validation_data=(x_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b5f78e98d407289ce80c574e723e81420d91d9e"},"cell_type":"code","source":"def cnfmatrix(y_test,results):\n    fp = 0.0\n    fn = 0.0\n    tp = 0.0\n    tn = 0.0\n    t = 0.0\n    n = 0.0\n    results.shape\n    for i in range(results.shape[0]):\n        if y_test[i]==1 and results[i]==1:\n            tp+=1\n            t+=1\n        elif y_test[i]==1 and results[i]==0:\n            fn+=1\n            t+=1\n        elif y_test[i]==0 and results[i]==1:\n            fp+=1\n            n+=1\n        elif y_test[i]==0 and results[i]==0:\n            tn+=1\n            n+=1\n    print(tp/results.shape[0],fp/results.shape[0])\n    print(fn/results.shape[0],tn/results.shape[0])\n    Precision  = tp/(tp+fp)\n    Recall = tp/(tp+fn)\n    print(\"Precision: \",Precision,\"Recall: \",Recall)\n    f1score = (2*Precision*Recall)/(Precision+Recall)\n    print(\"f1score: \",f1score)\n    print(\"accuracy: \",(tp+tn)/results.shape[0])\n    print(\"hate_acc: \", (tp)/t)\n    print(\"non_hate_acc: \", (tn)/n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"199b4375587cd375ab11c32d6120706c832e49fe"},"cell_type":"code","source":"predictions = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8118e73917151284ffbb7dd7413333d725f9c59c"},"cell_type":"code","source":"results = []\nfor prediction in predictions:\n    if prediction < 0.5:\n        results.append(0)\n    else:\n        results.append(1)\n        \nresults = np.array(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26c26a3698849ab66332ad4a78d15d759e1e18a2"},"cell_type":"code","source":"print(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c9e1765c5c2274a4b5ed00813c26be0ff718740"},"cell_type":"code","source":"cnfmatrix(y_test, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"522fd7967ca2e797596705c0c73861035229ab36","scrolled":false},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasRegressor,KerasClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n\ndef the_model():\n    model = Sequential()\n    model.add(Embedding(1+len(word_index), embedding_dim, input_length=maxlen))\n    model.add(CuDNNLSTM(maxlen))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n    return model\n\nann_estimator = KerasClassifier(build_fn= the_model, epochs=20, batch_size=None, verbose=True)\n\nboosted_ann = AdaBoostClassifier(base_estimator=ann_estimator, n_estimators = 5)\n\nboosted_ann.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf47c7e9a2d784b716a968bd623ca16c80932bce"},"cell_type":"code","source":"predictions = boosted_ann.predict_proba(x_test)\nresults  = [int(i[0] <  i[1]) for i in predictions]\ncnfmatrix(y_test, np.array(results))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f63e31f47f2f8544c3a1ec31fffe166fee134a8c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}