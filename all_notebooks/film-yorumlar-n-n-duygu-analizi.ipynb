{"cells":[{"metadata":{},"cell_type":"markdown","source":"# [Github](https://github.com/kubrakurt/turkish_movie_sentiment_analysis)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.layers import Embedding, GRU, Dense\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/turkish-movie-sentiment-analysis-dataset/turkish_movie_sentiment_dataset.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comments = lambda x : x[23:-24]\n\ndf[\"comment\"] = df[\"comment\"].apply(comments)\ndf[\"comment\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"floatize = lambda x : float(x[0:-2])\n\ndf[\"point\"] = df[\"point\"].apply(floatize)\ndf[\"point\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df[df[\"point\"] == 3].index, inplace = True)\ndf[\"point\"] = df[\"point\"].replace(1, 0)\ndf[\"point\"] = df[\"point\"].replace(2, 0)\ndf[\"point\"] = df[\"point\"].replace(4, 1)\ndf[\"point\"] = df[\"point\"].replace(5, 1)\ndf[\"point\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(inplace = True)\ndf.drop(\"index\", axis = 1, inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"comment\"] = df[\"comment\"].apply(lambda x: x.lower())\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punctuation(text):\n    no_punc = [words for words in text if words not in string.punctuation]\n    word_wo_punc = \"\".join(no_punc)\n    return word_wo_punc\n\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: remove_punctuation(x))\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: x.replace(\"\\r\", \" \"))\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: x.replace(\"\\n\", \" \"))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_numeric(corpus):\n    output = \"\".join(words for words in corpus if not words.isdigit())\n    return output\n\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: remove_numeric(x)) \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df[\"point\"].values.tolist()\ndata = df[\"comment\"].values.tolist()\n\ncutoff = int(len(data)*0.80)\n\nX_train, X_test = data[:cutoff], data[cutoff:]\ny_train, y_test = target[:cutoff], target[cutoff:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_words = 10000\ntokenizer = Tokenizer(num_words = num_words)\ntokenizer.fit_on_texts(data)\n# tokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_tokens = tokenizer.texts_to_sequences(X_train)\nX_test_tokens = tokenizer.texts_to_sequences(X_test)\n\nprint([X_train[1000]])\nprint(X_train_tokens[1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\nnum_tokens = np.array(num_tokens)\nnum_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(num_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(num_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_tokens = np.mean(num_tokens) + (2*np.std(num_tokens))\nmax_tokens = int(max_tokens)\nmax_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(num_tokens < max_tokens) / len(num_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens) \nX_test_pad = pad_sequences(X_test_tokens, maxlen = max_tokens)\n\nprint(X_train_pad.shape)\nprint(X_test_pad.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(X_train_tokens[800])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pad[2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = tokenizer.word_index\ninverse_map = dict(zip(idx.values(), idx.keys()))\n\ndef tokens_to_string(tokens):\n    words = [inverse_map[token] for token in tokens if token != 0]\n    text = \" \".join(words) # Kelimeler aralarında boşluk bırakılarak ard arda yazılacaktır.\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokens_to_string(X_train_tokens[350])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_size = 50\nmodel = Sequential()\nmodel.add(Embedding(input_dim = num_words, output_dim = embedding_size, input_length = max_tokens, name = \"embedding_layer\"))\nmodel.add(GRU(units = 16, return_sequences = True))\nmodel.add(GRU(units = 8, return_sequences = True))\nmodel.add(GRU(units = 4))\nmodel.add(Dense(1, activation = \"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(lr = 1e-3)\nmodel.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pad = np.array(X_train_pad)\ny_train = np.array(y_train)\n\nmodel.fit(X_train_pad, y_train, epochs = 5, batch_size = 256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test_pad[0:1000])\ny_pred = y_pred.T[0]\n# y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cls_pred = np.array([1.0 if p > 0.5 else 0.0 for p in y_pred])\ncls_true = np.array(y_test[0:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"incorrect = np.where(cls_pred != cls_true)\nincorrect = incorrect[0]\n# incorrect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(incorrect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = incorrect[10]\nX_test[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cls_true[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}