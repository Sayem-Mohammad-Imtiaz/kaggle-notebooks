{"cells":[{"metadata":{},"cell_type":"markdown","source":"Let's begin with importing the library that will be used along this notebook.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# data manipulation\nimport pandas as pd\nimport numpy as np\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\n\n# regular expression & itertools library\nimport re\nfrom itertools import chain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the dataset and see what we get.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = pd.read_csv(\"../input/data-scientist-role-in2020/DataScience_jobs.csv\",index_col='Unnamed: 0')\n\n# show dataset\ndisplay(ds.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 1282 entries and 5 categorical variables.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Data Dimensions:\", ds.shape,\"\\n\")\nprint(ds.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Let's see what kind of entries that missing out from the dataset.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(ds.isnull().sum())\nnull_index = ds[ds.skills.isnull()].index\nds.loc[null_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 3 missing values in **skills** variable. Since these entries has no specific locations, we can remove it from the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.dropna(subset=[\"skills\"],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## On Locations Variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's see the unique values from the locations variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sort(ds.locations.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are a lot inconsistency of the location name from the locations entries. We can fix it begin with:\n* Create new row(s) from locations name that include coma (,) in it.\n* Fix the locations name with bracket.\n* Fix the locations name that sounds synonim.\n* Remove the duplicated rows.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# some functions\n\n# return list from series of comma-separated strings\ndef chainer(s, pattern):\n    return list(chain.from_iterable(s.str.split(pattern)))\n\n# word changer\ndef word_changer(name,target,new_name):\n    if target in name.split(\" \"):\n        name = new_name\n    elif target == name:\n        name = new_name\n    return name\n\n# calculate lengths of splits\nlens = ds['locations'].str.split(\",\").map(len)\n\n# create new dataframe, repeating or chaining as appropriate\nds = pd.DataFrame({\n    'roles': np.repeat(ds['roles'], lens),\n    'companies': np.repeat(ds['companies'], lens),\n    'locations': chainer(ds['locations'], \",\"),\n    'experience': np.repeat(ds['experience'], lens),\n    'skills': np.repeat(ds['skills'], lens)\n})\n\n# capitalize locations name\nds.locations = ds.locations.apply(lambda x: x.strip().upper())\ndisplay(ds.head())\n\n# fix locations name with the bracket\nfor i,location in ds.locations.items():\n    if location.find(\"(\") >= 0:\n        pos = location.find(\"(\")\n        ds.locations.loc[i] = location[:pos].strip()\n\n# fix the locations name that sounds synonim\ntarget = [\"BANGALORE\",\"BENGALURU\",\"INDIA\",\"BHUBANESWAR\",\"DELHI\",\"MUMBAI\",\"NAGPUR\",\"OTHER NATIONAL LOCATIONS\"]\nnew = [\"BENGALURU\",\"BENGALURU\",\"INDIA\",\"BHUBANESHWAR\",\"DELHI\",\"MUMBAI\",\"NAGPUR\",\"INDIA\"]\n\nfor i in range(len(target)):\n    ds.locations = ds.locations.apply(lambda x: word_changer(x,target[i],new[i]))\n\n# country list    \ncountry = [\"JAPAN\",\"DENMARK\",\"GERMANY\",\"MALAYSIA\"\"POLAND\",\"SOUTH KOREA\",\"SPAIN\",\"UNITED KINGDOM\",\"UNITED STATES\",\"SINGAPORE\"]    \n    \n# fix other locations name\ntarget = [\"INTERNATIONAL\",\"ANY\",\"NOT SPECIFIED\",\"OVERSEAS\",\"REMOTE\"]\nother = \"OTHER\"\n\nfor i in range(len(target)):\n    ds.locations = ds.locations.apply(lambda x: word_changer(x,target[i],other))\n    \n# remove duplicated rows from dataset\nprint(f\"{ds.duplicated().sum()} duplicated rows successfully removed out.\",\"\\n\")\nds.drop_duplicates(inplace=True)\nds.reset_index(drop=True, inplace=True)\nprint(\"Rows Remain:\", ds.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sort(ds.locations.unique()))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds_india = ds[~ds.locations.isin(np.append(country,[\"OTHER\",\"INDIA\"]))]\n\nplt.figure(figsize=(15,8))\nchart = sns.countplot(data=ds_india, y=\"locations\", order=ds_india.locations.value_counts().index[:20], palette=\"terrain\")\n\nfor i in chart.patches:\n    chart.text(i.get_width()+1, i.get_y()+.6, str(i.get_width()), fontsize=12, color='dimgrey')\n\nplt.title(\"Top 20 Locations in India that Demanding Data Scientist Profession\")    \nplt.xticks(rotation=90)\nplt.xlabel(\"Demand(s)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bengaluru, Mumbai, Pune, Hyderabad, Gurgaon, Delhi, Chennai, and Noida are the top locations in India that demanding profession Data Scientist.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"international = ds[ds.locations.isin(country)]\n\nplt.figure(figsize=(15,3))\nchart = sns.countplot(data=international, y=\"locations\", order=international.locations.value_counts().index, palette=\"rainbow\")\n\nfor i in chart.patches:\n    chart.text(i.get_width()+.04, i.get_y()+.5, str(i.get_width()), fontsize=13, color='dimgrey')\n\nplt.title(\"Other Countries that India Demanding for Data Scientist Profession\")    \nplt.xticks(rotation=90)\nplt.ylabel(\"Country\"); plt.xlabel(\"Demand(s)\");\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like India demanding Data Scientist Profession from other countries too, like: Japan, United Kingdom, United States, Germany, Denmark, Shouth Korea, and Singapore.\n___","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## On Roles Variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, we need to change some word Sr to Senior, Jr to Junior, Mgr to Manager and so on. After that we remove unecessary character from roles, and look for word used the most before word \"Data Scientist\" and use that as the kind profession for Data Scientist","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# capitalize all roles name\nds.roles = ds.roles.apply(lambda x: x.upper())\n\n# unnecessary char removal\ntb = [\"/\",\",\",\"-\",\"â€“\",\"_\",\"(\",\")\",\".\",\"|\",\"[\",\"]\",\"+\"]\n\nfor i in range(len(tb)):\n    ds.roles = ds.roles.apply(lambda x: x.replace(tb[i],\" \"))\n    \n# change some word\ntarget = [\"SR\",\"JR\",\"DL\",\"ML\",\"MGR\"]\nalt = [\"SENIOR\",\"JUNIOR\",\"DEEP LEARNING\",\"MACHINE LEARNING\",\"MANAGER\"]\n\nfor x in range(len(target)):\n    for i,role in ds.roles.items():\n        if target[x] in role.split(\" \"):\n            ds.roles[i] = ds.roles[i].replace(target[x],alt[x])\n    \n# change some character\nds.roles = ds.roles.apply(lambda x: x.replace(\"R&D\",\"RESEARCH AND DEVELOPMENT\"))\nds.roles = ds.roles.apply(lambda x: x.replace(\"&\",\" AND \"))\nds.roles = ds.roles.apply(lambda x: x.replace(\"@\",\" AT \"))\n\n# profession name check function\ndef profession_partition(series,target):\n    \n    # empty var\n    df = pd.DataFrame()\n    df_index = []\n    \n    # get target value and its index\n    for i,role in series.items():\n\n        if role.find(target) >= 0:\n            parts = role.partition(target)\n\n            col1 = parts[0].strip()\n            col2 = parts[1]\n            col3 = parts[2].strip()\n\n            data = {\n                'before':col1,\n                'data_scientist':col2,\n                'after':col3\n            }\n            \n            # store it into dataframe\n            if df.empty:\n                df = pd.DataFrame([data])\n            else:\n                data = pd.DataFrame([data])\n                df = pd.concat([df,data])\n            \n            # get the index\n            df_index.append(i)\n            \n    # reset indexes\n    df.index = df_index\n    \n    return df\n\n# check for word before and after data scientist\ndsc = profession_partition(ds.roles,\"DATA SCIENTIST\")\ncount_before = dsc.before.value_counts()\ncount_before[count_before > 5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 515 blank space or not even word before data scientist, 125 Senior word, 42 Lead word, 13 Junior word, 11 Associate word, 8 Full Stack word, and 7 Manager word. Let's use that words and see what the most demanding position","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# professions and one terms\nposition = [\"SENIOR MANAGER\",\"SENIOR DATA SCIENTIST\",\"LEAD DATA SCIENTIST\",\"PRINCIPAL DATA SCIENTIST\",\n            \"JUNIOR DATA SCIENTIST\",\"ASSOCIATE DATA SCIENTIST\",\"FULL STACK DATA SCIENTIST\",\"MANAGER DATA SCIENTIST\",\n            \"DATA SCIENTIST\",\"DATA SCIENE ENGINEER\",\"DATA ENGINEER\",\"SENIOR DATA ANALYST\",\"DATA ANALYST\",\n            \"SENIOR ANALYST\",\"MACHINE LEARNING ENGINEER\",\"DEEP LEARNING ENGINEER\",\n            \"DATA SCIENCE TRAINER\",\"BUSINESS ANALYST\",\"PYTHON DEVELOPER\",\"STATISTICIAN\",\"SYSTEM ENGINEER\",\n            \"ACADEMIC COUNSELOR\",\"ASSISTANT MANAGER\"]\n\nterms = [\"MACHINE LEARNING\",\"DEEP LEARNING\",\"ARTIFICIAL INTELLIGENCE\",\"PREDICTIVE MODELING\",\"STATISTICAL ANALYSIS\",\n         \"BIG DATA\",\"DATA SCIENCE\",\"DATA ENGINEERING\",\"E COMMERCE\"]\n\nwords = []\n\nfor _,role in ds.roles.items():\n    regex = re.findall(\"[A-Z]+\",role)\n    \n    # combine word follow by position words\n    for an in position:\n        n = len(an.split(\" \"))\n        valid = 0\n        for word in an.split(\" \"):\n            if word in regex:\n                valid += 1\n        if valid == n:\n            for word in an.split(\" \"):\n                regex.remove(word)\n            regex.append(an)\n    \n    # combine word follow by terms words\n    for an in terms:\n        n = len(an.split(\" \"))\n        valid = 0\n        for word in an.split(\" \"):\n            if word in regex:\n                valid += 1\n        if valid == n:\n            for word in an.split(\" \"):\n                regex.remove(word)\n            regex.append(an)\n    \n    for r in regex:\n        words.append(r)\n\n# convert list to pandas Series\nwords = pd.Series(words)\n\n# plot words with Data Scientist in roles\nax = words[words.isin(position)].value_counts().plot.barh(figsize=(15,8), color=\"blue\")\n\n# set individual bar lables using above list\nfor v in ax.patches:\n    # get_width pulls left or right; get_y pushes up or down\n    ax.text(v.get_width()+2, v.get_y()+0.4, str(v.get_width()), fontsize=12, color='dimgrey')\n\nax.invert_yaxis()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Scientist are the most demanding position for Data Science Job in India. Followed by Senior Data Scientist, Lead Data Scientist, Data Engineer, Data Analyst, Machine Learning Engineer and so on\n___","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## On Companies Variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Frist, clean it up, and then see the top companies in India that demanding Data Science profession the most.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# capitalize all the name of companies variable\nds.companies = ds.companies.apply(lambda x: x.upper())\n\n# replace some words\nfor i,com in ds.companies.items():\n    \n    # remove BIGSHYFT HIRING FOR sentence from companies name\n    if \"FOR\" in com.split(\" \"):\n        ds.companies[i] = ds.companies[i].replace(\"BIGSHYFT HIRING FOR \",\"\").strip()\n    \n    # replace PVT with PRIVATe\n    if \"PVT\" in com.split(\" \"):\n        ds.companies[i] = ds.companies[i].replace(\"PVT\",\"PRIVATE\").strip()\n    if \"PVT.\" in com.split(\" \"):\n        ds.companies[i] = ds.companies[i].replace(\"PVT.\",\"PRIVATE\").strip()\n        \n    # replace LTD with LIMITED\n    if \"LTD\" in com.split(\" \"):\n        ds.companies[i] = ds.companies[i].replace(\"LTD\",\"LIMITED\").strip()\n    if \"LTD.\" in com.split(\" \"):\n        ds.companies[i] = ds.companies[i].replace(\"LTD.\",\"LIMITED\").strip()\n\n# plot words with Data Scientist in roles\nax = ds.companies.value_counts()[:15].plot.barh(figsize=(15,8), color=\"green\")\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    ax.text(i.get_width()+.3, i.get_y()+0.45, str(i.get_width()), fontsize=12, color='dimgrey')\n\nax.invert_yaxis()\nplt.title(\"Top 15 Companies in India that Demanding Data Scientist profession\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, Huquo Consulting are the top companies that demanding Data Scientist profession in India. While based on locations, Gurgaon are the highest place where Huquo Consulting looking for Data Scientist profession.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds[ds.companies == \"HUQUO CONSULTING PRIVATE LIMITED\"].locations.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## On Skills Variable","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# capitalize and transform word into one line\nds.skills = ds.skills.apply(lambda x: x.upper())\nds.skills = ds.skills.apply(lambda x: \", \".join(x.split(\"\\n\")))\n\n# assign into new dataframe while the index == roles that has word \"Data Scientist\" in it\ndf = ds.loc[dsc.index]\n\n# get all skills\nwords = []\nfor skills in ds.skills:\n    words  = np.append(words,skills.split(\", \"))\n    \nwords = pd.Series(words)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(f\"There are {len(words.sort_values().unique())} unique skills that required for being an Data Scientist in India\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# fix the list\nremove_index = []\nsplit_result = []\nfor i,skill in words.items():\n    \n    # remove long text\n    if len(skill) > 50:\n        remove_index.append(i)\n        \n    # remove DATA SCIENTIST word\n    if (skill.find(\"DATA SCIENTIST\") >= 0) or (skill.find(\"DATA SCINETIST\") >= 0) or (skill.find(\"DATA ANALYST\") >= 0):\n        remove_index.append(i)\n        \n    # change AI/ML into ARTIFICIAL INTILLEGENCE and MACHINE LEARNING\n    if (skill.find(\"/\") >= 0) and (skill.find(\"AI\") >= 0) and (skill.find(\"ML\") >= 0):\n        words[i] = \"ARTIFICIAL INTELLIGENCE, MACHINE LEARNING\"\n        \n    # change AI/ML into ARTIFICIAL INTILLEGENCE and MACHINE LEARNING    \n    if (skill.find(\"DECISSION\") >= 0) or (skill.find(\"DECISION TREE\") >= 0):\n        words[i] = \"DECISION TREE\"\n        \n    # merge BIG DATA word\n    if (skill.find(\"BIG\") >= 0) and (skill.find(\"DATA\") >= 0):\n        words[i] = \"BIG DATA\"\n        \n    # merge CLOUD word\n    if re.search(r\"^CLOUD \",skill):\n        words[i] = \"CLOUD\"\n        \n    # merge AGILE word\n    if re.search(r\"^AGILE \",skill):\n        words[i] = \"AGILE\"\n        \n    # merge SUPPLY CHAIN word\n    if skill.find(\"SUPPLY CHAIN\") >= 0:\n        words[i] = \"SUPPLY CHAIN\"\n    \n    # merge INTERNSHIP word\n    if (skill.find(\"INTERNSHIP\") >= 0) or (re.search(r\"INTERN\",skill)):\n        remove_index.append(i)\n    \n    # merge R word\n    if re.search(r\"^R \",skill):\n        words[i] = \"R\"\n        \n    # merge R word\n    if re.search(r\"^SQL \",skill):\n        words[i] = \"SQL\"\n    \n    # merge CONSULT word\n    if skill.find(\"CONSULT\") >= 0:\n        words[i] = \"CONSULTING\"\n        \n    # merge FINANC word\n    if skill.find(\"FINANC\") >= 0:\n        words[i] = \"FINANCE\"\n        \n    # merge STATISTICS word\n    if \"STATISTICAL\" in skill.split(\" \"):\n        words[i] = \"STATISTICS\"\n        \n    # merge ANALYTICS word\n    if (\"ANALYTICAL\" in skill.split(\" \")) or (re.search(r\"^ANALYST\",skill)):\n        words[i] = \"ANALYTICS\"\n        \n    # change PYTHON / R into PYTHON, R \n    if (\"PYTHON\" in skill.split(\" \")) and (\"R\" in skill.split(\" \")):\n        words[i] = \"PYTHON, R\"\n        \n    # merge PYTHON word\n    if re.search(r\"PYTHON\",skill):\n        words[i] = \"PYTHON\"\n        \n    # change DEEP LEARNING AND ARTIFICIAL INTELLIGENCE into DEEP LEARNING, ARTIFICIAL INTELLIGENCE\n    if re.search(r\"DEEP LEARNING AND ARTIFICIAL INTELLIGENCE\",skill):\n        words[i] = words[i].replace(\" AND \",\", \")\n        \n    # merge DEEP LEARNING word\n    if re.search(r\"DEEP LEARNING\",skill):\n        words[i] = \"DEEP LEARNING\"\n        \n    # merge MACHINE LEARNING word\n    if \"ML\" in skill.split(\" \"):\n        words[i] = \"MACHINE LEARNING\"\n    \n    # merge MACHINE LEARNING word\n    if skill.find(\"MACHINE LEARNING\") >= 0:\n        words[i] = \"MACHINE LEARNING\"\n        \n    # merge ARTIFICIAL INTELLIGENCE word\n    if \"AI\" in skill.split(\" \"):\n        words[i] = \"ARTIFICIAL INTELLIGENCE\"\n        \n    # remove DATA SCIENTIST word\n    if skill.find(\"DATA SCIENCE\") >= 0:\n        remove_index.append(i)        \n\n    # devide line with coma (,) and make it new row\n    if skill.find(\", \") >= 0:\n        if len(split_result) == 0:\n            split_result = skill.split(\", \")\n        else:\n            split_result = np.append(split_result,skill.split(\", \"))\n        remove_index.append(i)\n        \n# drop some unwanted value\nwords.drop(remove_index, inplace=True)\n\n# insert splited array\nwords = pd.Series(np.append(words,split_result))\n        \nall_skills = words.sort_values().unique()\n\n# plot\nfig = plt.figure(figsize=(15,20))\nax = sns.countplot(y=words[words.isin(all_skills)],\n                   order=pd.Series(words[words.isin(all_skills)]).value_counts().sort_values(ascending=False).index[:100], palette=\"ocean\")\n\nfor x in ax.patches:\n    ax.text(x.get_width()+1, x.get_y()+.655, str(x.get_width()), fontsize=10, color='dimgrey')\n\nplt.title(f\"Top 100 Skills that Require for being Recruite as an Data Scientist in India\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Machine Learning are the top skills that must be required if you want to be an Data Scientist in India, and of course it could be good if you combine it with other skills too.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## On Experience Variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Every recruiter in India type the year of experience very differently. But what isteresting me is that they almost looking for candidate with 5-10 or 3-8 years experience as Data Scientist on the field ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# create new dataframe for experience year\nexp = pd.DataFrame(np.sort(df.experience.unique()), columns=['experience'])\nexp['start_yr'] = pd.to_numeric(exp.experience.apply(lambda x: re.findall(\"[0-9]+\",x)[0]))\nexp['end_yr'] = pd.to_numeric(exp.experience.apply(lambda x: re.findall(\"[0-9]+\",x)[1]))\nexp.sort_values(by=['start_yr','end_yr'], inplace=True)\n\n# plot the data and sort it by the experience\nvalues = df.experience.value_counts().loc[exp.experience.unique()]\nax = values.plot.barh(color=\"orange\", figsize=(15,20))\n\nfor i in ax.patches:\n    ax.text(i.get_width()+.3, i.get_y()+.4, str(i.get_width()), fontsize=10, color='dimgrey')\n\nax.invert_yaxis()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}