{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Outline:\n\n- 1. Dataset Observation\n\n     \n     \n- 2. Exploratory Data Analysis and Cleaning\n    \n   - Missing Values\n   - Univariate Analysis (Target)\n   - Univariate Analysis (Independent Variables)\n   - Multivariate Analysis\n   - Outliers\n   - Normalization\n   - Correlation\n        \n    \n- 3. Model Preparation\n\n    - Split training and testing\n    - Encoding\n    \n    \n- 5. Models and Tuning / Evaluation Metrics\n    \n    - Regression Algorithms\n    - RMSE / MSE / MAE","metadata":{}},{"cell_type":"markdown","source":"# 1. Data Observation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/bigmart-sales-data/Train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train Shape: \", df_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_df = df_train.select_dtypes(include = 'object')\nnumerical_df = df_train.select_dtypes(exclude = 'object')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(categorical_df.columns)} Categorical Attributes\")\nprint(f\"There are {len(numerical_df.columns)} Numerical Attributes\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis\n\nExploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods.\n\nWe will be improve our features as we go through the visulizations. \n\nBut first, let's analyze the missing values.","metadata":{}},{"cell_type":"code","source":"xdf = df_train.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing Values","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,8))\nsns.heatmap(xdf.isnull(), cbar = False);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we know <b> Item_Weight </b> and <b> Outlet_Size </b> contains huge number of \"NaN\" but how much?","metadata":{}},{"cell_type":"code","source":"## Let's list them out:\n\ntotal = xdf.isnull().sum().sort_values(ascending = False)\npercent = ((xdf.isnull().sum() / xdf.shape[0]) * 100).sort_values(ascending = False)\npercent = np.round(percent, 3)\ntypes = xdf[percent.index].dtypes\n\nmissing_data = pd.concat([total, percent, types], axis = 1, keys = [\"Total\",\"Percent\",\"Type\"])\nmissing_data.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the values in <b> % </b>. <b> 28.27% </b> and<b> 17.16 % </b> values are missing in <b> Outlet_Size </b> and <b> Item_Weight </b> respectively.","metadata":{}},{"cell_type":"markdown","source":"### Outlet_Size \n\nSince this is a categorical attribute we will impute by using mode","metadata":{}},{"cell_type":"code","source":"xdf['Outlet_Size'].fillna(xdf['Outlet_Size'].mode()[0], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Item_Weight \n\nIt is a numeric variable, so we will be replacing it by <b> median </b>","metadata":{}},{"cell_type":"code","source":"xdf['Item_Weight'].fillna(xdf['Item_Weight'].median(), inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's confirm the impute","metadata":{}},{"cell_type":"code","source":"xdf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate Analysis\n\nStarting with the analyzation of <b> Target Attribute </b>","metadata":{}},{"cell_type":"code","source":"xdf['Item_Outlet_Sales'].describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Let's check the distribution of the Target Attribute\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10,6))\nsns.histplot(data = xdf, x = 'Item_Outlet_Sales', kde = True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## let's confirm the outliers\n\nplt.figure(figsize = (10,8))\nsns.boxplot( x = 'Item_Outlet_Sales', data = xdf);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, it is positively skewed and also containes some outliers.First let's remove outliers.","metadata":{}},{"cell_type":"code","source":"## First we will remove the outliers from this attribute\n## function to remove outlier\n\ndef remove_outliers(dataframe, column):\n    \n    Q3 = dataframe[column].quantile(0.75)\n    Q1 = dataframe[column].quantile(0.25)\n    \n    IQR = Q3 - Q1\n    \n    upper = Q3 + (1.5 * IQR)\n    lower = Q1 - (1.5 * IQR)\n    \n    df_no_outlier = dataframe[(dataframe[column] > lower ) & (dataframe[column] < upper)]\n\n    return df_no_outlier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Outliers form Item_Outlet_Sales\n\nxdf = remove_outliers(xdf, \"Item_Outlet_Sales\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quickly checking the result in boxplot\n\nplt.figure(figsize = (8,8))\nsns.boxplot(x = 'Item_Outlet_Sales', data = xdf);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will not be fixing skewness in our <b> target attribute </b> as it given incorrect <b> RMSE </b>","metadata":{}},{"cell_type":"code","source":"## Function for fixing positive skewness\ndef sqrt_transformation(dataframe):\n    return np.sqrt(dataframe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xdf['Item_Outlet_Sales'] = xdf['Item_Outlet_Sales'].map(sqrt_transformation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After fixing skewness\n\nplt.figure(figsize = (10,6))\nsns.histplot(data = xdf, x = 'Item_Outlet_Sales', kde = True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate Analysis (Independent Variables)","metadata":{}},{"cell_type":"code","source":"xxdf = xdf.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in numerical_df:\n    sns.displot(data = xxdf, x = i, kde = True, aspect = 2, height = 6);\n    plt.xlabel(i, fontsize = 12)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a note, which <b> feature </b> has skewed dataset.","metadata":{}},{"cell_type":"code","source":"# Checking for outliers\n\nfor i in numerical_df:\n    plt.figure(figsize =(8,6))\n    sns.scatterplot(data = xxdf, y = xdf.index, x = i);\n    plt.xlabel(i, fontsize = 12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also, let's take a note which <b> Attribute </b> contains outliers.","metadata":{}},{"cell_type":"code","source":"# Confirming the outliers\n\nfor i in numerical_df:\n    plt.figure(figsize =(8,6))\n    sns.boxplot(data = xxdf, y = i);\n    plt.xlabel(i, fontsize = 12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Observations: </b>\n\nItem_Visibility contains outliers, and as well as it is positively skewed on both the dastaset. Let's fix this.","metadata":{}},{"cell_type":"code","source":"sns.displot(data = xxdf, x = 'Item_Visibility', kde = True, aspect = 2, height = 6);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It contains a 0 value, let's fix that too.","metadata":{}},{"cell_type":"code","source":"## First Removing strange '0'\n\nxxdf['Item_Visibility'].replace(0, xxdf['Item_Visibility'].median(), inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Treating Postive skewness\n\nxxdf['Item_Visibility'] = xxdf[\"Item_Visibility\"].map(sqrt_transformation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Outliers\n\nxxdf = remove_outliers(xxdf, \"Item_Visibility\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After remvoing skewness and fixing outliers on trainset\n\nsns.displot(x = 'Item_Visibility', data = xxdf, aspect = 2, height = 6, kde = True);","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate Analysis\n\nFirst let's see the scatter plot of all the <b> Numerical variables</b> in term of <b> Item_Outlet_Sales </b>","metadata":{}},{"cell_type":"code","source":"for i in numerical_df:\n    plt.figure(figsize =(8,6))\n    sns.scatterplot(data = xxdf, x = i, y = xxdf['Item_Outlet_Sales']);\n    plt.xlabel(i, fontsize = 12)\n    plt.ylabel(\"Sales\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We observe, <b> Item_MRP </b> has linear relationship","metadata":{}},{"cell_type":"code","source":"bi_df = xxdf.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate Analysis (Categorical)","metadata":{}},{"cell_type":"code","source":"categorical_df.columns","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Countplot","metadata":{}},{"cell_type":"code","source":"for i in categorical_df:\n    plt.figure(figsize = (10,8))\n    sns.countplot( y = i, data = bi_df);   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Observations: </b>\n\n- Item Identifier: There are lot of individual Item Identifiers.\n- Item_Fat_Content: We have multiple same values, let's fix it.\n- Fruits & Vegies, Frozen food, Dariy, Household and Snacks has highest number of counts.\n- Supermarket has higher number of counts.\n\nFirst let's fix, <b> Item_Fat_Content","metadata":{}},{"cell_type":"code","source":"bi_df['Item_Fat_Content'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bi_df['Item_Fat_Content'] = bi_df['Item_Fat_Content'].map({\"low fat\": \"Low Fat\",\n                                                           \"Low Fat\": \"Low Fat\",\n                                                         \"LF\":\"Low Fat\",\n                                                         \"Regular\":\"Regular\",\n                                                         \"reg\":\"Regular\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bi_df['Item_Fat_Content'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> In term of Sales? </b>\n","metadata":{}},{"cell_type":"code","source":"for i in categorical_df:\n    plt.figure(figsize = (10,8))\n    sns.boxplot( y = i, x = bi_df['Item_Outlet_Sales'],data = bi_df);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b> Observations: </b>\n- In terms of 'Outlet_Type', Supermarket has highest demand (Type1 and Type3)\n- Starchy Food, Dairy, Fruits & Vegetables and Households has highest sales. But most of them all equal in terms of overall sales.\n","metadata":{}},{"cell_type":"markdown","source":"## Skewness on Numbers","metadata":{}},{"cell_type":"code","source":"for i in numerical_df:\n    print(\"\\n\")\n    print(i)\n    print(\"-\" * 20)\n    print(\"Skewness: %f\" % bi_df[i].skew())\n    print(\"Kurtosis: %f\" % bi_df[i].kurt())\n    print(\"-\" * 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_df = bi_df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Transformation","metadata":{}},{"cell_type":"code","source":"categorical_df.columns","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding \n\nLet's encode all the categorical values, and check the correlation of all the values with 'SalePrice'","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = preprocessing.LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_df = tf_df.select_dtypes(include = 'object')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_df = tf_df.copy()\nfor i in categorical_df:\n    label_df[i] = label_encoder.fit_transform(tf_df[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation","metadata":{}},{"cell_type":"code","source":"corrmat =label_df.corr()\nf, ax = plt.subplots(figsize = (20,9))\nsns.heatmap(corrmat, vmax = .8, annot = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping unrelated Columns","metadata":{}},{"cell_type":"code","source":"drop_columns = ['Item_Visibility','Outlet_Size','Outlet_Establishment_Year','Outlet_Type','Item_Weight','Item_Identifier']\n\ntf_df.drop(drop_columns, axis =1 , inplace = True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One Hot Encoding","metadata":{}},{"cell_type":"code","source":"tf_df = pd.get_dummies(tf_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing the Dataset","metadata":{}},{"cell_type":"code","source":"X = tf_df.drop(['Item_Outlet_Sales'], axis = 1)\ny = tf_df['Item_Outlet_Sales']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling the Dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX1 = scaler.fit_transform(X)\nX = pd.DataFrame(data = X1, columns = X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting Dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling and Evaluation Metrics","metadata":{}},{"cell_type":"markdown","source":"### Linear Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nimport math\n\n\nlr = LinearRegression(normalize = True)\nlr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_predict = lr.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yp = lr.predict(X_test)\nprint(\"R2 Score:\", r2_score(y_test, lr_predict))\nprint(\"Mean Squarred Error:\", mean_squared_error(y_test, lr_predict))\nprint(\"RMSE:\", math.sqrt(mean_squared_error(y_test, lr_predict)))\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(y_test,lr_predict)))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBOOST REGRESSOR","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(n_estimators = 1000, learning_rate = 0.05)\nxgb.fit(X_train, y_train)\n\npredict = xgb.predict(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"R2 Score:\", r2_score(y_test, predict))\nprint(\"Mean Squarred Error:\", mean_squared_error(y_test, predict))\nprint(\"RMSE:\", math.sqrt(mean_squared_error(y_test, predict)))\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(y_test,predict)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LASSO REGRSSOR","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls = Lasso(alpha = 0.01)\nls.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso_pred = ls.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"R2 Score:\", r2_score(y_test, lasso_pred))\nprint(\"Mean Squarred Error:\", mean_squared_error(y_test, lasso_pred))\nprint(\"RMSE:\", math.sqrt(mean_squared_error(y_test, lasso_pred)))\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(y_test,lasso_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LGBMRegressor","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm = LGBMRegressor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_pred = lgbm.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"R2 Score:\", r2_score(y_test, lgbm_pred))\nprint(\"Mean Squarred Error:\", mean_squared_error(y_test, lgbm_pred))\nprint(\"RMSE:\", math.sqrt(mean_squared_error(y_test, lgbm_pred)))\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(y_test,lgbm_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators = 50, max_depth = 15, random_state = 47, min_samples_leaf = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_pred = rf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"R2 Score:\", r2_score(y_test, rf_pred))\nprint(\"Mean Squarred Error:\", mean_squared_error(y_test, rf_pred))\nprint(\"RMSE:\", math.sqrt(mean_squared_error(y_test, rf_pred)))\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(y_test,rf_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DecisionTreeRegressor","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt = DecisionTreeRegressor()\n\nparam_dist = {\n            'max_depth': [2,5,10,50,25,30,40,],\n}\n\ndt_gs = GridSearchCV(dt, param_grid = param_dist, cv = 6)\ndt_gs.fit(X_train, y_train)\n\ndt_predict = dt_gs.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"R2 Score:\", r2_score(y_test, dt_predict))\nprint(\"Mean Squarred Error:\", mean_squared_error(y_test, dt_predict))\nprint(\"RMSE:\", math.sqrt(mean_squared_error(y_test, dt_predict)))\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(y_test,dt_predict)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}