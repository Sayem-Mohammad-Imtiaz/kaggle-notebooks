{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Main libraries\nimport os\nimport pandas as pd\nimport numpy as np\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\n#import plotly.graph_objects as go\n#from plotly.subplots import make_subplots\n# Classifiers and other relevant libraries\nimport sklearn\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, scale\nfrom sklearn.impute import SimpleImputer #, KNNImputer\nfrom scipy.spatial.distance import cdist\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.metrics import classification_report, confusion_matrix #, plot_confusion_matrix,\nfrom imblearn.over_sampling import SMOTE, RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.utils import resample\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.metrics import f1_score, accuracy_score, plot_confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_rows\", 200, \"display.max_columns\", 50)\n#pd.set_option('display.max_colwidth', None)\nplt.style.use('bmh')\n# create contants\nRS=42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir('../input'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"signal = pd.read_csv('../input/uci-semcom/uci-secom.csv')\nprint(f'There are {signal.shape[0]} rows and {signal.shape[1]} columns\\n')\ndisplay(signal.head())\ndisplay(signal.tail())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the data types first\nsignal.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time stamp data in useless, so we can remove that from here\n# also Pass/Fail column can be modified slightly for better clarity\nsignal.drop('Time',1,inplace=True)\nsignal.replace({-1: 0},inplace=True)\nsignal.rename(columns={\"Pass/Fail\": \"Fail\",},inplace=True)\n# Thus, Fail ==0, means product failed, else passed\nsignal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=signal.isna().sum()*100/signal.shape[0]\nfig = px.line(x=df.index, y=df,title=\"Percentage of missing values in all the features (data: signal)\")\nfig.update_xaxes(title_text= 'Features')\nfig.update_yaxes(title_text= 'Percentage of Missing values',range=[0,100])\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FLAG 1:** There are features with large number of missing values (upto 91%), which needs to be handled","metadata":{}},{"cell_type":"code","source":"df=signal.isna().sum()*100/signal.shape[0]\ndf = df[df>5].sort_values(ascending=False)\nfig = px.bar(x=df.index, \n             y = df, \n             title='Percentage of missing values per feature (with >5% NaNs), data=\"signal\"',\n             text = round(df,1))\nfig.update_xaxes(title_text='Features with more than 5% missing value (sorted)',type='category')\nfig.update_yaxes(title_text='Percentage of missing values')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remark:** There is big jump after 17.4% to 45.6%. Generally features with more than 35% missing data, do nto offer much value in prediction","metadata":{}},{"cell_type":"code","source":"df=(signal == 0).sum()*100/signal.shape[0]\nfig = px.line(x=df.index, y=df,title=\"Percentage of zeros in all the features (data: signal)\")\nfig.update_xaxes(title_text= 'Features')\nfig.update_yaxes(title_text= 'Percentage of zeros',range=[0,100])\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FLAG 2:** Large number of zeros are present. Many features have only 1 value, i.e. 0 throughout","metadata":{}},{"cell_type":"code","source":"df = pd.cut(signal.var().round(2),[-0.1,0,0.1,0.2,1,10,50,100,500,1000,float('inf')]).value_counts().sort_index()\ndf.index = df.index.map(str)\n\nfig = px.bar(x=df.index, y=df,title=\"variance (rounded off to 2 decimal places) vs number of features (data: signal)\", text = df)\nfig.update_xaxes(title='variance intervals')\nfig.update_yaxes(title='Number of features')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FLAG 3:** More than 250 features have extremely low variance (<0.1), thus having minimal contribution in the output","metadata":{}},{"cell_type":"markdown","source":"## 1.2 Data Modification: 2: drop features with high missing values and low variance","metadata":{}},{"cell_type":"code","source":"# Collect features with missing values more than 30%\ndf = signal.isna().sum()*100/signal.shape[0]\nmissing_features = df[df>30].index.tolist()\n\n# Collect features with variance less than or equal to 0.1\ndf = signal.drop('Fail',1).var().round(2)\nlow_var_features = df[df<=0.1].index.tolist()\n\n# combine the list and remove them frm the main dataset\nsignal2 = signal.drop(np.unique(low_var_features + missing_features).tolist(),1)\nprint(f'There are {signal2.shape[0]} rows and {signal2.shape[1]} columns\\n')\nprint(f'Features left: {round(signal2.shape[1]*100/signal.shape[1],2)}%\\n')\nsignal2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = signal2.drop('Fail',1)\nvif = pd.Series(np.linalg.inv(df.corr().values).diagonal(),index=df.columns,\n          name='VIF').abs().sort_values(ascending=False).round(2)\ndf = pd.cut(vif.round(1),[0,1,10,50,100,500,1000,float('inf')]).value_counts().sort_index()\ndf.index = df.index.map(str)\n\nfig = px.bar(x=df.index, y=df,title=\"vif (absolute, rounded off to 1 decimal place) vs Number of features (data: signal2)\", text = df)\nfig.update_xaxes(title='vif intervals')\nfig.update_yaxes(title='Number of features')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FLAG 4:** There are several highly multicollinear (high vif value) features. Generally vif>10 is considered as high. Let's remove these features as well","metadata":{}},{"cell_type":"code","source":"# Objective: To keep removing the highest vif feature one-by-one, until the highest vif is less than the limit passed\ndef capture_vif(df,limit):\n    high_vif = []\n    while 1:\n        temp_vif = pd.Series(np.linalg.inv(df.corr().values).diagonal(),index=df.columns,\n          name='VIF').abs().sort_values(ascending=False).round(2)\n        maxi = temp_vif.max()\n        if maxi>limit:\n            high_vif = temp_vif[temp_vif == maxi].index.tolist()[0]\n            df = df.drop(high_vif,1)\n        else:\n            return df\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Data Modification: 3: drop features with high multicollinearity","metadata":{}},{"cell_type":"code","source":"# Let's remove features with vif>10\nsignal3 = capture_vif(signal2,10)\nprint(f'There are {signal3.shape[0]} rows and {signal3.shape[1]} columns\\n')\nprint(f'Overall Features left: {round(signal3.shape[1]*100/signal.shape[1],2)}%\\n')\nsignal3.head(7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=((signal3 == 0).sum() + signal3.isna().sum())*100/signal3.shape[0]\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df.index, y=df,mode='lines'))#,name='markers'\nfig.layout = dict(title = 'Percentage of zeros + NA in all the features (data: signal3)',\n              xaxis= dict(title= 'Features'),\n                  yaxis= dict(title= 'Percentage of zeros + NA',range=[0,100]))\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = signal3.drop('Fail',1).nunique()\nDrop = df[df<=20]\nDrop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These two are the same features, which have high zeros, as shown in the previous plotly graph","metadata":{}},{"cell_type":"code","source":"x = Drop.index[0]\nprint('Pie plot (value_count) for feature: '+x)\nvc = signal3[x].value_counts().reset_index()\nfig = go.Figure(data=[go.Pie(labels=vc['index'], values=vc[x])])\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = Drop.index[1]\nprint('Pie plot (value_count) plot for feature: '+x)\nvc = signal3[x].value_counts().reset_index()\nfig = go.Figure(data=[go.Pie(labels=vc['index'], values=vc[x])])\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FLAG 5:** These two features offer no value in terms of predicting target column.  \n\nLet's also check if any other features is dominated by any value other than zero","metadata":{}},{"cell_type":"code","source":"df = signal3.apply(pd.value_counts).max()*100/signal3.shape[0]#.sort_values(ascending=False)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df.index, y=df,mode='lines'))#,name='markers'\nfig.layout = dict(title = 'Frequency of most frequent element (percentage) in all the features (data: after 3rd modification)',\n              xaxis= dict(title= 'Features'),\n                  yaxis= dict(title= 'frequency in percentage',range=[0,100]))\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, other than these two, no other feature is heavily dominated by a single value","metadata":{}},{"cell_type":"markdown","source":"## 1.4 Data Modification: 4: drop 2 features which are not adding any value (Flag:5)","metadata":{}},{"cell_type":"code","source":"signal4=signal3.drop(Drop.index,1)\nprint(f'There are {signal4.shape[0]} rows and {signal4.shape[1]} columns\\n')\nprint(f'Overall Features left: {round(signal4.shape[1]*100/signal.shape[1],2)}%\\n')\nsignal4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = signal4.drop('Fail',1).skew()\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df.index, y=df,mode='lines'))#,name='markers'\nfig.layout = dict(title='skewness for each feature (data:after 4th modification)',\n              xaxis= dict(title= 'features'),\n                  yaxis= dict(title= 'skewness'))\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = signal4.drop('Fail',1)\ndf = pd.cut(df.skew().round(1),[float('-inf'),-1,0,1,10,float('inf')]).value_counts().sort_index()\ndf.index = df.index.map(str)\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df.index, y=df,text = df,textposition='auto'))\nfig.layout = dict(title='skewness (rounded off to 1 decimal) vs number of features (data:after 4th modification)',\n              xaxis= dict(title= 'skewness intervals'),\n                  yaxis= dict(title= 'Number of features'))\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FLAG 6:** Generally, skewness of more than +1 or less than -1, is considered as high. In this case, skewness is extremely high, i.e. the distribution of many features are highly non-normal and are expected to have extreme outliers, which could affect the prediction accuracies of many classifiers","metadata":{}},{"cell_type":"code","source":"print('Top 5 features with highest positive skewness')\ndf = signal4.drop('Fail',1).skew().sort_values(ascending=False)\ndf[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = signal4.drop('Fail',1).skew().sort_values(ascending=False)\nx = df.index[0]\nprint('Distribution of feature with highest skewness: '+x)\nsignal4[x].value_counts().head(10)\nsignal4[x].hist(bins=100, figsize=(15,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, these features have high outliers","metadata":{}},{"cell_type":"code","source":"# return percentage of outliers for each numerical column\ndef IQR_outliers(data,limit=1.5):\n    numColumns = data.select_dtypes(include=np.number).columns.tolist(); # extract list of numeric columns\n    Q1 = data.quantile(0.25)\n    Q3 = data.quantile(0.75)\n    IQR = Q3-Q1;\n    outliers=((data[numColumns] < (Q1 - limit*IQR)) | (data[numColumns] > (Q3 + limit*IQR))).sum()*100/data.shape[0]\n    return outliers ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = signal4.drop(['Fail'],1).copy()\noutliers = IQR_outliers(df)\n\ntrace1 = go.Scatter(x=outliers.index, y=outliers,mode='lines',\n                    name='Outliers Before transformation')\ndata = [trace1]\nlayout = go.Layout(xaxis = dict(title= 'Features'),\n                   yaxis = dict(title= 'Percentage of IQR outliers'),\n                   title='Percentage of IQR outliers in all the features (data= signal4)')\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are too may IQR outliers to remove. In case of removal, there is a possibility that the nature of data might change, gievn the small size of 'Fail' data. Thus it might be better to use a different strategy.","metadata":{}},{"cell_type":"markdown","source":"Let's check their box plots as well to get a better understanding","metadata":{}},{"cell_type":"code","source":"skw = signal4.skew().sort_values(ascending=False)\nskewed_features = skw[(skw>1) | (skw<-1)].index.tolist()\ntry: skewed_features.remove('Fail')  # remove target column from the list, if it is present\nexcept: pass\n\ndf = signal4[skewed_features].copy()\ndf = df-df.mean()\ndf_melt = pd.concat([df,signal4['Fail']],1).melt(id_vars=['Fail'], value_vars=df.columns, var_name='signal_name', \n                                                 value_name='signal_value', ignore_index=False)\n\nfig = px.box(data_frame=df_melt, x='signal_value', color='Fail', animation_frame = 'signal_name',\n      title = 'Box plot of all features with skewness greater than +1 or less than -1 (data: signal4)')\nfig.update_layout(autosize=True)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, some features have extreme outliers, some have distribution closer to uniform distribution than normal distribution, some have clusters.","metadata":{}},{"cell_type":"code","source":"# Let's plot data with all centered columns\ndf = signal4.drop(['Fail'],1).copy()\ndf = df-df.mean()\nsignal4_melt = pd.melt(pd.concat([df,signal4['Fail']],1), \n                        id_vars=['Fail'], \n                        value_vars=df.columns, \n                        var_name='signal_name', \n                        value_name='signal_value', \n                        ignore_index=False)\nfig = px.line(signal4_melt,\n              x=signal4_melt.index, \n              y='signal_value', \n              color='Fail',\n              labels={'y':'signal_value'},\n              animation_frame='signal_name',\n             title='Visualisation of all the signals, with all features centered at 0 (data=signal4)')\nlimit = 2000\nfig.update_layout(yaxis_range=[-1*limit,limit])\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In these plots, we can clearly visualise the outliers and difference in values amongst signals.  \n(Use 'Autoscale', in case signal values are too small to visualise","metadata":{}},{"cell_type":"markdown","source":"Rather than dropping or manipulating outliers from the data, it might be better to use transformation (eg: quantile transformation) to increase normality in the data, and thereby reducing the number of IQR outliers and skewness without any data loss","metadata":{}},{"cell_type":"code","source":"df = signal4.drop(['Fail'],1).copy()\nquantile_transformer = QuantileTransformer(output_distribution='normal', random_state=RS)\ndf1 = pd.DataFrame(quantile_transformer.fit_transform(df),columns=df.columns)\noutliers = IQR_outliers(df)\noutliers1=IQR_outliers(df1)\n\ndf = df.skew()\ndf1 = df1.skew()\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df.index, y=df,mode='lines',name='Skewness before transformation'))\nfig.add_trace(go.Scatter(x=df1.index, y=df1,mode='lines',name='Skewness after transformation'))\nfig.layout = dict(title='skewness for each feature (data:after 4th modification)',\n              xaxis= dict(title= 'features'),yaxis= dict(title= 'skewness'))\niplot(fig)\n\nfig1 = go.Figure()\nfig1.add_trace(go.Scatter(x=outliers.index, y=outliers,mode='lines',name='Outliers before transformation'))\nfig1.add_trace(go.Scatter(x=outliers1.index, y=outliers1,mode='lines',name='Outliers after transformation'))\nfig1.layout = dict(title='Percentage of IQR outliers for each feature (data:after 4th modification)',\n              xaxis= dict(title= 'features'), yaxis= dict(title= 'percentage of IQR outliers'))\niplot(fig1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Skewness has reduced greatly (even though there are still some features with skewness less than -1) and number of features with IQR outliers has also reduced greatly after the transformation. Thus, the overall impact of outliers on classifier accuracy will also reduce and without manipulating or removing outliers","metadata":{}},{"cell_type":"markdown","source":"## 1.5 Data Manipulation: 5: imputation (with 0) on main data","metadata":{}},{"cell_type":"code","source":"# Here, imputation is done with replacing NaN with zeros, since missing data can be considered as zero output from the machine.\n# Other than this, KNNImputation can also be used, which can give good results\nsignal5 = signal4.replace(np.NaN, 0)\nsignal_X = signal5.drop('Fail',1)\nY = signal['Fail']\n\nprint('Actions performed: \\n1. Imputation on main data (signal)\\n2. X(signal_X) and Y(target) separated)')\nprint(f'signal dataframe: {signal5.shape[0]} rows and {signal5.shape[1]} columns\\n')\nprint(f'signal_X dataframe {signal_X.shape[0]} rows and {signal_X.shape[1]} columns\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(Y.value_counts().reset_index(), values='Fail', names='index',title='Pie plot for target column')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Thus, the target column is highly imbalanced.  \nTherefore, it might be better to use 'f1_score' as metric and imblearn and class_balance methods for classification","metadata":{}},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"def display_sbs(*args):\n# Objective: To display dataframes side by side, for clearer and concise presentation\n# Application: Simply pass two dataframes as arguments. * Works only for dataframes\n    from IPython.display import display_html\n    html_str=''\n    for df in args:\n        html_str+=df.to_html()\n    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find number of features required to capture a given variance (defualt: 95)\ndef find_pca(data,var=95, verbosity=0):\n    var/=100\n    for i in range(1,data.shape[1]+1):\n        pca = PCA(n_components=i, random_state=RS, whiten=True)\n        pca_data = pca.fit_transform(data)\n        #print(pca.explained_variance_ratio_)\n        if np.cumsum(pca.explained_variance_ratio_)[-1] >=var:\n            if verbosity == 1:\n                evr = np.cumsum(pca.explained_variance_ratio_)\n                #print(\"Overall variances captured: \",evr)\n                #print('variances: ', pca.explained_variance_ratio_)\n                fig = px.area(\n                                x=range(1, evr.shape[0] + 1),\n                                y=evr,\n                                labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}\n                            )\n                fig.show()\n            else:\n                print(\"Overall variances captured: \",np.cumsum(pca.explained_variance_ratio_)[-1])\n            break\n    return i, pca","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To save scores of different models in a proper format\ncv_scores=pd.DataFrame(index=['mean','std'])\nscores = pd.DataFrame(index=['train','test','CV'])\ndef save_scores(name,cv,test,train):\n    global cv_scores\n    global scores\n    cv_scores.loc['mean',name] = cv[0]\n    cv_scores.loc['std',name] = cv[1]\n    scores.loc['train',name] = train\n    scores.loc['test',name] = test\n    scores.loc['CV',name] = cv[0]\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find number of features required for capturing 95% variance\np95, _= find_pca(scale(signal_X),verbosity=1)\nprint('Features required: ',p95, '\\ni.e. Percentage of features: ',round(p95*100/signal_X.shape[1],2),'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find number of features required for capturing 99% variance\np99, _= find_pca(scale(signal_X),99,verbosity=1)\nprint('Features required: ',p99, '\\ni.e. Percentage of features: ',round(p99*100/signal_X.shape[1],2),'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i.e. we are able to capture 95% of the variance with 72.5% (103) features  \nand 99% of the variance with 88%(125) features","metadata":{}},{"cell_type":"code","source":"# train-test split\nX_train, X_test, y_train, y_test = train_test_split(signal_X, Y, test_size=0.25, stratify=Y, random_state=RS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Pca = PCA(n_components=103, random_state=RS, whiten=True) # to capture most important features with 95% variance\nSmot = SMOTE(random_state=RS) # to handle imbalanced classes\nTrans = QuantileTransformer(output_distribution='normal', random_state=RS) # Transformation to reduce outliers\nMinMax = MinMaxScaler() # Scaling for pca or classifier\nScaler = RobustScaler() # Scaling for pca or classifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Objective: To show the standard scores required and also save them in a dataframe\ndef give_scores(name,model,X_train, X_test, y_train, y_test):\n    cvs = cross_val_score(model,pd.concat([X_train,X_test]).sort_index(),\n                          pd.concat([y_train,y_test]).sort_index(),scoring='f1',cv=5)\n    cvs = cross_val_score(model,X_train,y_train,scoring='f1',cv=5)\n    print('CV score: ', cvs.mean().round(4))\n    print('\\nTrain Accuracy scores: ',round(accuracy_score(y_train, model.predict(X_train)),4))\n    print('\\nTest Accuracy scores: ',round(accuracy_score(y_test, model.predict(X_test)),4))\n    print('\\nClassification reports of train and test set, respectively '+name)\n    train_report = pd.DataFrame(classification_report(y_train, model.predict(X_train),output_dict=True)).T.round(3)\n    test_report = pd.DataFrame(classification_report(y_test, model.predict(X_test),output_dict=True)).T.round(3)\n    display_sbs(train_report,test_report)\n    \n    plot_confusion_matrix(model, X_test, y_test,cmap=plt.cm.Blues)\n                                 #display_labels=class_names,\n                                 \n    \n    save_scores(name,\n                [cvs.mean().round(4), cvs.std().round(4)],\n                test_report.loc['1','f1-score'],\n               train_report.loc['1','f1-score'])\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 1.1. SVM Classifier With PCA\nsvc = SVC(C = 40,gamma = 0.0001, kernel='rbf',random_state=RS)\nSVM_pipe1 = Pipeline([('trans',Trans),('scaler',Scaler),('pca',Pca),('smt', Smot), ('svc', svc)])\nSVM_pipe1.fit(X_train,y_train)\n\ngive_scores('svc-pca',SVM_pipe1,X_train, X_test, y_train, y_test) # show the scores and save them for plotting","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 1.2. SVM Classifier Without PCA\nsvc = SVC(C = 40,gamma = 0.0061, kernel='rbf',random_state=RS)\nSVM_pipe2 = Pipeline([('trans',Trans),('minmax',MinMax),('smt', Smot), ('svc', svc)])\nSVM_pipe2.fit(X_train,y_train)\n\ngive_scores('svc',SVM_pipe2,X_train, X_test, y_train, y_test) # show the scores and save them for plotting","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n##### 2.1. xgboost Classifier With PCA\nxgb_model = XGBClassifier(min_child_weight=2, max_depth=10,learning_rate=0.03, gamma=3,\n                    early_stopping_rounds=20, eval_metric = 'auc', verbosity = 0, random_state=RS,nthreads=-1)\n##### since xgboost is robust to outliers, transformation is not required\nxgb_pipe = Pipeline([('scaler',Scaler),('pca',Pca),('smt', Smot),('xgb', xgb_model)])\nxgb_pipe.fit(X_train,y_train)\n\ngive_scores('xgb-pca',xgb_pipe,X_train, X_test, y_train, y_test) # show the scores and save them for plotting","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n##### 2.2. xgboost Classifier Without pca\nxgb = XGBClassifier(min_child_weight=2, max_depth=6,learning_rate=0.05, gamma=15,\n                    early_stopping_rounds=20, eval_metric = 'auc', verbosity = 0, random_state=RS,nthreads=-1)\nxgb_pipe2 = Pipeline([('smt', Smot),('xgb', xgb)])\nxgb_pipe2.fit(X_train,y_train)\n\ngive_scores('xgb',xgb_pipe2,X_train, X_test, y_train, y_test) # show the scores and save them for plotting","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 3.1 Logistic regression with pca\n# with class_weight=balanced, smote doesn't have much impact, thus removed\nLR_cv = LogisticRegressionCV( scoring = 'f1', random_state=RS, class_weight='balanced',\n                              verbose=0, n_jobs=-1, max_iter=10000)\nLR_model1 = Pipeline([('trans',Trans),('scaler',Scaler),('pca',Pca),('LR', LR_cv)])\nLR_model1.fit(X_train,y_train)\n\ngive_scores('LR-pca',LR_model1,X_train, X_test, y_train, y_test) # show the scores and save them for plotting","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 3.2 Logistic regression without pca and scaling\nLR_cv = LogisticRegressionCV( scoring = 'f1', random_state=RS, class_weight='balanced',\n                              verbose=0, n_jobs=-1, max_iter=10000)\nLR_model2 = Pipeline([('trans',Trans),('LR', LR_cv)])\nLR_model2.fit(X_train,y_train)\n\ngive_scores('LR',LR_model2,X_train, X_test, y_train, y_test) # show the scores and save them for plotting","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Overall performace  \n1. **Best f1 score (test, Fail=1):** xgb without pca: 0.34\n1. **Best cv score:** Logistic regression without PCA: 0.2021\n1. **Best precision (test set, Fail=1)**: xb with pca:  0.385\n1. **Best Recall (test set, Fail=1)**: Logistic regression with pca;  0.692","metadata":{}},{"cell_type":"code","source":"# Objective: To plot the scores from different models saved in the 'scores' dataframe\ndef plot_scores(df=None):\n    global scores\n    if df==None: df = scores\n    fig, ax = plt.subplots(figsize=(10,15))\n    colors = ['orange','green', 'blue', 'red', 'yellow']\n    rectangles=[]\n    N =len(df.columns)\n    ind = np.arange(N)\n    xlabels = df.columns\n    width = 0.2       # the width of the bars\n    ax.set_yticks(ind + width)\n    ax.set_yticklabels(xlabels,fontsize=10)\n    ax.set_ylabel(\"Models\", fontsize=12)\n    ax.set_xlabel(\"scores\", fontsize=12)\n    ax.set_title('scores with different Models')\n    def labelvalues(rects):\n        for rect in rects:\n            height = rect.get_width()*100\n            ax.text(height/100, rect.get_y() + rect.get_height()/2., '{0:1.2f}'.format(height),va='center', ha='left')\n    for i in range(df.shape[0]):\n        rectangles.append(ax.barh(ind+width*i, df.iloc[i,:], width, color=colors[i]))\n        labelvalues(rectangles[i])\n    rect_leg = [item[0] for item in rectangles]\n    rect_leg.reverse()\n    scor = df.index.tolist()\n    scor.reverse()\n    ax.legend((rect_leg),(scor),bbox_to_anchor=(1.13, 1.01))\n    plt.show()\n    \n    global cv_scores\n    fig = go.Figure(data=go.Scatter(\n        x=cv_scores.columns.tolist(),y=cv_scores.loc['mean'],\n        error_y=dict(type='data', array=cv_scores.loc['std'], visible=True)))\n    fig.update_layout(title='CV scores with stadard deviation for different models',\n                      yaxis_zeroline=False, xaxis_zeroline=False)\n    fig.show()\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_scores()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, other than xgb-pca, all other algorithms have almost similar mean cv score.","metadata":{}},{"cell_type":"markdown","source":"## END","metadata":{}}]}