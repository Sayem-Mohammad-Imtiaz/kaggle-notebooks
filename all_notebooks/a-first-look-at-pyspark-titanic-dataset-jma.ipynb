{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport random\nimport os\n\nfrom pyspark.sql import SparkSession \nfrom pyspark.ml  import Pipeline     \nfrom pyspark.sql import SQLContext  \nfrom pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import QuantileDiscretizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly we create sparkSession (like a container)\nspark = SparkSession.builder.appName('Play with pyspark ML on titatic_dataset').getOrCreate()\n# After creating spark, we use spark.read.csv to read dataset, like pandas.read_csv\ndf = spark.read.csv('../input/titanic-machine-learning-from-disaster/train.csv',header = 'True',inferSchema='True')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.limit(3).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.printSchema()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pandas_df = df.toPandas()\n\nplt.figure(figsize=(10,5))\nplt.title('Age distribution among all Pasengers')\nsns.distplot(pandas_df['Age']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql.functions import isnan, when, count, col\ndf.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Because Cabin column has a lot missing value ( > 50%) so we can remove it\ndf = df.drop(\"Cabin\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))\ndf.limit(3).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are some misspelled Initials like Mlle or Mme that stand for Miss. we will replace them with Miss and same thing for other values.\ndf = df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n                        ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])\n\n# Checking the average age by Initials\ndf.groupby('Initial').avg('Age').collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are some misspelled Initials like Mlle or Mme that stand for Miss. we will replace them with Miss and same thing for other values.\ndf = df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n                        ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])\n\n# Checking the average age by Initials\ndf.groupby('Initial').avg('Age').collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Embarked columns has two missing values, let check it\ndf.groupBy(\"Embarked\").count().show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we can see, Majority Passengers boarded from \"S\". We can assign missing value with \"S\"\ndf = df.na.fill({\"Embarked\" : 'S'})\n# Check again the missing value status\ndf.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.withColumn(\"Family_Size\",col('SibSp')+col('Parch')) # Create new column: Family_size\ndf = df.withColumn('Alone',lit(0))  # Create new column: Alone and assign 0 default value to Alone column\ndf = df.withColumn(\"Alone\",when(df[\"Family_Size\"] == 0, 1).otherwise(df[\"Alone\"]))\n\n# converting Sex, Embarked & Initial columns from string to number using StringIndexer\nindexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\npipeline = Pipeline(stages=indexers)\ndf = pipeline.fit(df).transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.limit(3).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we drop columns that not needed for modelling\ndf = df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\")\n\n# Before modelling in Pyspark, we need to put all features to Vector using Pyspark VectorAssembler\nfeature = VectorAssembler(inputCols = df.columns[1:],outputCol=\"features\")\nfeature_vector= feature.transform(df)\nfeature_vector.limit(3).toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for data split in pyspark, we can use df.randomSplit()\n(train_df, test_df) = feature_vector.randomSplit([0.8, 0.2],seed = 11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.printSchema()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}