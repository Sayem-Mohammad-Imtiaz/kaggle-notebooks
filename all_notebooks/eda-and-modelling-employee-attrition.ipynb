{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA and Modeling Employee Attrition"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# make sure we have the latest seaborb package\n!pip install seaborn --upgrade","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# should be version 11\nimport seaborn as sns\nsns.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/employee-attrition/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the dtype and unique values for each column of the data frame\nfor feat in df.columns:\n    print(feat)\n    print(df[feat].dtype)\n    print(df[feat].unique())\n    print('#'*30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conlusion\n- `EmployeeCount`, `Over18`, `StandardHours` only one value -> drop\n- `EmployeeNumber` no predictive value -> drop"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['EmployeeCount', 'Over18', 'EmployeeNumber', 'StandardHours'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_ratio = ['Age', 'DailyRate', 'DistanceFromHome', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n              'PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', 'YearsInCurrentRole',\n              'YearsSinceLastPromotion', 'YearsWithCurrManager']\nlist_binary = ['Gender', 'OverTime']\nlist_cat = ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus']\nlist_ord = ['Education', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'PerformanceRating',\n            'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list_ratio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a grid space \nfig, axes = plt.subplots(nrows=5, ncols=3, figsize=(18,12))\n# hspace lets us see the names of each feature\nfig.subplots_adjust(hspace=0.5)\n# gives the plot a title\nfig.suptitle('Numeric features against the target')\n# for loop to populate each subplot with a chart\nfor feat, ax in zip(list_ratio, axes.flatten()):\n    sns.histplot(data=df, x=feat, hue='Attrition', ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conlusion \n- `MonthlyIncome`, `YearsAtCompany` seems to be good indicators"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_binary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(12,4))\nfig.suptitle('Binary features against the target')\nfor feat, ax in zip(list_binary, axes.flatten()):\n    sns.countplot(data=df, x=feat, hue='Attrition', ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conlusion\n- There seems to be no big differnece between `Gender`\n- Employees how do `OverTime` are more likely to leave"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 2, figsize=(14, 10))\nfig.subplots_adjust(hspace=0.8)\nfig.suptitle('categorical varibles against the target')\nfor feat, ax in zip(list_cat, axes.flatten()):\n    sns.countplot(data=df, x=feat, hue='Attrition', ax=ax)\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=20, horizontalalignment='right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n- Different job roles seem to affect employee attrition "},{"metadata":{},"cell_type":"markdown","source":"## Modeling\n- creat dummy varibales for the categorical variables\n- split data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creat dummy varibales\nlist_dummy = list(df.select_dtypes('object'))\ndf = pd.get_dummies(df, columns=list_dummy, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(columns='Attrition_Yes').values\ny = df['Attrition_Yes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale data\nscaler = StandardScaler()\nX_train_sc = scaler.fit_transform(X_train)\nX_test_sc = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train_sc, y_train)\nlogreg_pred = logreg.predict(X_test_sc)\n\nprint('accuracy: ', accuracy_score(y_test, logreg_pred))\nprint(confusion_matrix(y_test, logreg_pred))\nprint(classification_report(y_test, logreg_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature importance\nimportance = logreg.coef_\nfor i, v in enumerate(importance.flatten()):\n    print('Feature', i, ':', v)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"positive scores indicate that a feature predicts class 1, whereas negative scores indicate a feature that predicts class 0"},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train_sc, y_train)\nrf_pred = rf.predict(X_test_sc)\n\nprint('accuracy: ', accuracy_score(y_test, rf_pred))\nprint(confusion_matrix(y_test, rf_pred))\nprint(classification_report(y_test, rf_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resources\n- https://www.drawingfromdata.com/how-to-rotate-axis-labels-in-seaborn-and-matplotlib\n- https://medium.com/@rayheberer/generating-matplotlib-subplots-programmatically-cc234629b648\n- https://machinelearningmastery.com/calculate-feature-importance-with-python/\n- https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}