{"cells":[{"metadata":{"id":"7vANtJs1n92G"},"cell_type":"markdown","source":"# EMG Signal for gesture recognition"},{"metadata":{"id":"LhFOScPZS5iR","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nInput_path = '/kaggle/input/emg-signal-for-gesture-recognition/EMG-data.csv'\ndf = pd.read_csv(Input_path)\nprint(df.head())\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"0EKLGPduSQ7F","outputId":"04586f56-c508-4d5d-88d9-ab88b8b2b6c0","trusted":true},"cell_type":"code","source":"print(\"class :\", df[\"class\"].unique())\nprint()\n#print(\"Labels :\",df[\"label\"].unique()) # 36 people hand gesture data\n#print()\nprint(\"Value Count :\\n\",df[\"class\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"2n0TlXtqSa2l","outputId":"a412562a-5a6e-4aac-b658-c7ff245ad87a","trusted":true},"cell_type":"code","source":"features = df.drop(columns=[\"label\",\"class\",\"time\"])\ndisplay(features.head())\n#print(features.shape())","execution_count":null,"outputs":[]},{"metadata":{"id":"tLWCMkXASd_K","outputId":"99bdadff-2551-43f4-fe93-5a6d2ee30dbb","trusted":true},"cell_type":"code","source":"Class = df[\"class\"]\nprint(Class.unique())\n#print(Class.shape())","execution_count":null,"outputs":[]},{"metadata":{"id":"nZM3B29xSl8s","outputId":"62a2f6ac-0a6a-4d29-9da4-ee9aa24cd6d9","trusted":true},"cell_type":"code","source":"print(type(Class))\nprint(type(features))\n\nClass = Class.values\nfeatures = features.values\n\nprint(type(Class))\nprint(type(features))","execution_count":null,"outputs":[]},{"metadata":{"id":"MNT9FvwxSoGq","trusted":true},"cell_type":"code","source":"# split in training 70%, validation 10 %,  test 20% test \nfrom sklearn.model_selection import train_test_split\n# 80 and 20\nx_train, x_test, y_train, y_test = train_test_split(features, Class, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"kMAmEaHPSrSR","trusted":true},"cell_type":"code","source":"# Normalizing data\nmean = x_train.mean(axis=0)\nstd = x_train.std(axis=0)\n\nx_train -= mean\nx_train /= std\n\nx_test -= mean\nx_test /= std","execution_count":null,"outputs":[]},{"metadata":{"id":"3WpOpN9CSwc6","trusted":true},"cell_type":"code","source":"# one hot encoding Labels\ny_train = tf.keras.utils.to_categorical(y_train)\ny_test = tf.keras.utils.to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"YqNtIiv0SxvD","trusted":true},"cell_type":"code","source":"# creating a function for plotting\n\ndef plot(loss,val_loss,acc,val_acc):\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(loss) + 1)\n\n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    epochs = range(1, len(acc) + 1)\n\n    plt.plot(epochs, acc, 'bo', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation acc')\n    plt.xlabel('Epochs')\n    plt.ylabel('acc')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"TtML1XBxjwHM","trusted":true},"cell_type":"code","source":"#################################","execution_count":null,"outputs":[]},{"metadata":{"id":"whhF7VhOkUjV","trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers, Sequential, optimizers, Input, Model\n\ninput_tensor = Input(shape=(8,))\nx = layers.Dense(1024, activation='relu')(input_tensor)\ny = layers.Dense(512, activation='relu')(x)\nz = layers.Dense(256, activation='relu')(y)\nz = layers.Dense(128, activation='relu')(z)\nz = layers.Dense(64, activation='relu')(z)\nz = layers.Dense(32, activation='relu')(z)\nz = layers.Dense(128, activation='relu')(y) # acyclic graghs of layers\nz = layers.Dense(64, activation='relu')(z)\nz = layers.Dense(32, activation='relu')(z)\noutput_tensor = layers.Dense(8, activation='softmax')(z)\n\nmodel = Model(input_tensor, output_tensor)\n\n#SGD #RMSprop #Adam #Adadelta #Adagrad ##Adamax ###Nadam #Ftrl\nopt = optimizers.Nadam(lr=1e-3)\nmodel.compile(optimizer = opt, \n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])\n\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"UYxxVAP3k-Tz","trusted":true},"cell_type":"code","source":"# saving model, creating log for tensorboaed and applying few callbacks\n\ndef callbacks(Log,Dir):\n  import tensorflow as tf\n  import os\n\n  Filepath = Path\n  logdir = os.path.join(Filepath, Dir)\n  \n  callbacks_list = [tf.keras.callbacks.TensorBoard(\n                    log_dir=logdir,                 #  tensorboard log path      \n                    histogram_freq=1,),\n                    tf.keras.callbacks.EarlyStopping(   # stop if not improving\n                    monitor='val_accuracy',patience=2,),           # monitor validation accuracy\n                    #tf.keras.callbacks.ReduceLROnPlateau(\n                    #monitor='val_loss',factor=0.1,         # lr ko .1 se multiply kerdo (kam kerdo)\n                    #patience=10,),                # reduce the lrate if val loss stop improving\n                    tf.keras.callbacks.ModelCheckpoint(\n                    filepath= Filepath,             # save model path\n                    monitor='val_loss',             # only save best weights\n                    save_best_only=True,)]\n  return callbacks_list","execution_count":null,"outputs":[]},{"metadata":{"id":"D_bOgY4VjwPM","outputId":"d336489d-3862-47ae-857f-fe39d0454669","trusted":true},"cell_type":"code","source":"Path = \"model1\"\nDir = \"my_log_dir\"   \nCall_B_Fun = callbacks(Path,Dir)\n\nbatch_size = 512            \nepochs = 200                \n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size, epochs = epochs,\n                    validation_split = 0.2, callbacks=Call_B_Fun)\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplot(loss,val_loss,acc,val_acc)","execution_count":null,"outputs":[]},{"metadata":{"id":"R6uaEyPFjwSg","trusted":true},"cell_type":"code","source":"# saving our model\nmodel.save('model1/emg_1.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"CDCBgOIjs8_m","trusted":true},"cell_type":"code","source":"#################","execution_count":null,"outputs":[]},{"metadata":{"id":"IQSvDxmljwYb","outputId":"38c295d5-5355-4380-871e-48f1a4c3142d","trusted":true},"cell_type":"code","source":"# loading saved model\nfrom tensorflow.keras.models import load_model\nemg = 'model1/emg_1.h5'\nemg_model = load_model(emg)\n#emg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"Oya7H1NvvYjH","outputId":"cbb86a39-0c93-4acc-eeb8-6a1f1af1a477","trusted":true},"cell_type":"code","source":"# Removing layers\n\nnew_model = Model(emg_model.inputs, emg_model.layers[-2].output) # removing layers\nnew_model.summary()\n# removed all layers except conv","execution_count":null,"outputs":[]},{"metadata":{"id":"6tprWYHNr7nQ","outputId":"84c11a25-be80-4a89-aa2b-a8238342c60a","trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers, optimizers, Input, Model\n\ninput_tensor = Input(shape=(8,))\nx = new_model(input_tensor)       # this is our old model\n#z = layers.Dense(256, activation='relu')(x)\noutput_tensor = layers.Dense(8, activation='softmax')(x)\n\nmodel = Model(input_tensor, output_tensor)\n\n#SGD #RMSprop #Adam #Adadelta #Adagrad ##Adamax ###Nadam #Ftrl\nopt = optimizers.Nadam(lr=1e-3)\nmodel.compile(optimizer = opt, \n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"MilDJe_1vJ8p","trusted":true},"cell_type":"code","source":"def callbacks(Log,Dir):\n  import tensorflow as tf\n  import os\n\n  Filepath = Path\n  logdir = os.path.join(Filepath, Dir)\n  \n  callbacks_list = [tf.keras.callbacks.TensorBoard(\n                    log_dir=logdir,                 #  tensorboard log path      \n                    histogram_freq=1,),\n                    tf.keras.callbacks.EarlyStopping(   # stop if not improving\n                    monitor='val_loss',patience=2,),           # monitor validation loss\n                    tf.keras.callbacks.ReduceLROnPlateau(\n                    monitor='val_loss',factor=0.1,         # lr ko .1 se multiply kerdo (kam kerdo)\n                    patience=10,),                # reduce the lrate if val loss stop improving\n                    tf.keras.callbacks.ModelCheckpoint(\n                    filepath= Filepath,             # save model path\n                    monitor='val_loss',             # only save best weights\n                    save_best_only=True,)]\n  return callbacks_list","execution_count":null,"outputs":[]},{"metadata":{"id":"JqzpvSCAv46r","outputId":"9300bb8b-1532-489b-b2f5-2de62348a12e","trusted":true},"cell_type":"code","source":"Path = \"model2\"\nDir = \"my_log_dir\"   \nCall_B_Fun = callbacks(Path,Dir)\n\nbatch_size = 512            \nepochs = 200                \n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size, epochs = epochs,\n                    validation_split = 0.2, callbacks=Call_B_Fun)\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplot(loss,val_loss,acc,val_acc)","execution_count":null,"outputs":[]},{"metadata":{"id":"G-RL82Bsv5AB","trusted":true},"cell_type":"code","source":"# saving our model\nmodel.save('model2/emg_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"G-bk9G7Qv5Gz","trusted":true},"cell_type":"code","source":"###################","execution_count":null,"outputs":[]},{"metadata":{"id":"hX-JbgrQv5EW","trusted":true},"cell_type":"code","source":"# loading saved model\nfrom tensorflow.keras.models import load_model\nemg = 'model2/emg_2.h5'\nemg_model = load_model(emg)\n#emg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"9cFdvNaH0gss","trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers, Sequential, optimizers, Input, Model\n\ninput_tensor = Input(shape=(8,))\nx = layers.Dense(1024, activation='relu')(input_tensor)\ny = layers.Dense(512, activation='relu')(x)\nz = layers.Dense(256, activation='relu')(y)\nz = layers.Dense(128, activation='relu')(z)\nz = layers.Dense(64, activation='relu')(z)\nz = layers.Dense(32, activation='relu')(z)\nz = layers.Dense(128, activation='relu')(y) # acyclic graghs of layers\nz = layers.Dense(64, activation='relu')(z)\nz = layers.Dense(32, activation='relu')(z)\noutput_tensor = layers.Dense(8, activation='softmax')(z)\n\nmodel = Model(input_tensor, output_tensor)\n\nopt = optimizers.Nadam(lr=1e-3)\nmodel.compile(optimizer = opt, \n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])\n\nmodel.set_weights(emg_model.get_weights())   # using pretrained model weights\n\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"jjPuVpgsv4-L","outputId":"83047a16-c2b7-436c-a4d5-bae13b47486c","trusted":true},"cell_type":"code","source":"callbacks_list = [tf.keras.callbacks.EarlyStopping(   # stop if not improving\n                monitor='acc',patience=5,),           # monitor validation accuracy\n                tf.keras.callbacks.ModelCheckpoint(\n                filepath='my_model.h5',\n                monitor='val_loss',                   # only save best weights\n                save_best_only=True,)]                # when vall loss is improved\n\nbatch_size = 512           \nepochs = 15                \n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size, epochs = epochs,\n                    validation_split = 0.2,\n                    callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"id":"oiH8gtt_0aSS","trusted":true},"cell_type":"code","source":"model.save('emg_3.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"vszuFL6P0aP6","outputId":"947157d0-7039-4f65-f273-25bf71e520e1","trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplot(loss,val_loss,acc,val_acc)","execution_count":null,"outputs":[]},{"metadata":{"id":"Yhwxry0m6S3z","outputId":"5b61770e-9b51-4ec2-8315-40cb0b29564c","trusted":true},"cell_type":"code","source":"evaluation = model.evaluate(x_test,  y_test,batch_size=batch_size, verbose=2)\nprint()\nprint(\"Test loss :\",evaluation[0]*100,\"%\")\nprint(\"Test accuracy :\",evaluation[1]*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{"id":"awiJTiJLnbRQ"},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"id":"b0P5TPuki26a","outputId":"5bb62742-ff13-4ba4-aefb-d86a428fd1e1","trusted":true},"cell_type":"code","source":"predict = 105\na = np.argmax(model.predict(x_test)[predict])\nprint(\"Predicted Class: \",a)\nprint(\"Actual Class: \",np.argmax(y_test[predict]))","execution_count":null,"outputs":[]},{"metadata":{"id":"AgUKgBXomszP","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}