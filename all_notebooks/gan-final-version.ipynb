{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\nfrom keras.layers.merge import _Merge\n\nfrom keras.models import Model, Sequential\nfrom keras import backend as K\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ModelCheckpoint \nfrom keras.utils import plot_model\nfrom keras.initializers import RandomNormal\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_gen = ImageDataGenerator(preprocessing_function=lambda x: (x.astype('float32')) / 255)\nx_train = data_gen.flow_from_directory(\"/kaggle/input/celeba-dataset/img_align_celeba/\"\n                                        ,target_size = (256,256)\n                                        ,batch_size = 64\n                                        ,shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# no. of batches\n# image pixel values x_train[0][0] of 64 images (i.e. one batch)\n# image label values x_train[0][1] of 64 images (i.e. one batch)\nlen(x_train), len(x_train[0]), x_train[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Images were scaled from -1 to 1. This would scale them from 0-1\nplt.imshow((x_train[0][0][2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\nweight_init = RandomNormal(mean=0., stddev=0.02)\n\ndiscriminator_input = Input(shape= (256, 256, 3), name='discriminator_input')\nx = discriminator_input\n\n# First convolutional layer\nx = Conv2D(filters= 64, kernel_size= 5, strides= 2, padding= 'same', name= 'discriminator_conv_1', \n           kernel_initializer= weight_init)(x)\nx = LeakyReLU(alpha = 0.2)(x)\nx = Dropout(rate = 0.2)(x)\n\n# Second convolutional layer\nx = Conv2D(filters= 128, kernel_size= 5, strides= 2, padding= 'same', name= 'discriminator_conv_2', \n           kernel_initializer= weight_init)(x)\nx = LeakyReLU(alpha = 0.2)(x)\nx = Dropout(rate = 0.2)(x)\n\n\n# Third convolutional layer\nx = Conv2D(filters= 256, kernel_size= 5, strides= 2, padding= 'same', name= 'discriminator_conv_3', \n           kernel_initializer= weight_init)(x)\nx = LeakyReLU(alpha = 0.2)(x)\nx = Dropout(rate = 0.2)(x)\n\n\n# Fourth convolutional layer\nx = Conv2D(filters= 512, kernel_size= 5, strides= 2, padding= 'same', name= 'discriminator_conv_4', \n           kernel_initializer= weight_init)(x)\nx = LeakyReLU(alpha = 0.2)(x)\nx = Dropout(rate = 0.2)(x)\n\n\nx = Flatten()(x)\n\n# discriminator_output = Dense(1, activation= None, kernel_initializer= weight_init)(x)\ndiscriminator_output = Dense(1, activation= 'sigmoid', kernel_initializer= weight_init)(x)\ndiscriminator = Model(discriminator_input, discriminator_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_input = Input(shape=(100,), name='generator_input')\nx = generator_input\nx = Dense(np.prod(131072), kernel_initializer= weight_init)(x)\nx = BatchNormalization(momentum = 0.9)(x)\nx = LeakyReLU(alpha = 0.2)(x)\nx = Reshape((16, 16, 512))(x)\n\nx = UpSampling2D()(x)\nx = Conv2D(filters= 512, kernel_size= 5, padding= 'same', strides= 1, name = 'generator_conv_1', \n            kernel_initializer= weight_init)(x)\n# x = Conv2DTranspose(filters= 256, kernel_size= 5, padding= 'same', strides= 2, name = 'generator_conv_1', \n#                     kernel_initializer= weight_init)(x)\nx = BatchNormalization(momentum = 0.9)(x)\nx = LeakyReLU(alpha = 0.2)(x)\n\nx = UpSampling2D()(x)\nx = Conv2D(filters= 256, kernel_size= 5, padding= 'same', strides= 1, name = 'generator_conv_2', \n            kernel_initializer= weight_init)(x)\n# x = Conv2DTranspose(filters= 128, kernel_size= 5, padding= 'same', strides= 2, name = 'generator_conv_2', \n#                     kernel_initializer= weight_init)(x)\nx = BatchNormalization(momentum = 0.9)(x)\nx = LeakyReLU(alpha = 0.2)(x)\n\nx = UpSampling2D()(x)\nx = Conv2D(filters= 64, kernel_size= 5, padding= 'same', strides= 1, name = 'generator_conv_3', \n            kernel_initializer= weight_init)(x)\n# x = Conv2DTranspose(filters= 64, kernel_size= 5, padding= 'same', strides= 2, name = 'generator_conv_3',\n#                     kernel_initializer= weight_init)(x)\nx = BatchNormalization(momentum = 0.9)(x)\nx = LeakyReLU(alpha = 0.2)(x)\n\n\nx = Conv2DTranspose(filters= 3, kernel_size= 5, padding= 'same', strides= 2, name = 'generator_conv_4',\n                    kernel_initializer= weight_init)(x)\nx = Activation('sigmoid')(x)\n\ngenerator_output = x\ngenerator = Model(generator_input, generator_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\n\ndef wasserstein(y_true, y_pred):\n    return - K.mean(y_true * y_pred)\n\n# freezing weights of generator\ngenerator.trainable = False\nfor layer in generator.layers:\n    layer.trainable = False\n    \ndiscriminator.compile(optimizer= RMSprop(lr= 0.0008, decay=6e-8), \n                      loss= 'binary_crossentropy')\n\ndiscriminator.trainable = False\nfor layer in discriminator.layers:\n    layer.trainable = False\n    \ngenerator.trainable = True\nfor layer in generator.layers:\n    layer.trainable = True\n    \nmodel_input = Input(shape=(100,), name='model_input')\nmodel_output = discriminator(generator(model_input))\n\nmodel = Model(model_input, model_output)\n\nmodel.compile(optimizer= RMSprop(lr=0.0004, decay=3e-8),\n              loss= 'binary_crossentropy')\n\ndiscriminator.trainable = True\nfor layer in discriminator.layers:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_discriminator(x_train, batch_size):\n\n    valid = np.ones((batch_size,1))\n    fake = np.zeros((batch_size,1))\n\n    true_imgs = next(x_train)[0]\n    if true_imgs.shape[0] != batch_size:\n        true_imgs = next(x_train)[0]\n\n    noise = np.random.normal(0, 1, (batch_size, 100))\n    gen_imgs = generator.predict(noise)\n\n    d_loss_real = discriminator.train_on_batch(true_imgs, valid)\n    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n    d_loss = 0.5 * (d_loss_real + d_loss_fake)\n\n    return [d_loss, d_loss_real, d_loss_fake]\n\ndef train_generator(batch_size):\n    valid = np.ones((batch_size,1))\n    noise = np.random.normal(0, 1, (batch_size, 100))\n    return model.train_on_batch(noise, valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\");\n\nepoch = 0\nd_losses = []\ng_losses = []\n\nfor epoch in range(0, 3000):\n    d_loss = train_discriminator(x_train, 64)\n    g_loss = train_generator(64)\n    \n    d_losses.append(d_loss)\n    g_losses.append(g_loss)\n\n    if epoch%100 == 0:\n        print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)]  [G loss: %.3f] \" % (epoch, d_loss[0], d_loss[1], d_loss[2], g_loss))\n        \n    epoch += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n\nplt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\nplt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\nplt.plot(g_losses, color='orange', linewidth=0.25)\n\nplt.xlabel('batch', fontsize=18)\nplt.ylabel('loss', fontsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noise = np.random.normal(0, 1, (20, 100))\ngen_imgs = generator.predict(noise)\nfor i in gen_imgs:\n    plt.figure()\n    plt.imshow(i.reshape(256, 256, 3))\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\");\n\nepoch = 0\nd_losses = []\ng_losses = []\n\nfor epoch in range(0, 3000):\n    d_loss = train_discriminator(x_train, 64)\n    g_loss = train_generator(64)\n    \n    d_losses.append(d_loss)\n    g_losses.append(g_loss)\n\n    if epoch%100 == 0:\n        print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)]  [G loss: %.3f] \" % (epoch, d_loss[0], d_loss[1], d_loss[2], g_loss))\n        \n    epoch += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n\nplt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\nplt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\nplt.plot(g_losses, color='orange', linewidth=0.25)\n\nplt.xlabel('batch', fontsize=18)\nplt.ylabel('loss', fontsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noise = np.random.normal(0, 1, (20, 100))\ngen_imgs = generator.predict(noise)\nfor i in gen_imgs:\n    plt.figure()\n    plt.imshow(i.reshape(256, 256, 3))\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}