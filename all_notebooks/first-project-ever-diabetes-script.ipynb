{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read in data source\n\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\n\n#Quick check at first rows\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check out data\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Min value = 0 in most columns. No bueno."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Further Check out data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No NULL values. Wooooo!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace 0's of things that should not equal 0, so we can get a better look at the column values and their associated statistics\ndf[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.NaN)\n\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Min seems to be corrected. All other values were then fixed.  There might be a faster way to replace 0's with NULL for certain columns, just not sure off the top of my head"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(20,20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I see some outliers and a mostly right skewed distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check to see which columns have null values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first replace NaN values, used median due to the heavy skew right, mean would not be as effective of a fit\ndf['Glucose'].fillna(df['Glucose'].median(), inplace = True)\ndf['BloodPressure'].fillna(df['BloodPressure'].median(), inplace = True)\ndf['SkinThickness'].fillna(df['SkinThickness'].median(), inplace = True)\ndf['Insulin'].fillna(df['Insulin'].median(), inplace = True)\ndf['BMI'].fillna(df['BMI'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recheck to see if there are null values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check to see if there are any highly correlated inputs\nfig, ax = plt.subplots(figsize=(10,10)) \np=sns.heatmap(df.corr(), annot=True,cmap=\"BuGn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Does not seem to be any very highly correlated inputs to the outcome. Glucose has the strongest correlation to the outcome, but it still not very high."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create X and Y datasets\nx = df.drop(['Outcome'], axis=1)\ny = df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import modules\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier as KNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform data\nssc = StandardScaler()\n\nx_scaled = ssc.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data\nx_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size = .3, random_state= 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting Model and Transforming data\n\n# Instantiate lr\nlr = LogisticRegression(random_state=42)\n\n# Instantiate knn\nknn = KNN(n_neighbors=10)\n\n# Instantiate dt\ndt = DecisionTreeClassifier(min_samples_leaf=.10, random_state=42)\n\n\nclassifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate Each Model\nfor clf_name, clf in classifiers:    \n \n    # Fit clf to the training set\n    clf.fit(x_train, y_train)    \n   \n    # Predict y_pred\n    y_pred = clf.predict(x_test)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred) \n   \n    # Evaluate clf's accuracy\n    print('{:s} : {:.3f}'.format(clf_name, accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Classification Tree has highest accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ensemble Model\nvc = VotingClassifier(estimators=classifiers)     \n\n#Fit vc to x_train\nvc.fit(x_train, y_train)   \n\n#Evaluate the test set predictions\ny_pred = vc.predict(x_test)\n\n#Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint('Voting Classifier: {:.3f}'.format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensemble method has second highest accuracy, however Classification Tree is still highest\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}