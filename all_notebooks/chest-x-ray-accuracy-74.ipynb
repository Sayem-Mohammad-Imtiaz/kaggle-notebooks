{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nsns.set()\nimport PIL.Image\nimport matplotlib.pyplot as mpimg\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  *\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n#tf.keras.preprocessing.image.load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array,load_img\nfrom tensorflow.keras.preprocessing import image\nfrom keras.preprocessing.image import load_img\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:02.69428Z","iopub.execute_input":"2021-07-16T09:58:02.694768Z","iopub.status.idle":"2021-07-16T09:58:08.547283Z","shell.execute_reply.started":"2021-07-16T09:58:02.694691Z","shell.execute_reply":"2021-07-16T09:58:08.546346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:28.010206Z","iopub.execute_input":"2021-07-16T09:58:28.010712Z","iopub.status.idle":"2021-07-16T09:58:28.047679Z","shell.execute_reply.started":"2021-07-16T09:58:28.010681Z","shell.execute_reply":"2021-07-16T09:58:28.046772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:31.805537Z","iopub.execute_input":"2021-07-16T09:58:31.806208Z","iopub.status.idle":"2021-07-16T09:58:31.831071Z","shell.execute_reply.started":"2021-07-16T09:58:31.806167Z","shell.execute_reply":"2021-07-16T09:58:31.830076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_vals = train_df.isnull().sum()\nmissing_vals.plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:34.969886Z","iopub.execute_input":"2021-07-16T09:58:34.970221Z","iopub.status.idle":"2021-07-16T09:58:35.225634Z","shell.execute_reply.started":"2021-07-16T09:58:34.970193Z","shell.execute_reply":"2021-07-16T09:58:35.224585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dropna(how = 'all')\ntrain_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:38.470544Z","iopub.execute_input":"2021-07-16T09:58:38.470905Z","iopub.status.idle":"2021-07-16T09:58:38.499142Z","shell.execute_reply.started":"2021-07-16T09:58:38.470876Z","shell.execute_reply":"2021-07-16T09:58:38.498522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#impute unknown to null data points, we don't wanna see those ugly null values\ntrain_df.fillna('unknown', inplace=True)\ntrain_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:42.345547Z","iopub.execute_input":"2021-07-16T09:58:42.346136Z","iopub.status.idle":"2021-07-16T09:58:42.361163Z","shell.execute_reply.started":"2021-07-16T09:58:42.346104Z","shell.execute_reply":"2021-07-16T09:58:42.360476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\ntest_data = train_df[train_df['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")\ntest_data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:50.975573Z","iopub.execute_input":"2021-07-16T09:58:50.976042Z","iopub.status.idle":"2021-07-16T09:58:50.998515Z","shell.execute_reply.started":"2021-07-16T09:58:50.976011Z","shell.execute_reply":"2021-07-16T09:58:50.997794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print((train_df['Label_1_Virus_category']).value_counts())\nprint('--------------------------')\nprint((train_df['Label_2_Virus_category']).value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:58:57.071108Z","iopub.execute_input":"2021-07-16T09:58:57.071818Z","iopub.status.idle":"2021-07-16T09:58:57.083904Z","shell.execute_reply.started":"2021-07-16T09:58:57.071754Z","shell.execute_reply":"2021-07-16T09:58:57.082891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.countplot(train_data['Label_2_Virus_category']);","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:59:01.119687Z","iopub.execute_input":"2021-07-16T09:59:01.120155Z","iopub.status.idle":"2021-07-16T09:59:01.316092Z","shell.execute_reply.started":"2021-07-16T09:59:01.120123Z","shell.execute_reply":"2021-07-16T09:59:01.315141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img_dir = '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\ntrain_img_dir = '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n\nsample_train_images = list(os.walk(train_img_dir))[0][2][:8]\nsample_train_images = list(map(lambda x: os.path.join(train_img_dir, x), sample_train_images))\n\nsample_test_images = list(os.walk(test_img_dir))[0][2][:8]\nsample_test_images = list(map(lambda x: os.path.join(test_img_dir, x), sample_test_images))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:59:06.206198Z","iopub.execute_input":"2021-07-16T09:59:06.206558Z","iopub.status.idle":"2021-07-16T09:59:13.908002Z","shell.execute_reply.started":"2021-07-16T09:59:06.20653Z","shell.execute_reply":"2021-07-16T09:59:13.907014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nfor iterator, filename in enumerate(sample_train_images):\n    image = PIL.Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image, cmap=plt.cm.bone)\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:59:16.974566Z","iopub.execute_input":"2021-07-16T09:59:16.974909Z","iopub.status.idle":"2021-07-16T09:59:20.112891Z","shell.execute_reply.started":"2021-07-16T09:59:16.974869Z","shell.execute_reply":"2021-07-16T09:59:20.112218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove Pnuemonia with unknown value\nfinal_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') &\n                               (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n# add a target and class feature\nfinal_train_data['class'] = final_train_data.Label.apply(lambda x: 'negative' if x=='Normal' else 'positive')\ntest_data['class'] = test_data.Label.apply(lambda x: 'negative' if x=='Normal' else 'positive')\n\nfinal_train_data['target'] = final_train_data.Label.apply(lambda x: 0 if x=='Normal' else 1)\ntest_data['target'] = test_data.Label.apply(lambda x: 0 if x=='Normal' else 1)\n#get the important features\nfinal_train_data = final_train_data[['X_ray_image_name', 'class', 'target', 'Label_2_Virus_category']]\nfinal_test_data = test_data[['X_ray_image_name', 'class', 'target']]\n\ntest_data['Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:59:25.244711Z","iopub.execute_input":"2021-07-16T09:59:25.245179Z","iopub.status.idle":"2021-07-16T09:59:25.268853Z","shell.execute_reply.started":"2021-07-16T09:59:25.24515Z","shell.execute_reply":"2021-07-16T09:59:25.267924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a imagegenerator for for augmentation\ndatagen =  ImageDataGenerator(\n  shear_range=0.2,\n  zoom_range=0.2,\n)\ndef read_img(filename, size, path):\n    img = load_img(os.path.join(path, filename), target_size=size)\n    #convert image to array\n    img = img_to_array(img) / 255\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:59:28.769762Z","iopub.execute_input":"2021-07-16T09:59:28.770096Z","iopub.status.idle":"2021-07-16T09:59:28.775898Z","shell.execute_reply.started":"2021-07-16T09:59:28.770069Z","shell.execute_reply":"2021-07-16T09:59:28.774824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#augment the images labeled with covid-19 to balance the data\n\ncorona_df = final_train_data[final_train_data['Label_2_Virus_category'] == 'COVID-19']\nwith_corona_augmented = []\n\n#create a function for augmentation\ndef augment(name):\n    img = read_img(name, (255,255), train_img_dir)\n    i = 0\n    for batch in tqdm(datagen.flow(tf.expand_dims(img, 0), batch_size=32)):\n        with_corona_augmented.append(tf.squeeze(batch).numpy())\n        if i == 20:\n            break\n        i =i+1\n\n#apply the function\ncorona_df['X_ray_image_name'].apply(augment)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:59:31.819754Z","iopub.execute_input":"2021-07-16T09:59:31.82011Z","iopub.status.idle":"2021-07-16T09:59:52.019443Z","shell.execute_reply.started":"2021-07-16T09:59:31.820079Z","shell.execute_reply":"2021-07-16T09:59:52.018588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract the image from traing data and test data, then convert them as array\ntrain_arrays = [] \nfinal_train_data['X_ray_image_name'].apply(lambda x: train_arrays.append(read_img(x, (255,255), train_img_dir)))\ntest_arrays = []\nfinal_test_data['X_ray_image_name'].apply(lambda x: test_arrays.append(read_img(x, (255,255), test_img_dir)))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:00:05.969355Z","iopub.execute_input":"2021-07-16T10:00:05.96971Z","iopub.status.idle":"2021-07-16T10:01:24.997462Z","shell.execute_reply.started":"2021-07-16T10:00:05.969673Z","shell.execute_reply":"2021-07-16T10:01:24.996528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concatenate the training data labels and the labels for augmented images\ny_train = np.concatenate((np.int64(final_train_data['target'].values), np.ones(len(with_corona_augmented), dtype=np.int64)))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:02:24.6456Z","iopub.execute_input":"2021-07-16T10:02:24.64593Z","iopub.status.idle":"2021-07-16T10:02:24.650756Z","shell.execute_reply.started":"2021-07-16T10:02:24.645902Z","shell.execute_reply":"2021-07-16T10:02:24.649862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting Data to tensors\ntrain_tensors = tf.convert_to_tensor(np.concatenate((np.array(train_arrays), np.array(with_corona_augmented))))\ntest_tensors  = tf.convert_to_tensor(np.array(test_arrays))\ny_train_tensor= tf.convert_to_tensor(y_train)\ny_test_tensor = tf.convert_to_tensor(final_test_data['target'].values)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_tensors, y_train_tensor))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_tensors, y_test_tensor))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:02:29.019415Z","iopub.execute_input":"2021-07-16T10:02:29.019815Z","iopub.status.idle":"2021-07-16T10:02:33.145383Z","shell.execute_reply.started":"2021-07-16T10:02:29.019772Z","shell.execute_reply":"2021-07-16T10:02:33.144637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nBUFFER = 1000\n\ntrain_batches = train_dataset.shuffle(BUFFER).batch(BATCH_SIZE)\ntest_batches = test_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:02:38.714713Z","iopub.execute_input":"2021-07-16T10:02:38.715288Z","iopub.status.idle":"2021-07-16T10:02:38.731803Z","shell.execute_reply.started":"2021-07-16T10:02:38.715255Z","shell.execute_reply":"2021-07-16T10:02:38.730889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define input shape\nINPUT_SHAPE = (255,255,3) \n\n#get the pretrained model\nbase_model = tf.keras.applications.ResNet50(input_shape= INPUT_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\n#set the trainable method of covolution layer as false\n# why set to false?? because we don't want to mess up the pretrained weights of the model!!\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:02:42.459711Z","iopub.execute_input":"2021-07-16T10:02:42.460153Z","iopub.status.idle":"2021-07-16T10:02:45.065593Z","shell.execute_reply.started":"2021-07-16T10:02:42.460124Z","shell.execute_reply":"2021-07-16T10:02:45.064618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's try to pass an image to the model to verify the output shape\nfor i,l in train_batches.take(1):\n    pass\nbase_model(i).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:02:55.590297Z","iopub.execute_input":"2021-07-16T10:02:55.590686Z","iopub.status.idle":"2021-07-16T10:02:59.92394Z","shell.execute_reply.started":"2021-07-16T10:02:55.590655Z","shell.execute_reply":"2021-07-16T10:02:59.923087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(128))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))\n#model.add(Dense(1, activation = 'relu'))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:03:02.470727Z","iopub.execute_input":"2021-07-16T10:03:02.471095Z","iopub.status.idle":"2021-07-16T10:03:02.897511Z","shell.execute_reply.started":"2021-07-16T10:03:02.471061Z","shell.execute_reply":"2021-07-16T10:03:02.89672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#add a earlystopping callback to stop the training if the model is not learning anymore\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n\n#let's just choose adam as our optimizer, we all love adam anyway.\nmodel.compile(optimizer='adam',\n              loss = 'binary_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:03:08.516363Z","iopub.execute_input":"2021-07-16T10:03:08.516713Z","iopub.status.idle":"2021-07-16T10:03:08.535838Z","shell.execute_reply.started":"2021-07-16T10:03:08.516685Z","shell.execute_reply":"2021-07-16T10:03:08.534826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_batches, epochs=50, validation_data=test_batches, callbacks=[callbacks])","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:34:22.051214Z","iopub.execute_input":"2021-07-16T10:34:22.051587Z","iopub.status.idle":"2021-07-16T11:10:09.112451Z","shell.execute_reply.started":"2021-07-16T10:34:22.051556Z","shell.execute_reply":"2021-07-16T11:10:09.111615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict_classes(np.array(test_arrays))\n#let's print a classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(test_data['target'], pred.flatten()))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T11:12:20.915006Z","iopub.execute_input":"2021-07-16T11:12:20.915375Z","iopub.status.idle":"2021-07-16T11:13:32.875927Z","shell.execute_reply.started":"2021-07-16T11:12:20.915341Z","shell.execute_reply":"2021-07-16T11:13:32.875226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(test_data['target'], pred.flatten())\nplt.figure(figsize = (7,4))\nplt.title('CONFUSION MATRIX')\nsns.heatmap(con_mat, cmap='coolwarm',\n            yticklabels=['Negative', 'Positive'],\n            xticklabels=['Negative', 'Positive'],\n            annot=True);","metadata":{"execution":{"iopub.status.busy":"2021-07-16T11:13:42.891053Z","iopub.execute_input":"2021-07-16T11:13:42.891376Z","iopub.status.idle":"2021-07-16T11:13:43.125301Z","shell.execute_reply.started":"2021-07-16T11:13:42.891348Z","shell.execute_reply":"2021-07-16T11:13:43.124203Z"},"trusted":true},"execution_count":null,"outputs":[]}]}