{"cells":[{"metadata":{"_uuid":"b0361df799744c067d2a5a2c0790ab7783f99d6a"},"cell_type":"markdown","source":"# Linear Regression on Airbnb Dataset\nThis is a dataset of AirBnb having 29 columns. Aim of this linear regression is to predict the price of room from given features."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://fortunedotcom.files.wordpress.com/2014/07/new-logos-airbnb.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47f5e9965d87550bcf95076d3b9d27237cdea452"},"cell_type":"markdown","source":"# Load Libraries"},{"metadata":{"trusted":true,"_uuid":"5b29b1330b1032f3527a2d4cdf629cf5401e977a"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels as statm\nfrom statsmodels.formula.api import ols\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom plotnine import *\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d52f7b793b2b792906bcaef6d89cd943b065543"},"cell_type":"markdown","source":"# Load File"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"filedata= pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32ac47e5f85b15f549d7fd35021dce715fde649a"},"cell_type":"markdown","source":"# Exploratory Data Analysis(EDA)"},{"metadata":{"_uuid":"4124b72a9166a862f7dc3678d23fe73e93c69ce6"},"cell_type":"markdown","source":"## File structure and content"},{"metadata":{"trusted":true,"_uuid":"d63f541c0c380b325592f750ada304bc6c38e56f"},"cell_type":"code","source":"filedata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78cc704ff35be7e3b1d67f3281831dfa0ad48425"},"cell_type":"code","source":"len(filedata.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"600f85da06b65feb90de9e67bf541410fc1ad7cd"},"cell_type":"code","source":"filedata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3a80025b54e63d421ebd24f3e0777d5e5c2b831"},"cell_type":"code","source":"filedata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cde140d4d0a50a90537959e7557255577c1335a"},"cell_type":"code","source":"#check for missing data, and output columns that have missing data\nfor col in filedata:\n    if (filedata[col].isnull().any()):\n        print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"834122407810312403eb5947408fa79de68be013"},"cell_type":"code","source":"#fills missing data with 0s\n#GO BACK TO THIS, 0 may not be best fill for all missing data\nfiledata=filedata.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c39f0da1965d34bb5591a98e24150b04b2ecefa"},"cell_type":"code","source":"#summary stats on each of the numeric columns\nfiledata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49c6a37747bdca26d230292f69026cdf724f45cd"},"cell_type":"code","source":"#check all the statistics\nfiledata.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdd29f3dcf05ee2b7609ec104f68a68ce99f5ef5"},"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64','uint8']\nnumericdataX = filedata.select_dtypes(include=numerics)\nx= numericdataX['accommodates']\nsns.distplot(x);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9c000261d3c4e273d0e7eadba2844525c9437cc"},"cell_type":"code","source":"x= numericdataX.iloc[:,1]\nsns.distplot(x);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"917183f0fb368f9a712dd0e8754149e3f92bea6f"},"cell_type":"code","source":"ggplot(filedata, aes(x='room_type')) + geom_bar(fill = \"red\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"951abc39038d35b9b25029d6da4dfe0e9c9853e5"},"cell_type":"code","source":"ggplot(filedata, aes(x='city')) + geom_bar(fill = \"green\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17c9f7e959afe07c92f5b6981b032418774dc948"},"cell_type":"code","source":"#check categorical data\nfiledata.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8caf45e047a3bf5192b6b15b391bc0f7276ccdde"},"cell_type":"code","source":"#check numeric data\nfiledata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96b912b16fd8d3c4b08f4f1b79cd26fee917808d"},"cell_type":"code","source":"filedata.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ecaa3c6f173aa200474627fe98cb02e0658696f"},"cell_type":"markdown","source":"# Linear Assumptions"},{"metadata":{"_uuid":"fb4cb2320f82562d201b69253840d271d98b0740"},"cell_type":"markdown","source":"## Assumption that data point are linearly disributed "},{"metadata":{"trusted":true,"_uuid":"c5e1589f46e927e9971f49e76a19a50792f52cd0"},"cell_type":"code","source":"regressor = linear_model.LinearRegression()\nfor i in range(1,10): \n    x= np.array(numericdataX.iloc[:,i]).reshape(-1,1)\n    y= np.array(filedata['log_price']).reshape(-1,1)\n    regressor.fit(x,y)\n    plt.figure(figsize=(8,5))\n    plt.subplot(10,1,i)\n    plt.scatter(x,y,color='blue', alpha=0.1)\n    plt.plot(x,regressor.predict(x),color=\"red\")\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74d7bd0282022b475945b8cbd3ac961fce9e49eb"},"cell_type":"markdown","source":"## Q-Q plot\n"},{"metadata":{"trusted":true,"_uuid":"7ce3ba58b98ff983f829782f501ce805786b5c85"},"cell_type":"code","source":"statm.graphics.gofplots.qqplot(numericdataX.iloc[:,6], line='r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b92b2c8b6395ab5b5df91b25ce85c32558ff3d19"},"cell_type":"code","source":"statm.graphics.gofplots.qqplot(numericdataX.iloc[:,1], line='r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d963f818f53f35c56dccebc113eddc72620710a9"},"cell_type":"code","source":"statm.graphics.gofplots.qqplot(numericdataX.iloc[:,9], line='r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b858a82e9328a6e7d58ac1457e05214084829214"},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{"_uuid":"ffc194af571ba2f9fd50225e1740b552592c99c0"},"cell_type":"markdown","source":"### Functions"},{"metadata":{"trusted":true,"_uuid":"8b974c95f36b110ce5c4328f86e4aa4071c28d8a"},"cell_type":"code","source":"def checkCorrelation(data):\n    \"\"\"\n    Plot correlation Matrix for given data\n   :param data: dataset having features\n   :return: return plot representing pearson correlation\n   \"\"\"\n    plt.figure(figsize=(20, 20))\n    sns.heatmap(data.corr(),linewidths=0.25,vmax=1.0,square=True,cmap=\"BuGn_r\", \n    linecolor='w',annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59678b9b215c199b74e8b3b1c06c7c69722a7e87"},"cell_type":"code","source":"#return Model \ndef data_model(xdata):\n    \"\"\"\n     fits linear regression model on given data\n    :param xdata: independent variable dataset\n    :return: linear regression model with fit of xdata \n   \"\"\"\n    #add constant to data\n    X = sm.add_constant(xdata)\n    targetY=filedata[['log_price']]\n    y = targetY\n\n    # Fit the linear model\n    model = linear_model.LinearRegression()\n    results = model.fit(X, y)\n    model = sm.OLS(y, X)\n    results = model.fit()\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eeb55264370b61422b3f5ba89897cbe247289602"},"cell_type":"code","source":"def data_summary(xdata):\n    \"\"\"\n    Returns chart having summary of data\n   :param xdata: independent variable dataset\n   :return: summary of data \n   \"\"\"\n    results = data_model(xdata)\n    return results.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4704d05eff95d146fe723ce9471ea101155a561"},"cell_type":"code","source":"def crossValidationError(data):\n    \"\"\"\n   Finds cross validation error of model\n   :param X: independent variable dataset\n   :return: float value returns mean squared error\n   \"\"\"\n    numericdataX=data\n    X = np.array(numericdataX.drop(['log_price'],axis=1), dtype=pd.Series)\n    Y = np.array(numericdataX['log_price'], dtype=pd.Series)\n    regr1 = linear_model.LinearRegression()\n    ms_errors= cross_val_score(regr1, X, Y, cv=5, scoring = make_scorer(mean_squared_error))\n    rms_errors = np.sqrt(ms_errors)\n    mean_rms_error = rms_errors.mean()\n    return mean_rms_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"682b477dfa8b8ef93b4a2fbca428fe9f0da0f504"},"cell_type":"code","source":"#Checking correlation in data\ncheckCorrelation(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32086f53f45fb68610c2e81189e5590eb89b4da2"},"cell_type":"code","source":"#So as per correlation matrix colums such as latitude, longitude, number_of_reviews and review_scores_rating are not making much impact on log_price\n#as valueof cirrelation is poor\n#lets drop them from our dataset\nnumericdataX=numericdataX.drop(['id','number_of_reviews',\n       'review_scores_rating','latitude',\n       'longitude' ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a639b033bf49d5a240c7064f693201a42f4f7344"},"cell_type":"code","source":"# buid model and check summary\ndata_summary(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f4e147c0fec87c3888775a8dc6f4e01436b3fa2"},"cell_type":"code","source":"# there is also correlation between bathroom and accomodates and bedroom lets only keep acomodates\nnumericdataX = numericdataX.drop(['bathrooms','bedrooms','beds'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"555ca3881708472e32c98f16a07badc364058956"},"cell_type":"code","source":"# buid model and check summary\ndata_summary(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc2aed3f24d0d0cfa39f7920570ba64d56c242c9"},"cell_type":"code","source":"crossValidationError(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc159dbea846effe97e39cf331bb2c518cfc0d45"},"cell_type":"markdown","source":"## Handling Categorical Variables"},{"metadata":{"trusted":true,"_uuid":"87deb06c2b33b322bd736959088b7afd78e9b09b"},"cell_type":"code","source":"filedata.room_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"060e357b261b51702874323232e7a790648fff82"},"cell_type":"code","source":"#creating dummy variable for column room_type\nnumericdataX=pd.concat([numericdataX,filedata['room_type']], axis=1)\nnumericdataX=pd.get_dummies(numericdataX,columns= ['room_type'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bbee294125f4ec702faede800e33c54cf7dd06a"},"cell_type":"code","source":"numericdataX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd196bd3a52cea3276c17ea6bc2af55b792beda"},"cell_type":"code","source":"filedata.bed_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c9f0ea379fea3bc25874482fd412781d21b7eea"},"cell_type":"code","source":"numericdataX=pd.concat([numericdataX,filedata['bed_type']], axis=1)\nnumericdataX=pd.get_dummies(numericdataX,columns=['bed_type'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c12b59def2f4a9b85cc10ba4824861bfcbc10276"},"cell_type":"code","source":"filedata.cancellation_policy.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d01c405b49dfcf5aa98be1d156e823424f4adce"},"cell_type":"code","source":"numericdataX=pd.concat([numericdataX,filedata['cancellation_policy']], axis=1)\nnumericdataX=pd.get_dummies(numericdataX,columns=['cancellation_policy'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"057b55ffba5c3a13661b107f3a2bc4590b029541"},"cell_type":"code","source":"filedata.city.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e43c2ea29b99d93ab1e0a735b10f4a279d5ff7d7"},"cell_type":"code","source":"numericdataX=pd.concat([numericdataX,filedata['city']], axis=1)\nnumericdataX=pd.get_dummies(numericdataX,columns=['city'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8336acf8d35db545a02ffd0ddd1948277c022f7a"},"cell_type":"code","source":"filedata.instant_bookable.value_counts()\nnumericdataX=pd.concat([numericdataX,filedata['instant_bookable']], axis=1)\nnumericdataX=pd.get_dummies(numericdataX,columns=['instant_bookable'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30a4aa455d899b35fd53cfecc5a3cd613c6dbae9"},"cell_type":"markdown","source":"# Multicolinearity"},{"metadata":{"trusted":true,"_uuid":"b3c986879da44343ba7672848d9f04b1971d5168"},"cell_type":"code","source":"checkCorrelation(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dacc6d8ccfe66cb39d74c1ee05b7b3a0855873ab"},"cell_type":"code","source":"data_summary(numericdataX.drop(['log_price'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e86e545b64823958091637b365d400cf41f9eea4"},"cell_type":"code","source":"filedata.property_type.value_counts()\nnumericdataX=pd.concat([numericdataX,filedata['property_type']], axis=1)\nnumericdataX=pd.get_dummies(numericdataX,columns=['property_type'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d281077debc98642f62d6cae918b1b8568cef8d"},"cell_type":"code","source":"data_summary(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83988e5702356f677c4587f6fdaffc45d3463644"},"cell_type":"code","source":"crossValidationError(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c1555294419b52b862972db743da657e303816c"},"cell_type":"code","source":"# P value of bed type has poor P value\nnumericdataX = numericdataX.loc[:, ~numericdataX.columns.str.startswith('bed_type_')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e34ab0fa335a2764833f3f759020802a734d1f75"},"cell_type":"code","source":"data_summary(numericdataX.drop(['log_price'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8847ebe7a8554614308f2bba8a8f1132071bcd54"},"cell_type":"code","source":"crossValidationError(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7c95ae7557c6f916664b0d67d4f50734fa20463"},"cell_type":"markdown","source":"# Interaction Term"},{"metadata":{"trusted":true,"_uuid":"d500755f1eb76bb8408c9c8d22108559acad9247"},"cell_type":"code","source":"filedata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a86452d10edc937b9bc96c1b70716176d09200c"},"cell_type":"code","source":"interactionDF= pd.DataFrame()\ninteractionDF['bedrooms']=filedata['bedrooms']\ninteractionDF['beds']=filedata['beds']\ninteractionDF['bathrooms']=filedata['bathrooms']\ninteractionDF['bed*bathroom*bedrooms']=filedata['bedrooms']*filedata['beds']*filedata['bathrooms']\ndata_summary(interactionDF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adbec378410c67e254de9875f63ea33e6016b1f0"},"cell_type":"code","source":"numericdataX= pd.concat([numericdataX,interactionDF],axis=1)\ndata_summary(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"030f64361297bd547b0d0a6bee9f4fa38b78b54a"},"cell_type":"code","source":"interactionDF1= pd.DataFrame()\ninteractionDF1['review_scores_rating']=filedata['review_scores_rating']\ninteractionDF1['number_of_reviews']=filedata['number_of_reviews']\ninteractionDF1['reiew_score*Number']=filedata['review_scores_rating']*filedata['number_of_reviews']\ndata_summary(interactionDF1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48ea761be5ac6de13f1aafe69cf66741f55e7108"},"cell_type":"code","source":"numericdataX= pd.concat([numericdataX,interactionDF1],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5498676ddf512f202a38685a69d35f323e1c633"},"cell_type":"code","source":"data_summary(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45863bac48e4f1b28f3a2b993e287b3d6bfc11e6"},"cell_type":"code","source":"crossValidationError(numericdataX)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b50660d0f1a2657b14c9d22d4085828f12d56913"},"cell_type":"markdown","source":"## As we can see above tha by adding an interaction term our cross validation error gets lower and we are getting perfect R2 ,Aic and Bic values \n## This is a model we were looking for"},{"metadata":{"_uuid":"92fbb7e2422bc7750789dc28d073d29b69b15ff6"},"cell_type":"markdown","source":"## Thanks You!!!!! "},{"metadata":{"_uuid":"b06c401feb9b759e8196fde51817d9fdc5a118a3"},"cell_type":"markdown","source":"## Lets start with H20"},{"metadata":{"trusted":true,"_uuid":"98409124bbe8337a7781446a6915c741171b12a5"},"cell_type":"code","source":"\n##import h2o\n##from h2o.automl import H2OAutoML\n##h2o.init()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64b1ec5c292c33ea63fc54d2fb94442f7999cfb1"},"cell_type":"code","source":"numericdataX","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"405a06ce339011712b514a84522189a74c2abb39"},"cell_type":"markdown","source":"## Classification with Trees"},{"metadata":{"_uuid":"2b4c3c956844b98efbe817537245756a59609ceb"},"cell_type":"markdown","source":"## A.Classification with Logistic Regression\n## B. Classification with Trees\n               1. Bagging based tree algorithm (Random Forest)\n               2. Boosting based tree algorithm (GradientBoosting)\n"},{"metadata":{"_uuid":"c78b4b78d6fa8f74f99847eae9565d6ae13a29f4"},"cell_type":"markdown","source":"## A.Classification with Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"74cd3bdd0cffc69fa2996e135f646ab0331e6d7b"},"cell_type":"code","source":"filedata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4ee9604e1fbfa85e52aab3f95b505406db8d9d0"},"cell_type":"code","source":"mean_log= np.mean(numericdataX['log_price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6b2162cd75fe133255368fc194770bef0b5dbce"},"cell_type":"code","source":"classificationData= numericdataX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e6b8d537e0e7d4c8bb2c3e00f6a47bf827c62fd"},"cell_type":"code","source":"classificationData.loc[ classificationData['log_price'] <= mean_log, 'log_price'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76c7f01b372642bdabc64e884920c6c6caa67f92"},"cell_type":"code","source":"classificationData.loc[ classificationData['log_price'] > mean_log, 'log_price'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"080461761e9e982a6408986d5d489324f0a0f314"},"cell_type":"code","source":"classificationDataY= classificationData['log_price']\nclassificationDataX=classificationData.drop(['log_price'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c7bf7fec44a92a4c7eaf995e86da6633ec69227"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3b02e9f9bbf95c9fff9e327c48317ce2649bef4"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(classificationDataX, classificationDataY, test_size = 0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17acef20f606eed57cffa88675e7a024598677c8"},"cell_type":"code","source":"classifier= LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"203f8955e69f654ebf8e9d85c858b59399be36e2"},"cell_type":"code","source":"classifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b038fbacf56e35b74f47b273554056518b3fdb6"},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a4a86628e872c2aeb762b167c29683b38902c06"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"addd56d0d7dfc9cea0208c1168c3eb5f03e0a8e8"},"cell_type":"markdown","source":"6127+ 5905 correct predictions and 1468+1323 incorrect predictions."},{"metadata":{"_uuid":"71628f211ba15dfd86fbac08713a878e14ace06f"},"cell_type":"markdown","source":"Compute precision, recall, F-measure and support"},{"metadata":{"_uuid":"39ff255043ab6a6f5522a9aa29b0d43c2280255a"},"cell_type":"markdown","source":"The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n\nThe recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n\nThe F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n\nThe F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n\nThe support is the number of occurrences of each class in y_test."},{"metadata":{"trusted":true,"_uuid":"8a70eccc94158b9d36edf17affb7d39b4e73b1df"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90e58e0021d1395c23d3291ad5cb6c1b55ccd41d"},"cell_type":"markdown","source":"Interpretation: Of the entire test set, 81% price wa predicted properly"},{"metadata":{"trusted":true,"_uuid":"dbd63bda3703c860a4282b36f36ad2c3b827669d"},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\ndef rocAucCurve(classifier):\n    logit_roc_auc = roc_auc_score(y_test, classifier.predict(X_test))\n    fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n    plt.figure()\n    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.savefig('Log_ROC')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79d71fd0b1ca4e2d0752ba2b2d748c0262025a0d"},"cell_type":"code","source":"rocAucCurve(classifier)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb8b1c107fd325472b9ecac36ec8f1789412a8b8"},"cell_type":"markdown","source":"The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. \nThe dotted line represents the ROC curve of a purely random classifier;\na good classifier stays as far away from that line as possible (toward the top-left corner)."},{"metadata":{"_uuid":"0c9a64e3d043b617b5427ab3922836b8cac629e4"},"cell_type":"markdown","source":"## B. Classification with Trees\nThe best way to think about hyperparameters is like the settings of an algorithm that can be adjusted to optimize performance,\n Hyperparameter tuning relies more on experimental results than theory, and thus the best method to determine the optimal settings is to try many different combinations evaluate the performance of each model.\n Hyper Parameter\n  - n_estimators = number of trees in the foreset\n  - max_features = max number of features considered for splitting a node\n  - max_depth = max number of levels in each decision tree\n  - min_samples_split = min number of data points placed in a node before the node is split\n  - min_samples_leaf = min number of data points allowed in a leaf node\n  - bootstrap = method for sampling data points (with or without replacement)"},{"metadata":{"_uuid":"9c3d3730eb8f42b207bc3c8c494f5c8da5b83a82"},"cell_type":"markdown","source":" 1. Bagging based tree algorithm (Random Forest)"},{"metadata":{"trusted":true,"_uuid":"d463b93e7feea73ed35f35137fbc7dba895ed2ba"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier  \nclassifierDT = RandomForestClassifier()  \nclassifierDT.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6fa02e0cf4aae486ab6e2926ff2cf45ded259a0"},"cell_type":"code","source":"y_pred = classifierDT.predict(X_test)  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d29f2d54afc152829dd1da3b2fca157250e18b47"},"cell_type":"markdown","source":"Evaluating the Algorithm"},{"metadata":{"trusted":true,"_uuid":"1572fb099d0ab2affb1815ff2f724e20db6ddcac"},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, y_pred))  \nprint(classification_report(y_test, y_pred))  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25dd660daa5aef80995dabbfcc9d1fec10fdb488"},"cell_type":"markdown","source":"75% correct Prediction"},{"metadata":{"trusted":true,"_uuid":"82782e7e4dce8bd3ca0f36b167111fb63e615f92"},"cell_type":"code","source":"rocAucCurve(classifierDT)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9867a73ce7fea5b1b48f322bffdf06cc33a0bf1"},"cell_type":"markdown","source":"### Hyper Parameters Tuning"},{"metadata":{"_uuid":"a2ea0edd6a227609af8748ddde52428aaa4456a9"},"cell_type":"markdown","source":"Random Hyperparameter Grid\nTo use RandomizedSearchCV, we first need to create a parameter grid to sample from during fitting:\n    [More Details](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"},{"metadata":{"trusted":true,"_uuid":"2db96499fdf31679e1911e7c38a4a79aa30a8622"},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom pprint import pprint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33791c5e36e535ac0d4821dd392542fbf72d28c7"},"cell_type":"code","source":"#Let us see what default parameters our model used\nprint('Parameters currently in use:\\n')\npprint(classifierDT.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6e4d6c35e68773aea9e1a3438cac4c791641dfa"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 90],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4],\n    'min_samples_split': [8, 10],\n    'n_estimators': [100, 200]\n}\n# Create a based model\nrf = RandomForestClassifier()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6805fe8ad38171fd51a3792deb1551410bdd485f"},"cell_type":"code","source":"# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)\ngrid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d3e986c4508fcfb075b437137a6ddc417561fd1"},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e64edadfc534642bd0a2e23ed580f68e60e9dff0"},"cell_type":"code","source":"random1=RandomForestClassifier(n_estimators=200,max_depth=90, min_samples_split=8, min_samples_leaf=3, max_features=3,bootstrap=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e324f680d5b8c9120900f48016cd93a3dd98201"},"cell_type":"code","source":"random1.fit(X_train,y_train)\ny_pred = random1.predict(X_test)  \nprint(confusion_matrix(y_test, y_pred))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af09ac90aeac1fbbc02593c6b869e21cfd853924"},"cell_type":"code","source":"print(classification_report(y_test, y_pred)) \nrocAucCurve(random1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"424f9e8bbf426ae692e28af5f44d6b8b3b1db5c5"},"cell_type":"markdown","source":"Here after Tuning the parameters we got AUC as 0.81 as compared to \nRandom Forest not Tuned Parameter"},{"metadata":{"_uuid":"26e8099fe2c0aed4d9ee8aace1a3efc4b50b40fb"},"cell_type":"markdown","source":" ### 2. Boosting based tree algorithm (GradientBoosting)\n Lets consider another set of parameters for managing boosting:\n\n- learning_rate\nThis determines the impact of each tree on the final outcome (step 2.4). GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates.\nLower values are generally preferred as they make the model robust to the specific characteristics of tree and thus allowing it to generalize well.\nLower values would require higher number of trees to model all the relations and will be computationally expensive.\n- n_estimators\nThe number of sequential trees to be modeled (step 2)\nThough GBM is fairly robust at higher number of trees but it can still overfit at a point. Hence, this should be tuned using CV for a particular learning rate.\nsubsample\nThe fraction of observations to be selected for each tree. Selection is done by random sampling.\nValues slightly less than 1 make the model robust by reducing the variance.\nTypical values ~0.8 generally work fine but can be fine-tuned further.\nApart from these, there are certain miscellaneous parameters which affect overall functionality:\n\n- loss\nIt refers to the loss function to be minimized in each split.\nIt can have various values for classification and regression case. Generally the default values work fine. Other values should be chosen only if you understand their impact on the model.\n- init\nThis affects initialization of the output.\nThis can be used if we have made another model whose outcome is to be used as the initial estimates for GBM.\n- random_state\nThe random number seed so that same random numbers are generated every time.\nThis is important for parameter tuning. If we don’t fix the random number, then we’ll have different outcomes for subsequent runs on the same parameters and it becomes difficult to compare models.\nIt can potentially result in overfitting to a particular random sample selected. We can try running models for different random samples, which is computationally expensive and generally not used.\n- verbose\nThe type of output to be printed when the model fits. The different values can be:\n0: no output generated (default)\n1: output generated for trees in certain intervals >1: output generated for all trees\n- warm_start\nThis parameter has an interesting application and can help a lot if used judicially.\nUsing this, we can fit additional trees on previous fits of a model. It can save a lot of time and you should explore this option for advanced applications\n- presort \n Select whether to presort data for faster splits.\nIt makes the selection automatically by default but it can be changed if needed.\n\n\n"},{"metadata":{"trusted":true,"_uuid":"2c28fce9959422a9e67f3856ac8d91254353821c"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcfedabe8571514b6236b5602ec9a6673fcbb06c"},"cell_type":"code","source":"gb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82803c0f1e219c8faee1ac0e82b5064a88842997"},"cell_type":"code","source":"y_pred = gb.predict(X_test)  \nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2683d32063a5698b972c6a5196965543702fd07"},"cell_type":"code","source":"print(classification_report(y_test, y_pred)) \nrocAucCurve(gb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f489e8844f54a7774c883d27f1f86181a5f999a7"},"cell_type":"code","source":"learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\nfor learning_rate in learning_rates:\n    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n    gb.fit(X_train, y_train)\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9fa7766deee2a8aa8a58c94e2d66f15e8c92987"},"cell_type":"code","source":"#Learning rate 1  is good \ngb_op = GradientBoostingClassifier(n_estimators=20, learning_rate = 0.75, max_features=2, max_depth = 2, random_state = 0)\ngb_op.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4a14fcac94f6b9223847e3c21f38996d8a0d70d"},"cell_type":"code","source":"y_pred = gb_op.predict(X_test)  \nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19df6348c94b5870213d8185af3213ef66751ebb"},"cell_type":"code","source":"print(classification_report(y_test, y_pred)) \nrocAucCurve(gb_op)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4e30d4fbb135f3cb4ca3c66fd1ea248fe0c1489"},"cell_type":"markdown","source":"## Comparison of Classification Models\nLets Compare  Precision and AUC \n1. Logistic Regression\n  - Precision : 81%\n  - AUC : 0.81\n2. Random Forest\n  - Precision : 81%\n  - AUC : 0.81\n3. Gradient Boosting \n - Precision : 77%\n - AUC : 0.77"},{"metadata":{"_uuid":"0cdd25d9db94c2847f606bc8b4643813d96acecf"},"cell_type":"markdown","source":"As per the comparison Logistic Regression and Random Forest Works well on given Model for classification"},{"metadata":{"_uuid":"a2217ae049baae8d32383fb61fd6268aac6e23e2"},"cell_type":"markdown","source":"## Linear Regression"},{"metadata":{"_uuid":"302815e76f84471d9675130861c061c8fa6ae4cb"},"cell_type":"markdown","source":"### Regression with Trees"},{"metadata":{"trusted":true,"_uuid":"361e28dac862d35a8099ffa55cd402606378b07c"},"cell_type":"code","source":"Y= filedata['log_price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbd05bb71e2712515339da41d0c6007b6e2e3d47"},"cell_type":"code","source":"numericdataX= numericdataX.drop(['log_price'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db3e7faa04c9540278a44f30f34d987f96e963e6"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(numericdataX,Y, test_size=0.2, random_state=0)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34f17dc9decd4bda9298ca0d2bb3d50c8e0af08e"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor  \nregressor = RandomForestRegressor()  \nregressor.fit(X_train, y_train)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ba8f05cd2d103ccfe76af0fd34b27cf3d4441bf"},"cell_type":"code","source":"y_pred = regressor.predict(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6544611b5124ac0ea6e03392ab0bc174c57e145"},"cell_type":"code","source":"df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})  \ndf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b38a78280bf13c53d46a2d89e361566dea60427"},"cell_type":"markdown","source":"\nEvaluating the Algorithm\nTo evaluate performance of the regression algorithm, the commonly used metrics are mean absolute error, mean squared error, and root mean squared error. The Scikit-Learn library contains functions that can help calculate these values for us. To do so, use this code from the metrics package:\n"},{"metadata":{"trusted":true,"_uuid":"2a330036369cc6fa74e2a7fe0ca0f7f6d1a5a98a"},"cell_type":"code","source":"def regression_Metrics(y_test, y_pred):  \n    from sklearn import metrics  \n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"361c7ad4f221447107c3f5d2034a8899b60a51d6"},"cell_type":"code","source":"regression_Metrics(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f67d48d2c1451ec8f7f5a04bbceaa2e773c2ecc"},"cell_type":"markdown","source":"## Hyper Parameter Tuning"},{"metadata":{"trusted":true,"_uuid":"c91cf1d37ad4e6dc3be954025385e3dddd424f2f"},"cell_type":"code","source":"#Let us see what default parameters our model used\nprint('Parameters currently in use:\\n')\npprint(regressor.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41b7ebbc129eb1d88e3c0f266e4d828a2941e9ef"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 90],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4],\n    'min_samples_split': [8, 10],\n    'n_estimators': [100, 200]\n}\n# Create a based model\nrf = RandomForestRegressor()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9c38668f5f95923109e64f33060b7b6609cc844"},"cell_type":"code","source":"# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcbbc6004e91b023d17bf98043f01f9484979dd5"},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cd4d0d07c77671d67c062a071f1cf1ece54aad0"},"cell_type":"code","source":"regressor1=RandomForestRegressor(n_estimators=200,max_depth=90, min_samples_split=10, min_samples_leaf=10, max_features=3,bootstrap=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"203f5c8b1fce8e4dc40ebefa6baf3999424d3b3e"},"cell_type":"code","source":"regressor1.fit(X_train,y_train)\ny_pred = regressor1.predict(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a97f5cb6a295d0e449f87c409419a9c303c83110"},"cell_type":"code","source":"regression_Metrics(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57787732416bd5c492030a2374c3272492084515"},"cell_type":"markdown","source":"## Boosting based tree algorithm (GradientBoosting)"},{"metadata":{"trusted":true,"_uuid":"f535a9ec7b2b6314dd6626d365aa0aaf662c4fe2"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngb = GradientBoostingRegressor()\ngb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b32e37750bce1b88fe4fd44b79589130d44cfba"},"cell_type":"code","source":"y_pred = gb.predict(X_test)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de9c2e499c1a926b413bc6f6d59ec58a621324e7"},"cell_type":"code","source":"regression_Metrics(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ae5037f14415d662381c2c46b76165fac37906e"},"cell_type":"code","source":"learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\nfor learning_rate in learning_rates:\n    gb = GradientBoostingRegressor(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n    gb.fit(X_train, y_train)\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59100de6166a2a45a7321608a2983f699ac71b4c"},"cell_type":"code","source":"gb_op = GradientBoostingRegressor(n_estimators=20, learning_rate = 1, max_features=2, max_depth = 2, random_state = 0)\ngb_op.fit(X_train,y_train)\ny_pred = gb_op.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51288544b9a2a682550fc2c5e0b26495a2da585e"},"cell_type":"code","source":"regression_Metrics(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1927883ed8a793391e2facfb113f56bb855203d6"},"cell_type":"markdown","source":"## Comparison of different Approaches:"},{"metadata":{"_uuid":"54d388fa7b3458b1dedafdef6c5dfd3dfd062aa5"},"cell_type":"markdown","source":"1.  Linear Regression:\nRoot Mean Squared Error: 0.4721355501041085\n\n2.  Linear Regresssion with trees:\n    - Random Forest\n        -  Mean Absolute Error: 0.3681282451600619\n        - Mean Squared Error: 0.2388446162343491\n        - Root Mean Squared Error: 0.48871731730556583\n\n    -  Boosting \n         - Mean Absolute Error: 0.39340469697589975\n         - Mean Squared Error: 0.2670819491835599\n         - Root Mean Squared Error: 0.5167997186372685\n\n"},{"metadata":{"_uuid":"5542f8aa3e2436d1ab7ff506b2276ec7deea5997"},"cell_type":"markdown","source":"As per the comparison Regression with linear regression works well on given Model"},{"metadata":{"trusted":true,"_uuid":"0f6bc2a0d2b15b549d651270f4982e0301e69311"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}