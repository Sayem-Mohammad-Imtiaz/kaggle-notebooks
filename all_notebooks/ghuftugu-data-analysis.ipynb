{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA -  with Data Updation (GP Orders - 5)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\npd.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/gufhtugu-publications-dataset-challenge/GP Orders - 5.csv\", encoding = 'utf-8')\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As Column **Book Name** has 2 values missing so we'll drop these rows. Nan in columns **City (Billing)** and **Payment Method** will not effect our analysis much we'll leave it and replace this with '-' "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['Book Name'].notna()]\ndf['Order Date & Time'] = pd.to_datetime(df['Order Date & Time'])\ndf.fillna('-',inplace=True)\ndf['Order Status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"a = lambda x: x.strip('')\ndf['Book Name'] = df['Book Name'].map(a)\ndf['Book Name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\t\\t\\t*** INSIGHTS FOR BLOCKCHAIN ***\\n\\n\\n\")\nprint(df.iloc[0]['Book Name'],\"\\nTotal items: \",df.iloc[0]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")\nprint(df.iloc[28]['Book Name'],\"\\nTotal items: \",df.iloc[28]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")\nprint(df.iloc[6]['Book Name'],\"\\nTotal items: \",df.iloc[6]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")\nprint(df.iloc[11]['Book Name'],\"\\nTotal items: \",df.iloc[11]['Total items'])\nprint(\"-------x-------x----------x--------x--------------------------------------\\n\\n\")\nprint(\"\\t\\t\\t*** INSIGHTS FOR (C++)/C ***\\n\\n\\n\")\nprint(df.iloc[9]['Book Name'],\"\\nTotal items: \",df.iloc[9]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")\nprint(df.iloc[50]['Book Name'],\"\\nTotal items: \",df.iloc[50]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")\nprint(df.iloc[1012]['Book Name'],\"\\nTotal items: \",df.iloc[1012]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")\nprint(df.iloc[699]['Book Name'],\"\\nTotal items: \",df.iloc[699]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")\nprint(df.iloc[711]['Book Name'],\"\\nTotal items: \",df.iloc[711]['Total items'])\nprint(\"-------x-------x----------x--------x\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Points:\n\n\n1) From above we have seen that some of the quanities of books doesn't match to its item size in column **Total items**.\n\n2) So we have to add or repeat more books where needed. E.g at **Index 0** , **Index 6** and so on.\n\n3) Each cell contain multiple books so we have to split each cell in multiple rows.\n### Issue:\n4) We'll split it with the help of **/ (Fwd slash)** . But if we do this, it will interpret **(C++) ++سی/سی** as 2 different books instead of 1.\n### Solution:\n5) We are going to modify the string from **(C++) ++سی/سی** to **(C++) ++سی-سی**. Then we can split into rows easily. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Book Name'] = df['Book Name'].str.replace(r\"\\(C\\++\\)\\s\\++سی/سی\" , '(C++) ++سی-سی', regex=True)\n\ndef func(x):\n    ans = x.split('/')\n    return ans\n    \n\ndf[\"Book Name\"] = df[\"Book Name\"].map(func)\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Repeating String\nind = df.index\n\nfor ind in ind:\n    if (len(df['Book Name'][ind]) < df['Total items'][ind]):\n        count = df['Total items'][ind] - len(df['Book Name'][ind])\n#         print(\"Counter To Repeat String: \",count)\n#         print(\"-----BEFORE----\\n\\n\")\n#         print(\"\\nIndex: \", ind ,\"\\nBooks: \", df['Book Name'][ind] , \"\\nTotal Items: \", df['Total items'][ind] ,\\\n#         end=\"\\n-----------------------X---------------------X-----------------\\n\\n\")\n        for i in range(count):\n            df['Book Name'][ind].append(df['Book Name'][ind][0])\n#         print(\"-----After----\\n\\n\")\n#         print(\"\\nIndex: \", ind ,\"\\nBooks: \", df['Book Name'][ind] , \"\\nTotal Items: \", df['Total items'][ind] ,\\\n#         end=\"\\n-----------------------X---------------------X-----------------\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross Check\n\nind = df.index\nfor ind in ind:\n    if (len(df['Book Name'][ind]) < df['Total items'][ind]):\n        print(df['Book Name'][ind])\nelse:\n    print(\"cleaned\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting in multiple columns \nnew_df = df.explode(\"Book Name\", ignore_index= True)\nnew_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# POINT\n- No. of rows in **new_df or Book Name** should be equal to the sum of values in column **Total items**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Total items'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.head(50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TASK 1: \n## **What is the best-selling book?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Unique Status: \",new_df['Order Status'].unique() ,\\\n      \"\\nNo. of Unique Books :\", len(new_df['Book Name'].unique()) ,\\\n      \"\\nNo. of Unique Cities :\", len(new_df['City'].unique()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The best selling book can be extracted from where the Order Status is Completed**"},{"metadata":{"trusted":true},"cell_type":"code","source":"delievered = new_df[new_df['Order Status'] == 'Completed']\ndelievered['Order Status'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_selling_book = delievered['Book Name'].value_counts().to_frame()\nbest_selling_book.iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Answer:\n### Top 3 Selling Books, Respectively:\n\n1. انٹرنیٹ سے پیسہ کمائیں\n\n2. Python Programming\t\n\n3. Artificial Intelligence"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}