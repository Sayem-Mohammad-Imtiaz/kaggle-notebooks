{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classify wine data.\n\nIt is classified as 0,1 considering alcohol, sugar content, and pH characteristics.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\nfrom scipy.stats import uniform, randint\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nfrom sklearn.inspection import permutation_importance # 중요특성을 변환기\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import plot_tree\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\nimport os\n\n# wine_csv_data uploaded...\nfor dirname, _, filenames in os.walk('../input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nwine = pd.read_csv('../input/wine-scv-data/wine_csv_data.csv')\n\nprint(wine.head())\nprint(wine.info())\nprint(wine.describe())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-21T05:17:25.546506Z","iopub.execute_input":"2021-07-21T05:17:25.54693Z","iopub.status.idle":"2021-07-21T05:17:26.935399Z","shell.execute_reply.started":"2021-07-21T05:17:25.546896Z","shell.execute_reply":"2021-07-21T05:17:26.93359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\ntarget = wine['class'].to_numpy()\n\nprint(data[:5])\nprint(target[:5])","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:26.936899Z","iopub.execute_input":"2021-07-21T05:17:26.937173Z","iopub.status.idle":"2021-07-21T05:17:26.945097Z","shell.execute_reply.started":"2021-07-21T05:17:26.937144Z","shell.execute_reply":"2021-07-21T05:17:26.944094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input, test_input, train_target, test_target = train_test_split(\n    data, target, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:26.947338Z","iopub.execute_input":"2021-07-21T05:17:26.947861Z","iopub.status.idle":"2021-07-21T05:17:26.960831Z","shell.execute_reply.started":"2021-07-21T05:17:26.947813Z","shell.execute_reply":"2021-07-21T05:17:26.959828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LogisticRegresssion","metadata":{}},{"cell_type":"code","source":"ss = StandardScaler()\nss.fit(train_input)\n\ntrain_scaled = ss.transform(train_input)\ntest_scaled = ss.transform(test_input)\n\nlr = LogisticRegression()\nlr.fit(train_scaled, train_target)\ntrainscore = lr.score(train_scaled, train_target)\ntestscore = lr.score(test_scaled, test_target)\n\nplt.bar((0,1),(trainscore,testscore), color=('red','orange'), linewidth=3, width=0.3)\n#plt.xticks((0,1), (trainscore,testscore))\nplt.title('logisticRegression')\nred_patch = mpatches.Patch(color='red', label='trainscore')\norange_patch = mpatches.Patch(color='orange', label='testscore')\nplt.legend(handles=[red_patch,orange_patch])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:26.962917Z","iopub.execute_input":"2021-07-21T05:17:26.963272Z","iopub.status.idle":"2021-07-21T05:17:27.225081Z","shell.execute_reply.started":"2021-07-21T05:17:26.963239Z","shell.execute_reply":"2021-07-21T05:17:27.224314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DecisionTreeClassifier","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"dt = DecisionTreeClassifier(random_state=42,max_depth=3)\ndt.fit(train_input, train_target)\n\nscores = cross_validate(dt, train_input, train_target)\nplt.plot(scores['fit_time'])\nplt.title('fit_time')\nplt.show()\nplt.plot(scores['score_time'],label='score_time')\nplt.title('score_time')\nplt.show()\nplt.plot(scores['test_score'],label='test_score')\nplt.title('test_score')\nplt.show()\n\nplt.figure(figsize=(10,7),dpi=300)\nplot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:27.226278Z","iopub.execute_input":"2021-07-21T05:17:27.226682Z","iopub.status.idle":"2021-07-21T05:17:28.951583Z","shell.execute_reply.started":"2021-07-21T05:17:27.226652Z","shell.execute_reply":"2021-07-21T05:17:28.950352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GridSearchCV","metadata":{}},{"cell_type":"code","source":"params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),\n          'max_depth': range(5, 20, 1),\n          'min_samples_split': range(2, 100, 10)\n          }\n\ngs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)\ngs.fit(train_input, train_target)\n\nprint(gs.best_params_)\nprint(np.max(gs.cv_results_['mean_test_score']))\n\nplt.plot(gs.cv_results_['mean_test_score'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:28.953265Z","iopub.execute_input":"2021-07-21T05:17:28.953757Z","iopub.status.idle":"2021-07-21T05:17:44.743315Z","shell.execute_reply.started":"2021-07-21T05:17:28.953711Z","shell.execute_reply":"2021-07-21T05:17:44.742456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RandomizedSearchCV","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"params = {'min_impurity_decrease': uniform(0.0001, 0.001),\n          'max_depth': randint(20, 50),\n          'min_samples_split': randint(2, 25),\n          'min_samples_leaf': randint(1, 25),\n          }\n\ngs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params,\n                        n_iter=100, n_jobs=-1, random_state=42)\ngs.fit(train_input, train_target)\n\nprint(gs.best_params_)\nprint(np.max(gs.cv_results_['mean_test_score']))\ndt = gs.best_estimator_\nprint(dt.score(test_input, test_target))\n\nplt.plot(gs.cv_results_['mean_test_score'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:44.744643Z","iopub.execute_input":"2021-07-21T05:17:44.745156Z","iopub.status.idle":"2021-07-21T05:17:46.253336Z","shell.execute_reply.started":"2021-07-21T05:17:44.745121Z","shell.execute_reply":"2021-07-21T05:17:46.252528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=-1, random_state=42)\nscores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n\nprint(np.mean(scores['train_score']), np.mean(scores['test_score']))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:46.255547Z","iopub.execute_input":"2021-07-21T05:17:46.256Z","iopub.status.idle":"2021-07-21T05:17:47.881601Z","shell.execute_reply.started":"2021-07-21T05:17:46.255963Z","shell.execute_reply":"2021-07-21T05:17:47.880569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.fit(train_input, train_target)\nprint(rf.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:47.883101Z","iopub.execute_input":"2021-07-21T05:17:47.883373Z","iopub.status.idle":"2021-07-21T05:17:48.464631Z","shell.execute_reply.started":"2021-07-21T05:17:47.883347Z","shell.execute_reply":"2021-07-21T05:17:48.463348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RandomForestClassifier oob_score=True \n\n위 속성은 훈련 데이터로 사용하지 않은 데이터로 샘플데이터로 점수를 확인","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n\nrf.fit(train_input, train_target)\nprint(rf.oob_score_)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:48.466002Z","iopub.execute_input":"2021-07-21T05:17:48.466302Z","iopub.status.idle":"2021-07-21T05:17:49.043111Z","shell.execute_reply.started":"2021-07-21T05:17:48.466274Z","shell.execute_reply":"2021-07-21T05:17:49.042372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ExtraTreesClassifier","metadata":{}},{"cell_type":"code","source":"et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\nscores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n\nprint(np.mean(scores['train_score']), np.mean(scores['test_score']))\n\net.fit(train_input, train_target)\nprint(et.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:49.044289Z","iopub.execute_input":"2021-07-21T05:17:49.044775Z","iopub.status.idle":"2021-07-21T05:17:51.027842Z","shell.execute_reply.started":"2021-07-21T05:17:49.044726Z","shell.execute_reply":"2021-07-21T05:17:51.026721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gb = GradientBoostingClassifier(random_state=42)\nscores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n\nprint(np.mean(scores['train_score']), np.mean(scores['test_score']))\n\ngb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42) # tree 갯수를 500개로 지정\nscores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n\nprint(np.mean(scores['train_score']), np.mean(scores['test_score']))\n\ngb.fit(train_input, train_target)\nprint(gb.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:51.029075Z","iopub.execute_input":"2021-07-21T05:17:51.029383Z","iopub.status.idle":"2021-07-21T05:17:58.036987Z","shell.execute_reply.started":"2021-07-21T05:17:51.029353Z","shell.execute_reply":"2021-07-21T05:17:58.035993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HistGradientBoostingClassifier","metadata":{}},{"cell_type":"code","source":"hgb = HistGradientBoostingClassifier(random_state=42)\nscores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n\nprint(np.mean(scores['train_score']), np.mean(scores['test_score']))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:58.039456Z","iopub.execute_input":"2021-07-21T05:17:58.039786Z","iopub.status.idle":"2021-07-21T05:17:59.237893Z","shell.execute_reply.started":"2021-07-21T05:17:58.039753Z","shell.execute_reply":"2021-07-21T05:17:59.237055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# permutation_importance","metadata":{}},{"cell_type":"code","source":"hgb.fit(train_input, train_target)\nresult = permutation_importance(hgb, train_input, train_target, n_repeats=10,\n                                random_state=42, n_jobs=-1)\nprint(result.importances_mean)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:17:59.239315Z","iopub.execute_input":"2021-07-21T05:17:59.239691Z","iopub.status.idle":"2021-07-21T05:18:00.271207Z","shell.execute_reply.started":"2021-07-21T05:17:59.239643Z","shell.execute_reply":"2021-07-21T05:18:00.270413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = permutation_importance(hgb, test_input, test_target, n_repeats=10,\n                                random_state=42, n_jobs=-1)\nprint(result.importances_mean)\n\n\nhgb.score(test_input, test_target)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:18:00.272188Z","iopub.execute_input":"2021-07-21T05:18:00.27245Z","iopub.status.idle":"2021-07-21T05:18:00.519878Z","shell.execute_reply.started":"2021-07-21T05:18:00.272424Z","shell.execute_reply":"2021-07-21T05:18:00.519047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBClassifier","metadata":{}},{"cell_type":"code","source":"xgb = XGBClassifier(tree_method='hist', random_state=42)\nscores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n\nprint(np.mean(scores['train_score']), np.mean(scores['test_score']))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:18:00.523882Z","iopub.execute_input":"2021-07-21T05:18:00.52598Z","iopub.status.idle":"2021-07-21T05:19:19.45218Z","shell.execute_reply.started":"2021-07-21T05:18:00.525926Z","shell.execute_reply":"2021-07-21T05:19:19.451019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBMClassifier","metadata":{}},{"cell_type":"code","source":"lgb = LGBMClassifier(random_state=42)\nscores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n\nprint(np.mean(scores['train_score']), np.mean(scores['test_score']))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:19:19.453748Z","iopub.execute_input":"2021-07-21T05:19:19.454174Z","iopub.status.idle":"2021-07-21T05:19:21.08429Z","shell.execute_reply.started":"2021-07-21T05:19:19.45413Z","shell.execute_reply":"2021-07-21T05:19:21.083502Z"},"trusted":true},"execution_count":null,"outputs":[]}]}