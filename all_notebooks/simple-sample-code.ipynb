{"cells":[{"metadata":{},"cell_type":"markdown","source":"このNotebookでは簡単なサンプルコードを通じて、機械学習の一連の処理\n1. ファイル読み込み\n2. データの前処理\n3. 学習モデルの作成\n4. 学習\n5. 学習済みモデルの評価\n6. 学習済みモデルで判定\n7. 提出用ファイルの作成  \nをみていきます。"},{"metadata":{},"cell_type":"markdown","source":"# 1. ファイル読み込み 〜 2.データの前処理"},{"metadata":{},"cell_type":"markdown","source":"## train.csvファイルの読み込みコード"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nroot_dir = \"/kaggle/input/mj1-anomaly-images-detection-challenge/\"\ntrain_csv_filepath = root_dir + \"train.csv\"\n\n# ファイルの読み込み\ntrain_df = pd.read_csv(train_csv_filepath)\n\n# 出力して中身を確認\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 画像の読み込み"},{"metadata":{"trusted":true},"cell_type":"code","source":"resize_w = 256\nresize_h = 256\nchannel = 3\n\nimport cv2\n# 画像が大きいと計算が遅いため、リサイズ縮小\ndef resize(tmp_image):\n    return cv2.resize(tmp_image , (resize_h, resize_w))\n\n# 4次元配列化()　\ndef to_4d(tmp_image):\n    return tmp_image.reshape(1, resize_h, resize_w, channel)\n    \n\n# 256段階の色調を0.0~1.0にする\ndef normalize(tmp_image):\n    return tmp_image / 255.0\n\n# 画像の前処理付きロード\ndef load_preprocessed_image(image_filepath):\n    tmp_image = cv2.imread(image_filepath)\n    tmp_image = resize(tmp_image)\n    tmp_image = normalize(tmp_image)\n    tmp_image = to_4d(tmp_image)\n    return tmp_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = None\nfor fn in train_df['filename']:\n    image_filepath = root_dir + 'train/' + fn\n    tmp_image = load_preprocessed_image(image_filepath)\n    if (images is None):\n        images = tmp_image\n    else:\n        images = np.vstack((images, tmp_image))\n\n# 確認\nimages.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ラベル"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\n\nanomaly_flags = np.array([flag for flag in train_df['anomaly']])\n\n# 確認\nanomaly_flags = np_utils.to_categorical(anomaly_flags, 2)\nanomaly_flags.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.学習モデルの作成"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n#データの読み込みと前処理\n\nfrom keras.datasets import mnist\n#kerasでCNN構築\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.optimizers import Adam\n\n \n'''\nCNNの構築\n'''\n \nmodel = Sequential()\n \nmodel.add(Conv2D(filters=10, kernel_size=(4,4), padding='same', input_shape=(256, 256, 3), activation='relu'))\nmodel.add(Conv2D(filters=10, kernel_size=(3,3), padding='same', input_shape=(64, 64, 8), activation='relu'))\nmodel.add(Conv2D(filters=10, kernel_size=(2,2), padding='same', input_shape=(16, 16, 16), activation='relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='softmax'))\n \nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0003), metrics=['accuracy'])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## データ分割\n\n学習(train)と、評価(validate、あるいはtest)用にデータを分けます。  \n・学習に使ったデータは判定が簡単ですが、学習に使ってない未知のデータは判定が難しく精度に大きな差があります。\n・実際に判定するデータは、未知のデータばかりなので、未知のデータで性能を測ることが一般的です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = images[:100]\ny_test = anomaly_flags[:100]\nX_train = images[100:]\ny_train = anomaly_flags[100:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. 学習処理\n\n機械学習ライブラリの、fit()関数を呼ぶと学習を開始します。"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train,\n                    y_train,\n                    epochs=50,\n                    batch_size=16,\n                    verbose=1,\n                    validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5.学習済みモデルの評価"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_score = model.evaluate(X_train, y_train, verbose=0)\ntest_score = model.evaluate(X_test, y_test, verbose=0)\n\n\nprint('Train Loss:{0:.3f}'.format(train_score[0]))\nprint('Train accuracy:{0:.3}'.format(train_score[1]))\nprint('Test Loss:{0:.3f}'.format(test_score[0]))\nprint('Test accuracy:{0:.3}'.format(test_score[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. 学習済みモデルで判定"},{"metadata":{},"cell_type":"markdown","source":"## 判定用ファイルの読み込み"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nfrom pathlib import Path\n\ntest_images = None\ntest_filenames = None\nfor test_filepath in glob.glob('/kaggle/input/mj1-anomaly-images-detection-challenge/test/*.png'):\n    tmp_image = load_preprocessed_image(test_filepath)\n    if (test_images is None):\n        test_images = tmp_image\n        test_filenames = [Path(test_filepath).name]\n    else:\n        test_images = np.vstack((test_images, tmp_image))\n        test_filenames.append(Path(test_filepath).name)\n\ntest_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filenames[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 判定\n判定は、predict()関数で行います。"},{"metadata":{"trusted":true},"cell_type":"code","source":"result_predict = model.predict(test_images)\nresult_predict = np.argmax(result_predict, axis=1)\nresult_predict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7.提出用ファイルの作成\n\nkaggleコンペに提出する形式のcsvを作成します。  \n\n計算が終了するとNotebookのデータフォルダ/Outputの下にcsvファイルが作成されます。  "},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_filepath = \"/kaggle/input/mj1-anomaly-images-detection-challenge/sample_submit.csv\"\nsubmit_df = pd.read_csv(submit_filepath, index_col=0)\nsubmit_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\nsubmit_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.to_csv('result_submit.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}