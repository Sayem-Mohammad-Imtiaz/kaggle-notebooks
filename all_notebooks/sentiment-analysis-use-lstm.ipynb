{"cells":[{"metadata":{},"cell_type":"markdown","source":"导入必要的包。"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport numpy as np \nimport pandas as pd \nimport nltk\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, Dropout\n\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"加载数据，只需要'text'和'sentiment'这两列。"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/Sentiment.csv')\ndata = data[['text','sentiment']]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"只做正负面的，删除中性的评论。"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data.sentiment != \"Neutral\"]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"所有句子里的单词都变成小写，去除特殊字符，删掉rt。"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = data['text'].apply(lambda x: x.lower())\ndata['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\ndata['text'] = data['text'].apply((lambda x: x.replace('rt',' ') ))\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"正负样本很不均衡，可能会出现过拟合现象。"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[ data['sentiment'] == 'Positive'].size)\nprint(data[ data['sentiment'] == 'Negative'].size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"下面代码是找出所有句子中的唯一单词，以及句子的最大长度。在所有的语料中，一共有15693个单词，句子的最大长度是30."},{"metadata":{"trusted":true},"cell_type":"code","source":"Maxlen = 0\nunique_words = set()\ncount = 0\n\nfor i in range(len(data['text'].values)):\n    txt = data['text'].values[i]\n    words = nltk.word_tokenize(txt)\n    unique_words = unique_words.union(set(words))\n    lenth = len(words)\n    count += 1\n    if lenth > Maxlen:\n        Maxlen = lenth\nprint('all_sent:',count)\nprint('max length:',Maxlen)\nprint('total unique words:',len(unique_words))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"句子序列化，变成可放入模型的形式。所有序列长度都变成30，如果不够用0填充。"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_fatures = 10000\nMaxlen = 30\n\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X,maxlen = Maxlen)       #序列转化为经过填充以后的一个长度相同的新序列，用0填充。\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"正负样本打标签，Positive -> 1,Negative -> 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = np.zeros(len(data['sentiment'].values))\n\nfor i in range(len(data['sentiment'].values)):\n    if data['sentiment'].values[i] == 'Positive':\n        Y[i]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"划分训练集和测试集"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.25, random_state = 1)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LSTM模型"},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_dim = 128\nlstm_out = 64\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = Maxlen))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer='rmsprop',metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"设置模型的callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 当监测值不再改善时，该回调函数将中止训练\nearlyStopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3,verbose=1)\n\n# 在每个epoch后保存最优模型\nmodelCheckpoint = ModelCheckpoint('../my_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n\n# 当评价指标不再提升时，减少学习率\nreduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='min', min_delta=0.0001)\n\n# callbacks是个列表形式\ncallbacks_list = [earlyStopping,modelCheckpoint,reduceLROnPlateau]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"训练模型"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"batch_size = 32\nhistory = model.fit(X_train, Y_train, epochs = 20, batch_size=batch_size,validation_split=1/4,verbose = 1,callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"验证模型"},{"metadata":{"trusted":true},"cell_type":"code","source":"score,acc = model.evaluate(X_test, Y_test, verbose = 1, batch_size = batch_size)\nprint(\"loss: %.2f\" % (score))\nprint(\"accuracy: %.2f\" % (acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"举两个例子测试下效果。"},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = ['this is a great kernel']\nprint('the sentence is：',test1[0])\n\ntest1 = tokenizer.texts_to_sequences(test1)\ntest1 = pad_sequences(test1, maxlen=Maxlen, dtype='int32', value=0)\n\nsentiment = model.predict(test1)[0][0]\n\nif sentiment > 0.5:\n    print(\"I am {:.2%} sure it's Positive\".format(sentiment))\nelse:\n    print(\"I am {:.2%}sure it's Negative\".format(1- sentiment))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = ['this is a bad kernel']\nprint('the sentence is：',test2[0])\n\ntest2 = tokenizer.texts_to_sequences(test2)\ntest2 = pad_sequences(test2, maxlen=Maxlen, dtype='int32', value=0)\n\nsentiment = model.predict(test2)[0][0]\n\nif sentiment > 0.5:\n    print(\"I am {:.2%} sure it's Positive\".format(sentiment))\nelse:\n    print(\"I am {:.2%} sure it's Negative\".format(1- sentiment))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}