{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Machine Learning from Blood Donations Prediction:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **1. Introduction**\n\nBlood transfusion saves lives - from replacing lost blood during major surgery or a serious injury to treating various illnesses and blood disorders. Ensuring that there's enough blood in supply whenever needed is a serious challenge for the health professionals. The demand for blood fluctuates throughout the year. As one prominent example, blood donations slow down during busy holiday seasons. An accurate forecast for the future supply of blood allows for an appropriate action to be taken ahead of time and therefore saving more lives.\n\nAim Of Project:\n\nTo build a model which can identify who is likely to donate blood again using TPOT. TPOT can eliminate the most tedious part of machine learning seemlessly and effortlessly more than ever. TPOT is meant to be an assistant that gives you ideas on how to solve a particular machine learning problem by exploring pipeline configurations that you might have never considered, then leaves the fine-tuning to more constrained parameter tuning techniques.\n\nYou can reach TPOT website and documentation from [TPOT](http://epistasislab.github.io/tpot/).\n\nLet's get started exploring the data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1) **Importing Libraries**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing necessary libraries \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom tpot import TPOTClassifier\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score\n\n#Importing library for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filter the unwanted warning\nimport warnings\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2) **Loading the blood donations data**\n\nWe now know that we are working with a typical CSV file (i.e., the delimiter is ,, etc.). We proceed to loading the data into memory.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Lets get started exploring the data.\n\ntrain = pd.read_csv(\"../input/predicting-blood-analysis/blood-train.csv\")\ntest=pd.read_csv(\"../input/predicting-blood-analysis/blood-test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3) **Inspecting transfusion DataFrame**\n\nThe RFM model stands for Recency, Frequency and Monetary Value and it is commonly used in marketing for identifying the best customers. In this case, the customers are blood donors.\n\nRFMTC is a variation of the RFM model. Below is a description of what each column means in the dataset:\n\nR (Recency - months since the last donation)\nF (Frequency - total number of donation)\nM (Monetary - total volume blood donated in c.c.)\nT (Time - months since the first donation)\na binary variable representing whether he/she donated blood in March 2007 (1 stands for donating blood; 0 stands for not donating blood)\nIt will be helpful to rename these columns as such; except for the last column, which will be the Target column, as the aim is to predict whether someone donated blood in March 2007.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing the train and test size\nprint(\"Train Shape : \",train.shape)\nprint(\"Test Shape : \",test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTE:\n\n> We can see that there are 576 rows and 6 columns in our training dataset\n\n> We can see that there are 200 rows and 5 columns in our test dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print a concise summary of transfusion DataFrame\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTE:\n\n> We can see that there is no missing vale for any row.\n\n> The datatype for all features is integer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"4. **Creating target column**\n\nWe are aiming to predict the value in whether he/she donated blood in March 2007 column. Let's rename this it to target so that it's more convenient to work with","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename target column as 'target' for brevity\ntrain.rename(\n    columns={'Made Donation in March 2007':'Target'},\n    inplace=True\n)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5.**Checking target incidence**\n\nWe want to predict whether or not the same donor will give blood the next time the vehicle comes to campus. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:\n\n0 - the donor will not give blood\n1 - the donor will give blood\nTarget incidence is defined as the number of cases of each individual target value in a dataset. That is, how many 0s in the target column compared to how many 1s? Target incidence gives us an idea of how balanced (or imbalanced) is our dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counting the number of people who donated and not donated\ntrain[\"Target\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note:\n> This is an imbalance dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"6) **Looking into the testing dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note:\n> Made Donation in March 2007 is not present in Test data.\n\n> We have to train our classifier using the Train data and generate predictions (Made Donation in March 2007) on Test data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTE:\n\n> We can see that there is no missing vale for any row.\n> \n> The datatype for all features is an integer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Data Exploration**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"7) **Describing training dataset**\n\ndescribe() method can show different values like count, mean, standard deviation, etc. of numeric data types.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics of the data\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Boxplot for Months since Last Donation\nplt.figure(figsize=(20,10)) \nsns.boxplot(y=\"Months since Last Donation\",data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note:\n> We can see that most of donations happened around 10th month\n> There are some outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation between all variables [Checking how different variable are related]\ncorrmat=train.corr()\nf, ax = plt.subplots(figsize =(9, 8)) \nsns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1,fmt = \".2f\",annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTE:\nHeatmap of Correlation between different features:\n\nPositive numbers = Positive correlation, i.e. increase in one feature will increase the other feature & vice-versa.\nNegative numbers = Negative correlation, i.e. increase in one feature will decrease the other feature & vice-versa.\n\nIn our case, we focus on which features have strong positive or negative correlation with the Target feature.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Model Building**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"9. **Splitting dataset into train and test datasets**\n\nWe'll now use train_test_split() method to split DataFrame.This is very easy to do using the train_test_split() method from the scikit learn library - all we need to do is specify the stratify parameter. In our case, we'll stratify on the target column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import train_test_split method\nfrom sklearn.model_selection import train_test_split\n\n# Split transfusion DataFrame into\n# X_train, X_test, y_train and y_test datasets,\n# stratifying on the `target` column\nX_train, X_test, y_train, y_test = train_test_split(\n    train.drop(columns=['Target','Unnamed: 0']),\n    train.Target,\n    test_size=0.2,\n    random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"10. **Selecting model using TPOT**\n\nTPOT is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.\n![download.png](attachment:download.png)\n\nTPOT will automatically explore hundreds of possible pipelines to find the best one for our dataset. Note, the outcome of this search will be a scikit-learn pipeline, meaning it will include any pre-processing steps as well as the model.\n\nWe are using TPOT to help us zero in on one model that we can then explore and optimize further.","attachments":{"download.png":{"image/png":"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"}},"execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import TPOTClassifier and roc_auc_score\nfrom tpot import TPOTClassifier\nfrom sklearn.metrics import roc_auc_score\n\n# Instantiate TPOTClassifier\ntpot = TPOTClassifier(\n    generations=5,\n    population_size=20,\n    verbosity=2,\n    scoring='roc_auc',\n    random_state=42,\n    disable_update_check=True,\n    config_dict='TPOT light'\n)\ntpot.fit(X_train, y_train)\n\n# AUC score for tpot model\ntpot_auc_score = roc_auc_score(y_test, tpot.predict_proba(X_test)[:, 1])\nprint(f'\\nAUC score: {tpot_auc_score:.4f}')\n\n\n# Print best pipeline steps\nprint('\\nBest pipeline steps:', end='\\n')\nfor idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n    # Print idx and transform\n    print(f'{idx}. {transform}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpot.fitted_pipeline_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TPOT picked LogisticRegression as the best model for our dataset with no pre-processing , giving us the AUC score of 0.8042. This is a great starting point. Let's see if we can make it better.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"10. Training the linear regression model¶\n\nWe are now ready to train the linear regression model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing modules\nfrom sklearn.linear_model import LogisticRegression\n# Instantiate LogisticRegression\nlogreg = LogisticRegression(C=25.0, random_state=42)\n#Fitting the model\nlogreg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting on the test data\npred=logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#printing the confusion matrix\nconfusion_matrix(pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AUC score for tpot model\nlogreg_auc_score = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\nprint(f'\\nAUC score: {logreg_auc_score:.4f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"11. **Conclusion**\n\nIn this notebook, we explored automatic model selection using TPOT and AUC score we got was 0.8042. This is better than simply choosing 0 all the time (the target incidence suggests that such a model would have 76% success rate). If you plan to use TPOT in the future, I strongly suggest you look at its excellent [documentation](http://epistasislab.github.io/tpot/). You can further improve the auc score by removing outliers as logistic regression is sensitive to outliers. Thus, removing outliers can further improve it.\n\nThank you for reading my notebook,please upvote it if you like it.\n ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}