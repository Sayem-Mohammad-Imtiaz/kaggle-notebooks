{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import seaborn as sns\nimport numpy as np \nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt\nfrom IPython.display import display, Markdown, HTML\nfrom collections import Counter, defaultdict\nfrom joblib import Memory\nfrom shutil import rmtree\n\n# Preprocessing modules\nfrom scipy.stats import kstest, shapiro, normaltest\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, MaxAbsScaler\nfrom sklearn.model_selection import KFold, cross_validate, train_test_split, GridSearchCV\nfrom sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n\n# Classifiers\nfrom sklearn.naive_bayes import GaussianNB as NaiveBayes\nfrom sklearn.svm import SVC as SVM\nfrom sklearn.ensemble import RandomForestClassifier as RandomForest\nfrom sklearn.ensemble import GradientBoostingClassifier as GradientBoosting\nfrom sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier as AdaBoost\n\n\n# Metrics\nfrom sklearn.metrics import accuracy_score as accuracy\nfrom sklearn.metrics import confusion_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')\n                        \n# Auxiliary display functions\nshow = lambda _df: display(HTML(_df.to_html()))\nshape = lambda _df: print(f\"Number of features: {_df.shape[1]}\\nNumber of examples: {_df.shape[0]}\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:08:40.227479Z","iopub.execute_input":"2021-08-01T23:08:40.228051Z","iopub.status.idle":"2021-08-01T23:08:41.714654Z","shell.execute_reply.started":"2021-08-01T23:08:40.22794Z","shell.execute_reply":"2021-08-01T23:08:41.713323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_file = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        input_file.append(os.path.join(dirname, filename))\ninput_file = input_file[0]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:08.684933Z","iopub.execute_input":"2021-08-01T23:09:08.685324Z","iopub.status.idle":"2021-08-01T23:09:08.693188Z","shell.execute_reply.started":"2021-08-01T23:09:08.685291Z","shell.execute_reply":"2021-08-01T23:09:08.69202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(input_file, sep='|')\nfeatures = df.columns\nshape(df)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:10.135994Z","iopub.execute_input":"2021-08-01T23:09:10.13638Z","iopub.status.idle":"2021-08-01T23:09:11.846422Z","shell.execute_reply.started":"2021-08-01T23:09:10.136348Z","shell.execute_reply":"2021-08-01T23:09:11.845436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset overview","metadata":{"editable":false}},{"cell_type":"code","source":"# Check DataFrame for invalid values\nshow(pd.DataFrame.from_dict(\\\n                            {'Valids': df.notna().sum().sum(),\\\n                            'Invalids': df.isna().sum().sum()}, \\\n                            orient='index', \\\n                            columns=['values']))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:16.502331Z","iopub.execute_input":"2021-08-01T23:09:16.502912Z","iopub.status.idle":"2021-08-01T23:09:16.607458Z","shell.execute_reply.started":"2021-08-01T23:09:16.502877Z","shell.execute_reply":"2021-08-01T23:09:16.606684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The dataset does not contain invalid values, lets check what data types it contains\nshow(pd.DataFrame.from_dict(\\\n                            Counter(df.dtypes.values),\\\n                            orient='index', \\\n                            columns=['features']))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:16.692745Z","iopub.execute_input":"2021-08-01T23:09:16.693281Z","iopub.status.idle":"2021-08-01T23:09:16.704011Z","shell.execute_reply.started":"2021-08-01T23:09:16.693248Z","shell.execute_reply":"2021-08-01T23:09:16.702991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking Class Balancing\nsns.set(font_scale=2)\nfig = plt.figure(figsize=(15,2))\nsns.countplot(y='legitimate', data=df);\nclass_counts = df.legitimate.value_counts()\nclass_proportions = ((df.legitimate.value_counts()/len(df))*100).round(2)\n\nshow(pd.DataFrame.from_dict(\\\n                            {'Total number of examples': f\"{class_counts[0] + class_counts[1]}\",\\\n                             'Malware (0)': f\"{class_counts[0]} ({class_proportions[0]}%)\",\\\n                             'Legitimate (1)': f\"{class_counts[1]} ({class_proportions[1]}%)\"},\\\n                            orient='index', columns=['']))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:16.907823Z","iopub.execute_input":"2021-08-01T23:09:16.90825Z","iopub.status.idle":"2021-08-01T23:09:17.184092Z","shell.execute_reply.started":"2021-08-01T23:09:16.908218Z","shell.execute_reply":"2021-08-01T23:09:17.182654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All but 2 features contains only numeric values. Lets check those.\ndf[df.select_dtypes(include='object').columns].sample(n=5)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:17.18589Z","iopub.execute_input":"2021-08-01T23:09:17.186287Z","iopub.status.idle":"2021-08-01T23:09:17.232352Z","shell.execute_reply.started":"2021-08-01T23:09:17.18625Z","shell.execute_reply":"2021-08-01T23:09:17.230947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Both columns contain strings\n# The 'md5' feature brings no important information for our analysis.\n# Malware examples does not inform file extensions, therefore the feature 'Name' may also be discarded\ndf.drop(['Name', 'md5'], axis=1, inplace=True)\nshape(df)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:17.23472Z","iopub.execute_input":"2021-08-01T23:09:17.235212Z","iopub.status.idle":"2021-08-01T23:09:17.280055Z","shell.execute_reply.started":"2021-08-01T23:09:17.235164Z","shell.execute_reply":"2021-08-01T23:09:17.277828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data distribution","metadata":{"editable":false}},{"cell_type":"markdown","source":"### Normality tests","metadata":{"editable":false}},{"cell_type":"markdown","source":"* H0 (null hypothesis): the data follow a normal distribution\n* H1: the data do not follow a normal distribution\n\n\n- $\\alpha = 0.05$\n- p-value $\\leq \\alpha$: reject H0 (data is not normally distributed)\n- p-value $> \\alpha$: do not reject H0 (assume that the sampling distribution of the mean is normal)","metadata":{"editable":false}},{"cell_type":"code","source":"# Auxiliary functions\nH1 = \"Reject H0\"\nH0 = \"Do not Reject H0\"\ndef shapiro_wilk(values: pd.Series, alpha=0.05):\n    _, p = shapiro(values)\n    \n    return 0 if p <= alpha else 1\n\ndef k_squared(values: pd.Series, alpha=0.05):\n    _, p = normaltest(values)\n    \n    return 0 if p <= alpha else 1\n\ndef kolmogorov_smirnov(values: pd.Series, mu: np.float64, sd: np.float64, alpha=0.05):\n    _, p = kstest(values, 'norm', args=(mu, sd))\n    \n    return 0 if p <= alpha else 1\n\n# Majority decision function\ndef test_result(tests: list):\n    val = sum(tests)\n    \n    return H1 if val < 2 else H0\n\ndef is_normal(data: pd.DataFrame, description=None, dtypes=['float64','int64'], alpha=0.05):\n    if not isinstance(description, pd.DataFrame):\n        description = data.describe(include=dtypes)\n    \n    normal_features = []\n    result = []\n    for feature in list(data.columns):\n        series = data[feature]\n        mean = description[feature]['mean']\n        sd = description[feature]['std']\n        \n        tests = [shapiro_wilk(series),\\\n                 k_squared(series),\\\n                 kolmogorov_smirnov(series, mean, sd)]\n        \n        tres = test_result(tests)\n        if tres == H0:\n            normal_features.append(feature)\n            \n        result.append(tres)\n        \n    summary = dict(Counter(result))\n    \n    if normal_features:\n        print(f\"Gaussian: {', '.join(normal_features)}\")\n        \n    return pd.DataFrame.from_dict(summary, orient='index', columns=['features'])\n\ndef drop_and_rebuild_class_dfs(data, to_drop, index=False):\n    if index:\n        new_data = data.drop(index=to_drop)\n    else:\n        new_data = data.drop(columns=to_drop)\n    legit = new_data[new_data.legitimate == 1].drop(['legitimate'], axis=1)\n    mal = new_data[new_data.legitimate == 0].drop(['legitimate'], axis=1)\n    shape(df)\n    return new_data, legit, mal","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:17.892548Z","iopub.execute_input":"2021-08-01T23:09:17.892923Z","iopub.status.idle":"2021-08-01T23:09:17.908932Z","shell.execute_reply.started":"2021-08-01T23:09:17.892891Z","shell.execute_reply":"2021-08-01T23:09:17.907805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if legitimate data has normally distributed features\nlegit_df = df[df.legitimate == 1].drop(['legitimate'], axis=1)\nshow(is_normal(legit_df)) ","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:18.469535Z","iopub.execute_input":"2021-08-01T23:09:18.469925Z","iopub.status.idle":"2021-08-01T23:09:19.211836Z","shell.execute_reply.started":"2021-08-01T23:09:18.469891Z","shell.execute_reply":"2021-08-01T23:09:19.211182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if malware data has normally distributed features\nmal_df = df[df.legitimate == 0].drop(['legitimate'], axis=1)\nshow(is_normal(mal_df)) ","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:19.213134Z","iopub.execute_input":"2021-08-01T23:09:19.21355Z","iopub.status.idle":"2021-08-01T23:09:20.518316Z","shell.execute_reply.started":"2021-08-01T23:09:19.213509Z","shell.execute_reply":"2021-08-01T23:09:20.517364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LoaderFlags and NumberOfRvaAndSizes presented distinct distributions in Legitimate and Malware data.\n# Let's take a closer look at these features.\nselected_features = ['LoaderFlags', 'NumberOfRvaAndSizes']\nshow(pd.concat(\\\n                [round(legit_df[selected_features].describe(),2),\\\n                 round(mal_df[selected_features].describe(),2)],\\\n               axis=1, keys=['Legitimate Statistics', 'Malware Statistics']))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:20.520796Z","iopub.execute_input":"2021-08-01T23:09:20.52124Z","iopub.status.idle":"2021-08-01T23:09:20.562182Z","shell.execute_reply.started":"2021-08-01T23:09:20.521195Z","shell.execute_reply":"2021-08-01T23:09:20.561174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The observed difference seems to be caused by outliers in Malware data.\n# Lets plot the distributions.\nlegit_df[selected_features].boxplot(figsize=(10,5))\nplt.tight_layout()\nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:20.563718Z","iopub.execute_input":"2021-08-01T23:09:20.564062Z","iopub.status.idle":"2021-08-01T23:09:20.852668Z","shell.execute_reply.started":"2021-08-01T23:09:20.564029Z","shell.execute_reply":"2021-08-01T23:09:20.851671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mal_df[selected_features].boxplot(figsize=(10,5))\nplt.tight_layout()\nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:20.85415Z","iopub.execute_input":"2021-08-01T23:09:20.854566Z","iopub.status.idle":"2021-08-01T23:09:21.392616Z","shell.execute_reply.started":"2021-08-01T23:09:20.854524Z","shell.execute_reply":"2021-08-01T23:09:21.391185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since, with the removal of outliers, these features will have zero standard deviation, \n# they will not add useful information to our model. We can then safely remove them.\ndf, legit_df, mal_df = drop_and_rebuild_class_dfs(df, selected_features)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:21.394502Z","iopub.execute_input":"2021-08-01T23:09:21.395211Z","iopub.status.idle":"2021-08-01T23:09:21.531917Z","shell.execute_reply.started":"2021-08-01T23:09:21.395156Z","shell.execute_reply":"2021-08-01T23:09:21.530436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SMALL_SIZE = 8\nMEDIUM_SIZE = 10\nBIGGER_SIZE = 12\nplt.rc('font', size=SMALL_SIZE)         \nplt.rc('axes', titlesize=SMALL_SIZE)    \nplt.rc('axes', labelsize=SMALL_SIZE)   \nplt.rc('xtick', labelsize=SMALL_SIZE)   \nplt.rc('ytick', labelsize=SMALL_SIZE) ","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:21.533608Z","iopub.execute_input":"2021-08-01T23:09:21.533955Z","iopub.status.idle":"2021-08-01T23:09:21.540786Z","shell.execute_reply.started":"2021-08-01T23:09:21.533922Z","shell.execute_reply":"2021-08-01T23:09:21.539126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check if we have more constants\nlegit_df.hist(figsize=(15,10), alpha=0.5)\nplt.tight_layout()\nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:21.543459Z","iopub.execute_input":"2021-08-01T23:09:21.543788Z","iopub.status.idle":"2021-08-01T23:09:30.795271Z","shell.execute_reply.started":"2021-08-01T23:09:21.543759Z","shell.execute_reply":"2021-08-01T23:09:30.793985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apparently there are other constants, let's check.\ndef check_constants(data):\n    description = data.describe()\n    cols = data.columns\n    result = set()\n    for col in cols:\n        if description[col]['75%'] == description[col]['min']:\n            result.add(col)\n    return result\n\ndef compare_dfs(data1, data2, name1='legit', name2='malware'):\n    data1_const_features = check_constants(data1)\n    data2_const_features = check_constants(data2)\n    union = list(data1_const_features.union(data2_const_features))\n    show(pd.DataFrame.from_dict(\\\n                                {name1:[len(data1_const_features)],\\\n                                name2:[len(data2_const_features)],\\\n                                'Union': [len(union)]},\\\n                               orient='index', columns=['constant_features']))\n    \n    return data1_const_features, data2_const_features, union","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:30.797083Z","iopub.execute_input":"2021-08-01T23:09:30.797385Z","iopub.status.idle":"2021-08-01T23:09:30.805358Z","shell.execute_reply.started":"2021-08-01T23:09:30.797357Z","shell.execute_reply":"2021-08-01T23:09:30.804494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legit_const, mal_const, constants = compare_dfs(legit_df, mal_df)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:30.806691Z","iopub.execute_input":"2021-08-01T23:09:30.807265Z","iopub.status.idle":"2021-08-01T23:09:31.291371Z","shell.execute_reply.started":"2021-08-01T23:09:30.807216Z","shell.execute_reply":"2021-08-01T23:09:31.290141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets take a deeper look at these constant features\nshow(pd.concat(\\\n                [round(legit_df[constants].describe(),2),\\\n                 round(mal_df[constants].describe(),2)],\\\n               axis=1, keys=['Legitimate Statistics', 'Malware Statistics']).T)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:31.292932Z","iopub.execute_input":"2021-08-01T23:09:31.293256Z","iopub.status.idle":"2021-08-01T23:09:31.382264Z","shell.execute_reply.started":"2021-08-01T23:09:31.293224Z","shell.execute_reply":"2021-08-01T23:09:31.381496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since these constants do not add information and can bias the model, we chose to remove them.\ndf.drop(columns=constants, inplace=True)\nlegit_df = df[df.legitimate == 1].drop(['legitimate'], axis=1)\nmal_df = df[df.legitimate == 0].drop(['legitimate'], axis=1)\nshape(df)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:31.383459Z","iopub.execute_input":"2021-08-01T23:09:31.38389Z","iopub.status.idle":"2021-08-01T23:09:31.467452Z","shell.execute_reply.started":"2021-08-01T23:09:31.383835Z","shell.execute_reply":"2021-08-01T23:09:31.466335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding outliers","metadata":{"editable":false}},{"cell_type":"code","source":"# Auxiliary functions\ndef iqr_score(data: pd.DataFrame):\n    description = data.describe()\n    iqr_values = defaultdict(lambda: defaultdict(np.float64))\n    \n    for feature in description.columns:\n        q1 = description[feature]['25%']\n        q3 = description[feature]['75%']\n        iqr = q3 - q1\n        factor = 1.5 * iqr\n        iqr_values[feature]['inf'] = q1 - factor\n        iqr_values[feature]['sup'] = q3 + factor\n    \n    return iqr_values\n\ndef find_outliers(data: pd.DataFrame):\n    iqr_score_limits = iqr_score(data)\n    total_instances = data.shape[0]\n    result = []\n    outliers_index = defaultdict(list)\n    \n    for feature in data.columns:\n        inf = iqr_score_limits[feature]['inf']\n        sup = iqr_score_limits[feature]['sup']\n        outliers = data[(data[feature] < inf)|(data[feature] > sup)].index\n        proportion = (len(outliers)/total_instances)\n        result.append(proportion)\n        for ix in outliers:\n            outliers_index[ix].append(feature)\n        \n    return np.array(result), instance_outlier_proportion(data,outliers_index)\n\ndef instance_outlier_proportion(data, outliers_index):\n    aux = data.copy()\n    aux['outlier_proportion'] = 0.0\n    features = data.columns\n    outlier_features_by_index = defaultdict(list)\n    for ix in outliers_index:\n        prop = len(outliers_index[ix])/len(features)\n        aux.loc[ix, 'outlier_proportion'] = prop\n    \n    return aux\n\ndef select_by_outlier_treshold(data, treshold, get_index=False, get_examples=False, simplify=False):\n    if not 'outlier_proportion' in data.columns:\n        return\n    selection = data[data.outlier_proportion >= treshold]\n    if get_examples:\n        return selection.sort_values('outlier_proportion', ascending=False)\n    if get_index:\n        return selection.index.tolist()\n    \n    abs_val = selection.shape[0]\n    prop = round(abs_val/data.shape[0], 4)\n    \n    if not simplify:\n        show(data.outlier_proportion.describe().to_frame())\n    print(f'{abs_val} ({prop}%) examples contain at least {treshold*100}% of feature outliers\\n')\n\ndef outliers_summary(outliers: np.array, instances: int):\n    total_points = int(outliers.sum() * instances)\n    total_proportion = outliers.mean() * 100\n    max_prop = outliers.max() * 100\n    min_prop = outliers.min() * 100\n    median_prop = np.median(outliers) * 100\n    \n\n    display(HTML(pd.DataFrame.from_dict({'Outliers': total_points,\n    'Outlier Proportion': f\"{round(total_proportion, 2)}%\",\n    'Min Outlier Proportion': f\"{round(min_prop,2)}%\",\n    'Median': f\"{round(median_prop,2)}%\",\n    'Max Outlier Proportion': f\"{round(max_prop,2)}%\"}, orient='index', columns=['']).to_html()))\n\ndef outlier_stats(data, name='', rate=0.5, simplify=False):\n    out_result, out_rate = find_outliers(data)\n    if not simplify:\n        print(f'{name} data outliers overview')\n        outliers_summary(out_result, data.shape[0])\n    \n    print(f'{name} examples outlier stats')\n    select_by_outlier_treshold(out_rate, rate, get_index=False, get_examples=False, simplify=simplify)\n\ndef get_outlier_indexes(data, rate=0.5):\n    _, out_rate = find_outliers(data)\n    return select_by_outlier_treshold(out_rate, rate, get_index=True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:31.46926Z","iopub.execute_input":"2021-08-01T23:09:31.469612Z","iopub.status.idle":"2021-08-01T23:09:31.491353Z","shell.execute_reply.started":"2021-08-01T23:09:31.469577Z","shell.execute_reply":"2021-08-01T23:09:31.49018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets try to identify the outliers using the Interquartile Distance (IQR) metric.\noutlier_stats(legit_df, name='Legit')\noutlier_stats(mal_df, name='Malware')","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:09:31.494002Z","iopub.execute_input":"2021-08-01T23:09:31.494348Z","iopub.status.idle":"2021-08-01T23:10:15.729888Z","shell.execute_reply.started":"2021-08-01T23:09:31.494311Z","shell.execute_reply":"2021-08-01T23:10:15.728531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The number of lines containing more than 50% of outliers is small for both classes. \n# Removing them will help us standardize the data and balance the classes.\noutlier_indexes = get_outlier_indexes(legit_df, 0.5) + get_outlier_indexes(mal_df, 0.5)\ndf, legit_df, mal_df = drop_and_rebuild_class_dfs(df, outlier_indexes, index=True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:10:15.732329Z","iopub.execute_input":"2021-08-01T23:10:15.732773Z","iopub.status.idle":"2021-08-01T23:11:00.235156Z","shell.execute_reply.started":"2021-08-01T23:10:15.732718Z","shell.execute_reply":"2021-08-01T23:11:00.234089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's verify the results\noutlier_stats(legit_df, name='Legit', simplify=True)\noutlier_stats(mal_df, name='Malware', simplify=True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:11:00.236707Z","iopub.execute_input":"2021-08-01T23:11:00.237378Z","iopub.status.idle":"2021-08-01T23:11:44.320235Z","shell.execute_reply.started":"2021-08-01T23:11:00.237329Z","shell.execute_reply":"2021-08-01T23:11:44.319184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model evaluation","metadata":{"editable":false}},{"cell_type":"markdown","source":"## Data Scaling","metadata":{"editable":false}},{"cell_type":"code","source":"# Globals\nscale_results_dict = defaultdict(lambda: defaultdict(np.float64))\nscale_frequency = defaultdict(lambda:defaultdict(lambda: Counter()))\nreduce_dim_results = {'classifier':[], 'k':[], 'accuracy': []}","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:11:44.321789Z","iopub.execute_input":"2021-08-01T23:11:44.322217Z","iopub.status.idle":"2021-08-01T23:11:44.327723Z","shell.execute_reply.started":"2021-08-01T23:11:44.322174Z","shell.execute_reply":"2021-08-01T23:11:44.326863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constants\nlabel = 'legitimate'\ny = df[label]\nX = df.drop(columns=label)\n\nK_FOLD = KFold(n_splits=5, shuffle=True, random_state=1)\nCLASSIFIERS = [(NaiveBayes(), ''),\\\n              (SVM(), '(kernel=rbf)'),\\\n              (AdaBoost(), '(n_estimators=50)'),\\\n              (ExtraTreesClassifier(), '(n_estimators=100)'),\\\n              (GradientBoosting(), '(n_estimators=100, learning_rate=0.1)'),\\\n              (RandomForest(), '(n_estimators=100)')]\n\nMETRICS = ['accuracy','precision', 'recall', 'f1', 'roc_curve', 'roc_auc']","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:11:44.329719Z","iopub.execute_input":"2021-08-01T23:11:44.330308Z","iopub.status.idle":"2021-08-01T23:11:44.365333Z","shell.execute_reply.started":"2021-08-01T23:11:44.330257Z","shell.execute_reply":"2021-08-01T23:11:44.363789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_validation(X_train, y_train, classifier, cv=K_FOLD, _metrics=METRICS):\n\n    return cross_validate(classifier,\n                            X_train,\n                            y_train,\n                            scoring=_metrics,\n                            return_train_score=True,\n                            cv=cv,\n                            n_jobs=-1)\n\ndef plot_scaler_comparison(classifier: str, scaler_df: pd.DataFrame, params=''):\n    scaler_df = scaler_df.sort_values(by=list(scaler_df.index), axis=1)\n    scaler_df.plot.bar(figsize=(7,5),title=f\"{classifier} {params}\", rot=0, fontsize=12)\n    plt.legend(loc='upper left', bbox_to_anchor=(1,1), fancybox=True, framealpha=0.2)\n    plt.ylabel('Valor')\n    plt.grid(b=True, which='major', color='#666666', linestyle='-', axis='y')\n    plt.minorticks_on()\n    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.6, axis='y')\n    plt.show();\n\ndef feed_results_dict(val: np.float64, acc_type: str, method: str):\n    last = scale_results_dict[method][acc_type]\n    scale_results_dict[method][acc_type] = val if not last else (val + last)/2\n    \n# Test models accuracy on each scaling method\ndef test_scalers(X_train, y_train, classifier, cv=K_FOLD, _metrics='accuracy', params=None, last=False):\n    method = repr(classifier).split('(')[0]\n    scalers = [None, StandardScaler(), MaxAbsScaler(), RobustScaler()]\n    test_acc = 'test_accuracy'\n    train_acc = 'train_accuracy'\n    \n    res = {train_acc:[], test_acc:[]}\n    cols =[]\n    \n    method_test_acc = scale_results_dict[method]['test_accuracy']\n    method_train_acc = scale_results_dict[method]['train_accuracy']\n    \n    for scaler in scalers:\n        if not scaler:\n            cross_val = cross_validation(X_train, y_train, classifier, cv.split(X_train), _metrics)\n        else:\n            pipeline = Pipeline(steps=[('scaler', scaler), \n                                       ('method', classifier)])\n\n            cross_val = cross_validate(pipeline,\n                                        X_train,\n                                        y_train,\n                                        scoring=_metrics,\n                                        return_train_score=True,\n                                        cv=cv,\n                                        n_jobs=-1)\n            \n        cols.append(repr(scaler).split('(')[0])\n        \n        for k in res:\n            res[k].append(cross_val[k.replace('accuracy', 'score')].mean())\n            \n    # Create results DataFrame\n    res_df = pd.DataFrame.from_dict(res, orient='index', columns=cols)\n    \n    best_train = res_df.loc[train_acc].sort_values()\n    feed_results_dict(best_train[-1], train_acc, method)\n    best_train = best_train[best_train==best_train[-1]].index.tolist()\n    scale_frequency[method][train_acc].update(best_train)\n    best_train = ', '.join(best_train)\n    \n    best_test = res_df.loc[test_acc].sort_values()\n    feed_results_dict(best_test[-1], test_acc, method)\n    best_test = best_test[best_test==best_test[-1]].index.tolist()\n    scale_frequency[method][test_acc].update(best_test)\n    best_test = ', '.join(best_test)\n    \n    # Presents the results\n    plot_scaler_comparison(method, res_df, params)\n    display(HTML(f\"<center>{res_df.to_html()}\"))\n    display(Markdown(f\"<center><p>Method: <strong>{method}</strong><br />Best on training: <strong>{best_train}</strong><br />Best on testing: <strong>{best_test}</strong>\"))\n    display(Markdown('---'))\n    \n    if last:\n        display(Markdown(\"<strong>Best results:</strong><br />\"))\n        show(pd.DataFrame.from_dict(scale_results_dict))\n        show(pd.DataFrame.from_dict(scale_frequency))\n\n# Evaluate different Scalers\ndef execute_test_scalers():\n    \n    for ix, classifier in enumerate(CLASSIFIERS):\n        method = classifier[0]\n        params = classifier[1]\n        \n        if ix < (len(CLASSIFIERS) - 1):\n            test_scalers(X, y, method, params=params)\n        else:\n            test_scalers(X, y, method, params=params, last=True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:11:44.367491Z","iopub.execute_input":"2021-08-01T23:11:44.368147Z","iopub.status.idle":"2021-08-01T23:11:44.395532Z","shell.execute_reply.started":"2021-08-01T23:11:44.3681Z","shell.execute_reply":"2021-08-01T23:11:44.394009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"execute_test_scalers()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-01T23:11:44.397878Z","iopub.execute_input":"2021-08-01T23:11:44.3984Z","iopub.status.idle":"2021-08-02T01:40:04.899881Z","shell.execute_reply.started":"2021-08-01T23:11:44.398318Z","shell.execute_reply":"2021-08-02T01:40:04.898198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dimensionality reduction","metadata":{"editable":false}},{"cell_type":"markdown","source":"### Using SelectKBest","metadata":{"editable":false}},{"cell_type":"code","source":"def execute_test_dimensionality_reduction():\n    \n    # Best Scaling results\n    best_scaling =[(NaiveBayes(), None),\n                   (SVM(), StandardScaler()),\n                  (AdaBoost(), StandardScaler()),\n                  (ExtraTreesClassifier(), None),\n                  (GradientBoosting(), None),\n                  (RandomForest(), MaxAbsScaler())]\n    \n    for classifier in best_scaling:\n        method = classifier[0]\n        scaler = classifier[1]\n        test_dimentionality_reduction(X, y, method, scaler)\n\n# Test the effect of dimensionality reduction on accuracy\ndef test_dimentionality_reduction(X_train, y_train, classifier, scaler):\n    location = 'cachedir'\n    memory = Memory(location=location, verbose=0)\n    \n    # Numer of features to test \n    n_features_to_test = np.arange(1, len(X_train.columns)+1)\n    \n    if scaler:\n        pipe = Pipeline(memory=memory,\n                        steps=[\n                        ('scaler', scaler), # Scale\n                        ('reduce_dim', SelectKBest()), # Reduce dimensionality\n                        ('classifier', classifier) # Apply classifier\n                        ])\n    else:\n        pipe = Pipeline(memory=memory,\n                        steps=[\n                        ('reduce_dim', SelectKBest()), # Reduce dimensionality\n                        ('classifier', classifier) # Apply classifier\n                        ])\n    \n    params = [\n        {'reduce_dim__k': n_features_to_test}\n        ]\n    \n    # Apply GridSearchCV\n    grid = GridSearchCV(pipe, params, cv=K_FOLD, refit='accuracy', scoring='accuracy', n_jobs=-1).fit(X, y)\n    best = grid.best_params_\n    \n    # Record the best results \n    class_name = repr(classifier).split('(')[0]\n    best_k = best['reduce_dim__k']\n    red_dim_method = f\"SelectKBest(k={best_k})\"\n    best_score = grid.best_score_\n    \n    \n    reduce_dim_results['classifier'].append(class_name)\n    reduce_dim_results['k'].append(best_k)\n    reduce_dim_results['accuracy'].append(best_score)\n    \n    param =  'param_reduce_dim__k'\n    grid_df = pd.DataFrame.from_dict(grid.cv_results_)\n    grid_df = grid_df[[param, 'mean_test_score' ]][grid_df[param].notna()].set_index(param)\n    \n    # Plot results\n    ax = grid_df.plot(figsize=(10,5))\n    ax.set_title(f\"{class_name}, {red_dim_method} (best score: {round(best_score, 4)})\", fontsize=16)\n    ax.set_ylabel('accuracy', fontsize=14)\n    ax.set_xlabel('features', fontsize=14)\n    ax.axvline(grid_df.idxmax().values[0],color='r', linestyle='--', label='best_accuracy')\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.legend(loc='lower center', framealpha =0.4, fontsize=12)\n    plt.show()\n    display(Markdown('---'))\n    \n    # Deleta a pasta temporária\n    memory.clear(warn=False)\n    rmtree(location)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-02T01:40:04.903261Z","iopub.execute_input":"2021-08-02T01:40:04.903894Z","iopub.status.idle":"2021-08-02T01:40:04.923398Z","shell.execute_reply.started":"2021-08-02T01:40:04.903805Z","shell.execute_reply":"2021-08-02T01:40:04.922524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"execute_test_dimensionality_reduction()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-02T01:40:04.926281Z","iopub.execute_input":"2021-08-02T01:40:04.926648Z","iopub.status.idle":"2021-08-02T05:08:39.423591Z","shell.execute_reply.started":"2021-08-02T01:40:04.926615Z","shell.execute_reply":"2021-08-02T05:08:39.421033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame.from_dict(reduce_dim_results).set_index('classifier')\nresults.loc[:,'accuracy'] = round(100*results.loc[:,'accuracy'],2)\nshow(results)\nresults.plot(kind='bar', y='accuracy', rot=35,figsize=(10,7))\nplt.legend(fontsize=10)\nplt.ylabel('%')","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-02T05:08:39.431086Z","iopub.execute_input":"2021-08-02T05:08:39.432107Z","iopub.status.idle":"2021-08-02T05:08:39.719512Z","shell.execute_reply.started":"2021-08-02T05:08:39.432025Z","shell.execute_reply":"2021-08-02T05:08:39.718256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using SelectFromModel","metadata":{"editable":false}},{"cell_type":"code","source":"_y = df['legitimate'].values\n_X = df.drop(['legitimate'], axis=1).values\nnew_res = defaultdict(list)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-02T05:08:39.721542Z","iopub.execute_input":"2021-08-02T05:08:39.722107Z","iopub.status.idle":"2021-08-02T05:08:40.006298Z","shell.execute_reply.started":"2021-08-02T05:08:39.722058Z","shell.execute_reply":"2021-08-02T05:08:40.004815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def selec_from_model_reduce_dim(classifier, x=_X, y=_y):\n    res = []\n    name = repr(classifier).split('(')[0]\n    select_features = classifier.fit(x, y)\n    clf = SelectFromModel(select_features, prefit=True)\n    X_transformed = clf.transform(x)\n    dim = X_transformed.shape[1]\n    for train_ix, test_ix in K_FOLD.split(X_transformed):\n        X_train, X_test = X_transformed[train_ix], X_transformed[test_ix]\n        y_train, y_test = y[train_ix], y[test_ix]\n        classifier.fit(X_train, y_train)\n        res.append(classifier.score(X_test, y_test))\n        pred = classifier.predict(X_test)\n        cm = confusion_matrix(y_test, pred)\n    new_res['classifier'].append(name)\n    new_res['k'].append(dim)\n    new_res['accuracy'].append(round(100*sum(res)/len(res),2))\n    new_res['false positives'].append(round(100*cm[0][1] / float(sum(cm[0])), 2))\n    new_res['false negatives'].append(round(100*cm[1][0] / float(sum(cm[1])), 2))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-02T05:08:40.008983Z","iopub.execute_input":"2021-08-02T05:08:40.009395Z","iopub.status.idle":"2021-08-02T05:08:40.022341Z","shell.execute_reply.started":"2021-08-02T05:08:40.009352Z","shell.execute_reply":"2021-08-02T05:08:40.020795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for classifier, params in CLASSIFIERS[-3:]:\n    selec_from_model_reduce_dim(classifier)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-02T05:08:40.024061Z","iopub.execute_input":"2021-08-02T05:08:40.024625Z","iopub.status.idle":"2021-08-02T05:12:05.55665Z","shell.execute_reply.started":"2021-08-02T05:08:40.024571Z","shell.execute_reply":"2021-08-02T05:12:05.555512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_results = pd.DataFrame.from_dict(new_res).set_index('classifier')\nshow(new_results)\nnew_results.plot(kind='bar', y='accuracy', rot=35,figsize=(10,7))\nplt.legend(fontsize=10)\nplt.ylabel('%')","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-08-02T05:12:05.558305Z","iopub.execute_input":"2021-08-02T05:12:05.558646Z","iopub.status.idle":"2021-08-02T05:12:05.779691Z","shell.execute_reply.started":"2021-08-02T05:12:05.558611Z","shell.execute_reply":"2021-08-02T05:12:05.778637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{"editable":false}},{"cell_type":"markdown","source":"While DataScaling proved inadequate for our data, Dimensionality Reduction was very effective. Although SelectKBest led to better accuracy results than SelectFromModel, the latter proved to be more efficient in reducing dimensionality without impairing accuracy. An interesting result that is worth highlighting is that, with SelectFromModel, the GradientBoostingClassifier reached an accuracy of 98% using only 3 features.","metadata":{"editable":false}}]}