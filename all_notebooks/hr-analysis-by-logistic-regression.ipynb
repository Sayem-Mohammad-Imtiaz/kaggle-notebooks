{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Packages / libraries\nimport matplotlib\nmatplotlib.rcParams['backend'] = 'module://ipykernel.pylab.backend_inline'\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report, log_loss\nfrom math import sqrt\n#%matplotlib inline\n# To install sklearn type \"pip install numpy scipy scikit-learn\" to the anaconda termi\n# To change scientific numbers to float\nnp.set_printoptions(formatter={'float_kind':'{:f}'.format})\n# Increases the size of sns plots\nsns.set(rc={'figure.figsize':(12,10)})\n# import sys\n# !conda list Check the packages installed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/hr-analytics/HR_comma_sep.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Explotary Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Department\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"salary\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **Average  Numbers for column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('left').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***0 means they retained, 1 means they left***\n\nfrom above data we can point out that\n1. If the **satisfication level** is *low* ,employee left.\n2. If the **average monthly hours** is High, they left.\n3. **Promotion_last_5years** : if employee doesn't get any promotion they left\n"},{"metadata":{},"cell_type":"markdown","source":"## **Impact of salary**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.salary,df.left).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the chart we can see that, most of the employee with high salary are retaining.**"},{"metadata":{},"cell_type":"markdown","source":"**Impact of Department**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.Department,df.left).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above chart we are not sure how much impact on department"},{"metadata":{},"cell_type":"markdown","source":"# Making categorical variables into numeric representation"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data=pd.get_dummies(df, columns = ['salary','Department'])\nnew_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\nprint(new_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection:\n\n- Steps of Running Feature Importance\n- Split the data into X & y\n- Run a Tree-based estimators (i.e. decision trees & random forests)\n- Run Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into X & y\n\nX = new_data.drop([\"left\"],axis=\"columns\")\nprint(X.shape)\n\ny=new_data.left\nprint(y.shape)\n\n# Making sure y as integer\ny = y.astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Run a Tree-based estimators**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(random_state=15, criterion = 'entropy', max_depth = 10)\ndt.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running Feature Importance\nfi_col = []\nfi = []\n\nfor i,column in enumerate(new_data.drop([\"left\"],axis=\"columns\")):\n    print('The feature importance for {} is : {}'.format(column, dt.feature_importances_[i]))\n    \n    fi_col.append(column)\n    fi.append(dt.feature_importances_[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes: We want to import them as a dataframe and select the highest importance feature**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a Dataframe\n# zip two list\n\nfi_df = zip(fi_col, fi)\nfi_df = pd.DataFrame(fi_df, columns = ['Feature','Feature Importance'])\nfi_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ordering the data\nfi_df = fi_df.sort_values('Feature Importance', ascending = False).reset_index()\n\nfi_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating columns to keep\ncolumns_to_keep = fi_df['Feature'][0:13]\n\ncolumns_to_keep","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Hold out Validation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(new_data.shape)\nprint(new_data[columns_to_keep].shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = new_data[columns_to_keep].values\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = new_data.left\ny = y.astype(int)\ny\n\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hold-out validation\n\n# first one\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size=0.2, random_state=15)\n\n# Second one(From Training)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size = 0.9, test_size=0.1, random_state=15)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(X_valid.shape)\n\nprint(y_train.shape)\nprint(y_test.shape)\nprint(y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Investigating the distribution  of all y so that we can know is it balanced data or not\n\nax = sns.countplot(x =y_train, palette = \"Set3\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x =y_test, palette = \"Set3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x =y_valid, palette = \"Set3\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It doesn't look a balanced data"},{"metadata":{},"cell_type":"markdown","source":"# **Running Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training my model\n\nlog_reg = LogisticRegression(random_state=10, solver = 'lbfgs')\n\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Methods we can use in Logistic\n\n# predict - Predict class labels for samples in X\nlog_reg.predict(X_train)\ny_pred = log_reg.predict(X_train)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict_proba - Probability estimates\npred_proba = log_reg.predict_proba(X_train)\npred_proba","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes:**\n\nWe calculate probability bcz we want to label class to be 0 or 1\n\nProbability>0.5 = 1\nProbability<0.5 = 0 First row, 0.63>0.5 so class is 0. check y_pred, it's 0"},{"metadata":{},"cell_type":"markdown","source":"**Now we have to calculate coeifficient**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# coef_ - Coefficient of the features in the decision function\nlog_reg.coef_\n\n# score- Returns the mean accuracy on the given test data and labels - below","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Evaluating Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy on Train\nprint(\"The Training Accuracy is: \", log_reg.score(X_train, y_train))\n\n# Accuracy on Test\nprint(\"The Testing Accuracy is: \", log_reg.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification Report\nprint(classification_report(y_train, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix function\n\ndef plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n    \"\"\"Plots a confusion matrix.\"\"\"\n    if classes is not None:\n        sns.heatmap(cm, cmap=\"YlGnBu\", xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True, annot_kws={'size':50})\n    else:\n        sns.heatmap(cm, vmin=0., vmax=1.)\n    plt.title(title)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing cm\n\ncm = confusion_matrix(y_train, y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm.sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_norm = cm / cm.sum(axis=1).reshape(-1,1)\ncm_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What are the classes\nlog_reg.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(cm_norm, classes = log_reg.classes_, title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We have predicted actual 0->93%, where 7.3% 0 we predicted as 1 \n\n- 0.68% predicted as 0 where actual is 1 and 32% is predicted correctly as 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating False Positives (FP), False Negatives (FN), True Positives (TP) & True Negatives (TN)\n\nFP = cm.sum(axis=0) - np.diag(cm)\nFN = cm.sum(axis=1) - np.diag(cm)\nTP = np.diag(cm)\nTN = cm.sum() - (FP + FN + TP)\n\n# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP / (TP + FN)\nprint(\"The True Positive Rate is:\", TPR)\n\n# Precision or positive predictive value\nPPV = TP / (TP + FP)\nprint(\"The Precision is:\", PPV)\n\n# False positive rate or False alarm rate\nFPR = FP / (FP + TN)\nprint(\"The False positive rate is:\", FPR)\n\n\n# False negative rate or Miss Rate\nFNR = FN / (FN + TP)\nprint(\"The False Negative Rate is: \", FNR)\n\n\n\n##Total averages :\nprint(\"\")\nprint(\"The average TPR is:\", TPR.sum()/2)\nprint(\"The average Precision is:\", PPV.sum()/2)\nprint(\"The average False positive rate is:\", FPR.sum()/2)\nprint(\"The average False Negative Rate is:\", FNR.sum()/2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**False Positive rate is quite high**"},{"metadata":{},"cell_type":"markdown","source":"# Logarithmic loss - or Log Loss - or cross-entropy loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running Log loss on training\nprint(\"The Log Loss on Training is: \", log_loss(y_train, pred_proba))\n\n# Running Log loss on testing\npred_proba_test = log_reg.predict_proba(X_test)\nprint(\"The Log Loss on Testing Dataset is: \", log_loss(y_test, pred_proba_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For training & testing both Log Loss same**"},{"metadata":{},"cell_type":"markdown","source":"# Hyper Parameter Tuning"},{"metadata":{},"cell_type":"markdown","source":"- We will loop over parameter C (Inverse of regularization strength).\n- Inverse of regularization strength helps to avoid overfitting - it penalizes large values of your parameters\n- It also helps to find Global Minimum by moving to better \"solutions\" from local minimum to global minimum\n- The values of C to search should be n-equally-spaced values in log space ranging from 1e-5 to 1e5"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.geomspace(1e-5, 1e5, num=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a range for C values\nnp.geomspace(1e-5, 1e5, num=20)\n\n# ploting it\nplt.plot(np.geomspace(1e-5, 1e5, num=20)) #  uniformly distributed in log space\nplt.plot(np.linspace(1e-5, 1e5, num=20)) # uniformly distributed in linear space, instead of log space","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looping over the parameters\n\nC_List = np.geomspace(1e-5, 1e5, num=20)\nCA = []\nLogarithmic_Loss = []\n\nfor c in C_List:\n    log_reg2 = LogisticRegression(random_state=10, solver = 'lbfgs', C=c)\n    log_reg2.fit(X_train, y_train)\n    score = log_reg2.score(X_test, y_test)\n    CA.append(score)\n    print(\"The CA of C parameter {} is {}:\".format(c, score))\n    pred_proba_t = log_reg2.predict_proba(X_test)\n    log_loss2 = log_loss(y_test, pred_proba_t)\n    Logarithmic_Loss.append(log_loss2)\n    print(\"The Logg Loss of C parameter {} is {}:\".format(c, log_loss2))\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We want to choose lowest logarithmic and highest classification accuracy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# putting the outcomes in a Table\n\n# reshaping\nCA2 = np.array(CA).reshape(20,)\nLogarithmic_Loss2 = np.array(Logarithmic_Loss).reshape(20,)\n\n# zip\noutcomes = zip(C_List, CA2, Logarithmic_Loss2)\n\n#df\ndf_outcomes = pd.DataFrame(outcomes, columns = [\"C_List\", 'CA2','Logarithmic_Loss2'])\n\n#print\ndf_outcomes\n\n# Ordering the data (sort_values)\ndf_outcomes.sort_values(\"Logarithmic_Loss2\", ascending = True).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Another way we can do it\n\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=3, random_state=0, shuffle=True)\n\n# Logistic Reg CV\nLog_reg3 = LogisticRegressionCV(random_state=15, Cs = C_List, solver ='lbfgs')\nLog_reg3.fit(X_train, y_train)\n\npred_proba_t = Log_reg3.predict_proba(X_test)\nlog_loss3 = log_loss(y_test, pred_proba_t)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The CA is:\", Log_reg3.score(X_test, y_test))\n\nprint(\"The Logistic Loss is: \", log_loss3)\n\nprint(\"The optimal C parameter is: \", Log_reg3.C_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Maybe we have a different metric we want to track\n\n# Looping over the parameters\n\nC_List = np.geomspace(1e-5, 1e5, num=20)\nCA = []\nLogarithmic_Loss = []\n\nfor c in C_List:\n    log_reg2 = LogisticRegression(random_state=10, solver = 'lbfgs', C=c)\n    log_reg2.fit(X_train, y_train)\n    score = log_reg2.score(X_test, y_test)\n    CA.append(score)\n    print(\"The CA of C parameter {} is {}:\".format(c, score))\n    pred_proba_t = log_reg2.predict_proba(X_test)\n    log_loss2 = log_loss(y_test, pred_proba_t)\n    Logarithmic_Loss.append(log_loss2)\n    print(\"The Logg Loss of C parameter {} is {}:\".format(c, log_loss2))\n    print(\"\")\n    \n    y_pred = log_reg2.predict(X_train)\n    cm = confusion_matrix(y_train, y_pred)\n    cm_norm = cm / cm.sum(axis=1).reshape(-1,1)\n    plot_confusion_matrix(cm_norm, classes = log_reg.classes_, title='Confusion matrix')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training a Dummy Classifier\n\nfrom sklearn.dummy import DummyClassifier\n\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X_train, y_train)\nscore = dummy_clf.score(X_test, y_test)\n\npred_proba_t = dummy_clf.predict_proba(X_test)\nlog_loss2 = log_loss(y_test, pred_proba_t)\n\nprint(\"Testing Acc:\", score)\nprint(\"Log Loss:\", log_loss2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final Model \n\nlog_reg3 = LogisticRegression(random_state=10, solver = 'lbfgs', C=784.759970)\nlog_reg3.fit(X_train, y_train)\nscore = log_reg3.score(X_valid, y_valid)\n\npred_proba_t = log_reg3.predict_proba(X_valid)\nlog_loss2 = log_loss(y_valid, pred_proba_t)\n\nprint(\"Testing Acc:\", score)\nprint(\"Log Loss:\", log_loss2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Notes: We test our data with totally unseen data ( Xvalid). & we have seen that log loss fell down**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}