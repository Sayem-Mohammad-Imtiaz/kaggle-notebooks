{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport re \nimport math\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import to_categorical, Sequence, plot_model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom keras.models import Sequential, Model\nfrom keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\nfrom keras.layers import Embedding, Dense, Dropout, LSTM, Input, BatchNormalization, concatenate\n\nfrom tensorflow import set_random_seed\nfrom numpy.random import seed\nset_random_seed(2)\nseed(40)","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/facebook-antivaccination-dataset/posts_full.csv', \n                   index_col=0).dropna(subset=['text'])\ndata = data[['text', 'anti_vax']]\ndata.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                                                text  anti_vax\n0  The latest conspiracy theory is that MMR vacci...     False\n1  The New Vaccine Surveillance Network Report on...     False\n2  Someone with  in Santa Clara County, #Californ...     False\n3  There are 33 new measles cases in Brooklyn, br...     False\n4  It took less a few minutes to debunk the lates...     False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>anti_vax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The latest conspiracy theory is that MMR vacci...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The New Vaccine Surveillance Network Report on...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Someone with  in Santa Clara County, #Californ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are 33 new measles cases in Brooklyn, br...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It took less a few minutes to debunk the lates...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"discord = pd.read_csv('../input/game-of-cones/Game of Cones - battle-for-the-cone 231969664027066368.csv', \n                      sep=';').drop('Unnamed: 4', axis=1).dropna(subset=['Content'])\ndiscord['anti_vax'] = False\ndiscord = discord[['Content', 'anti_vax']].rename({'Content': 'text'}, axis=1)\ndiscord.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                             text  anti_vax\n0                                          NO DND     False\n1                                   NO MAPLESTORY     False\n2  https://www.pathofexile.com/ascendancy/classes     False\n3                                       No gurlzz     False\n4    http://boards.4chan.org/pol/thread/103070474     False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>anti_vax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NO DND</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NO MAPLESTORY</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.pathofexile.com/ascendancy/classes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No gurlzz</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://boards.4chan.org/pol/thread/103070474</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([data, discord]).reset_index(drop=True)\ndata.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(131303, 2)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Build Tokenizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove unwanted punctuation\nFILTER_STRING = '\"$%&()*+,.!?-/:;<=>[\\\\]@#^_`{|}~\\t\\n'\nUNWANTED = {x for x in FILTER_STRING}\ndef filter_unwanted(x):\n    x = \"\".join([c if c not in UNWANTED else \" \" for c in x]).lower()\n    return x.encode(\"utf8\").decode(\"ascii\",'ignore')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = [sentence for sentence in data.text.apply(filter_unwanted)]\ndata.text.tail()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"131298                                      w open gspektjq\n131299    nice  michael  you opened the j list box and g...\n131300                                         w dailygacha\n131301                            w claim sachiko shinozaki\n131302    nice  itsthtguy  you claimed    sachiko shinoz...\nName: text, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add n-gram input sequences\nNUM_WORDS = 50_000\nMAX_SEQUENCE_LENGTH = 200\n\ntokenizer = Tokenizer(num_words=NUM_WORDS, filters=FILTER_STRING, \n                      lower=True)\ntokenizer.fit_on_texts(data.text)\nwith open('tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Training Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tokenizer.texts_to_sequences(data.text)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\nX[0][-40:], data.text.head(1)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     1,  1047,  3092,  1787,     7,    10,   262,\n           16,     7, 18223,    44,    21,    13,   503,     2,    66,\n         3627,     4,    17,  1308,     1, 19517,   885,    15,     1,\n          262,    21,    64,   259], dtype=int32),\n 0    the latest conspiracy theory is that mmr vacci...\n Name: text, dtype: object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_eval, y_train, y_eval = train_test_split(X, data.anti_vax.values, \n                                                    test_size=0.2, \n                                                    random_state=3000)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(NUM_WORDS, 10, input_length=(X.shape[1])))\nmodel.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dropout(rate=0.3))\nmodel.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center\">Final Model</h1>\n<img src=\"model.png\" width=\"200\">"},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"model-{epoch:02d}-{val_loss:.2f}.hdf5\", \n                             monitor='val_loss', verbose=0, \n                             save_best_only=True, period=1)\nstopping = EarlyStopping(monitor='val_loss', patience=2)\nhistory = model.fit(X_train, y_train, epochs=20, \n                    verbose=2, batch_size=32, validation_data=(X_eval, y_eval), \n                    callbacks=[checkpoint, stopping])","execution_count":13,"outputs":[{"output_type":"stream","text":"Train on 105042 samples, validate on 26261 samples\nEpoch 1/1\n 34720/105042 [========>.....................] - ETA: 14:05 - loss: 0.2772 - acc: 0.8932","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-b42f07db9860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(X_train, y_train, epochs=1, \n\u001b[1;32m      6\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=[checkpoint, stopping])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"## Comparing Loss per Epoch"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_epochs(results, col, **kwargs):\n    def plot_epoch_helper(hist_df, col, ax):\n        ax.plot(hist_df[col], **kwargs)\n        ax.set_title(col + ' per epoch')\n        ax.set_ylabel(col)\n        ax.set_xlabel('epoch')\n        for sp in ax.spines:\n            ax.spines[sp].set_visible(False)\n        ax.yaxis.grid(True, alpha=0.3)\n        ax.legend(labels=[n[0] for n in results])\n        ax.set_ylim(0, 1)\n    fig, ax = plt.subplots(figsize=(21, 10))\n    for name, hist in results:\n        plot_epoch_helper(hist, col, ax)\nplot_epochs([('Model', pd.DataFrame(history.history))], 'val_Main_Output_loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_epochs([('Model', pd.DataFrame(history.history))], 'val_Aux_Output_loss')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}