{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/loan-predication/train_u6lujuX_CVtuZ9i (1).csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA PREPROCESSING","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fill the missing values for numerical terms -- mean\ndf['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].mean())\ndf['Credit_History'] = df['Credit_History'].fillna(df['Credit_History'].mean())\ndf['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fill na values for categorical terms -- mode\ndf['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])\ndf['Married'] = df['Married'].fillna(df['Married'].mode()[0])\ndf['Dependents'] = df['Dependents'].fillna(df['Dependents'].mode()[0])\ndf['Self_Employed'] = df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explotatory Analysis","metadata":{}},{"cell_type":"code","source":"# categorical visualisation\nplt.figure(figsize = (9,5))\nsns.countplot(df['Gender'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df['Married'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df['Dependents'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df['Self_Employed'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df['Education'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df['Property_Area'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df['Loan_Status'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numerical visualization\nplt.figure(figsize = (12,15))\nsns.displot(df['ApplicantIncome'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#apply for transformation to the attribute\ndf['ApplicantIncomeLog'] = np.log(df['ApplicantIncome'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,15))\nsns.displot(df['ApplicantIncomeLog'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize = (16,19))\nsns.displot(df['CoapplicantIncome'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['CoapplicantIncomeLog']= np.log(df['CoapplicantIncome']*100)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,15))\nsns.displot(df['LoanAmount'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['LoanAmountLog'] = np.log(df['LoanAmount'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,15))\nsns.displot(df['LoanAmountLog'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(df['Loan_Amount_Term'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Loan_Amount_TermLog']= np.log(df['Loan_Amount_Term'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(df['Loan_Amount_TermLog'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(df['Credit_History'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# creating new attributes","metadata":{}},{"cell_type":"code","source":"#total income \ndf['Total_income'] = df['ApplicantIncome']+ df['CoapplicantIncome']\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Total_incomeLog']= np.log(df['Total_income'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation matrix","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,9))\nsns.heatmap(df.corr(), annot = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop unnecessary columns\ncols = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term', 'Total_income', 'Loan_ID', 'CoapplicantIncomeLog']\ndf = df.drop(columns = cols, axis =1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncols = ['Gender', 'Married','Education','Self_Employed','Property_Area','Loan_Status', 'Dependents']\nle = LabelEncoder()\nfor col in cols:\n    df[col]= le.fit_transform(df[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"code","source":"x = df.drop(columns = ['Loan_Status'], axis = 1)\ny = df['Loan_Status']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.25, random_state=51)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n# define classify function\ndef classify(model,x,y):\n    x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.25, random_state=51)\n    model.fit(x_train,y_train)\n    print('Accuracy is ', model.score(x_test,y_test)*100)\n    #cross_validation basically used for better validation of model\n    score = cross_val_score(model,x,y,cv=5)\n    print('cross_validation ', np.mean(score)*100)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nclassify(model,x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nclassify(model,x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nmodel = RandomForestClassifier()\nclassify(model,x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ExtraTreesClassifier()\nclassify(model,x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyper parameter tuning","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=50,min_samples_split=18, max_depth=7, max_features=1)\nclassify(model,x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"model =RandomForestClassifier()\nmodel.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred = model.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm,annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}