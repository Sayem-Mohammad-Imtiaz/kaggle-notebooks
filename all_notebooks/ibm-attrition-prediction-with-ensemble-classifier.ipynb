{"cells":[{"metadata":{"_uuid":"03c6fd48fa6c94495f48bacd8316557de322d706"},"cell_type":"markdown","source":"# IBM Attrition Prediction with a Ensemble Classifier"},{"metadata":{"_uuid":"01318d65632578386b066d99b865dd227a0e455d"},"cell_type":"markdown","source":"## Summary\n\nTo increase retention rates, HR might first identify the employees who might leave the company. This notebook built an ensemble model with the [IBM attrition data][1]* to predict high-risk employees and generated actionable insights. \n\nWhen I was working on this project, I learned a lot from [Anisotropic][2], [Alja≈æ][3], and [Vincent Lugat][4]'s work. \n\nHere are the steps I've taken:\n\n1. [**Load libraries and data**](#section-one)\n2. [**Exploratory data analysis**](#section-two)\n    * Examine Feature distribution and the distribution against employee attrition\n3. [**Data engineering**](#section-three)\n    * Create new features and remove collinear ones\n4. [**Build Modesl**](#section-four)\n    * Use F1 score as the metric to benchmark models\n    * Interpret Feature Importance\n    \nFurture steps:\n* Examine feature interactions and their impact on predictions\n\n*Please note that this is a fictional dataset\n\n[1]:https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset\n[2]:https://www.kaggle.com/arthurtok/employee-attrition-via-ensemble-tree-based-methods\n[3]:https://www.kaggle.com/aljaz91/ibm-s-attrition-tackling-class-imbalance-with-gbm\n[4]:https://www.kaggle.com/vincentlugat/ibm-attrition-analysis-and-prediction"},{"metadata":{"_uuid":"2630b4ceac3ba8a8c49d080148cb911a6f72e84f"},"cell_type":"markdown","source":"## <a class=\"anchor\" id=\"section_one\">1. Load libraries and dataset  </a>\n#### 1.1 Load libraries"},{"metadata":{"trusted":true,"_uuid":"7d0eee773fdc8a6bdf27c185741d9bd02c132308"},"cell_type":"code","source":"%matplotlib inline\n\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom itertools import chain\n\nfrom scipy.stats import chi2_contingency, zscore\nfrom sklearn.decomposition import PCA \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import (train_test_split, \n                                     GridSearchCV)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import (RandomForestClassifier, \n                              GradientBoostingClassifier)\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.ensemble import BalancedRandomForestClassifier\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings('ignore')\nsns.set_style(\"whitegrid\")\npd.set_option('precision', 3) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc1d96b6f95fa36bb68541d63f2b4a2a782ca914"},"cell_type":"markdown","source":"#### 1.2 Load Data"},{"metadata":{"trusted":true,"_uuid":"6888bbfa556249b3db243559ffa39ea40f0b6659"},"cell_type":"code","source":"df = pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv')\nsample_n, var_n = df.shape\nprint(f'This dataset contains {sample_n} samples and {var_n} varialbes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d8addeeded3eef78f79b1fa995053f9bbfeeaf1"},"cell_type":"code","source":"var_with_missing_values = df.columns[df.isnull().sum() > 0]\nprint(f'{len(var_with_missing_values)} variable has missing values')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58447a9763a4305aef411ed8c8809743fb54cd5c"},"cell_type":"markdown","source":"#### 1.3 Drop meaningless variables \n* Drop variables with only one value (EmployeeCount, StandardHours, Over18)\n* Drop EmployeeNumber (ID)\n"},{"metadata":{"trusted":true,"_uuid":"15ed15eeda607043b4e6c3e889f875e8d4bc6826"},"cell_type":"code","source":"cols_with_one_value = [col for col in df.columns if len(df[col].unique()) == 1]\nto_drop = cols_with_one_value + ['EmployeeNumber']\ndf.drop(to_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4690d1f414f07ce2e906eda67cbc8e3037d17aaf"},"cell_type":"markdown","source":"#### 1.4 Separate different data types\n\n* Separate features into three groups according to their data type (Measurement, Ordinal or Nominal)."},{"metadata":{"trusted":true,"_uuid":"bfd8221ba8790f33e228701a996fd566caa63df4"},"cell_type":"code","source":"measurement_vars = [col for col, dtype in df.dtypes.items() if dtype == 'int' and len(df[col].unique()) > 5]\nordinal_vars = [col for col, dtype in df.dtypes.items() if dtype == 'int' and len(df[col].unique()) <= 5]\nnominal_vars = [col for col, dtype in df.dtypes.items() if dtype != 'int']\nnominal_vars = nominal_vars[1:]\n\ndef print_vars(data_type, var_names):\n    print(f'{data_type}:\\n', ', '.join(var_names), end=\"\\n\\n\")\n\nprint_vars('Measurement Data', measurement_vars)\nprint_vars('Ordinal Data', ordinal_vars)\nprint_vars('Nominal Data', nominal_vars)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee60705effede16dfdaef7b9675982c5eac176e8"},"cell_type":"markdown","source":"#### 1.5 Rename feature levels\n\n* Rename long descriptions with shorter abbreviations  "},{"metadata":{"trusted":true,"_uuid":"dc2b3e3d9e3451dce844b271ccbb45f587da79cc"},"cell_type":"code","source":"df['BusinessTravel'].replace({'Travel_Rarely': 'Rare',\n                             'Travel_Frequently': 'Freq',\n                             'Non-Travel': 'None'}, \n                             inplace=True)\ndf['Department'].replace({'Research & Development': 'R&D',\n                          'Human Resources': 'HR'},\n                            inplace=True)\ndf['EducationField'].replace({'Life Sciences': 'LifeSci',\n                             'Medical': 'Med',\n                             'Marketing': ' Mktg',\n                             'Technical Degree': 'Tech',\n                             'Human Resources': 'HR'},\n                            inplace=True)\ndf['JobRole'].replace({'Sales Executive': 'SalesExec',\n                      'Research Scientist': 'ResSci',\n                      'Laboratory Technician': 'LabTech',\n                      'Manufacturing Director': 'ManuDir',\n                      'Healthcare Representative': 'HCRep',\n                      'Sales Representative': 'SalesRep',\n                      'Research Director': 'ResDir',\n                      'Human Resources': 'HR'},\n                     inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"774d717324102fb7d1acc6a1e135a15166a020be"},"cell_type":"markdown","source":"#### 1.6 Split dataset \n* Split the dataset into a training set and a testing set\n* Keep the proportion of values around the same level between the training and testing set"},{"metadata":{"trusted":true,"_uuid":"52f8b79566dd428a11282ca8f827fdedb1b022d7"},"cell_type":"code","source":"X = df.drop('Attrition', axis=1)\ny = df['Attrition']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\ndf_train = pd.concat([X_train, y_train], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"447dc83f63ff6a0971c3a1589c6958e2f2840834"},"cell_type":"code","source":"df_prop = pd.concat([y_train.value_counts()/ len(y_train),\n          y_test.value_counts()/ len(y_test)],\n          axis=1)\ndf_prop.columns = ['training', 'testing']\nprint(df_prop)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5536c5e4d2b913df2b3dd6d492f15a03a6f9838"},"cell_type":"markdown","source":"##  <a class=\"anchor\" id=\"section-two\">2. Exploratory Data Analysis</a>\n#### 2.1 Feature distribution"},{"metadata":{"trusted":true,"_uuid":"9a85659eed8cd6bca981b41c1fa1b12e861c89cd"},"cell_type":"code","source":"def plot_EDA(df, cols, subplot_func, title=None, \n             sbp_info =(3,5), sbp_adj={},**kwargs):\n    \"\"\"\n    plot feature distributions\n    \"\"\"\n    n_col, subplot_size = sbp_info\n    n_row = int(np.ceil(len(cols) / n_col))\n    \n    fig, ax = plt.subplots(n_row, n_col, \n                           figsize=(n_col * subplot_size, n_row * subplot_size))\n    ax = ax.ravel()\n    \n    for i, col in enumerate(cols):\n        subplot_func(df, col, ax[i], **kwargs)\n    \n    for ax in ax[len(cols):]:\n        ax.axis('off')\n        \n    fig.suptitle(title, fontsize=20)\n    fig.subplots_adjust(**sbp_adj)\n    \n\ndef feature_dist(df, col, ax):\n    \"\"\"\n    subplot function\n    \"\"\"\n    if isinstance(df[col][0], str):\n        data = pd.DataFrame(df[col].value_counts()).reset_index()\n        data.columns = [col, 'count']\n    \n        rotation = 0\n        if sum(map(lambda x: len(x),list(data[col]))) > 20:\n            rotation = 50\n\n        sns.barplot(x=col, y='count', data = data , \n                alpha=0.4, ax=ax).set_title(col, fontsize=14)\n    \n        ax.set_xticklabels(ax.get_xticklabels(), \n                       fontsize=12,\n                       rotation=rotation)\n    else:\n        sns.distplot(df[col], kde=False, ax=ax).set_title(col, fontsize=14)\n        \n    ax.set_xlabel('')   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20a7c6ae8cc5dbc35c179b5e12dfd156e5f841e4"},"cell_type":"code","source":"plot_EDA(X_train, \n         measurement_vars + ordinal_vars + nominal_vars,\n         feature_dist, \n         title=\"Feature Distribution\", \n         sbp_info=(4, 4),\n         sbp_adj={'top': .94, 'hspace': .6})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"468980d1b901a9e72ef568c9fbbe4f4917b8f2e7"},"cell_type":"markdown","source":"**Takeaways**:\n\nMany features showed skewed distributions. In section 3, we could recode those features into more symmetrical distributions."},{"metadata":{"_uuid":"b6007e2f5af079494fb42198cd82b226b51f0db6"},"cell_type":"markdown","source":"#### 2.2 Distribution Against Employee Attrition\n\n* Compared the distribution of each feature between the employees who have left their jobs and who stayed in the company.\n* Features were sorted by the effect sizes of the comparison against Attrition, separately for different types of data."},{"metadata":{"trusted":true,"_uuid":"7ae608bb88e9d8cb57986a82ce1372afca8f4b9e"},"cell_type":"code","source":"def get_ES(df, cols, group=None):\n    \"\"\"\n    get effect size\n    \"\"\"\n    df = df[[group] + cols]\n    means = df.groupby(group).mean().T\n    std = df.groupby(group).std().T\n\n    n1, n2 = df[group].value_counts().values\n    cohen_d = ((means.values * [1, -1]).sum(axis=1) / \n          ((std.values ** 2 * [n1 -1, n2 -1]).sum(axis=1) / (n1 + n2 -2)) ** .5 )\n    return dict(zip(cols, abs(cohen_d))) \n\ndef get_chi2(df, cols, group=None):\n    \"\"\"\n    get chi square (independence of variables)\n    \"\"\"\n    cols_chi2 = []\n    for col in cols:\n        ct = pd.crosstab(df['Attrition'], df[col])\n        chi2, _, _, _ = chi2_contingency(ct)\n        cols_chi2.append(chi2)\n    return dict(zip(cols, cols_chi2))\n\ndef sort_by_results(df, cols, func=None, group=None, with_value=False):\n    \"\"\"\n    sort by the results of a given test\n    \"\"\"\n    measure = func(df, cols, group=group)\n    if with_value:\n        return sorted(measure.items(), key=lambda x: x[1], reverse=True)\n    else:\n        return sorted(measure, key=measure.get, reverse=True)\n    \ndef measurement_dist_against_attrition(df, col, ax):\n    \"\"\"\n    distribution comparisons for measurement data \n    \"\"\"\n    sns.distplot(df.loc[df['Attrition']=='Yes', col], ax=ax).set_title(col, fontsize=14)\n    sns.distplot(df.loc[df['Attrition']=='No', col], ax=ax)\n    ax.set_xlabel('')\n    #ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n\n\ndef categorical_dist_against_attrition(df, col, ax):\n    \"\"\"\n    distribution comparisons for categorical data \n    \"\"\"\n    ct = pd.crosstab(df['Attrition'], df[col]).apply(lambda r: r/r.sum(), axis=1)\n    stacked = ct.stack().reset_index().rename(columns={0:'value'})\n    \n    rotation = 0\n    if sum(map(lambda x: len(str(x)),list(stacked[col].unique()))) > 30:\n        rotation = 40\n\n    sns.barplot(x=stacked[col], y=stacked.value, \n                hue=stacked.Attrition, \n                alpha=.4, ax=ax).set_title(col, fontsize=14)\n    \n    ax.set_xticklabels(ax.get_xticklabels(), rotation=rotation, fontsize=12)\n    ax.set_xlabel('')\n    ax.set_ylabel('')\n\n    \ndef dist_against_attrition(df, col, ax):\n    if (not isinstance(df[col][0], str)) and len(df[col].unique()) > 6:\n        measurement_dist_against_attrition(df, col, ax)\n    else:\n        categorical_dist_against_attrition(df, col, ax)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"540a2a2713cad34cec0dbff1392025f24aed43bb"},"cell_type":"code","source":"# sort features by the effect size of comparison on Attrition\nsorted_measurement_vars = sort_by_results(df_train, measurement_vars, \n                                          func=get_ES, group='Attrition')\nsorted_categorical_vars = sort_by_results(df_train, ordinal_vars + nominal_vars, \n                                      func=get_chi2, group='Attrition')\n\n\nplot_EDA(df_train, sorted_measurement_vars + sorted_categorical_vars, \n         dist_against_attrition,\n         title=\"Distribution Against Employee Attrition\",\n         sbp_info=(2, 8),\n         sbp_adj={'top': 0.97, 'hspace': 0.6, 'wspace': 0.4 })","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f26cff15b62393eba0da2159915f19c91483530e"},"cell_type":"markdown","source":"**Takeaways**:\n\nWe could draw some insights on how experience, job roles, and working environment affect attrition from the above EDA\n\n1. Employees who have left the job tent to be younger, and have a lower number of working years. \n\n2. Sales representatives and Lab technicians had higher attrition rates than other roles. \n\n3. Working overtime, traveling frequently were also related to employee attrition.\n"},{"metadata":{"_uuid":"1e74855a8532a05be65c87ecac488eb4cf5efe2b"},"cell_type":"markdown","source":"## <a class=\"anchor\" id=\"section-three\">3. Data Engineering</a>\n#### 3.1 Recode target variable"},{"metadata":{"trusted":true,"_uuid":"0f3e1ee5b9b3cf7fabf0a83a62578077802a06ed"},"cell_type":"code","source":"y_train = y_train.replace({'No': 0, 'Yes': 1})\ny_test = y_test.replace({'No': 0, 'Yes': 1})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0060787d2b41d7dd164ae197185edb33de77c59a"},"cell_type":"markdown","source":"#### 3.2 Create new features"},{"metadata":{"trusted":true,"_uuid":"6320982bf4d3ba34384ef16653aacaa8b3f818ea"},"cell_type":"code","source":"def recode_features(df):\n    new_df = pd.DataFrame()\n    new_df['FarFromHome'] = df['DistanceFromHome'] > 10\n    \n    new_df['YearsPerCompany'] = np.log(df['TotalWorkingYears'] / \n                                   (df['NumCompaniesWorked'] + 1) + 1)\n    \n    new_df['Satisfaction'] = zscore(df[['JobSatisfaction', \n                                'EnvironmentSatisfaction', \n                                'RelationshipSatisfaction',\n                                'JobInvolvement', \n                                'WorkLifeBalance']].mean(axis=1))\n    \n    new_df['TravelOften'] = df['BusinessTravel'].map({'Rare': False, 'None': False, 'Freq': True})\n\n    new_df['JuniorLevel'] = df['JobLevel'] == 1\n    new_df['NoStock'] = df['StockOptionLevel'] == 0\n    return new_df\n    \nrecode_cols = ['DistanceFromHome', 'TotalWorkingYears', \n               'NumCompaniesWorked', 'JobSatisfaction', \n               'EnvironmentSatisfaction', 'JobInvolvement', \n               'WorkLifeBalance', 'BusinessTravel','RelationshipSatisfaction',\n               'JobLevel', 'StockOptionLevel']\nremove_cols = ['EducationField', 'Department']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fd685adeb4a1dee52e2ffc46e2b5c6f65c50d9b"},"cell_type":"markdown","source":"#### 3.3 Making dummy variables "},{"metadata":{"trusted":true,"_uuid":"d95b44436706ecf4a48ba22fadf05001f01f5789"},"cell_type":"code","source":"def making_dummy(df):\n    return pd.get_dummies(df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"323ec797d082a2075896c0c76eac1785925c075e"},"cell_type":"markdown","source":"#### 3.4 Normalize features"},{"metadata":{"trusted":true,"_uuid":"81069c1e5f81b3d728087e97600d562ab654eb48"},"cell_type":"code","source":"def normalize_vars(training, testing, power=False):\n    if power:\n        tr = PowerTransformer()\n    else:\n        tr = StandardScaler()\n    \n    train = tr.fit_transform(training)\n    test = tr.transform(testing)\n    train_df = pd.DataFrame(train,\n                            index = training.index,\n                            columns = training.columns)\n    test_df = pd.DataFrame(test,\n                           index = testing.index,\n                           columns = testing.columns)\n    return train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fe9ff085cd9fb3946cbb5b08838bc99ffb29ce6"},"cell_type":"code","source":"numeric_cols = list(set(measurement_vars) - set(recode_cols) - set(remove_cols))\ncategorical_cols = list(set(nominal_vars + ordinal_vars) - set(recode_cols) - set(remove_cols))\n\n# recode variable\nX_train_recode = recode_features(X_train)\nX_test_recode = recode_features(X_test)\n\n# use dummy coding\nX_train_dummies = making_dummy(\n    pd.concat([X_train[categorical_cols], X_train_recode], axis=1)\n)\nX_test_dummies = making_dummy(\n    pd.concat([X_test[categorical_cols], X_test_recode], axis=1)\n)\n# standard scaling \nX_train_normalized, X_test_normalized = normalize_vars(\n    X_train[numeric_cols], X_test[numeric_cols]\n    )\n\n# combine all features\nX_train_preprocessed = pd.concat([X_train_normalized, \n                                    X_train_dummies], axis=1)\nX_test_preprocessed = pd.concat([X_test_normalized, \n                                    X_test_dummies], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79b21e86254849b4ee9c625e5975f33cb08e6491"},"cell_type":"markdown","source":"#### 3.5 Remove multicollinearity"},{"metadata":{"trusted":true,"_uuid":"993a08961fa792c11ad27b86dc31243fff962100"},"cell_type":"code","source":"corr = X_train_preprocessed.corr()\nfig, ax = plt.subplots(1, 1, figsize=(9, 8))\nax = sns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21bb12ac80d290ef412bf6243dbb727addeefb99"},"cell_type":"code","source":"def get_correlated_with_cutoff(corr_matrix, cutoff):\n    \"\"\"\n    get the pairs of variables with correlations higher than the cutoff\n    \"\"\"\n    corr_df =  abs(corr_matrix.unstack().sort_values(ascending=False).drop_duplicates())\n    filtered_df = corr_df[(corr_df < 1) & (corr_df > cutoff)]\n    \n    links = (corr > cutoff).sum() -1\n    \n    return filtered_df, set(chain(*filtered_df.index)), links[links > 0]\n\ncorr_df, corr_items, corr_links = get_correlated_with_cutoff(corr, .7)\n\nprint('Highly Correlated Features:', end='\\n\\n')\nprint(corr_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4094abc31e68ab19c9794a8269a92d1827892793"},"cell_type":"code","source":"to_drop_cols = [\n    'NoStock',\n    'PerformanceRating', \n    'YearsInCurrentRole', \n    'YearsWithCurrManager', \n]\n\nX_train_preprocessed.drop(to_drop_cols, axis=1, inplace=True)\nX_test_preprocessed.drop(to_drop_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f94a8ebf19ee4c05f7edba073a8e73871fd0f50"},"cell_type":"markdown","source":"## <a class=\"anchor\" id=\"section-four\">4. Build Models</a>\n#### 4.1 Choose Metrics\n\nWe aimed to build machine learning models that predict whether employees would leave their positions or not. One challenge of this dataset is the inherent imbalance of the attrition data: only a small proportion (16%) of employees have left their jobs. We choose the F1 score as our metric since it combines both recall and precision. Also, because the goal is to identify high-risk employees, recall rate is more important than the precision rate in this project."},{"metadata":{"_uuid":"f0b768549018453b0326c557a5f885811cfd0761"},"cell_type":"markdown","source":"#### 4.2 Train and test models"},{"metadata":{"trusted":true,"_uuid":"52dab58f052d3d4abcdc1471c46200b67728f70e"},"cell_type":"code","source":"def print_results(model, X_test, y_test):\n    \"\"\"\n    print summrized results\n    \"\"\"\n    y_pred = model.predict(X_test)\n    y_pred_prob = model.predict_proba(X_test)[:, 1]\n    \n    auc = metrics.roc_auc_score(y_test, y_pred_prob)\n    acc = metrics.accuracy_score(y_test, y_pred)\n    f1 = metrics.f1_score(y_test, y_pred)\n    conf_mat = metrics.confusion_matrix(y_test, y_pred)\n    conf_mat_df = pd.DataFrame(conf_mat, \n                               index= ['true_no', 'true_yes'],\n                              columns = ['predict_no', 'predict_yes'])\n    \n    model_name = str(model).split('(')[0]\n    print(f'{\"*\" *10} {model_name} {\"*\" *10}')\n    print(f'Accuracy: {acc:.3f}')\n    print(f'AUC: {auc:.3f}')\n    print(f'F1: {f1:.3f}\\n', end='\\n')\n    print('Confusion Matrix:', end='\\n')\n    print(conf_mat_df, end='\\n\\n')\n    print('Classification Report:', end='\\n')\n    print(metrics.classification_report(y_test, y_pred))\n\n\ndef params_tuning(X_train, y_train, X_test, y_test,\n                  model=None, param_grid=None,\n                 scoring=None, balance_weight=False):\n    \"\"\"\n    Use the best params resulted from GridSearchCV to fit models\n    \"\"\"\n    if balance_weight:\n        sample_weight = y_train.map(dict(0.5 / y_train.value_counts())).values\n    else:\n        sample_weight = None\n    \n    # Grid Search for the best parameters\n    clf = GridSearchCV(model, param_grid, cv=5, scoring=scoring)\n    clf.fit(X_train, y_train, sample_weight=sample_weight)\n    # train model with the selected best parameters\n    model.set_params(**clf.best_params_)\n    model.fit(X_train, y_train)\n    # pring results\n    print_results(model, X_test, y_test)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0b59d6895f45bb50883ca1668870c038f524947"},"cell_type":"markdown","source":"#### 4.2.1 Logistic Regression Classifier\n\nWe first trained a Logistic Regression model with L2 regularization to predict employee attritions. The performance was not bad for this simple model."},{"metadata":{"trusted":true,"_uuid":"a06ca758a541ab2ac091b7745c35e42494482fef"},"cell_type":"code","source":"lr_params = {\n    'max_iter': 1000,\n    'class_weight': 'balanced'\n}\n# lr_grid_params = {\n#     'C': np.linspace(.1, 1, 10),\n#     'penalty': ['l1', 'l2'],\n#     'class_weight': ['balanced']\n# }\n\n# lr = params_tuning(\n#     X_train_preprocessed, y_train,\n#     X_test_preprocessed, y_test,\n#     model=LogisticRegression(**lr_params),\n#     param_grid=lr_grid_params,\n#     scoring='f1',\n# )\n\nlr_tuned_params = {'penalty': 'l2', 'C': .6}\nlr = LogisticRegression(**lr_params, **lr_tuned_params)\nlr.fit(X_train_preprocessed, y_train)\nprint_results(lr, X_test_preprocessed, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcc9ffa11d0f05a4dc45411c4b1970e4818c5903"},"cell_type":"markdown","source":"#### 4.2.2 Random Forest Classifier (with oversampling)\nClass imbalance affects Ensemble classifiers a lot. Therefore, we employed the Synthetic Minority Oversampling Technique (SMOTE) before model training. On the testing set, random forest classifier showed the highest accuracy among all the tested models. However, this classifier had a low recall rate."},{"metadata":{"trusted":true,"_uuid":"e3ced1c8bc9157af7660f6449bcf947e861a1c23"},"cell_type":"code","source":"oversampler=SMOTE(random_state=0)\nX_train_smote, y_train_smote = oversampler.fit_sample(\n    X_train_preprocessed, y_train)\n\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 1000,\n    'min_samples_leaf': 2,\n    'verbose': 0,\n    'oob_score': True,\n}\n\n#rf_grid_params = {\n#     'max_depth': [2, 5, 8, 12],\n#     'max_features': [.3, .5, .8]\n#                  }\n\n# rf = params_tuning(\n#     X_train_smote, y_train_smote,\n#     X_test_preprocessed, y_test,\n#     model=RandomForestClassifier(**rf_params),\n#     param_grid=rf_grid_params,\n#     scoring='f1',\n# )\n\nrf_tuned_params = {'max_depth': 12, 'max_features': .3}\nrf = RandomForestClassifier(**rf_params, **rf_tuned_params)\nrf.fit(X_train_smote, y_train_smote)\nprint_results(rf, X_test_preprocessed, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b5d38e27b28f83b066a92a11ccbd15351ac1404"},"cell_type":"markdown","source":"#### 4.2.3 Gradient Boosting Classifier(with oversampling)\n\nThough Gradient Boosting Classifier showed high accuracy, it didn't perform well on AUC and F1 scoring, which are more important metrics for imbalanced datasets."},{"metadata":{"trusted":true,"_uuid":"f6bcf44798441d41832b7cdd9e1f515112df6b7c"},"cell_type":"code","source":"gb_params = {\n    'n_estimators': 1000,\n    'min_samples_leaf': 2,\n}\n# gb_grid_params = {'learning_rate': np.linspace(.1, 1, 10),\n#                  'max_depth': [2, 3, 5, 8],\n#                  'max_features': [.3, .5, .8]}\n\n# gb = params_tuning(\n#     X_train_smote, y_train_smote,\n#     X_test_preprocessed, y_test,\n#     model=GradientBoostingClassifier(**gb_params),\n#     param_grid=gb_grid_params,\n#     scoring='f1',\n# )\n\ngb_tuned_params = {'max_depth': 8, 'max_features': .3, 'learning_rate': 0.4}\ngb = GradientBoostingClassifier(**gb_params, **gb_tuned_params)\ngb.fit(X_train_smote, y_train_smote)\nprint_results(gb, X_test_preprocessed, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43b4a823824ff41d39af75f0d5b6793cafeb128a"},"cell_type":"markdown","source":"#### 4.2.4 Support Vector Classifier\n\nWe then trained and tested a Support Vector Classifier with a linear kernel and balanced class weights; it showed the highest AUC score and F1 score among the examined machine learning models. Though, in comparison with the Logistic regression model, the feature weights of SVC were harder to interpret."},{"metadata":{"trusted":true,"_uuid":"59c7152d6e8b7e8d621a5262e991fc86f4c95446"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc_params = {\n    'cache_size': 200, \n    'kernel': 'linear',\n    'gamma': 'auto',\n    'class_weight': 'balanced',\n    'probability': True\n}\n# svc_grid_params = {'C': [.05, .1, .2, .5, 1, 2, 5, 10, 20]}\n\n# svc = params_tuning(\n#     X_train_preprocessed, y_train,\n#     X_test_preprocessed, y_test,\n#     model=SVC(**svc_params),\n#     param_grid=svc_grid_params,\n#     scoring='f1',\n# )\n\nsvc_tuned_params = {'C': 10}\nsvc = SVC(**svc_params, **svc_tuned_params)\nsvc.fit(X_train_preprocessed, y_train)\nprint_results(svc, X_test_preprocessed, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"735668a28a0a563b61cbaf2f0aae16e69b9208e8"},"cell_type":"markdown","source":"#### 4.2.5 Ensemble Classifier\n\nWe combined the predictions of the models with decent performance (Logistic Regression, Random Forest, and SVC) and took the majority vote. This Ensemble Classifier showed even higher F1 score than the best classifier (SVC) in the ensemble."},{"metadata":{"trusted":true,"_uuid":"d8a8e2dd683c2e077e1dfe4611599829eb864256"},"cell_type":"code","source":"class VotingClassifier:\n    def __init__(self, models):\n        self.models = models\n        \n    def __repr__(self):\n        model_info = ', '.join(list(models.keys()))\n        return f'EnsembleVoting({model_info})'\n    \n    def predict(self, X_test):\n        predictions = [model.predict(X_test) for model in self.models.values()]\n        return np.array(predictions).mean(0) > .5\n        \n    def predict_proba(self, X_test):\n        prob= [model.predict_proba(X_test) for model in models.values()]\n        return np.stack(prob).mean(0)\n        \n        \nmodels = {\n    'Logistic Regression': lr, \n    'Random Forest': rf,\n    'SVC': svc,\n    }\nvt = VotingClassifier(models)\nprint_results(vt, X_test_preprocessed, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a900acfb6fb90218cf4e1a26a11754c8335aa7b6"},"cell_type":"markdown","source":"#### 4.3 Bechmark Classifiers"},{"metadata":{"trusted":true,"_uuid":"87937ceef3e87c1a563da55d46839203336a0d9d"},"cell_type":"code","source":"def plot_curves(y_test, y_pred_prob, ax1, ax2):\n    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_prob)\n    pr, rc, _ = metrics.precision_recall_curve(y_test, y_pred_prob)\n    ax1.plot(fpr, tpr)\n    ax2.plot(rc, pr)\n    \n\ndef get_model_results(y_test, y_pred, y_pred_prob):\n    return pd.Series({\n        'Accuracy': metrics.accuracy_score(y_test, y_pred),\n        'ROC AUC': metrics.roc_auc_score(y_test, y_pred_prob),\n        'F1': metrics.f1_score(y_test, y_pred),\n    })\n    \n\ndef plot_comparison(models, X_test, y_test):\n    \"\"\"\n    Plot ROC and Precision/Recall Curves\n    \"\"\"\n    fig,(ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n\n    df_results = pd.DataFrame()\n    for name, model in models.items():\n        y_pred_prob = model.predict_proba(X_test)[:, 1]\n        y_pred = model.predict(X_test)\n        plot_curves(y_test, y_pred_prob, ax1, ax2)\n        df_results[name] = get_model_results(y_test, y_pred, y_pred_prob)\n\n    ax1.set_xlabel('Specificity', fontsize=14)\n    ax1.set_ylabel('Sensitivity', fontsize=14)\n    ax1.set_title('ROC', fontsize=18)\n    ax1.legend(handles=ax1.lines, labels=list(models.keys()), fontsize=12)\n    ax1.plot([0, 1], [0, 1], 'k--')\n\n    ax2.set_xlabel('Recall', fontsize=14)\n    ax2.set_ylabel('Precision', fontsize=14)\n    ax2.set_title('Precision/Recall', fontsize=18)\n    \n    print(\"Benchmark Results:\")\n    print(df_results.T, end='\\n\\n')\n    #ax[1].legend(handles=ax[1].lines, labels=list(models.keys()), fontsize=12)\n    \n    # bechmark results\n#     df_results = df_results.unstack().reset_index()\n#     df_results.columns = ['models', 'metrics', 'values']\n#     sns.factorplot(x='metrics', y='values', hue='models',\n#                     data=df_results, kind='bar', ax=ax3,\n#                   legend_out=True)\n#     ax3.set_ylim(0,1)\n#     ax3.set_title('Benchmak Model Performance', fontsize=18)\n#     ax3.set_ylabel('')\n#     ax3.set_xlabel('')\n#     ax3.set_xticklabels(ax3.get_xticklabels(), fontsize=14)\n#     ax3.legend(bbox_to_anchor=(.7, 1), loc=2, borderaxespad=0., fontsize=12)\n#     plt.close(2)\n#     plt.subplots_adjust(hspace=.4)\n\n    \ncompare_models = models.copy()\ncompare_models['Ensemble'] = vt\nplot_comparison(compare_models, X_test_preprocessed, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d67619acdbebcd565ec66b584eb1cac868d20048"},"cell_type":"markdown","source":"The benchmark analysis revealed better performance (F1, AUC score) in SVC than in Logistic Regression and Random Forest model. Though Random Forest classifier showed highest classification accuracy, it tent to classify employees as without attritions, causing low recall rate. However, since the goal of this project is to identify the employees with high attrition risk (minority class), it is more important to consider recall than precision. \n\nNext, we combined the three models with majority voting. This classifier further enhanced the performance on F1 score. "},{"metadata":{"_uuid":"4a6ed2c65b1fe2c15fbdbcc80dd0390f69f0e3fe"},"cell_type":"markdown","source":"#### 4.4 Feature Importance"},{"metadata":{"trusted":true,"_uuid":"e565dbe79a74c262444192c9a3e57764060e1fa4"},"cell_type":"code","source":"def plot_feature_importance(features, importance, \n                            topN=20, ax=None):\n\n    df = pd.DataFrame({'features': features, \n                  'importance': importance})\n    df['abs_importance'] = abs(df['importance'])\n    df.sort_values('abs_importance', inplace=True, ascending=False)\n    \n    sns.barplot(y=\"features\", x=\"importance\", data=df[:20], \n                color=\"b\", alpha=.4, ax=ax)\n    ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)\n    ax.set_ylabel(\"\")\n    ax.set_xlabel(\"\")\n    \n\nmodel_feature_info ={\n    'Logistic Regression': ('Coef', lr.coef_[0] ),\n    'SVC': ('Coef', svc.coef_[0] ),\n    'Random Forest': ('Feature Importance', rf.feature_importances_)\n}\n\ndef compare_feature_importance(model_feature_info):\n    col_n, ph, pw = 2, 6, 6\n    model_n = len(model_feature_info)\n    row_n = int(np.ceil( model_n / col_n))\n    \n    f, ax = plt.subplots(row_n, col_n, \n                         figsize=(col_n * ph, row_n * pw))\n    ax = ax.ravel()\n    \n    features = list(X_test_preprocessed.columns)\n    for i, (model_name, model_info) in enumerate(model_feature_info.items()):\n        plot_feature_importance(\n            features, model_info[1], ax=ax[i])\n        ax[i].set_title(model_name, fontsize=14)\n        ax[i].set_xlabel(model_info[0], fontsize=12)\n        \n    plt.subplots_adjust(wspace=0.8)\n    \n    for ax in ax[model_n:]:\n        ax.axis('off')\n\nmodel_feature_info ={\n    'Logistic Regression': ('Feature Coefficient', lr.coef_[0] ),\n    'SVC': ('Feature Weight', svc.coef_[0] ),\n    'Random Forest': ('Feature Importance', rf.feature_importances_)\n}\ncompare_feature_importance(model_feature_info)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50645f5f6c907ec1bf05d0ec8678ebf40e82b952"},"cell_type":"markdown","source":" In some scenarios, a complicated black box model with the best performance is all we need. This project, however, was not the case. The **interpretability** of the model is equally critical since HR would rely on these insights to devise intervention strategies. \n\nThough the exact feature importance levels differ among the three examined models, their patterns share a lot in common.  \n\n1. Several working environment factors were associated with higher attrition risks: such as working overtime, living far away from the company, lack of satisfaction, and traveling a lot. \n2. Some job roles, such as sales and HR, had higher attrition risks; in contrast, research scientists and directors showed lower risks. Also, employees in junior level positions were more likely to leave their jobs. \n3. Some personal attributes also contributed to the attrition risks, such as single, young age, and a history of short stays at each worked company.\n\nThough formulating policies to increase retention is beyond the scope of this project, we could draw some actionable insights. Such as:\n\n1. Give recognition or compensations to the employees who have been working overtime, or spending a lot of time in commute or traveling\n2. Allocate more resources to the departments with low retention rate for team and culture building\n3. Provide more guidance (orientation, mentorship) to junior employees"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}