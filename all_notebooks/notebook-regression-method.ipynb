{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Notebook, Regression method","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Create a summary of regression machine learning methods using House price prediction as the subject.\n\n*Classification method\nhttps://www.kaggle.com/urayukitaka/notebook-classification-method","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Classification Medhod\nLinear model<br>\n- Linear regression\n- Ridge regression\n- Lasso regression\n- ElasticNet<br>\n\nTree model<br>\n- Decision tree regression\n- Random forest regression\n- XGBoost regression\n- LGBM regression\n- GradientBoosting regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Basic Libraries\nimport numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Visualization\nimport matplotlib.pyplot as plt\nplt.style.use(\"fivethirtyeight\")\nimport seaborn as sns\n\n# Statistics\nfrom scipy import stats\n\n# Data preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# StratifiedKFold\nfrom sklearn.model_selection import StratifiedKFold\n\n# Grid search\nfrom sklearn.model_selection import GridSearchCV\n\n# Validataion\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Define function","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Scatter plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_point(y_train, y_test, y_train_pred, y_test_pred):\n    fig, ax = plt.subplots(1,2,figsize=(20,10))\n    # Scatter plot\n    ax[0].scatter(y_train, y_train_pred, color=\"blue\", alpha=0.3, s=5,\n                  label=\"Train data R2 score:{}\".format(r2_score(y_true=y_train, y_pred=y_train_pred).round(3)))\n    ax[0].scatter(y_test, y_test_pred, color=\"red\", alpha=0.3, s=5,\n                  label=\"Test data R2 score:{}\".format(r2_score(y_true=y_test, y_pred=y_test_pred).round(3)))\n    ax[0].set_xlabel(\"true value\")\n    ax[0].set_ylabel(\"predicted value\")\n    ax[0].set_title(\"Scatter plot\")\n    ax[0].legend()\n    # Residual plot\n    ax[1].scatter(y_train_pred, y_train_pred - y_train, color=\"blue\", alpha=0.3, s=5,\n                  label=\"Train data MSE:{}\".format(mean_squared_error(y_true=y_train, y_pred=y_train_pred).round(3)))\n    ax[1].scatter(y_test_pred, y_test_pred - y_test, color=\"red\", alpha=0.3, s=5,\n                  label=\"Test data MSE:{}\".format(mean_squared_error(y_true=y_test, y_pred=y_test_pred).round(3)))\n    ax[1].set_xlabel(\"prediction\")\n    ax[1].set_ylabel(\"residual\")\n    ax[1].set_title(\"Residual plot\")\n    ax[1].legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data loading and check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Data loading\ndf = pd.read_csv(\"/kaggle/input/housesalesprediction/kc_house_data.csv\", header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data frame\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Null values\ndf.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data info\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Create target flag","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(20,6))\n\nsns.distplot(df[\"price\"], ax=ax[0])\nax[0].set_xlabel(\"price\")\nax[0].set_ylabel(\"frequency\")\n\nsns.distplot(np.log10(df[\"price\"]), ax=ax[1])\nax[1].set_xlabel(\"price_log\")\nax[1].set_ylabel(\"frequency\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This forecast is for price. Looking at the price distribution, it can be seen that it is biased to the left. Therefore, it was decided to logarithmize and make the distribution as close to the normal distribution as possible, and predict the logarithmized value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create log price columns\ndf[\"price_log\"] = np.log(df[\"price\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target value\ny = df[\"price_log\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confirmation of explanatory variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The zip code, latitude and longitude are not used this time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ex_columns = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view',\n              'condition', 'grade','sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The year of construction is changed to the number of years of construction. The largest year is set as the latest and used as the starting point.\nIf yr_renov is 0, it is the building age, otherwise it is the number of years from the latest year.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# yr_built\nlatest_year = df[\"yr_built\"].max()\ndf[\"yr_built\"] = latest_year - df[\"yr_built\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define function\ndef renov(x):\n    if x[\"yr_renovated\"] == 0:\n        res = x[\"yr_built\"]\n    else:\n        res = latest_year - x[\"yr_renovated\"]\n    return res\n\n# apply function\ndf[\"yr_renovated\"] = df.apply(renov, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[ex_columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample 200\nsns.pairplot(X.sample(200))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Correlation\nmatrix = X.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(matrix, vmax=1, vmin=-1, cmap=\"bwr\", square=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Many collinearities are confirmed. This time, it will be carried out as it is, and the regularization effect will be confirmed in the linear prediction.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To compare the prediction results, separate into training data and test data. For regression analysis, data scaling is required, so that processing is performed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# data split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling\nsc = StandardScaler()\nsc.fit(X_train)\n\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Medhod\nLinear model<br>\n- Linear regression\n- Ridge regression\n- Lasso regression\n- ElasticNet<br>\n\nTree model<br>\n- Decision tree regression\n- Random forest regression\n- XGBoost regression\n- LGBM regression\n- GradientBoosting regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> # Linear regression\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Instance\nln = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting\nln.fit(X_train_std, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\ny_train_pred = ln.predict(X_train_std)\ny_test_pred = ln.predict(X_test_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation score\nprint(\"MSE train %.3f\" % mean_squared_error(y_true=y_train, y_pred=y_train_pred))\nprint(\"MSE test %.3f\" % mean_squared_error(y_true=y_test, y_pred=y_test_pred))\n\nprint(\"R2 score train %.3f\" % r2_score(y_true=y_train, y_pred=y_train_pred))\nprint(\"R2 score test %.3f\" % r2_score(y_true=y_test, y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficients and intercept\ncoef_ln_df = pd.DataFrame({\"params\":X.columns, \"Coefficient\":ln.coef_}).sort_values(by=\"Coefficient\")\nintercept = pd.DataFrame([[\"intercept\", ln.intercept_]], columns=coef_ln_df.columns)\n\ncoef_ln_df = coef_ln_df.append(intercept)\n\ncoef_ln_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Stats model\nhttps://www.statsmodels.org/stable/regression.html\n\n### Note ! stats model need to intercept columns for training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dataframe\ndata = pd.DataFrame(X_train_std, columns=X_train.columns)\n# Note ! stats model need to intercept columns for training\ndata = sm.add_constant(data)\ndata[\"price\"] = y_train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nlm = smf.ols(formula=\"price ~ bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+sqft_basement+yr_built+yr_renovated+sqft_living15+sqft_lot15\", data=data)\nmodel = lm.fit()\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some parameter's p value is large, this linear regression does not do necessary things such as deleting variables including multicollinearity. Therefore, the reliability of the coefficient is low.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution\nresid = model.resid\n\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VIF check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n = lm.exog.shape[1]\nvifs = [variance_inflation_factor(lm.exog, i) for i in range(0, n)]\npd.DataFrame(vifs, index=lm.exog_names, columns=[\"VIF\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Ridge regression\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.linear_model import Ridge\n\n# Instance\nri = Ridge()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nparams = {'alpha': [1000, 100, 10, 1, 0.1, 0.01, 0.001]}\n\n# Fitting\ncv_r = GridSearchCV(ri, params, cv=10, n_jobs =1)\ncv_r.fit(X_train_std, y_train)\n\nprint(\"Best params:{}\".format(cv_r.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_r = cv_r.best_estimator_\n\n# prediction\ny_train_pred_r = best_r.predict(X_train_std)\ny_test_pred_r = best_r.predict(X_test_std)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_r)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_r)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_r)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_r)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_r, y_test_pred_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficients and intercept\ncoef_ri_df = pd.DataFrame({\"params\":X.columns, \"Coefficient\":best_r.coef_}).sort_values(by=\"Coefficient\")\nintercept = pd.DataFrame([[\"intercept\", best_r.intercept_]], columns=coef_ri_df.columns)\n\ncoef_ri_df = coef_ri_df.append(intercept)\n\ncoef_ri_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_r - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stats model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\n# create model\nmodel = smf.ols(formula=\"price ~ bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+sqft_basement+yr_built+yr_renovated+sqft_living15+sqft_lot15\", data=data)\nridge = model.fit_regularized(L1_wt=0)\n# L1_wt = 0:Ridge, 1:Lasso, 0.5:Elastic Net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params, cannot sumary table\nridge.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> # Lasso regression\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.linear_model import Lasso\n\n# Instance\nla = Lasso()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nparams = {'alpha': [10, 1, 0.1, 0.01, 0.001, 0.0001]}\n\n# Fitting\ncv_l = GridSearchCV(la, params, cv=10, n_jobs =1)\ncv_l.fit(X_train_std, y_train)\n\nprint(\"Best params:{}\".format(cv_l.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_l = cv_l.best_estimator_\n\n# prediction\ny_train_pred_l = best_l.predict(X_train_std)\ny_test_pred_l = best_l.predict(X_test_std)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_l)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_l)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_l)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_l)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_l, y_test_pred_l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficients and intercept\ncoef_la_df = pd.DataFrame({\"params\":X.columns, \"Coefficient\":best_l.coef_}).sort_values(by=\"Coefficient\")\nintercept = pd.DataFrame([[\"intercept\", best_l.intercept_]], columns=coef_la_df.columns)\n\ncoef_la_df = coef_la_df.append(intercept)\n\ncoef_la_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_l - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stats model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\n# create model\nmodel = smf.ols(formula=\"price ~ bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+sqft_basement+yr_built+yr_renovated+sqft_living15+sqft_lot15\", data=data)\nlasso = model.fit_regularized(L1_wt=1)\n# L1_wt = 0:Ridge, 1:Lasso, 0.5:Elastic Net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params, cannot sumary table\nlasso.params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Elastic Net\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.linear_model import ElasticNet\n\n# Instance\nel = ElasticNet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nparams = {'alpha': [10, 1, 0.1, 0.01, 0.001, 0.0001]}\n\n# Fitting\ncv_e = GridSearchCV(el, params, cv=10, n_jobs =1)\ncv_e.fit(X_train_std, y_train)\n\nprint(\"Best params:{}\".format(cv_l.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_e = cv_e.best_estimator_\n\n# prediction\ny_train_pred_e = best_e.predict(X_train_std)\ny_test_pred_e = best_e.predict(X_test_std)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_e)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_e)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_e)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_e)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_e, y_test_pred_e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficients and intercept\ncoef_el_df = pd.DataFrame({\"params\":X.columns, \"Coefficient\":best_e.coef_}).sort_values(by=\"Coefficient\")\nintercept = pd.DataFrame([[\"intercept\", best_e.intercept_]], columns=coef_el_df.columns)\n\ncoef_el_df = coef_el_df.append(intercept)\n\ncoef_el_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_e - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stats model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\n# create model\nmodel = smf.ols(formula=\"price ~ bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+sqft_basement+yr_built+yr_renovated+sqft_living15+sqft_lot15\", data=data)\nelast = model.fit_regularized(L1_wt=0.5)\n# L1_wt = 0:Ridge, 1:Lasso, 0.5:Elastic Net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params, cannot sumary table\nelast.params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Decision tree regression\nhttps://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Instance\ntree = DecisionTreeRegressor(random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nparam_range = [5, 10,15]\nleaf = [50,55,60,65,70]\nparam_grid = {\"max_depth\":param_range, \"max_leaf_nodes\":leaf}\n\n# Fitting\ncv_tree = GridSearchCV(tree, param_grid, cv=10, n_jobs =1)\ncv_tree.fit(X_train, y_train)\n\nprint(\"Best params:{}\".format(cv_tree.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_tr = cv_tree.best_estimator_\n\n# prediction\ny_train_pred_tr = best_tr.predict(X_train)\ny_test_pred_tr = best_tr.predict(X_test)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_tr)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_tr)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_tr)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_tr)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_tr, y_test_pred_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_tr - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization tree\nwith dtreeviz","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#! pip install dtreeviz\n#!brew install poppler\n#!brew install pdf2svg\n#!brew install graphviz --with-librsvg --with-app --with-pango","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn import tree\n#from dtreeviz.trees import *\n#import graphviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting\ntree_c = tree.DecisionTreeRegressor(max_depth=10, max_leaf_nodes=60)\ntree_c.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization\n# Omitted because image is heavy\n# viz = dtreeviz(tree_c, X_train, y_train, target_name=\"price_flg\", feature_names=list(X_train.columns), class_names=list(y_train))\n# viz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Random forest regressor\nhttps://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=random%20forest%20regressor#sklearn.ensemble.RandomForestRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instance\nforest = RandomForestRegressor(random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nparam_range = [10,15,20,25]\nleaf = [55, 60,65,70]\nparam_grid = {\"n_estimators\":param_range, \"max_depth\":param_range, \"max_leaf_nodes\":leaf}\n\n# Fitting\ncv_forest = GridSearchCV(forest, param_grid, cv=10, n_jobs =1)\ncv_forest.fit(X_train, y_train)\n\nprint(\"Best params:{}\".format(cv_forest.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_fo = cv_forest.best_estimator_\n\n# prediction\ny_train_pred_fo = best_fo.predict(X_train)\ny_test_pred_fo = best_fo.predict(X_test)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_fo)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_fo)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_fo)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_fo)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_fo, y_test_pred_fo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_fo - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # XGB Regressor\nhttps://xgboost.readthedocs.io/en/latest/python/python_api.html","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nimport xgboost as xgb\n\n# Instance\nxgbr = xgb.XGBRegressor(random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nlearning_rate = [0.05, 0.1, 0.15]\nmax_depth = [3, 5, 7]\nsubsample = [0.85, 0.9, 0.95, 1]\ncolsample_bytree = [0.3, 0.5, 0.8]\n\nparam_grid = {'learning_rate': learning_rate, 'max_depth': max_depth, \n          'subsample': subsample, 'colsample_bytree': colsample_bytree}\n\n# Fitting\ncv_xgb = GridSearchCV(xgbr, param_grid, cv=10, n_jobs =1)\ncv_xgb.fit(X_train, y_train)\n\nprint(\"Best params:{}\".format(cv_xgb.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_xg = cv_xgb.best_estimator_\n\n# prediction\ny_train_pred_xg = best_xg.predict(X_train)\ny_test_pred_xg = best_xg.predict(X_test)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_xg)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_xg)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_xg)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_xg)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_xg, y_test_pred_xg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_xg - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # LGBM Regressor\nhttps://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nimport lightgbm as lgb\n\n# Instance\nlgbm = lgb.LGBMRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nlearning_rate = [0.05, 0.1, 0.15]\nmax_depth = [5,10,15]\n\nparam_grid = {'learning_rate': learning_rate, 'max_depth': max_depth}\n\n# Fitting\ncv_lgbm = GridSearchCV(lgbm, param_grid, cv=10, n_jobs =1)\ncv_lgbm.fit(X_train, y_train)\n\nprint(\"Best params:{}\".format(cv_lgbm.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_lg = cv_lgbm.best_estimator_\n\n# prediction\ny_train_pred_lg = best_lg.predict(X_train)\ny_test_pred_lg = best_lg.predict(X_test)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_lg)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_lg)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_lg)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_lg)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_lg, y_test_pred_lg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_lg - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # GradientBoostingRegressor\nhttps://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html?highlight=gradient%20boosting#sklearn.ensemble.GradientBoostingRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Instance\ngbr = GradientBoostingRegressor(random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training and score\nlearning_rate = [0.05, 0.1, 0.15]\nmax_depth = [3, 5, 7]\n\nparam_grid = {'learning_rate': learning_rate, 'max_depth': max_depth}\n\n# Fitting\ncv_gbr = GridSearchCV(gbr, param_grid, cv=10, n_jobs =1)\ncv_gbr.fit(X_train, y_train)\n\nprint(\"Best params:{}\".format(cv_gbr.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nbest_gbr = cv_gbr.best_estimator_\n\n# prediction\ny_train_pred_gbr = best_gbr.predict(X_train)\ny_test_pred_gbr = best_gbr.predict(X_test)\n\nprint(\"MSE train:{}\".format(mean_squared_error(y_train, y_train_pred_gbr)))\nprint(\"MSE val;{}\".format(mean_squared_error(y_test, y_test_pred_gbr)))\n\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred_gbr)))\nprint(\"R2 score val:{}\".format(r2_score(y_test, y_test_pred_gbr)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, scatter and residual\nplot_point(y_train, y_test, y_train_pred_gbr, y_test_pred_gbr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resid\nresid = y_train_pred_gbr - y_train\n\n# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(resid, ax=ax[0])\nax[0].set_xlabel(\"resid\")\nax[0].set_ylabel(\"frequency\")\nax[0].set_title(\"Prediction resid\")\n\n# Probability  plot\nstats.probplot(resid, plot=ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # Summery","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"name = [\"Linear\", \"Ridge\", \"Lasso\", \"E-Net\", \"D-tree\", \"R-forest\", \"XGB\", \"LGBM\", \"GBR\"]\n\nmse = mean_squared_error(y_train, y_train_pred)\nmse_r = mean_squared_error(y_train, y_train_pred_r)\nmse_l = mean_squared_error(y_train, y_train_pred_l)\nmse_e = mean_squared_error(y_train, y_train_pred_e)\nmse_tr = mean_squared_error(y_train, y_train_pred_tr)\nmse_fo = mean_squared_error(y_train, y_train_pred_fo)\nmse_xg = mean_squared_error(y_train, y_train_pred_xg)\nmse_lg = mean_squared_error(y_train, y_train_pred_lg)\nmse_gbr = mean_squared_error(y_train, y_train_pred_gbr)\n\nr2 = r2_score(y_train, y_train_pred)\nr2_r = r2_score(y_train, y_train_pred_r)\nr2_l = r2_score(y_train, y_train_pred_l)\nr2_e = r2_score(y_train, y_train_pred_e)\nr2_tr = r2_score(y_train, y_train_pred_tr)\nr2_fo = r2_score(y_train, y_train_pred_fo)\nr2_xg = r2_score(y_train, y_train_pred_xg)\nr2_lg = r2_score(y_train, y_train_pred_lg)\nr2_gbr = r2_score(y_train, y_train_pred_gbr)\n\nmse = [mse, mse_r, mse_l, mse_e, mse_tr, mse_fo, mse_xg, mse_lg, mse_gbr]\nr2 = [r2, r2_r, r2_l, r2_e, r2_tr, r2_fo, r2_xg, r2_lg, r2_gbr]\n\n# bar plot\nfig, ax = plt.subplots(1,2, figsize=(20,6))\n\nax[0].bar(name, mse, color=\"blue\")\nax[0].set_ylabel(\"mese\")\nax[0].set_xlabel(\"method\")\nax[0].set_title(\"MSE\")\n\nax[1].bar(name, r2, color=\"red\")\nax[1].set_ylabel(\"R2 score\")\nax[1].set_xlabel(\"method\")\nax[1].set_title(\"R2 score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}