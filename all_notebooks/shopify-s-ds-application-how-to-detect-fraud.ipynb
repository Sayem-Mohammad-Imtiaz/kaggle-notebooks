{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Shopify's Data Science Internship Fall 2021: Overview and Answers\n\nIf you are the Shopify employee reviewing my application: I did my best to display my answers at the top of the page and my work below, to help review my answers as easily as possible.\n\nIf you are a member of a general audience: this notebook is for you as well. Hopefully, this notebook will give you a peek into the skill testing questions that big tech companies could ask you.\n  \nWhile the questions for applicants seem straight forward at first, a careful inspection reveals that there is more going on beneath the surface.  \n\n\nOriginal Job Posting (Open Until May 9th, 2021):(https://jobs.smartrecruiters.com/Shopify/743999744930811-fall-2021-data-science-internship)\n","metadata":{}},{"cell_type":"markdown","source":"## Question 1\n(The following is the prompt given for our dataset. We will aim to answer all the questions).  \n  \n \nQuestion 1: Given some sample data, write a program to answer the following:   \n  \nOn Shopify, we have exactly 100 sneaker shops, and each of these shops sells only one model of shoe. We want to do some analysis of the average order value (AOV). When we look at orders data over a 30 day window, we naively calculate an AOV of $3145.13. Given that we know these shops are selling sneakers, a relatively affordable item, something seems wrong with our analysis.   \n\n#### Question 1a)\na) Think about what could be going wrong with our calculation. Think about a better way to evaluate this data.  \n#### Answer  \nGiven such a high mean value, we can assume that there are outliers present in our data set.  \nTherefore, a better metric would be Median Order Volume.  \nHowever, in the work below I demonstrate that this is not the best approach. The better way to evaluate the data is to recalculate the Average Order Volume after removing the large orders, and removing transactions involving store 78 (given that store 78 is charging $25,725 per pair of shoes).\n\n#### Question 1b)\nb) What metric would you report for this dataset?    \n#### Answer\nThe metric I use is Average Small Order Volume, after removing the over priced orders from store 78.  \n(In case of ATS: Median Order Volume)\n#### Question 1c)\nc) What is its value?  \n#### Answer\n302.58  \n(In case of ATS: 284)","metadata":{}},{"cell_type":"markdown","source":"### Question 2:\nFor this question youâ€™ll need to use SQL. Follow this link to access the data set required for the challenge. Please use queries to answer the following questions. Paste your queries along with your final numerical answers below.  \n  \n#### a) How many orders were shipped by Speedy Express in total?  \n  \nSELECT COUNT(OrderID) FROM Orders  \nWHERE ShipperID =   \n(SELECT ShipperID FROM Shippers   \nWHERE ShipperName = 'Speedy Express');  \n  \nReturns 54  \n\n#### b) What is the last name of the employee with the most orders?  \n  \nSELECT LastName FROM Employees  \nWHERE EmployeeID = (SELECT TOP 1 EmployeeID FROM   \n(SELECT EmployeeID, COUNT(OrderID) FROM Orders GROUP BY EmployeeID ORDER BY COUNT(OrderID) DESC));  \n    \nReturns Peacock    \n  \n#### c) What product was ordered the most by customers in Germany?   \n  \nSELECT ProductName FROM Products  \nWHERE ProductID IN (SELECT TOP 1 ProductID FROM OrderDetails  \nWHERE OrderID IN (  \nSELECT OrderID FROM Orders  \nWHERE CustomerID IN (SELECT CustomerID FROM Customers  \nWHERE Country = 'Germany'))  \nGROUP BY ProductID  \nORDER BY COUNT(OrderDetailID) DESC);  \n      \nReturns \"Gorgonzola Telino\"","metadata":{}},{"cell_type":"markdown","source":"### Section 1.0: The Set Up","metadata":{}},{"cell_type":"code","source":"# import our packages\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load our dataset.\ndata =  pd.read_csv('../input/shopify-data-science-internship-challenge/Shopify.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Dictionary\n\nAbove we can see the basic columns:  \n1) order_id: Unique integer that defines our order number.  \n2) shop_id: integer used to identify the shop which the order was placed.  \n3) user_id: Integer value, indicating the user who preformed the order.  \n4) order_amount: (in dollars) the value of the customer paid to the store.  \n5) total_items: Number of items (shoes in this case) bought in the order.  \n6) payment_method: cash, credit_card, debit.  \n7) created_at: date/time information when the order was placed.","metadata":{}},{"cell_type":"code","source":"# We are dealing with 5000 rows of order data.\ndata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Section 1.1 (Question 1a.)\nRecall: Naive Average Order Value was \\$3145.13, which for sneakers is very pricy.  \na) Think about what could be going wrong with our calculation. Think about a better way to evaluate this data.  ","metadata":{}},{"cell_type":"markdown","source":"The simple answer that I believe they are looking for here is Median Order Value. Its a well known technique in data analysis to use the median as the \"average\" function when there are outliers present in the data. However, before we conclude the simple answer, one must always do their due dillegence. In our case, we will first confirm our statistics, then visualize the distribution of order size to look for outliers.","metadata":{}},{"cell_type":"code","source":"# Verify Average Order Value is $3145.13, Display Median Order Value\nprint('Average Order Value:', data['order_amount'].mean(), ',',\n      'Median Order Value:', data['order_amount'].median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the distribution of order sizes.\nsns.countplot(x='total_items', data=data)\npd.DataFrame(data['total_items'].value_counts().sort_index())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aha! Our intuition is correct. We have 17 orders (0.34% of the total orders) that are massive, and thus throwing off our mean calculations.  \n  \nThe next step here is to just split our mean calculations into \"small orders\" (<10 in this case), and \"large orders\" (orders of size 2000). Interestingly, we still run into issues with this approach:","metadata":{}},{"cell_type":"code","source":"# Small and large order averages. \ndata[data['total_items'] < 10]['order_amount'].mean(), data[data['total_items'] == 2000]['order_amount'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Small Order Average is 754.09, yet the Total Median Order Value is 284.  \nThis should raise some eyebrows, why such a large discrepancy?  \n  \nSo next we ask what is the average price to a pair of shoes in our dataset, and we will finally uncover the underlying deception.","metadata":{}},{"cell_type":"code","source":"# Create a price per pair of shoes for every order.\ndata['price_per_item'] = data['order_amount']/data['total_items']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(data['price_per_item'].describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Who is charging \\$25,725 for a pair of shoes? Let us see.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(data['price_per_item'].value_counts().sort_index())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And our key insight here, all shoes are below 400, except for 46 orders which all share an outragous price tag of 25,725!  \n  \nThus, we ought to examine the heavily overpriced orders to see if there are any patterns.","metadata":{}},{"cell_type":"code","source":"normal_orders = data[data['price_per_item'] < 400 ]\nfraudulent_orders = data[data['price_per_item'] == 25725]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fraudulent_orders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And the pattern is clear as day, Shop_id = 78 is the only culprit of the fraud!","metadata":{}},{"cell_type":"code","source":"# Shop #78 has 0 orders under $400, and 46 orders priced at $25,725 per pair of shoes!!\nlen(normal_orders[normal_orders['shop_id']==78]), len(fraudulent_orders[fraudulent_orders['shop_id']==78])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So the final steps of our analysis is to filter out the overpriced orders from shop 78, and filter out the outliers in order size to get a decent handle of Average Order Volume.","metadata":{}},{"cell_type":"code","source":"new_data = data[data['shop_id'] != 78]\nnew_data_small_orders = new_data[new_data['total_items'] != 2000]\nnew_data_large_orders = new_data[new_data['total_items'] == 2000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# QED.\nnew_data_small_orders['order_amount'].mean(), new_data['order_amount'].median()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}