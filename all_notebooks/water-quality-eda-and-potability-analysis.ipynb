{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What is Potabible water\n\nAt its most basic level, potabible water relates to the safety of water. \n\nMany questions begin to emerge.\n* Are we able to consume all fresh water types?\n* What percentage of the worlds fresh water can be accessed?\n* Has the water table increased as sea levels have rised?","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T11:50:14.744126Z","iopub.execute_input":"2021-08-01T11:50:14.744726Z","iopub.status.idle":"2021-08-01T11:50:15.757536Z","shell.execute_reply.started":"2021-08-01T11:50:14.74462Z","shell.execute_reply":"2021-08-01T11:50:15.756512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Import the dataset for review as a DataFrame\ndf = pd.read_csv(\"../input/water-potability/water_potability.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.759137Z","iopub.execute_input":"2021-08-01T11:50:15.759438Z","iopub.status.idle":"2021-08-01T11:50:15.789293Z","shell.execute_reply.started":"2021-08-01T11:50:15.759408Z","shell.execute_reply":"2021-08-01T11:50:15.788315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review the first 5 observations\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.791137Z","iopub.execute_input":"2021-08-01T11:50:15.791433Z","iopub.status.idle":"2021-08-01T11:50:15.825561Z","shell.execute_reply.started":"2021-08-01T11:50:15.791402Z","shell.execute_reply":"2021-08-01T11:50:15.824399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display information about the DataFrame\ndf.info(memory_usage=\"deep\")","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.827223Z","iopub.execute_input":"2021-08-01T11:50:15.82755Z","iopub.status.idle":"2021-08-01T11:50:15.848035Z","shell.execute_reply.started":"2021-08-01T11:50:15.82752Z","shell.execute_reply":"2021-08-01T11:50:15.84693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the dataframe\nprint(df.shape)\n# Find the number of rows within a dataframe\nprint(len(df))\n# Extracting information from the shape tuple\nprint(f'Number of rows: {df.shape[0]} \\nNumber of columns: {df.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.848969Z","iopub.execute_input":"2021-08-01T11:50:15.849259Z","iopub.status.idle":"2021-08-01T11:50:15.860958Z","shell.execute_reply.started":"2021-08-01T11:50:15.849233Z","shell.execute_reply":"2021-08-01T11:50:15.859951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1a. Summary statistics","metadata":{}},{"cell_type":"code","source":"# Review the high level summary details for each variable\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.8623Z","iopub.execute_input":"2021-08-01T11:50:15.862584Z","iopub.status.idle":"2021-08-01T11:50:15.916956Z","shell.execute_reply.started":"2021-08-01T11:50:15.862556Z","shell.execute_reply":"2021-08-01T11:50:15.916027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1b. Missing values","metadata":{}},{"cell_type":"code","source":"# Check for the missing values by columns\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.918236Z","iopub.execute_input":"2021-08-01T11:50:15.918541Z","iopub.status.idle":"2021-08-01T11:50:15.928797Z","shell.execute_reply.started":"2021-08-01T11:50:15.918511Z","shell.execute_reply":"2021-08-01T11:50:15.927763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Proportion of missing values by column\ndef isnull_prop(df):\n    total_rows = df.shape[0]\n    missing_val_dict = {}\n    for col in df.columns:\n        missing_val_dict[col] = [df[col].isnull().sum(), (df[col].isnull().sum() / total_rows)]\n    return missing_val_dict\n\n# Apply the missing value method\nnull_dict = isnull_prop(df)\nprint(null_dict.items())","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.931856Z","iopub.execute_input":"2021-08-01T11:50:15.932298Z","iopub.status.idle":"2021-08-01T11:50:15.945824Z","shell.execute_reply.started":"2021-08-01T11:50:15.932252Z","shell.execute_reply":"2021-08-01T11:50:15.944558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe of the missing value information\ndf_missing = pd.DataFrame.from_dict(null_dict, orient=\"index\", columns=['missing', 'miss_percent'])\ndf_missing","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.947166Z","iopub.execute_input":"2021-08-01T11:50:15.947442Z","iopub.status.idle":"2021-08-01T11:50:15.959584Z","shell.execute_reply.started":"2021-08-01T11:50:15.947416Z","shell.execute_reply":"2021-08-01T11:50:15.958567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display missing values using a heatmap to understand if any patterns are present\nplt.figure(figsize=(15,8))\nsns.heatmap(df.isnull());","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:50:15.960769Z","iopub.execute_input":"2021-08-01T11:50:15.961062Z","iopub.status.idle":"2021-08-01T11:50:16.848878Z","shell.execute_reply.started":"2021-08-01T11:50:15.961031Z","shell.execute_reply":"2021-08-01T11:50:16.847982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set the histogram, mean and median\nsns.displot(df[\"ph\"], kde=False)\nplt.axvline(x=df.ph.mean(), linewidth=3, color='g', label=\"mean\", alpha=0.5)\nplt.axvline(x=df.ph.median(), linewidth=3, color='y', label=\"median\", alpha=0.5)\n\n# set title, legends and labels\nplt.xlabel(\"ph\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of ph\", size=14)\nplt.legend([\"mean\", \"median\"]);\n\nprint(f'Mean pH value {df.ph.mean()} \\n Median pH value {df.ph.median()} \\n Min pH value {df.ph.min()} \\n Max pH value {df.ph.max()}')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:55:27.637286Z","iopub.execute_input":"2021-08-01T11:55:27.637658Z","iopub.status.idle":"2021-08-01T11:55:28.220865Z","shell.execute_reply.started":"2021-08-01T11:55:27.637627Z","shell.execute_reply":"2021-08-01T11:55:28.219815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do these values of pH relate to actual water or are there a wider range of sources being supplied?\n![pH scale](https://www.scienceabc.com/wp-content/uploads/2019/07/A-pH-scale-on-white-background-illustration-VectorBlueRingMedias.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Predict Potability","metadata":{}},{"cell_type":"code","source":"# Preprocessing\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.feature_selection import RFE\n\n# Classifiers\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\n# Performance metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:50:54.530994Z","iopub.execute_input":"2021-07-29T22:50:54.531355Z","iopub.status.idle":"2021-07-29T22:50:54.537147Z","shell.execute_reply.started":"2021-07-29T22:50:54.531323Z","shell.execute_reply":"2021-07-29T22:50:54.536374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply mean value to the missing values\ndf['ph'].fillna(df['ph'].mean(), inplace=True)\ndf['Sulfate'].fillna(df['Sulfate'].mean(), inplace=True)\ndf['Trihalomethanes'].fillna(df['Trihalomethanes'].mean(), inplace=True)\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:39.3081Z","iopub.execute_input":"2021-07-29T22:45:39.308543Z","iopub.status.idle":"2021-07-29T22:45:39.322022Z","shell.execute_reply.started":"2021-07-29T22:45:39.308449Z","shell.execute_reply":"2021-07-29T22:45:39.320821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate into X and y variables\nX = df.drop(['Potability'], axis=1)\ny = df['Potability'].values","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:40.412991Z","iopub.execute_input":"2021-07-29T22:45:40.413347Z","iopub.status.idle":"2021-07-29T22:45:40.418832Z","shell.execute_reply.started":"2021-07-29T22:45:40.413312Z","shell.execute_reply":"2021-07-29T22:45:40.418026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the features\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:41.549795Z","iopub.execute_input":"2021-07-29T22:45:41.550338Z","iopub.status.idle":"2021-07-29T22:45:41.565938Z","shell.execute_reply.started":"2021-07-29T22:45:41.550288Z","shell.execute_reply":"2021-07-29T22:45:41.564787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Does scaling the features change the dynamics\nX_scaled = scale(X)\n\n# Print the mean and standard deviation of the unscaled features\nprint(\"Mean of Unscaled Features: {}\".format(np.mean(X))) \nprint(\"Standard Deviation of Unscaled Features: {}\".format(np.std(X)))\n\n# Print the mean and standard deviation of the scaled features\nprint(\"Mean of Scaled Features: {}\".format(np.mean(X_scaled))) \nprint(\"Standard Deviation of Scaled Features: {}\".format(np.std(X_scaled)))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:44.015707Z","iopub.execute_input":"2021-07-29T22:45:44.016597Z","iopub.status.idle":"2021-07-29T22:45:44.03417Z","shell.execute_reply.started":"2021-07-29T22:45:44.016502Z","shell.execute_reply":"2021-07-29T22:45:44.032702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# k-NN classifier\n\n# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=2, stratify=y)\n\n# Create a k-NN classifier with 7 neighbors\nknn = KNeighborsClassifier(n_neighbors=7)\n\n# Fit the classifier to the training data\nknn.fit(X_train, y_train)\n\n# Print the accuracy\nprint(knn.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:46.110121Z","iopub.execute_input":"2021-07-29T22:45:46.110491Z","iopub.status.idle":"2021-07-29T22:45:46.174275Z","shell.execute_reply.started":"2021-07-29T22:45:46.110459Z","shell.execute_reply":"2021-07-29T22:45:46.172802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets understand the performance of the k-NN classifer across a range of clusters\n# Setup arrays to store train and test accuracies\nneighbors = np.arange(1, 12)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n\n# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    # Setup a k-NN Classifier with k neighbors\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    # Fit the classifier to the training data\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = knn.score(X_train, y_train)\n\n    #Compute accuracy on the testing set\n    test_accuracy[i] = knn.score(X_test, y_test)\n\n# Generate plot\nplt.title('k-NN: Varying Number of Neighbors')\nplt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:47.54674Z","iopub.execute_input":"2021-07-29T22:45:47.547141Z","iopub.status.idle":"2021-07-29T22:45:49.317312Z","shell.execute_reply.started":"2021-07-29T22:45:47.547107Z","shell.execute_reply":"2021-07-29T22:45:49.31609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup the pipeline steps\nsteps = [('scaler', StandardScaler()),\n        ('knn', KNeighborsClassifier())]\n        \n# Create the pipeline\npipeline = Pipeline(steps)\n\n# Fit the pipeline to the training set\nknn_scaled = pipeline.fit(X_train, y_train)\n\n# Instantiate and fit a k-NN classifier to the unscaled data\nknn_unscaled = KNeighborsClassifier().fit(X_train, y_train)\n\n# Compute and print metrics\nprint('Accuracy with Scaling: {}'.format(knn_scaled.score(X_test, y_test)))\nprint('Accuracy without Scaling: {}'.format(knn_unscaled.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:51.310429Z","iopub.execute_input":"2021-07-29T22:45:51.310885Z","iopub.status.idle":"2021-07-29T22:45:51.471811Z","shell.execute_reply.started":"2021-07-29T22:45:51.310848Z","shell.execute_reply":"2021-07-29T22:45:51.470085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree classifier\n# Setup the parameters and distributions to sample\nparam_dist = {\"max_depth\": [3, None],\n              \"max_features\": randint(1, 9),\n              \"min_samples_leaf\": randint(1, 9),\n              \"criterion\": [\"gini\", \"entropy\"]}\n\n# Instantiate a Decision Tree classifier\ntree = DecisionTreeClassifier()\n\n# Instantiate the RandomizedSearchCV object\ntree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n\n# Fit it to the data\ntree_cv.fit(X, y)\n\n# Print the tuned parameters and score\nprint(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\nprint(\"Best score is {}\".format(tree_cv.best_score_))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:13:16.541293Z","iopub.execute_input":"2021-07-29T22:13:16.541625Z","iopub.status.idle":"2021-07-29T22:13:18.045245Z","shell.execute_reply.started":"2021-07-29T22:13:16.541596Z","shell.execute_reply":"2021-07-29T22:13:18.044448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelBuild():\n    # Constructor\n    def __init__(self, X, y, model=DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=8)):\n        self.X = X\n        self.y = y\n        self.model = model\n    \n    # Method to perform the train test split\n    def _train_test_split(self):\n        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=42)\n        return X_train, X_test, y_train, y_test\n    \n    # Method to set the pipeline\n    def _pipeline(self):\n        steps = [('scaler', StandardScaler()),\n                 ('model_name', self.model)]\n        return Pipeline(steps)\n    \n    # Method to run all steps\n    def model_build(self):\n        if __name__ == \"__main__\":\n            X_train, X_test, y_train, y_test = self._train_test_split()\n            pipeline = self._pipeline()\n            fit = pipeline.fit(X_train, y_train)\n            return print(\"Accuracy: {}\".format(pipeline.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:55.408759Z","iopub.execute_input":"2021-07-29T22:45:55.409273Z","iopub.status.idle":"2021-07-29T22:45:55.421656Z","shell.execute_reply.started":"2021-07-29T22:45:55.409225Z","shell.execute_reply":"2021-07-29T22:45:55.420615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ModelBuild(X, y).model_build()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:57.058702Z","iopub.execute_input":"2021-07-29T22:45:57.059061Z","iopub.status.idle":"2021-07-29T22:45:57.082158Z","shell.execute_reply.started":"2021-07-29T22:45:57.059027Z","shell.execute_reply":"2021-07-29T22:45:57.080723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeatureSelection(ModelBuild):\n    \n    # Inherit the ModelBuild features\n    def __init__(self, X, y, model=RandomForestClassifier()):\n        super().__init__(X, y, model=RandomForestClassifier())\n        self.X = X\n        self.y = y\n        self.model = model\n    \n    # Method to evaluate list of models\n    def rfe_model(self):\n        model_dict = dict()\n        for i in range(2, len(self.X.columns)):\n            rfe = RFE(estimator=self.model, n_features_to_select=i)\n            model = DecisionTreeClassifier()\n            model_dict[str(i)] = Pipeline(steps=[('rfe', rfe), ('mod', model)])\n        return model_dict\n    \n    # Method to evaluate the models\n    def eval_model(self, model):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=6)\n        scores = cross_val_score(model, self.X, self.y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n    \n    # Lets understand the features being selected\n    def feature_select(self, n_feature):\n        rfe = RFE(estimator=self.model, n_features_to_select=n_feature)\n        rfe.fit(self.X, self.y)\n#         for i in range(X.shape[1]):\n        for i, col in enumerate(X.columns):\n            print('Column: %s, Selected %s, Rank: %.3f' % (col, rfe.support_[i], rfe.ranking_[i]))   \n    \n    # Method to run all steps\n    def feature_selection(self):\n        if __name__ == \"__main__\":\n            models = self.rfe_model()\n            results, names = list(), list()\n            for name, model in models.items():\n                scores = self.eval_model(model)\n                results.append(scores)\n                names.append(name)\n                print(f'{name}, mean_score: {np.mean(scores)}, std_score: {np.std(scores)}')\n                box_plt = plt.boxplot(results, labels=names, showmeans=True)\n            return box_plt","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:45:58.906391Z","iopub.execute_input":"2021-07-29T22:45:58.907023Z","iopub.status.idle":"2021-07-29T22:45:58.919923Z","shell.execute_reply.started":"2021-07-29T22:45:58.906983Z","shell.execute_reply":"2021-07-29T22:45:58.918161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"box = FeatureSelection(X, y, model=DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=8)).feature_selection()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:25:49.676022Z","iopub.execute_input":"2021-07-29T22:25:49.676387Z","iopub.status.idle":"2021-07-29T22:25:56.538387Z","shell.execute_reply.started":"2021-07-29T22:25:49.676354Z","shell.execute_reply":"2021-07-29T22:25:56.537329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = FeatureSelection(X, y, model=DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=8)).feature_select(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:46:01.612246Z","iopub.execute_input":"2021-07-29T22:46:01.612775Z","iopub.status.idle":"2021-07-29T22:46:01.672585Z","shell.execute_reply.started":"2021-07-29T22:46:01.612724Z","shell.execute_reply":"2021-07-29T22:46:01.671416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets try a Light GBM\nfrom lightgbm import LGBMClassifier","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:46:03.734155Z","iopub.execute_input":"2021-07-29T22:46:03.734559Z","iopub.status.idle":"2021-07-29T22:46:03.739347Z","shell.execute_reply.started":"2021-07-29T22:46:03.734525Z","shell.execute_reply":"2021-07-29T22:46:03.738054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=2, stratify=y)\n\n# Instantiate the LGBM\nlgbm = LGBMClassifier()\n\n# Fit the classifier to the training data\nlgbm.fit(X_train, y_train)\n\n# Perform prediction\ny_pred = lgbm.predict(X_test)\n\n# Print the accuracy\nprint(lgbm.score(X_test, y_test))\n\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:46:04.826151Z","iopub.execute_input":"2021-07-29T22:46:04.826604Z","iopub.status.idle":"2021-07-29T22:46:04.991975Z","shell.execute_reply.started":"2021-07-29T22:46:04.826568Z","shell.execute_reply":"2021-07-29T22:46:04.990637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets understand the baseline params\nlgbm.get_params()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:46:10.957922Z","iopub.execute_input":"2021-07-29T22:46:10.958313Z","iopub.status.idle":"2021-07-29T22:46:10.964882Z","shell.execute_reply.started":"2021-07-29T22:46:10.958279Z","shell.execute_reply":"2021-07-29T22:46:10.963712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup the pipeline\nsteps = [('scaler', StandardScaler()),\n         ('lgbm', LGBMClassifier())]\n\npipeline = Pipeline(steps)\n\n# Specify the hyperparameter space\nparameters = {\n    'lgbm__learning_rate':[0.03, 0.05, 0.1],\n    'lgbm__objective':['binary'],\n    'lgbm__metric':['binary_logloss'],\n    'lgbm__max_depth':[10],\n    'lgbm__n_estimators':[100, 200, 300]\n}\n\n# Create train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Instantiate the GridSearchCV object\ncv = GridSearchCV(pipeline, parameters, cv=3)\n\n# Fit to the training set\ncv.fit(X_train, y_train)\n\n# Predict the labels of the test set\ny_pred = cv.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:49:40.036036Z","iopub.execute_input":"2021-07-29T22:49:40.036549Z","iopub.status.idle":"2021-07-29T22:49:46.47631Z","shell.execute_reply.started":"2021-07-29T22:49:40.036515Z","shell.execute_reply":"2021-07-29T22:49:46.475157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display best score and params\nprint(f'Best score : {cv.best_score_}')\nprint(f'Best params : {cv.best_params_}')\n\n# Compute and print metrics\nprint(\"Accuracy: {}\".format(cv.score(X_test, y_test)))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T22:52:52.9911Z","iopub.execute_input":"2021-07-29T22:52:52.991464Z","iopub.status.idle":"2021-07-29T22:52:53.016594Z","shell.execute_reply.started":"2021-07-29T22:52:52.991433Z","shell.execute_reply":"2021-07-29T22:52:53.015337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}