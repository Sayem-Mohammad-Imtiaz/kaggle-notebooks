{"cells":[{"metadata":{},"cell_type":"markdown","source":" # Predicting House Prices (Two-Stage Hybrid Approach)"},{"metadata":{},"cell_type":"markdown","source":"### Description\n\nA hybrid approach is applied for this dataset so that in the first stage the Linear Regression and then the Neural Networks Regression in the second stage is used. At the end of this notebook we will see that following this approach leads to achieve the value of 0.88 for R-squared. \n\nThis work has been done in collaboration with my colleagues Chiel Bakkeren, Remco Stam, Biljana Gvozdic, Yuan Li, Elangovan Krishnan and Michiel van Lunsen. "},{"metadata":{},"cell_type":"markdown","source":"### Loading and inspecting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's import the needeed libraries \nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom scipy.special import boxcox\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('../input/housesalesprediction/kc_house_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect the dataset, the first rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect the feature names\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataFrame information\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting missing values in the dataset\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Summary statistics\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization\n### Data distribution for each variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creat a dataset with only numeric columns\ndf_num = df.select_dtypes(include=['int64', 'float64'])\n\n# Histogram of the numeric columns\ndf_num.hist(bins=20, figsize=(20,20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First Stage: Multiple Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['id', 'date'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:, df.columns != 'price'].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset into train and test sets\ntrain_set, test_set = train_test_split(df, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate the linear regressior\nlr = linear_model.LinearRegression()\n\n# Define the train and test sets\nX_train = train_set.loc[:, train_set.columns != 'price']\ny_train = train_set['price']\nX_test = test_set.loc[:, train_set.columns != 'price']\ny_test = test_set['price']\n\n# Fit the model\nlr.fit(X_train, y_train)\n\n# Generate predictions\ny_pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = df.loc[:, train_set.columns != 'price'].shape[1]\nn = df.shape[0]\n# Add the new results to the result DataFrame\nresult = pd.DataFrame({\n                       'R^2(train)': lr.score(X_train, y_train), \n                       'R^2(test)': lr.score(X_test, y_test), \n                       'Adjusted R^2(train)': lr.score(X_train, y_train)-(k-1)/(n-k)*(1-lr.score(X_train, y_train)),\n                       'Adjusted R^2(test)': lr.score(X_test, y_test)-(k-1)/(n-k)*(1-lr.score(X_test, y_test)), \n                       '5-Fold Cross Validation': \n                           cross_val_score(lr, df.loc[:, df.columns != 'price'], df[['price']], cv=5).mean()\n                      }, index=['Multiple with all the features'])\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"### Feature Transformation"},{"metadata":{},"cell_type":"markdown","source":"The Box-Cox transformation is applied for a subset of the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist plot of the data\nplt.subplot(121)\ndf['price'].hist()\nplt.title('Original')\n\n# Apply the Box-Cox tranformation\ndf['boxcox_price'] = boxcox(df['price'], -0.2)\n\n# Hist plot of the data after tra\nplt.subplot(122)\ndf['boxcox_price'].hist()\nplt.title('Transformed version')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist plot of the data \nplt.subplot(121)\ndf['sqft_living'].hist()\n\n# Apply the Box-Cox transformation\ndf['boxcox_sqft_living'] = boxcox(df['sqft_living'], 0)\n\n# Hist plot the data after transformation\nplt.subplot(122)\ndf['boxcox_sqft_living'].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist plot of data \nplt.subplot(121)\ndf['sqft_lot'].hist()\n\n# Apply the Box-Cox transformation\ndf['boxcox_sqft_lot'] = boxcox(df['sqft_lot'], -0.2)\n\n# Hist plot of the data transformation\nplt.subplot(122)\ndf['boxcox_sqft_lot'].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist plot of the data \nplt.subplot(121)\ndf['sqft_above'].hist()\n\n# Applying Box-Cox\ndf['boxcox_sqft_above'] = boxcox(df['sqft_above'], 0)\n\n# Hist plot of the data after transformation\nplt.subplot(122)\ndf['boxcox_sqft_above'].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist plot of the data\nplt.subplot(121)\ndf['sqft_living15'].hist()\n\n# Applying the Box-Cox\ndf['boxcox_sqft_living15'] = boxcox(df['sqft_living15'], 0.1)\n\n# Hist plot of the data after transformation\nplt.subplot(122)\ndf['boxcox_sqft_living15'].hist()\n# Hist plot of the data after transformation\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist plot of the data\nplt.subplot(121)\ndf['sqft_lot15'].hist()\n\n# Apply the Box-Cox\ndf['boxcox_sqft_lot15'] = boxcox(df['sqft_lot15'], -0.2)\n\n# Hist plot of the data after transformation\nplt.subplot(122)\ndf['boxcox_sqft_lot15'].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection\n\nLet's just use informative features to build the model. For instance, as we consider 'zipcode', the 'lat' and 'lon' are not used. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = df[['boxcox_price', 'bedrooms', 'bathrooms', 'boxcox_sqft_living', 'boxcox_sqft_lot', 'floors', 'waterfront', \n            'view', 'condition', 'grade', 'boxcox_sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', \n            'zipcode', 'boxcox_sqft_living15', 'boxcox_sqft_lot15']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outlier Treatment\n\nOutlier removal, based on zscore, is used only for those columns that have normal distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute z-scores for selected columns\nzscores = df_new[['boxcox_price', 'boxcox_sqft_living', 'boxcox_sqft_lot','boxcox_sqft_above', \n                 'boxcox_sqft_living15', 'boxcox_sqft_lot15']].apply(stats.zscore)\nmax_abs = zscores.apply(lambda x: max(abs(x)) < 3, axis='columns')\n\n# Creat a dataset without outliers\ndf_clean = df_new.loc[max_abs, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape Before Cleaning:', df_new.shape)\nprint('Shape After Cleaning:', df_clean.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hist of the updated datset\ndf_clean.hist(figsize=(20, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing\n\nTake advantage of 'zipcode' to generate predictive features (dummy variables)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert 'zipcode' column from numeric into string type\ndf_clean['zipcode'] = df_clean['zipcode'].astype(str)\n\n# Counts of unique categories\nprint(df_clean['zipcode'].value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert categorical variable into dummy variables\ndummies = pd.get_dummies(df_clean['zipcode']).rename(columns=lambda x: 'zipcode_' + x)\n\n# Display the head of the dataframe\ndummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate the dummy dataframe and the dataset\ndf_cln = pd.concat([df_clean, dummies], axis=1)\n\n# Drop the 'zipcode' column from the dataset\ndf_cln.drop('zipcode', axis=1, inplace=True)\n\n# Display the created dataset\ndf_cln.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalization with SatndardScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate StandardScaler\nss = StandardScaler()\n\n# Applying StandardScaler (not for the dummies)\nfor column in df_cln.iloc[:, :16]:\n    df_cln[column] = ss.fit_transform(df_cln[[column]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the shape of the new dataset\ndf_cln.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = linear_model.LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(df_cln.iloc[:,1:], df_cln['boxcox_price'], test_size=0.3, random_state=42)\n\n# Fit the model\nlr.fit(X_train, y_train)\n\n# Generate prediction\ny_pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = df_cln.iloc[:, 1:].shape[1]\nn = df_cln.shape[0]\n\n# Add the new results to the result DataFrame\nresult_new = pd.DataFrame({ \n                       'R^2(train)': lr.score(X_train, y_train), \n                       'R^2(test)': lr.score(X_test, y_test), \n                       'Adjusted R^2(train)': lr.score(X_train, y_train)-(k-1)/(n-k)*(1-lr.score(X_train, y_train)),\n                       'Adjusted R^2(test)': lr.score(X_test, y_test)-(k-1)/(n-k)*(1-lr.score(X_test, y_test)), \n                       '5-Fold Cross Validation': \n                           cross_val_score(lr, df_cln.iloc[:, 1:], df_cln['boxcox_price'], cv=5).mean()\n                      }, index=['Processed data '])\nresult = result.append(result_new)\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, with the help of data preprocessing and feature engineering, we have been able to achieve a value higher than 0.87 for R-squared. Now let's see if neural network regressor can further improve this accuracy. "},{"metadata":{},"cell_type":"markdown","source":"# Second Stage: Neural Network Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_lr = lr.predict(X_train)\ny_error = y_train - y_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow\ntensorflow.random.set_seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasRegressor\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.layers.normalization import BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nnnr = Sequential()\nnnr.add(Dense(128, input_dim=X_train.shape[1], kernel_regularizer=regularizers.l2(0.01), activation='relu'))\nnnr.add(Dense(64, activation='relu'))\nnnr.add(Dropout(0.5))\nnnr.add(Dense(1))\nnnr.summary()\n# Compile model\nnnr.compile(loss='mse', optimizer='rmsprop')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model training\ntraining = nnr.fit(X_train, y_error, validation_split=0.2, verbose =1, epochs=100, batch_size=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(training.history['loss'])\nplt.plot(training.history['val_loss'])\nplt.title(\"Model's Training & Validation loss across epochs\")\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a flat list\nl = nnr.predict(X_test)\n\ny_nnr = []\nfor sublist in l:\n    for item in sublist:\n        y_nnr.append(item)\n\n        \ny_hybrid = lr.predict(X_test) + y_nnr\ny_hybrid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, y_hybrid)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import pearsonr\ncorr, _ = pearsonr(y_test, y_hybrid)\nprint('R^2: %.3f'% corr**2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"The above result shows that the follow-up model can slightly improve the accuracy with the R-squared of greater than 0.88. \n\nI hope you like this work. Cheers!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}