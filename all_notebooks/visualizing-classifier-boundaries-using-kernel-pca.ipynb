{"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi Everyone!\n\nThis is one of my first kernels on Kaggle, so any input is appreciated. Like many people starting out with machine learning, visualizing classification boundaries in high dimensions is often difficult to comprehend. I intended this kernel to teach me how different classifiers place boundaries in feature space. Ofcourse since we are limited to how many dimensions we can visualize, I used different types to kernel PCA's to see their effect on different types of classifiers. Lets go ahead and load the data/libraries","metadata":{"_uuid":"ee32bf0bb18f8f190af00c4dddaf2b9d5f4b9660","_cell_guid":"5856f3f4-338a-4b38-bbc8-8056e485dc16"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"9c5cbfcba3c182dbfaa9f8e17037f7f68e5d1a70","_cell_guid":"84b699f0-b149-4146-a348-a9ffb6160a9d"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import KernelPCA\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom matplotlib.colors import ListedColormap\n\ndata = pd.read_csv('../input/data.csv')\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n","execution_count":null},{"cell_type":"markdown","source":"Checking for missing values... Looks like one of the columns is missing data for all the rows. We can go ahead and eliminate it.","metadata":{"_uuid":"adb7acce5fd00896302615c3abadb45438fc0922","_cell_guid":"ad24cfd9-7187-411c-b37d-2ec45ec2a35a"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"fc834250aad97a39e02c89b4846eeaf83dbc00a8","_cell_guid":"380758a1-cb16-4f22-8fbd-c08f363e8548"},"cell_type":"code","source":"data.isnull().sum()\ndata.drop('Unnamed: 32', axis = 1, inplace = True )","execution_count":null},{"cell_type":"markdown","source":"We can count how many people have malignant and benign tumors . Now lets also split the data into our features and labels, then map our labels to integers.","metadata":{"_uuid":"5b15794addf92e9d98bcdb3a0b090098a490f8b8","_cell_guid":"64c4f344-746a-4c7e-9cda-a3422b6cf474"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"28117b84000fe65adf33d7e15663e786688773e1","_cell_guid":"bd3f79cb-4df0-4682-b335-60dfae5d5156"},"cell_type":"code","source":"\nsns.countplot(x = 'diagnosis', data = data)\n\n\nx = data.iloc[:, 3:]\n\ny = data.diagnosis\ny = y.map({'M':1,'B':0})","execution_count":null},{"cell_type":"markdown","source":"The features looks like they are broken into three main categories, value means, standard deivations, and 'worst'. We can check to see if there are any correlations between these subsets of features","metadata":{"_uuid":"bd3eea45761c98830ee7f6c90b23bff53daa16d5","_cell_guid":"cc34d27c-886b-4504-ba32-012c583bfac8"}},{"outputs":[],"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"825d148e929e0b1082be7982c7f30e9dcb3115cf","collapsed":true,"_cell_guid":"0fb6c3ee-2949-41c8-9ae1-4e38a9c68805"},"cell_type":"code","source":"x.columns\nfeatures_mean = x.columns[1:9]\nfeatures_se = x.columns[9:19]\nfeatures_worst = x.columns[19:]\n\n#Correlation between sets of features\ncorr = x[features_mean].corr()\ng = sns.heatmap(corr, cbar = True, annot=True, annot_kws={'size': 15}, fmt= '.2f', square = True, cmap = 'coolwarm' )\ng.set_xticklabels(rotation=90, labels = features_mean, size = 15)\ng.set_yticklabels(rotation=0, labels = features_mean, size = 15)\ng.set_xticks(np.arange(.5,9.5,1))\nplt.rcParams[\"figure.figsize\"] = (15,15)\n\n\n\n","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"c720c1133c95d752a21d82cf9faeb67d71dd470a","_cell_guid":"4f6f5601-b695-46b9-a04b-03cae8ddd281"},"cell_type":"code","source":"corr = x[features_se].corr()\ng = sns.heatmap(corr, cbar = True, annot=True, annot_kws={'size': 15}, fmt= '.2f', square = True, cmap = 'coolwarm' )\ng.set_xticklabels(rotation=90, labels = features_se, size = 15)\ng.set_yticklabels(rotation=0, labels = features_se, size = 15)\ng.set_xticks(np.arange(.5,10.5,1))\nplt.rcParams[\"figure.figsize\"] = (15,15)","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"4f0d478bac92f3031352aea22f9ec9ef03884c64","_cell_guid":"9647267f-91cc-49e7-87b3-1f416ca22afb"},"cell_type":"code","source":"corr = x[features_worst].corr()\ng = sns.heatmap(corr, cbar = True, annot=True, annot_kws={'size': 15}, fmt= '.2f', square = True, cmap = 'coolwarm' )\ng.set_xticklabels(      rotation=90, labels = features_worst, size = 15)\ng.set_yticklabels(rotation=0, labels = features_worst, size = 15)\ng.set_xticks(np.arange(.5,10.5,1))\nplt.rcParams[\"figure.figsize\"] = (15,15)","execution_count":null},{"cell_type":"markdown","source":"Lets go ahead and move on to preprocessing our data in order to apply our ML classifiers. In addition, we need to break out or data into a training and test set","metadata":{"_uuid":"f1f773b076f2284a50d8e833a0d6984d9904b377","_cell_guid":"7de8330c-7164-4c8f-91b5-66e8c3b27462"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"03da0363c6f07a79ff5a0d2b86f28f6895b67fc3","_cell_guid":"68163d03-b4f0-4fcf-b1c7-c0f6d9186912"},"cell_type":"code","source":"scaler = StandardScaler()\nx = scaler.fit_transform(x)\n\n\n#Split data to get hold out test set\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .1)","execution_count":null},{"cell_type":"markdown","source":"The next chunk of code will help us automate the next few steps. This function accepts three inputs:\n1) The kernel used for PCA\n2) Which classifier we will be using\n3) The name of the classifier (used for plot title)\n\nOn the advice of some comments I decided to create a large subplot which will show the summary of boundary lines for each classifier and kernel PCA. This is a consice way of looking at the boundary lines, however I have kept the original breakdown of the test and training boundary lines below if you would like further detail. As you can see some of the arguments for this function are not needed for this summary plot, however all the arguments are needed for the graphs below.","metadata":{"_uuid":"a662f7810201af981f5a28b8e44a77e3baff5401","_cell_guid":"1aaa4c45-de61-456a-bcdd-86631430f46b"}},{"outputs":[],"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"195a20bc572258a911722cc75a538cae0e0364ba","collapsed":true,"_cell_guid":"d7be44f8-7d33-42cb-9602-b0090f988481"},"cell_type":"code","source":"def BoundaryLine(kernel, algo, algo_name):\n    reduction = KernelPCA(n_components=2, kernel = kernel)\n    x_train_reduced = reduction.fit_transform(x_train)\n    x_test_reduced = reduction.transform(x_test)\n    \n    classifier = algo\n    classifier.fit(x_train_reduced, y_train)\n    \n    y_pred = classifier.predict(x_test_reduced)\n    \n\n    #Boundary Line\n    X_set, y_set = np.concatenate([x_train_reduced, x_test_reduced], axis = 0), np.concatenate([y_train, y_test], axis = 0)\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.5, cmap = ListedColormap(('red', 'green')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green'))(i), label = j)\n    #plt.title('{} Boundary Line with {} PCA' .format(algo_name, kernel))\n    #plt.xlabel('Component 1')\n    #plt.ylabel('Component 2')\n    #plt.legend()\n    plt.xticks(fontsize = 3)\n    plt.yticks(fontsize = 3)\n\n    \n\n\n\n\n\n","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"3af52a9f8521d513ac4661eb9881b1ccf760f858","_cell_guid":"839a0b44-a2e3-4b98-9e9d-0e14da7ec92a"},"cell_type":"code","source":"fig = plt.figure()\n\nfig.suptitle('Classifiers and Kernel PCA')\n#Logistic Regression   \nfrom sklearn.linear_model import LogisticRegression\nax = plt.subplot(7,5,1)\nax.set_title('Linear PCA')\nax.set_ylabel('Logistic \\n Regression', rotation = 0, labelpad=30, fontsize = 10)\nBoundaryLine('linear', LogisticRegression(), \"Logistic Regression\")\n\nax = plt.subplot(7,5,2)\nax.set_title('RBF PCA')\nBoundaryLine('rbf', LogisticRegression(), \"Logistic Regression\")\n\nax = plt.subplot(7,5,3)\nax.set_title('Poly PCA')\nBoundaryLine('poly', LogisticRegression(), \"Logistic Regression\")\n\nax = plt.subplot(7,5,4)\nax.set_title('Sigmoid PCA')\nBoundaryLine('sigmoid', LogisticRegression(), \"Logistic Regression\")\n\nax = plt.subplot(7,5,5)\nax.set_title('Cosine PCA')\nBoundaryLine('cosine', LogisticRegression(), \"Logistic Regression\")\n\n\n#Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nax = plt.subplot(7,5,6)\nax.set_ylabel('Naive \\n Bayes', rotation = 0, labelpad=30, fontsize = 10)\nBoundaryLine('linear', GaussianNB(), \"Naive Bayes\")\nax = plt.subplot(7,5,7)\nBoundaryLine('rbf', GaussianNB(), \"Naive Bayes\")\nax = plt.subplot(7,5,8)\nBoundaryLine('poly', GaussianNB(), \"Naive Bayes\")\nax = plt.subplot(7,5,9)\nBoundaryLine('sigmoid', GaussianNB(), \"Naive Bayes\")\nax = plt.subplot(7,5,10)\nBoundaryLine('cosine', GaussianNB(), \"Naive Bayes\")\n\n#K-Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nax = plt.subplot(7,5,11)\nax.set_ylabel('KNN', rotation = 0, labelpad=30, fontsize = 10)\nBoundaryLine('linear', KNeighborsClassifier(), \"KNN\")\nax = plt.subplot(7,5,12)\nBoundaryLine('rbf', KNeighborsClassifier(), \"KNN\")\nax = plt.subplot(7,5,13)\nBoundaryLine('poly', KNeighborsClassifier(), \"KNN\")\nax = plt.subplot(7,5,14)\nBoundaryLine('sigmoid', KNeighborsClassifier(), \"KNN\")\nax = plt.subplot(7,5,15)\nBoundaryLine('cosine', KNeighborsClassifier(), \"KNN\")\n\n#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nax = plt.subplot(7,5,16)\nax.set_ylabel('Random \\n Forest', rotation = 0, labelpad=30, fontsize = 10)\nBoundaryLine('linear', RandomForestClassifier(), \"Random Forest\")\nax = plt.subplot(7,5,17)\nBoundaryLine('rbf', RandomForestClassifier(), \"Random Forest\")\nax = plt.subplot(7,5,18)\nBoundaryLine('poly', RandomForestClassifier(), \"Random Forest\")\nax = plt.subplot(7,5,19)\nBoundaryLine('sigmoid', RandomForestClassifier(), \"Random Forest\")\nax = plt.subplot(7,5,20)\nBoundaryLine('cosine', RandomForestClassifier(), \"Random Forest\")\n\n#Support Vector - linear\nfrom sklearn.svm import SVC\nax = plt.subplot(7,5,21)\nax.set_ylabel('SVM \\n Linear', rotation = 0, labelpad=30, fontsize = 10)\nBoundaryLine('linear', SVC(kernel = 'linear'), \"SVM - Linear\")\nax = plt.subplot(7,5,22)\nBoundaryLine('rbf', SVC(kernel = 'linear'), \"SVM - Linear\")\nax = plt.subplot(7,5,23)\nBoundaryLine('poly', SVC(kernel = 'linear'), \"SVM - Linear\")\nax = plt.subplot(7,5,24)\nBoundaryLine('sigmoid', SVC(kernel = 'linear'), \"SVM - Linear\")\nax = plt.subplot(7,5,25)\nBoundaryLine('cosine', SVC(kernel = 'linear'), \"SVM - Linear\")\n\n#Support Vector - RBF\nax = plt.subplot(7,5,26)\nax.set_ylabel('SVM \\n rbf', rotation = 0, labelpad=30, fontsize = 10)\nBoundaryLine('linear', SVC(kernel = 'rbf'), \"SVM - rbf\")\nax = plt.subplot(7,5,27)\nBoundaryLine('rbf', SVC(kernel = 'rbf'), \"SVM - rbf\")\nax = plt.subplot(7,5,28)\nBoundaryLine('poly', SVC(kernel = 'rbf'), \"SVM - rbf\")\nax = plt.subplot(7,5,29)\nBoundaryLine('sigmoid', SVC(kernel = 'rbf'), \"SVM - rbf\")\nax = plt.subplot(7,5,30)\nBoundaryLine('cosine', SVC(kernel = 'rbf'), \"SVM - rbf\")\n\n\n#Support Vector - Poly\nax = plt.subplot(7,5,31)\nax.set_ylabel('SVM \\n poly', rotation = 0, labelpad=30, fontsize = 10)\nBoundaryLine('linear', SVC(kernel = 'poly'), \"SVM - poly\")\nax = plt.subplot(7,5,32)\nBoundaryLine('rbf', SVC(kernel = 'poly'), \"SVM - poly\")\nax = plt.subplot(7,5,33)\nBoundaryLine('poly', SVC(kernel = 'poly'), \"SVM - poly\")\nax = plt.subplot(7,5,34)\nBoundaryLine('sigmoid', SVC(kernel = 'poly'), \"SVM - poly\")\nax = plt.subplot(7,5,35)\nBoundaryLine('cosine', SVC(kernel = 'poly'), \"SVM - poly\")\n\nfig.show()","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"842cc17f7e9bb7aea5f0a8dbd5c3c0e5a4abf659","_cell_guid":"01a41582-2e4d-4f0e-9d84-899fc4189b93"},"cell_type":"code","source":"def BoundaryLine(kernel, algo, algo_name):\n    reduction = KernelPCA(n_components=2, kernel = kernel)\n    x_train_reduced = reduction.fit_transform(x_train)\n    x_test_reduced = reduction.transform(x_test)\n    \n    classifier = algo\n    classifier.fit(x_train_reduced, y_train)\n    \n    y_pred = classifier.predict(x_test_reduced)\n    \n    print(confusion_matrix(y_test, y_pred))\n    print(classification_report(y_test, y_pred))\n    \n    plt.subplot(2,1,1)\n    #Train set boundary\n    X_set, y_set = x_train_reduced, y_train\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('red', 'green')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green'))(i), label = j)\n    plt.title('{} Boundary Line with {} PCA (Train Set)' .format(algo_name, kernel))\n    plt.xlabel('Component 1')\n    plt.ylabel('Component 2')\n    plt.legend()\n    \n    \n    plt.subplot(2,1,2)\n    #Test set boundary\n    X_set, y_set = x_test_reduced, y_test\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('red', 'green')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green'))(i), label = j)\n    plt.title('{} Boundary Line with {} PCA (Test Set)' .format(algo_name, kernel))\n    plt.xlabel('Component 1')\n    plt.ylabel('Component 2')\n    plt.legend()\n    plt.tight_layout()","execution_count":null},{"cell_type":"markdown","source":"\n\nThis function is a modified from the one created above. In addition to the boundary lines, it will output the confusion matrix, classification report, and graph of the decision boundary on both the training and test set.\n\nThe next parts will have very little commentary but hopefully you will get the gist of it. There will be multiple classifiers used under different PCA conditions. Lets see what happens!","metadata":{"_uuid":"86b3354f1d446bbd4e9ac8b891ed8f4ff89f5aa5","_cell_guid":"afcd6620-0cd4-4b78-960f-965284cc9c05"}},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"dab804877f5d203dd37867a68437d86ba82e9446","_cell_guid":"8e49971d-ce6a-4c1d-af38-4f6040f6f47c"},"cell_type":"code","source":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"f013984a212a42fa2e21a7a9255d03baa9742165","_cell_guid":"bc985a32-d98d-4f84-92dd-edf385229ca9"},"cell_type":"code","source":"BoundaryLine('linear', LogisticRegression(), \"Logistic Regression\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"4e12f7828332a1440e4b3c6c99d0ba976de0852f","_cell_guid":"67d4f92e-dab2-4d1e-819a-acfe05b9136e"},"cell_type":"code","source":"BoundaryLine('rbf', LogisticRegression(), \"Logistic Regression\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"98fe639605aa34451feda6e0a7561391a2be3f56","_cell_guid":"4faa5f77-a27e-4168-b5f7-84b75de345ea"},"cell_type":"code","source":"BoundaryLine('poly', LogisticRegression(), \"Logistic Regression\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"8709cd4d1e64b8456ecfe2d63fb6d0e0a9d34831","_cell_guid":"627d39bc-3dda-4433-8e06-de485940ab89"},"cell_type":"code","source":"BoundaryLine('sigmoid', LogisticRegression(), \"Logistic Regression\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"1af3da7c45d36e1f6c65ffc7a0fc430e85fd9bb7","_cell_guid":"2ad3f59c-dc2f-4932-9258-eda0aabaa5ff"},"cell_type":"code","source":"BoundaryLine('cosine', LogisticRegression(), \"Logistic Regression\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"0e4c36de1d89f1ee730ad723d0b7407763958b6c","_cell_guid":"76887b12-39ea-4181-95b6-5d6c56c860d6"},"cell_type":"code","source":"#Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"3697ce9054c7cc62acc30ec5709039cacfd95060","_cell_guid":"e4c0db49-afdf-42fa-a4e2-991c7fd240ec"},"cell_type":"code","source":"BoundaryLine('linear', GaussianNB(), \"Naive Bayes\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"491fb15472b79152743f3c34d6ddf1db24668d43","_cell_guid":"9c97242c-6beb-4ab2-8645-0131ed20c5de"},"cell_type":"code","source":"BoundaryLine('rbf', GaussianNB(), \"Naive Bayes\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"4ea173d0b478df9fbbfbbc18fa06e858173a62c5","_cell_guid":"1fef4114-696d-4cfd-8155-4da14e9cf673"},"cell_type":"code","source":"BoundaryLine('poly', GaussianNB(), \"Naive Bayes\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"29c23e08331bb339c4499c49498fdded880cd436","_cell_guid":"79bba9eb-ab02-4fb1-ae41-d0ccb7807339"},"cell_type":"code","source":"BoundaryLine('sigmoid', GaussianNB(), \"Naive Bayes\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"b5a875df21476d2d089969877ee8e69386ce46a8","_cell_guid":"8b9392c6-d07f-41db-ac7f-548db65a14f7"},"cell_type":"code","source":"BoundaryLine('cosine', GaussianNB(), \"Naive Bayes\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"8d2c480bcbf2a85448046abf4c0576e608128c5b","_cell_guid":"26a0d6cc-f983-4db6-ad79-bbcb93397b8d"},"cell_type":"code","source":"#K-Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"3eba039c5576055601cea9cbe06678a28e4964aa","_cell_guid":"18acdfcd-b61e-4834-85ac-4efe6a565d57"},"cell_type":"code","source":"BoundaryLine('linear', KNeighborsClassifier(), \"KNN\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"39c29c3f3b9391aa9e63c840386f27e2b205f8a4","_cell_guid":"9fb2e368-2ea8-4e51-8a3d-62e21f095f9e"},"cell_type":"code","source":"BoundaryLine('rbf', KNeighborsClassifier(), \"KNN\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"497eb6c70b3d52abdeb0dd707564d6edac7f01d0","_cell_guid":"e10c27d2-8428-493a-8aee-d66526b71cb0"},"cell_type":"code","source":"BoundaryLine('poly', KNeighborsClassifier(), \"KNN\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"f73e9bdda610bde888647166c64302858c284dda","_cell_guid":"2972df59-e8f5-4a30-bb36-e98bfea89780"},"cell_type":"code","source":"BoundaryLine('sigmoid', KNeighborsClassifier(), \"KNN\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"8852f6075264604284dad11cc93a2646ba4d51b9","_cell_guid":"761f1314-6831-4740-9b97-1ec68651083a"},"cell_type":"code","source":"BoundaryLine('cosine', KNeighborsClassifier(), \"KNN\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"2f76b2e97f86273b4c8ecdee797189380e80159c","_cell_guid":"8f7e948b-1b53-413e-95a0-550cc8773de4"},"cell_type":"code","source":"#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"b4c80ad3f28d7e74092150ed305487972ea81af6","_cell_guid":"28a6eabf-3479-4e91-9bb4-265bf641c6d5"},"cell_type":"code","source":"BoundaryLine('linear', RandomForestClassifier(), \"Random Forest\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"60fd6133194bb33713f5c87adbd596a01e893a8b","_cell_guid":"4adbb08d-2181-47a4-8e3e-7a8cb6dffaed"},"cell_type":"code","source":"BoundaryLine('rbf', RandomForestClassifier(), \"Random Forest\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"dcbfd07c9139a7f88cce86b6d377c34cc22765cc","_cell_guid":"e556940d-0142-41a1-9c00-ec18701a7f14"},"cell_type":"code","source":"BoundaryLine('poly', RandomForestClassifier(), \"Random Forest\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"7082414c0826052857774458d2275e8a312e4224","_cell_guid":"72d37751-d164-48a7-a2c3-ebe19a0036b9"},"cell_type":"code","source":"BoundaryLine('sigmoid', RandomForestClassifier(), \"Random Forest\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"8b698019d21496c19438c6e796e65190f5d1545a","_cell_guid":"6a9ebde4-fb6f-45c4-8523-6f2b24b67f32"},"cell_type":"code","source":"BoundaryLine('cosine', RandomForestClassifier(), \"Random Forest\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"30a8916eb37b3914b72dfbe3af8c28e2aad5b1d9","_cell_guid":"9badb604-5a2d-4db1-ab90-45d906e2f2f3"},"cell_type":"code","source":"#Support Vector - linear\nfrom sklearn.svm import SVC","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"a3f2f2bd2729d6183308e00739f90bbfd6fb0865","_cell_guid":"ace66cc9-9910-4080-a15a-cc67e89ccc4f"},"cell_type":"code","source":"BoundaryLine('linear', SVC(kernel = 'linear'), \"SVM - Linear\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"2f0fd6591b1660f569446764fa7bb8fc3cfa64d8","_cell_guid":"8e200a08-3b52-42b3-8a73-8d17f005d20e"},"cell_type":"code","source":"BoundaryLine('rbf', SVC(kernel = 'linear'), \"SVM - Linear\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"9ab4b1788a3415d7ad47a8432ade7c7b49e21d7c","_cell_guid":"9ab1693a-5872-4dcb-a8a7-7904c55458dc"},"cell_type":"code","source":"BoundaryLine('poly', SVC(kernel = 'linear'), \"SVM - Linear\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"344c0ed7964ec7ac6181f308f2ed8112de0d7ce1","_cell_guid":"17053422-a6de-42be-b4be-ad838a75477b"},"cell_type":"code","source":"BoundaryLine('sigmoid', SVC(kernel = 'linear'), \"SVM - Linear\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"5103fbbb7c1bd32aaaeb042be70f3e9325e8b24a","_cell_guid":"2c130784-84d7-4aad-9616-f3a13fd70361"},"cell_type":"code","source":"BoundaryLine('cosine', SVC(kernel = 'linear'), \"SVM - Linear\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"91863f1d18dfee962809693000f13368a0a84bf9","_cell_guid":"732ac4b7-48a6-4a31-bdfe-0723c1d2d1c1"},"cell_type":"code","source":"#Support Vector - RBF\nBoundaryLine('linear', SVC(kernel = 'rbf'), \"SVM - rbf\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"b7adf9ebe93ff7c58e5f2147e3a6992eb30fa261","_cell_guid":"b29ec3ec-46a8-49b3-ba37-e17f693d7485"},"cell_type":"code","source":"BoundaryLine('rbf', SVC(kernel = 'rbf'), \"SVM - rbf\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"6618a0637e8ce9be60183bbd4ff8ee8311ee8700","_cell_guid":"82dfbe3f-387f-4471-8333-96d864971a8b"},"cell_type":"code","source":"BoundaryLine('poly', SVC(kernel = 'rbf'), \"SVM - rbf\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"a39dfe0253a2409f9680ba6425f95e43e2854620","_cell_guid":"56ff2720-b0c0-43f9-8f99-bd3367b4c5a4"},"cell_type":"code","source":"BoundaryLine('sigmoid', SVC(kernel = 'rbf'), \"SVM - rbf\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"53a2fe348e1258361a1a9b067917b0014995fe74","_cell_guid":"42c23073-3c56-4ed4-bef0-ac333c1072e7"},"cell_type":"code","source":"BoundaryLine('cosine', SVC(kernel = 'rbf'), \"SVM - rbf\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"bc482c326c18d29f9b7eef07ba2809e7f6d00e23","_cell_guid":"8f4ed11b-7355-4b4f-891d-c96df20ae465"},"cell_type":"code","source":"#Support Vector - Poly\nBoundaryLine('linear', SVC(kernel = 'poly'), \"SVM - poly\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"1915784723e8505e7bf0dc4b0cbedfb768dc69be","_cell_guid":"22d3030c-7818-4503-88b6-afef5ce871d6"},"cell_type":"code","source":"BoundaryLine('rbf', SVC(kernel = 'poly'), \"SVM - poly\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"f3bb4ec5114721e28b82ccbe0b7010e084e1985e","_cell_guid":"28498f22-12bb-4f55-8a2d-bddb9683ae6c"},"cell_type":"code","source":"BoundaryLine('poly', SVC(kernel = 'poly'), \"SVM - poly\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"b85b7c1cd66b4bd74282f264e335b71787a2ce27","_cell_guid":"6bfdac45-bf23-4b34-9b93-eeebeb596df2"},"cell_type":"code","source":"BoundaryLine('sigmoid', SVC(kernel = 'poly'), \"SVM - poly\")","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"b6cea8b2facfb58296eddd002075660c6cafa1bd","_cell_guid":"aa1dfed8-61e5-4236-8c1b-ebbb85877279"},"cell_type":"code","source":"BoundaryLine('cosine', SVC(kernel = 'poly'), \"SVM - poly\")","execution_count":null}],"nbformat_minor":1,"metadata":{"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","name":"python","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}}}