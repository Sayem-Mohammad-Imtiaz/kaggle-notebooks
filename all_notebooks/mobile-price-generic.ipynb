{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T02:25:31.552146Z","iopub.execute_input":"2021-06-11T02:25:31.552517Z","iopub.status.idle":"2021-06-11T02:25:31.57295Z","shell.execute_reply.started":"2021-06-11T02:25:31.55244Z","shell.execute_reply":"2021-06-11T02:25:31.569903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\nimport numpy as np\nfrom optparse import OptionParser\nimport sys\nfrom time import time\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.extmath import density\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nm1_file_path = '/kaggle/input/mobile-price-classification/train.csv'\nm2_file_path = '/kaggle/input/mobile-price-classification/test.csv'\n\nm_tr = pd.read_csv(m1_file_path) \nm_ts = pd.read_csv(m2_file_path)\n\n\n\ndata_train= m_tr\ndata_test = m_ts\n\n\nmobile_features = ['blue', 'battery_power', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n       'touch_screen', 'wifi','price_range']  \n\nmobile_features1 = ['ram',  'talk_time']  \noutput = ['price_range']\n\ndata_train = data_train[mobile_features]\nY = m_tr[output]\n\ny = Y.values.ravel() \nX_train,X_test, y_train,y_test = train_test_split(data_train,y,test_size=0.20, shuffle = True) \n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:25:31.574647Z","iopub.execute_input":"2021-06-11T02:25:31.575019Z","iopub.status.idle":"2021-06-11T02:25:32.864192Z","shell.execute_reply.started":"2021-06-11T02:25:31.574984Z","shell.execute_reply":"2021-06-11T02:25:32.863485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s %(levelname)s %(message)s')\n\n\n\nop = OptionParser()\nop.add_option(\"--report\",\n              action=\"store_true\", dest=\"print_report\",\n              help=\"Print a detailed classification report.\")\nop.add_option(\"--chi2_select\",\n              action=\"store\", type=\"int\", dest=\"select_chi2\",\n              help=\"Select some number of features using a chi-squared test\")\nop.add_option(\"--confusion_matrix\",\n              action=\"store_true\", dest=\"print_cm\",\n              help=\"Print the confusion matrix.\")\nop.add_option(\"--top10\",\n              action=\"store_true\", dest=\"print_top10\",\n              help=\"Print ten most discriminative terms per class\"\n                   \" for every classifier.\")\nop.add_option(\"--all_categories\",\n              action=\"store_true\", dest=\"all_categories\",\n              help=\"Whether to use all categories or not.\")\nop.add_option(\"--use_hashing\",\n              action=\"store_true\",\n              help=\"Use a hashing vectorizer.\")\nop.add_option(\"--n_features\",\n              action=\"store\", type=int, default=2 ** 16,\n              help=\"n_features when using the hashing vectorizer.\")\nop.add_option(\"--filtered\",\n              action=\"store_true\",\n              help=\"Remove newsgroup information that is easily overfit: \"\n                   \"headers, signatures, and quoting.\")\n\ndef is_interactive():\n    return not hasattr(sys.modules['__main__'], '__file__')\n\n\n# work-around for Jupyter notebook and IPython console\nargv = [] if is_interactive() else sys.argv[1:]\n(opts, args) = op.parse_args(argv)\nif len(args) > 0:\n    op.error(\"this script takes no arguments.\")\n    sys.exit(1)\n\nprint(__doc__)\nop.print_help()\nprint()\n\n\n# %%\n# Benchmark classifiers\n# ------------------------------------\n# We train and test the datasets with 15 different classification models\n# and get performance results for each model.\ndef benchmark(clf):\n    print('_' * 80)\n    print(\"Training: \")\n    print(clf)\n    t0 = time()\n    clf.fit(X_train, y_train)\n    train_time = time() - t0\n    print(\"train time: %0.3fs\" % train_time)\n\n    t0 = time()\n    pred = clf.predict(X_test)\n    test_time = time() - t0\n    print(\"test time:  %0.3fs\" % test_time)\n\n    score = metrics.accuracy_score(y_test, pred)\n    print(\"accuracy:   %0.3f\" % score)\n\n    if hasattr(clf, 'coef_'):\n        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n        print(\"density: %f\" % density(clf.coef_))\n\n        if opts.print_top10 and feature_names is not None:\n            print(\"top 10 keywords per class:\")\n            for i, label in enumerate(target_names):\n                top10 = np.argsort(clf.coef_[i])[-10:]\n                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n        print()\n\n    if opts.print_report:\n        print(\"classification report:\")\n        print(metrics.classification_report(y_test, pred,\n                                            target_names=target_names))\n\n    if opts.print_cm:\n        print(\"confusion matrix:\")\n        print(metrics.confusion_matrix(y_test, pred))\n\n    print()\n    clf_descr = str(clf).split('(')[0]\n    return clf_descr, score, train_time, test_time\n# Train Data in 15 Models \nresults = []\nfor clf, name in (\n        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n        (Perceptron(max_iter=50), \"Perceptron\"),\n        (PassiveAggressiveClassifier(max_iter=50),\n         \"Passive-Aggressive\"),\n        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n        (RandomForestClassifier(), \"Random forest\")):\n    print('=' * 80)\n    print(name)\n    results.append(benchmark(clf))\n\nfor penalty in [\"l2\", \"l1\"]:\n    print('=' * 80)\n    print(\"%s penalty\" % penalty.upper())\n    # Train Liblinear model\n    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n                                       tol=1e-3)))\n\n    # Train SGD model\n    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n                                           penalty=penalty)))\n\n# Train SGD with Elastic Net penalty\nprint('=' * 80)\nprint(\"Elastic-Net penalty\")\nresults.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n                                       penalty=\"elasticnet\")))\n\n# Train NearestCentroid without threshold\nprint('=' * 80)\nprint(\"NearestCentroid (aka Rocchio classifier)\")\nresults.append(benchmark(NearestCentroid()))\n\n# Train sparse Naive Bayes classifiers\nprint('=' * 80)\nprint(\"Naive Bayes\")\nresults.append(benchmark(MultinomialNB(alpha=.01)))\nresults.append(benchmark(BernoulliNB(alpha=.01)))\nresults.append(benchmark(ComplementNB(alpha=.1)))\n\nprint('=' * 80)\nprint(\"LinearSVC with L1-based feature selection\")\n# The smaller C, the stronger the regularization.\n# The more regularization, the more sparsity.\nresults.append(benchmark(Pipeline([\n  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n                                                  tol=1e-3))),\n  ('classification', LinearSVC(penalty=\"l2\"))])))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:25:39.076758Z","iopub.execute_input":"2021-06-11T02:25:39.077369Z","iopub.status.idle":"2021-06-11T02:25:40.644824Z","shell.execute_reply.started":"2021-06-11T02:25:39.077334Z","shell.execute_reply":"2021-06-11T02:25:40.643294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%\n# Add plots\n# ------------------------------------\n# The bar plot indicates the accuracy, training time (normalized) and test time\n# (normalized) of each classifier.\nindices = np.arange(len(results))\n\nresults = [[x[i] for x in results] for i in range(4)]\n\nclf_names, score, training_time, test_time = results\ntraining_time = np.array(training_time) / np.max(training_time)\ntest_time = np.array(test_time) / np.max(test_time)\n\nplt.figure(figsize=(12, 8))\nplt.title(\"Score\")\nplt.barh(indices, score, .2, label=\"score\", color='navy')\nplt.barh(indices + .3, training_time, .2, label=\"training time\",\n         color='c')\nplt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\nplt.yticks(())\nplt.legend(loc='best')\nplt.subplots_adjust(left=.25)\nplt.subplots_adjust(top=.95)\nplt.subplots_adjust(bottom=.05)\n\nfor i, c in zip(indices, clf_names):\n    plt.text(-.3, i, c)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T02:26:42.097481Z","iopub.execute_input":"2021-06-11T02:26:42.097798Z","iopub.status.idle":"2021-06-11T02:26:42.384323Z","shell.execute_reply.started":"2021-06-11T02:26:42.097772Z","shell.execute_reply":"2021-06-11T02:26:42.383656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}