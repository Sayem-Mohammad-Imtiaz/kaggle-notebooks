{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/identify-the-dance-form/train.csv')\ntest=pd.read_csv('/kaggle/input/identify-the-dance-form/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['target'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Class_map={'manipuri':0, 'bharatanatyam':1, 'odissi':2 ,'kathakali':3, 'kathak':4, 'sattriya':5,\n 'kuchipudi':6, 'mohiniyattam':7}\ninverse_map={0:'manipuri', 1:'bharatanatyam', 2:'odissi' ,3:'kathakali',4: 'kathak', 5:'sattriya',\n 6:'kuchipudi', 7:'mohiniyattam'}\ntrain['target']=train['target'].map(Class_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_h,img_w= (224,224)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ntrain_img=[]\ntrain_label=[]\nj=0\npath='/kaggle/input/identify-the-dance-form/train'\nfor i in tqdm(train['Image']):\n    final_path=os.path.join(path,i)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(img_h,img_w))\n    img=img.astype('float32')\n    train_img.append(img)\n    train_label.append(train['target'][j])\n    j=j+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_valid, y_train, y_valid = train_test_split(train_img,train_label, test_size=0.3, shuffle= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img=[]\npath='/kaggle/input/identify-the-dance-form/test'\nfor i in tqdm(test['Image']):\n    final_path=os.path.join(path,i)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(img_h,img_w))\n    img=img.astype('float32')\n    test_img.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,# divide each input by its std\n        rescale=1./255,\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\ntest_datagen= ImageDataGenerator(rescale=1./255)\nvalid_datagen= ImageDataGenerator(rescale=1./255)\ntrain_datagen.fit(x_train)\ntest_datagen.fit(test_img)\nvalid_datagen.fit(x_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tensorflow.keras.applications.vgg19 import VGG19,preprocess_input\nbase_model_3=VGG19(include_top=False, weights='imagenet',input_shape=(img_h,img_w,3), pooling='max')\n\nres_name = []\nfor layer in base_model_3.layers:\n    res_name.append(layer.name)\n    \nset_trainable = False\nfor layer in base_model_3.layers:\n    if layer.name in res_name[:-4]:\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n        \nmodel_3=Sequential()\nmodel_3.add(base_model_3)\nmodel_3.add(Flatten())\n\nmodel_3.add(Dense(2048, activation='relu'))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dropout(0.3))\n\n\nmodel_3.add(Dense(1024, activation='relu'))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(512, activation='relu'))\n\nmodel_3.add(Dense(256, activation='relu'))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dropout(0.3))\nmodel_3.add(Dense(128, activation='relu'))\nmodel_3.add(Dense(8,activation='softmax'))\n\nmodel_3.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel_3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img=np.array(train_img)\nx_train= np.array(x_train)\nx_valid= np.array(x_valid)\ny_train= np.array(y_train)\ny_valid= np.array(y_valid)\ntest_img=np.array(test_img)\ntrain_label=np.array(train_label)\nprint(\"Shape of training data=\",x_train.shape,\" and shape of labels of training data= \",y_train.shape)\nprint(\"Shape of validation data=\",x_valid.shape,\" and shape of labels of validation data= \",y_valid.shape)\nprint(\"Shape of test data=\",test_img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_3.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=32),epochs=40,\n          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=32),\n          verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = model_3.predict(test_img)\nprint(labels[:4])\nlabel = [np.argmax(i) for i in labels]\nclass_label = [inverse_map[x] for x in label]\nprint(class_label[:3])\nsubmission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\nsubmission.head(10)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}