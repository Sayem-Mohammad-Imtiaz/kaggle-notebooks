{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2741e151-0177-62ca-ec4a-19b4bee5d815"},"source":"# Machine Learning Engineer Nano Degree - Capstone Project\n## Student: Nick Maiorana\n## January 08, 2017\n\n## Overview\n\nThis project started as a work project that I performed for my professional career. The original project was used to identify false/positive readings from web sources that were marked as external attack points against our public web site. After completing the project successfully, my thoughts were that it would be perfect Capstone project for the Machine Learning Engineer Nanodegree program. It encompassed everything I had learned in the course and was applied in an actual environment with very accurate results. However, my employer is very wary of data (even anonymized data) from being used outside the company. My solution to this was to utilize the same process, however change the data source and goal of the project. For this I turned to a Kaggle dataset.\n\nAfter searching the Kaggle available datasets, I decided to use one focused on lower back pain symptoms. This dataset offered me a real-world problem that needed solving, with enough information to exercise the process I used for my current job. I have always felt the medical community could benefit from either machine learning technologies or expert systems. This project will offer me the capability to see how accurate I can build a lower back diagnostic classifier, if all I had available to me were the data attributes.\n\nThe medical field is comprised of individual doctors and physicians that are tasked with diagnosing patientâ€™s illnesses based on patient symptoms and test results. By using machine learning, these healthcare professionals can be assisted in their diagnosis by using patient data to predict the causes of the patient's symptoms.\nThis project is designed to provide a methodology of taking raw data and transforming it into a classification tool that can be used to diagnose patients with normal or abnormal spinal conditions. The purpose of this project is to assume raw unclassified data is available and, through the process laid out here, derive classification for each data set through data grouping and random sampling.\n\nA Kaggle dataset will be used for the feature and classification data. Although the data contains a classification attribute, this will only be used to identify clusters of data groups taken from random samples.\nThe goal of this project is to generate a training data set using clustering techniques to separate records into Normal and Abnormal classes. Once the training data is created, a classification model is built and then scored against how well the classifier predicts the original classification of each record. \nMy goal is simple, determine how close to some of the Kaggle reports I can get a classifier to predict. The biggest difference is that I will not use the dataset directly, but will use unsupervised learning to determine classification attribute. In the end, I will use an accuracy score to compare my classifier against the actual dataset classification.\n\nFor reference, here are some Kaggle entries and their scores:\n\n\n__Kaggle Reference         | Score Method   | Score__\n***\n- [Discriminating Normal-vs-Abnormal Spines](https://www.kaggle.com/antonio00/d/sammy123/lower-back-pain-symptoms-dataset/discriminating-normal-vs-abnormal-spines/discussion)  | Specificity | 54% \n- [Using k-NN to Predict Abnormal Spines](https://www.kaggle.com/sammy123/lower-back-pain-symptoms-dataset/discussion/24230) | Accuracy | 93% "},{"cell_type":"markdown","metadata":{"_cell_guid":"943473e1-869b-0c2a-d26d-4851e99b6d7f"},"source":"## Process\n\nThe process used for this project is pretty straigt forward. It will take on the following steps:\n\n- Load and display the original dataset\n- Remove and segregate classification information\n- Remove less important features\n- Scale and Transform the feature data\n- Use Unsupervised Learning to classify the data\n- Peform PCA to display UL classification information\n- Simulate cluster sample evaluation to identify cluster types (Normal/Abnormal)\n- Generate training dataset by classifying data using cluster analysis \n- Determine a suitable classification model to be used\n- Generate model using final training dataset\n- Evaluate model classification against original classification attribute for accuracy"},{"cell_type":"markdown","metadata":{"_cell_guid":"1688f627-d0c7-e189-14a4-4a04b6a6b40d"},"source":"## Data source\n\nThe data for this project has been downloaded from Kaggle and is named the \"Lower Back Pain Symptoms Dataset\"  (https://www.kaggle.com/sammy123/lower-back-pain-symptoms-dataset) \n\nThe information is layed out with 12 different featurs, labeld Col1-Col12 (Attribute1-12) and a classification attribute of \"Abnormal\" or \"Normal\". The descriptions for each attribute are as follows:\n\n- Attribute1 = pelvic_incidence  (numeric) \n- Attribute2 = pelvic_tilt (numeric) \n- Attribute3 = lumbar_lordosis_angle (numeric) \n- Attribute4 = sacral_slope (numeric) \n- Attribute5 = pelvic_radius (numeric) \n- Attribute6 = degree_spondylolisthesis (numeric) \n- Attribute7 = pelvic_slope(numeric)\n- Attribute8 = direct_tilt(numeric)\n- Attribute9 = thoracic_slope(numeric)\n- Attribute10 = cervical_tilt(numeric)\n- Attribute11 = sacrum_angle(numeric)\n- Attribute12 = scoliosis_slope(numeric)\n \nAlthough not necessary, for this project the feature names will be replaced with their descriptions to allow for easier feature analsyis. \n\nThe classification attribute will be used to classify clusters or groups of data items with similar features and will not be directly used in constructing a classifier for the dataset. The origninal classificatin attribute will be used to evaluate the final classification model."},{"cell_type":"markdown","metadata":{"_cell_guid":"8a350e82-43c4-fd14-47a0-3b6261df8074"},"source":"## Data Gathering\n### Data Import and Display"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8032b2e0-1651-e1ff-3860-1401eef06b12"},"outputs":[],"source":"# Import libraries necessary for this project\nimport numpy as np\nimport pandas as pd\n\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n# Show matplotlib plots inline (nicely formatted in the notebook)\n%matplotlib inline\n\ninput_file = '../input/Dataset_spine.csv'\ninput_data = pd.read_csv(input_file)\n\nrenamed_columns = {\n    'Col1': 'pelvic_incidence',\n    'Col2': 'pelvic_tilt',\n    'Col3': 'lumbar_lordosis_angle',\n    'Col4': 'sacral_slope',\n    'Col5': 'pelvic_radius',\n    'Col6': 'degree_spondylolisthesis',\n    'Col7': 'pelvic_slope',\n    'Col8': 'direct_tilt',\n    'Col9': 'thoracic_slope',\n    'Col10': 'cervical_tilt',\n    'Col11': 'sacrum_angle',\n    'Col12': 'scoliosis_slope',\n    'Class_att' : 'classification'\n}\ninput_data.rename(columns=renamed_columns, inplace=True)\ninput_data.drop(input_data.columns[13], axis=1, inplace=True)\ndisplay(input_data.head())\ndisplay(input_data.tail())\ndisplay(input_data.describe())"},{"cell_type":"markdown","metadata":{"_cell_guid":"36e65c8b-5630-9c84-3709-21c0a2c9cd86"},"source":"#### Sample and Remove non-feature data\n\nSince this dataset only has 310 items, the entire dataset will be used for this project. The ability to reduce the data by sampling a subset of the information is provided via the 'sample_size' variable and can be used if the dataset grows to an unmanagible amount. \n\nAs can be seen below, the data set is unbalanced. There are 210 Abnormal spinal data points and only 100 Normal spinal datapoints.\n\nI also removed the classification attribute since it is not needed for the initial phase of this project. The intent is to use a clustering algorythm to group the data into common subgroups. This classification attribute will be used later during the cluster analysis to identify how each cluster should be classified. It will also be used as a final step to determine the accuracy of the classificaiton model generated."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fbc265a6-74e5-367e-7861-b1e676b14dc6"},"outputs":[],"source":"# take a sample size of the data, 1.0 if the data is not too large.\nimport pandas as pd\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\nsample_size = 1.0\ndata = input_data.sample(frac=sample_size)\n\n# Randomize the data\ndata = data.sample(frac=1.0).reset_index(drop=True)\n\ndisplay(data.head())\n\n# Extract the classification column from the data\nclassification = data[['classification']]\ndisplay(classification.describe())\ndisplay(classification.head())\nclassification.describe().to_csv(\"classification_stats.csv\", float_format='%.6f', index=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd22cc26-a36a-b888-703b-8df65556e886"},"source":"## Feature Relevance\n\n### Feature Relevance Part 1\n\nIn this step we will determine how relavent each feature is to determining spinal conditions for patients. To do this we will run through the dataset 12 times, and each time remove a feature. For each iteration, we will create and fit a regressor model to the subset of data so see how accurate the subset can predict the value of that removed feature. \n\nFor starters, I will put any feature that scores less than 0.0 as the suggested features to drop\n\nThis will give us an indication of which features to keep as we build our classificaiton model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4066d1f1-49e7-41e0-5a9a-711170cd7c81"},"outputs":[],"source":"import pandas as pd\nfrom IPython.display import display # Allows the use of display() for DataFrames\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn import preprocessing\n\n# Scale the data using the natural logarithm\n#preprocessed_data = reduced_feature_data.apply(np.log)\n\n# Scale the data using preprocessing function in sklearn\nfeature_cols = list(data.columns[:-1])\npreprocessed_data = data.copy()\n\nsuggested_features_to_drop = []\nfor feature in feature_cols:\n    # Make a copy of the DataFrame, using the 'drop' function to drop the given feature\n    # Extract the values of the dataframe to be used for the regression\n    new_data = preprocessed_data.drop([feature], axis = 1, inplace = False)\n    remaining_cols = list(new_data.columns[:-1])\n    new_data_values = new_data[remaining_cols].values\n    target_label = data[feature].values\n\n    # Split the data into training and testing sets using the given feature as the target\n    X_train, X_test, y_train, y_test = train_test_split(new_data_values, target_label, test_size=0.20, random_state=42)\n\n    # Create a decision tree regressor and fit it to the training set\n    regressor = tree.DecisionTreeRegressor(random_state=42)\n    regressor.fit(X_train, y_train)\n    y_pred = regressor.predict(X_test)\n\n    # Report the score of the prediction using the testing set\n    score = regressor.score(X_test, y_test)\n    print (feature, score)\n    if score < 0.0:\n        suggested_features_to_drop.append(feature)\n        \n\nprint (\"\\nSuggested features to drop:\")\nfor feature in suggested_features_to_drop: print (feature)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a4b2ba51-5dde-d3b9-9253-7d60eac933c1"},"source":"### Feature Relevance Part 2\n\nBy reviewing the scores above, I will decide on which features to remove. I may revisit this to remove additional features as the analysis continues. In the segment below, I will indicate the initial features removed as well as any additional features as I progress through the project via comments. The goal is to reduce the feature set to a managable number of dimensions with at least 95% varience.\n\nFor my initial feature removal, I will eliminate the features with negative scores."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a5672dd-f14f-9c33-a062-2a02484413f2"},"outputs":[],"source":"import pandas as pd\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n# Initial set of features to drop by using the features with negative scores above\ndropped_features = ['pelvic_radius', 'pelvic_slope', 'direct_tilt', 'thoracic_slope', 'cervical_tilt', 'sacrum_angle', 'scoliosis_slope']\n \nreduced_feature_data = data.copy()\nfor feature in dropped_features:\n    print (\"Manually dropping feature:\", feature)\n    reduced_feature_data.drop([feature], axis = 1, inplace = True)\n    \ndisplay(reduced_feature_data.head())\nreduced_feature_data.to_csv(\"reduced_feature_data.csv\", float_format='%.6f', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"cb0ee814-c24e-2028-928b-0e5fdfdd51f4"},"source":"## Feature Scaling & Transformation\n\n### Feature Scaling\n\n- In order to create a greater amount of variance, we will adjust the values for all the features by e^x.\n- To verify we are getting a better distribution of data, we will visualize the data befor and after scaling.\n- The scatter matrix below will indicate which features will work well together by showing the greatest amount of variance. This can also be used to return to the last section to remove additional features from the data. What we are looking for are gaussian distributions of the data to gain the most variance between the features.\n- Using the logarithmic function for scaling certain values may generate NA values. We will remove the NA values from the dataset.\n- The scaled dataset will be stored so that it can be used later without having to recreate it from start. This is done throught the project to allow for quick experimentation."},{"cell_type":"markdown","metadata":{"_cell_guid":"19e9fa27-04f3-7b9a-b7b9-534041564f34"},"source":"#### Visualize the original data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8a878e8-9236-8feb-9db1-1df691ab144a"},"outputs":[],"source":"import pandas as pd\n\nreduced_feature_data = pd.read_csv(\"reduced_feature_data.csv\")\nfeature_cols = list(reduced_feature_data.columns[:-1])\n\n# Visulalize the original data\npd.scatter_matrix(reduced_feature_data[feature_cols], alpha = 0.3, figsize = (8,10), diagonal = 'kde');"},{"cell_type":"markdown","metadata":{"_cell_guid":"9b2f8e41-83d6-644e-033a-21841fcd414b"},"source":"#### Scale the data\n\nHere I will apply a function to scale the data to make it more linearly separable and create more variance. The log function I used generated some NA values in the data, which had to be removed. It is important to review the amount of data remaining since a significant percentage drop may leave the remaining data useless for further diagnosis.\n\nI also provided an alternative to use sklearn."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e80b230-4c3f-a727-54f3-b9324b36f9cc"},"outputs":[],"source":"import pandas as pd\nfrom sklearn import preprocessing\nimport numpy as np\n\nfeature_cols = list(reduced_feature_data.columns[:-1])\ntarget_col = reduced_feature_data.columns[-1] \npreprocessed_data = reduced_feature_data.copy()\n\n# Scale the data using the natural logarithm\n\nif True:\n    preprocessed_data = preprocessed_data[feature_cols].apply(np.log)\n    preprocessed_data = pd.concat([preprocessed_data, reduced_feature_data[target_col]], axis = 1)\n\n# Scale the data using preprocessing function in sklearn\n\nif False:\n    scaler=preprocessing.StandardScaler()\n    scaler.fit(reduced_feature_data[feature_cols])\n    preprocessed_data[feature_cols] = scaler.transform(reduced_feature_data[feature_cols])\n\n    display(preprocessed_data.describe())\n\n# Drop any rows that contain NA values due to the scaling\npreprocessed_data.dropna(subset=feature_cols, inplace=True)\n\n# Display the percentage of the dataset kept.\npercent_kept = (float(len(preprocessed_data)) / float(len(reduced_feature_data))) * 100.00\nprint (\"Percentage kept:  {:2.2f}%\".format(percent_kept))"},{"cell_type":"markdown","metadata":{"_cell_guid":"b0ff23e4-a88a-1271-f3f9-7400b621d3c6"},"source":"#### Store and display scaled data\n\nHere we will re-introduce the classification data (to be used later during cluster sampling analysis) and persist the data in a file. This allows us to experiment throughout the project w/out having to start from the beginning every time. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce75b62a-d135-169b-0b69-aa4339898a34"},"outputs":[],"source":"import pandas as pd\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n# Output data set so that the analysis can be restarted w/out having to replay the entire notebook\npreprocessed_data.to_csv(\"scaled_data.csv\", float_format='%.6f', index=False)\n\n# Visualize the scaled data\ndisplay(preprocessed_data.head())\npd.scatter_matrix(preprocessed_data, alpha = 0.3, figsize = (8,10), diagonal = 'kde');"},{"cell_type":"markdown","metadata":{"_cell_guid":"1a43f612-1699-1044-d5d4-15cdab136f38"},"source":"Outlier Detection\n\nIn this step I will identify (if any) any feature containing outliers using [Tukey's Method for identfying outliers](http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/). If any feature value is determined to be an outlier, that data point will be removed from the dataset."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80418966-8dcd-1c6a-ef07-d7faf9cff01f"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n# Get the scaled data data set so that the analysis can be restarted w/out having to replay the entire notebook\nscaled_data = pd.read_csv(\"scaled_data.csv\")\n\n# For each feature find the data points with extreme high or low values\noutlierCounts = np.array([])\n\nfeature_cols = list(scaled_data.columns[:-1])\n\nfor feature in feature_cols:\n    \n    # Calculate Q1 (25th percentile of the data) for the given feature\n    Q1 = np.percentile(scaled_data[feature].values, 25)\n    \n    # Calculate Q3 (75th percentile of the data) for the given feature\n    Q3 = np.percentile(scaled_data[feature].values, 75)\n    \n    # Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n    step = 1.5 * (Q3 - Q1)\n    \n    # Display the outliers\n    print (\"Data points considered outliers for the feature '{}':\".format(feature))\n    is_outlier = ~((scaled_data[feature] >= Q1 - step) & (scaled_data[feature] <= Q3 + step))\n    display(scaled_data[~((scaled_data[feature] >= Q1 - step) & (scaled_data[feature] <= Q3 + step))])\n    outlierCounts = np.append(outlierCounts, scaled_data[~((scaled_data[feature] >= Q1 - step) & (scaled_data[feature] <= Q3 + step))].index)\n\n# OPTIONAL: Select the indices for data points you wish to remove\noutlierCounts = outlierCounts.astype(int)\noutlierCounted = Counter(outlierCounts)\n\nprint (\"Number of data points that have one or more outlier features: \", len(outlierCounted))\n\noutliers = [key for key,val in outlierCounted.items()]\nprint (\"Data points with outliers: \", outliers)\n# Remove the outliers, if any were specified\ngood_scaled_data = scaled_data.drop(scaled_data.index[outliers]).reset_index(drop = True)\n\ndisplay(good_scaled_data.describe())\n\n# Output good scaled data set so that the analysis can be restarted w/out having to replay the entire notebook\ngood_scaled_data.to_csv(\"good_scaled_data.csv\", float_format='%.6f', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f82a497d-2d83-6d25-6bec-409b09b383a7"},"source":"#### Use Clustering to group data \n\nFor this stage of the analysis I decided to use K-Means clustering. The clustering portion is to isolate each classificaiton (Normal/Abnormal) into distinct clusters so that a sampling from each cluster will allow me to identify what type of data is in each cluster. The goal is to get to a point where each cluster is mostly homogenous (90%) so that I can use the cluster information to classify the original data.\n\nThis may involve repeating this process so that the clustering function can be accuratly tuned. In other words, once the clustering is complete, sample data from each cluster will be taken and scored for homogeniality. If the desired 90% is not achieved, the function will be tuned and retried.\n\n- Attempt to use a range of cluster components\n- Score each one\n- Use the one with the best score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b319f0b-1589-3ec8-5047-85219b9a1cdc"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AffinityPropagation\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.metrics import silhouette_score\n\n# Get the scaled data data set so that the analysis can be restarted w/out having to replay the entire notebook\ngood_scaled_data = pd.read_csv(\"good_scaled_data.csv\")\n\nfeature_cols = list(good_scaled_data.columns[:-1])\nfeature_data = good_scaled_data[feature_cols]\n\nkmeans = KMeans(n_clusters=3)\nafprop =  AffinityPropagation(preference=-50)\ngmm_spherical = GaussianMixture(n_components=3, covariance_type='spherical', random_state = 42)\n\nclusterers = [kmeans, afprop, gmm_spherical]\n\nbest = -1.0\nfor clusterer in clusterers:\n    clusterer.fit(feature_data)\n\n    # Predict the cluster for each data point\n    preds = clusterer.predict(feature_data)\n\n    # Calculate the mean silhouette coefficient for the number of clusters chosen\n    score = silhouette_score(feature_data, preds)\n    \n    print (\"Clusterer {}      score {:0.4f}.\".format(type(clusterer).__name__, score))\n\n    if best < score:\n        best = score\n        best_clusterer = clusterer\n        best_preds = preds\n\nprint (\"\\nThe best score was {:0.4f} using {} clusterer.\".format(best, type(best_clusterer).__name__))\n\npredictions = pd.DataFrame(best_preds, columns = ['cluster'])\npredictions.to_csv(\"predictions.csv\", float_format='%.6f', index=False)\n\nprint (\"\\n\", predictions.groupby(['cluster']).size())\n\nprint (\"\\nClustering complete.\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"42f2e4b6-cc9c-14f5-c3b0-82a08f35e523"},"source":"#### Display the Cluster\n\nI will use PCA to perform feature reduction to present a graph of the cluster results"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac3786ec-53fd-7d5e-881d-1e55ff29c094"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n%matplotlib inline\n\ngood_scaled_data = pd.read_csv('good_scaled_data.csv')\npredictions = pd.read_csv('predictions.csv')\nfeature_data = good_scaled_data.drop(['classification'], axis = 1)\n\npca_components = 2\npca = PCA(n_components=pca_components).fit(feature_data)\nreduced_data = pca.transform(feature_data)\n\n# Create a DataFrame for the reduced data\nreduced_data = pd.DataFrame(reduced_data, columns = ['Dimension 1', 'Dimension 2'])\n\n# Output data set\nreduced_data.to_csv(\"reduced_data.csv\", float_format='%.6f', index=False)\nplot_data = pd.concat([predictions, reduced_data], axis = 1)\n\n# Generate the cluster plot\nfig, ax = plt.subplots(figsize = (8,8))\n\n# Color map\ncmap = cm.get_cmap('gist_rainbow')\n\nclusters = plot_data['cluster'].unique()\n\n# Color the points based on assigned cluster\nfor i, cluster in plot_data.groupby('cluster'):   \n    cluster.plot(ax = ax, kind = 'scatter', x = 'Dimension 1', y = 'Dimension 2', \\\n                 color = cmap((i)*1.0/(len(clusters)-1)), label = 'Cluster %i'%(i), s=200);\n\n# Set plot title\nax.set_title(\"Cluster Learning on PCA-Reduced Data\");"},{"cell_type":"markdown","metadata":{"_cell_guid":"24dda6d1-3ddc-45ba-91ab-4c08b9457b2c"},"source":"#### Recombine scaled data with cluster information\n\n- Here we can map back in the descriptive data (cluster, Dimension 1, Dimesion 2, ... , Dimension N) so that we can begin to analyze what kind of data is in each cluster.\n- Save the full data set along with cluster information for further analysis"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4073a8cb-5d5c-8daa-9384-ce3ee4bd74b4"},"outputs":[],"source":"import pandas as pd\n\ngood_scaled_data = pd.read_csv('good_scaled_data.csv')\nreduced_data = pd.read_csv('reduced_data.csv')\npredicitons = pd.read_csv('predictions.csv')\n\nfull_data = pd.concat([good_scaled_data, predictions, reduced_data], axis = 1)\n\nfull_data.to_csv('full_processed_data.csv', index=False)\ndisplay(full_data.head())"},{"cell_type":"markdown","metadata":{"_cell_guid":"f09c2b1f-ed6f-ce16-4809-0b400a513bcb"},"source":"#### Gather Data Samples\n\nHere I will gather a sampling of data to analyze how pure each identified cluster is. In other words, I'm looking for cluster samples with mostly all of the same class (Normal or Abnormal). Under real-world circumstances, this would be a manual step to research the sample set to identify which class it belongs to. For the purposes of this project, the original classification attribute will be used to simulate this analysis.\n\nI will be looking to sample a humanly manageable amount of data. The current data set has approximately 250 items. A manageable number would be approximately 20 items.\n\n#### Store sample data for analysis\n\nUnder normal circumstances, the classification information would not be available to us. At this step in the process, we would need to identify the sample data to see which kind of data is in each cluster. This will allow us to generate our training data set from our original data set (w/out having classification). \n\nThe importance of this is that it allow us to use data samples instead of the entire dataset to provide a classfication for each of the data items. In a normal dataset with 1000s or more data items, it would be humanly impossible to classify each item. By using the information derived from our clustering work, we can generalize the clusters into the appropropriate classification for that cluster.\n\nMy proposal for a real-world scenario is to store the sample data gathered above, and perform the appropriate analysis to classify each sample. Once this is done, we can reasonably assign a classification to each cluster. The analyzed date can be read into memory to begin constructing the final training set. \n\nFor this project, we will use the conveniently provided classification information to determine how each cluster should be classified."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ad35077-569a-744e-2482-bbf1f830025f"},"outputs":[],"source":"import pandas as pd\n\nfull_data = pd.read_csv('full_processed_data.csv')\n\nsample_data = full_data.sample(frac=0.0)\nfrac_samples_per_cluster = 0.20 / float(len(full_data['cluster'].unique()))\nsamples_per_cluster = 20\n\nclusters = full_data['cluster'].unique()\n\nfor cluster_number in clusters:\n    cluster_data = full_data[full_data['cluster'] == cluster_number].sample(n=samples_per_cluster)\n    sample_data = sample_data.append(cluster_data)\n\nprint (\"Chosen samples segments dataset:\")\n#sample_data = full_data.sample(n=20)\ndisplay(sample_data.sort_values(by=['cluster']))\n\nsample_data.to_csv('sample_data.csv', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"fc35e296-c512-2943-2dd8-f06fa3035290"},"source":"#### Analyze Samples\n\nHere is where the manually analysed samples can be used to identify clusters.\n\n- Determine how pure each cluster sample is for individual classification (Normal/Abnormal)\n- If the cluster samples are too mixed, consider using additional cluster components to further isolate each class"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8294495-c3fd-15a9-050e-65b74488792c"},"outputs":[],"source":"import pandas as pd\nfrom sklearn.metrics.cluster import homogeneity_score\nfrom sklearn.metrics.cluster import v_measure_score\nfrom sklearn.metrics import adjusted_rand_score\n\nsample_data = pd.read_csv('sample_data.csv')\n\nprint(\"Homogeneity Score is:       %.2f\" % homogeneity_score(sample_data['cluster'].values, sample_data['classification'].values))\nprint(\"V Measure Score is:         %.2f\" % v_measure_score(sample_data['cluster'].values, sample_data['classification'].values))\nprint(\"Adjusted Rand Score is:     %.2f\" % adjusted_rand_score(sample_data['cluster'].values, sample_data['classification'].values))"},{"cell_type":"markdown","metadata":{"_cell_guid":"38c3b4ac-8224-0c8c-67f4-62ac88f3da4b"},"source":"### Determine which clusters contain \"Abnormal\" data points"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc158297-e903-0759-b327-21ac5412e3d1"},"outputs":[],"source":"import pandas as pd\nfrom scipy.stats import mode\n\nabnormal_clusters = []\nsample_data = pd.read_csv('sample_data.csv')\nclusters = sample_data['cluster'].unique()\n\nfor cluster_number in clusters:\n    cluster_data = sample_data[sample_data['cluster'] == cluster_number]\n    \n    cluster_size = len(cluster_data)\n    print (\"Cluster\", cluster_number, \"has\", cluster_size, \"elements\")\n    \n    cluster_classification = mode(cluster_data[['classification']])[0][0][0]\n    \n    print (\"Cluster\", cluster_number, \"will be classified as\", cluster_classification)\n    \n    if cluster_classification == 'Abnormal':\n        abnormal_clusters.append(cluster_number)\n\n\nabnormal_preds = full_data[(full_data['cluster'].isin(abnormal_clusters))]\nnormal_preds = full_data[(~full_data['cluster'].isin(abnormal_clusters))]\nprint (\"Abnormal Preds:            {}\".format(len(abnormal_preds.index)))\nprint (\"Normal Preds:              {}\".format(len(normal_preds.index)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"a7b63d23-6495-79ea-8589-a2c6186c31f4"},"source":"#### Visualize the cluster\n\nThis step is not necessary, but will present the cluster analayis over the first 2 dimensions and samples visually to provide a graphical representation of our data.\n\n- Blue ^ are Normal data points\n- Black v are Abnormal data points"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1b716e2-db5c-2e76-d7c6-089b1ff88d29"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n%matplotlib inline\n\n# Visualize the cluster data\nfull_data = pd.read_csv('full_processed_data.csv')\nsample_data = pd.read_csv('sample_data.csv')\n\npca_samples = sample_data[['Dimension 1', 'Dimension 2', 'classification']]\n\nplot_data = full_data[['cluster', 'Dimension 1', 'Dimension 2']]\n# Generate the cluster plot\nfig, ax = plt.subplots(figsize = (8,8))\n\n# Color map\ncmap = cm.get_cmap('gist_rainbow')\n\ncenters = plot_data['cluster'].unique()\n\n# Color the points based on assigned cluster\nfor i, cluster in plot_data.groupby('cluster'):   \n    cluster.plot(ax = ax, kind = 'scatter', x = 'Dimension 1', y = 'Dimension 2', \\\n                 color = cmap((i)*1.0/(len(centers)-1)), label = 'Cluster %i'%(i), s=200);\n\n# Plot transformed abnormal sample points \nabnormal_samples = pca_samples[(pca_samples['classification'] == 'Abnormal')].values\nax.scatter(x = abnormal_samples[:,0], y = abnormal_samples[:,1], \\\n           s = 30, linewidth = 1, color = 'black', marker = 'v');\n\n# Plot transformed normal sample points \nabnormal_samples = pca_samples[(pca_samples['classification'] == 'Normal')].values\nax.scatter(x = abnormal_samples[:,0], y = abnormal_samples[:,1], \\\n           s = 30, linewidth = 1, color = 'blue', marker = '^');\n# Set plot title\nax.set_title(\"Cluster Learning on PCA-Reduced Data - Sample Classifcations Marked [N = ^, A = v]\");"},{"cell_type":"markdown","metadata":{"_cell_guid":"67aada3e-2ca9-28e9-0c6c-dac0c8963b76"},"source":"#### Build Training Dataset\n\n- Build a training datafram using the full data and the cluster information.\n- Store the training data to a csv file"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6865cdc0-ee21-401b-f0e0-19f96cdd9ac9"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\nfull_data = pd.read_csv('full_processed_data.csv')\ntraining_data = full_data.drop(['classification', 'Dimension 1', 'Dimension 2'], axis=1)\n\ntraining_data.loc[training_data['cluster'].isin(abnormal_clusters), 'project_classification'] = 'Abnormal'\ntraining_data.loc[~training_data['cluster'].isin(abnormal_clusters), 'project_classification'] = 'Normal'\n\ntraining_data.drop(['cluster'], axis=1, inplace=True)\n\n# Randomize the data\ntraining_data = training_data.sample(frac=1.0)\n\ntraining_data.to_csv('training_data.csv', float_format='%.6f', index=False)\n\ndisplay(training_data.head())\nprint (\"Training data created.\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"7ffae37e-3376-0197-5acf-d83efcf7a906"},"source":"### Classification\n\nIn this section we will take the training data derived above to create a classifier"},{"cell_type":"markdown","metadata":{"_cell_guid":"81ea3df2-2e20-ea2a-cd60-7411d2969663"},"source":"#### Extract the Feature Data from the Target Data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e564c96a-cb00-be9e-f72a-e8e6318f826b"},"outputs":[],"source":"import pandas as pd\n\ntraining_data = pd.read_csv('training_data.csv')\n\n# Extract feature columns (first set)\nfeature_cols = list(training_data.columns[:-1])\n\n# Extract target column 'false_positive' (last column)\ntarget_col = training_data.columns[-1] \n\n# Show the list of columns\nprint (\"Feature columns:\\n{}\".format(feature_cols))\nprint (\"\\nTarget column: {}\".format(target_col))\n\n# Separate the data into feature data and target data (X_all and y_all, respectively)\nX_all = training_data[feature_cols]\ny_all = training_data[target_col]"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b9e3253-a128-f74d-a779-c5af1f7d13d5"},"source":"#### Train and Score Models\n\n- We will attempt 3 different models\n- Train and score each one\n- Select the one with the best test scores"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d91266c6-5afd-da2e-f5dd-79afe98c1532"},"outputs":[],"source":"# Import the three supervised learning models from sklearn\nimport pandas as pd\nfrom sklearn import tree\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.model_selection import cross_val_score\n\n# Initialize the three models\nclf_A = tree.DecisionTreeClassifier(random_state=42)\nclf_A_parameters = {'min_samples_split':(2, 200, 2000), 'min_samples_leaf': (2, 4, 6, 8 , 10), 'splitter': ('best', 'random')}\n\nclf_B = SVC(random_state=42)\nclf_B_parameters = {'kernel':('linear', 'rbf', 'sigmoid'), 'gamma': (1, 100, 1000, 10000, 100000), 'C':(1.0, 2.0, 3.0)}\n\nclf_C = GaussianNB()\nclf_C_parameters = {}\n\nclassifiers = [clf_A, clf_B, clf_C]\nparameters = [clf_A_parameters, clf_B_parameters, clf_C_parameters]\n\n# Loop through each classifier, train and test. Keep the one with the best test score\nbest_score = 0.0\nfor index in range(len(classifiers)):\n    clf = classifiers[index]\n    print (\"\\n{}:\".format(clf.__class__.__name__))\n    \n    # Using Cross Validation\n    \n    scores = cross_val_score(clf, X_all, y_all, cv=10)\n    print (\"F1 mean score for CV training set: {:.4f}.\".format(scores.mean()))\n\n    if best_score < scores.mean():\n        best_score = scores.mean()\n        best_clf = clf\n        best_parms = parameters[index]\n\nprint (\"\\nThe best testing score was : {:.4f}.\".format(best_score))\nprint (\"The best classifier was: {}\".format(best_clf.__class__.__name__))\nprint (\"The optional parameteres for this classifier was: {}\".format(best_parms))"},{"cell_type":"markdown","metadata":{"_cell_guid":"8b40ecc6-8e8e-872b-5823-2e7a5835aadf"},"source":"#### Model Tuning\n\n- Using GridSearch and Cross Validation, find optimal tuning parameters for classifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adfa913b-3eb6-64b3-3013-c017553042aa"},"outputs":[],"source":"import pandas as pd\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\n\n# Perform grid search on the classifier using the f1_scorer as the scoring method\ngrid_obj = GridSearchCV(best_clf, param_grid=best_parms, cv=10)\n\n# Fit the grid search object to the training data and find the optimal parameters\ngrid_obj.fit(X_all, y_all)\n\nprint (\"Best parameters set found on development set:\")\nprint (grid_obj.best_params_)\nprint ()\n# Get the estimator\nclf = grid_obj.best_estimator_\nprint (clf)\n\nprint (\"\\nBest score: {:.4f}.\".format(grid_obj.best_score_))"},{"cell_type":"markdown","metadata":{"_cell_guid":"2e102c79-12d5-9bfa-2f62-0bff555e62d6"},"source":"#### Model Persitance\n\n- Save the model to a file called classification_model.pkl\n- Test loading the model\n- Test the loaded model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b50725e2-3270-28eb-edd9-74d959c7c11f"},"outputs":[],"source":"from sklearn.externals import joblib\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import train_test_split\nimport math\n\n# Shuffle and split the dataset into the number of training and testing points above\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, train_size=0.75, test_size=0.25, random_state=42)\n\n# Show the results of the split\nprint (\"Training set has {} samples.\".format(X_train.shape[0]))\nprint (\"Testing set has {} samples.\".format(X_test.shape[0]))\n\njoblib.dump(clf, 'classification_model.pkl')\nloaded_clf = joblib.load('classification_model.pkl')\n\ntesting_pred = loaded_clf.predict(X_test)\n# Get Score based on training data\nf1_score_testing_data = f1_score(y_test.values, testing_pred, pos_label=\"Abnormal\")\nprint (\"F1 score for test set: {:.4f}.\".format(f1_score_testing_data))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9db2294d-9915-8113-0730-8ced7d2bc5de"},"outputs":[],"source":"# Finally score the original classification to the one derived by the model\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfull_data = pd.read_csv('full_processed_data.csv')\nvalidation_data = full_data.drop(['cluster', 'Dimension 1', 'Dimension 2'], axis=1)\n\n# Extract feature columns (first set)\nfeature_cols = list(validation_data.columns[:-1])\n\n# Extract target column 'false_positive' (last column)\ntarget_col = validation_data.columns[-1] \n\n# Show the list of columns\nprint (\"Feature columns:\\n{}\".format(feature_cols))\nprint (\"\\nTarget column: {}\".format(target_col))\n\n# Separate the data into feature data and target data (X_all and y_all, respectively)\nX_all = validation_data[feature_cols]\ny_all = validation_data[target_col]\n\nloaded_clf = joblib.load('classification_model.pkl')\n\nvalidation_pred = loaded_clf.predict(X_all)\n# Get Score based on training data\nvalidation_score = accuracy_score(y_all.values, validation_pred)\nprint (\"\\nValidation accuracy score: {:.4f}\".format(validation_score))\n\ntarget_names = ['Abnormal', 'Normal']\n\nreport = classification_report(y_all.values, validation_pred, target_names)\ncf_matrix = confusion_matrix(y_all.values, validation_pred, target_names)\n\nconfusion = pd.crosstab(y_all, validation_pred, rownames=['Actual'], colnames=['Classified As'])\n\ndisplay(confusion)\n\n\ncf_matrix = confusion.values\nsensitivity = cf_matrix[0][0] / float(np.sum(cf_matrix[0][0:]))\nspecificity =  cf_matrix[1][1] / float(np.sum(cf_matrix[1][0:]))\n\nprint (\"\\nSensitivity:             {:.4f}\".format(sensitivity))\nprint (\"\\nSpecificity:             {:.4f}\".format(specificity))\nprint (\"\\nClassification Report\\n\", report)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b01af3f-8bc9-f7c6-18a1-820fc05608fc"},"source":"### Conclusion\n\nThis was a very interesting data set to work with. I was very surprised that I could get to a 82% accuracy against the original classified data (88% of top Kaggle submission) using Unsupervised Learning and making conclusions via sampling. This is closer to how things work in the real-world. You don't always have the classification data readily available and you need to somehow separate the data points into similar buckets and make decisions on what your observations are about each bucket's makeup.\n\nComparing my results to those submitted by Kaggle members, I believe I did a good job considering I did not use the provided classification data to construct a classifier. One entry posted a 93% accuracy, 11% higher than the one I derived, but they had the benefit of using 100% of the provided classification data. In addition to the accuracy score, another entry posted a specificity score of 54%, while I could achieve a score of 86%.\n\nI would have to say that the methodology used for this project can be applied to real-world problems where classification data is not available. In fact, I have used this same process for my job to classify false/positive transaction sources predicted by other systems.\n\nI thoroughly enjoyed working this problem and getting much better in my Python and Pandas skill set.\n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}