{"cells":[{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification, make_blobs\nfrom matplotlib.colors import ListedColormap\n%matplotlib notebook","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/ionosphere/ionosphere.txt',header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":"X=df.iloc[:,0:33]\nY=df.iloc[:,34]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nX_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 0)\n\nclf = LinearSVC().fit(X_train, y_train)\nprint('Ionosphere dataset')\nprint('Accuracy of Linear SVC classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of Linear SVC classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = LinearSVC(C=5, random_state = 67).fit(X_train, y_train)\nprint('Coefficients:\\n', clf1.coef_)\nprint('Intercepts:\\n', clf1.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf', C=10).fit(X_train, y_train)\nsvm.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_poly=SVC(kernel='poly', C=100,probability=True).fit(X_train, y_train)\nsvm_poly.score(X_test,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_sigmoid=SVC(kernel='sigmoid', C=100,probability=True).fit(X_train, y_train)\nsvm_sigmoid.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_decf = SVC(kernel='rbf', C=1,decision_function_shape='ovr').fit(X_train, y_train)\nsvm_decf.score(X_test, y_test)\n# svm_decf.decision_function(X.iloc[:,6:8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(kernel='rbf', C=1)\nclf.fit(X_train[[6,14]], y_train)\nplt.figure()\nplt.scatter(X.iloc[:,6:7],X.iloc[:,14:15],zorder=10,\n            c=['r','b'],cmap=plt.cm.Paired,edgecolor='k', s=10)\nplt.scatter(X_test.iloc[:,6:7],X_test.iloc[:,14:15],s=50,\n            facecolors='none',zorder=10,edgecolor='k')\nplt.axis('tight')\n\nx_min = X.iloc[:,6].min()\nx_max = X.iloc[:,6].max()\ny_min = X.iloc[:,14].min()\ny_max = X.iloc[:,14].max()\n\n\n\nprint(x_min)\nprint(x_max)\nprint(y_min)\nprint(y_max)\n\nXX, YY = np.mgrid[ x_min : x_max :200j,  y_min : y_max :200j]\nZ = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n\n    # Put the result into a color plot\nZ = Z.reshape(XX.shape)\nplt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\nplt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n                linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(kernel='rbf', C=1)\nclf.fit(X_train[[15,28]], y_train)\nplt.figure()\nplt.scatter(X.iloc[:,15],X.iloc[:,28],zorder=10,\n            c=['r','b'],cmap=plt.cm.Paired,edgecolor='k', s=10)\nplt.scatter(X_test.iloc[:,6:7],X_test.iloc[:,14:15],s=50,\n            facecolors='none',zorder=10,edgecolor='k')\nplt.axis('tight')\n\nx_min = X.iloc[:,15].min()\nx_max = X.iloc[:,15].max()\ny_min = X.iloc[:,28].min()\ny_max = X.iloc[:,28].max()\n\n\n\nprint(x_min)\nprint(x_max)\nprint(y_min)\nprint(y_max)\n\nXX, YY = np.mgrid[ x_min : x_max :200j,  y_min : y_max :200j]\nZ = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n\n    # Put the result into a color plot\nZ = Z.reshape(XX.shape)\nplt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\nplt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n                linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df_with_dummies= pd.get_dummies(Y, prefix='Category_', columns=['Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=df\ndf2.rename(columns={34:\"class\"},inplace=True)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\np1 = sns.heatmap(df.iloc[:,2:32])\ncorr_matrix=df.corr()\n\n# plot it\n# sns.heatmap(corr_matrix, cmap='PuOr')\n#sns.plt.show()\n\n\n# library\n\nnp.random.seed(0)\n \n# Create a dataset (fake)\nplt.figure()\n \n# Can be great to plot only a half matrix\nmask = np.zeros_like(corr_matrix)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    p2 = sns.heatmap(corr_matrix, mask=mask, square=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['info']=[0 if i=='b' else 1 for i in df['class']]\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nimport matplotlib.dates as mdates\n\n\nplt.scatter(df2.iloc[:,6:7],df2['info'],c='red',label='6')\nplt.scatter(df2.iloc[:,14:15],df2['info'],c='green',label='14')\nplt.scatter(df2.iloc[:,8:9],df2['info'],c='b',label='8')\nplt.scatter(df2.iloc[:,4:5],df2['info'],c='c',label='4')\nplt.scatter(df2.iloc[:,5:6],df2['info'],c='m',label='5')\nplt.scatter(df2.iloc[:,7:8],df2['info'],c='y',label='7')\nplt.scatter(df2.iloc[:,9:10],df2['info'],c='k',label='9')\nplt.scatter(df2.iloc[:,10:11],df2['info'],c='black',label='10')\nplt.scatter(df2.iloc[:,12:13],df2['info'],c='red',label='12')\nplt.scatter(df2.iloc[:,16:17],df2['info'],c='lavender',label='16')\nplt.scatter(df2.iloc[:,18:19],df2['info'],c='salmon',label='18')\nplt.scatter(df2.iloc[:,19:20],df2['info'],c='coral',label='19')\nplt.xlim(-1.2,1.2)\nplt.xticks(np.arange(-1.2, 1.2, 0.1))\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfilter=df2[[4,5,6,7,8,9,10,12,14,16,18,19,'info']]\ndfilter.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns_plot = sns.pairplot(dfilter,hue='info')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.scatter(df.iloc[:,6:7],df.iloc[:,14:15],c=['r','b'])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.scatter(df.iloc[:,10:11],df.iloc[:,18:19],c=['r','b'])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\nclf = DecisionTreeClassifier().fit(X_train, y_train)\n\nprint('Accuracy of Decision Tree classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of Decision Tree classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf2 = DecisionTreeClassifier(max_depth = 3).fit(X_train, y_train)\n\nprint('Accuracy of Decision Tree classifier on training set: {:.2f}'\n     .format(clf2.score(X_train, y_train)))\nprint('Accuracy of Decision Tree classifier on test set: {:.2f}'\n     .format(clf2.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Feature importances: {}'.format(clf.feature_importances_))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":"feat=[]\nfor i in range(0,len(clf.feature_importances_)):\n    feat.append((list(clf.feature_importances_)[i],i))\nfeat.sort(reverse=True)\n\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":"## important feature\nf1=[4,26,2,3,27]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz \nfrom sklearn import tree\ndot_data = tree.export_graphviz(clf, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph.render(\"ionosphere\") \n\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":"feature=[str(i) for i in X.columns]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = tree.export_graphviz(clf, out_file=None, \n                         feature_names=feature,  \n                         class_names=['g','r'],  \n                         filled=True, rounded=True,  \n                         special_characters=True) \ngraph=graphviz.Source(dot_data)\ngraph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 0)\n\nclf = GradientBoostingClassifier().fit(X_train, y_train)\nclf.score(X_test,y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, random_state = 0)\n\nclf = RandomForestClassifier(max_features = 12, random_state = 0)\nclf.fit(X_train, y_train)\n\nprint('Accuracy of RF classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of RF classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list_random=list(clf.feature_importances_)\n# feature_list_random\nl=[]\n\nfor i in range(0,len(feature_list_random)):\n    l.append((feature_list_random[i],i))\nl.sort(reverse=True)\nprint(l)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# random forest using limited feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_limited=df[f1]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X1_limited,Y, random_state = 0)\n\nclf = RandomForestClassifier(max_features=3,random_state = 0)\nclf.fit(X_train, y_train)\n\nprint('Accuracy of RF classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of RF classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_STATE=0\nfrom collections import OrderedDict\nensemble_clfs = [\n    (\"RandomForestClassifier, max_features='sqrt'\",\n        RandomForestClassifier(warm_start=True, oob_score=True,\n                               max_features=\"sqrt\",\n                               random_state=RANDOM_STATE)),\n    (\"RandomForestClassifier, max_features='log2'\",\n        RandomForestClassifier(warm_start=True, max_features='log2',\n                               oob_score=True,\n                               random_state=RANDOM_STATE)),\n    (\"RandomForestClassifier, max_features=None\",\n        RandomForestClassifier(warm_start=True, max_features=None,\n                               oob_score=True,\n                               random_state=RANDOM_STATE))\n]\n\n# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\nerror_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n\n# Range of `n_estimators` values to explore.\nmin_estimators = 15\nmax_estimators = 175\nplt.figure()\nfor label, clf in ensemble_clfs:\n    for i in range(min_estimators, max_estimators + 1):\n        clf.set_params(n_estimators=i)\n        clf.fit(X, Y)\n\n        # Record the OOB error for each `n_estimators=i` setting.\n        oob_error = 1 - clf.oob_score_\n        error_rate[label].append((i, oob_error))\n\n# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\nfor label, clf_err in error_rate.items():\n    xs, ys = zip(*clf_err)\n    plt.plot(xs, ys, label=label)\n\nplt.xlim(min_estimators, max_estimators)\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"OOB error rate\")\nplt.legend(loc=\"upper right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, random_state = 0)\n\nclf = LogisticRegression().fit(X_train, y_train)\n\nprint('Accuracy of Logistic regression classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of Logistic regression classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ny=df2['info']\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0)\n\nclf = RandomForestClassifier(max_features = 12, random_state = 0)\nclf.fit(X_train, y_train)\npredicted=clf.predict(X_test)\nconfusion = confusion_matrix(y_test,predicted)\n\nprint ('Most frequent class \\n', confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n# Accuracy = TP + TN / (TP + TN + FP + FN)\n# Precision = TP / (TP + FP)\n# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n# F1 = 2 * Precision * Recall / (Precision + Recall) \nprint('Accuracy: {:.2f}'.format(accuracy_score(y_test, predicted)))\nprint('Precision: {:.2f}'.format(precision_score(y_test, predicted)))\nprint('Recall: {:.2f}'.format(recall_score(y_test, predicted)))\nprint('F1: {:.2f}'.format(f1_score(y_test, predicted)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\nprecision, recall, thresholds = precision_recall_curve(y_test, predicted)\nclosest_zero = np.argmin(np.abs(thresholds))\nclosest_zero_p = precision[closest_zero]\nclosest_zero_r = recall[closest_zero]\n\nplt.figure()\nplt.xlim([0.0, 1.01])\nplt.ylim([0.0, 1.01])\nplt.plot(precision, recall, label='Precision-Recall Curve')\nplt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\nplt.xlabel('Precision', fontsize=16)\nplt.ylabel('Recall', fontsize=16)\nplt.axes().set_aspect('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\n\nfpr_lr, tpr_lr, _ = roc_curve(y_test, predicted)\nroc_auc_lr = auc(fpr_lr, tpr_lr)\n\nplt.figure()\nplt.xlim([-0.01, 1.00])\nplt.ylim([-0.01, 1.01])\nplt.plot(fpr_lr, tpr_lr, lw=3, label='ROC curve (area = {:0.2f})'.format(roc_auc_lr))\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curve ', fontsize=16)\nplt.legend(loc='lower right', fontsize=13)\nplt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\nplt.axes().set_aspect('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import average_precision_score\naverage_precision = average_precision_score(y_test, predicted)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))\nprecision, recall, _ = precision_recall_curve(y_test, predicted)\n\nplt.figure()\nplt.step(recall, precision, color='b', alpha=0.2,\n         where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.2,\n                 color='b')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n          average_precision))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"file_extension":".py","version":"3.6.4","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}