{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn=pd.read_csv('../input/churn-modelling/Churn_Modelling.csv',header=0)\nchurn.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets drop, RowNumber, Customer ID, Surname, as they wouldn't contribute to our analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn=churn.drop(['RowNumber','CustomerId','Surname'],axis=1)\nchurn.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exited column is our traget and hence, lets remove that and store it separately"},{"metadata":{"trusted":true},"cell_type":"code","source":"target=churn['Exited']\nchurn=churn.drop('Exited',axis=1)\nchurn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing entries or null values. But, there are some fields that have improper data type (Gender, HasCrCard,IsActiveMemenr, should be boolean values intead of int)"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn=churn.astype({'HasCrCard':bool,'IsActiveMember':bool})\nchurn.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target=target.astype(bool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets focus on the categorical variable. We would have to convert them to numerical variable for our model to work with them. This can be using the get_dummies function"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_updated=pd.get_dummies(churn,columns=['Geography','Gender'],prefix=['Geography','Gender'])\nchurn_updated.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_updated.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see, these new columns are of the type int. This has to be updated to bool, otherwise our model would be treating them as number and this would impact the performance of our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_updated=churn_updated.astype({'Geography_France':bool,'Geography_Germany':bool,'Geography_Spain':bool,'Gender_Female':bool,'Gender_Male':bool})\nchurn_updated.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, things seems good. We can now split the data into train, dev and test set to get started with our model design"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=churn_updated.iloc[0:8000,:]\nX_dev=churn_updated.iloc[8000:9000,:]\nX_test=churn_updated.iloc[9000:10000,:]\n\nprint(X_train.shape,'\\n',X_dev.shape,'\\n',X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train=target[0:8000]\nY_dev=target[8000:9000]\nY_test=target[9000:10000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y_train.shape,'\\n',Y_dev.shape,'\\n',Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets use Sklearn and its functions to scale all the features to the same range. This would help gradient descent converge faster"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.fit_transform(X_test)\nX_dev=sc.fit_transform(X_dev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test.shape,'\\n')\nprint(Y_test.shape,'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following steps converts all the data into numpy series (this is just a precautionary measure)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.asarray(X_train)\nY_train = np.asarray(Y_train)\nX_test = np.asarray(X_test)\nY_test = np.asarray(Y_test)\nX_dev=np.asarray(X_dev)\nY_dev=np.asarray(Y_dev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have data in the right form, lets import the required packages and get started with building models!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow import constant, float32\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets create the NN model\n\nclassifier=Sequential()\n\nclassifier.add(Dense(64,activation='relu',input_dim=13))\nclassifier.add(Dense(32,activation='relu'))\nclassifier.add(Dense(1,activation='sigmoid'))\n\nclassifier.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=classifier.fit(X_train, Y_train,epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test.shape,'\\n')\nprint(Y_test.shape,'\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.evaluate(X_dev,Y_dev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that the <b>accuracy of the model 1 on the training set is 90% and in the test set is 85%.</b> We can be sure that the model is not impacted by over fitting. However, the model can do much better on the training set. \n\nLets create different models to wotr with the available data, so that we can select the best model\n"},{"metadata":{},"cell_type":"markdown","source":"<h3>Model 2</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This model is going to be 1 layer deeper than the previous one\n\nclassifier2=keras.Sequential()\n\nclassifier2.add(keras.layers.Dense(64,activation='relu',input_shape=(13,)))\nclassifier2.add(keras.layers.Dense(64,activation='relu'))\nclassifier2.add(keras.layers.Dense(32,activation='relu'))\nclassifier2.add(keras.layers.Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets compile this model\n\nclassifier2.compile(optimizer='adam',loss='mse',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history2=classifier2.fit(X_train,Y_train,epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.evaluate(X_dev,Y_dev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Model 2 has a training set accuracy of 96% and dev set accuracy of 83.9%</b>"},{"metadata":{},"cell_type":"markdown","source":"<h3>Model 3</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier3=keras.Sequential()\n\nclassifier3.add(keras.layers.Dense(64,activation='sigmoid',input_shape=(13,)))\nclassifier3.add(keras.layers.Dense(32,activation='sigmoid'))\nclassifier3.add(keras.layers.Dense(1,activation='sigmoid'))\n\nclassifier3.compile(optimizer='adam',loss='mse',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier3.fit(X_train,Y_train,epochs=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier3.evaluate(X_dev,Y_dev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Using a model that uses Sigmoid function impacts the performance of the model on the training set too!\n\nTraining set accuracy: 87%\nDev set accuracy: 84%\n</b>    "},{"metadata":{},"cell_type":"markdown","source":"<b>Lets go with model one, as its dev set accuracy seems to be the highest</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=classifier.predict(X_test)\nprint(type(prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(prediction)):\n    if prediction[i]<=0.5:\n        prediction[i]=False\n    else:\n        prediction[i]=True\n\nprediction[0:5]    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}