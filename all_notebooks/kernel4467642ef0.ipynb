{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filepath='../input/for-simple-exercises-time-series-forecasting/Alcohol_Sales.csv'\ndata=pd.read_csv(filepath, index_col='DATE', parse_dates=True)\ndata['sales']=data['S4248SM144NCEN']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hypothesis:\n1. Months with festivals may have more sales \n2. Weekends may have more no. of sales\n3. As year increases sales may increase","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style='darkgrid')\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sales'].plot(figsize=(16,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we observe an increasing trend in data, this can validate our hypothesis that as year increases sales increases","execution_count":null},{"metadata":{},"cell_type":"raw","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['date']=data.index\ndata['month']=data['date'].dt.month\ndata['year']=data['date'].dt.year\ndata.drop('date', axis=1, inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ndata.groupby('year')['sales'].mean().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. This plot confirms hypothesis that sales increase as year increases.\n2. In year 2019 sales is less because we have only first month (january) data.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ndata.groupby('month')['sales'].mean().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that month of may - june have high sales and also december have high sales may be of christmas and newyear","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata.groupby(['year','month'])['sales'].mean().plot(figsize=(16,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly=data.resample('m').mean()\nyearly=data.resample('y').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs= plt.subplots(2,1)\nmonthly['sales'].plot(figsize=(16,8), title='Monthly',fontsize=12, ax=axs[0])\nyearly['sales'].plot(figsize=(16,8), title='Yearly', fontsize=12,  ax=axs[1])\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we seen that time series becomes more stable as we aggregate from monthly to yearly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=data.loc[:'2011-12-01']\nvalid=data.loc['2011-12-01':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ntrain['sales'].plot(kind='line',color='blue',label='train')\nvalid['sales'].plot(kind='line', color='orange',label='valid')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Moving Average of last 12 observations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = valid.copy()\ny_pred['movig_avg']=valid['sales'].rolling(6).mean().iloc[-1]\ntrain['sales'].plot(figsize=(16,8), color='blue', label='Train')\nvalid['sales'].plot(figsize=(16,8), color='orange', label='Valid')\ny_pred['movig_avg'].plot(figsize=(16,8), color='green', label='Moving Averages')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error \nfrom math import sqrt \nrms = sqrt(mean_squared_error(valid.sales, y_pred['movig_avg'])) \nprint(rms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Holt's linear model for trend","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nsm.tsa.seasonal_decompose(train['sales']).plot() \nresult = sm.tsa.stattools.adfuller(train.sales)\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.api import Holt\npred_y=valid.copy()\nfit1= Holt(np.asarray(train['sales'])).fit(smoothing_level= 0.3, smoothing_slope= 0.01)\npred_y['holt']=fit1.forecast(len(valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ntrain['sales'].plot(color='blue', label='Train')\nvalid['sales'].plot(color='orange', label='valid')\npred_y['holt'].plot(color='green', label='Holt')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(valid.sales, pred_y['holt']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ARIMA Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For good forcasting we have to remove trend from time-series data\n1. Using log to penalise increasing trend\n2. using shift diffrence to reduce trend\n3. making mean and covariance constant","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_stationarity(data):\n    rolmean=data.rolling(window=12).mean()\n    rolstd=data.rolling(window=12).std()\n    plt.plot(data, color='blue', label='original')\n    plt.plot(rolmean, color='red', label='Rolling Mean')\n    plt.plot(rolstd, color='black', label='Rolling std')\n    plt.legend(loc='best')\n    plt.show()\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(data, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    \n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pylab import rcParams \nrcParams['figure.figsize'] = 20,10\ntest_stationarity(train['sales'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_log=np.log(train['sales'])\nplt.figure(figsize=(16,8))\nmov_avg=train_log.rolling(12).mean()\nplt.plot(train_log,label='log')\nplt.plot(mov_avg,label='mov_avg')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_log_mov_avg_diff=train_log-mov_avg\ntrain_log_mov_avg_diff.dropna(inplace=True)\ntest_stationarity(train_log_mov_avg_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Log diffrence\ntrain_log_diff= train_log - train_log.shift(1)\ntrain_log_diff.fillna(0,inplace=True)\ntest_stationarity(train_log_diff)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since Test statistics < critical values so we can assume that series is stationary, but the constant moving average confirms our assumptions that series is stationary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf \nlag_acf = acf(train_log_diff.dropna(), nlags=25) \nlag_pacf = pacf(train_log_diff.dropna(), nlags=25, method='ols')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(lag_acf) \nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.title('Autocorrelation Function') \nplt.show() \nplt.plot(lag_pacf) \nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray') \nplt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray') \nplt.title('Partial Autocorrelation Function') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(train_log, order=(2, 1, 2))  \nresults_ARIMA = model.fit(disp=-1)  \nplt.plot(train_log_diff.dropna(),  label='original') \nplt.plot(results_ARIMA.fittedvalues, color='red', label='predicted') \nplt.legend(loc='best') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_prediction_diff(predict_diff, given_set):\n    predict_diff= predict_diff.cumsum().shift().fillna(0)\n    predict_base = pd.Series(np.ones(given_set.shape[0]) * np.log(given_set['sales'])[0], index = given_set.index)\n    predict_log = predict_base.add(predict_diff,fill_value=0)\n    predict = np.exp(predict_log)\n\n    plt.plot(given_set['sales'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['sales']))/given_set.shape[0]))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ARIMA_predict_diff=results_ARIMA.predict(start=\"2011-12-01\", end=\"2019-01-01\")\ncheck_prediction_diff(ARIMA_predict_diff, valid)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}