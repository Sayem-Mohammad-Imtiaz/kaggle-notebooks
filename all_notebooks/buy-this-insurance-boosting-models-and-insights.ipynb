{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report,f1_score\nsns.set(style='whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\nsubmission = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/sample_submission.csv')\ntest = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.heatmap(train.corr(),annot=True, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Response'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On observing the target variable we come across a class imbalance problem and we see a lot of customers bailing out of the company \nwhich raises the flag that there is something fundamentally wrong with the company."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Response',y='Vintage',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's no influence on the number of days the customer has been in touch with the company. This doesn't have any direct relevance with the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Response',y='Age',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People who are younger are more likely to discontinue their subscription/insurance with the company as compared to people of middle age."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.distplot(train['Policy_Sales_Channel'], bins=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's a majority of policies sold by the policy channels 26, 124 and 152. The organization needs to focus on other policy channels to increase the sales of insurance policies."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.distplot(train['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see a huge chunk of young people in our data whereas there's a wide distribution in middle and older age."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\n#train['Region_Code'].hist()\nsns.distplot(train['Region_Code'], bins=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that Region 28 has the largest response with a wide margin whereas other regions fail to catch up. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train['Response'],train['Previously_Insured'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A lot of customers who were previously insured and even the new ones bailed out in their first shot. Some people who weren't previously insured did decide to go again with the company(12.2%) but extremely few people who were ensured before decided to continue(0.04%). This company has a problem of customer retention."},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['source'] = 'train'\ntest['source'] = 'test'\ndf = pd.concat([train,test])\n\n\ndf['Policy_Region'] = df['Policy_Sales_Channel'].astype(str) + '_' + df['Region_Code'].astype(str)\ndf['Vehicle_License'] = df['Vehicle_Age'].astype(str) + '_' + df['Driving_License'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncat_cols = ['Gender','Driving_License','Region_Code','Previously_Insured',\n                'Vehicle_Damage','Policy_Sales_Channel','Policy_Region',\n                'Vehicle_Age','Vintage','Annual_Premium','Vehicle_License']\nlabel = 'Response'\n\ndef categorical_encoding(data, cat_cols):\n    label_dict = {}\n    for col in cat_cols:\n        le = LabelEncoder()\n        le.fit(df[col].unique().tolist())\n        df[col] = le.transform(df[col])\n        label_dict[col] = le\n    le = LabelEncoder()\n    df[label] = le.fit_transform(df[[label]])\n    label_dict[label] = le\n    return df, label_dict\ndf, label_dict = categorical_encoding(df, cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import KBinsDiscretizer\npremium_discretizer = KBinsDiscretizer(n_bins = 8, encode = 'ordinal', strategy = 'quantile')\ndf['Premium_bins'] = premium_discretizer.fit_transform(df['Annual_Premium'].values.reshape(-1,1)).astype(int)\n\nage_discretizer = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'quantile')\ndf['Age_bins'] = age_discretizer.fit_transform(df['Age'].values.reshape(-1,1)).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_counts = df['Gender'].value_counts().to_dict()\ndf['Gender_Count'] = df['Gender'].map(gender_counts)\n\nprevious_insured_counts = df['Previously_Insured'].value_counts().to_dict()\ndf['Pre_Insured_Counts'] = df['Previously_Insured'].map(previous_insured_counts)\n\nvehicle_age_counts = df['Vehicle_Age'].value_counts().to_dict()\ndf['vehicle_counts_age'] = df['Vehicle_Age'].map(vehicle_age_counts)\n\nvehicle_dam_count = df['Vehicle_Damage'].value_counts().to_dict()\ndf['Vehicle_Damage_Count'] = df['Vehicle_Damage'].map(vehicle_dam_count)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Policy_Per_Region'] = df.groupby('Region_Code')['Policy_Sales_Channel'].transform('nunique')\ndf['Policy_Per_Region_Sum'] = df.groupby('Region_Code')['Policy_Sales_Channel'].transform('sum')\n\ndf['Vintage'] = df['Vintage'] / 365 \n#df['Previous_Insure_Region'] = df.groupby('Region_Code')['Previously_Insured'].transform('sum')\ndf['Premium_Per_Region'] = df.groupby('Region_Code')['Annual_Premium'].transform('sum')\ndf['Premium_Per_Policy'] = df.groupby('Policy_Sales_Channel')['Annual_Premium'].transform('sum')\ndf['Policy_Per_Premium_Bin'] = df.groupby('Premium_bins')['Policy_Sales_Channel'].transform('nunique')\ndf['Premium_Per_Age_Bin'] = df.groupby('Age_bins')['Annual_Premium'].transform('mean')\ndf['Mean_Premium_Per_Region'] = df.groupby('Region_Code')['Annual_Premium'].transform('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"float_col = df.select_dtypes(include=['float'])\nfor col in float_col:\n  df[col] = df[col].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train = df[df['source']=='train']\ntarget = final_train['Response']\nfinal_train = final_train.drop(columns=['id', 'source', 'Response'])\nfinal_test = df[df['source']=='test']\nfinal_test_id = final_test['id']\nfinal_test = final_test.drop(columns=['id', 'source', 'Response'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold,  StratifiedShuffleSplit\nX = final_train\ny = train['Response']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=150303,stratify=y,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost Classifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nprobs = np.zeros(shape=(len(final_test)))\nscores = []\navg_loss = []\n\nX_train, y_train = final_train, target\nseeds = [1]\n\nfor seed in range(len(seeds)):\n    print(' ')\n    print('#'*100)\n    print('Seed', seeds[seed])\n    sf = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=seed)\n    for i, (idxT, idxV) in enumerate(sf.split(X_train, y_train)):\n        print('Fold', i)\n        print('Rows of Train= ', len(idxT), 'Rows of Holdout = ', len(idxV))\n        clf = XGBClassifier(n_estimators=100000,\n                           max_depth=7,\n                           min_child_weight = 5,\n                           learning_rate=0.03,\n                            subsample=0.7,\n                            colsample_bytree=0.8,\n                            gamma=0.2,\n                            scale_pos_weight = 1,\n                            objective='binary:logistic',\n                            random_state=1)\n        preds = clf.fit(X_train.iloc[idxT], y_train.iloc[idxT],\n                       eval_set=[(X_train.iloc[idxV], y_train.iloc[idxV])],\n                       verbose=100, eval_metric=['auc', 'logloss'],\n                       early_stopping_rounds=40)\n        probs_oof = clf.predict_proba(X_train.iloc[idxV])[:,1]\n        probs += clf.predict_proba(final_test)[:,1]\n        roc = roc_auc_score(y_train.iloc[idxV], probs_oof)\n        scores.append(roc)\n        avg_loss.append(clf.best_score)\n        print(\"ROC_AUC= \", roc)\n        print('#'*100)\n        \nprint(\"Loss= {0:0.5f}, {1:0.5f}\".format(np.array(avg_loss).mean(), np.array(avg_loss).std()))\nprint('%.6f (%.6f)' % (np.array(scores).mean(), np.array(scores).std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = probs / 5\np1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier()\nprobs = np.zeros(shape=(len(final_test)))\nscores = []\navg_loss = []\n\nX_train, y_train = final_train, target\nseeds = [1]\nmodel = model.fit(X_train, y_train,cat_features=cat_cols,eval_set=(X_test, y_test),plot=True,early_stopping_rounds=40,verbose=100)\ny_pred = model.predict(X_test)\nprobs_cat_train = model.predict_proba(X_train)[:, 1]\nprobs_cat_test = model.predict_proba(X_test)[:, 1]\nroc_auc_score(y_train, probs_cat_train)\nroc_auc_score(y_test, probs_cat_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = pd.Series(model.feature_importances_, index=X.columns)\nfeature_importance.nlargest(15).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_pred= model.predict_proba(final_test)[:, 1]\n#submission['Response'] = cat_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Response'] = 0.75 * cat_pred + 0.25 * p1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"result.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}