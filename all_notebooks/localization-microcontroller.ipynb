{"cells":[{"metadata":{"id":"zM-zvnYu7bW5","outputId":"733966b3-40fa-4db9-afdd-97fbd9ef62e8","trusted":false},"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","execution_count":0,"outputs":[]},{"metadata":{"id":"3brNQTZ01e1z"},"cell_type":"markdown","source":"# Packages"},{"metadata":{"id":"a-O-zSNwDPuY","outputId":"dc1f9fc1-e914-421f-fd37-d97b6ad7941c","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom copy import deepcopy\nimport os\nfrom xml.etree import cElementTree as ElementTree\nfrom sys import stdout\nfrom time import time\nfrom PIL import Image\nfrom display_box import dataset\nfrom display_box import XmlDictConfig,XmlListConfig,dataset\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6ly10dfZsXwG"},"cell_type":"markdown","source":"# MODEL without using transfer learning"},{"metadata":{"trusted":true,"id":"CZXfNCfqLsda","outputId":"2f47d810-aa08-4e6c-de78-3b446ee79c29"},"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,Conv2D,Input,MaxPooling2D,Flatten,MaxPool2D,Dropout\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import plot_model\nheight , width , channels = 225, 225 , 3\nn_classes = 4\nn_coordinate = 4\nimg_input = Input(shape=(height,width,channels))\nx = Conv2D(filters=32,kernel_size=(3,3),activation='relu')(img_input)\nx = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(x)\nx = MaxPool2D(pool_size=(2,2))(x)\nx = Dropout(0.1)(x)\nx = Conv2D(filters=128,kernel_size=(3,3),activation='relu')(x)\nx = MaxPool2D(pool_size=(2,2))(x)\nx = Dropout(0.2)(x)\nx = Conv2D(filters=256,kernel_size=(3,3),activation='relu')(x)\nx = MaxPool2D(pool_size=(2,2))(x)\nx = Dropout(0.2)(x)\nx = Flatten()(x)\ny = Dense(units=512,activation='sigmoid')(x)\nz = Dense(units=1024,activation='sigmoid')(x)\nconfidences= Dense(units = n_classes , activation='softmax',name='classes')(y)\ncoordinate = Dense(units = n_coordinate , activation='sigmoid',name='boxes')(z)\nmodel_loc_cls =Model(inputs=img_input, outputs = [coordinate,confidences])\nmodel_loc_cls.summary()\nplot_model(model_loc_cls,show_layer_names=True,show_shapes=True,rankdir='TB',expand_nested = True,dpi=75)","execution_count":null,"outputs":[]},{"metadata":{"id":"92iTVjViR5HB"},"cell_type":"markdown","source":"# data generator "},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title Image Data Generator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndef data_generator(TRAINING_DIR,TEST_DIR,TARGET_SIZE,COLOR_MODE,BATCH_SIZE=32,\n                     CLASSE_MODE='categorical', SHUFFLE=True,SHUFFLE_TEST = False):\n                   \n  training_datagen = ImageDataGenerator(rescale=1. / 255)                              \n  testing_datagen = ImageDataGenerator(rescale=1. / 255)\n  \"Takes the path to a directory & generates batches of augmented data.\"\n  train_generator = training_datagen.flow_from_directory(\n                                                          TRAINING_DIR,\n                                                          target_size=TARGET_SIZE,\n                                                          class_mode=CLASSE_MODE,\n                                                          color_mode=COLOR_MODE,\n                                                          batch_size=BATCH_SIZE,\n                                                          shuffle=SHUFFLE\n                                                        )\n  \"Takes the path to a directory & generates batches of augmented data.\"\n  test_generator = testing_datagen.flow_from_directory(\n                                                          TEST_DIR,\n                                                          target_size=TARGET_SIZE,\n                                                          class_mode=CLASSE_MODE,\n                                                          color_mode=COLOR_MODE,\n                                                          batch_size= BATCH_SIZE,\n                                                          shuffle=SHUFFLE_TEST\n                                                      )\n  return train_generator,test_generator","execution_count":null,"outputs":[]},{"metadata":{"id":"TgI9ZMx78mU6"},"cell_type":"markdown","source":"#MODEL MICRO DETECTER\n"},{"metadata":{"id":"fjr4Y4piBRBS","trusted":true,"collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nmobile=tf.keras.applications.MobileNetV2(\n    input_shape=None,\n    alpha=1.0,\n    include_top=True,\n    weights=\"imagenet\",\n    input_tensor=None,\n    pooling=None,\n    classes=1000,\n    classifier_activation=\"softmax\"\n    )","execution_count":null,"outputs":[]},{"metadata":{"id":"vZHpkBiuH50P"},"cell_type":"markdown","source":"SET TRAINABLE LAYERS"},{"metadata":{"id":"X1qU5oEVH_qy","trusted":false},"cell_type":"code","source":"for layer in mobile.layers[:-2]:\n  layer.trainable = False","execution_count":0,"outputs":[]},{"metadata":{"id":"wjF-gDDCem_E","outputId":"c84e2f87-39b2-459d-d411-14a04da16185","trusted":false},"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,Conv2D,Input,MaxPooling2D,Flatten,MaxPool2D,Dropout\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import plot_model\nheight , width , channels = 225, 225 , 3\nn_classes = 4\nn_coordinate = 4\nimg_input = mobile.input\nx = Conv2D(filters=32,kernel_size=(3,3),activation='relu')(img_input)\nx = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(x)\nx = MaxPool2D(pool_size=(2,2))(x)\nx = Dropout(0.1)(x)\nx = Conv2D(filters=128,kernel_size=(3,3),activation='relu')(x)\nx = MaxPool2D(pool_size=(2,2))(x)\nx = Dropout(0.2)(x)\nx = Conv2D(filters=256,kernel_size=(3,3),activation='relu')(x)\nx = MaxPool2D(pool_size=(2,2))(x)\nx = Dropout(0.2)(x)\nx = Flatten()(x)\ny= mobile.get_layer(index=-3).output\nz =Flatten()(y)\n\ncoordinate = Dense(units = n_coordinate , activation='sigmoid',name='boxes')(x)\nconfidences= Dense(units = n_classes , activation='softmax',name='classes')(z)\n\nmodel_loc_cls =Model(inputs=img_input, outputs = [coordinate,confidences])\nplot_model(model_loc_cls,show_layer_names=True,show_shapes=True,rankdir='TB',expand_nested = True,dpi=75)","execution_count":null,"outputs":[]},{"metadata":{"id":"OOumlySesfo_"},"cell_type":"markdown","source":"#COMPILE"},{"metadata":{"id":"XL6so6F3k43z","trusted":false},"cell_type":"code","source":"model_loc_cls.compile(\n                      optimizer = 'adam', loss = {'classes':'categorical_crossentropy',\n                                                  'boxes':'MeanAbsoluteError'},\n                      metrics= {'classes':'accuracy','boxes':custom.iou_metric},\n                      loss_weights={'classes':1.0,'boxes':10.0}\n                      )","execution_count":0,"outputs":[]},{"metadata":{"id":"v64N57118bJ5"},"cell_type":"markdown","source":"# READ TRAIN AND TEST XML  "},{"metadata":{"id":"RurZ8_f1D_xi","outputId":"21c84ae4-40d0-4753-8de9-6935130f44aa","trusted":true},"cell_type":"code","source":"objet = dataset(folder_path ='/kaggle/input/microcontroller-detection/Microcontroller Detection/train/',target_shape=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"id":"gYV85rWbFp6e","outputId":"a7f24a27-d0fa-411c-c1de-d600889b4901","trusted":true},"cell_type":"code","source":"objet_test= dataset(folder_path ='/kaggle/input/microcontroller-detection/Microcontroller Detection/test/',\n                    target_shape=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"IDmBUOKtRwDq"},"cell_type":"markdown","source":"#RUN PREPARE FOLDERS to image data generator \nfor one time"},{"metadata":{"id":"ZDUmWgwdJDLY","trusted":false},"cell_type":"code","source":"adapt_data_to_image_generator('/content/drive/My Drive/DATASETS/Microcontroller Detection/train_image_2',xml_objet =objet)\n#adapt_data_to_image_generator('/content/drive/My Drive/DATASETS/Microcontroller Detection/test_image_2',xml_objet =objet_test)","execution_count":0,"outputs":[]},{"metadata":{"id":"1TSKuh_cmFcx"},"cell_type":"markdown","source":"# Train detection micro controller "},{"metadata":{"id":"_kUweI8r2NGd","trusted":true},"cell_type":"code","source":"import tensorflow\nimport numpy as np\n'''\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nes = EarlyStopping(monitor ='val_loss', mode='min', verbose=0, patience=5)\nmc = ModelCheckpoint('/content/drive/My Drive/best_model.h5', monitor='boxes_iou_metric', mode='max', verbose=0, save_best_only=True)\n'''\nmy_histo = []\ndef tt(BATCH_SIZE):\n  return dd(BATCH_SIZE)[0],dd(BATCH_SIZE)[1]\n  \nBATCH_SIZE = 40;tuple_train,tuple_test = tt(BATCH_SIZE)\n\nfor e in range(50):\n  print('epochs ', e)\n\n  if e == 32: \n    BATCH_SIZE = 30;tuple_train,tuple_test = tt(BATCH_SIZE)\n  if e == 45 :\n     BATCH_SIZE = 15;tuple_train,tuple_test = tt(BATCH_SIZE)\n  if e == 50 : \n    BATCH_SIZE = 10;tuple_train,tuple_test = tt(BATCH_SIZE) \n  if e == 60 : \n    BATCH_SIZE = 5;tuple_train,tuple_test = tt(BATCH_SIZE)\n  datagen =tuple_train\n  batches_per_epoch = datagen.samples // datagen.batch_size + (datagen.samples % datagen.batch_size > 0)\n\n  \n  for i in range(batches_per_epoch):\n      curent_batch_train = next(datagen)\n      curent_batch_test = next(tuple_test)\n\n      def small(datagen):\n        current_index = ((datagen.batch_index-1) * datagen.batch_size)               \n        if current_index < 0:\n            if datagen.samples % datagen.batch_size > 0:\n                return max(0,datagen.samples - datagen.samples % datagen.batch_size)\n            else:\n                return max(0,datagen.samples - datagen.batch_size)\n        else:\n          return current_index \n\n      current_index = small(datagen)\n      current_index_test =small(tuple_test)\n\n      #Train\n      index_array = datagen.index_array[current_index:current_index + datagen.batch_size].tolist()\n      img_file_name = [datagen.filenames[idx].split('/')[-1]  for idx in index_array]\n      cls_one_hot_train=curent_batch_train[1]\n      #Test\n      index_array_test = tuple_test.index_array[current_index_test:current_index_test + tuple_test.batch_size].tolist()\n      img_file_name_test = [tuple_test.filenames[idx].split('/')[-1] for idx in index_array_test]        \n      cls_one_hot_test=curent_batch_test[1] \n\n      annot_train = [filename.split('/')[-1] for filename in objet.list_dir_files]\n      annot_test = [filename.split('/')[-1] for filename in objet_test.list_dir_files]\n      boxes_train = np.array( [objet.resized_coordinate [annot_train.index(name)]  for name in img_file_name] ) / 225.0\n      boxes_test = np.array( [objet_test.resized_coordinate[annot_test.index(name)] for name in img_file_name_test] ) / 225.0\n      # print(model_loc_cls.train_on_batch(x = curent_batch_train , y= [boxes_train, cls_one_hot_train],reset_metrics=False))\n      histo = model_loc_cls.fit(x = curent_batch_train , y= [boxes_train, cls_one_hot_train],\n                          validation_data=(curent_batch_test,[ boxes_test ,cls_one_hot_test ]),\n                          epochs = 1,\n                          batch_size = datagen.batch_size,\n                          initial_epoch = 0,\n                          callbacks=[mc]\n                        )      \n      if i == 0:\n        myhisto = histo.history\n      else:\n        for key in list(histo.history.keys()):\n          myhisto[key].append(histo.history[key][0])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"eWvpWuPClFU8"},"cell_type":"markdown","source":"# save or load model weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow\nclass file:\n    \n        def save_model(architecture,name_file,save_weight = True,dictn=True):\n\n            # serialize model(Architecture) to JSON\n            model_json = architecture.to_json()\n            with open(name_file+'_model'+\".json\", \"w\") as json_file:\n                print('Save the architecture of model to disk ... ')\n                json_file.write(model_json)\n            \n            # serialize weights to HDF5                \n            if save_weight:\n                \n              print(\"Save weights to disk ... \")\n              architecture.save_weights(name_file+'_weights'+\".h5\")\n        \n        \n        def load_model(path_model,path_weight=None):\n\n            # load json and create model\n            \n            json_file = open(path_model, 'r')\n            print(\"Load architecture model from disk ... \")\n            loaded_model_json = json_file.read()\n            json_file.close()\n            loaded_model = tensorflow.keras.models.model_from_json(loaded_model_json)\n            \n            # load weights into new model\n  \n            if path_weight:\n                print(\"Loaded weights model from disk ...\")\n                loaded_model.load_weights(path_weight)\n            \n            return loaded_model","execution_count":null,"outputs":[]},{"metadata":{"id":"uEzkKXsrmK37"},"cell_type":"markdown","source":"**SAVE**"},{"metadata":{"id":"wUn2Y3ZfC7JR","outputId":"ec794329-89df-4f14-8bab-95a9f2280f09","trusted":false},"cell_type":"code","source":"file.save_model(model_loc_cls,name_file='micro_transfer_learning_regression')","execution_count":0,"outputs":[]},{"metadata":{"id":"MxAQ60jqmMry"},"cell_type":"markdown","source":"**LOAD**"},{"metadata":{"id":"fTQPWvRFmJe_","outputId":"65678fdf-d714-4d66-c7c5-5d6ca87de36d","trusted":true},"cell_type":"code","source":"model = file.load_model(path_model='/kaggle/input/modelmicro/micro_transfer_learning_regression_model.json',\n                        path_weight= '/kaggle/input/modelmicro/micro_transfer_learning_regression_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"-_nrOvzvlMkM"},"cell_type":"markdown","source":"# display boxes"},{"metadata":{"id":"KmsNT4KHjCjV","outputId":"ab686579-40e6-4d0d-a898-706176e2b780","trusted":true},"cell_type":"code","source":"objet = dataset(folder_path ='/kaggle/input/microcontroller-detection/Microcontroller Detection/train/',target_shape=(224,224))\nobjet.show_boxes(30,model=model,subplot=(6,5,1))\n#prediction red\n#true boxes green","execution_count":null,"outputs":[]},{"metadata":{"id":"0Lq_K-U2cMQK","outputId":"d8bac77c-f094-45a2-f2da-ed66ed935892","trusted":true},"cell_type":"code","source":"objet_test= dataset(folder_path ='/kaggle/input/microcontroller-detection/Microcontroller Detection/test/',\n                    target_shape=(224,224))\nobjet_test.show_boxes(7,model=model,subplot=(2,5,1))","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"__Microcontroller_localization.ipynb","provenance":[],"collapsed_sections":["6ly10dfZsXwG","IDmBUOKtRwDq","92iTVjViR5HB","1TSKuh_cmFcx"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}