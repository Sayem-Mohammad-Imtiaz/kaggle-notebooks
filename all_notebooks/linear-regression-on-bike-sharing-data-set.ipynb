{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Linear Regression\n## Bike Sharing Assignment\n#### Problem Statement:\n\n- To identify the variables affecting demand for shared bikes in American Market\n\n- To know Which variables are significant in predicting the demand for shared bikes.\n\n- To know the accuracy of the model, i.e. how well these variables can predict demand.\n- To know the priority of the variables(i.e) influence the demand","metadata":{}},{"cell_type":"markdown","source":"# Steps for acheving above statements:\n    - Reading,understanding and visualising the data\n    - Preparing the data for modelling (train-set split,rescaling etc.)\n    - Training the model\n    - Residual analysis\n    - Predictions and evaluation on the test set","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Reading and Understanding the Data\n\nLet us first import NumPy and Pandas and read the housing dataset","metadata":{}},{"cell_type":"code","source":"## Supress Warnings \nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:39.83721Z","iopub.execute_input":"2021-08-30T08:03:39.83787Z","iopub.status.idle":"2021-08-30T08:03:39.849131Z","shell.execute_reply.started":"2021-08-30T08:03:39.837754Z","shell.execute_reply":"2021-08-30T08:03:39.848204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Importing required libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport calendar","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:39.850862Z","iopub.execute_input":"2021-08-30T08:03:39.851635Z","iopub.status.idle":"2021-08-30T08:03:40.951413Z","shell.execute_reply.started":"2021-08-30T08:03:39.851582Z","shell.execute_reply":"2021-08-30T08:03:40.950233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike = pd.read_csv('../input/bike-sharing-data-set/day.csv') ## Importing data set into bike variable","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:40.953496Z","iopub.execute_input":"2021-08-30T08:03:40.953961Z","iopub.status.idle":"2021-08-30T08:03:40.977855Z","shell.execute_reply.started":"2021-08-30T08:03:40.953887Z","shell.execute_reply":"2021-08-30T08:03:40.976846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head() # Display the top 5 records for the datframe using head() function","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:40.979407Z","iopub.execute_input":"2021-08-30T08:03:40.979701Z","iopub.status.idle":"2021-08-30T08:03:41.018407Z","shell.execute_reply.started":"2021-08-30T08:03:40.979671Z","shell.execute_reply":"2021-08-30T08:03:41.017091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.shape # Shape of data frame (no of rows & cols)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.021854Z","iopub.execute_input":"2021-08-30T08:03:41.022367Z","iopub.status.idle":"2021-08-30T08:03:41.028023Z","shell.execute_reply.started":"2021-08-30T08:03:41.022333Z","shell.execute_reply":"2021-08-30T08:03:41.02697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.info() ## Info of dataset , column data types and non- null values ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.029517Z","iopub.execute_input":"2021-08-30T08:03:41.0298Z","iopub.status.idle":"2021-08-30T08:03:41.063416Z","shell.execute_reply.started":"2021-08-30T08:03:41.029773Z","shell.execute_reply":"2021-08-30T08:03:41.062463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.isnull().sum() ### Looking for any null values present in given data set","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.06567Z","iopub.execute_input":"2021-08-30T08:03:41.066263Z","iopub.status.idle":"2021-08-30T08:03:41.08469Z","shell.execute_reply.started":"2021-08-30T08:03:41.06621Z","shell.execute_reply":"2021-08-30T08:03:41.083734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.describe() ## getting statistical information about dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.087172Z","iopub.execute_input":"2021-08-30T08:03:41.087892Z","iopub.status.idle":"2021-08-30T08:03:41.148946Z","shell.execute_reply.started":"2021-08-30T08:03:41.087833Z","shell.execute_reply":"2021-08-30T08:03:41.147861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dropping columns which are irrelavant for model building","metadata":{}},{"cell_type":"markdown","source":"Dropping instant, dteday,casual,registered\n\n- 1) Instant - it is necessary to drop the variable becuase it is unique identifier of row and not required for regression\n- 2) Dteday - It is a redundant variable as we could see we have yr,mnth explains \n- 3) Casual & Registered - these variables are target variables and they are not available all the time. Also we have given one more target variable where we can get combination of casual & regisrtered as cnt. So it is necessary to drop these variables as well","metadata":{}},{"cell_type":"code","source":"not_req = ['instant','dteday','casual','registered']\n\nbike = bike.drop(not_req,axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.150249Z","iopub.execute_input":"2021-08-30T08:03:41.150846Z","iopub.status.idle":"2021-08-30T08:03:41.158678Z","shell.execute_reply.started":"2021-08-30T08:03:41.150799Z","shell.execute_reply":"2021-08-30T08:03:41.157246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.shape ## checking whether changes are implemented","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.160188Z","iopub.execute_input":"2021-08-30T08:03:41.160522Z","iopub.status.idle":"2021-08-30T08:03:41.175805Z","shell.execute_reply.started":"2021-08-30T08:03:41.160492Z","shell.execute_reply":"2021-08-30T08:03:41.174414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head()  ## Its always good practise to inspect dataframe ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.177144Z","iopub.execute_input":"2021-08-30T08:03:41.17754Z","iopub.status.idle":"2021-08-30T08:03:41.200431Z","shell.execute_reply.started":"2021-08-30T08:03:41.177508Z","shell.execute_reply":"2021-08-30T08:03:41.199442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Before Starting anything lets visual; the data, By seeing data we could see there are some categorical variables mentioned with int data types and some numerical varariables","metadata":{}},{"cell_type":"code","source":"## Correlation between variables\n## Heat map is one of best way of visualizing correlation between variables\n\nplt.figure(figsize=(20,8))\nax = sns.heatmap(bike.corr(),annot=True)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:41.201844Z","iopub.execute_input":"2021-08-30T08:03:41.202159Z","iopub.status.idle":"2021-08-30T08:03:42.201336Z","shell.execute_reply.started":"2021-08-30T08:03:41.20213Z","shell.execute_reply":"2021-08-30T08:03:42.199985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## nunique is the function in python which helps to give some idea about the columns whether they are categorical or not\n\nbike.nunique()\nbike.nunique().sort_values(ascending= True)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:42.203034Z","iopub.execute_input":"2021-08-30T08:03:42.203477Z","iopub.status.idle":"2021-08-30T08:03:42.225569Z","shell.execute_reply.started":"2021-08-30T08:03:42.203428Z","shell.execute_reply":"2021-08-30T08:03:42.224231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## By seeing above info we can have some idea the cols [temp,hum,windspeed,atemp,cnt] are definetly numerical columns\n## The possible best way to visualize numerical columns is pair plot\n\nsns.pairplot(data=bike,vars=['temp', 'atemp', 'hum','windspeed','cnt'])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:42.227441Z","iopub.execute_input":"2021-08-30T08:03:42.227852Z","iopub.status.idle":"2021-08-30T08:03:47.216303Z","shell.execute_reply.started":"2021-08-30T08:03:42.227814Z","shell.execute_reply":"2021-08-30T08:03:47.215242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As per above visual we could see temp and atemp variables are highly correlated. To Avoid the multicollinearity it is better to drop one of these variables. Hence dropping atemp ","metadata":{}},{"cell_type":"code","source":"bike = bike.drop(['atemp'],axis =1) ## Using drop function and we need column so axis = 1","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:47.217748Z","iopub.execute_input":"2021-08-30T08:03:47.218415Z","iopub.status.idle":"2021-08-30T08:03:47.225619Z","shell.execute_reply.started":"2021-08-30T08:03:47.218355Z","shell.execute_reply":"2021-08-30T08:03:47.224401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.shape  ## Shape of data frame after atemp variable is removed","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:47.227018Z","iopub.execute_input":"2021-08-30T08:03:47.227597Z","iopub.status.idle":"2021-08-30T08:03:47.241186Z","shell.execute_reply.started":"2021-08-30T08:03:47.227557Z","shell.execute_reply":"2021-08-30T08:03:47.240045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co = bike[['temp', 'hum','windspeed','cnt']].corr()  ## calculating correlation again for numeric columns\nco","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:47.242779Z","iopub.execute_input":"2021-08-30T08:03:47.2433Z","iopub.status.idle":"2021-08-30T08:03:47.265827Z","shell.execute_reply.started":"2021-08-30T08:03:47.243263Z","shell.execute_reply":"2021-08-30T08:03:47.26495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Visualizing corr() using heat map for best representation\n\nax = sns.heatmap(co,annot=True,cmap=\"YlGnBu\")\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:47.267179Z","iopub.execute_input":"2021-08-30T08:03:47.2675Z","iopub.status.idle":"2021-08-30T08:03:47.742893Z","shell.execute_reply.started":"2021-08-30T08:03:47.267469Z","shell.execute_reply":"2021-08-30T08:03:47.741348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets visualize categorical columns in the data frame.\n    - As we could see there are categorical columns by above info using nunique function. \n    - To visualize the categories lets use box plot using subplot for all categorical columns","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 12))\n\nplt.subplot(2,4,1)\nsns.boxplot(x = 'yr', y = 'cnt', data = bike)\n\nplt.subplot(2,4,2)\nsns.boxplot(x = 'holiday', y = 'cnt', data = bike)\n\nplt.subplot(2,4,3)\nsns.boxplot(x = 'workingday', y = 'cnt', data = bike)\n\nplt.subplot(2,4,4)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = bike)\n\nplt.subplot(2,4,5)\nsns.boxplot(x = 'season', y = 'cnt', data = bike)\n\nplt.subplot(2,4,6)\nsns.boxplot(x = 'weekday', y = 'cnt', data = bike)\n\nplt.subplot(2,4,7)\nsns.boxplot(x = 'mnth', y = 'cnt', data = bike)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:47.749009Z","iopub.execute_input":"2021-08-30T08:03:47.74959Z","iopub.status.idle":"2021-08-30T08:03:48.922117Z","shell.execute_reply.started":"2021-08-30T08:03:47.749541Z","shell.execute_reply":"2021-08-30T08:03:48.921167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inferences:\n    - Defintely we could see in the year 2019, cnt values increased means shared bike count increased when compared to year 2018 \n    - Also we could see in the weather sit where 1 - represent clear have highest cnt value which means the shared bikes is pretty high in clear when compared to other weather condition.\n    - For the season spring has outlier of 8000 count how ever in the season 3 which is fall as per data dictionary has highest usage of bikes\n    - The cnt value is less during holidays\n    - In the month graph, except oct all the months never started with 0 which means atleast there are few usages where as in the oct month it has no bookings on someday however it has descent number of bookings when compared to other months","metadata":{}},{"cell_type":"markdown","source":"### We can also visualise these category columns by using hue as holiday","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 5))\nsns.boxplot(x = 'mnth', y = 'cnt', hue = 'holiday', data = bike)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:48.924255Z","iopub.execute_input":"2021-08-30T08:03:48.924719Z","iopub.status.idle":"2021-08-30T08:03:49.498727Z","shell.execute_reply.started":"2021-08-30T08:03:48.924684Z","shell.execute_reply":"2021-08-30T08:03:49.498006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-  <font color = blue>`By using above group we found some interesting insghts that in the month of March & August there is no cnt values on holidays`</font>","metadata":{}},{"cell_type":"markdown","source":"## Step 2: Data Preparation for model building\n    - Converting some category columns into categories\n    - Also for regression we need only numeric columns so if we have any of these we need to handle them","metadata":{}},{"cell_type":"code","source":"bike.shape\nbike.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.499753Z","iopub.execute_input":"2021-08-30T08:03:49.500165Z","iopub.status.idle":"2021-08-30T08:03:49.51455Z","shell.execute_reply.started":"2021-08-30T08:03:49.500133Z","shell.execute_reply":"2021-08-30T08:03:49.513795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.nunique().sort_values(ascending=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.515507Z","iopub.execute_input":"2021-08-30T08:03:49.515887Z","iopub.status.idle":"2021-08-30T08:03:49.538881Z","shell.execute_reply.started":"2021-08-30T08:03:49.515858Z","shell.execute_reply":"2021-08-30T08:03:49.537664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.weathersit.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.540348Z","iopub.execute_input":"2021-08-30T08:03:49.540675Z","iopub.status.idle":"2021-08-30T08:03:49.550498Z","shell.execute_reply.started":"2021-08-30T08:03:49.540644Z","shell.execute_reply":"2021-08-30T08:03:49.549277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Even though data dict provides 4 types of weather sit we have only 3 unique types in the dataset by above info","metadata":{}},{"cell_type":"markdown","source":"#### By above info of nunique function we could convert categorical variables to corresponding category\n\n- 1) season : It has 4 count and can map as (1 - Spring,2 - Summer,3-Fall,4-Winter)\n- 2) yr : No need to modify as it is binary categorical variable\n- 3) mnth : It has 12 Count and can map as (1- Jan to 12 -Dec)\n- 4) holiday, workingday : No need to modify as it is binary categorical variable\n- 5) Weekday : it has 7 count can be mapped as (sun - 0 to sat 6)\n- 6) Weathersit : it has 3 unique count can be mapped as (1 - Clear , 2 - Mist & Cloud, 3 - Light Rain & Snoq 4 - Heavy Rain & Snow","metadata":{}},{"cell_type":"code","source":"## Converting the required categorical colums into categories by using map function and for month using calendar function to extract month \nbike.season = bike.season.map({1: 'spring',2:'summer',3:'fall',4:'winter'})\nbike['mnth'] = bike['mnth'].apply(lambda x:calendar.month_name[x])   \nbike.weekday = bike.weekday.map({0:\"Sunday\",1:\"Monday\",2:\"Tuesday\",3:\"Wednesday\",4:\"Thursday\",5:\"Friday\",6:\"Saturday\"})\nbike.weathersit = bike.weathersit.map({1:'Clear',2:'Mist & Cloudy', \n                                             3:'Light Rain & Snow',4:'Heavy Rain & Snow'})","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.552141Z","iopub.execute_input":"2021-08-30T08:03:49.552814Z","iopub.status.idle":"2021-08-30T08:03:49.575689Z","shell.execute_reply.started":"2021-08-30T08:03:49.552763Z","shell.execute_reply":"2021-08-30T08:03:49.57474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Inspect the data frame whether changes has been reflected or not\nbike.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.577333Z","iopub.execute_input":"2021-08-30T08:03:49.578013Z","iopub.status.idle":"2021-08-30T08:03:49.599201Z","shell.execute_reply.started":"2021-08-30T08:03:49.577959Z","shell.execute_reply":"2021-08-30T08:03:49.59816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Lets look the info of dataframe for data types etc\nbike.info() ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.600588Z","iopub.execute_input":"2021-08-30T08:03:49.601194Z","iopub.status.idle":"2021-08-30T08:03:49.619808Z","shell.execute_reply.started":"2021-08-30T08:03:49.601146Z","shell.execute_reply":"2021-08-30T08:03:49.618405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Dummy variables for the categorical columns which just now created above","metadata":{}},{"cell_type":"code","source":"cat_cols = ['season','mnth','weekday','weathersit']\n\ncat_df = bike[cat_cols]\ncat_df","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.621354Z","iopub.execute_input":"2021-08-30T08:03:49.621761Z","iopub.status.idle":"2021-08-30T08:03:49.643084Z","shell.execute_reply.started":"2021-08-30T08:03:49.621725Z","shell.execute_reply":"2021-08-30T08:03:49.64187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`In pandas we have function called get dummies to get dummies  of respective columns and by default it will also include the first set, but to avoid redundancy and multi collinearity\nit is necessary to drop first set`","metadata":{}},{"cell_type":"code","source":"cat_df = pd.get_dummies(cat_df,drop_first=True) ## We are creating a seperated dataframe for all dummy variables","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.644651Z","iopub.execute_input":"2021-08-30T08:03:49.645113Z","iopub.status.idle":"2021-08-30T08:03:49.658771Z","shell.execute_reply.started":"2021-08-30T08:03:49.645065Z","shell.execute_reply":"2021-08-30T08:03:49.657765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_df.head() ## Inspecting top 5 rows for results ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.66062Z","iopub.execute_input":"2021-08-30T08:03:49.661401Z","iopub.status.idle":"2021-08-30T08:03:49.691013Z","shell.execute_reply.started":"2021-08-30T08:03:49.661346Z","shell.execute_reply":"2021-08-30T08:03:49.689588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Merging cat_df dataframe with bike\n\nbike = pd.concat([bike,cat_df],axis = 1)    ### Now that we concat the dummy variables data frame with our original df bike to use of them\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.692894Z","iopub.execute_input":"2021-08-30T08:03:49.693382Z","iopub.status.idle":"2021-08-30T08:03:49.702571Z","shell.execute_reply.started":"2021-08-30T08:03:49.693332Z","shell.execute_reply":"2021-08-30T08:03:49.700983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.shape  ## Geeting shape whether they were added to data frame or not","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.704708Z","iopub.execute_input":"2021-08-30T08:03:49.70525Z","iopub.status.idle":"2021-08-30T08:03:49.723047Z","shell.execute_reply.started":"2021-08-30T08:03:49.70517Z","shell.execute_reply":"2021-08-30T08:03:49.721815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head() ## Checking few rows of data frame","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.724716Z","iopub.execute_input":"2021-08-30T08:03:49.725242Z","iopub.status.idle":"2021-08-30T08:03:49.759558Z","shell.execute_reply.started":"2021-08-30T08:03:49.725207Z","shell.execute_reply":"2021-08-30T08:03:49.758108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns',50)  ## By Default the pandas allowed max 30 cols Hence pd.set_option is used","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.761477Z","iopub.execute_input":"2021-08-30T08:03:49.76195Z","iopub.status.idle":"2021-08-30T08:03:49.770247Z","shell.execute_reply.started":"2021-08-30T08:03:49.761878Z","shell.execute_reply":"2021-08-30T08:03:49.76917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.771419Z","iopub.execute_input":"2021-08-30T08:03:49.771713Z","iopub.status.idle":"2021-08-30T08:03:49.804143Z","shell.execute_reply.started":"2021-08-30T08:03:49.771684Z","shell.execute_reply":"2021-08-30T08:03:49.803115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## To avoid reduncy we will drop the variables for which dummy variables are created\n\nbike = bike.drop(cat_cols,axis = 1) \n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.80548Z","iopub.execute_input":"2021-08-30T08:03:49.805803Z","iopub.status.idle":"2021-08-30T08:03:49.816386Z","shell.execute_reply.started":"2021-08-30T08:03:49.805764Z","shell.execute_reply":"2021-08-30T08:03:49.815542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.817613Z","iopub.execute_input":"2021-08-30T08:03:49.818103Z","iopub.status.idle":"2021-08-30T08:03:49.84988Z","shell.execute_reply.started":"2021-08-30T08:03:49.818063Z","shell.execute_reply":"2021-08-30T08:03:49.848899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.851339Z","iopub.execute_input":"2021-08-30T08:03:49.851965Z","iopub.status.idle":"2021-08-30T08:03:49.864074Z","shell.execute_reply.started":"2021-08-30T08:03:49.851919Z","shell.execute_reply":"2021-08-30T08:03:49.863013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we have prepared data for regression techniques such as (splitting data,model building etc.,)","metadata":{}},{"cell_type":"markdown","source":"### Step 4 : Split the data set into training and test","metadata":{}},{"cell_type":"code","source":"## Importing required libraries for Linear regression \nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\n\n\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:49.865503Z","iopub.execute_input":"2021-08-30T08:03:49.866199Z","iopub.status.idle":"2021-08-30T08:03:51.201885Z","shell.execute_reply.started":"2021-08-30T08:03:49.866159Z","shell.execute_reply":"2021-08-30T08:03:51.200961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)    ## Random seed is function in numpy to select random from our dataset\n## By using train split menthod we are diving the given data set into training and test in the size of 70%:30% ratio\nbike_train,bike_test=train_test_split(bike, train_size = 0.7, random_state = 100)  ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.203447Z","iopub.execute_input":"2021-08-30T08:03:51.204171Z","iopub.status.idle":"2021-08-30T08:03:51.213679Z","shell.execute_reply.started":"2021-08-30T08:03:51.204115Z","shell.execute_reply":"2021-08-30T08:03:51.212461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_train.shape ## Shape of training set after split ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.215491Z","iopub.execute_input":"2021-08-30T08:03:51.216316Z","iopub.status.idle":"2021-08-30T08:03:51.225187Z","shell.execute_reply.started":"2021-08-30T08:03:51.216264Z","shell.execute_reply":"2021-08-30T08:03:51.223929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_test.shape ## Shape of test set after split","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.226775Z","iopub.execute_input":"2021-08-30T08:03:51.227135Z","iopub.status.idle":"2021-08-30T08:03:51.236267Z","shell.execute_reply.started":"2021-08-30T08:03:51.227102Z","shell.execute_reply":"2021-08-30T08:03:51.235195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_train.head()  ## Inspecting data for train set","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.238089Z","iopub.execute_input":"2021-08-30T08:03:51.238633Z","iopub.status.idle":"2021-08-30T08:03:51.267237Z","shell.execute_reply.started":"2021-08-30T08:03:51.238578Z","shell.execute_reply":"2021-08-30T08:03:51.265959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols = ['temp','hum','windspeed','cnt']   ## Creating list of numeric columns which requires scaling","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.268578Z","iopub.execute_input":"2021-08-30T08:03:51.268895Z","iopub.status.idle":"2021-08-30T08:03:51.272662Z","shell.execute_reply.started":"2021-08-30T08:03:51.268864Z","shell.execute_reply":"2021-08-30T08:03:51.271943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling is a feature in regression which is very helpful for good interpretation. As we could see the numeric columns there are some numeric coulumns like cnt, hum have different scales with each other. To interpret the coefficient in model it would be difficult, so if we scale them by using scaling techniques it would be very easy to interpret coeff.","metadata":{}},{"cell_type":"markdown","source":"`Using MinMax Scaling technique which is also normalization technique to get all the results of columns in between 0 and 1 where highest value in column is 1 and lowest is 0`","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()  ## Creating MinMaxScaler object \nbike_train[num_cols] = scaler.fit_transform(bike_train[num_cols]) ## We are fiiting scaler on data set and also transforming results into dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.274078Z","iopub.execute_input":"2021-08-30T08:03:51.274602Z","iopub.status.idle":"2021-08-30T08:03:51.295565Z","shell.execute_reply.started":"2021-08-30T08:03:51.274566Z","shell.execute_reply":"2021-08-30T08:03:51.294448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_train.head() ## Inspecting data frame","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.297111Z","iopub.execute_input":"2021-08-30T08:03:51.29743Z","iopub.status.idle":"2021-08-30T08:03:51.330313Z","shell.execute_reply.started":"2021-08-30T08:03:51.297399Z","shell.execute_reply":"2021-08-30T08:03:51.329125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_train.describe()  ## After scaling it is good to use describe function because describe will give min max of entries in the columns apart from mean,median,count","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.331721Z","iopub.execute_input":"2021-08-30T08:03:51.332297Z","iopub.status.idle":"2021-08-30T08:03:51.450223Z","shell.execute_reply.started":"2021-08-30T08:03:51.332252Z","shell.execute_reply":"2021-08-30T08:03:51.44904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the correlation coefficients to see which variables are highly correlated on training data set \n\nplt.figure(figsize=(25,15))\nax = sns.heatmap(bike_train.corr(),annot=True)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:51.452023Z","iopub.execute_input":"2021-08-30T08:03:51.452466Z","iopub.status.idle":"2021-08-30T08:03:55.932228Z","shell.execute_reply.started":"2021-08-30T08:03:51.45242Z","shell.execute_reply":"2021-08-30T08:03:55.931085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_\"By Above heat map we could see temp variable is highly correlated with cnt variable. So lets visulize that particular alone\"_","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=[5,5])\nplt.scatter(bike_train.temp, bike_train.cnt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:55.933539Z","iopub.execute_input":"2021-08-30T08:03:55.933862Z","iopub.status.idle":"2021-08-30T08:03:56.085635Z","shell.execute_reply.started":"2021-08-30T08:03:55.933832Z","shell.execute_reply":"2021-08-30T08:03:56.084609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## To predict some more varibles or derieve fractors lets build Model building using RFE","metadata":{}},{"cell_type":"code","source":"y_train = bike_train.pop('cnt')  ## Dividing data set into X variable and y varibles where X Variables are independent variables and y is dependent variable\nX_train = bike_train","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.087119Z","iopub.execute_input":"2021-08-30T08:03:56.087442Z","iopub.status.idle":"2021-08-30T08:03:56.092528Z","shell.execute_reply.started":"2021-08-30T08:03:56.087411Z","shell.execute_reply":"2021-08-30T08:03:56.091471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = LinearRegression()   ## Creating Linear regression object \nlm.fit(X_train, y_train) ### Fit the model on data set \n\nrfe = RFE(lm, 12)             # running RFE of top 12 variables which we will select \nrfe = rfe.fit(X_train, y_train) ## Fit it ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.093799Z","iopub.execute_input":"2021-08-30T08:03:56.094237Z","iopub.status.idle":"2021-08-30T08:03:56.337791Z","shell.execute_reply.started":"2021-08-30T08:03:56.094202Z","shell.execute_reply":"2021-08-30T08:03:56.336573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Rfe has two function which makes our job earier is support function to give bool values true or false for consideration and ranking on priority wise\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))  ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.339403Z","iopub.execute_input":"2021-08-30T08:03:56.339742Z","iopub.status.idle":"2021-08-30T08:03:56.351742Z","shell.execute_reply.started":"2021-08-30T08:03:56.339703Z","shell.execute_reply":"2021-08-30T08:03:56.350406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Now that we have columns needs to be considered for model building\ncol = X_train.columns[rfe.support_] ## Extracting column names from data set \ncol","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.353499Z","iopub.execute_input":"2021-08-30T08:03:56.353861Z","iopub.status.idle":"2021-08-30T08:03:56.365822Z","shell.execute_reply.started":"2021-08-30T08:03:56.353824Z","shell.execute_reply":"2021-08-30T08:03:56.365036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_rfe = X_train[col]  ## Creating another data frame with selected columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.367207Z","iopub.execute_input":"2021-08-30T08:03:56.3675Z","iopub.status.idle":"2021-08-30T08:03:56.378646Z","shell.execute_reply.started":"2021-08-30T08:03:56.367471Z","shell.execute_reply":"2021-08-30T08:03:56.377779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_rfe.head() ## Inspecting data frame of top 5 rows","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.379742Z","iopub.execute_input":"2021-08-30T08:03:56.380156Z","iopub.status.idle":"2021-08-30T08:03:56.40466Z","shell.execute_reply.started":"2021-08-30T08:03:56.380125Z","shell.execute_reply":"2021-08-30T08:03:56.403856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## We need to add constant because it fits a regression line passing through the origin, by default.in statsmodel \nX_train_rfe = sm.add_constant(X_train_rfe)  ## Adding constant","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.414685Z","iopub.execute_input":"2021-08-30T08:03:56.41519Z","iopub.status.idle":"2021-08-30T08:03:56.42711Z","shell.execute_reply.started":"2021-08-30T08:03:56.415146Z","shell.execute_reply":"2021-08-30T08:03:56.42575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm1 = sm.OLS(y_train,X_train_rfe).fit()  ## Using ordinary Least squared is the best method for linear building for models\nlm1.params","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.429849Z","iopub.execute_input":"2021-08-30T08:03:56.430375Z","iopub.status.idle":"2021-08-30T08:03:56.452489Z","shell.execute_reply.started":"2021-08-30T08:03:56.430334Z","shell.execute_reply":"2021-08-30T08:03:56.450651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm1.summary()) ## Printing summary of model","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.454181Z","iopub.execute_input":"2021-08-30T08:03:56.45496Z","iopub.status.idle":"2021-08-30T08:03:56.477102Z","shell.execute_reply.started":"2021-08-30T08:03:56.454894Z","shell.execute_reply":"2021-08-30T08:03:56.475456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### By above summary information we could see R-Squared and adjusted R-Squared are almost similar and F-Stat is almost zero and p values for atleast 11 variables shows statistically significant","metadata":{}},{"cell_type":"markdown","source":"#### How ever we will use variance inflaction factor to determine how much the variables are correlated with each other","metadata":{}},{"cell_type":"code","source":"vif = pd.DataFrame()\nX = X_train_rfe\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.479233Z","iopub.execute_input":"2021-08-30T08:03:56.479741Z","iopub.status.idle":"2021-08-30T08:03:56.516227Z","shell.execute_reply.started":"2021-08-30T08:03:56.479691Z","shell.execute_reply":"2021-08-30T08:03:56.515181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`We can observer constant has VIF but however constant needs to be removed from VIF calculation`","metadata":{}},{"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop(['const'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.517513Z","iopub.execute_input":"2021-08-30T08:03:56.518115Z","iopub.status.idle":"2021-08-30T08:03:56.525108Z","shell.execute_reply.started":"2021-08-30T08:03:56.518069Z","shell.execute_reply":"2021-08-30T08:03:56.523817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif = pd.DataFrame()\nX = X_train_rfe\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.526943Z","iopub.execute_input":"2021-08-30T08:03:56.527395Z","iopub.status.idle":"2021-08-30T08:03:56.572787Z","shell.execute_reply.started":"2021-08-30T08:03:56.527345Z","shell.execute_reply":"2021-08-30T08:03:56.571269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`From above table we can see hum variable has high VIF we will drop this variable`","metadata":{}},{"cell_type":"code","source":"X_train_new1 = X_train_rfe.drop([\"hum\"], axis = 1) ## Dropping the hum column and adding to new dataframe","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.575047Z","iopub.execute_input":"2021-08-30T08:03:56.575537Z","iopub.status.idle":"2021-08-30T08:03:56.583703Z","shell.execute_reply.started":"2021-08-30T08:03:56.57549Z","shell.execute_reply":"2021-08-30T08:03:56.582282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new1 = sm.add_constant(X_train_new1) ## Adding constant to df","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.585661Z","iopub.execute_input":"2021-08-30T08:03:56.586196Z","iopub.status.idle":"2021-08-30T08:03:56.607764Z","shell.execute_reply.started":"2021-08-30T08:03:56.586141Z","shell.execute_reply":"2021-08-30T08:03:56.606157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm2 = sm.OLS(y_train,X_train_new1).fit() ## model build again","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.609755Z","iopub.execute_input":"2021-08-30T08:03:56.610303Z","iopub.status.idle":"2021-08-30T08:03:56.626447Z","shell.execute_reply.started":"2021-08-30T08:03:56.610251Z","shell.execute_reply":"2021-08-30T08:03:56.624781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.627842Z","iopub.execute_input":"2021-08-30T08:03:56.628534Z","iopub.status.idle":"2021-08-30T08:03:56.658833Z","shell.execute_reply.started":"2021-08-30T08:03:56.628489Z","shell.execute_reply":"2021-08-30T08:03:56.657403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`As per above summary of lm2, there is no drastic change in R and adjusted R2 square and also p value also can infer <=0.05 which are statistically significant`","metadata":{}},{"cell_type":"markdown","source":"#### Let's caluculate VIF again to look after results","metadata":{}},{"cell_type":"code","source":"X_train_new1 = X_train_new1.drop(['const'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.660649Z","iopub.execute_input":"2021-08-30T08:03:56.661037Z","iopub.status.idle":"2021-08-30T08:03:56.669422Z","shell.execute_reply.started":"2021-08-30T08:03:56.660999Z","shell.execute_reply":"2021-08-30T08:03:56.666352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif = pd.DataFrame()\nX = X_train_new1\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.671636Z","iopub.execute_input":"2021-08-30T08:03:56.672614Z","iopub.status.idle":"2021-08-30T08:03:56.716511Z","shell.execute_reply.started":"2021-08-30T08:03:56.672553Z","shell.execute_reply":"2021-08-30T08:03:56.715231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As per above info we could see VIF has reduced has reduced drastically after dropping hum column . Now lets remove one more column to improve model. Selection of mnth_July has 0.05 p value -","metadata":{}},{"cell_type":"code","source":"X_train_new2 = X_train_new1.drop([\"mnth_July\"], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.718429Z","iopub.execute_input":"2021-08-30T08:03:56.718923Z","iopub.status.idle":"2021-08-30T08:03:56.727631Z","shell.execute_reply.started":"2021-08-30T08:03:56.718855Z","shell.execute_reply":"2021-08-30T08:03:56.725827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new2 = sm.add_constant(X_train_new2) ## Adding constant","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.730198Z","iopub.execute_input":"2021-08-30T08:03:56.730754Z","iopub.status.idle":"2021-08-30T08:03:56.744543Z","shell.execute_reply.started":"2021-08-30T08:03:56.730702Z","shell.execute_reply":"2021-08-30T08:03:56.743345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm3 = sm.OLS(y_train,X_train_new2).fit()   ## Building model again","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.746559Z","iopub.execute_input":"2021-08-30T08:03:56.747048Z","iopub.status.idle":"2021-08-30T08:03:56.760276Z","shell.execute_reply.started":"2021-08-30T08:03:56.747002Z","shell.execute_reply":"2021-08-30T08:03:56.758855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm3.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.76187Z","iopub.execute_input":"2021-08-30T08:03:56.762787Z","iopub.status.idle":"2021-08-30T08:03:56.797944Z","shell.execute_reply.started":"2021-08-30T08:03:56.762726Z","shell.execute_reply":"2021-08-30T08:03:56.796881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`From above info the pvalue is 0.08 for season . Before that we could see VIF values` ","metadata":{}},{"cell_type":"code","source":"X_train_new2 = X_train_new2.drop(['const'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.799503Z","iopub.execute_input":"2021-08-30T08:03:56.799939Z","iopub.status.idle":"2021-08-30T08:03:56.806861Z","shell.execute_reply.started":"2021-08-30T08:03:56.799874Z","shell.execute_reply":"2021-08-30T08:03:56.805432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif = pd.DataFrame()\nX = X_train_new2\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.808652Z","iopub.execute_input":"2021-08-30T08:03:56.809145Z","iopub.status.idle":"2021-08-30T08:03:56.845104Z","shell.execute_reply.started":"2021-08-30T08:03:56.809095Z","shell.execute_reply":"2021-08-30T08:03:56.843843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Now the VIF has below 5 which is acceptable and for season_spring it has 0.008 value so lets improve model furthur`","metadata":{}},{"cell_type":"code","source":"X_train_new3 = X_train_new2.drop([\"season_spring\"], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.84721Z","iopub.execute_input":"2021-08-30T08:03:56.847648Z","iopub.status.idle":"2021-08-30T08:03:56.854537Z","shell.execute_reply.started":"2021-08-30T08:03:56.847601Z","shell.execute_reply":"2021-08-30T08:03:56.853332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new3 = sm.add_constant(X_train_new3)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.856279Z","iopub.execute_input":"2021-08-30T08:03:56.856701Z","iopub.status.idle":"2021-08-30T08:03:56.871482Z","shell.execute_reply.started":"2021-08-30T08:03:56.856664Z","shell.execute_reply":"2021-08-30T08:03:56.870205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm4 = sm.OLS(y_train,X_train_new3).fit()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.873341Z","iopub.execute_input":"2021-08-30T08:03:56.873716Z","iopub.status.idle":"2021-08-30T08:03:56.882516Z","shell.execute_reply.started":"2021-08-30T08:03:56.873681Z","shell.execute_reply":"2021-08-30T08:03:56.881233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm4.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.884185Z","iopub.execute_input":"2021-08-30T08:03:56.884668Z","iopub.status.idle":"2021-08-30T08:03:56.91943Z","shell.execute_reply.started":"2021-08-30T08:03:56.884625Z","shell.execute_reply":"2021-08-30T08:03:56.918014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new3 = X_train_new3.drop(['const'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.920667Z","iopub.execute_input":"2021-08-30T08:03:56.921028Z","iopub.status.idle":"2021-08-30T08:03:56.927041Z","shell.execute_reply.started":"2021-08-30T08:03:56.920993Z","shell.execute_reply":"2021-08-30T08:03:56.925941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif = pd.DataFrame()\nX = X_train_new3\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.928653Z","iopub.execute_input":"2021-08-30T08:03:56.929317Z","iopub.status.idle":"2021-08-30T08:03:56.96253Z","shell.execute_reply.started":"2021-08-30T08:03:56.929266Z","shell.execute_reply":"2021-08-30T08:03:56.961113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Interference: \n    - Now that we have our final model which has 83 for r2 squared which is pretty good model\n    - Also the adjusted and normal R2 square are almost similar which is acceptable\n    - The F-Stat metric is again good\n    - ALl the pvalues have 0 values which is strongly say that variables are statistically significant \n    - Also the VIF for all predictors are less than 5 ","metadata":{}},{"cell_type":"markdown","source":"## Step 7: Residual Analysis of the train data\n\nSo, now to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like.","metadata":{}},{"cell_type":"code","source":"X_train_new3.shape ## Shape of final model df\nX_train_new3 = sm.add_constant(X_train_new3) ##  Adding constant variable","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.964426Z","iopub.execute_input":"2021-08-30T08:03:56.964878Z","iopub.status.idle":"2021-08-30T08:03:56.976809Z","shell.execute_reply.started":"2021-08-30T08:03:56.964832Z","shell.execute_reply":"2021-08-30T08:03:56.975533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_cnt = lm4.predict(X_train_new3)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.978649Z","iopub.execute_input":"2021-08-30T08:03:56.979135Z","iopub.status.idle":"2021-08-30T08:03:56.987243Z","shell.execute_reply.started":"2021-08-30T08:03:56.979087Z","shell.execute_reply":"2021-08-30T08:03:56.986294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nsns.distplot((y_train - y_train_cnt), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)                         # X-label\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:56.990548Z","iopub.execute_input":"2021-08-30T08:03:56.991064Z","iopub.status.idle":"2021-08-30T08:03:57.205828Z","shell.execute_reply.started":"2021-08-30T08:03:56.991026Z","shell.execute_reply":"2021-08-30T08:03:57.204845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 8: Making Predictions Using the Final Model\n\nNow that we have fitted the model and checked the normality of error terms and it is normally distributed\nit's time to go ahead and make predictions using the final, i.e. fourth model.","metadata":{}},{"cell_type":"markdown","source":"### Lets perform same operations on test data set like scaling and make predictions","metadata":{}},{"cell_type":"code","source":"bike_test[num_cols] = scaler.transform(bike_test[num_cols]) ## Instead of fit_tranform we will only transform on test data set because its already fitted on train set","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.207296Z","iopub.execute_input":"2021-08-30T08:03:57.207651Z","iopub.status.idle":"2021-08-30T08:03:57.219613Z","shell.execute_reply.started":"2021-08-30T08:03:57.207616Z","shell.execute_reply":"2021-08-30T08:03:57.218458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_test.describe() ## Describe function to see the values again","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.221082Z","iopub.execute_input":"2021-08-30T08:03:57.221465Z","iopub.status.idle":"2021-08-30T08:03:57.334699Z","shell.execute_reply.started":"2021-08-30T08:03:57.22142Z","shell.execute_reply":"2021-08-30T08:03:57.333494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.336192Z","iopub.execute_input":"2021-08-30T08:03:57.336551Z","iopub.status.idle":"2021-08-30T08:03:57.362918Z","shell.execute_reply.started":"2021-08-30T08:03:57.33652Z","shell.execute_reply":"2021-08-30T08:03:57.361789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Dividing data set into X and y variables \ny_test = bike_test.pop('cnt') \nX_test = bike_test","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.364444Z","iopub.execute_input":"2021-08-30T08:03:57.364765Z","iopub.status.idle":"2021-08-30T08:03:57.37028Z","shell.execute_reply.started":"2021-08-30T08:03:57.364729Z","shell.execute_reply":"2021-08-30T08:03:57.369218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = sm.add_constant(X_test) ## Adding the constant ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.371745Z","iopub.execute_input":"2021-08-30T08:03:57.372226Z","iopub.status.idle":"2021-08-30T08:03:57.392759Z","shell.execute_reply.started":"2021-08-30T08:03:57.372186Z","shell.execute_reply":"2021-08-30T08:03:57.391614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.columns  ## Getting test columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.39435Z","iopub.execute_input":"2021-08-30T08:03:57.394688Z","iopub.status.idle":"2021-08-30T08:03:57.408988Z","shell.execute_reply.started":"2021-08-30T08:03:57.394656Z","shell.execute_reply":"2021-08-30T08:03:57.407762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new3.columns ## Getting final model training data set columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.4107Z","iopub.execute_input":"2021-08-30T08:03:57.411061Z","iopub.status.idle":"2021-08-30T08:03:57.425405Z","shell.execute_reply.started":"2021-08-30T08:03:57.411016Z","shell.execute_reply":"2021-08-30T08:03:57.423779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new3 = X_train_new3.drop(['const'], axis=1) ## Dropping the constant columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.427097Z","iopub.execute_input":"2021-08-30T08:03:57.427496Z","iopub.status.idle":"2021-08-30T08:03:57.439482Z","shell.execute_reply.started":"2021-08-30T08:03:57.427459Z","shell.execute_reply":"2021-08-30T08:03:57.437954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new3.columns ## Getting columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.441464Z","iopub.execute_input":"2021-08-30T08:03:57.442006Z","iopub.status.idle":"2021-08-30T08:03:57.454834Z","shell.execute_reply.started":"2021-08-30T08:03:57.441951Z","shell.execute_reply":"2021-08-30T08:03:57.453679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = X_test[X_train_new3.columns] ## Modifying test data set with same columns as train set","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.456426Z","iopub.execute_input":"2021-08-30T08:03:57.456763Z","iopub.status.idle":"2021-08-30T08:03:57.469936Z","shell.execute_reply.started":"2021-08-30T08:03:57.456729Z","shell.execute_reply":"2021-08-30T08:03:57.468606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.471745Z","iopub.execute_input":"2021-08-30T08:03:57.472273Z","iopub.status.idle":"2021-08-30T08:03:57.482283Z","shell.execute_reply.started":"2021-08-30T08:03:57.472236Z","shell.execute_reply":"2021-08-30T08:03:57.481219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new3.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.484283Z","iopub.execute_input":"2021-08-30T08:03:57.484766Z","iopub.status.idle":"2021-08-30T08:03:57.499321Z","shell.execute_reply.started":"2021-08-30T08:03:57.484714Z","shell.execute_reply":"2021-08-30T08:03:57.498042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = sm.add_constant(X_test) ## Adding constant","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.501269Z","iopub.execute_input":"2021-08-30T08:03:57.501717Z","iopub.status.idle":"2021-08-30T08:03:57.512715Z","shell.execute_reply.started":"2021-08-30T08:03:57.501677Z","shell.execute_reply":"2021-08-30T08:03:57.511343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.514367Z","iopub.execute_input":"2021-08-30T08:03:57.514763Z","iopub.status.idle":"2021-08-30T08:03:57.532896Z","shell.execute_reply.started":"2021-08-30T08:03:57.514691Z","shell.execute_reply":"2021-08-30T08:03:57.531898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Predicting values","metadata":{}},{"cell_type":"code","source":"y_pred = lm4.predict(X_test) ","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.534297Z","iopub.execute_input":"2021-08-30T08:03:57.534608Z","iopub.status.idle":"2021-08-30T08:03:57.542004Z","shell.execute_reply.started":"2021-08-30T08:03:57.534579Z","shell.execute_reply":"2021-08-30T08:03:57.540917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.543374Z","iopub.execute_input":"2021-08-30T08:03:57.543801Z","iopub.status.idle":"2021-08-30T08:03:57.556482Z","shell.execute_reply.started":"2021-08-30T08:03:57.543748Z","shell.execute_reply":"2021-08-30T08:03:57.555331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting r2_square for data set","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nr2_score(y_true= y_test ,y_pred=y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.558149Z","iopub.execute_input":"2021-08-30T08:03:57.55861Z","iopub.status.idle":"2021-08-30T08:03:57.569452Z","shell.execute_reply.started":"2021-08-30T08:03:57.558573Z","shell.execute_reply":"2021-08-30T08:03:57.568339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('R-Sqaured',round(r2_score(y_test, y_pred),2))\nprint('MSE',round(np.sqrt(mean_squared_error(y_test, y_pred)),4))\nprint('Mean Absolute Error',mean_absolute_error(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.571096Z","iopub.execute_input":"2021-08-30T08:03:57.571444Z","iopub.status.idle":"2021-08-30T08:03:57.583111Z","shell.execute_reply.started":"2021-08-30T08:03:57.57141Z","shell.execute_reply":"2021-08-30T08:03:57.582029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Notes: Now we can observe the difference between training set r squared and above r2_square is less than 5 % which is in acceptable range","metadata":{}},{"cell_type":"markdown","source":"## Step 9: Model Evaluation\n\nLet's now plot the graph for actual vs predicted values.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_test_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)                          # Y-label\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.584486Z","iopub.execute_input":"2021-08-30T08:03:57.584838Z","iopub.status.idle":"2021-08-30T08:03:57.749149Z","shell.execute_reply.started":"2021-08-30T08:03:57.584798Z","shell.execute_reply":"2021-08-30T08:03:57.748026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Getting priorities of precictors which influence for demand","metadata":{}},{"cell_type":"code","source":"param = pd.DataFrame(lm4.params)\nparam.rename(columns = {0:'Coefficient value'},inplace = True)\nparam.insert(0,'Variables',param.index)\nparam.sort_values(by = 'Coefficient value',ascending = False,inplace = True)\nparam.set_index('Variables',inplace = True)\nparam","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.750662Z","iopub.execute_input":"2021-08-30T08:03:57.751068Z","iopub.status.idle":"2021-08-30T08:03:57.77002Z","shell.execute_reply.started":"2021-08-30T08:03:57.751034Z","shell.execute_reply":"2021-08-30T08:03:57.768617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the equation of our best fitted line is:\n\n$ cnt = 0.125926 + 0.548008  X  temp + 0.232861  X  yr + 0.129345 X season_Winter + 0.101195 X mnth_September + 0.088080 X season_summer -0.078375 X  weathersit_Mist & Cloudy -0.098685 X holiday  -0.153246 X windspeed -0.282869 X weathersit_Light Rain & Snow $","metadata":{}},{"cell_type":"code","source":"r2_score(y_true= y_test ,y_pred=y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-30T08:03:57.771836Z","iopub.execute_input":"2021-08-30T08:03:57.772247Z","iopub.status.idle":"2021-08-30T08:03:57.788931Z","shell.execute_reply.started":"2021-08-30T08:03:57.772205Z","shell.execute_reply":"2021-08-30T08:03:57.787586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences :\n- 1) First of all positive sign indicates that increases in cnt variable and negativve sign indicates it has decrease \n- 2) The positive signed variables or predictors are temp as top followed by yr,season_winter\n- 3) Negative signed variables or predictors are weathersit_Light Rain & Snow followed by windspeed\n      \nWhat we can interpreted:\n   - Temp is top variable and influence the count of shared bike increase. It indicates that when there is unit increase in temp, the output cnt is estimated to increase by 0.54 units, keeping all the other attributes constant.\n   - yr coefficient is 0.2328. It indicates that the year 2019 was favoring the target variable cnt.\n   - And Weather and windspeed are influencing decrease in demand for bikes that means not favorable for bike rentals\n   \n#### To Summarize, Business is growing Year over year and tempearture plays major role in bike rentals. Season and Weather seems to be good predictors of how bike sharing is happening. Also, during holidays bike sharing is less. \n      ","metadata":{}}]}