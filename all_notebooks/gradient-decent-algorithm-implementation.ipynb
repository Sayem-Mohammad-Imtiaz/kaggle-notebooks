{"cells":[{"metadata":{"id":"6X8A-SDW0W2X","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"id":"n5ka4SsKkGe5","colab_type":"text"},"cell_type":"markdown","source":"**Data Preprocessing**"},{"metadata":{"id":"Q-acVsSPz7WR","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#import statements\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport random","execution_count":null,"outputs":[]},{"metadata":{"id":"8BA8YEtm7jBG","colab_type":"code","outputId":"05d46f3d-7137-4258-ef98-b253e9d6e537","colab":{"base_uri":"https://localhost:8080/","height":35},"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/gpu-runtime/sgemm_product.csv')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"ryDK-1c40mHh","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#creating Runtime, target variable by taking average of Run1, Run2, Run3, Run4\ndf['Runtime']=df[['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)']].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"STEMeQrf0sPb","colab_type":"code","outputId":"e3ac1b7b-6f9c-4222-83dd-b8985408c8d9","colab":{"base_uri":"https://localhost:8080/","height":202},"trusted":true},"cell_type":"code","source":"#viewing data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"SKWVMRHz0uNQ","colab_type":"code","outputId":"fbf8ce04-3892-4f45-8fc7-8e806d8bf802","colab":{"base_uri":"https://localhost:8080/","height":364},"trusted":true},"cell_type":"code","source":"#drop other Run time variables\ndf1=df.drop(columns =['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'], axis = 1)\ndf1.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"eS3kDX710wSt","colab_type":"code","outputId":"880d5de2-8752-4eb9-91d0-ac473b92276c","colab":{"base_uri":"https://localhost:8080/","height":509},"trusted":true},"cell_type":"code","source":"#checking descriptive stats\ndf1.describe().T","execution_count":null,"outputs":[]},{"metadata":{"id":"1dGcQI5V0ykI","colab_type":"code","outputId":"5ac95e29-6149-499c-c9b1-9fc8a8981556","colab":{"base_uri":"https://localhost:8080/","height":295},"trusted":true},"cell_type":"code","source":"#checking for NULL values\ndf1.isnull().sum() #no NULL values","execution_count":null,"outputs":[]},{"metadata":{"id":"1PeHDptF00dF","colab_type":"code","outputId":"411e905e-842a-4de6-840f-cdfa402464f8","colab":{"base_uri":"https://localhost:8080/","height":394},"trusted":true},"cell_type":"code","source":"#checking for outliers\nplt.figure(figsize=(10,6))\nsns.boxplot(df1['Runtime']);","execution_count":null,"outputs":[]},{"metadata":{"id":"T5cvJJ6W02WX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":509},"outputId":"645e5579-f706-4c0e-a266-acfb79140573","trusted":true},"cell_type":"code","source":"#removing outliers\nQ1=df1['Runtime'].quantile(0.25)\nQ2=df1['Runtime'].quantile(0.75)\nIQR = Q2 - Q1\nLL=Q1-1.5*IQR\nUL=Q2+1.5*IQR\ndf2 = df1[(df1.Runtime>LL) & (df1.Runtime<UL)]\ndf2.describe().T","execution_count":null,"outputs":[]},{"metadata":{"id":"rX5Ag9qwi41Q","colab_type":"code","outputId":"b3e66a7a-dc94-4d45-944e-69fb6ba72e54","colab":{"base_uri":"https://localhost:8080/","height":394},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.boxplot(df2['Runtime']);","execution_count":null,"outputs":[]},{"metadata":{"id":"bdNWm8k504VI","colab_type":"code","outputId":"1d49e9a4-21a4-4122-f516-5186d19f5575","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#checking variable distribution\nfor index in range(10):\n   df2.iloc[:,index] = (df2.iloc[:,index]-df2.iloc[:,index].mean()) / df2.iloc[:,index].std();\ndf2.hist(figsize= (14,16));","execution_count":null,"outputs":[]},{"metadata":{"id":"aRMa1e-k06v-","colab_type":"code","outputId":"def2cffe-9d13-4204-a8f5-7cfebdc51f6f","colab":{"base_uri":"https://localhost:8080/","height":303},"trusted":true},"cell_type":"code","source":"#plotting the distribution of Runtime\nsns.distplot(df2['Runtime'])","execution_count":null,"outputs":[]},{"metadata":{"id":"CPblhA6U6co0","colab_type":"code","outputId":"3e54bca4-c53d-47c5-f636-e3e7d1f834a6","colab":{"base_uri":"https://localhost:8080/","height":407},"trusted":true},"cell_type":"code","source":"df2['target']=np.log(df2.Runtime)\nsns.distplot(df2['target'])","execution_count":null,"outputs":[]},{"metadata":{"id":"SzM8EedS1ClZ","colab_type":"code","outputId":"cd3f9ec7-2ea1-4e93-c997-65e41b61f0b9","colab":{"base_uri":"https://localhost:8080/","height":813},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,14))\nsns.set(font_scale=1)\nsns.heatmap(df2.corr(),cmap='GnBu_r',annot=True, square = True ,linewidths=.5);\nplt.title('Variable Correlation')","execution_count":null,"outputs":[]},{"metadata":{"id":"uCzZB8xHbzmw","colab_type":"code","outputId":"5830602d-afc1-4eb1-88d3-841783cb0038","colab":{"base_uri":"https://localhost:8080/","height":435},"trusted":true},"cell_type":"code","source":"#creating an intercept varible during martix dot product\ndf2.insert(0,'intercept',1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"K5_NEflskT_h","colab_type":"text"},"cell_type":"markdown","source":"**Linear Regression**"},{"metadata":{"id":"gBfJQHEE1EmZ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#define cost function\ndef linear_costfunc(dfile,targetvar,coefmat):\n  loss=np.dot(dfile,coefmat.T)-targetvar\n  cost=np.sum(np.power(loss,2)/(2*len(dfile)))\n  return cost","execution_count":null,"outputs":[]},{"metadata":{"id":"RE6D6BRRT0rC","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#define gradient decent considering fixed iterations\ndef linear_gdesc(dfile,targetvar,coefmat,alpha,iterations,threshold):\n  cost_ls=[linear_costfunc(dfile,targetvar,coefmat)]\n  gddf=pd.DataFrame(coefmat)\n  for i in range(1,iterations):\n    loss=np.dot(dfile,coefmat.T)-targetvar\n    dep=np.dot(loss.T,dfile)\n    coefmat=coefmat-dep*alpha/len(dfile)   \n    gddf=gddf.append(pd.DataFrame(coefmat),ignore_index=True)\n    cost_ls+=[linear_costfunc(dfile,targetvar,coefmat)]\n    if (abs(cost_ls[i]-cost_ls[i-1]))<=threshold:\n      break\n  gddf['cost']=cost_ls\n  #print(gddf)\n  print(\"Iterations needed to converge: \", i+1)\n  min_cost=gddf[gddf.cost==min(gddf.cost)]\n  print('Cost at convergance: ', cost_ls[i])\n  min_cost=min_cost.drop(columns='cost',axis=1)\n  #print(min_cost)\n  return min_cost","execution_count":null,"outputs":[]},{"metadata":{"id":"p30j7YMCKzVe","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#predicting target variable\ndef predict(cost_mat,xtest):\n  predic_target=xtest.dot(cost_mat.T)\n  return predic_target","execution_count":null,"outputs":[]},{"metadata":{"id":"_FNYnnONK2fH","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#RMSE\ndef linear_rmse(ypredict,ytest):\n  sum_sq=np.sum((ytest-ypredict)**2)\n  mse=sum_sq/len(ytest)\n  rmse=(mse)**(1/2)\n  return rmse","execution_count":null,"outputs":[]},{"metadata":{"id":"ZnQSgrSldsq2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#Linear Regression fucntion\ndef LinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold):\n  if len(alpha)>1:\n    coef_ls=[0]*len(alpha)\n    ypredict=[0]*len(alpha)\n    rmse=[0]*len(alpha)\n    for i, a in enumerate(alpha, start=0):\n      coef_ls[i]=linear_gdesc(x1_train,y1_train,coefmat,a,iterations,threshold)\n      ypredict[i]=predict(coef_ls[i],x1_test)\n      rmse[i]=linear_rmse(ypredict[i],y1_test)\n      print(\"For learning rate=\", a, \" RMSE is: \", rmse[i])\n      print(\"Coeffients: \",coef_ls[i])\n    plt.plot(alpha,rmse)\n    plt.xlabel('Learning Rate')\n    plt.ylabel('RMSE')\n    plt.show()\n  elif len(threshold)>1:\n    coef_ls=[0]*len(threshold)\n    ypredict=[0]*len(threshold)\n    rmse=[0]*len(threshold)\n    for i, t in enumerate(threshold, start=0):\n      coef_ls[i]=linear_gdesc(x1_train,y1_train,coefmat,alpha,iterations,t)\n      ypredict[i]=predict(coef_ls[i],x1_test)\n      rmse[i]=linear_rmse(ypredict[i],y1_test)\n      print(\"For threshold=\", t, \" RMSE is: \", rmse[i])\n      print(\"Coeffients: \",coef_ls[i])\n    plt.plot(threshold,rmse)\n    plt.xlabel('Threshold')\n    plt.ylabel('RMSE')\n    plt.show()\n  else:\n    coef_ls=[0]\n    ypredict=[0]\n    rmse=[0]\n    for i in range(1):\n      coef_ls[i]=linear_gdesc(x1_train,y1_train,coefmat,alpha,iterations,threshold)\n      ypredict[i]=predict(coef_ls[i],x1_test)\n      rmse[i]=linear_rmse(ypredict[i],y1_test)\n      print(\"For threshold=\", threshold,\" and learning rate: \",alpha, \" RMSE is: \", rmse[i])\n      print(\"Coeffients: \",coef_ls[i])\n    return rmse[i]","execution_count":null,"outputs":[]},{"metadata":{"id":"kcnMaG0EcgNc","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#test and train data\niterations=1000\ndf_target=df2[['target']].values\ndf_features=df2.drop(columns=['target','Runtime'],axis=1).values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)","execution_count":null,"outputs":[]},{"metadata":{"id":"26MrLPptLSLS","colab_type":"text"},"cell_type":"markdown","source":"Experiment 1 - varying learning rate, fixed iterations"},{"metadata":{"id":"MSC_keX6Iwlo","colab_type":"code","outputId":"310fab84-9b07-4dc4-830e-fd9aae555bea","colab":{"base_uri":"https://localhost:8080/","height":903},"trusted":true},"cell_type":"code","source":"#Part 1 for minimum rmse with train and test data\nthreshold=[0.000001]\nalpha=[0.09,0.095,0.1,0.2,0.3]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"KHA4NVLQftBa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":892},"outputId":"4bc1dfee-ebfa-4503-b0a7-8e7472100ad4","trusted":true},"cell_type":"code","source":"threshold=[0.000001]\nalpha=[0.001,0.01,0.1,0.2,0.5]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"0bHvYUSrK_j9","colab_type":"code","outputId":"e6aaf13f-22c0-4862-9e7e-5f3f958b5204","colab":{"base_uri":"https://localhost:8080/","height":781},"trusted":true},"cell_type":"code","source":"#Part 2 for minimum rmse within training data\nthreshold=[0.000001]\nalpha=[0.7,0.75,0.8,0.85]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLinearReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"MSB4-kiahgA7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":892},"outputId":"2492bbb8-c41c-4378-d7e9-6b8f7b886e40","trusted":true},"cell_type":"code","source":"threshold=[0.000001]\nalpha=[0.001,0.01,0.1,0.8,0.9]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLinearReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"sVtJ46FVW3ln","colab_type":"text"},"cell_type":"markdown","source":"Experiment 2 - varying threshold with best alpha"},{"metadata":{"id":"89sulXwVW9sB","colab_type":"code","outputId":"35f11465-41ff-4386-d5d1-8ac26e4c7c57","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Part 1 for minimum rmse with train and test data\nthreshold=[0.00000001,0.0000001,0.0000002,0.0000003,0.0000004,0.0000005,0.0000006,0.0000007,0.0000008,0.0000009,0.000001,0.000002,0.000003,0.000004,0.000005]\nalpha=[0.2]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"_O0m7OtnTTRA","colab_type":"code","outputId":"077b7552-f257-4fa5-8717-a45566d28330","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Error as a function of number of gradient descent iterations for test and train\nthreshold=[0.000001]\nalpha=[0.2]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nitera=[]\nrmse=[]\ncost_ls=[linear_costfunc(x1_train,y1_train,coefmat)]\ngddf=pd.DataFrame(coefmat)\nfor i in range(1,iterations):\n  loss=np.dot(x1_train,coefmat.T)-y1_train\n  dep=np.dot(loss.T,x1_train)\n  coefmat=coefmat-dep*alpha/len(x1_train)   \n  ypredict=predict(coefmat,x1_test)\n  rmse+=[linear_rmse(ypredict,y1_test)]\n  itera+=[i]\n  cost_ls+=[linear_costfunc(x1_train,y1_train,coefmat)]\n  if (abs(cost_ls[i]-cost_ls[i-1]))<=threshold:\n    break\n  print(\"For iteration: \",i,\" RMSE is: \", linear_rmse(ypredict,y1_test))\n#print(\"Coeffients: \",min_cost)\nplt.plot(itera,rmse)\nplt.xlabel('Iteration')\nplt.ylabel('RMSE')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"CUOwR7bnXu8Y","colab_type":"code","outputId":"cb827a85-70d0-4714-d456-d469ebc23639","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Part 2 for minimum rmse within training data\n#threshold=[0.000000000000001,0.00000000000001,0.0000000000001]\nthreshold=[0.0000000000000001,0.000000000000001,0.000000000000002,0.000000000000003,0.000000000000004,0.000000000000005,0.000000000000006,0.000000000000007,0.000000000000008,0.000000000000009,0.00000000000001]\nalpha=[0.8]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLinearReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"j1OhQG9yxGFF","colab_type":"code","outputId":"46a9d860-ba2d-47bf-fe75-43da45862e46","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Error as a function of number of gradient descent iterations within train\nthreshold=[0.000001]\nalpha=[0.8]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nitera=[]\nrmse=[]\ncost_ls=[linear_costfunc(x1_train,y1_train,coefmat)]\ngddf=pd.DataFrame(coefmat)\nfor i in range(1,iterations):\n  loss=np.dot(x1_train,coefmat.T)-y1_train\n  dep=np.dot(loss.T,x1_train)\n  coefmat=coefmat-dep*alpha/len(x1_train)   \n  ypredict=predict(coefmat,x1_train)\n  rmse+=[linear_rmse(ypredict,y1_train)]\n  itera+=[i]\n  cost_ls+=[linear_costfunc(x1_train,y1_train,coefmat)]\n  if (abs(cost_ls[i]-cost_ls[i-1]))<=threshold:\n    break\n  print(\"For iteration: \",i,\" RMSE is: \", linear_rmse(ypredict,y1_train))\n#print(\"Coeffients: \",min_cost)\nplt.plot(itera,rmse)\nplt.xlabel('Iteration')\nplt.ylabel('RMSE')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"UUCVcH8eyeos","colab_type":"text"},"cell_type":"markdown","source":"Experiment 3 - choosing 8 random features"},{"metadata":{"id":"HmHP6yCRydF1","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"iterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\ndf_feat=features.sample(axis = 1,random_state=0,n=8) \ndf_feat.insert(0,'intercept',1)\ndf_features=df_feat.values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"jM3tY1InJ-19","colab_type":"code","outputId":"54847a40-42d8-475c-c396-55b7709bdc85","colab":{"base_uri":"https://localhost:8080/","height":208},"trusted":true},"cell_type":"code","source":"#Random 8 features for test and train\nthreshold=[0.000001]\nalpha=[0.2]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nprint('For features: ', df_feat.columns)\nLinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"aWtnWqMuJ_Dt","colab_type":"code","outputId":"fdfc146b-5c0e-4ac1-de60-a560d171ff0b","colab":{"base_uri":"https://localhost:8080/","height":208},"trusted":true},"cell_type":"code","source":"#Random 8 features within train\nthreshold=[0.000001]\nalpha=[0.8]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nprint('For features: ', df_feat.columns)\nLinearReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"HNU9EBT1Samu","colab_type":"text"},"cell_type":"markdown","source":"Experiment 4 - Choosing 8 best features"},{"metadata":{"id":"E8-IURcpvGD7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"c5653999-a1f6-44f7-8f66-a36971a1693c","trusted":true},"cell_type":"code","source":"#Fixed 8 features for test and train\niterations=1000\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nls=['MWG', 'NWG', 'KWG', 'MDIMC', 'NDIMC', 'STRM', 'SA', 'SB']\ndf_feat=features[ls] \ndf_feat.insert(0,'intercept',1)\ndf_features=df_feat.values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\nthreshold=[0.000001]\nalpha=[0.2]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nprint('For features: ', df_feat.columns)\nLinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"JlQ0DZ2oS1ir","colab_type":"code","outputId":"8fddcb88-4cda-4bdf-913a-c28a8681247a","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Random 8 features for test and train loop to validate\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nitera=[]\nlsrmse=[]\nfor i in range(50):\n  print('For seed=', i)\n  df_feat=features.sample(axis = 1,random_state=i,n=8) \n  df_feat.insert(0,'intercept',1)\n  df_features=df_feat.values\n  x1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\n  threshold=[0.000001]\n  alpha=[0.2]\n  coefmat=np.zeros((1,len(x1_train[0])),dtype=int)\n  iterations=1000\n  print('For features: ', df_feat.columns)\n  r=LinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)\n  itera+=[i]\n  lsrmse+=[r]\nplt.plot(itera,lsrmse)","execution_count":null,"outputs":[]},{"metadata":{"id":"1fV3ZeREwsuy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"0d8e8e17-1280-4780-f912-48dab6a8c1ca","trusted":true},"cell_type":"code","source":"#Random 8 features within train\niterations=1000\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nls=['MWG', 'NWG', 'KWG', 'MDIMC', 'NDIMC', 'STRM', 'SA', 'SB']\ndf_feat=features[ls] \ndf_feat.insert(0,'intercept',1)\ndf_features=df_feat.values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\nthreshold=[0.000001]\nalpha=[0.8]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nprint('For features: ', df_feat.columns)\nLinearReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"X2TcIRajS2RP","colab_type":"code","outputId":"3e789ae1-3da5-4952-99f7-1a4d91c78797","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Random 8 features within train loop to validate\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nitera=[]\nlsrmse=[]\nfor i in range(50):\n  print('For seed=', i)\n  df_feat=features.sample(axis = 1,random_state=i,n=8) \n  df_feat.insert(0,'intercept',1)\n  df_features=df_feat.values\n  x1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\n  threshold=[0.000001]\n  alpha=[0.2]\n  coefmat=np.zeros((1,len(x1_train[0])),dtype=int)\n  iterations=1000\n  print('For features: ', df_feat.columns)\n  r=LinearReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)\n  itera+=[i]\n  lsrmse+=[r]\nplt.plot(itera,lsrmse)","execution_count":null,"outputs":[]},{"metadata":{"id":"kHlYipQwjpLt","colab_type":"text"},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{"id":"brHw-bqF8tgf","colab_type":"code","outputId":"f4979046-6994-49eb-f5c0-e0dcc13efa3b","colab":{"base_uri":"https://localhost:8080/","height":121},"trusted":true},"cell_type":"code","source":"iterations=1000\nmean = df2['target'].mean()\ndf2.loc[df2['target'] <= mean, 'target'] = 0\ndf2.loc[df2['target'] > mean, 'target'] = 1\ndf_target=df2[['target']].values\ndf_features=df2.drop(columns=['target','Runtime'],axis=1).values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)","execution_count":null,"outputs":[]},{"metadata":{"id":"sq79K2fiu1Gc","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def sigmoid(dfile,coefmat):\n  y_hat=np.dot(dfile,coefmat.T)\n  z=1/(1+np.exp(-y_hat))\n  return z","execution_count":null,"outputs":[]},{"metadata":{"id":"zwtDzTETzsKq","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#define cost function\ndef logit_costfunc(dfile,targetvar,coefmat):\n  fterm=np.sum(np.dot(targetvar.T,np.log(sigmoid(dfile,coefmat))))\n  sterm=np.sum(np.dot((1-targetvar).T,np.log(1-sigmoid(dfile,coefmat))))\n  cost=-(fterm+sterm)/len(dfile)\n  return cost","execution_count":null,"outputs":[]},{"metadata":{"id":"3Fee7VeCCIwm","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#define gradient decent considering fixed iterations\ndef logit_gdesc(dfile,targetvar,coefmat,alpha,iterations,threshold):\n  cost_ls=[logit_costfunc(dfile,targetvar,coefmat)]\n  gddf=pd.DataFrame(coefmat)\n  for i in range(1,iterations):\n    loss=sigmoid(dfile,coefmat)-targetvar\n    dep=np.dot(loss.T,dfile)\n    coefmat=coefmat-dep*alpha/len(dfile)   \n    #print('matrix: ',coefmat)\n    gddf=gddf.append(pd.DataFrame(coefmat),ignore_index=True)\n    cost_ls+=[logit_costfunc(dfile,targetvar,coefmat)]\n    #print('iteration=',i,' cost_ls:',cost_ls)\n    if (abs(cost_ls[i]-cost_ls[i-1]))<=threshold:\n      break\n  gddf['cost']=cost_ls\n  #print(gddf)\n  print(\"Iterations needed to converge: \", i+1)\n  min_cost=gddf[gddf.cost==min(gddf.cost)]\n  print('Cost at convergance: ', cost_ls[i])\n  min_cost=min_cost.drop(columns='cost')\n  return min_cost","execution_count":null,"outputs":[]},{"metadata":{"id":"uyrB0etyJdv0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def log_predict(cost_mat,xtest):\n  predic_target=xtest.dot(cost_mat.T)\n  target= np.where(predic_target >= 0.5 , 1, 0)\n  return target","execution_count":null,"outputs":[]},{"metadata":{"id":"8viv_a2WJePB","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def accuracy(ypredict,ytest):\n  df = pd.DataFrame({'actual': ytest.flatten(), 'predicted': ypredict.flatten()})\n  correct= df.loc[df['actual'] == df['predicted']]\n  rate=len(correct)/len(ytest)   \n  return rate","execution_count":null,"outputs":[]},{"metadata":{"id":"rHMBGiH3Eh4I","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def LogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold):\n  if len(alpha)>1:\n    coef_ls=[0]*len(alpha)\n    ypredict=[0]*len(alpha)\n    accu=[0]*len(alpha)\n    for i, a in enumerate(alpha, start=0):\n      coef_ls[i]=logit_gdesc(x1_train,y1_train,coefmat,a,iterations,threshold)\n      ypredict[i]=log_predict(coef_ls[i],x1_test)\n      accu[i]=accuracy(ypredict[i],y1_test)\n      print(\"For learning rate=\", a, \" Accuracy is: \", accu[i])\n      print(\"Coeffients: \",coef_ls[i])\n    plt.plot(alpha,accu)\n    plt.xlabel('Learning Rate')\n    plt.ylabel('Accuracy')\n    plt.show()\n  elif len(threshold)>1:\n    coef_ls=[0]*len(threshold)\n    ypredict=[0]*len(threshold)\n    accu=[0]*len(threshold)\n    for i, t in enumerate(threshold, start=0):\n      #print('t',t)\n      coef_ls[i]=logit_gdesc(x1_train,y1_train,coefmat,alpha,iterations,t)\n      ypredict[i]=log_predict(coef_ls[i],x1_test)\n      #print('y_hat:',ypredict)\n      accu[i]=accuracy(ypredict[i],y1_test)\n      print(\"For threshold=\", t, \" Accuracy is: \", accu[i])\n      print(\"Coeffients: \",coef_ls[i])\n    plt.plot(threshold,accu)\n    plt.xlabel('Threshold')\n    plt.ylabel('Accuracy')\n    plt.show()\n  else:\n    coef_ls=[0]\n    ypredict=[0]\n    accu=[0]\n    for i in range(1):\n      coef_ls[i]=logit_gdesc(x1_train,y1_train,coefmat,alpha,iterations,threshold)\n      ypredict[i]=log_predict(coef_ls[i],x1_test)\n      accu[i]=accuracy(ypredict[i],y1_test)\n      print(\"For threshold=\", threshold,\" and learning rate: \",alpha, \" Accuracy is: \", accu[i])\n      print(\"Coeffients: \",coef_ls[i])\n    return accu[i]","execution_count":null,"outputs":[]},{"metadata":{"id":"WjGj3xN528iE","colab_type":"text"},"cell_type":"markdown","source":"Experiment 1 - varying learning rate, fixed iterations"},{"metadata":{"id":"WOQk_5oiz4Ds","colab_type":"code","outputId":"3b80afa3-c4d0-4bf2-9c38-df3453490f66","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Part 1 for minimum rmse with train and test data\nthreshold=[0.000001]\nalpha=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3]\nLogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"sRAagyUWzi8s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2d5e307f-4ed0-4cf1-b44e-693bebbf2766","trusted":true},"cell_type":"code","source":"threshold=[0.000001]\nalpha=[0.0001,0.001,0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3]\nLogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"aIqBLxph3GoC","colab_type":"code","outputId":"9c9ab14c-ca5d-4bc9-8d3a-c19cb6e5e1be","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Part 2 for minimum rmse within training data\nthreshold=[0.000001]\nalpha=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3,4,5]\nLogisticReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"dMgoPfkL2NXr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4cce5f42-84b1-4fd5-dfca-438602db34c6","trusted":true},"cell_type":"code","source":"threshold=[0.000001]\nalpha=[0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3,4,5]\nLogisticReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"yFvqF_FG3tF5","colab_type":"text"},"cell_type":"markdown","source":"Experiment 2 - varying threshold with best alpha"},{"metadata":{"id":"bVx2ADH53-VW","colab_type":"code","outputId":"fd131456-4333-4b0f-9cd1-4277a89054af","colab":{"base_uri":"https://localhost:8080/","height":771},"trusted":true},"cell_type":"code","source":"#Part 1 for minimum rmse with train and test data\nthreshold=[0.0000005,0.000001,0.000002,0.000003]\nalpha=[0.4]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"M5zVSd_F4Fbo","colab_type":"code","outputId":"296c9d1a-22e6-417f-ae83-2464295a53e6","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Error as a function of number of gradient descent iterations for test and train\nthreshold=[0.000001]\nalpha=[0.6]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nitera=[]\naccu=[]\ncost_ls=[logit_costfunc(x1_train,y1_train,coefmat)]\ngddf=pd.DataFrame(coefmat)\nfor i in range(1,iterations):\n  loss=sigmoid(x1_train,coefmat)-y1_train\n  dep=np.dot(loss.T,x1_train)\n  coefmat=coefmat-dep*alpha/len(x1_train)   \n  ypredict=log_predict(coefmat,x1_test)\n  accu+=[accuracy(ypredict,y1_test)]\n  itera+=[i]\n  cost_ls+=[logit_costfunc(x1_train,y1_train,coefmat)]\n  if (abs(cost_ls[i]-cost_ls[i-1]))<=threshold:\n    break\n  print(\"For iteration: \",i,\" accuracy is: \", accuracy(ypredict,y1_test))\n#print(\"Coeffients: \",min_cost)\nplt.plot(itera,accu)\nplt.xlabel('Iteration')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9XZJQyp04Kmv","colab_type":"code","outputId":"368dc76f-f2f6-4da4-a9b3-858518d867e9","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Part 2 for minimum rmse within training data\nthreshold=[0.0000001,0.0000005,0.000001,0.000002,0.000003,0.000004,0.000005]\nalpha=[1]\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nLogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"a3RA0oWG4O8d","colab_type":"code","outputId":"344430aa-d7f3-4db1-ef9e-df0865e88509","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Error as a function of number of gradient descent iterations within train\nthreshold=[0.000001]\nalpha=[1]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nitera=[]\naccu=[]\ncost_ls=[logit_costfunc(x1_train,y1_train,coefmat)]\ngddf=pd.DataFrame(coefmat)\nfor i in range(1,iterations):\n  loss=sigmoid(x1_train,coefmat)-y1_train\n  dep=np.dot(loss.T,x1_train)\n  coefmat=coefmat-dep*alpha/len(x1_train)   \n  ypredict=log_predict(coefmat,x1_train)\n  accu+=[accuracy(ypredict,y1_train)]\n  itera+=[i]\n  cost_ls+=[logit_costfunc(x1_train,y1_train,coefmat)]\n  if (abs(cost_ls[i]-cost_ls[i-1]))<=threshold:\n    break\n  print(\"For iteration: \",i,\" accuracy is: \", accuracy(ypredict,y1_train))\n#print(\"Coeffients: \",min_cost)\nplt.plot(itera,accu)\nplt.xlabel('Iteration')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"IpfK5YMTaFiC","colab_type":"text"},"cell_type":"markdown","source":"Experiment 3 - choosing 8 random features"},{"metadata":{"id":"zWElMAu2aIzt","colab_type":"code","outputId":"db1ac19c-8057-4a89-ad00-df28a2f2d493","colab":{"base_uri":"https://localhost:8080/","height":121},"trusted":true},"cell_type":"code","source":"iterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nmean = df2['target'].mean()\ndf2.loc[df2['target'] <= mean, 'target'] = 0\ndf2.loc[df2['target'] > mean, 'target'] = 1\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\ndf_feat=features.sample(axis = 1,random_state=0,n=8) \ndf_feat.insert(0,'intercept',1)\ndf_features=df_feat.values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"nRQKQYWBaJtS","colab_type":"code","outputId":"6948550f-dc60-452e-ec92-9974539603e1","colab":{"base_uri":"https://localhost:8080/","height":208},"trusted":true},"cell_type":"code","source":"#Random 8 features for test and train\nthreshold=[0.000001]\nalpha=[0.6]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nprint('For features: ', df_feat.columns)\nLogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"--jAfva1aR6S","colab_type":"code","outputId":"6a4631dd-2e3e-402d-c97f-4466a73fa0c6","colab":{"base_uri":"https://localhost:8080/","height":208},"trusted":true},"cell_type":"code","source":"#Random 8 features within train\nthreshold=[0.000001]\nalpha=[1]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\niterations=1000\nprint('For features: ', df_feat.columns)\nLogisticReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"qYDkFm_ZadOm","colab_type":"text"},"cell_type":"markdown","source":"Experiment 4 - Choosing 8 best features"},{"metadata":{"id":"7OlulF5H3iG9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":277},"outputId":"3721078a-d758-489b-91e7-c6a85aa8e01c","trusted":true},"cell_type":"code","source":"iterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nmean = df2['target'].mean()\ndf2.loc[df2['target'] <= mean, 'target'] = 0\ndf2.loc[df2['target'] > mean, 'target'] = 1\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nls=['MWG', 'NWG', 'KWG', 'MDIMC', 'NDIMC', 'STRM', 'SA', 'SB']\ndf_feat=features[ls] \ndf_feat.insert(0,'intercept',1)\ndf_features=df_feat.values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\nthreshold=[0.000001]\nalpha=[0.6]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nprint('For features: ', df_feat.columns)\nLogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"1vhavMw8ag_b","colab_type":"code","outputId":"fefe068e-c7c6-4161-bdf0-281ddd3dff1a","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Random 8 features for test and train for loop to validate\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nmean = df2['target'].mean()\ndf2.loc[df2['target'] <= mean, 'target'] = 0\ndf2.loc[df2['target'] > mean, 'target'] = 1\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nitera=[]\nlsaccu=[]\nfor i in range(50):\n  print('For seed=', i)\n  df_feat=features.sample(axis = 1,random_state=i,n=8) \n  df_feat.insert(0,'intercept',1)\n  df_features=df_feat.values\n  x1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\n  threshold=[0.000001]\n  alpha=[0.6]\n  coefmat=np.zeros((1,len(x1_train[0])),dtype=int)\n  iterations=1000\n  print('For features: ', df_feat.columns)\n  a=LogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)\n  itera+=[i]\n  lsaccu+=[a]\nplt.plot(itera,lsaccu)","execution_count":null,"outputs":[]},{"metadata":{"id":"viiZwCRI5qS1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":277},"outputId":"8689789c-5866-458d-eaeb-6b50983270b6","trusted":true},"cell_type":"code","source":"iterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nmean = df2['target'].mean()\ndf2.loc[df2['target'] <= mean, 'target'] = 0\ndf2.loc[df2['target'] > mean, 'target'] = 1\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nls=['MWG', 'NWG', 'KWG', 'MDIMC', 'NDIMC', 'STRM', 'SA', 'SB']\ndf_feat=features[ls] \ndf_feat.insert(0,'intercept',1)\ndf_features=df_feat.values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\nthreshold=[0.000001]\nalpha=[1]\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nprint('For features: ', df_feat.columns)\nLogisticReg(x1_train,x1_test,y1_train,y1_test,alpha,iterations,coefmat,threshold)","execution_count":null,"outputs":[]},{"metadata":{"id":"gwE1BjveamJq","colab_type":"code","outputId":"722e6fb7-d47c-4570-caaa-32b8ac111633","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#Random 8 features within train to validate\niterations=1000\ncoefmat=np.zeros((1,len(x1_train[0])),dtype=int)\nmean = df2['target'].mean()\ndf2.loc[df2['target'] <= mean, 'target'] = 0\ndf2.loc[df2['target'] > mean, 'target'] = 1\ndf_target=df2[['target']].values\nfeatures=df2.drop(columns=['target','Runtime','intercept'])\nitera=[]\nlsaccu=[]\nfor i in range(50):\n  print('For seed=', i)\n  df_feat=features.sample(axis = 1,random_state=i,n=8) \n  df_feat.insert(0,'intercept',1)\n  df_features=df_feat.values\n  x1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.2, random_state = 0)\n  threshold=[0.000001]\n  alpha=[1]\n  coefmat=np.zeros((1,len(x1_train[0])),dtype=int)\n  iterations=1000\n  print('For features: ', df_feat.columns)\n  a=LogisticReg(x1_train,x1_train,y1_train,y1_train,alpha,iterations,coefmat,threshold)\n  itera+=[i]\n  lsaccu+=[a]\nplt.plot(itera,lsaccu)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"ML_assignment1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}