{"cells":[{"metadata":{"_uuid":"2237537b4797263f0c939f37dcdeacacbc467d7a"},"cell_type":"markdown","source":"<div align='center' style='font-size:25px;color:green;font-weight:bold'>Classification Algorithms</div>\n<div style='font-size:16px;padding-top:20px '>\nWe are starting with some simple algorithms to advanced algorithms for classification.And also boosting our skills on the classification problems on real world datasets.\n</div>\n\n<div style='padding-top:25px'><p style='font-weight:bold;font-size:17px' >Algorithms I am using are :</p>\n<ul style='font-size:15px'>\n<li>Support Vector Classifier</li>\n<li>K-nearest Neighbors Classifier</li>\n<li>Logistic Regression</li>\n<li>DecisionTree Classifier</li>\n<li>RandomForest Classifier</li>\n<li>GradientBoosting Classifier</li>\n</ul>\n</div>"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"5cffe1439b89f6ce767beb72d7e23e9f8c5cf57a"},"cell_type":"code","source":"import pandas as pd  #for loading the dataset as DataFrame\nimport numpy as np   #for handling multi-D arrays and mathematical computations\nimport seaborn as sb #highly interactive visualization of dataset\nfrom matplotlib import pyplot as plt #visualization the data\nfrom sklearn.model_selection import train_test_split  # split the data into trian and test sets\n# different algorithms for comparisons\nfrom sklearn.ensemble import RandomForestClassifier # also used for feature selection\nfrom sklearn.ensemble import GradientBoostingClassifier #boosting algorithm\nfrom sklearn.tree import DecisionTreeClassifier     \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC   # support vector classifier (SVC)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c14cde0397baadc96f519d23229d441c1252e39"},"cell_type":"markdown","source":"<div style='font-size:20px'>Reading the Dataset :</div>"},{"metadata":{"trusted":false,"_uuid":"479d03d68c093a2558380e4c0670b1add5c19b2c"},"cell_type":"code","source":"data = pd.read_csv('../input/loan-prediction.csv') \n#our dataset is about Loan Status of different applicants with several features","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"11da5ead07efedf48cc2a33f819a8fe6f8d5c0bc"},"cell_type":"code","source":"data.head() #overview of our dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00ebc16656963c9e7c7a587d96324df00336550f"},"cell_type":"markdown","source":"<div style='font-size:20px'>Start Analysing :</div>"},{"metadata":{"trusted":false,"_uuid":"c3a860c219c6478a51ab295402f658388bcca892"},"cell_type":"code","source":"data.isna().sum() #check how many number of Nan are present in each column","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1b24cfc93806049f5b2d410d1f7e5680d3bba7e2"},"cell_type":"code","source":"data.shape   #dimension of our dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dd5f1ff89674377b49e4556ebfdb5064d86f90c"},"cell_type":"markdown","source":"<div style='font-size:20px'>Handling the Nan Values :</div>"},{"metadata":{"trusted":false,"_uuid":"085d9b08995e9aa6d63df9d5b540e8fe3900ab2f"},"cell_type":"code","source":"data.fillna(method='bfill',inplace=True) # here we are use backward filling to remove our Nan from Dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6baa1b6e0e682f772b2f4f5bf9f995f48f52bcf7"},"cell_type":"markdown","source":"<div style='font-size:20px'>Visualization of data set :</div>"},{"metadata":{"trusted":false,"_uuid":"caf905db6752763e53baa608c56086221a40e57d"},"cell_type":"code","source":"#countplot of different gender on the basis of there loan status\nsb.countplot(x='Gender',\n             data=data,\n             hue='Loan_Status',\n             palette=\"GnBu_d\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a786d43733cd994e05e57f073d13d232bb254c9d"},"cell_type":"code","source":"#here we are clearly obeserve the what is applicantIncome and whether he/she is self_employed or not,\n#with there Loan Status\nsb.catplot(x='Gender',\n           y='ApplicantIncome',\n           data=data,\n           kind ='bar',\n           hue='Loan_Status',\n           col='Self_Employed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9bbac266a7b7cd4b98a5c8fffe1262cfcbbde192"},"cell_type":"code","source":"#here we are clearly obeserve the what is co-applicantIncome and whether he/she is self_employed or not,\n#with there Loan Status\nsb.catplot(x='Gender',\n           y='CoapplicantIncome',\n           data=data,\n           kind ='bar',\n           hue='Loan_Status',\n           col='Self_Employed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ef8ed9a18cd5fa0b97b525f7b1ac8444e93d7b21"},"cell_type":"code","source":"data['ApplicantIncome'].plot(kind='hist',bins=50) #histogram of Applicant-Income\n# we see that most of them are in between 0-10000","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"933e2391cce26c3b662894ead787f0375a74166d"},"cell_type":"code","source":"data['CoapplicantIncome'].plot(kind='hist',bins=50)\n#histogram of coappicantIncome which almost similar to the ApplicantIncome's histogram","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"372499e9300311c7c113ec568634d52027a68fdc"},"cell_type":"code","source":"#it is more useful to use ApplicantIncome and CoapplicantIncome as one featue i.e, Total_Income\n#for reducing the feature set\n#So, I am creating new column Total_Income as the sum of ApplicantIncome and CopplicantIncome\ndata['Total_Income']=(data['ApplicantIncome']+data['CoapplicantIncome'])\ndata['Total_Income'].plot(kind='hist',bins=50) #histogram of Total_Income which is almost similar with above two\ndata.drop(columns=['ApplicantIncome','CoapplicantIncome'],inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b0e5b6867cdd66a36dbd1b0659a30182624810ea"},"cell_type":"code","source":"sb.countplot(data.Dependents,data=data,hue='Loan_Status')\n#count of different dependents with respect to there Loan_status","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"19262812bdc13baf48eae4012a35bb7f55336150"},"cell_type":"code","source":"sb.countplot(data.Education,data=data,hue='Loan_Status',palette='Blues')\n#count of graduated or non-graduated with respect to there Loan_status","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"aa819935ded071974feb4a67ae78e15a47273202"},"cell_type":"code","source":"sb.countplot(data.Married,data=data,hue='Loan_Status')\n#count of Married or non-Married applicant with respect to there Loan_status","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"14ca7c6980dc5e5a9bce00045054401508434b97"},"cell_type":"code","source":"sb.barplot(x='Credit_History',y='Property_Area',data=data,hue='Loan_Status',orient='h')\n# relation of credit history in different Property Area with respect to there Loan_Status","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"66cce1a155a791b9ed31b946de210ea6dee0115e"},"cell_type":"code","source":"sb.barplot(x='Loan_Amount_Term',y='LoanAmount',data=data,hue='Loan_Status',palette='Blues')\n#visualizing LoanAmount on the basis of LoanAmountTerm with respect to Loan_Status","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24b1b57947d406248f25afe34d620da0a7a15383"},"cell_type":"markdown","source":"<div style='font-size:20px'>Handling Categorical Columns :</div>"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"fefdb2c7e6cfba417cf0e4c1cb17945664042827"},"cell_type":"code","source":"#As above we observe that our there are so many columns with categorical values.\n#which are useful feature for predicting our Loan Status at the end\n#for the sake of simplicity I am coverting these categorical values in to numeric values.\nx = pd.Categorical(data['Gender'])               # Male=1,Female=0\ndata['Gender']=x.codes\n\nx = pd.Categorical(data['Married'])              # Yes=1,No=0\ndata['Married']=x.codes\n\nx = pd.Categorical(data['Education'])            #Graduate=0,Non-graduated=1\ndata['Education']=x.codes\n\nx = pd.Categorical(data['Self_Employed'])        #Yes=1,No=0\ndata['Self_Employed']=x.codes\n\nx = pd.Categorical(data['Property_Area'])        # Rural=0,SemiUrban=1,Urban=2\ndata['Property_Area']=x.codes\n\nx = pd.Categorical(data['Loan_Status'])          #Y=1,N=0\ndata['Loan_Status'] = x.codes\n\n#in dependent column we clearly see that there is + sign for dependents more than 3\n#which makes it column of object data type \n#So, I am going to remove this sign and convert it into numeric value\ndata['Dependents'] = data['Dependents'].str.replace('+','')     \ndata['Dependents'] = pd.to_numeric(data['Dependents'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"885c1da7e4cf162b1391359dd3c0fa2fe9774a4b"},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsb.heatmap(data.corr(),cmap='Greens',annot=True)\n#Visualizing the correlation matrix using heatmap ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7e6038f0f74a9eace666c4ca5a87073ebcb28d7"},"cell_type":"markdown","source":"<div style='font-size:20px'>Feature Selection Process :</div>\n<div style='font-size:15px'>There many methods for selecting some of the specific features but, now I am using RandomForest Classifier for feature selection.\n</div>\n\n<div style='font-size:20px;padding-top:20px'>\nSteps are :\n<ul style='font-size:15px'>\n<li>Fit training data set to RandomForest Classifier</li>\n<li>Use feature_importance to see the importance of each feature for predicting</li>\n<li>Then pick few features having high feature_importance value.</li>\n</ul>\n</div>"},{"metadata":{"trusted":false,"_uuid":"b59371a13c1f7b8fb976bd350cc86247596d5317"},"cell_type":"code","source":"#We are going to predict the Loan_Status\nY=data['Loan_Status']\nX=data.drop(columns=['Loan_Status','Loan_ID']) #X is all columns except Loan_Status and Loan_ID\n# split the train and test dataset where test set is 30% of original dataset\nxtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size=0.3) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de51625644ca4bb93d700466af28509aaf963751"},"cell_type":"markdown","source":"<div style='font-size:18px;color:brown;font-weight:bold'>RandomForest Classifier :</div>\n<p style='font-size:15px'>Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes or mean prediction of the individual trees. </p>"},{"metadata":{"trusted":false,"_uuid":"eb6b7a84b9d4d0304ab162a1a321ee7eec8d051d"},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=400,max_depth=5) #defining RandomForest Classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1b1d39048861514e13a1330c1e2222998e4abb8a"},"cell_type":"code","source":"clf = clf.fit(xtrain,ytrain)  #fitting our train dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"57548d655de517bedc833058834014d14df88ac0"},"cell_type":"code","source":"clf.score(xtest,ytest)       #score on our test dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8354fc6cc8003849fde5277376b10e143ddb49af"},"cell_type":"code","source":"pd.Series(clf.feature_importances_,xtrain.columns).sort_values(ascending=False)\n#feature importance in descending order\n#So, I am using only top 4 features as my input","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"bf00cb3970ecbe374f18beeca7d8fa5ed9cf75bb"},"cell_type":"code","source":"#Respliting the trianing and testing dataset\nY=data['Loan_Status']\nX=data[['Credit_History','Total_Income','LoanAmount']] #X is top 3 feature having more feature importance values\n# split the train and test dataset where test set is 30% of original dataset\nxtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size=0.3) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c7d8af0e41701562188b9d31214279a8a58b0bad"},"cell_type":"code","source":"#Re-applying the RandomForest Classifiers\nclf = RandomForestClassifier(n_estimators=400,max_depth=5) \nclf = clf.fit(xtrain,ytrain) \nclf.score(xtest,ytest)\n#we can clearly observe that it increases the accuracy percentage","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"546d07219845e019ce77149c19f0fba3ee2e44a2"},"cell_type":"markdown","source":"<div style='font-size:18px;color:brown;font-weight:bold'>Logistic Regression :</div>\n<p style='font-size:15px'>The logistic model is a widely used statistical model that, in its basic form, uses a logistic function to model a binary dependent variable; many more complex extensions exist.</p>"},{"metadata":{"trusted":false,"_uuid":"507d67244b4ba06552881f4312dc84fa89f4935d"},"cell_type":"code","source":"clf = LogisticRegression()  #defining Logistic Regression\nclf = clf.fit(xtrain,ytrain) \nclf.score(xtest,ytest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"373b3725bf4a39bf0c76d4f3a2daec1b32831a25"},"cell_type":"markdown","source":"<div style='font-size:18px;color:brown;font-weight:bold'>Support Vector Classifier :</div>\n<p style='font-size:15px'>Support-Vector machines are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.A support-vector machine constructs a hyperplane or set of hyperplanes in a high- or infinite-dimensional space, which can be used for classification, regression, or other tasks like outliers detection.</p>"},{"metadata":{"trusted":false,"_uuid":"38daf8722c8c1cf57cd1c77bbcd720fcd15e4be9"},"cell_type":"code","source":"clf = SVC()  #defining Support Vector Classifier\nclf = clf.fit(xtrain,ytrain) \nclf.score(xtest,ytest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"673add69825bd70039edaab92ba21b63ead1aacf"},"cell_type":"markdown","source":"<div style='font-size:18px;color:brown;font-weight:bold'>K-nearest Neighbors Classifier :</div>\n<p style='font-size:15px'>An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.</p>"},{"metadata":{"trusted":false,"_uuid":"9e9aefa915cb796b7652bfdbaf07f4ed4e9cb27c"},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors=3)  #defining K-nearest Neighbors(KNN) Classifier\nclf = clf.fit(xtrain,ytrain) \nclf.score(xtest,ytest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f9a034623e13f9fef0665354c3b5b02763753b6"},"cell_type":"markdown","source":"<div style='font-size:18px;color:brown;font-weight:bold'>DecisionTree Classifier :</div>\n<p style='font-size:15px'>A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.</p>"},{"metadata":{"trusted":false,"_uuid":"4b5bce9c1cb7c78cd608425c1ba1f8363db3de55"},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth=3)  #defining DecisionTree Classifier\nclf = clf.fit(xtrain,ytrain) \nclf.score(xtest,ytest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"297f07f606a1689967bd8348a288420bd8cfb84c"},"cell_type":"markdown","source":"<div style='font-size:18px;color:brown;font-weight:bold'>GradientBoosting Classifier :</div>\n<p style='font-size:15px'>Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function.</p>"},{"metadata":{"trusted":false,"_uuid":"2181c6c2fe7fe5500ce646473d0d630de5bb0629"},"cell_type":"code","source":"clf = GradientBoostingClassifier(n_estimators=100,learning_rate=0.1,max_depth=2)  #defining Logistic Regression\nclf = clf.fit(xtrain,ytrain) \nclf.score(xtest,ytest)","execution_count":null,"outputs":[]}],"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}