{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"background-color:yellow;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">AGE PREDICTION</h1>\n","metadata":{}},{"cell_type":"markdown","source":"<center><img src=\"https://assets.newatlas.com/dims4/default/8e1ebab/2147483647/strip/true/crop/2000x1333+0+0/resize/1200x800!/format/webp/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fef%2Fe6%2F73fef15a43e38ed11e20af5cf62e%2Fdepositphotos-11882201-l-2015.jpg\",height='500',width='600'></center>\n","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">OverView </h1>\n<a id=0></a>","metadata":{}},{"cell_type":"markdown","source":"In this dataset our main objective is to predict the Age of the person by analysing his/her images. Here we have about 24k labeled examples, by using this we have to make a generalised model for predicting the Age of the person. The column pixels contains the value of pixels of the image in string format separated by a space.","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Importing modules and Loading datasets</h1>\n<a id=1></a>","metadata":{}},{"cell_type":"code","source":"import  pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization,MaxPool2D,Dense,Conv2D,Flatten\nfrom keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/age-gender-and-ethnicity-face-data-csv/age_gender.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def values_to_array(pixels):\n    arr=np.array(pixels.split(),'float64')\n    arr=arr.reshape(48,48)\n#     print(arr.shape)\n    return arr\ndata['pixels']=data['pixels'].apply(values_to_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Train test spliting of data</h1>\n<a id=2></a>","metadata":{}},{"cell_type":"code","source":"train_img,test_img,train_age,test_age=train_test_split(data['pixels'],data['age'],test_size=0.2,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Data Visualization</h1>\n<a id=3></a>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.distplot(train_age)\nplt.title('Age Distribution')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor i in range(0,10):\n    plt.subplot(2,4,(i%8)+1)\n    num=np.random.randint(1000)\n    plt.title(\"image no.{0} , Age:-{1}\".format(i+1,train_age.iloc[num]))\n    plt.imshow(train_img.iloc[num],cmap='gray')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Changing Dimension Of Data</h1>\n<a id=4></a>","metadata":{}},{"cell_type":"code","source":"def change_image_dimension(data):\n    data=np.reshape(data.to_list(),(len(data),48,48,1))\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img=change_image_dimension(train_img)\ntest_img=change_image_dimension(test_img)\n# train_img\ntrain_img=train_img/255.0\ntest_img=test_img/255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Callback Functions</h1>\n<a id=5></a>","metadata":{}},{"cell_type":"code","source":"def schedule(epoch,lr):\n    if epoch>=5:\n        return 0.0001\n    return 0.001\nearly_stop=EarlyStopping(monitor='val_mean_absolute_error',patience=2)\nlearning_rate_scheduler=LearningRateScheduler(schedule)\nreduceLR=ReduceLROnPlateau(monitor='val_mean_absolute_error',patience=1,min_lr=0.00001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Convolutional Neural Network</h1>\n<a id=5></a>","metadata":{}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv2D(128,(3,3),activation='relu',input_shape=(48,48,1)))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),activation='relu'))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(1,activation='relu'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='mse',metrics=[keras.metrics.mean_absolute_error])\nr=model.fit(train_img,train_age,validation_data=(test_img,test_age),epochs=15,callbacks=[reduceLR])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Model Summary</h1>\n<a id=7></a>","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Curve of Mean Squared Error Losses</h1>\n<a id=8></a>","metadata":{}},{"cell_type":"code","source":"plt.plot(r.history['loss'])\nplt.plot(r.history['val_loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Curve of Absolute Mean Error Losses</h1>\n<a id=8></a>","metadata":{}},{"cell_type":"code","source":"plt.plot(r.history['mean_absolute_error'])\nplt.plot(r.history['val_mean_absolute_error'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Visualizing Train Data Prediction</h1>\n<a id=12></a>","metadata":{}},{"cell_type":"code","source":"pred_train_Age=model.predict(train_img)\ntrain_age=np.array(train_age,'int32')\npred_train_Age=np.reshape(pred_train_Age,(len(train_age),))\ntrain_age=np.reshape(train_age,(len(train_age),))\ntrain_images=np.reshape(train_img,(len(train_img),48,48))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\nfor i in range(0,5):\n    plt.subplot(1,4,(i%4)+1)\n    plt.title(\"Predicted Age is {0} and Actual Age is {1}\".format(np.round(pred_train_Age[i]),train_age[i]))\n    plt.imshow(train_images[i],cmap='gray')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Visualizing Test Data Prediction</h1>\n<a id=12></a>","metadata":{}},{"cell_type":"code","source":"pred_test_Age=model.predict(test_img)\ntest_age=np.array(test_age,'int32')\npred_test_Age=np.reshape(pred_test_Age,(len(test_age),))\ntest_age=np.reshape(test_age,(len(test_age),))\ntest_images=np.reshape(test_img,(len(test_img),48,48))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\nfor i in range(0,5):\n    plt.subplot(1,4,(i%4)+1)\n    plt.title(\"Predicted Age is {0} and Actual Age is {1}\".format(np.round(pred_test_Age[i]),test_age[i]))\n    plt.imshow(test_images[i],cmap='gray')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:green;font-family:newtimeroman;font-size:400%;text-align:center;border-radius: 15px 50px;padding: 3px\">Conclusion</h1>\n<a id=12></a>","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"background-color:lightblue;font-family:newtimeroman;font-size:200%;text-align:center;padding: 3px\">From above prediction it can be easily seen that there is not much difference in the actual and predicted Age . so we could considered it to be an efficient model for predicting Age by the images.</h3>","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"background-color:lightyellow;font-family:newtimeroman;font-size:200%;text-align:center;padding: 3px\">If you liked the notebook please upvote it and if having any queries feel free to ask in comment section.</h3>","metadata":{}}]}