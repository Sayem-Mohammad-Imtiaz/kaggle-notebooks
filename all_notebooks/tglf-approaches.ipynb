{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport math\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T15:50:03.98219Z","iopub.execute_input":"2021-07-15T15:50:03.982902Z","iopub.status.idle":"2021-07-15T15:50:04.013718Z","shell.execute_reply.started":"2021-07-15T15:50:03.982705Z","shell.execute_reply":"2021-07-15T15:50:04.01286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv(\"../input/tglf-new-coefficients/TAML_227_test.csv\")#TAML_227_actually_logged.csv\")\ndataset= dataset.dropna()\n#dataset = dataset[dataset['cc'] > 0.3]\n\ndataset.shape\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:51:14.513679Z","iopub.execute_input":"2021-07-15T15:51:14.514301Z","iopub.status.idle":"2021-07-15T15:51:14.643418Z","shell.execute_reply.started":"2021-07-15T15:51:14.514239Z","shell.execute_reply":"2021-07-15T15:51:14.642732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = dataset.iloc[:, 0:13]\n# x[\"RLTS_1^2\"]=x[\"RLTS_1\"]**2\n# x.drop(\"RLTS_1\", axis=1)\n\n#inverse\n#inv_x = x.join((1/(x+0.001)).add_prefix('inv_'))\n#x = inv_x\n\ny = dataset.iloc[:, 13:16]\n\n# for i in range(len(x.columns)):\n#     #new_col = \"log10(abs(\"+x.columns[i]+\"))\"\n#     x =x.rename(columns={x.columns[i]:new_col})\n    \nx.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-15T15:52:14.235716Z","iopub.execute_input":"2021-07-15T15:52:14.236134Z","iopub.status.idle":"2021-07-15T15:52:14.259607Z","shell.execute_reply.started":"2021-07-15T15:52:14.236093Z","shell.execute_reply":"2021-07-15T15:52:14.258536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state = 2)\n\ny_cols = list(y.columns)\nx_cols = list(x.columns)\nprint(x_cols)\nprint(y_cols)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:53:13.466103Z","iopub.execute_input":"2021-07-15T15:53:13.466467Z","iopub.status.idle":"2021-07-15T15:53:14.568415Z","shell.execute_reply.started":"2021-07-15T15:53:13.466438Z","shell.execute_reply":"2021-07-15T15:53:14.567581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"XGBoost (for base accuracy)","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nprint(y_cols)\nfor i in y_cols:\n    xgb = XGBRegressor()\n    xgb.fit(x_train, y_train[i])\n\n    y_pred = xgb.predict(x_test)\n\n    from sklearn.metrics import r2_score\n    print(i,r2_score(y_test[i],y_pred))\n    \n    cost = sum((y_pred - y_test[i])**2) / sum((y_test[i] - np.mean(y_pred))**2)\n    print(\"Cost\",cost)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:53:51.451373Z","iopub.execute_input":"2021-07-15T15:53:51.451754Z","iopub.status.idle":"2021-07-15T15:54:01.391152Z","shell.execute_reply.started":"2021-07-15T15:53:51.451724Z","shell.execute_reply":"2021-07-15T15:54:01.390203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PolyTrain Function","metadata":{}},{"cell_type":"markdown","source":"Getting Coefficients of A Polynomial (it seems degree=2 produces the most accurate results)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression, HuberRegressor, SGDRegressor, Ridge, Lasso, ElasticNet\nimport matplotlib.pyplot as plt\nimport matplotlib\n\n# max_r_score = 0\ndef poly_train(x_train, x_test, y_train, y_test, degree, graph=False):\n    poly = PolynomialFeatures(degree = degree)\n    x_poly = poly.fit_transform(x_train)\n    poly.fit(x_poly, y_train)\n    \n    #increase iterations, epsilon\n    model = LinearRegression()#HuberRegressor(epsilon=1.0,max_iter=1000,alpha=0.05)\n    model.fit(x_poly, y_train)\n\n    y_pred = model.predict(poly.fit_transform(x_test))\n    \n    from sklearn.metrics import r2_score, mean_squared_error\n    r_score = r2_score(y_pred,y_test)\n    mse = mean_squared_error(y_pred,y_test)\n    cost = sum(abs(y_pred - y_test))\n    \n    if graph:\n        max_r_score = r_score\n        print(\"L1 Error: \",cost)\n\n        print(\"R-score: \",r_score)\n        \n        print(\"MSE: \",mse)\n\n        coefs = list(model.coef_)[1:]\n        intercept = str(model.intercept_)\n        features = poly.get_feature_names(x_train.columns)[1:]\n        for feat in range(len(features)):\n            split_feats=features[feat].split(' ')\n            if len(split_feats) > 1:\n                features[feat]=split_feats[0]+'*'+split_feats[1]\n            if \"^\" in features[feat]:\n                features[feat]=features[feat][:-2]+\"**2\"\n            \n        equation = \"=10**(\"\n        for i in range(len(coefs)):\n            equation += str(coefs[i])+\"*\"+features[i] +\" + \" #\"& \\n\"\n        equation += intercept\n        equation += \")\"\n        print(\"Equation: \",equation)\n        \n        plt.ylabel('analytic')\n        plt.xlabel('NN')\n\n        plt.hist2d(y_test, y_pred, bins=100, cmap='viridis', norm=matplotlib.colors.LogNorm())\n        plt.plot([-1.5, 2],[-1.5, 2], color='red', linewidth=3)\n        \n#         plt.xlim(-1.5,2)\n#         plt.ylim(-1.5,2)\n#         plt.xlim(-1, 2)\n#         plt.ylim(-1, 2)\n        plt.show()\n    return r_score","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:55:58.121003Z","iopub.execute_input":"2021-07-15T15:55:58.121372Z","iopub.status.idle":"2021-07-15T15:55:58.142471Z","shell.execute_reply.started":"2021-07-15T15:55:58.121341Z","shell.execute_reply":"2021-07-15T15:55:58.140864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Base polynomial accuracy","metadata":{}},{"cell_type":"code","source":"max_r_score = 0\n\nprint(\"aa\")\npoly_train(x_train, x_test, y_train['aa'], y_test['aa'], 1, graph=True)\n\nprint(\"bb\")\npoly_train(x_train, x_test, y_train['bb'], y_test['bb'], 1, graph=True)\n\nprint(\"cc\")\npoly_train(x_train, x_test, y_train['cc'], y_test['cc'], 1, graph=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:58:22.0079Z","iopub.execute_input":"2021-07-15T15:58:22.008457Z","iopub.status.idle":"2021-07-15T15:58:22.551435Z","shell.execute_reply.started":"2021-07-15T15:58:22.008424Z","shell.execute_reply":"2021-07-15T15:58:22.550218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bruteforce Combination of all variables","metadata":{}},{"cell_type":"code","source":"import itertools\ndef feature_selection(coefficient):\n    columns = x.columns.tolist() \n    print(columns)\n    features = []\n    complexity = []\n    scores = []\n    \n    print(\"Best combination\")\n    for k in range(1,5):\n        print(\"Trying\",str(k))\n        combinations = itertools.combinations(columns, k)\n        max_r_score = -1e9\n        for combination in combinations:\n            r_score = poly_train(x_train[list(combination)], x_test[list(combination)], y_train[coefficient], y_test[coefficient], 1)\n            if r_score > max_r_score:\n                max_r_score = r_score\n                features = combination\n        scores.append(1-max_r_score)\n        complexity.append(k)\n        print(sorted(features))\n    \n    print(\"\\nSequentially removed features\")\n    scores_sequentially_subtracted = []\n    feature = \"\"\n    selected_features_subtraction=[]\n    for k in range(1,5):\n        print(\"Trying with -\",k,\"features\")\n        max_r_score = -1e9\n        for col in columns:\n            cols = set(columns) - set([col])\n            r_score = poly_train(x_train[cols], x_test[cols], y_train[coefficient], y_test[coefficient], 1)\n            if r_score > max_r_score:\n                max_r_score = r_score\n                feature = col\n        scores_sequentially_subtracted.insert(0,1-max_r_score)\n        selected_features_subtraction.append(feature)\n        columns.remove(feature)\n        print(sorted(columns))\n    \n    print(\"\\nSequentially added features\")\n    columns = x.columns.tolist() \n    scores_sequentially_added = []\n    feature = \"\"\n    selected_features=[]\n    for k in range(1,5):\n        print(\"Trying with\",k,\"features\")\n        max_r_score = -1e9\n        for col in columns:\n            cols = selected_features + [col]\n            r_score = poly_train(x_train[cols], x_test[cols], y_train[coefficient], y_test[coefficient], 1)\n            if r_score > max_r_score:\n                max_r_score = r_score\n                feature = col\n        scores_sequentially_added.append(1-max_r_score)\n        selected_features.append(feature)\n        columns.remove(feature)\n        print(sorted(selected_features))\n    \n    \n    \n    plt.title(coefficient)\n    plt.xlabel(\"# of Terms\")\n    plt.ylabel(\"1-r^2\")\n    plt.plot(complexity,scores, color='blue', marker='o', label=\"Best combination\")\n    plt.plot(complexity,scores_sequentially_subtracted, color='red', marker='o', label=\"Sequentially removed features\")\n    plt.plot(complexity,scores_sequentially_added, color='green', marker='o', label=\"Sequentially added features\")\n    plt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:14:23.269995Z","iopub.execute_input":"2021-07-15T16:14:23.270477Z","iopub.status.idle":"2021-07-15T16:14:23.303878Z","shell.execute_reply.started":"2021-07-15T16:14:23.270434Z","shell.execute_reply":"2021-07-15T16:14:23.302579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_selection(\"aa\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:14:25.084692Z","iopub.execute_input":"2021-07-15T16:14:25.085081Z","iopub.status.idle":"2021-07-15T16:14:40.852512Z","shell.execute_reply.started":"2021-07-15T16:14:25.085043Z","shell.execute_reply":"2021-07-15T16:14:40.851346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_selection(\"bb\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:05:05.605732Z","iopub.execute_input":"2021-07-15T16:05:05.606127Z","iopub.status.idle":"2021-07-15T16:05:07.646801Z","shell.execute_reply.started":"2021-07-15T16:05:05.606092Z","shell.execute_reply":"2021-07-15T16:05:07.645849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_selection(\"cc\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:05:11.280011Z","iopub.execute_input":"2021-07-15T16:05:11.280622Z","iopub.status.idle":"2021-07-15T16:05:13.488636Z","shell.execute_reply.started":"2021-07-15T16:05:11.280572Z","shell.execute_reply":"2021-07-15T16:05:13.487449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's take a closer look at the features we chose from the output of the feature_selection function","metadata":{}},{"cell_type":"code","source":"chosen_features_aa = ['DELTA_LOC', 'P_PRIME_LOC', 'RLTS_1', 'TAUS_2', 'VEXB_SHEAR', 'XNUE']\npoly_train(x_train[list(chosen_features_aa)], x_test[list(chosen_features_aa)], y_train['aa'], y_test['aa'], 1,True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:06:38.731619Z","iopub.execute_input":"2021-07-15T16:06:38.732012Z","iopub.status.idle":"2021-07-15T16:06:38.930993Z","shell.execute_reply.started":"2021-07-15T16:06:38.731981Z","shell.execute_reply":"2021-07-15T16:06:38.929998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chosen_features_bb = ['DEBYE', 'DELTA_LOC', 'Q_PRIME_LOC', 'RLNS_2', 'RLTS_1', 'VPAR_1']\npoly_train(x_train[list(chosen_features_bb)], x_test[list(chosen_features_bb)], y_train['bb'], y_test['bb'], 1,True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:07:12.827241Z","iopub.execute_input":"2021-07-15T16:07:12.827752Z","iopub.status.idle":"2021-07-15T16:07:13.013901Z","shell.execute_reply.started":"2021-07-15T16:07:12.827721Z","shell.execute_reply":"2021-07-15T16:07:13.013099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chosen_features_cc = ['DELTA_LOC', 'RLTS_1', 'RLTS_2', 'TAUS_2', 'XNUE']\npoly_train(x_train[list(chosen_features_cc)], x_test[list(chosen_features_cc)], y_train['cc'], y_test['cc'], 1,True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:07:15.542217Z","iopub.execute_input":"2021-07-15T16:07:15.542581Z","iopub.status.idle":"2021-07-15T16:07:15.728317Z","shell.execute_reply.started":"2021-07-15T16:07:15.54255Z","shell.execute_reply":"2021-07-15T16:07:15.727543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection Function","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.feature_selection import SelectKBest\nimport matplotlib.pyplot as plt\n\ndef getFeatures(column):\n    #Extra Trees\n    np.seterr(divide='ignore', invalid='ignore')\n    feature_tree = ExtraTreesRegressor()\n    feature_tree.fit(x,y[column])\n\n    feat_importances_tree = pd.Series(feature_tree.feature_importances_, index=x.columns)\n    tree_features = feat_importances_tree.nlargest(13)\n#     tree_features.plot(kind='barh')\n#     plt.show()\n    \n    #KBest\n    KBest = SelectKBest()\n    feature_kbest = KBest.fit(x,y[column])\n    feat_importances_kbest = pd.Series(feature_kbest.scores_, index=x.columns)\n    kbest_features = feat_importances_kbest.nlargest(13)\n#     kbest_features.plot(kind='barh')\n#     plt.show()\n    return kbest_features.keys(), tree_features.keys()\n\ngetFeatures(\"aa\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:07:53.798335Z","iopub.execute_input":"2021-07-15T16:07:53.798895Z","iopub.status.idle":"2021-07-15T16:08:07.371058Z","shell.execute_reply.started":"2021-07-15T16:07:53.798847Z","shell.execute_reply":"2021-07-15T16:08:07.37007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generateEquations(complexity, column, degrees):\n    features = 13-complexity\n    kbest_feats, tree_feats = getFeatures(column)\n\n    kbest_cols = []\n    for i in kbest_feats[:-features]:\n        kbest_cols.append(i)\n        for degree in degrees:\n            poly_train(x_train[kbest_cols], x_test[kbest_cols], y_train[column], y_test[column], degree, graph=True)\n            \n    tree_cols = []\n    for j in tree_feats[:-features]:\n        tree_cols.append(j)\n        for degree in degrees:\n            poly_train(x_train[tree_cols], x_test[tree_cols], y_train[column], y_test[column], degree, graph=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:09:37.950385Z","iopub.execute_input":"2021-07-15T16:09:37.950846Z","iopub.status.idle":"2021-07-15T16:09:37.960064Z","shell.execute_reply.started":"2021-07-15T16:09:37.950789Z","shell.execute_reply":"2021-07-15T16:09:37.959191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models with less complexity and printed coefficients","metadata":{}},{"cell_type":"code","source":"#aa\ngenerateEquations(6, \"aa\", [1])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:10:25.405229Z","iopub.execute_input":"2021-07-15T16:10:25.405761Z","iopub.status.idle":"2021-07-15T16:10:39.88607Z","shell.execute_reply.started":"2021-07-15T16:10:25.405728Z","shell.execute_reply":"2021-07-15T16:10:39.885104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bb\ngenerateEquations(8, \"bb\", [1])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T16:11:22.603919Z","iopub.execute_input":"2021-07-15T16:11:22.604329Z","iopub.status.idle":"2021-07-15T16:11:37.445053Z","shell.execute_reply.started":"2021-07-15T16:11:22.604296Z","shell.execute_reply":"2021-07-15T16:11:37.443968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cc\ngenerateEquations(12, \"cc\", [1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}