{"cells":[{"metadata":{},"cell_type":"markdown","source":"# How HR can help to prevent loss of good people to organization\n\nThe key to success in any organization is attracting and retaining top talent.\n\nEmployee churn can be defined as a leak or departure of an intellectual asset from a company or organization. Alternatively, in simple words, you can say, when employees leave the organization is known as churn. Another definition can be when a member of a population leaves a population, is known as churn.\n\nIn Research, it was found that employee churn will be affected by age, tenure, pay, job satisfaction, salary, working conditions, growth potential and employee’s perceptions of fairness. Some other variables such as age, gender, ethnicity, education, and marital status, were essential factors in the prediction of employee churn. In some cases such as the employee with niche skills are harder to replace.\n\nIt affects the ongoing work and productivity of existing employees.\n\nAcquiring new employees as a replacement has its costs such as hiring costs and training costs. Also, the new employee will take time to learn skills at the similar level of technical or business expertise knowledge of an older employee. Organizations tackle this problem by applying machine learning techniques to predict employee churn, which helps them in taking necessary actions.\n\nYou are an HR analyst at a company, and one of the tasks is to determine which factors keep employees at the company and which prompt others to leave.\n\nYou need to know what factors can change to prevent the loss of good people.\n\n### What data we have?\nData has various data points on our employees, but you are most interested in whether they’re still with my company or whether they’ve gone to work somewhere else.\n\n### Data Information\n\n- Education: 1 'Below College’, 2 'College’, 3 'Bachelors', 4 'Master’, 5 'Doctors'\n- Environment Satisfaction: 1 'Low', 2 'Medium', 3 'High', 4 'Very High'\n- Job Involvement: 1 'Low’, 2 'Medium', 3 'High’, 4 'Very High'\n- Job Satisfaction: 1 'Low’, 2 'Medium’, 3 'High’, 4 'Very High'\n- Performance Rating: 1 'Low’, 2 'Good’, 3 'Excellent’, 4 'Outstanding'\n- Relationship Satisfaction: 1 'Low’, 2 'Medium’, 3 'High’, 4 'Very High'\n- Work Life Balance: 1 'Bad’, 2 'Good’, 3 'Better’, 4 'Best"},{"metadata":{},"cell_type":"markdown","source":"### Load Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\n# To avoid Warning message inbetween ...\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/Attrition1.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick Analysis on Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quick Analysis on Dataset : DataTypes, Rows and Columns ,Null values, Unique values ...\ndef quick_analysis(df):\n    print(\"Data Types:\")\n    print(df.dtypes)\n    print(\"\\nRows and Columns:\")\n    print(df.shape)\n    print(\"\\nColumn names:\")\n    print(df.columns)\n    print(\"\\nNull Values\")\n    print(df.apply(lambda x: sum(x.isnull()) / len(df)))\n    print(\"\\nUnique values\")\n    print(df.nunique())\n\nquick_analysis(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing Unwanted Variables"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Dropping the unwanted columns: Those having only one unique value.\ndf=df.drop([\"EmployeeCount\",\"Over18\",\"StandardHours\",\"EmployeeNumber\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis (EDA)"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Visual Exploratory Data Analysis (EDA) And Your First Model\n#EDA on Feature Variables\nprint(list(set(df.dtypes.tolist())))\ndf_object = df.select_dtypes(include=[\"object\"]).copy()\ndf_int = df.select_dtypes(include=['int64']).copy()\n\ncategorical = df_object.columns\nnumerical = df_int.columns\n\nprint(\"Datashape of Object Dataframe:\",df_object.shape)\nprint(\"Datashape of Interger Dataframe:\",df_int.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Univariate Analysis\n# EDA with Categorical Variables\n\nfig,ax = plt.subplots(3,2, figsize=(20,20))\nfor variable,subplot in zip(categorical,ax.flatten()):\n    sns.countplot(df[variable],ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis on: Numerical Variables"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# EDA with Numerical Variables\ndf[numerical].hist(bins=50,figsize=(16,20),layout=(8,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bivariate analysis"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Bivariate analysis - Categorical (Target variable) vs Numerical ( Feature Variables)\nfig , ax =plt.subplots(4,6,figsize=(30,30))\nfor var,subplot in zip(numerical,ax.flatten()):\n    sns.boxplot(x=\"Attrition\",y=var,data=df, ax=subplot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#fig , ax =plt.subplots(3,8,figsize=(30,30))\nfor var,subplot in zip(numerical,ax.flatten()):\n    facet = sns.FacetGrid(df,hue=\"Attrition\",aspect=4)\n    facet.map(sns.kdeplot,var,shade= True)\n    facet.set(xlim=(0,df[var].max()))\n    facet.add_legend()\n    plt.show()\n    #sns.boxplot(x=\"Attrition\",y=var,data=df, ax=subplot) ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"Attrition\",row=\"Gender\",aspect=1,height=4,hue=\"Department\") \ng.map(sns.distplot, \"YearsAtCompany\")\ng.set(xlim=(0,df[\"YearsAtCompany\"].max()))\n#plt.xlim(0,6)\ng.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"Attrition\",row=\"Department\",hue=\"Gender\",aspect=1,height=5) \ng.map(sns.distplot, \"MonthlyIncome\")\ng.add_legend()\ng.set(xlim=(0,df[\"MonthlyIncome\"].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"Attrition\",row=\"JobRole\",hue=\"Gender\",aspect=1,height=5) \ng.map(sns.distplot, \"MonthlyIncome\")\ng.add_legend()\nplt.ylim(0,0.0010)\ng.set(xlim=(0,df[\"MonthlyIncome\"].max()))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"figure = plt.figure(figsize=(20,8))\nplt.hist([df[df['Attrition'] == 1]['MonthlyIncome'], df[df['Attrition'] == 0]['MonthlyIncome']], \n         stacked=True,\n         bins = 80, label = ['Attrition','Not_Attrition'])\nplt.xlabel('MonthlyIncome')\nplt.ylabel('Number of Employees')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df.groupby([\"JobRole\",\"Gender\"]).Attrition.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"labels = df['JobRole'].astype('category').cat.categories.tolist()\ncounts = df['JobRole'].value_counts()\nsizes = [counts[var_cat] for var_cat in labels]\nprint(sizes)\nfig1, ax1 = plt.subplots(figsize=(6,6))\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True) #autopct is show the % on plot\nax1.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Manuplation in the Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Data Manuplation in the Dataset\n# Data types changes for :Features Variables\n\n# Variables in df needs to be changed to the object type from int64.\ndf[\"Education\"] = df[\"Education\"].astype(object)\ndf[\"EnvironmentSatisfaction\"] = df[\"EnvironmentSatisfaction\"].astype(object)\ndf[\"JobInvolvement\"] = df[\"JobInvolvement\"].astype(object)\ndf[\"JobLevel\"] = df[\"JobLevel\"].astype(object)\ndf[\"JobSatisfaction\"] = df[\"JobSatisfaction\"].astype(object)\ndf[\"PerformanceRating\"] = df[\"PerformanceRating\"].astype(object)\ndf[\"RelationshipSatisfaction\"] = df[\"RelationshipSatisfaction\"].astype(object)\ndf[\"StockOptionLevel\"] = df[\"StockOptionLevel\"].astype(object)\ndf[\"TrainingTimesLastYear\"] = df[\"TrainingTimesLastYear\"].astype(object)\ndf[\"WorkLifeBalance\"] = df[\"WorkLifeBalance\"].astype(object)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature engineering "},{"metadata":{},"cell_type":"markdown","source":"Data Manuplation in the Dataset and Feature engineering and selection.\n\nTaking sqrt tranformation,so the data distribution look normal Distribution.\n\nTaking log tranformation on Montly Income,so the data distribution look normal Distribution ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"df[\"TotalWorkingYears\"] =np.sqrt(df[\"TotalWorkingYears\"])\ndf[\"YearsAtCompany\"] =np.sqrt(df[\"YearsAtCompany\"])\n\n# Taking log tranformation,so the data distribution look normal Distribution ...\ndf[\"MonthlyIncome\"] = np.log(df[\"MonthlyIncome\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### YearsInCurrentRole from the Dataframe ... Explanation as follows\n\n- 0 >YearsInCurrentRole in between 0 and 2 - Termed as Fresher in the Current Role.\n- 1 > YearsInCurrentRole in between 3 and 6 - Termed as Intermidate in the Current Role.\n- 2 > YearsInCurrentRole in between 7 and 10 - Termed as Experienced in the Current Role.\n- 3 > YearsInCurrentRole in between 11 and 18 - Termed as SME in the Current Role."},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[ df['YearsInCurrentRole'] <= 2,'YearsInCurrentRole'] = 0\ndf.loc[ (df['YearsInCurrentRole'] >=3) & (df['YearsInCurrentRole'] <= 6) ,'YearsInCurrentRole'] = 1\ndf.loc[ (df['YearsInCurrentRole'] >=7) & (df['YearsInCurrentRole'] <= 10), 'YearsInCurrentRole'] = 2\ndf.loc[ (df['YearsInCurrentRole'] >=11) & (df['YearsInCurrentRole'] <= 18), 'YearsInCurrentRole'] = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### YearsSinceLastPromotion from the Dataframe ... Explanation as follows\n\n- 0 > YearsSinceLastPromotion in between 0 and 1 - Termed as Less than one Year -- Newly Promoted\n- 1 > YearsSinceLastPromotion in between 2 and 4 - Termed as between 2 and 4 year -- Waiting for a while for Promoting \n- 2 > YearsSinceLastPromotion in between 5 and 7 - Termed as between 5 and 7 year -- Too Much Waiting for Promoting\n- 3 > YearsSinceLastPromotion in between 8 and 15 - Termed as between 8 and 15 year -- No promotions given for along while"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[ df['YearsSinceLastPromotion'] <= 1,'YearsSinceLastPromotion'] = 0\ndf.loc[ (df['YearsSinceLastPromotion'] >=2) & (df['YearsSinceLastPromotion'] <= 4) ,'YearsSinceLastPromotion'] = 1\ndf.loc[ (df['YearsSinceLastPromotion'] >=5) & (df['YearsSinceLastPromotion'] <= 7), 'YearsSinceLastPromotion'] = 2\ndf.loc[ (df['YearsSinceLastPromotion'] >=8) & (df['YearsSinceLastPromotion'] <= 15), 'YearsSinceLastPromotion'] = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### YearsWithCurrManager from the Dataframe ... Explanation as follows\n\n- 0 > YearsWithCurrManager in between 0 and 1 - Termed as Less than one Year \n- 1 > YearsWithCurrManager in between 2 and 3 - Termed as between 2 and 3 year \n- 2 > YearsWithCurrManager in between 4 and 6 - Termed as between 4 and 6 year \n- 3 > YearsWithCurrManager in between 7 and 9 - Termed as between 7 and 9 year \n- 4 > YearsWithCurrManager in between 10 and 17 - Termed as between 10 and 17 year "},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[ df['YearsWithCurrManager'] < 1,'YearsWithCurrManager'] = 0\ndf.loc[ (df['YearsWithCurrManager'] >=2) & (df['YearsWithCurrManager'] <= 3) ,'YearsWithCurrManager'] = 1\ndf.loc[ (df['YearsWithCurrManager'] >=4) & (df['YearsWithCurrManager'] <= 6), 'YearsWithCurrManager'] = 2\ndf.loc[ (df['YearsWithCurrManager'] >=7) & (df['YearsWithCurrManager'] <= 9), 'YearsWithCurrManager'] = 3\ndf.loc[ (df['YearsWithCurrManager'] >=10) & (df['YearsWithCurrManager'] <= 17), 'YearsWithCurrManager'] = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### DistanceFromHome from the Dataframe ... Explanation as follows\n\n- 0 > DistanceFromHome in between 0 and 2 - Termed as Less than one Year -- Very close \n- 1 > DistanceFromHome in between 3 and 5 - Termed as between 2 and 4 year -- Normal Distance\n- 2 > DistanceFromHome in between 6 and 8 - Termed as between 5 and 8 year -- Modearte DiStance\n- 3 > DistanceFromHome in between 9 and 12 - Termed as between 9 and 15 year -- Average DiStance  \n- 4 > DistanceFromHome in between 13 and 20 - Termed as between 9 and 15 year -- Little Fare\n- 5 > DistanceFromHome in between 21 and 29 - Termed as between 9 and 15 year -- Long Fare away"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[ df['DistanceFromHome'] <= 2,'DistanceFromHome'] = 0\ndf.loc[ (df['DistanceFromHome'] >=3) & (df['DistanceFromHome'] <= 5) ,'DistanceFromHome'] = 1\ndf.loc[ (df['DistanceFromHome'] >=6) & (df['DistanceFromHome'] <= 8), 'DistanceFromHome'] = 2\ndf.loc[ (df['DistanceFromHome'] >=9) & (df['DistanceFromHome'] <= 12), 'DistanceFromHome'] = 3\ndf.loc[ (df['DistanceFromHome'] >=13) & (df['DistanceFromHome'] <= 20), 'DistanceFromHome'] = 4\ndf.loc[ (df['DistanceFromHome'] >=21) & (df['DistanceFromHome'] <= 29), 'DistanceFromHome'] = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### NumCompaniesWorked from the Dataframe ... Explanation as follows\n\n0 > NumCompaniesWorked in between 0 and 2 - Termed as Less than one Year -- Very close \n1 > NumCompaniesWorked in between 3 and 5 - Termed as between 2 and 4 year -- Normal Distance\n2 > NumCompaniesWorked in between 6 and 8 - Termed as between 5 and 8 year -- Modearte DiStance\n3 > NumCompaniesWorked in between 9 and 12 - Termed as between 9 and 15 year -- Average DiStance  \n4 > NumCompaniesWorked in between 13 and 20 - Termed as between 9 and 15 year -- Little Fare\n5 > NumCompaniesWorked in between 21 and 29 - Termed as between 9 and 15 year -- Long Fare away"},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[ df['NumCompaniesWorked'] <= 1,'NumCompaniesWorked'] = 0\ndf.loc[ (df['NumCompaniesWorked'] >=2) & (df['NumCompaniesWorked'] <= 4) ,'NumCompaniesWorked'] = 1\ndf.loc[ (df['NumCompaniesWorked'] >=5) & (df['NumCompaniesWorked'] <= 6), 'NumCompaniesWorked'] = 2\ndf.loc[ (df['NumCompaniesWorked'] >=7) & (df['NumCompaniesWorked'] <= 9), 'NumCompaniesWorked'] = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### PercentSalaryHike from the Dataframe ... Explanation as follows\n\n- 0 > PercentSalaryHike in between 11 and 12 - Termed as Less than one Year\n- 1 > PercentSalaryHike in between 13 and 14 - Termed as between 2 and 4 year \n- 2 > PercentSalaryHike in between 15 and 18 - Termed as between 5 and 8 year \n- 3 > PercentSalaryHike in between 19 and 21 - Termed as between 9 and 15 year\n- 4 > PercentSalaryHike in between 22 and 25 - Termed as between 9 and 15 year "},{"metadata":{"trusted":false},"cell_type":"code","source":"df.loc[ df['PercentSalaryHike'] <= 12,'PercentSalaryHike'] = 0\ndf.loc[ (df['PercentSalaryHike'] >=13) & (df['PercentSalaryHike'] <= 14) ,'PercentSalaryHike'] = 1\ndf.loc[ (df['PercentSalaryHike'] >=15) & (df['PercentSalaryHike'] <= 18), 'PercentSalaryHike'] = 2\ndf.loc[ (df['PercentSalaryHike'] >=19) & (df['PercentSalaryHike'] <= 21), 'PercentSalaryHike'] = 3\ndf.loc[ (df['PercentSalaryHike'] >=22) & (df['PercentSalaryHike'] <= 25), 'PercentSalaryHike'] = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Data Manuplation in the Converted Object variables\n###### Data types changes for :Features Variables"},{"metadata":{"trusted":false},"cell_type":"code","source":"df[\"YearsInCurrentRole\"] = df[\"YearsInCurrentRole\"].astype(object)\ndf[\"YearsSinceLastPromotion\"] = df[\"YearsSinceLastPromotion\"].astype(object)\ndf[\"YearsWithCurrManager\"] = df[\"YearsWithCurrManager\"].astype(object)\ndf[\"DistanceFromHome\"] = df[\"DistanceFromHome\"].astype(object)\ndf[\"NumCompaniesWorked\"] = df[\"NumCompaniesWorked\"].astype(object)\ndf[\"PercentSalaryHike\"] = df[\"PercentSalaryHike\"].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#EDA on Feature Variables\nprint(list(set(df.dtypes.tolist())))\ndf_object = df.select_dtypes(include=[\"object\"]).copy()\ndf_int = df.select_dtypes(include=['int64','float64']).copy()\n\ncategorical = df_object.columns\nnumerical = df_int.columns\n\nprint(\"Datashape of Object Dataframe:\",df_object.shape)\nprint(\"Datashape of Interger Dataframe:\",df_int.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature selection"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Features encoding and scaling\n# Preprocessing packages \nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# Model selection for Train and Test split the dataset\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def feature_imp_Dataset(df):\n    #Target Columns\n    target_col = [\"Attrition\"]\n\n    #Categorical Columns\n    cat_cols = df.nunique()[df.nunique() < 10].keys().tolist()\n    cat_cols = [x for x in cat_cols if x not in target_col]\n\n    #numerical columns\n    num_cols = [x for x in df.columns if x not in cat_cols + target_col]\n\n    #Binary columns with 2 values\n    bin_cols = df.nunique()[df.nunique() == 2].keys().tolist()\n\n    #Columns more than 2 values\n    multi_cols = [i for i in cat_cols if i not in bin_cols] \n    \n    df_feature_imp = df.copy()\n    \n    #Label encoding Binary columns\n    le = LabelEncoder()\n    for i in cat_cols:\n        df_feature_imp[i] = le.fit_transform(df_feature_imp[i])\n\n    #Dulpicating columns for Multiple value columns\n    #df = pd.get_dummies(data=df,columns= multi_cols,drop_first=True)\n    df_feature_imp= pd.get_dummies(data=df_feature_imp,columns= multi_cols)\n    \n    return df_feature_imp","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Feature selection\n\n# Inorder to avoid the Dummy trap, we are removing the less Importance Dummy Varaible columns...\n# For this we are using the Random Forest to select the Importance Feature...\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100, max_features='sqrt')\n\n# Loading the dataset:\ndf_feature_imp = feature_imp_Dataset(df)\n\n# Def X and Y for Unscaled Dataset\ntarget_col = [\"Attrition\"]\ny = pd.DataFrame(df_feature_imp,columns=target_col)\n#y = df_unscaled[\"Attrition\"]\nX = df_feature_imp.drop('Attrition',1)\n\n# Fit the Model with the X and y ...\nclf = clf.fit(X, y)\nfeatures = pd.DataFrame()\nfeatures['feature'] = X.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\nfeatures.plot(kind='barh', figsize=(25, 25))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Overcome Dummy Trap "},{"metadata":{"trusted":false},"cell_type":"code","source":"# As per the Importance Features Techinque With the help of Random Forest Classifier we could see the below Dummy Variables\n# has less Importance compared to other Dummy variables, so we are removing those variables.\n\nto_drop_dummy_variable_trap= ['BusinessTravel_0','Department_0','DistanceFromHome_2','Education_4','EducationField_0','EnvironmentSatisfaction_1',\n 'JobInvolvement_3','JobLevel_3','JobRole_4','JobSatisfaction_1','MaritalStatus_0','NumCompaniesWorked_1','PercentSalaryHike_3',\n 'RelationshipSatisfaction_1','StockOptionLevel_2','TrainingTimesLastYear_5','WorkLifeBalance_3','YearsInCurrentRole_3','YearsInCurrentRole_3',\n 'YearsWithCurrManager_4']\n#df = df.drop(columns=to_drop_dummy_variable_trap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix : With respect to Depedent variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Correlation Matrix - Orginal Dataset ...\n\n#correlation for Orginal Dataset\ncorrelation = df.corr()\n\n#tick labels\n#matrix_cols = correlation.columns.tolist()\n#convert to array\n#corr_array  = np.array(correlation)\n\n# Viewing the Correlation with respect to Attrition ...\ncorr_list = correlation['Attrition'].sort_values(axis=0,ascending=False)#.iloc[1:]\n#corr_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Prepartion "},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\ndef _compute_class_weight_dictionary(y):\n    # helper for returning a dictionary instead of an array\n    classes = np.unique(y)\n    class_weight = compute_class_weight(\"balanced\", classes, y)\n    class_weight_dict = dict(zip(classes, class_weight))\n    return class_weight_dict   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y=df[\"Attrition\"]\nprint(\"Class Weight for the Attrition Attribute:\")\n_compute_class_weight_dictionary(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Unsacled Dataset(Dataframe as its given...)"},{"metadata":{},"cell_type":"markdown","source":"Here we have created a copy of the dataset after Feature engineering.\n\nThe below steps were taken as part of this funtion:\n\n - Label Encoded the categorical columns which has less than 10 unique elements.\n - Removed the variables which has more the 0.7 correlation value with respect to independent variables.\n - Removed some of the categorical variables which we converted with LabelEncoder inorder to avoid the Dummy Variable trap.\n - Split the Dataset to train and test for further techinques."},{"metadata":{"trusted":false},"cell_type":"code","source":"def unscaled_data(df):\n    #global to_drop_dummy_variable_trap\n    #Target Columns\n    target_col = [\"Attrition\"]\n\n    #Categorical Columns\n    cat_cols = df.nunique()[df.nunique() < 10].keys().tolist()\n    cat_cols = [x for x in cat_cols if x not in target_col]\n\n    #numerical columns\n    num_cols = [x for x in df.columns if x not in cat_cols + target_col]\n\n    #Binary columns with 2 values\n    bin_cols = df.nunique()[df.nunique() == 2].keys().tolist()\n\n    #Columns more than 2 values\n    multi_cols = [i for i in cat_cols if i not in bin_cols]\n    \n    df_unscaled = df.copy()\n\n    #Label encoding Binary columns\n    le = LabelEncoder()\n    for i in cat_cols:\n        df_unscaled[i] = le.fit_transform(df_unscaled[i])\n\n    #Dulpicating columns for Multiple value columns\n    #df = pd.get_dummies(data=df,columns= multi_cols,drop_first=True)\n    df_unscaled= pd.get_dummies(data=df_unscaled,columns= multi_cols)\n\n    #Dropping original values merging scaled values for numerical columns\n    #f_unscaled = df.copy()\n    \n    ###############################################################################\n    # Remove collinear features for Unscaled Dataset ...\n    # Threshold to remove correlated Variables\n    threshold = 0.7\n    #0.8 - Initailly i have taken as\n\n    # Absolute value of corelation matrix\n    corr_matrix = df_unscaled.corr().abs()\n    corr_matrix.head()\n\n    # Upper triangle of correlations\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n    upper.head()\n\n    # Select columns with correlations above threshold\n    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n    print('There are %d columns to remove:' %(len(to_drop)))\n    print(\"Threshold more than %s \\n\" %threshold ,to_drop)\n    df_unscaled = df_unscaled.drop(columns=to_drop)\n    \n    #Columns thats is to avoid dummy variable trap: to_drop_dummy_variable_trap\n    \n    to_drop_dummy_variable_trap_un = [i for i in to_drop_dummy_variable_trap if i not in to_drop]\n    df_unscaled = df_unscaled.drop(columns=to_drop_dummy_variable_trap_un)\n    print(\"\\nRemoving variables to avoid Dummy variable trap:\\n\")\n    print(to_drop_dummy_variable_trap_un)\n    print(\"\\n\")\n    \n    ###############################################################################\n    #y=df_unscaledl[\"Attrition\"]\n    #print(\"Class Weight for the Attrition Attribute:\\n\")\n    #_compute_class_weight_dictionary(y)\n    #print(\"\\n\")\n    \n    ###############################################################################\n    # Prepare dataset\n    # Define (X, y)\n\n    # Def X and Y for Unscaled Dataset\n    y = pd.DataFrame(df_unscaled,columns=target_col)\n    #y = df_unscaled[\"Attrition\"]\n    X = df_unscaled.drop('Attrition',1)\n    \n    # execute this step if you need the Orginal \"Train test split :X_train, X_test, y_train, y_test\" \n    random_state =0\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = random_state)\n    # Defining Cols variables to store the Column names of X Unscaled dataframe.\n    cols = X_train.columns\n    \n    return X_train,X_test,y_train,y_test,cols,X,y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Scaled Dataset"},{"metadata":{},"cell_type":"markdown","source":"Here we have created a copy of the dataset after Feature engineering.\n\nThe below steps were taken as part of this funtion:\n\n- Label Encoded the categorical columns which has less than 10 unique elements.\n- Removed the variables which has more the 0.7 correlation value with respect to independent variables.\n- Scaled the numerical variable inorder to standardize.\n- Removed some of the categorical variables which we converted with LabelEncoder inorder to avoid the Dummy Variable trap.\n- Split the Dataset to train and test for further techinques."},{"metadata":{"trusted":false},"cell_type":"code","source":"def scaled_data(df):\n    #Target Columns\n    target_col = [\"Attrition\"]\n\n    #Categorical Columns\n    cat_cols = df.nunique()[df.nunique() < 10].keys().tolist()\n    cat_cols = [x for x in cat_cols if x not in target_col]\n\n    #numerical columns\n    num_cols = [x for x in df.columns if x not in cat_cols + target_col]\n\n    #Binary columns with 2 values\n    bin_cols = df.nunique()[df.nunique() == 2].keys().tolist()\n\n    #Columns more than 2 values\n    multi_cols = [i for i in cat_cols if i not in bin_cols]\n    \n    df_scaled = df.copy()\n    \n    #Label encoding Binary columns\n    le = LabelEncoder()\n    for i in cat_cols:\n        df_scaled[i] = le.fit_transform(df_scaled[i])\n\n    #Dulpicating columns for Multiple value columns\n    #df = pd.get_dummies(data=df,columns= multi_cols,drop_first=True)\n    df_scaled = pd.get_dummies(data=df_scaled,columns= multi_cols)\n\n    #Scaling the Numerical columns\n    std = StandardScaler()\n    scaled = std.fit_transform(df_scaled[num_cols])\n    scaled = pd.DataFrame(scaled,columns=num_cols)\n\n    #Dropping original values merging scaled values for numerical columns\n    df_scaled = df_scaled.drop(columns= num_cols,axis=1)\n    df_scaled = df_scaled.merge(scaled,left_index=True,right_index=True,how=\"left\")\n    \n    ###############################################################################\n    # Threshold to remove correlated Variables\n    threshold = 0.7\n    #0.8 - Initailly i have taken as\n\n    # Absolute value of corelation matrix\n    corr_matrix = df_scaled.corr().abs()\n    corr_matrix.head()\n\n    # Upper triangle of correlations\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n    upper.head()\n\n    # Select columns with correlations above threshold\n    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n    print('There are %d columns to remove:' %(len(to_drop)))\n    print(\"Threshold more than %s \\n\" %threshold ,to_drop)\n    df_scaled = df_scaled.drop(columns=to_drop)\n    print(to_drop)\n    \n    #Columns thats is to avoid dummy variable trap: to_drop_dummy_variable_trap\n    \n    to_drop_dummy_variable_trap_un = [i for i in to_drop_dummy_variable_trap if i not in to_drop]\n    df_scaled = df_scaled.drop(columns=to_drop_dummy_variable_trap_un)\n    print(\"\\nRemoving variables to avoid Dummy variable trap:\\n\")\n    print(to_drop_dummy_variable_trap_un)\n    print(\"\\n\")\n    \n    ###############################################################################\n    # Def X and Y for Scaled Dataset\n    y_scale = pd.DataFrame(df_scaled,columns=target_col)\n    #y = df_unscaled[\"Attrition\"]\n    X_scale = df_scaled.drop('Attrition',1)\n    \n    ###############################################################################   \n    # execute this step if you need the Scaled \"Train test split :X_train, X_test, y_train, y_test\" \n    random_state = 0\n    X_train, X_test, y_train, y_test = train_test_split(X_scale,y_scale, test_size = 0.30, random_state = random_state)\n    # Defining Cols variables to store the Column names of X scaled dataframe.\n    cols = X_train.columns\n    \n    return X_train, X_test, y_train, y_test,cols,X_scale,y_scale","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cross Validation Scores"},{"metadata":{"trusted":false},"cell_type":"code","source":"def cross_validate_(model,X,y,num_validations=5):\n    accuracy_train = cross_val_score(model,X,y,scoring=\"accuracy\",cv=num_validations)\n    precision_train = cross_val_score(model,X,y,scoring=\"precision\",cv=num_validations)\n    recall_train = cross_val_score(model,X,y,scoring=\"recall\",cv=num_validations)\n    f1_train = cross_val_score(model,X,y,scoring=\"f1_weighted\",cv=num_validations)                                  \n    \n    print(\"Cross Validation of : {}\".format(model.__class__.__name__))\n    print('*********************')\n    print(\" Model :\",model)\n    #print(\"Transforming {}\".format(transformer.__class__.__name__))\n    print(\"Accuracy: \" , round(100*accuracy_train.mean(), 2))\n    print(\"Precision: \",  round(100*precision_train.mean(), 2))\n    print(\"Recall: \",  round(100*recall_train.mean(), 2))\n    print(\"F1 Score: \",  round(100*f1_train.mean(), 2))\n    print('**************************************************************************\\n')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling"},{"metadata":{},"cell_type":"markdown","source":"##### Loading neccesary libraries ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Modelling\n# Baseline Model\n\n# Support functions\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_validate\nfrom scipy.stats import uniform\n\n# Fit models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nimport statsmodels.api as sm\n\n\n# Scoring functions\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import mean_squared_error\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basics function for Prediction"},{"metadata":{},"cell_type":"markdown","source":"##### Function which can predict the Accuracy and Area under the curve(AUC) of test data from Train dataset in a single shot ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Basics function for Prediction\n# Function which can predict the Accuracy and Area under the curve(AUC) of test data from Train dataset in a single shot ...\n\ndef Attrition_prediction(algorthim,train_x,test_x,train_y,test_y,cols):\n    \n    #model\n    algorthim.fit(train_x,train_y)\n    predictions = algorthim.predict(test_x)\n    #probabilities = algorthim.predict_proba(test_x)\n     \n    #roc_auc_score\n    model_roc_auc = roc_auc_score(test_y,predictions)\n    \n    #RMSE values of Train Model ...\n    train_y_pred = algorthim.predict(train_x)\n    confusion_matrix(train_y,train_y_pred)\n\n    final_mse = mean_squared_error(train_y,train_y_pred) \n    train_final_rmse = np.sqrt(final_mse)\n    \n    #RMSE values of Test Model ...\n    final_mse = mean_squared_error(test_y,predictions) \n    test_final_rmse = np.sqrt(final_mse)\n    \n    #Confusion Matrix for Train Model ...\n    confuse_train = confusion_matrix(train_y, train_y_pred)\n    \n    #Confusion Matrix for Train Model ...\n    confuse_test = confusion_matrix(test_y, predictions)\n    \n    print(\"Algorthims parameters used :\\n\\n\",algorthim)\n    print(\"\\n Classification Report :\\n\", classification_report(test_y,predictions))\n    print(\"Accuracy Score of Train :\", accuracy_score(train_y,train_y_pred),\"\\n\")\n    print(\"Accuracy Score of Test :\", accuracy_score(test_y,predictions),\"\\n\")\n    print(\"Area under the curve :\",model_roc_auc,\"\\n\")\n    print(\"RMSE of the Train Model :\",train_final_rmse,\"\\n\")\n    print(\"Confusion Matrix of the Train Model :\\n\",confuse_train)\n    print(\"RMSE of the Test Model :\",test_final_rmse,\"\\n\")\n    print(\"Confusion Matrix of the Test Model :\\n\",confuse_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's try different base models"},{"metadata":{},"cell_type":"markdown","source":"### Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"In this method we will use cross validation techinque into different Machine learning algorthims by using the all dataset inorder to calculate which Algorthims shows better:\n - Accuracy\n - Precision\n - Recall\n - F1 Score"},{"metadata":{"trusted":false},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg_cv = LogisticRegressionCV()\nrandom_f = RandomForestClassifier()\nknn = KNeighborsClassifier()\nsvc = SVC(kernel='linear')\nxgb = XGBClassifier()\n\nclassifiers = [logreg, logreg_cv, random_f, knn, svc, xgb]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Cross Validation: Unscaled Dataset:"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\nprint('**************************************************************************\\n')\n#for model in classifiers:\n    #cross_validate_(model,X,y,num_validations=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Cross Validation: Scaled Dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\nprint('**************************************************************************\\n')\nfor model in classifiers:\n    cross_validate_(model,X,y,num_validations=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bagging Techinque"},{"metadata":{},"cell_type":"markdown","source":"#### Bagging different Machine Learning Techinques ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg_cv = LogisticRegressionCV()\nrandom_f = RandomForestClassifier()\nknn = KNeighborsClassifier()\nsvm = SVC()\nxgb = XGBClassifier()\nfrom sklearn.ensemble import BaggingClassifier\nclassifiers = [logreg, logreg_cv, random_f, knn, svm, xgb]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Bagging Techinque: Unscaled Dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\nprint('**************************************************************************\\n')\nfor model in classifiers:\n    print(\"Bagging Techinque on :{}\".format(model.__class__.__name__))\n    print(\"**********************\")\n    print(\"Model used:\", model)\n    bag_model = BaggingClassifier(base_estimator=model,n_estimators=100,bootstrap=True)\n    bag_model = bag_model.fit(X_train,y_train)\n    ytest_pred = bag_model.predict(X_test)\n    print(\"Bagging Accuarcy :\", bag_model.score(X_test,y_test))\n    print(\"Confusin Matrix :\\n \", confusion_matrix(y_test,ytest_pred))\n    print(\"***************************************************************************\\n\")\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Bagging Techinque: Scaled Dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\nprint('**************************************************************************\\n')\nfor model in classifiers:\n    print(\"Bagging Techinque on :{}\".format(model.__class__.__name__))\n    print(\"**********************\")\n    print(\"Model used:\", model)\n    bag_model = BaggingClassifier(base_estimator=model,n_estimators=100,bootstrap=True)\n    bag_model = bag_model.fit(X_train,y_train)\n    ytest_pred = bag_model.predict(X_test)\n    print(\"Bagging Accuarcy :\", bag_model.score(X_test,y_test))\n    print(\"Confusin Matrix :\\n \", confusion_matrix(y_test,ytest_pred))\n    print(\"***************************************************************************\\n\")\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Auto ML method: TPOT"},{"metadata":{},"cell_type":"markdown","source":"##### Loading the libraries:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from tpot import TPOTClassifier\nfrom tpot import TPOTRegressor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Calling the Tpot Classifier for Unscaled dataset..."},{"metadata":{"trusted":false},"cell_type":"code","source":"tpot = TPOTClassifier(generations=5,verbosity=2)\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\ntpot.fit(X_train.values,y_train.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Evaluate the Score of the TPOT Unscaled Dateset"},{"metadata":{"trusted":false},"cell_type":"code","source":"tpot.score(X_test.values,y_test.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Export the TPOT Unscaled PIPELINE Python file"},{"metadata":{"trusted":false},"cell_type":"code","source":"#tpot.export('tpot_Attrition_modeling_pipeline.py')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Calling the Tpot Classifier for Scaled dataset..."},{"metadata":{"trusted":false},"cell_type":"code","source":"tpot = TPOTClassifier(generations=5,verbosity=2)\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\ntpot.fit(X_train.values,y_train.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Evaluate the Score of the TPOT Unscaled Dateset"},{"metadata":{"trusted":false},"cell_type":"code","source":"tpot.score(X_test.values,y_test.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Export the TPOT Scaled PIPELINE Python file"},{"metadata":{"trusted":false},"cell_type":"code","source":"#tpot.export('tpot_Attrition_modeling_scaled_pipeline.py')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression..."},{"metadata":{},"cell_type":"markdown","source":"#### Using Unscaled Data"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Logistic Regression...\n\n# Using Unscaled Data set for Logistic Regression...\n\nclassifier = LogisticRegression()\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using Scaled Data"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Logistic Regression...\n\n# Using Scaled Data set for Logistic Regression...\n\nclassifier = LogisticRegression()\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid Search on Logistic Regression\n\n##### Unscaled Dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on Logistic Regression ...\n\n# Fit the parameters for logistic regression ...\n\nparam_grid = {'C':np.logspace(-3,3,8),'penalty':[\"l1\",\"l2\"],'max_iter':[100],'intercept_scaling':[1]}\nlog_param_grid = GridSearchCV(LogisticRegression(),param_grid=param_grid,cv=10,refit=True,verbose=1)\n\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\n#Applying Grid Search on Orginal Dataset ...\nlog_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=log_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Scaled Data"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on Logistic Regression ...\n\n# Fit the parameters for logistic regression ...\n\nparam_grid = {'C':np.logspace(-3,3,8),'penalty':[\"l1\",\"l2\"],'max_iter':[100],'intercept_scaling':[0.97,0.98,1]}\nlog_param_grid = GridSearchCV(LogisticRegression(),param_grid=param_grid,cv=7,refit=True,verbose=1)\n\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\n#Applying Grid Search on Orginal Dataset ...\nlog_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=log_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN"},{"metadata":{},"cell_type":"markdown","source":"##### Using Unscaled Dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# KNN ...\n# Using Unscaled Data set for KNN...\nclassifier = KNeighborsClassifier()\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using Scaled Dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Using Scaled Data set for KNN...\nclassifier = KNeighborsClassifier()\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Grid Search on KNN Scaled Dataset ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on KNN Scaled Dataset ...\n\n# Fit the parameters for KNN ...\nparam_grid = {'n_neighbors':[3,5,7,9],'weights':['uniform','distance'],'metric':['euclidean','manhattan','minkowski'],\n             'leaf_size':[40,45,50,60]}\nknn_param_grid = GridSearchCV(KNeighborsClassifier(),param_grid,cv=7,refit=True,n_jobs=-1,verbose=1)\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\n\n#Applying Grid Search on Orginal Dataset ...\nknn_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=knn_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Grid Search on KNN UnScaled Dataset ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on KNN unScaled Dataset ...\n\n# Fit the parameters for KNN ...\nparam_grid = {'n_neighbors':[3,5,7,9,11],'weights':['uniform','distance'],'metric':['euclidean','manhattan','minkowski'],\n             'leaf_size':[60,90,100,150,200,300]}\nknn_param_grid = GridSearchCV(KNeighborsClassifier(),param_grid,cv=7,refit=True,n_jobs=-1,verbose=1)\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\n\n#Applying Grid Search on Orginal Dataset ...\nknn_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=knn_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest "},{"metadata":{},"cell_type":"markdown","source":"##### Using Scaled Data set for Random Forest ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Random Forest \n\n#Create a Gaussian Classifier ...\n# Using scaled Data set for Random Forest ...\nclassifier = RandomForestClassifier()\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using Unscaled Data set for Random Forest .."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Create a Gaussian Classifier ...\n# Using Unscaled Data set for Random Forest ...\nclassifier = RandomForestClassifier()\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Grid Search on Random Forest Scaled Dataset ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on Random Forest Scaled Dataset ...\n\n# Fit the parameters for Random Forest ...\nparam_grid = {'max_depth':[3,4,5,6],'max_features':['sqrt', 'auto', 'log2'],'n_estimators':[50,100],\n             'min_samples_split':[2,3,5,6,7],'bootstrap':[True,False],'min_samples_leaf':[1,3,10]}\nclass_weight = dict({0: 0.5961070559610706, 1: 3.1012658227848102})\ncross_validation = StratifiedKFold(n_splits=10)\nRF_param_grid = GridSearchCV(RandomForestClassifier(class_weight=class_weight),param_grid,cv=cross_validation,refit=True,n_jobs=-1,verbose=1)\n\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\n\n#Applying Grid Search on Orginal Dataset ...\nRF_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=RF_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Grid Search on Random Forest Unscaled Dataset ..."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Grid Search on Random Forest UnScaled Dataset ...\n\n# Fit the parameters for Random Forest ...\nparam_grid = {'max_depth':[3,4,5,6],'max_features':['sqrt', 'auto', 'log2'],'n_estimators':[50,100],\n             'min_samples_split':[2,3,5,6,7],'bootstrap':[True,False],'min_samples_leaf':[1,3,10]}\ncross_validation = StratifiedKFold(n_splits=10)\nclass_weight = dict({0: 0.5961070559610706, 1: 3.1012658227848102})\nRF_param_grid = GridSearchCV(RandomForestClassifier(class_weight=class_weight),param_grid,cv=cross_validation,refit=True,n_jobs=-1,verbose=1)\n\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\n\n#Applying Grid Search on Orginal Dataset ...\nRF_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=RF_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine"},{"metadata":{},"cell_type":"markdown","source":"##### Using Unscaled Data set..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Support Vector Machine\n\n# Using Unscaled Data set.\nclassifier = SVC(kernel='linear')\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using Scaled Data set..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Using Scaled Data set ...\nclassifier = SVC(kernel='linear')\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Grid Search on SVM Scaled Dataset ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on SVM Scaled Dataset ...\n\n# Fit the parameters for SVM ...\nparam_grid = {'C':[0.45,0.5,0.51,0.53,0.55,1,1.5,5],'kernel': ['linear']}\ncross_validation = StratifiedKFold(n_splits=10)\nSVC_param_grid = GridSearchCV(SVC(),param_grid,cv=cross_validation,refit=True,n_jobs=-1,verbose=1)\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\n\n#Applying Grid Search on Orginal Dataset ...\nSVC_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=SVC_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Grid Search on SVM - RBF Scaled Dataset ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on SVM-RBF Scaled Dataset ...\n\n# Fit the parameters for SVM ...\nparam_grid = {'C':[0.5,1,1.5,5],'gamma':[1,0.1,0.01,0.001],'probability':[True,False],'kernel': ['rbf']}\ncross_validation = StratifiedKFold(n_splits=5)\nSVC_param_grid = GridSearchCV(SVC(),param_grid,cv=cross_validation,refit=True,n_jobs=-1,verbose=1)\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\n\n#Applying Grid Search on Orginal Dataset ...\nSVC_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=SVC_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Grid Search on SVM - Poly Scaled Dataset ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Grid Search on SVM Scaled Dataset ...\n\n# Fit the parameters for SVM ...\nparam_grid = {'C':[0.5,1,1.5,5],'gamma':[1,0.1,0.01,0.001],'probability':[True,False],'kernel': ['poly'],\n             'degree':[2,3]}\ncross_validation = StratifiedKFold(n_splits=5)\nSVC_param_grid = GridSearchCV(SVC(),param_grid,cv=cross_validation,refit=True,n_jobs=-1,verbose=1)\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\n\n#Applying Grid Search on Orginal Dataset ...\nSVC_param_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=SVC_param_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extreme Gradient boosting classifier"},{"metadata":{},"cell_type":"markdown","source":"##### Using Scaled Data"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Extreme Gradient boosting classifier using Scaled Data ...\n\nclassifier = XGBClassifier()\nX_train,X_test,y_train,y_test,cols,X,y=scaled_data(df)\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using Unscaled Data ..."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Extreme Gradient boosting classifier using UnScaled Data ...\n\nclassifier = XGBClassifier()\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Gridsearch for XGBoost"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# A parameter grid for XGBoost\nparams = {\n        'n_estimators' : [100, 200, 500, 750],\n        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25],\n        'min_child_weight': [1, 5, 7, 10],\n        'gamma': [0.1, 0.5, 1, 1.5, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5, 10, 12]\n        }\n\nfolds = 5\nparam_comb = 800\nfrom sklearn.model_selection import RandomizedSearchCV\n# Extreme Gradient boosting classifier using UnScaled Data ...\nclassifier = XGBClassifier()\nxgb_grid = RandomizedSearchCV(classifier, param_distributions=params,n_iter=param_comb, cv=5,n_jobs=-1, refit=True, verbose=1)\n\nX_train,X_test,y_train,y_test,cols,X,y=unscaled_data(df)\n#Applying Grid Search on Orginal Dataset ...\nxgb_grid.fit(X_train,y_train)\n# Find the best estimator from the model ...\nfinal_model=xgb_grid.best_estimator_\n# Predicting the Accuracy and AUC value from the function we defined above ...\nAttrition_prediction(final_model,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA "},{"metadata":{},"cell_type":"markdown","source":"##### Applying PCA on the Scaled Data"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Applying PCA function on training \n# and testing set of X component \n\nfrom sklearn.decomposition import PCA\nX_train,X_test,y_train,y_test,cols,X,y= scaled_data(df)\n\npca = PCA().fit(X)\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\nplt.title('Attrition Level')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Explained variance "},{"metadata":{"trusted":false},"cell_type":"code","source":"explained_variance = pca.explained_variance_ratio_ \nlen(explained_variance)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Execute this step if you need the \"PCA\" Scaled \"Train test split :X_train, X_test, y_train, y_test\" "},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# execute this step if you need the \"PCA\" Scaled \"Train test split :X_train, X_test, y_train, y_test\" \npca = PCA(0.95)\nX_unscale_pca = pca.fit_transform(X)\nX_train,X_test,y_train,y_test,cols,X,y= scaled_data(df)\nrandom_state = 0\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, random_state = random_state)\n# Defining Cols variables to store the Column names of X scaled dataframe.\n\n#Logistic Regression...\n\n# Using PCA scaled Data set for Logistic Regression...\n\nclassifier = LogisticRegression()\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)\nprint(\"************************************************************\")\nclassifier = SVC(kernel='linear')\nAttrition_prediction(classifier,X_train,X_test,y_train,y_test,cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imbalanced Data"},{"metadata":{},"cell_type":"markdown","source":"##### Libraries needed for Imbalance Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Load the Imbalance Librarires for the further processing ...\nfrom imblearn.over_sampling import SMOTE,RandomOverSampler\nfrom imblearn.under_sampling import ClusterCentroids,NearMiss,RandomUnderSampler\nfrom imblearn.combine import SMOTEENN,SMOTETomek\n#from imblearn.ensemble import BalanceCascade\n\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report \nfrom sklearn.metrics import recall_score,accuracy_score,confusion_matrix, f1_score, precision_score, auc,roc_auc_score,roc_curve, precision_recall_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Helper functions"},{"metadata":{},"cell_type":"markdown","source":"The below functions used to itrate different Imbalance Techique (Transform Functions) to Techinques (Benchmark).\n\nBenchmark:\n- Performing Logistic Regression with penalty \"L2\".\n- Doing Gridsearch on the above step.\n- Fit the Dataset.\n\nTransform:\n- Transformer - Different Imbalance Techinques.\n- Fit the Imbalanced libraries on the Dataset."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Helper functions\n\ndef benchmark(sampling_type,X,y):\n    #clf = LogisticRegression(penalty='l2')\n    clf = model\n    param_grid = {'C':[0.01,0.1,1,10]}\n    \"\"\"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)\"\"\"\n    grid_search_lr = GridSearchCV(estimator=clf,param_grid=param_grid,scoring='accuracy',cv=10,verbose=1,refit=True,n_jobs=-1)\n    grid_search_lr = grid_search_lr.fit(X.values,y.values.ravel())\n    \n    return sampling_type,grid_search_lr.best_score_,grid_search_lr.best_params_['C']\n\ndef transform(transformer,X,y):\n    print(\"Transforming {}\".format(transformer.__class__.__name__))\n    X_resampled,y_resampled =transformer.fit_sample(X.values,y.values.ravel())\n    return transformer.__class__.__name__,pd.DataFrame(X_resampled),pd.DataFrame(y_resampled)\n    \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#####  Apply transform functions to Unscaled dataset\n"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"\nX_train,X_test,y_train,y_test,cols,X,y= unscaled_data(df)\n\ndatasets = []\ndatasets.append((\"base\",X_train,y_train))\ndatasets.append(transform(SMOTE(n_jobs=-1),X_train,y_train))\ndatasets.append(transform(RandomOverSampler(),X_train,y_train))\ndatasets.append(transform(NearMiss(n_jobs=-1),X_train,y_train))\ndatasets.append(transform(RandomUnderSampler(),X_train,y_train))\ndatasets.append(transform(SMOTEENN(),X_train,y_train))\ndatasets.append(transform(SMOTETomek(),X_train,y_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Determine best hyperparameters using: Benchmark"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"benchmark_scores =[]\nfor sample_type,X,y in datasets:\n    print('__________________________________________________________________________')\n    print('{}'.format(sample_type))\n    benchmark_scores.append(benchmark(sample_type,X,y))\n    print('__________________________________________________________________________')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Check the output of Benchmarf Functions:"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"benchmark_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train/evaluate models for each of tranformed datasets"},{"metadata":{},"cell_type":"markdown","source":"The below function used to Test the data on models and find the Different Matrics scores for each Imbalance Techiques."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Train/evaluate models for each of tranformed datasets\n\nscores=[]\n# Train model based on benchmark params ...\n\nfor sample_type,score,parm in benchmark_scores:\n    print(\"Training on {}\".format(sample_type))\n    clf = LogisticRegression(penalty='l1',C=parm)\n    for s_type,X,y in datasets:\n        if s_type == sample_type:\n            clf.fit(X.values,y.values.ravel())\n            pred_test = clf.predict(X_test.values)\n            pred_test_probs = clf.predict_proba(X_test.values)\n            probs = clf.decision_function(X_test.values)\n            fpr, tpr , thresholds = roc_curve(y_test.values.ravel(),pred_test)\n            p,r,t = precision_recall_curve(y_test.values.ravel(),probs)\n            scores.append((sample_type,\n                          f1_score(y_test.values.ravel(),pred_test), \n                          precision_score(y_test.values.ravel(),pred_test),\n                           recall_score(y_test.values.ravel(),pred_test),\n                           accuracy_score(y_test.values.ravel(),pred_test),\n                           auc(fpr,tpr),\n                           auc(p,r,reorder=True),\n                           confusion_matrix(y_test.values.ravel(),pred_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tabulate results"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"#Tabulate results\nsampling_results_unscaled = pd.DataFrame(scores,columns=['Sampling Type','F1 Score','Precision','Recall','Accuracy','AUC_Score',\n                                               'AUC_PR','Confusion Matrix'])\nsampling_results_unscaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Apply transform functions to Scaled dataset"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"\nX_train,X_test,y_train,y_test,cols,X,y= scaled_data(df)\n\ndatasets = []\ndatasets.append((\"base\",X_train,y_train))\ndatasets.append(transform(SMOTE(n_jobs=-1),X_train,y_train))\ndatasets.append(transform(RandomOverSampler(),X_train,y_train))\ndatasets.append(transform(NearMiss(n_jobs=-1),X_train,y_train))\ndatasets.append(transform(RandomUnderSampler(),X_train,y_train))\ndatasets.append(transform(SMOTEENN(),X_train,y_train))\ndatasets.append(transform(SMOTETomek(),X_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Determine best hyperparameters using: Benchmark"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"benchmark_scores =[]\nfor sample_type,X,y in datasets:\n    print('__________________________________________________________________________')\n    print('{}'.format(sample_type))\n    benchmark_scores.append(benchmark(sample_type,X,y))\n    print('__________________________________________________________________________')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Train/evaluate models for each of tranformed Scaled datasets"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Train/evaluate models for each of tranformed datasets\n\nscores=[]\n# Train model based on benchmark params ...\n\nfor sample_type,score,parm in benchmark_scores:\n    print(\"Training on {}\".format(sample_type))\n    clf = LogisticRegression(penalty='l1',C=parm)\n    for s_type,X,y in datasets:\n        if s_type == sample_type:\n            clf.fit(X.values,y.values.ravel())\n            pred_test = clf.predict(X_test.values)\n            pred_test_probs = clf.predict_proba(X_test.values)\n            probs = clf.decision_function(X_test.values)\n            fpr, tpr , thresholds = roc_curve(y_test.values.ravel(),pred_test)\n            p,r,t = precision_recall_curve(y_test.values.ravel(),probs)\n            scores.append((sample_type,\n                          f1_score(y_test.values.ravel(),pred_test), \n                          precision_score(y_test.values.ravel(),pred_test),\n                           recall_score(y_test.values.ravel(),pred_test),\n                           accuracy_score(y_test.values.ravel(),pred_test),\n                           auc(fpr,tpr),\n                           auc(p,r,reorder=True),\n                           confusion_matrix(y_test.values.ravel(),pred_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Tabulate results"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"#Tabulate results\nsampling_results_scaled = pd.DataFrame(scores,columns=['Sampling Type','F1 Score','Precision','Recall','Accuracy','AUC_Score',\n                                               'AUC_PR','Confusion Matrix'])\nsampling_results_scaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion "},{"metadata":{},"cell_type":"markdown","source":"Algorthim which can be used for *Employee Attrition Modelling* can be:\n\n- Logistic Regression:\n    - Giving Test Accuracy of 89.756\n    - PCA Accuarcy : 89.56\n- SVC:\n    - Giving Test Accuarcy of 89.34\n- XGB:\n    - Giving Test Accuarcy of 87.30\n  "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}