{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom scipy import signal\nimport soundfile as sf\nimport keras\nfrom keras.models import Sequential\nfrom keras.datasets import mnist\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, Input\nfrom keras.initializers import Constant\nfrom keras.regularizers import l2\nfrom keras.applications import ResNet101\nfrom keras import backend as K\nfrom keras.layers import PReLU\nimport cv2\nimport librosa","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X_train_1 = np.load('../input/spec-dataset-3/stft_dataset.npy')\nY_train_1 = np.load('../input/spec-dataset-3/target.npy')\nX_train_2 = np.load('../input/spec-dataset-3-aug/stft_dataset.npy')\nY_train_2 = np.load('../input/spec-dataset-3-aug/target.npy')\nprint(X_train_1.shape)\nprint(X_train_2.shape)\nX_train = np.concatenate((X_train_1, X_train_2))\nY_train = np.concatenate((Y_train_1, Y_train_2))\nprint(X_train.shape)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(Y_train, return_counts = True)\nprint(unique)\nprint(counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_classes = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = keras.utils.to_categorical(Y_train, num_classes = no_classes)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(Y_train, return_counts = True, axis = 0)\nprint(unique)\nprint(counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n# input_shape = X_train.shape[-3:]\n# input_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(Conv2D(32, [7,11], strides = [2,2], input_shape = input_shape))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(MaxPooling2D())\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, [5,5], kernel_regularizer = l2(0.01)))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(Dropout(0.3))\n# model.add(MaxPooling2D())\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(128, [3,3], padding = 'SAME', kernel_regularizer = l2(0.01)))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(Dropout(0.5))\n# model.add(MaxPooling2D())\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(256, [3,3], padding = 'SAME', activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(Dropout(0.5))\n# model.add(MaxPooling2D())\n\n# model.add(Conv2D(128, [1,1], padding = 'SAME', activation = 'relu'))\n# model.add(Flatten())\n\n# model.add(Dense(64, activation = 'relu'))\n# model.add(Dropout(0.5))\n\n# model.add(Dense(16, activation = 'relu'))\n# model.add(Dense(no_classes, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(Dropout(0.25))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, kernel_size=(3, 3),  kernel_regularizer = l2(0.05), padding = 'same'))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(Dropout(0.25))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n# model.add(Dense(256, activation = 'relu',  kernel_regularizer = l2(0.05)))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(Dense(no_classes, activation='softmax'))\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(Conv2D(128, [7,11], strides = [2,2], padding = 'SAME', input_shape = input_shape))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(Dropout(0.5))\n# model.add(MaxPooling2D())\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(256, [5,5], kernel_regularizer = l2(0.01)))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(Dropout(0.5))\n# model.add(MaxPooling2D())\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(256, [1,1], padding = 'SAME', kernel_regularizer = l2(0.01)))\n# model.add(Conv2D(256, [3,3], padding = 'SAME'))\n# model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n# model.add(MaxPooling2D())\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(512, [3,3], padding = 'SAME', activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(MaxPooling2D())\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n\n# model.add(Dense(4096, activation = 'relu'))\n# model.add(Dropout(0.5))\n\n# model.add(Dense(512, activation = 'relu'))\n# model.add(Dense(4, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(Conv2D(64, [5,7], padding = 'SAME', activation = 'relu', input_shape = input_shape))\n# model.add(Dropout(0.5))\n# model.add(MaxPooling2D(pool_size = (2, 3)))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, [3,3], padding = 'SAME', activation = 'relu'))\n# model.add(Conv2D(64, [3,3], padding = 'SAME', activation = 'relu'))\n# model.add(Dropout(0.5))\n# model.add(MaxPooling2D(pool_size = (2, 3)))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(128, [3,3], padding = 'SAME', activation = 'relu'))\n# model.add(Conv2D(128, [3,3], padding = 'SAME', activation = 'relu'))\n# model.add(Dropout(0.5))\n\n# model.add(MaxPooling2D(pool_size = (2, 3)))\n# model.add(Conv2D(128, [3,3], padding = 'SAME', activation = 'relu'))\n# model.add(Conv2D(128, [3,3], padding = 'SAME', activation = 'relu'))\n# model.add(BatchNormalization())\n\n# model.add(Dropout(0.5))\n# model.add(Flatten())\n# model.add(Dense(100, activation = 'relu'))\n# model.add(Dropout(0.5))\n# model.add(BatchNormalization())\n# model.add(Dense(4, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n \n# model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape))\n# model.add(Dropout(0.3))\n# model.add(MaxPool2D(pool_size = (2, 2)))\n# model.add(BatchNormalization())\n \n# model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n# model.add(Dropout(0.3))\n# model.add(MaxPool2D(pool_size = (2, 2)))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n# model.add(Dropout(0.3))\n# model.add(MaxPool2D(pool_size = (2, 2)))\n# model.add(BatchNormalization())\n \n# model.add(Flatten())\n\n# model.add(Dense(64, activation = 'relu')) \n# model.add(Dense(32, activation = 'relu')) \n# model.add(Dropout(0.3)) \n \n# model.add(Dense(no_classes, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = ResNet101(include_top = False, input_shape = input_shape, weights = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n\n# input_tensor = Input(shape = input_shape)\n# vgg_model = VGG19(include_top = False, input_tensor = input_tensor)\n# for layer in vgg_model.layers:\n#     model.add(layer)\n\n# model.add(Dense(no_classes, activation = 'softmax'))\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(VGG19(include_top = False, pooling = 'max', input_shape = input_shape))\n# model.add(Flatten())\n# model.add(Dense(no_classes, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for layer in model.layers:\n#     layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n\n# model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape, kernel_regularizer = l2(0.01)))\n# model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(MaxPool2D(pool_size = (2, 2)))\n# model.add(Dropout(0.3))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(MaxPool2D(pool_size = (2, 2)))\n# model.add(Dropout(0.3))\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n\n# model.add(Dense(64, activation = 'relu')) \n# model.add(Dense(32, activation = 'relu')) \n# model.add(Dropout(0.3)) \n# model.add(Dense(no_classes, activation = 'softmax'))\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dim = (125, 40)\n# X_train_resized = []\n# for i in range(X_train.shape[0]):\n#     sample = cv2.resize(X_train[i], dim, interpolation = cv2.INTER_AREA)\n#     sample = cv2.merge([sample, sample, sample])\n#     X_train_resized.append(sample)\n\n# X_train_resized = np.array(X_train_resized)\n# X_train = np.copy(X_train_resized)\n# del X_train_resized\n# X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = librosa.util.normalize(X_train)\n\nminimum = np.min(X_train)\nmaximum = np.max(X_train)\nX_train = (X_train - minimum) / (maximum - minimum)\n\nprint(minimum, maximum)\n\n# from sklearn.preprocessing import MinMaxScaler\n# scaler = MinMaxScaler()\n# scaler.fit(X_train)\n# X_train = scaler.transform(X_train)\nprint(np.min(X_train), np.max(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\ninput_shape = X_train.shape[-3:]\ninput_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.05, random_state=42)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n\n# model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape, kernel_regularizer = l2(0.01)))\n# model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(MaxPool2D(pool_size = (2, 2)))\n# model.add(Dropout(0.3))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\n# model.add(MaxPool2D(pool_size = (2, 2)))\n# model.add(Dropout(0.3))\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n\n# model.add(Dense(64, activation = 'relu')) \n# model.add(Dense(32, activation = 'relu')) \n# model.add(Dropout(0.3)) \n# model.add(Dense(no_classes, activation = 'softmax'))\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = keras.applications.VGG19(weights='imagenet', include_top = False, input_shape = input_shape) \n# model.add(Dense(no_classes, activation = 'softmax'))\n# model.summary()\n# vgg_model = keras.applications.ResNet101(weights = 'imagenet', include_top = False, input_shape = input_shape, pooling = 'max')\n# for layer in vgg_model.layers:\n#     model.add(layer)\n\n# model = Sequential()\n# model.add(keras.applications.VGG19(weights = 'imagenet', include_top = False, input_shape = input_shape, pooling = 'max'))\n\n# for layer in model.layers:\n#     layer.trainable = False\n\n# model.add(Flatten())\n# # model.add(Dense(64, activation = 'relu'))\n# # model.add(Dense(16, activation = 'relu'))\n# model.add(Dense(no_classes, activation = 'softmax'))\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64, kernel_size=5, activation='relu', input_shape=input_shape))\n\nmodel.add(Conv2D(128, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling2D(2)) \n\nmodel.add(Conv2D(256, kernel_size=5, activation='relu'))\n\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))   \nmodel.add(Dense(4, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape, kernel_regularizer = l2(0.01)))\n# model.add(Dropout(0.5))\n# model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n# model.add(Flatten())\n# model.add(Dense(32, activation = 'relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(4, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(BatchNormalization())\n# model.add(Conv2D(32, kernel_size=(5,5), strides=(1, 1), activation='relu', input_shape=input_shape))\n# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# model.add(Conv2D(64, (3,3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Flatten())\n# model.add(Dense(1000, activation='relu'))\n# model.add(Dropout(0.4))\n# model.add(Dense(no_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = ResNet101(include_top = True, weights = 'imagenet')\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nno_epochs = 10\nvalidation_split = 0.05\nverbosity = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta = 0, patience = 10, verbose = 0, mode = 'auto',baseline = None, restore_best_weights = True)\nmodel.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adam(learning_rate = 0.1), metrics = ['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size = batch_size, epochs = no_epochs, verbose = verbosity, validation_split = validation_split)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Training accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation accuracy')\nplt.title('training / validation accuracies')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()\nplt.plot(history.history['loss'], label='Training loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.title('training / validation loss values')\nplt.ylabel('Loss value')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test)\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = np.argmax(pred, axis = 1)\ngt = np.argmax(y_test, axis = 1)\n\npercentage = np.sum((predict == gt).astype(int)) * 100 / pred.shape[0]\npercentage","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}