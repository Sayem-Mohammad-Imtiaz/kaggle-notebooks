{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"version":"3.6.3","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","name":"python","file_extension":".py","nbconvert_exporter":"python"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_uuid":"00f67072a7a7a292c03553b82c8b78a46c40b9e4","_kg_hide-output":false,"_cell_guid":"0b456f21-6b40-4bb1-8035-d65007139642","collapsed":true,"_kg_hide-input":false},"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n\ndf  = pd.read_csv(\"../input/news-week-aug24.csv\")\ndf.head(5)"},{"metadata":{"_uuid":"a90187e409e6ebc5681149e5537cdff2667bba31","_cell_guid":"e195b517-f5ab-4279-91c8-88cf45df8a12"},"cell_type":"markdown","source":"**Listing count of headlines corresponding to each feed code **"},{"metadata":{"_uuid":"81a1fc04eb6cefd11e0202f3005080b70580cf11","_kg_hide-output":true,"_cell_guid":"f7c5e5d3-2e55-42ba-b9aa-630353151c31","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"df['feed_code'].value_counts()"},{"metadata":{"_uuid":"a29816f086c8796fd29299ba2c0e6e871c0fefae","_cell_guid":"8a21039e-3223-443c-a5a6-d3938de33793"},"cell_type":"markdown","source":"**'w3-wn' comes out as a clear winner with ~50k articles. **\n**\nQuick scan of the type of articles published with this feed code reveals that https://wn.com/ is the biggest contributor to the sample news dataset**"},{"metadata":{"_uuid":"78bfd741d5df736ab5ae62332036eaccaae7f6e4","_kg_hide-output":true,"_cell_guid":"440b4674-f4a1-4a3a-9522-47085a2c4454","collapsed":true,"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code","source":"df[df.feed_code == 'w3-wn']"},{"metadata":{"_uuid":"432ef1419baa6a9f214c411ef51d750b18ef2603","_cell_guid":"e96a926d-21a2-4c36-9997-0783cd0cb87b","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"df.count()"},{"metadata":{"_uuid":"b0cd84690d15bd3203d1958d29f8c25711d5f7a1","_cell_guid":"29af73c3-669d-4114-8cb4-21c836a1ee7e"},"cell_type":"markdown","source":"**Dropping nulls and nans**"},{"metadata":{"_uuid":"9dd72801aaabc3ba461e4f3f857722bb7bfea56a","_cell_guid":"fc9bda3a-043e-447a-9751-4c51415938f3","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"df_no_null = df.dropna()\ndf_no_null.count()"},{"metadata":{"_uuid":"295f0fa9b3ebc77af4781be7e001cadac9c3c225","_cell_guid":"d11d9c0f-68c4-467f-86c8-3680285c29f1"},"cell_type":"markdown","source":"**Based on English and non-English stopwords, trying to assign the best fit language to each of the headlines**"},{"metadata":{"_uuid":"15e53e6ca7256fc9e383ad35402b0506cfecaf8f","_kg_hide-output":true,"_cell_guid":"7a7411fd-2bf7-44a6-ab73-f266e395e3d3","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"import nltk\n \nenglishStopWords = set(nltk.corpus.stopwords.words('english'))\nnonEnglishStopWords = set(nltk.corpus.stopwords.words()) - englishStopWords\n\nprint (\"English Stop words - \",englishStopWords)\nprint (\"Non-English Stop words - \",nonEnglishStopWords)\n "},{"metadata":{"_uuid":"496f352b2f8c4531750eb3eca537bca0fb3c715b","_kg_hide-output":true,"_cell_guid":"24d85968-ff62-45a1-9dfb-17c3a33b3429","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"stopWordsDictionary = {lang: set(nltk.corpus.stopwords.words(lang)) for lang in nltk.corpus.stopwords.fileids()}\n\nprint(stopWordsDictionary)"},{"metadata":{"_uuid":"f85ffe3ef11082051bbffb4b226d68803d8c3dc1","_kg_hide-output":true,"_cell_guid":"8dfd7e35-46cd-42a4-8850-1deafe2e9508","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"df_no_null.headline_text.dropna()"},{"metadata":{"_uuid":"cc92db5133700275ba1881a56545bf1639e729ff","_cell_guid":"5a2b565f-0dbd-4200-bf0b-5a5c19c5f497"},"cell_type":"markdown","source":"**Method to assign an appropriate language to the headline**"},{"metadata":{"_uuid":"50da6c6036d58e9517165cba8bf1d99ef7aff6b8","_cell_guid":"f5efe79e-cad2-4319-b3b3-9fa571e79c40","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"def get_language(text):\n    if type(text) is str:\n        text = text.lower()\n    words = set(nltk.wordpunct_tokenize(text))\n    return max(((lang, len(words & stopwords)) for lang, stopwords in stopWordsDictionary.items()), key = lambda x: x[1])[0]"},{"metadata":{"_uuid":"91f9c04f7e7822642849618fea2ac2fed70da882","_cell_guid":"3b43ca20-ca65-447d-b4a7-cbd1b0202210"},"cell_type":"markdown","source":"**Testing language for first headline based on the above stopwords**"},{"metadata":{"_uuid":"4e678cd9767b5b280d39f2729ee484c05b75e01f","_cell_guid":"aaa679fc-2022-41ce-b6f9-282e80abb141","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"language = get_language(df_no_null['headline_text'][0])\nprint (df_no_null['headline_text'][0])\nprint (language)"},{"metadata":{"_uuid":"c40d11c815016342e843807342914cade9f0b253","_cell_guid":"6b36be9a-27e7-468d-ba98-2df0130e11a2"},"cell_type":"markdown","source":"**Create a new data frame with headline text and corresponding language by using the above method**"},{"metadata":{"_uuid":"a5e8fe872125e27e42e579a5807d17d53b68a060","_kg_hide-output":true,"_cell_guid":"ead35aa3-f379-48af-a647-ff678fc47806","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"df_no_null[['headline_text', 'feed_code']][0:1661]"},{"metadata":{"_uuid":"1872299259ce8e481c312ee50d72b90ced334cd1","_kg_hide-output":true,"_cell_guid":"9d323391-a8bd-4d42-9fde-4caea00d5066","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"language = []\nfor row in df_no_null['headline_text']:\n    language.append(get_language(row))\nlanguage"},{"metadata":{"_uuid":"34c79f8bfabef58a6fbb951e0d7c0a41f470e685","_cell_guid":"997d8dd2-8397-4b4d-bccf-05bff86c2282"},"cell_type":"markdown","source":"**Finally add the language column to the original data frame**"},{"metadata":{"_uuid":"3400447d3c1cf3b8bbfe26393e156458b46149ee","_cell_guid":"e3a45924-cde6-4cfa-a0ad-dc5fb782d286","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"df_no_null['language'] = language\nCountHeadlinesPerLanguage = df_no_null['language'].value_counts()\nCountHeadlinesPerLanguage"},{"metadata":{"_uuid":"a6bf92d65b003d7de552d1ffa5bae6c3a12e22dd","_cell_guid":"31370bc8-7c25-488c-8978-cfdacedf2176"},"cell_type":"markdown","source":"**Let's plot the frequency distribution of count of headlines per language!**"},{"metadata":{"_uuid":"e99e90b3bae3082b825edf30d3e81d2b5aade57e","_cell_guid":"c2f820cf-fd2d-4d98-b8ad-80f70c731f70","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"CountHeadlinesPerLanguage.plot.barh()"}]}