{"cells":[{"metadata":{"_uuid":"0184d1f347ebe5775876379fd586b266f7592d1b"},"cell_type":"markdown","source":"# [Large Scale Learning Post](https://machinelearningmedium.com/2018/06/22/large-scale-learning/)\n\n- [Github Link](https://github.com/shams-sam/CourseraMachineLearningAndrewNg/blob/master/LargeScaleLearning.ipynb)\n- Implementation of Gradient Descent:\n    - Batch Gradient Descent\n    - Stochastic Gradient Descent\n    - Mini Batch Gradient Descent"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ac17dbab0ae68fb04fe5ddbe5d3d5e9ea6ee84bf"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ccbf3fb14e5dc92222096307e3653ea7bdd1c5e3"},"cell_type":"code","source":"def banner(msg, _verbose=1):\n    if not _verbose:\n        return\n    print(\"-\"*80)\n    print(msg.upper())\n    print(\"-\"*80)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbed4150f8339a8982acecf10d6c512add9de313"},"cell_type":"markdown","source":"# Data Import and Preprocessing"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1e60148472c2b9ef85dc3f6e14ce8b5af754142e"},"cell_type":"code","source":"df = pd.read_csv('../input/Housing.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def convert_to_binary(string):\n    return int('yes' in string)\n\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        df[col] = df[col].apply(convert_to_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"51cbab7a7912a0c6f40eeba537afb7433b547f57"},"cell_type":"code","source":"data = df.values\n\nscaler = StandardScaler()\ndata = scaler.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e78a97bea9345dc5efef9cd787ec03c8b0f50209","collapsed":true},"cell_type":"code","source":"X = data[:, 1:]\ny = data[:, 0]\n\nprint(\"X: \", X.shape)\nprint(\"y: \", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"84da3e67b5d85e1de9f7e710a2cfa14e86afac12"},"cell_type":"code","source":"def get_torch_variable(x):\n    return torch.from_numpy(x).double()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80a2a1cd0a34768716e3eb1f41ceea8d493fac5e","collapsed":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = map(get_torch_variable, train_test_split(X, y, test_size=0.2))\nprint(\"X_train: \", X_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"X_valid: \", X_valid.shape)\nprint(\"y_valid: \", y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e991022a96b32cc675c9a547f08a23f3db45d756"},"cell_type":"code","source":"class LinearRegression:\n    def __init__(self, X_train, y_train, X_valid, y_valid):\n        self.X_train = X_train\n        self.y_train = y_train\n        self.X_valid = X_valid\n        self.y_valid = y_valid\n        \n        self.Theta = torch.randn((X_train.shape[1]+1)).type(type(X_train)).double()\n        \n    def _add_bias(self, tensor):\n        bias = torch.ones((tensor.shape[0], 1)).double()\n        return torch.cat((bias, tensor), 1)\n        \n    def _forward(self, tensor):\n        return torch.matmul(\n            self._add_bias(tensor),\n            self.Theta\n        ).view(-1)\n    \n    def forward(self, train=True):\n        if train:\n            return self._forward(self.X_train)\n        else:\n            return self._forward(self.X_valid)\n    \n    def _cost(self, X, y):\n        y_hat = self._forward(X)\n        mse = torch.sum(torch.pow(y_hat - y, 2))/2/X.shape[0]\n        return mse\n    \n    def cost(self, train=True):\n        if train:\n            return self._cost(self.X_train, self.y_train)\n        else:\n            return self._cost(self.X_valid, self.y_valid)\n        \n    def batch_update_vectorized(self):\n        m, _ = self.X_train.size()\n        return torch.matmul(\n                self._add_bias(self.X_train).transpose(0, 1),\n                (self.forward() - self.y_train)\n            ) / m\n    \n    def batch_update_iterative(self):\n        m, _ = self.X_train.size()\n        update_theta = None\n        X = self._add_bias(self.X_train)\n        for i in range(m):\n            if type(update_theta) == torch.DoubleTensor:\n                update_theta += (self._forward(self.X_train[i].view(1, -1)) - self.y_train[i]) * X[i]\n            else:\n                update_theta = (self._forward(self.X_train[i].view(1, -1)) - self.y_train[i]) * X[i]\n        return update_theta/m\n        \n    \n    def batch_train(self, tolerance=0.01, alpha=0.01):\n        converged = False\n        prev_cost = self.cost()\n        init_cost = prev_cost\n        num_epochs = 0\n        while not converged:\n            self.Theta = self.Theta - alpha * self.batch_update_vectorized()\n            cost = self.cost()\n            if (prev_cost - cost) < tolerance:\n                converged = True\n            prev_cost = cost\n            num_epochs += 1\n        banner(\"Batch\")\n        print(\"\\tepochs: \", num_epochs)\n        print(\"\\tcost before optim: \", init_cost)\n        print(\"\\tcost after optim: \", cost)\n        print(\"\\ttolerance: \", tolerance)\n        print(\"\\talpha: \", alpha)\n            \n    def stochastic_train(self, tolerance=0.01, alpha=0.01):\n        converged = False\n        m, _ = self.X_train.size()\n        X = self._add_bias(self.X_train)\n        init_cost = self.cost()\n        num_epochs=0\n        while not converged:\n            prev_cost = self.cost()\n            for i in range(m):\n                self.Theta = self.Theta - alpha * (self._forward(self.X_train[i].view(1, -1)) - self.y_train[i]) * X[i]\n            cost = self.cost()\n            if prev_cost-cost < tolerance:\n                converged=True\n            num_epochs += 1\n        banner(\"Stochastic\")\n        print(\"\\tepochs: \", num_epochs)\n        print(\"\\tcost before optim: \", init_cost)\n        print(\"\\tcost after optim: \", cost)\n        print(\"\\ttolerance: \", tolerance)\n        print(\"\\talpha: \", alpha)\n        \n    def mini_batch_train(self, tolerance=0.01, alpha=0.01, batch_size=8):\n        converged = False\n        m, _ = self.X_train.size()\n        X = self._add_bias(self.X_train)\n        init_cost = self.cost()\n        num_epochs=0\n        while not converged:\n            prev_cost = self.cost()\n            for i in range(0, m, batch_size):\n                self.Theta = self.Theta - alpha / batch_size * torch.matmul(\n                    X[i:i+batch_size].transpose(0, 1),\n                    self._forward(self.X_train[i: i+batch_size]) - self.y_train[i: i+batch_size]\n                )\n            cost = self.cost()\n            if prev_cost-cost < tolerance:\n                converged=True\n            num_epochs += 1\n        banner(\"Stochastic\")\n        print(\"\\tepochs: \", num_epochs)\n        print(\"\\tcost before optim: \", init_cost)\n        print(\"\\tcost after optim: \", cost)\n        print(\"\\ttolerance: \", tolerance)\n        print(\"\\talpha: \", alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14903c3c27724f37f6ca24b309f2663644dddaf8","collapsed":true},"cell_type":"code","source":"%%time\nl = LinearRegression(X_train, y_train, X_valid, y_valid)\nl.mini_batch_train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ca8a3ee20b05c9ef4369f65497806f9f7001366","collapsed":true},"cell_type":"code","source":"%%time\nl = LinearRegression(X_train, y_train, X_valid, y_valid)\nl.stochastic_train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfb06eb94fde14b23fc5ab8256876fa77f047d8a","collapsed":true},"cell_type":"code","source":"%%time\nl = LinearRegression(X_train, y_train, X_valid, y_valid)\nl.batch_train()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}