{"cells":[{"metadata":{"_cell_guid":"f37a9596-11de-4330-6e6d-2fda24efdba3"},"cell_type":"markdown","source":"**This is based on the official [notebook](https://www.kaggle.com/robinkraft/getting-started-with-the-data-now-with-docs) from the competition `Planet: Understanding the Amazon from Space`, adjusted to the paths in this subset of the main dataset. **\n\n# *Planet: Understanding the Amazon from Space* challenge\n\nThis notebook will show you how to do some basic manipulation of the images and label files."},{"metadata":{"_cell_guid":"9018e828-1983-15e2-6566-b93fa759ca04","trusted":true},"cell_type":"code","source":"import sys\nimport os\nimport random\nimport subprocess\nfrom tqdm import tqdm\n\nfrom six import string_types\n\n# Make sure you have all of these packages installed, e.g. via pip\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport plotly.express as px\nimport scipy\nfrom skimage import io\nfrom scipy import ndimage\nfrom IPython.display import display\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a4f4f743-8c83-28b6-b759-1f85d91bd4f9","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!ls -lha ../input/planets-dataset/planet/planet","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"de648e34-cf96-3c7d-37ad-59bc2b8360f7"},"cell_type":"markdown","source":"## Setup\nSet `PLANET_KAGGLE_ROOT` to the proper directory where we've got the TIFF and JPEG zip files, and accompanying CSVs."},{"metadata":{"_cell_guid":"bace665c-f34b-09ff-7808-9efa412c65ca","trusted":true},"cell_type":"code","source":"PLANET_KAGGLE_ROOT = os.path.abspath(\"../input/planets-dataset/planet/planet\")\nPLANET_KAGGLE_JPEG_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\nPLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_classes.csv')\nassert os.path.exists(PLANET_KAGGLE_ROOT)\nassert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\nassert os.path.exists(PLANET_KAGGLE_LABEL_CSV)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3468c4df-3507-4650-e1ef-33348b7507ec"},"cell_type":"markdown","source":"## Inspect image labels\nThe labels are in a CSV entitled `train.csv`. Note that each image can be tagged with multiple tags. We'll convert them to a \"one hot\" style representation where each label is a column:"},{"metadata":{"_cell_guid":"6a90f711-8222-e7b0-9635-a00456ed64b0","trusted":true},"cell_type":"code","source":"labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f556c7f8-5e52-aab8-ca43-f5184a85836e","trusted":true},"cell_type":"code","source":"# Build list with unique labels\nlabel_list = []\nfor tag_str in labels_df.tags.values:\n    labels = tag_str.split(' ')\n    for label in labels:\n        if label not in label_list:\n            label_list.append(label)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e9f1be5a-b833-e0c3-bbf3-a95a72d02335","trusted":true},"cell_type":"code","source":"# Add onehot features for every label\nfor label in label_list:\n    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n# Display head\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"918adbb3-fd30-0d4d-6da2-12b49c6fa3bd","trusted":true},"cell_type":"code","source":"# Histogram of label instances\nlabels_df[label_list].sum().sort_values().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"345bfce6-c8d5-1c83-4e69-c2ba2ddf256c","trusted":true},"cell_type":"code","source":"def make_cooccurence_matrix(labels):\n    numeric_df = labels_df[labels]; \n    c_matrix = numeric_df.T.dot(numeric_df)\n    sns.heatmap(c_matrix, cmap =\"Blues\")\n    return c_matrix\n    \n# Compute the co-ocurrence matrix\nmake_cooccurence_matrix(label_list)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c130a544-2ae7-71c9-04f1-51c3e69ce842"},"cell_type":"markdown","source":"Each image should have exactly one weather label:"},{"metadata":{"_cell_guid":"4c40a10f-83cc-5ab3-7c95-f8e26a08068f","trusted":true},"cell_type":"code","source":"weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\nmake_cooccurence_matrix(weather_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f61ee506-ee56-9ba1-db45-1da151978e5c"},"cell_type":"markdown","source":"But the land labels may overlap:"},{"metadata":{"_cell_guid":"b503e3da-a478-ac7f-41e5-1893394f3a68","trusted":true},"cell_type":"code","source":"land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation']\nmake_cooccurence_matrix(land_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e06f07e-3c31-067b-78dc-323505ca5d6c"},"cell_type":"markdown","source":"The rarer labels have very little overlap:"},{"metadata":{"_cell_guid":"8703df07-3d6b-abfe-8614-28d4ff068e4a","trusted":true},"cell_type":"code","source":"rare_labels = [l for l in label_list if labels_df[label_list].sum()[l] < 2000]\nmake_cooccurence_matrix(rare_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Labels vs weather \n**Cloudy** label has no other labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"for w in weather_labels:\n    df_weather_subset = labels_df.loc[labels_df[w] == 1, label_list].drop([w], axis=1)\n    weather_percent_subset = df_weather_subset.sum(axis =0) / df_weather_subset.shape[0]\n    weather_percent_subset = weather_percent_subset[weather_percent_subset >0].sort_values(ascending=False)\n    fig = px.bar(x=weather_percent_subset.index, y=weather_percent_subset.values,  \n                 labels={'x':'label', 'y':f'Another labels given {w} label'})\n    fig.update_layout(title_text=f\"Main label: {w}\", yaxis_tickformat=',.0%')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cbd4cc2b-dc23-5d51-813d-58191d04e36a"},"cell_type":"markdown","source":"## Inspect images\nLet's display an image and visualize the pixel values. Here we will pick an image, load every single single band, then create RGB stack. These raw images are 16-bit (from 0 to 65535), and contain red, green, blue, and [Near infrared (NIR)](https://en.wikipedia.org/wiki/Infrared#Regions_within_the_infrared) channels. In this example, we are discarding the NIR band just to simplify the steps to visualize the image. However, you should probably keep it for ML classification.\n\nThe files can be easily read into numpy arrays with the skimage."},{"metadata":{"_cell_guid":"ee7b99e6-53d9-3443-67db-3ab30742d448","trusted":true},"cell_type":"code","source":"def sample_images(tags, n=None):\n    \"\"\"Randomly sample n images with the specified tags.\"\"\"\n    condition = True\n    if isinstance(tags, string_types):\n        raise ValueError(\"Pass a list of tags, not a single tag.\")\n    for tag in tags:\n        condition = condition & labels_df[tag] == 1\n    if n is not None:\n        return labels_df[condition].sample(n)\n    else:\n        return labels_df[condition]\n    \n\ndef plot_rgbn_histo(r, g, b):\n    for slice_, name, color in ((r,'r', 'red'),(g,'g', 'green'),(b,'b', 'blue')):\n        plt.hist(slice_.ravel(), bins=100, \n                 range=[0,rgb_image.max()], \n                 label=name, color=color, histtype='step')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d4165497-7319-fe38-b113-c572493c9c8c","trusted":true},"cell_type":"code","source":"def load_image(filename):\n    '''Look through the directory tree to find the image you specified\n    (e.g. train_10.tif vs. train_10.jpg)'''\n    for dirname in os.listdir(PLANET_KAGGLE_ROOT):\n        path = os.path.abspath(os.path.join(PLANET_KAGGLE_ROOT, dirname, filename))\n        if os.path.exists(path):\n            #print('Found image {}'.format(path))\n            return io.imread(path)\n    # if you reach this line, you didn't find the image you're looking for\n    print('Load failed: could not find image {}'.format(path))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7dfe886c-8f3c-5375-3c3c-e950170249a5"},"cell_type":"markdown","source":"Let's look at an individual image. First, we'll plot a histogram of pixel values in each channel. Note how the intensities are distributed in a relatively narrow region of the dynamic range"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_rgb_image(labels=['primary', 'water', 'road'], n_samples=1):\n    s = sample_images(labels, n=n_samples)\n    fnames = s.loc[:, \"image_name\"].apply(lambda fname: '{}.{}'.format(fname, \"jpg\"))\n    rgb_images = []\n    for name in fnames:\n    # find the image in the data directory and load it\n        bgr_image = load_image(name)\n        rgb_image = bgr_image[:, :, [2,1,0]]\n        rgb_images.append(rgb_image)\n    return np.array(rgb_images)\n\n\ndef get_r_g_b_channels(rgb_image):\n    b, g, r = rgb_image[:, :, 2], rgb_image[:, :, 1], rgb_image[:, :, 0]\n    return r, g, b","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e61ff246-835d-ab3d-e1a3-6693896ab18a","trusted":true},"cell_type":"code","source":"rgb_images= get_rgb_image(labels=['primary', 'water', 'road'], n_samples=5)\nrgb_image = rgb_images[0]\nr, g, b = get_r_g_b_channels(rgb_image)\n# plot a histogram of rgbn values\nplot_rgbn_histo(r, g, b)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8d7cd8aa-f9a9-5a53-9f62-78597f9c65d9"},"cell_type":"markdown","source":"We can look at each channel individually:"},{"metadata":{"_cell_guid":"576746f5-ce04-bb53-25e7-740d20c2cb3b","trusted":true},"cell_type":"code","source":"# Plot the bands\nfig = plt.figure()\nfig.set_size_inches(9, 3)\nfor i, (x, c) in enumerate(((r, 'r'), (g, 'g'), (b, 'b'))):\n    a = fig.add_subplot(1, 3, i+1)\n    a.set_title(c)\n    plt.imshow(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(rgb_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calibrate the image"},{"metadata":{},"cell_type":"markdown","source":"Find the mean for the colors across the entire dataset. It takes agess, **I'm unable to commit it due to the long performance.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_image_paths = os.listdir(PLANET_KAGGLE_JPEG_DIR)\nrandom.shuffle(all_image_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 200\n\nref_colors = [[],[],[]]\nfor _file in tqdm(all_image_paths[:n]):\n    # keep only the first 3 bands, RGB\n    _img = mpimg.imread(os.path.join(PLANET_KAGGLE_JPEG_DIR, _file))[:,:,:3]\n    # Flatten 2-D to 1-D\n    _data = _img.reshape((-1,3))\n    # Dump pixel values to aggregation buckets\n    for i in range(3): \n        ref_colors[i] = ref_colors[i] + _data[:,i].tolist()\n    \nref_colors = np.array(ref_colors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ref_colors = np.array(ref_colors)\nref_color_mean = [np.mean(ref_colors[i]) for i in range(3)]\nref_color_std = [np.std(ref_colors[i]) for i in range(3)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ref_color_mean:\")\nprint(ref_color_mean)\nprint(\"ref_color_std:\")\nprint(ref_color_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calibrate_image(rgb_img):\n    calibrated_img = rgb_image.copy().astype('float32')\n    for i in range(3):\n        calibrated_img[:,:,i] = (rgb_img[:,:,i] -  np.mean(rgb_img[:,:,i])) / np.std(rgb_img[:,:,i])\n        calibrated_img[:,:,i] = calibrated_img[:,:,i] * ref_color_std[i] + ref_color_mean[i]\n    return calibrated_img.astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = calibrate_image(rgb_image)\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sample images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_multiple_images(rgb_images):\n    col, row = (1, len(rgb_images)) if len(rgb_images) <=4 else ((len(rgb_images) / 4) + 1, 4)\n    fig = plt.figure()\n    fig.set_size_inches(12, 3 * col)\n    for i, _img in enumerate(rgb_images):\n        a = fig.add_subplot(col, row, i+1)\n        plt.imshow(calibrate_image(_img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['water']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['primary']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['agriculture']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['cultivation']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['habitation']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['selective_logging']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['slash_burn']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['blow_down']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['blooming']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['conventional_mine']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# provide labels to display sample images\nlabels = ['artisinal_mine']\nrgb_images= get_rgb_image(labels=labels, n_samples=4)\ndisplay_multiple_images(rgb_images)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"64ff4caf-cebb-857a-8292-4b6af9edfec2"},"cell_type":"markdown","source":"Original Notebook by Jesus Martinez Manso and Benjamin Goldenberg\n\n(C) Planet 2017"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":4}