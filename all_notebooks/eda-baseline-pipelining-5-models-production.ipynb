{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<span style=\"color:crimson;\">Kindly upvote if you like the pipeline ðŸ˜ƒ</span>** "},{"metadata":{},"cell_type":"markdown","source":"### **Lets Dive into finding the best model for production**\n\n*** Short description of different steps followed ***\n   \n\n    1. Understanding dataset.\n\n    2. Exploratory data analysis.\n      * Most importantly, plot a countplot of the target variable, this will reveal if the dataset is imbalanced.\n      *  Since this is classification problem, we need to check if there is imbalance in the dataset \n      *  if the dataset is imbalanced we need to perform either undersampling or oversampling \n    3. Creating Baseline model \n    4. Gridsearch and Pipeline\n      * we define series of 5 models and define a pipeline to run all these 5 models through gridsearch \n      * The model with highest accuracy is noted, Its hyper-parameters are noted \n\n    5. Define production model with the found best parameter\n    "},{"metadata":{},"cell_type":"markdown","source":"*** Summary of Interesting Finding from Exploratory data analysis**\n\n    *  The loan acceptance and rejection rate is balanced\n    *  The dataset is balanced dataset so we don't need undersampling or oversampling\n    *  Male applicants are obiously more than female applicants\n    *  More graudates are given loan than the non graudates\n    *  Male's median loan amount is more than Females\n    *  Males tend to ask more loan than females\n    *  Graduates tend to ask more loan than non graduates\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.base import TransformerMixin, BaseEstimator\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nimport seaborn as sns\n!pip install miceforest\nimport miceforest as mf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ndf_test = pd.read_csv('/kaggle/input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv')\nprint(\"Train has {} rows\" .format(len(df_train)))\nprint(\"Test has {} rows\" .format(len(df_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display\npd.options.display.max_columns = None\ndisplay(df_train.head(5))\ndisplay(df_test.head(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helper function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_unnecessary_columns(df, column_name):\n    \"\"\"\n    Function to delete the list of columns \n    Parameters\n    ----------\n    df : dataframe\n            pass in full dataframe\n    column_name : list\n            pass in list of full column\n    ----------\n    Returns: Dataframe\n    \"\"\"\n    \n    df = df.drop(column_name, axis=1)\n    return df\n\ndef print_unique_values(df):\n    \"\"\"\n    Function to print unique values in categorical datatypes \n    Parameters\n    ----------\n    df : dataframe\n            pass in full dataframe\n    ----------\n    Returns: None\n    \"\"\"\n    \n    print(\"unique values\\n\")\n    for col in df.columns:\n        if df[col].dtypes=='object':\n            if len(df[col].unique())>5:\n                print('{:>15s} \\t more than 5 unique'.format(col))\n            else:\n                print('{:>15s} \\t {}'.format(col,df[col].unique() ))\n\ndef split_categ_numer(df):\n    \"\"\"\n    Function to split dataframe into two, one having categorical columns and another having numerical columns\n    Parameters\n    ----------\n    df : dataframe\n            pass in full dataframe\n    ----------\n    Returns: \n        dataframe with categorical columns\n        dataframe with numerical columns\n    \"\"\"\n    categorical_col = []\n    numerical_col = []\n    for c in df.columns:\n        if df[c].dtype =='object':\n            categorical_col.append(c)\n        else:\n            numerical_col.append(c)\n    return df[categorical_col], df[numerical_col]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preliminary data analysis"},{"metadata":{},"cell_type":"markdown","source":"* we see from the below preliminary analysis that \n\n    * There are no duplicate row\n    * There are some nan's across columns in both train and test\n    * The dataset is balanced\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"number of duplicate records in train - {}\".format(df_train.duplicated().sum()))\nprint(\"number of duplicate records in test - {}\".format(df_test.duplicated().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We see below that the categorical variables are not more sparse, except for Loan_id which will be removed later**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_unique_values(df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The data set is balanced with almost 45% of \"N\" values compared to 55% of \"Y\" values"},{"metadata":{"trusted":true},"cell_type":"code","source":"approved = len(df_train[df_train['Loan_Status']=='Y'])\nrejected = len(df_train[df_train['Loan_Status']=='N'])\nprint(\"proportion of 'No' vs 'Yes' {:>3.2f}%\".format(rejected/approved*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* By experience, we can say that the loan_id is not an useful attribute for our classification problem\n* hence we remove the \"loan_id\" from both train and test "},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing the train set\ndf_train = drop_unnecessary_columns(df_train, ['Loan_ID'])\n# # preparing the test set\nx_test = drop_unnecessary_columns(df_test, ['Loan_ID'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_train.drop(['Loan_Status'], axis=1)\ny = df_train['Loan_Status']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The loan acceptance and rejection rate is balanced\n* The dataset is balanced dataset so we don't need undersampling or oversampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Loan_Status', data=df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Male applicants are obiously more than female applicants"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Loan_Status', data=df_train, hue='Gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* More graudates are given loan than the non graudates"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Loan_Status', data=df_train, hue='Education')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Male's median loan amount is more than Females"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Gender', y='LoanAmount', data=df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Males tend to ask more loan than females"},{"metadata":{"trusted":true},"cell_type":"code","source":"fg = sns.FacetGrid(df_train, col='Gender')\nfg.map(sns.barplot, 'Loan_Status', 'LoanAmount' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Graduates tend to ask more loan than non graduates"},{"metadata":{"trusted":true},"cell_type":"code","source":"fg = sns.FacetGrid(df_train, col='Education')\nfg.map(sns.barplot, 'Loan_Status', 'LoanAmount' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing"},{"metadata":{},"cell_type":"markdown","source":"> Defining pipelines"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_transformer = Pipeline(steps = [('simple_imputer',SimpleImputer(strategy='most_frequent')),\n                                            ('one_hot_encodr', OneHotEncoder(sparse=False))\n                                           ])\n\nnumerical_transformer = Pipeline(steps = [('iterative_imputer', IterativeImputer())])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating categorical train dataset and numerical train dataset\ncat_train_df, numeri_train_df = split_categ_numer(x)\n\n# extracting the categroical column names and numerical column names\ncat_train_features = cat_train_df.columns\nnum_train_features = numeri_train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_train_features),\n        ('cat', categorical_transformer, cat_train_features)\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test, y_train, y_test = train_test_split(x,y, train_size=70, random_state=42)\nfrom sklearn.preprocessing import LabelEncoder\nlb = LabelEncoder()\ny_train = pd.Series(lb.fit_transform(y_train))\ny_test = pd.Series(lb.transform(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline model"},{"metadata":{},"cell_type":"markdown","source":"* we take random forest as our baseline model,\n* The accuracy of the mode is 72.97%\n* our objective is to find a model that give better accuracy than this baseline model\n* hence we try other models with and without grid search"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = Pipeline(steps = [('preprocessor',preprocessor),\n                      ('classifier', RandomForestClassifier() )])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(x_train, y_train)\ny_pred = rf.predict(x_test)\nprint('Train set score : ', rf.score(x_train, y_train))\nprint('Test set score : ', accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling "},{"metadata":{},"cell_type":"markdown","source":"### without Grid_search"},{"metadata":{},"cell_type":"markdown","source":"* Here we find that the Gradient boosting is performing better with accuracy of 73.71%"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier()\n    ]\n\nscores= []\nfor classifier in classifiers:\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('classifier', classifier)])\n    pipe.fit(x_train, y_train)   \n    scores.append(pipe.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model = ['knn','decision tree', 'random forest', 'ada boost', 'gradient boost']\ndf_x = pd.DataFrame(list(zip(ml_model,scores)), columns=['models','scores'])\nprint(df_x)\nsns.barplot(x='models', y='scores', data=df_x.sort_values(by='scores'), )\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### With grid search"},{"metadata":{},"cell_type":"markdown","source":"* However using grid search we find that the random forest preforms much better with acc of 78.57% than the baseline model of acc 72.97%"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier()\n    ]\n\nknn_param_grid = {\n                'classifier__n_neighbors':[2,3,4,5]\n                }\n\ndt_param_grid = { \n    'classifier__max_features': ['sqrt', 'log2'],\n    'classifier__max_depth' : [4,5,6,7,8],\n        }\n\nrf_param_grid = { \n    'classifier__n_estimators': [200, 500],\n    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n    'classifier__max_depth' : [4,5,6,7,8],\n    'classifier__criterion' :['gini', 'entropy']\n    }\n\n\nada_param_grid = {\n         'classifier__n_estimators':[200, 500]#,\n        }\n\ngbc_param_grid = {\n              \"classifier__learning_rate\": [0.1,0.01,0.001]\n        }\n\ngrids = [knn_param_grid, dt_param_grid, rf_param_grid, ada_param_grid, gbc_param_grid]\nscores = []\nbest_params= []\nfor i, model in enumerate(classifiers):\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('classifier', model)])\n    CV = GridSearchCV(pipe, grids[i], n_jobs= 1)\n    CV.fit(x_train, y_train)    \n    best_params.append(CV.best_params_)\n    scores.append(CV.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model = ['knn','decision tree', 'random forest', 'ada boost', 'gradient boost']\ndf_x = pd.DataFrame(list(zip(ml_model,scores)), columns=['models','scores'])\nprint(df_x)\nsns.barplot(x='models', y='scores', data=df_x.sort_values(by='scores'))\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Production model"},{"metadata":{},"cell_type":"markdown","source":"* Since the acc of tuned Random forest model is better than any model, we will use it to estimate the loan_status of the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest_param = best_params[3]\nprint(random_forest_param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = Pipeline(steps = [('preprocessor',preprocessor),\n                      ('classifier', RandomForestClassifier(n_estimators= 200))])\nrf.fit(x, y)\ny_pred = rf.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_series = pd.Series(y_pred)\nd = pd.concat([df_test, pd.DataFrame(y_pred_series)], axis=1)\nd","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}