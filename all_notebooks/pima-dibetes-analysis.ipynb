{"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","metadata":{"_uuid":"7956a2ec2ef4384815cc6506f0fcf41e7a7245ca","_cell_guid":"2ab92871-2db6-4292-ab6d-cde25f8f6773"},"execution_count":null,"outputs":[]},{"source":"filename = '../input/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndf=pd.read_csv(\"../input/\"+filename,names=names)\nskew=df.skew()","cell_type":"code","metadata":{"_uuid":"bdfb80bf05dfdb185e6d41f55204317b699e30c2","_cell_guid":"b39d6332-a8e1-4bd4-a780-660c2a15d92c","collapsed":true},"execution_count":null,"outputs":[]},{"source":"print(skew)\n#for normally distributed data skewness should be close to zero. If skewness>0 then\n#it means that there is more weight on the left tail of the distribution and if skewness<0 then it means that\n# there is more weight on the right tail of the distribution","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"df.head()","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"df.head()","cell_type":"code","metadata":{"_uuid":"02cca1acfd3571c2d19d9adc75d5d347d3c27451","_cell_guid":"f52ee6cc-5865-44f3-b885-07981a7317ff"},"execution_count":null,"outputs":[]},{"source":"df.hist(figsize=(10,8))\nplt.show()","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"corr=df.corr()\nsns.heatmap(corr,vmax=0.8)","cell_type":"code","metadata":{"_uuid":"7e34c53a17f79cc873d397105f33cc31643c5b37","_cell_guid":"15d826e1-0f38-4772-8ada-c403c8763ade"},"execution_count":null,"outputs":[]},{"source":"#lets see the relationship between our independent variables and dependent variable(Class)\nsns.barplot(\"class\",\"preg\",data=df)","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"sns.barplot(\"class\",\"plas\",data=df)","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"sns.barplot(\"class\",\"pres\",data=df)","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"sns.barplot(\"class\",\"skin\",data=df)","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"sns.barplot(\"class\",\"test\",data=df)","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"sns.barplot(\"class\",\"mass\",data=df)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"sns.barplot(\"class\",\"pedi\",data=df)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"sns.barplot(\"class\",\"age\",data=df)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"\nX=df.iloc[:,0:8]\ny=df.iloc[:,8]\nX.head()\n\n","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Spliiting our dataset into training and test set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Applying Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Ppplying logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression(random_state=0)\nclassifier.fit(X_train,y_train)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Calculating Y_pred\ny_pred=classifier.predict(X_test)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Forming a confusion matrix to check our accuracy\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\nprint(cm)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"acc=(98+29)/(98+29+18+9)\nprint(acc)\n#We got an accuracy of 82.46%","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":1,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","name":"python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python"}}}