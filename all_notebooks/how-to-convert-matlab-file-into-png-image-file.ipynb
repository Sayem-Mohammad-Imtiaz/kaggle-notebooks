{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How To Convert MATLAB File Into PNG File?","metadata":{}},{"cell_type":"markdown","source":"### Image Segmentations are mosty developed by skilled people in `.mat` format in MATLAB. We cannot visualize or process those images as such. We may need to convert them suitably into a readable, yet uncompressed, format such as PNG or something else. ","metadata":{}},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"# to manage paths\nimport os\n# to process images\nimport cv2\n# to read MATLAB file\nfrom scipy import io\n# for array operations\nimport numpy as np\n# for final dataframe outputs\nimport pandas as pd\n# to display images\nimport matplotlib.pyplot as plt\n# to display image legends\nimport matplotlib as mpl\n# to visualize iterations\nfrom tqdm import tqdm\n# to process tensors\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:39:30.274402Z","iopub.execute_input":"2021-06-10T05:39:30.274851Z","iopub.status.idle":"2021-06-10T05:39:36.460342Z","shell.execute_reply.started":"2021-06-10T05:39:30.274755Z","shell.execute_reply":"2021-06-10T05:39:36.459238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MATLAB files","metadata":{}},{"cell_type":"markdown","source":"### We use open source image segmentation files and their corresponding original images (with a Special Thanks!).The open source collection is available at https://github.com/bearpaw/clothing-co-parsing\n","metadata":{}},{"cell_type":"markdown","source":"### Acknowledgement:\n> @inproceedings{yang2014clothing,\n  title={Clothing Co-Parsing by Joint Image Segmentation and Labeling},\n  author={Yang, Wei and Luo, Ping and Lin, Liang}\n  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},\n  year={2013},\n  organization={IEEE}\n}\n\n","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/bearpaw/clothing-co-parsing.git","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:39:49.463335Z","iopub.execute_input":"2021-06-10T05:39:49.463735Z","iopub.status.idle":"2021-06-10T05:39:54.514294Z","shell.execute_reply.started":"2021-06-10T05:39:49.463697Z","shell.execute_reply":"2021-06-10T05:39:54.513015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Have a Look at the downloaded contents","metadata":{}},{"cell_type":"code","source":"!ls -p clothing-co-parsing","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:39:59.003387Z","iopub.execute_input":"2021-06-10T05:39:59.003808Z","iopub.status.idle":"2021-06-10T05:39:59.74227Z","shell.execute_reply.started":"2021-06-10T05:39:59.003772Z","shell.execute_reply":"2021-06-10T05:39:59.741071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `photos/` directory and `annotations/` directory are the images and segmentations collections respectively. ","metadata":{}},{"cell_type":"markdown","source":"# Read Images, Segmentations and Labels","metadata":{}},{"cell_type":"markdown","source":"### There are 1000 images of people fashion and clothing - and corresponding 1000 segmentation mask images. The image files are in JPG format and masks are in MATLAB format. The files do not have consistency in size (variable height). However, image and mask pairs do have identical sizes. We read the files and write them into tensors for further processing.","metadata":{}},{"cell_type":"markdown","source":"### 1. Read Images","metadata":{}},{"cell_type":"code","source":"# a list to store image tensors\nimages = []\n# read 1000 images\nfor i in range(1,1001):\n    url = './clothing-co-parsing/photos/%04d.jpg'%(i)\n    # use OpenCV for lossless reading\n    img = cv2.imread(url, 1)\n    # convert BGR image into RGB image\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # convert into a tensor\n    img = tf.convert_to_tensor(img)\n    # resize the image by either cropping or padding with zeros\n    img = tf.image.resize_with_crop_or_pad(img,825,550)\n    # add to the list\n    images.append(img)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:40:08.329348Z","iopub.execute_input":"2021-06-10T05:40:08.329724Z","iopub.status.idle":"2021-06-10T05:40:18.158144Z","shell.execute_reply.started":"2021-06-10T05:40:08.329691Z","shell.execute_reply":"2021-06-10T05:40:18.15701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample an image and visualize it\nplt.figure(figsize=(4,7))\nexample_image = images[0]\nplt.imshow(example_image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:45:58.73925Z","iopub.execute_input":"2021-06-10T05:45:58.739659Z","iopub.status.idle":"2021-06-10T05:45:58.968436Z","shell.execute_reply.started":"2021-06-10T05:45:58.739626Z","shell.execute_reply":"2021-06-10T05:45:58.967248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Segmentations","metadata":{}},{"cell_type":"code","source":"# a list to collect mask tensors\nsegmentations = []\n# read 1000 files\nfor i in range(1,1001):\n    url = './clothing-co-parsing/annotations/pixel-level/%04d.mat'%(i)\n    # read MATLAB file as image\n    file = io.loadmat(url)\n    # convert into a tensor\n    mask = tf.convert_to_tensor(file['groundtruth'])\n    # resize expects 3D image, but we got 2D grayscale image \n    # so expand dimensions\n    mask = tf.expand_dims(mask,-1)\n    # resize by either cropping excess or padding with zeros\n    mask = tf.image.resize_with_crop_or_pad(mask,825,550)\n    # append the mask image to the list\n    segmentations.append(mask)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:44:59.328713Z","iopub.execute_input":"2021-06-10T05:44:59.329268Z","iopub.status.idle":"2021-06-10T05:45:02.35541Z","shell.execute_reply.started":"2021-06-10T05:44:59.329235Z","shell.execute_reply":"2021-06-10T05:45:02.354422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample a mask and visualize it\nexample_seg = segmentations[0]\nplt.figure(figsize=(5,7))\nplt.imshow(example_seg, cmap='jet')\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:45:39.643968Z","iopub.execute_input":"2021-06-10T05:45:39.644371Z","iopub.status.idle":"2021-06-10T05:45:40.168374Z","shell.execute_reply.started":"2021-06-10T05:45:39.644337Z","shell.execute_reply":"2021-06-10T05:45:40.167255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what are the unique pixel values?\nnp.unique(example_seg)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:46:19.238622Z","iopub.execute_input":"2021-06-10T05:46:19.239022Z","iopub.status.idle":"2021-06-10T05:46:19.254123Z","shell.execute_reply.started":"2021-06-10T05:46:19.238988Z","shell.execute_reply":"2021-06-10T05:46:19.252562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Read Labels","metadata":{}},{"cell_type":"code","source":"label_url = './clothing-co-parsing/label_list'\n# read the labels list MATLAB file\nlabel_file = io.loadmat(label_url)['label_list']\n# what is its shape?\nlabel_file.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:47:38.699398Z","iopub.execute_input":"2021-06-10T05:47:38.699832Z","iopub.status.idle":"2021-06-10T05:47:38.708537Z","shell.execute_reply.started":"2021-06-10T05:47:38.699797Z","shell.execute_reply":"2021-06-10T05:47:38.707491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove unnecessary dimension\nlabel_file = np.squeeze(label_file)\nlabel_file.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:48:05.79298Z","iopub.execute_input":"2021-06-10T05:48:05.79342Z","iopub.status.idle":"2021-06-10T05:48:05.799711Z","shell.execute_reply.started":"2021-06-10T05:48:05.793382Z","shell.execute_reply":"2021-06-10T05:48:05.798664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view the file\nlabel_file","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:48:17.824094Z","iopub.execute_input":"2021-06-10T05:48:17.824501Z","iopub.status.idle":"2021-06-10T05:48:17.831753Z","shell.execute_reply.started":"2021-06-10T05:48:17.824468Z","shell.execute_reply":"2021-06-10T05:48:17.830719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Each label is an array. Extract the label strings alone. ","metadata":{}},{"cell_type":"code","source":"labels = [label[0].astype(str) for label in label_file]\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:48:30.892924Z","iopub.execute_input":"2021-06-10T05:48:30.893366Z","iopub.status.idle":"2021-06-10T05:48:30.899962Z","shell.execute_reply.started":"2021-06-10T05:48:30.893318Z","shell.execute_reply":"2021-06-10T05:48:30.899238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample a mask and show the class labels as legends\nplt.figure(figsize=(7,7))\nexample_seg = segmentations[0]\n# obtain unique values (the class numbers)\nannotations = np.unique(example_seg.numpy().ravel())\n# read the names\nnames = [labels[a] for a in annotations]\n# the values range from 0 to 58, hence normalize for homogeneity\nNORM = mpl.colors.Normalize(vmin=0, vmax=58)\n# visulaize the image\nplt.imshow(example_seg, cmap='jet', norm=NORM)\nplt.axis('off')\n# prepare patches for legends\nPATCHES = [mpl.patches.Patch(color=mpl.cm.jet(NORM(a)), label=f'{a}: {names[i]}') for i,a in enumerate(annotations)]\nplt.legend(handles=PATCHES, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:56:33.98906Z","iopub.execute_input":"2021-06-10T05:56:33.989476Z","iopub.status.idle":"2021-06-10T05:56:34.171625Z","shell.execute_reply.started":"2021-06-10T05:56:33.989443Z","shell.execute_reply":"2021-06-10T05:56:34.1705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We have read necessary contents from the source file directory. We can delete the directory and its contents to save memory and get clean outputs finally.","metadata":{}},{"cell_type":"code","source":"!rm -r clothing-co-parsing","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:59:31.993329Z","iopub.execute_input":"2021-06-10T05:59:31.993936Z","iopub.status.idle":"2021-06-10T05:59:32.934374Z","shell.execute_reply.started":"2021-06-10T05:59:31.993878Z","shell.execute_reply":"2021-06-10T05:59:32.93285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display Images, Segmentations and Labels","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,16))\n# display 9 images and corresponding masks with legends\nfor i in range(1,9):\n    # display a mask with legends\n    plt.subplot(4,4,2*i-1)\n    example_seg = segmentations[i]\n    annotations = np.unique(example_seg.numpy().ravel())\n    names = [labels[a] for a in annotations]\n    NORM = mpl.colors.Normalize(vmin=0, vmax=58)\n    plt.imshow(example_seg, cmap='jet', norm=NORM)\n    plt.axis('off')\n    PATCHES = [mpl.patches.Patch(color=mpl.cm.jet(NORM(a)), label=names[i]) for i,a in enumerate(annotations)]\n    plt.legend(handles=PATCHES, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    \n    # display an image\n    plt.subplot(4,4,2*i)\n    example_image = images[i]\n    plt.imshow(example_image)\n    plt.axis('off')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:02:07.959161Z","iopub.execute_input":"2021-06-10T06:02:07.959635Z","iopub.status.idle":"2021-06-10T06:02:09.998251Z","shell.execute_reply.started":"2021-06-10T06:02:07.959595Z","shell.execute_reply":"2021-06-10T06:02:09.997035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Images and Segmentations into PNG File","metadata":{}},{"cell_type":"markdown","source":"### PNG images are the uncompressed formats, hence lossless. Obtaining a lossless transition is crucial becuase the segmentation masks are made with integers that refer to the object classes. In the earlier versions of this notebook, conversion was made into JPEG formats. Though JPEG yields compressed and compact outputs, the segmentation classes are compromised. For instance, the conversion creates new classes in the masks, despite there are no such classes in the original masks. Learning Segmentations may become complicated and misleading with such lossy transitions. Hence latest versions of this notebook prefer conversions into PNG formats.","metadata":{}},{"cell_type":"markdown","source":"### 1. Convert Images","metadata":{}},{"cell_type":"code","source":"for i in tqdm(range(1000)):\n    img = images[i]\n    # encode into PNG\n    img = tf.io.encode_png(img)\n    # create a path\n    path = os.path.join('IMAGES','img_%04d.png'%(i+1))\n    file_name = tf.constant(path)\n    # write the PNG file\n    tf.io.write_file(file_name, img)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:13:24.015003Z","iopub.execute_input":"2021-06-10T06:13:24.015516Z","iopub.status.idle":"2021-06-10T06:16:27.505521Z","shell.execute_reply.started":"2021-06-10T06:13:24.015472Z","shell.execute_reply":"2021-06-10T06:16:27.5035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for proper encoding","metadata":{}},{"cell_type":"code","source":"# a list to store image paths\nPNG_IMAGES = []\nfor root, dirs, files in os.walk('.'):\n    for file in files:\n        if 'img_' in file:\n            # get image paths\n            path = os.path.join(root, file)\n            PNG_IMAGES.append(path)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:16:27.507451Z","iopub.execute_input":"2021-06-10T06:16:27.507811Z","iopub.status.idle":"2021-06-10T06:16:27.516994Z","shell.execute_reply.started":"2021-06-10T06:16:27.507773Z","shell.execute_reply":"2021-06-10T06:16:27.51581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filenames are unsorted while writing so sort them now\nPNG_IMAGES.sort()\nprint(PNG_IMAGES[:10])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:16:27.519273Z","iopub.execute_input":"2021-06-10T06:16:27.519846Z","iopub.status.idle":"2021-06-10T06:16:27.561723Z","shell.execute_reply.started":"2021-06-10T06:16:27.519787Z","shell.execute_reply":"2021-06-10T06:16:27.55966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample an image\nim = tf.io.read_file(PNG_IMAGES[102])\n# decode it into a tensor\ndec = tf.io.decode_png(im, channels=3, dtype=tf.dtypes.uint8)\n# visualize it\nplt.figure(figsize=(4,7))\nplt.imshow(dec)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:19:47.309409Z","iopub.execute_input":"2021-06-10T06:19:47.310013Z","iopub.status.idle":"2021-06-10T06:19:47.545899Z","shell.execute_reply.started":"2021-06-10T06:19:47.309958Z","shell.execute_reply":"2021-06-10T06:19:47.544917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Convert Segmentations","metadata":{}},{"cell_type":"code","source":"# encode 1000 masks into PNG files\nfor i in tqdm(range(1000)):\n    seg = segmentations[i]\n    # encode the tensor into PNG\n    seg = tf.io.encode_png(seg)\n    # create a path to write\n    path = os.path.join('MASKS','seg_%04d.png'%(i+1))\n    file_name = tf.constant(path)\n    # write the PNG file\n    tf.io.write_file(file_name, seg)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:16:27.788129Z","iopub.execute_input":"2021-06-10T06:16:27.788609Z","iopub.status.idle":"2021-06-10T06:16:35.782758Z","shell.execute_reply.started":"2021-06-10T06:16:27.788558Z","shell.execute_reply":"2021-06-10T06:16:35.781494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a list to store the mask paths\nPNG_MASKS = []\nfor root, dirs, files in os.walk('.'):\n    for file in files:\n        if 'seg_' in file:\n            # obtain the path\n            path = os.path.join(root, file)\n            PNG_MASKS.append(path)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:16:35.784413Z","iopub.execute_input":"2021-06-10T06:16:35.784754Z","iopub.status.idle":"2021-06-10T06:16:35.794262Z","shell.execute_reply.started":"2021-06-10T06:16:35.78472Z","shell.execute_reply":"2021-06-10T06:16:35.792748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths are unsorted while writing\nPNG_MASKS.sort()\n# view some paths\nprint(PNG_MASKS[:10])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:19:10.073061Z","iopub.execute_input":"2021-06-10T06:19:10.073473Z","iopub.status.idle":"2021-06-10T06:19:10.079219Z","shell.execute_reply.started":"2021-06-10T06:19:10.073437Z","shell.execute_reply":"2021-06-10T06:19:10.078063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for proper encoding","metadata":{}},{"cell_type":"code","source":"# read a sample mask\nim = tf.io.read_file(PNG_MASKS[102])\n# decode into a tensor\ndec = tf.io.decode_png(im, channels=0, dtype = tf.dtypes.uint8)\n# visualize the mask\nplt.figure(figsize=(5,7))\nplt.imshow(dec, cmap='jet', norm=NORM)\nplt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:20:02.044271Z","iopub.execute_input":"2021-06-10T06:20:02.044989Z","iopub.status.idle":"2021-06-10T06:20:02.308064Z","shell.execute_reply.started":"2021-06-10T06:20:02.044934Z","shell.execute_reply":"2021-06-10T06:20:02.307272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Write Files to Output","metadata":{}},{"cell_type":"markdown","source":"### Zip Images and Segmentations (helpful for download!)","metadata":{}},{"cell_type":"code","source":"!zip -r -q png_images.zip IMAGES/\n!zip -r -q png_masks.zip MASKS/","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:21:18.499651Z","iopub.execute_input":"2021-06-10T06:21:18.500377Z","iopub.status.idle":"2021-06-10T06:21:40.209555Z","shell.execute_reply.started":"2021-06-10T06:21:18.500318Z","shell.execute_reply":"2021-06-10T06:21:40.208103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Keep a Few Images and Segmentations and Remove the rest (for clean output, otherwise, the output pane will be overcrowded!)","metadata":{}},{"cell_type":"code","source":"for i in range(6,1000):\n    # define the paths\n    image_path = './IMAGES/img_%04d.png'%(i)\n    mask_path = './MASKS/seg_%04d.png'%(i)\n    # delete the image\n    if os.path.exists(image_path):\n        os.remove(image_path)\n    \n    # delete the mask\n    if os.path.exists(mask_path):\n        os.remove(mask_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T06:23:26.758437Z","iopub.execute_input":"2021-06-10T06:23:26.759177Z","iopub.status.idle":"2021-06-10T06:23:26.772314Z","shell.execute_reply.started":"2021-06-10T06:23:26.759092Z","shell.execute_reply":"2021-06-10T06:23:26.77114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Write the class labels names into a CSV file","metadata":{}},{"cell_type":"code","source":"labels = np.array(labels)\nlabels = pd.Series(labels, name='label_list')\nlabels.to_csv('labels.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T12:42:20.349384Z","iopub.execute_input":"2021-06-09T12:42:20.350012Z","iopub.status.idle":"2021-06-09T12:42:20.364849Z","shell.execute_reply.started":"2021-06-09T12:42:20.34996Z","shell.execute_reply":"2021-06-09T12:42:20.363573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The downloaded PNG files (and the JPEG files from earlier versions of this notebook) and the labels list CSV file are available as a Kaggle Dataset at [https://www.kaggle.com/rajkumarl/people-clothing-segmentation](https://www.kaggle.com/rajkumarl/people-clothing-segmentation). \n\n### A Notebook on this dataset is available at [https://www.kaggle.com/rajkumarl/get-started-with-semantic-segmentation](https://www.kaggle.com/rajkumarl/get-started-with-semantic-segmentation)","metadata":{}},{"cell_type":"markdown","source":"### Thank You For Your Time!","metadata":{}}]}