{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Background\nLet's say we have to develop an AI model that can predict flight delays during the\nflight duration based on data about previous delay/turbulence encountered.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport emoji\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import preprocessing\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\nimport warnings\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\nwarnings.filterwarnings(action='ignore', category=FutureWarning)\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/feb-2020-us-flight-delay/feb-20-us-flight-delay.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Format\nData Source : [US Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236)\n\nAfter carefully analyzing each data points, I decided to manually pick 9 variable to predict if there will be a delay in the flight.\n- __MONTH__ - Month\n- __DAY_OF_MONTH__ - Day of Month\n- __DAY_OF_WEEK__ - Day of Week\n- __OP_UNIQUE_CARRIER__ - Unique Carrier Code\n- __ORIGIN__ - Origin airport location\n- __DEST__ - Destination airport location\n- __DEP_TIME__ - Actual Departure Time (local time: hhmm)\n- __DEP_DEL15__ - Departure Delay Indicator, 15 Minutes or More (1=Yes, 0=No) [TARGET VARIABLE]\n- __DISTANCE__ - Distance between airports (miles)","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We might have an extra column in our dataset, let's get rid of it first","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Unnamed: 9'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find out the distribution of our target variable","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data['DEP_DEL15'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we have highly imbalanced data, as we there are only __14.43%__ rows with the value of 1.0 (Delay in flight).\n\nWe will drop a significant amount of rows where our target variable is 0.0 (No delay in flight).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into positive and negative\npositive_rows = data.DEP_DEL15 == 1.0\ndata_pos = data.loc[positive_rows]\ndata_neg = data.loc[~positive_rows]\n\n# Merge the balanced data\ndata = pd.concat([data_pos, data_neg.sample(n = len(data_pos))], axis = 0)\n\n# Shuffle the order of data\ndata = data.sample(n = len(data)).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's quickly remove the NULL values if present any","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are around __~0.5%__ NULL values present in __DEP_TIME__ and __DEP_DEL15__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that our target variable __DEP_DEL15__ has the datatype of _float64_.\n\nLet's convert it into _int_.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['DEP_DEL15'] = data['DEP_DEL15'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's have a look at the number of columns and rows in our dataset.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(f\"There are {data.shape[0]} rows and {data.shape[1]} columns in our dataset.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\nLet's uncover some meaningful and hidden insights out of our dataset.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apart from the statistics given in the table above, we can also that there are 6 numerical and 3 categorical variables in our dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's quickly visualize the distribution of __DISTANCE__ variable","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.distplot(data['DISTANCE'], hist=False, color=\"b\", kde_kws={\"shade\": True})\nplt.xlabel(\"Distance\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of distance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our __DISTANCE__ variable is positively skewed.\nI am just curious to find out the correlation between the distance and delay of a flight.","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(emoji.emojize(\"Let's find it out :fire:\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Though, there is no possible way to find correlation between a continuous and categorical variable, I'll try to find the average distance for __DEP_DEL15__ variable.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(f\"Average distance if there is a delay {data[data['DEP_DEL15'] == 1]['DISTANCE'].values.mean()} miles\")\nprint(f\"Average distance if there is no delay {data[data['DEP_DEL15'] == 0]['DISTANCE'].values.mean()} miles\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the categorical variables.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Count of carriers in the dataset","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.countplot(x=data['OP_UNIQUE_CARRIER'], data=data)\nplt.xlabel(\"Carriers\")\nplt.ylabel(\"Count\")\nplt.title(\"Count of unique carrier\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Count of origin and destination airport","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,70))\nsns.countplot(y=data['ORIGIN'], data=data, orient=\"h\")\nplt.xlabel(\"Airport\")\nplt.ylabel(\"Count\")\nplt.title(\"Count of Unique Origin Airports\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,70))\nsns.countplot(y=data['DEST'], data=data, orient=\"h\")\nplt.xlabel(\"Airport\")\nplt.ylabel(\"Count\")\nplt.title(\"Count of Unique Destination Airports\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Our __MONTH__ variable is constant so it will not have any effect on in the training.\nIt's better to remove it. Also, let's rename the __DEP_DEL15__ column name to __TARGET__ to avoid confusion between predictors and target variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.rename(columns={'DEP_DEL15':'TARGET'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Encoding the categorical variable__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_encoding(categories):\n    \"\"\"\n    To perform mapping of categorical features\n    \"\"\"\n    categories = list(set(list(categories.values)))\n    mapping = {}\n    for idx in range(len(categories)):\n        mapping[categories[idx]] = idx\n    return mapping","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data['OP_UNIQUE_CARRIER'] = data['OP_UNIQUE_CARRIER'].map(label_encoding(data['OP_UNIQUE_CARRIER']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ORIGIN'] = data['ORIGIN'].map(label_encoding(data['ORIGIN']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['DEST'] = data['DEST'].map(label_encoding(data['DEST']))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['TARGET'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[['DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST', 'DEP_TIME', 'DISTANCE']].values\ny = data[['TARGET']].values","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Splitting Train-set and Test-set\nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=41)\n\n# Splitting Train-set and Validation-set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=41)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Choosing the evaluation metric\nHere we will go with the __Accuracy__ metric for our predicted values because we have already balanced our dataset.\nSo, accuracy is the best metric to evaluate any binary classification problem if it is performed on a balanced dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formula to get accuracy\ndef get_accuracy(y_true, y_preds):\n    # Getting score of confusion matrix\n    true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_true, y_preds).ravel()\n    # Calculating accuracy\n    accuracy = (true_positive + true_negative)/(true_negative + false_positive + false_negative + true_positive)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating some baseline models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Logistic Regression__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=0).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__CatboostClassifier__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize CatBoostClassifier\ncatboost = CatBoostClassifier(random_state=0)\ncatboost.fit(X_train, y_train, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Naive Bayes__","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"gnb = GaussianNB()\ngnb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Random Forest Classifier__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state=0)\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__KNN Classifier__","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__XGBoost Classifier__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation of accuracy on validation dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [lr, catboost, gnb, rf, knn, xgb]\nacc = []\nfor model in models:\n    preds_val = model.predict(X_val)\n    accuracy = get_accuracy(y_val, preds_val)\n    acc.append(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = ['Logistic Regression', 'Catboost', 'Naive Bayes', 'Random Forest', 'KNN', 'XGBoost']\naccuracy = dict(zip(model_name, acc))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nax = sns.barplot(x = list(accuracy.keys()), y = list(accuracy.values()))\nfor p, value in zip(ax.patches, list(accuracy.values())):\n    _x = p.get_x() + p.get_width() / 2\n    _y = p.get_y() + p.get_height() + 0.008\n    ax.text(_x, _y, round(value, 3), ha=\"center\") \nplt.xlabel(\"Models\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model vs. Accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We tried to fit our data on default parameters of different algorithms for binary classification.\n\nSurprisingly, __KNN Classifier__ turned out to best in terms of validation set accuracy.\n\nNow we'll try to find the best possible parameters for K-Nearest Neighbors Algorithm.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Accuracy on Test set with KNN before hyperparameter tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = knn.predict(X_test)\nget_accuracy(y_test, test_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter tuning for KNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leaf_size = list(range(1,5))\nn_neighbors = list(range(1,3))\np=[1,2]\n\nhyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n\nknn_2 = KNeighborsClassifier()\n\nclf = GridSearchCV(knn_2, hyperparameters, cv=2)\n\nbest_model = clf.fit(X_train,y_train)\n\nprint('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\nprint('Best p:', best_model.best_estimator_.get_params()['p'])\nprint('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_best = KNeighborsClassifier(leaf_size=3, p=1, n_neighbors=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_best.fit(X_train, y_train)\ntest_preds_1 = knn_best.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy on Test set with KNN after hyperparameter tuning","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"get_accuracy(y_test, test_preds_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### We see an increment of __~ 6.1%__ in the accuracy of our model after tuning the hyperparamter.\n\n#### Accuracy can be improved further if time and resources are given.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Also, this is my first kernel on Kaggle. Feel free to correct me if I am wrong anywhere :)**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}