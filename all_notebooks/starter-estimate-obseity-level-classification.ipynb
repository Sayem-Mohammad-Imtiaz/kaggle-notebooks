{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Obesity Dataset"},{"metadata":{},"cell_type":"markdown","source":"This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform."},{"metadata":{},"cell_type":"markdown","source":"Attributes consisting of \n\n* What is your gender? (Gender) = Female, Male\n* what is your age? (Age) = Numeric value\n* What is your height? (Height) = Numeric value in meters\n* What is your weight? (Weight) = Numeric value in Kilograms\n* Has a family member suffered or suffers from overweight? = Yes, No\n* Do you eat high caloric food frequenlty? (FAVC) = Yes, No\n* Do you usually eat vegatables in your meals? (FCVC) = 1-3 follow by usually meal\n* How many main means do you have daily? (NCP) = Between 1 y 2, 3, more than 4\n* Do you eat any food between mean? (CAEC) = No, Sometimes, Frequently, Always\n* Do you smoke? (Smoke) = Yes, No\n* How much water do you drink daily? (CH20) = less than a liter, between 1 and 2L, more than 2 L\n* Do you monitor the calories you eat daily? (SCC) = Yes, No\n* How often do you have physical activity? (FAF) = I do not have, 1 or 2 days, 2 or 4 days, 4 or 5 day\n* How much time do you use technological devices? (TUE) = 0-2 hours, 3-5 hours, more than 5 hours\n* How often do you drink alcohol? (CALC) =I don't drink, Sometimes, Frequently, Always\n* Which transportation do you usually use? (MTRANS) = Automobile, Motorbike, Bike Public Transportation, Walking \n\n* Associated task: regression, classification, clustering\n      "},{"metadata":{},"cell_type":"markdown","source":"## 1. Importing Library"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Default\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly \nimport plotly.graph_objects as go\nimport seaborn as sns\n\n# Data prepocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# Tuning parameter\nfrom sklearn.model_selection import GridSearchCV\n\n# Model\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom keras.optimizers import SGD\nfrom keras.optimizers import Adam\nfrom sklearn.neural_network import MLPClassifier\n\n# result\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\n\n\n#retina\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Importing dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/obesity-levels/ObesityDataSet_raw_and_data_sinthetic.csv\")\n# rename the lebel columns from 'NObeyesdad' to 'result'\ndf = df.rename(columns={'NObeyesdad': 'result'})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Dataset consisting of ',df.shape[0],' observations')\nprint('Dataset consisting of ',df.shape[1],' columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Data includes of both numerical data and catagorical data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* None of missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. EDA"},{"metadata":{},"cell_type":"markdown","source":"Overall of result"},{"metadata":{"trusted":true},"cell_type":"code","source":"name = df['result'].value_counts().index\nnum = df['result'].value_counts().values\n\nfig = px.pie(data_frame=df,names=name,values=num\n             ,title='Pies chard show the over all result',width=800,height=600)\nfig.update_traces(textposition='inside',textinfo='label+percent')\nfig.show()\n\nplt.figure(figsize=(12,7))\nsns.countplot(x='result',data=df,order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Results of each weight',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The label of this dataset contain of 7 weight type which are Insufficient weight, Normal weight, Overweight level I, Overweight level II, Obesity type II, and Obesity type II. Each type of Obesty quite normal distribution and closely same value (12%-16%) and it slightly imbalance"},{"metadata":{},"cell_type":"markdown","source":"Results and Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='Gender',order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.ylabel('Count',fontsize=12)\nplt.xlabel(None)\nplt.title('The result of weight Vs Gender',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* When classified the obisity levels by gender found that some of levels are super-imbalance (Obisity type II and Obisity type III)"},{"metadata":{},"cell_type":"markdown","source":"Results and Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='Age',data=df,order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.title('Result Vs Age',fontsize=15)\nplt.ylabel('Age (Year old)',fontsize=12)\nplt.xlabel(None)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Insufficient weight  are in the young age (19-21)\n* The obesity level increasing follow by age except Obesity type III"},{"metadata":{},"cell_type":"markdown","source":"Result and weight"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13,8))\nsns.barplot(x='result',y='Weight',data=df,\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Weight (kg)',fontsize=12)\nplt.title('Result Vs Weight',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Make sense"},{"metadata":{},"cell_type":"markdown","source":"Has family member suffer or suffers from overweight?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='family_history_with_overweight',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs overweight family',fontsize=15)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Obesity in family effected to sample"},{"metadata":{},"cell_type":"markdown","source":"Do you eat high caloric food frequenlty? "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='FAVC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Eat high caloric food',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Make Sense"},{"metadata":{},"cell_type":"markdown","source":"Do you usually eat vagatables in your meals? "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='FCVC',data=df,\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Amount of event',fontsize=12)\nplt.title('Result Vs Vegatable in meals',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many main meals do you have daily?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='NCP',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Amount of meals',fontsize=12)\nplt.title('Result Vs Main means do you have daily',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do you eat any food between meals?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='CAEC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Any food between meals',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do you smoke? "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='SMOKE',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Smoking',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How much water do you drink daily?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='CH2O',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Water (L)',fontsize=12)\nplt.title('Result Vs drink water (L)',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do you monitor the calories you eat daily?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='SCC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Monitor the calories',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How often do you have physical activity?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='FAF',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.ylabel('Amount of days',fontsize=12)\nplt.xlabel(None)\nplt.title('Result Vs Weekly working out \\n 0-5 day',fontsize=15)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How much time do you have physical activity?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.barplot(x='result',y='TUE',data=df,hue_order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Hours',fontsize=12)\nplt.title('Result Vs Hour',fontsize=15)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How often do you drink alcohol?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='CALC',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs How often drink alcohol',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Which transportation do you usually use?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='result',data=df,hue='MTRANS',\n            order=['Insufficient_Weight','Normal_Weight','Overweight_Level_I',\n'Overweight_Level_II','Obesity_Type_I','Obesity_Type_II','Obesity_Type_III'])\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=12)\nplt.title('Result Vs Transportation',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Heatmap(Correlation)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(),annot=True,square=True,center=0,vmin=-1,vmax=1,\n            cmap='BrBG',linewidths=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"   The dataset contaning of both numerical data and categorical data then I splited data to feature as attribute and answer as label and encoder the object types column"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.copy()\n\nfeature = data.drop('result',axis=1)\nanswer = data['result'].values.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nfor column_name in feature.columns:\n  if feature[column_name].dtype == object:\n    feature[column_name] = le.fit_transform(feature[column_name])\n  else:\n    pass\n\nanswer = le.fit_transform(answer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Modeling and tuning hyperparameter"},{"metadata":{},"cell_type":"markdown","source":"This experiment perform on various model:\n    * DecisionTree\n    * RandomForest\n    * Neural network using Multilayer perceptron\n    * Neural network using Keras\nand using GridSearch for tuning hyper parameter\n "},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nparam_grid = {'criterion':['gini', 'entropy'],\n              'splitter':['best','random'],\n              'max_depth':list(range(1,50)),\n              }\n\ngrid = GridSearchCV(DecisionTreeClassifier(random_state=42),param_grid,cv=5)\ngrid.fit(xtrain,ytrain)\nprint(grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(criterion='entropy',max_depth=9,splitter='best')\nclf.fit(xtrain,ytrain)\ny_pred = clf.predict(xtest)\ny_prob = clf.predict_proba(xtest)\n\nmapping = dict(zip(le.classes_, range(0, len(le.classes_)+1)))\n\ncm = confusion_matrix(ytest,y_pred)\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy Decision Tree (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nparam_grid = {'n_estimators':list(range(8,30)),\n              'criterion':['gini','entropy'],\n              'max_depth':list(range(1,50))\n              }\n\ngrid = GridSearchCV(RandomForestClassifier(random_state=42),param_grid,cv=5)\ngrid.fit(xtrain,ytrain)\nprint(grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(criterion='entropy',max_depth=10,n_estimators=29)\nclf.fit(xtrain,ytrain)\ny_pred = clf.predict(xtest)\ny_prob = clf.predict_proba(xtest)\n\nmapping = dict(zip(le.classes_, range(0, len(le.classes_)+1)))\nprint(mapping)\n\n\ncm = confusion_matrix(ytest,y_pred)\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy of Random Forest (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Neural network: Multilayer perceptron**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nscaler = StandardScaler()\nxtrain = scaler.fit_transform(xtrain)\nxtest = scaler.fit_transform(xtest)\n\nparam_grid = {'hidden_layer_sizes': [(16,),(32,),(48,)],\n    'activation': ['logistic', 'relu',  'tanh'],\n    'solver': ['sgd', 'adam'],\n    'learning_rate': ['constant','adaptive'],\n    'learning_rate_init':[0.001,0.1,0.2]\n}\n\ngrid = GridSearchCV(MLPClassifier(random_state=42),param_grid=param_grid,cv=5)\ngrid.fit(xtrain,ytrain)\nprint(grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MLPClassifier(random_state=42, activation='tanh',hidden_layer_sizes=(16,),learning_rate='constant',learning_rate_init=0.2,solver='sgd')\nclf.fit(xtrain,ytrain)\ny_pred = clf.predict(xtest)\ny_prob = clf.predict_proba(xtest)\n\nmapping = dict(zip(le.classes_, range(0, len(le.classes_)+1)))\n\n\ncm = confusion_matrix(ytest,y_pred)\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy of Neural network (MLP) (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Neural network: Keras**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(feature,answer,test_size=0.3,random_state=42)\n\nscaler = StandardScaler()\nxtrain = scaler.fit_transform(xtrain)\nxtest = scaler.fit_transform(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef create_model(optimizer='adam',init_mode='uniform',activation='relu',learn_rate=0.01):\n    model = Sequential()\n    model.add(Dense(32, input_dim=16,kernel_initializer=init_mode, activation=activation))\n    model.add(Dense(7,kernel_initializer=init_mode, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n\nmodel = KerasClassifier(build_fn=create_model,epochs=200,batch_size=10, verbose=0)\n\noptimizer = ['SGD', 'Adam']\nlearn_rate = [0.001, 0.01, 0.1, 0.2]\ninit_mode = ['uniform', 'normal', 'zero']\nactivation = ['relu', 'tanh', 'sigmoid']\n\nparam_grid = dict(optimizer=optimizer,learn_rate=learn_rate,init_mode=init_mode,activation=activation)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(xtrain, ytrain)\n\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nytrain = to_categorical(ytrain)\n\n\ndef create_model(learn_rate=0.1):\n    model = Sequential()\n    model.add(Dense(32, input_dim=16,kernel_initializer='uniform', activation='tanh'))\n    model.add(Dense(7, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n# create model\nmodel = KerasClassifier(build_fn=create_model, verbose=0,epochs=200,batch_size=10)\n# define the grid search parameters\nmodel.fit(xtrain,ytrain)\n\ny_pred = model.predict(xtest)\ny_prob = model.predict_proba(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(ytest,y_pred)\n# Transform to df for easier plotting\ncm_df = pd.DataFrame(cm,index=mapping)\n\nplt.figure(figsize=(8,6))                  \nsns.heatmap(cm_df, annot=True)\nplt.title('The accuracy of Neural Network (Keras) (Best param): {0:.3f}'.format(accuracy_score(ytest,y_pred)),fontsize=13)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label',)\nplt.show()\n\nprint('Accuracy score: ', accuracy_score(ytest,y_pred))\nprint('Precision score: ',precision_score(ytest,y_pred,average='macro'))\nprint('Recall: ', recall_score(ytest,y_pred,average='macro'))\nprint('F1 score: ',f1_score(ytest,y_pred,average='macro'))\nprint('ROC-AUC score',roc_auc_score(ytest, y_prob, multi_class=\"ovo\",\n                                  average=\"macro\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy = [0.9495268138801262,0.9290220820189274,0.9495268138801262,0.9542586750788643]\nPrecision = [0.9496370646467616,0.9289982846109511,0.9479671732410866,0.9527158255497573]\nRecall =[0.949554506796094,0.9282477859822877,0.9490035908012435,0.9539127392113407]\nF1Score = [0.9484366746957662,0.9282682517367851,0.9482428382213861,0.9529216047587254]\nRoc = [0.974036944270467,0.994470045662756,0.9975705078538368,0.9976146480444302]\n\nresult = pd.DataFrame(index=['DecisionTree','RandomForest','MLP','Keras'])\nresult['Accuracy'] = Accuracy\nresult['Precision'] = Precision\nresult['Recall'] = Recall\nresult['F1-Score'] = F1Score\nresult['ROC-AUC score'] = Roc\n\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As i said, I am still a beginner in this field so if you guys please suggest the wrong part or what to do, That would be a great help to me. Appreciate that, Thank you."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}