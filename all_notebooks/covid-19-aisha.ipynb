{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Comments\n- Hi Aisha,\nGreat job on your project. Your submission was simple and straightforward.\nI have left comments within the code blocks; the comments look like this\n```\n## Mercy's comments:\n# You are converting \"ObservationDate\" to a datetime field and reassigning it to a different column.\n# You should either create a totally new column or reassign it back to the \"ObservationDate\" column.\n```\n\n### Additionally, if you notice how the covid data is being structured, you'll see that more records are being added on a daily basis. So one way to work with only the most recent data is by doing this:\n\n```\nrecent_data = df[df['ObservationDate'] == df['ObservationDate'].max()]\n```\n\ni.e creating a new data frame that holds the most recent data (the `.max()` selects the most recent data which also happens to be the maximum date.\n\nDoing this helps you compare the current status of the cases across different countries and regions."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npd.set_option('display.max_rows', 50000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(df['Country/Region'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"cases grouped according to date\"\"\"\n## Mercy's comments:\n# You are converting \"ObservationDate\" to a datetime field and reassigning it to a different column.\n# You should either create a totally new column or reassign it back to the \"ObservationDate\" column.\n\ndf[\"Province/State\"] = pd.to_datetime(df[\"ObservationDate\"])\nregion_wise= df.groupby(['ObservationDate']).agg({\"Confirmed\":'sum',\"Recovered\":'sum',\"Deaths\":'sum'})\nprint(region_wise)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail(80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Mercy's comments:\n# If you check the sums recorded for Nigeria, you'll see that with the way you are aggregating the values, \n# we have a lot more cases down below than we actually have. \n# The reason behind this is that you are summing all the daily recorded cases together. \n# A better alternative would be to use the .max() function. \n# When I use the .max() function here, I'm getting the maximum values for these 3 columns because \n# the values are incremented daily, so the maximum holds the most recent values for every country. \n\n\"\"\"cases grouped according to Country/region\"\"\"\ngrouping = df.groupby(['Country/Region']).agg({\"Confirmed\":'max',\"Recovered\":'max',\"Deaths\":'max'}).reset_index()\nprint(grouping)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all =len(df[\"Country/Region\"].unique())\nprint('The total number of countries with disease spread is ' + str(all))\n\n## Mercy's comments:\n# Your numbers here are incorrect because of how the data is currently structured in the dataset, \n# which is daily counts of the number of cases for each country. \n# To get the real sums, you'll need to get the actual counts of confirmed, \n# recovered and deaths in each of the countries and then sum that up.\n# i.e from the `grouping` variable you created \nall_1 = sum(df[\"Confirmed\"])\nprint(\"\\nThe Current total number of confirmed cases around the world is  \",str(all_1))\n\n\nall_2 = sum(df[\"Recovered\"])\nprint(\"\\nThe total number of recorverd cases around the world is \",str(all_2))\n\nall_3 = sum(df[\"Deaths\"])\nprint(\"\\nThe total number of death cases around the word is \", str(all_3))\n\nmaximum_number =max(df['Confirmed'])\nprint('\\nThe maximum_number currently gotten in a coutry is',str(maximum_number) )\n\n## Mercy's comments: Here is how I would have gotten the actual sums\n\nall_grouping_1 = sum(grouping[\"Confirmed\"])\nprint(\"\\n___________________________ Accurate Results __________________________\")\nprint(\"\\nThe Current total number of actual confirmed cases around the world is  \",str(all_grouping_1))\n\n\nall_grouping_2 = sum(grouping[\"Recovered\"])\nprint(\"\\nThe total number of actual recorverd cases around the world is \",str(all_grouping_2))\n\nall_grouping_3 = sum(grouping[\"Deaths\"])\nprint(\"\\nThe total number of actual death cases around the word is \", str(all_grouping_3))\n\nmaximum_number_grouping =max(grouping['Confirmed'])\n\nprint('\\nThe actual maximum_number currently gotten in a coutry is',str(maximum_number_grouping) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouping[\"Confirmed\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (80, 20 ), dpi = 50)\nsns.barplot(x=grouping[\"Country/Region\"], y=grouping[\"Confirmed\"])\nplt.xlabel('COUNTRY/REGION', size=60)\nplt.ylabel('CONFIRMED CASES', size=60)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (80, 20 ), dpi = 50)\nsns.barplot(x=df[\"ObservationDate\"], y=df[\"Confirmed\"])\nplt.xlabel('OBSERVATION DATES', size=60)\nplt.ylabel('CONFIRMED CASES', size=60)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (80, 20 ), dpi = 50)\nsns.barplot(x=df[\"ObservationDate\"], y=df[\"Deaths\"])\nplt.xlabel('OBSERVATION DATES', size=60)\nplt.ylabel('DEATH CASES', size=60)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}