{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing Required Libraries **"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom matplotlib import pyplot\nimport seaborn as sn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nimport sklearn\nfrom sklearn import preprocessing\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing Data Set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/health-insurance-cross-sell-prediction/'\ntrain_df = pd.read_csv(path + \"train.csv\")\ntest_df = pd.read_csv(path + \"test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Shape of Training & Test Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Shape of Train Data Set :\",train_df.shape)\nprint(\"The Shape of Test Data Set :\", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Columns of Test & Train Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Columns of Train Data Set: \\n\",train_df.columns)\nprint(\"-------------------------\")\nprint(\"-------------------------\")\nprint(\"Columns of Test Data Set: \\n\",test_df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(x=\"Gender\", data = train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(x=\"Driving_License\", data = train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(x=\"Previously_Insured\", data = train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(x=\"Vehicle_Age\", data = train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(x=\"Vehicle_Damage\", data = train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(x=\"Response\", data = train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.distplot(train_df.Age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.distplot(train_df.Annual_Premium)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Numerical_Features = ['Age', 'Driving_License', 'Vehicle_Age','Annual_Premium','Vintage']\ntrain_df[Numerical_Features].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize =(10, 7)) \nplt.boxplot(train_df.Age) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize =(8, 7)) \nplt.boxplot(train_df.Annual_Premium) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize =(8, 7)) \nplt.boxplot(train_df.Vintage) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[Numerical_Features].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection For Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"X= train_df[['Gender', 'Age', 'Driving_License', 'Region_Code','Previously_Insured', 'Vehicle_Age','Vehicle_Damage', 'Annual_Premium','Policy_Sales_Channel', 'Vintage']]\ny= train_df['Response']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is some categorical features that need to be encoded\nX_features = list(X.columns)\nencoded_Data_df= pd.get_dummies(X[X_features],drop_first=True)\nX=encoded_Data_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"radm_clf = RandomForestClassifier( max_depth=15,n_estimators=20,max_features = 'auto')\n## Fitting the model with the training set\nradm_clf.fit(X,y )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_rank = pd.DataFrame( { 'feature': X.columns,'importance': radm_clf.feature_importances_ } )\n## Sorting the features based on their importances with mosti important feature at top.\nfeature_rank = feature_rank.sort_values('importance', ascending =False)\nplt.figure(figsize=(8, 6))\nsn.barplot( y = 'feature', x = 'importance', data = feature_rank )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Driving_License is not a significant feature and hence will drop from model building "},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(\"Response\", data=train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Since Data Set is impbalanced, I will use SMOTE to balance the representation of Response Feature in the data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX, y = oversample.fit_resample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of X after over-Sampling:\", X.shape)\nprint(\"Shape of y after over-Sampling:\", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping feature \"Driving_License\"\nX= X.drop(['Driving_License'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Initializing the StandardScaler\nX_scaler = StandardScaler()\n## Standardize all the feature columns\nX_scaled = X_scaler.fit_transform(X)\nX=X_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the dataset into the traing set and test set\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=43)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boosting Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"gboost_clf = GradientBoostingClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gboost_clf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_ROC(fpr, tpr, m_name):\n    roc_auc = sklearn.metrics.auc(fpr, tpr)\n    plt.figure(figsize=(10,8))\n    lw = 2\n    plt.plot(fpr, tpr, color='blue',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)    \n    plt.plot([0, 1], [0, 1], color='red', lw=lw, linestyle='--', alpha=0.5)    \n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.grid(True)\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.title('Receiver operating characteristic for %s'%m_name, fontsize=20)\n    plt.legend(loc=\"lower right\", fontsize=16)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gboost_preds = gboost_clf.predict_proba(X_test)\nGboost_class = gboost_clf.predict(X_test)\nGboost_score = roc_auc_score(y_test, Gboost_preds[:,1], average = 'weighted')\n(fpr, tpr, thresholds) = roc_curve(y_test, Gboost_preds[:,1])\nplot_ROC(fpr, tpr, 'Gboost')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# preparing & submitting the final result"},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is some categorical features that need to be encoded\nFeatures = list(test_df.columns)\nencoded_Data_df= pd.get_dummies(test_df[Features],drop_first=True)\ntest_df=encoded_Data_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test = test_df.drop([\"id\",\"Driving_License\"],axis=1)\nTest.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = gboost_clf.predict(Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame(index=test_df.index)\nsubmit[\"id\"] = test_df.id\nsubmit[\"Response\"] = pred\nsubmit.set_index('id').reset_index(inplace=True)\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv(\"Submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}