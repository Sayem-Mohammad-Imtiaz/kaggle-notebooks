{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Sentiment analysis of product reviews, an application\nproblem, has recently become very popular in text mining\nand computational linguistics research.\nThis notebook is all about the data analysis on customer reviews text analysis ,based on the reviews they post on several amazon products\nSo here I have performed sentiment analysis,with the help of NLP  and re modules \nI also extracted the most frequent words which appear in negative as well as positive reviews given by the customers with the help of wordcloud \nAlso determined which set of customers amazon should target in order to increase profit** ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sqlite3\nimport nltk\nimport string\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"The column or features in the dataset:\nId\nProductId — unique identifier for the product\nUserId — unqiue identifier for the user\nProfileName\nHelpfulnessNumerator — number of users who found the review helpful\nHelpfulnessDenominator — number of users who indicated whether they found the review helpful or not\nScore — rating between 1 and 5\nTime — timestamp for the review\nSummary — brief summary of the review\nText — text of the review","metadata":{}},{"cell_type":"code","source":"# Create a SQL connection to our SQLite database\n# con = sqlite3.connect('C://Users//MUSKAN//Downloads//Project 5--__ Amazon Customers Data Analysis-20210331T135011Z-001//Project 5--_ Amazon Customers Data Analysis//database.sqlite')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# type(con)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### reading data from Sqlite database","metadata":{}},{"cell_type":"code","source":"# pd.read_sql_query(\"SELECT * FROM Reviews\", con)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df=pd.read_sql_query(\"SELECT * FROM Reviews\", con)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CSV file reading","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"../input/amazon-reviews/Reviews.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### reading some n number of rows, use LIMIT over ther","metadata":{}},{"cell_type":"code","source":"# pd.read_sql_query(\"SELECT * FROM Reviews LIMIT 3\", con)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### What is sentiment analysis?\n    Sentiment analysis is the computational task of automatically determining what feelings a writer is expressing in text\n    Some examples of applications for sentiment analysis include:\n\n\n    Sentiment analysis is not perfect.It also cannot tell you why a writer is feeling a certain way. However, it can be useful to quickly summarize some qualities of text, especially if you have so much text that a human reader cannot analyze it.For this project,the goal is to to classify Food reviews based on customers' text.","metadata":{}},{"cell_type":"code","source":"!pip install textblob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from textblob import TextBlob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TextBlob(df['Summary'][0]).sentiment.polarity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npolarity=[] # list which will contain the polarity of the comments\n\nfor i in df['Summary']:\n    try:\n        polarity.append(TextBlob(i).sentiment.polarity)   \n    except:\n        polarity.append(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(polarity)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['polarity']=polarity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['polarity'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets perform EDA for the Positve sentences¶","metadata":{}},{"cell_type":"code","source":"data_positive = data[data['polarity']>0]\ndata_positive.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords=set(STOPWORDS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive=data_positive[0:200000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntotal_text= (' '.join(data_positive['Summary']))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(total_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_text[0:10000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ntotal_text=re.sub('[^a-zA-Z]',' ',total_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## remove extra spaces\ntotal_text=re.sub(' +',' ',total_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_text[0:10000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(total_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width = 1000, height = 500,stopwords=stopwords).generate(total_text)\nplt.figure(figsize=(15,5))\nplt.imshow(wordcloud)\nplt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets perform EDA for the Neagtive sentences","metadata":{}},{"cell_type":"code","source":"data_negative = data[data['polarity']<0]\ndata_negative.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_negative.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_negative= (' '.join(data_negative['Summary']))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_negative","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ntotal_negative=re.sub('[^a-zA-Z]',' ',total_negative)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(total_negative)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_negative","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_negative=re.sub(' +',' ',total_negative)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(total_negative)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwordcloud = WordCloud(width = 1000, height = 500,stopwords=stopwords).generate(total_negative)\nplt.figure(figsize=(15,5))\nplt.imshow(wordcloud)\nplt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyse to which set of users Amazon Can recommend more product","metadata":{}},{"cell_type":"markdown","source":"#### Amazon can recommend more products to only those who are going to buy more or to one who has a better conversion rate,so lets ready data according to this problem statement","metadata":{}},{"cell_type":"code","source":"df['UserId'].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['UserId'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw=df.groupby(['UserId']).agg({'Summary':'count', 'Text':'count','Score':'mean','ProductId':'count'}).sort_values(by='Text',ascending=False)\nraw","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw.columns=['Number_of_summaries','num_text','Avg_score','Number_of_products_purchased']\nraw","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_10=raw.index[0:10]\nnumber_10=raw['Number_of_products_purchased'][0:10]\n\nplt.bar(user_10, number_10, label='java developer')\nplt.xlabel('User_Id')\nplt.ylabel('Number of Products Purchased')\nplt.xticks(rotation=60)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### These are the Top 10 Users so we can recommend more & more Prodcuts to these Usser Id as there will be a high probability that these person are going to be buy more","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## picking a random sample\nfinal=df.sample(n=2000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final=df[0:2000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### check missing values in dataset","metadata":{}},{"cell_type":"code","source":"final.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Removing the Duplicates if any","metadata":{}},{"cell_type":"code","source":"final.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analyse Length of Comments whether Customers are going to give Lengthy comments or short one","metadata":{}},{"cell_type":"code","source":"final.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final['Text'][0].split(' '))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef calc_len(text):\n    return (len(text.split(' ')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text_length']=final['Text'].apply(calc_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\npx.box(final, y=\"Text_length\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion-->>\n    Seems to have Almost 50 percent users are going to give their Feedback limited to 50 words whereas there are only few users who are going give Lengthy Feedbacks","metadata":{}},{"cell_type":"markdown","source":"#### Analyze Score","metadata":{}},{"cell_type":"code","source":"sns.countplot(final['Score'], palette=\"plasma\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text Pre-Processsing","metadata":{}},{"cell_type":"code","source":"# converting the text to lower case","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'] =final['Text'].str.lower()\nfinal.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'][164]\n# 164 index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nre.sub('[^a-zA-Z]',' ',final['Text'][164])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### drawback of this re.sub in this use-case is, it will remove some numerical data too & may be that numerical values matters alot","metadata":{}},{"cell_type":"markdown","source":"#### logic to remove punctuations or all the special characters","metadata":{}},{"cell_type":"code","source":"# define punctuation\npunctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n\ndata= final['Text'][164]\n\n# remove punctuation from the string\nno_punct = \"\"\nfor char in data:\n    if char not in punctuations:\n        no_punct = no_punct + char\n\n# display the unpunctuated string\nno_punct","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Create function to remove punctuations in your review","metadata":{}},{"cell_type":"code","source":"# # import string\n# string.punctuation\n# import nltk\n# nltk.download('stopwords')\n# from nltk.corpus import stopwords\n# stopwords.words('english') #another approach","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Let's define a pipeline to clean up all the messages \n# # The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n\n# def message_cleaning(message):\n#     Test_punc_removed = [char for char in message if char not in string.punctuation]\n#     Test_punc_removed_join = ''.join(Test_punc_removed)\n#     Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n#     return Test_punc_removed_join_clean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final['Text']=final['Text'].apply(message_cleaning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(final['Text'][1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punc(review):\n    import string\n    punctuations =string.punctuation\n    # remove punctuation from the string\n    no_punct = \"\"\n    for char in review:\n        if char not in punctuations:\n            no_punct = no_punct + char\n    return no_punct","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'] =final['Text'].apply(remove_punc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'][164]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Removal of Stopwords","metadata":{}},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review='seriously this product was as tasteless as they come there are much better tasting products out there but at 100 calories its better than a special k bar or cookie snack pack you just have to season it or combine it with something else to share the flavor'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"re=[word for word in review.split(' ') if word not in set(stopwords.words('english'))]\nstr=''\nfor wd in re:\n    str=str+wd\n    str=str+' '\n#     including some space #instead of this we can use join as well\n\nstr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### using join to convert list into string","metadata":{}},{"cell_type":"code","source":"re=[word for word in review.split(' ') if word not in set(stopwords.words('english'))]\n' '.join(re)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_stopwords(review):\n    return ' '.join([word for word in review.split(' ') if word not in set(stopwords.words('english'))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remove_stopwords(review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'] = final['Text'].apply(remove_stopwords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### check if urls is present in Text column or not","metadata":{}},{"cell_type":"code","source":"final['Text'].str.contains('http?').sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'].str.contains('http').sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows',2000)\n# to show all the 2000 rows otherwise it will display with the gap\nfinal['Text'].str.contains('http',regex=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'][21]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### we will observe we have some kind of URLs over here in the data that is definitely a kind of Dirtines in data, so we have to clean this data & make ready data for the analysis purpose","metadata":{}},{"cell_type":"markdown","source":"####  Removal of urls","metadata":{}},{"cell_type":"code","source":"final['Text'][21]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review=final['Text'][21]\nreview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url_pattern = re.compile(r'href|http.\\w+')\n# w indicate any A -Z and a-z\n#after http you have any number of character till space . if there is anything ,and w+ means www or similar way for another charachters\nurl_pattern.sub(r'', review)\n#just replace it with space","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef remove_urls(review):\n    url_pattern = re.compile(r'href|http.\\w+')\n    return url_pattern.sub(r'', review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'] = final['Text'].apply(remove_urls)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'].str.contains('http').sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['Text'][34]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### as we will see we have lots of br in my data, let me remove wherever i have br","metadata":{}},{"cell_type":"code","source":"final['Text'][34].replace('br','')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(final['Text'])):\n    final['Text'][i]=final['Text'][i].replace('br','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2=final.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2['Text'][34]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Advantages of Word Clouds :\nAnalyzing customer and employee feedback.\nIdentifying new SEO keywords to target.","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords = set(STOPWORDS) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_words = '' \nfor val in data2['Text']:\n    # typecaste each val to string\n    \n    # split the value \n    tokens = val.split() \n    \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n    comment_words=comment_words+ \" \".join(tokens)+\" \"\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the WordCloud image                        \nplt.figure(figsize = (8, 8)) \nplt.imshow(wordcloud) \nplt.axis(\"off\") ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}