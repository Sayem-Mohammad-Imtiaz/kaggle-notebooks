{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-06-24T10:18:13.310968Z","iopub.execute_input":"2021-06-24T10:18:13.311415Z","iopub.status.idle":"2021-06-24T10:18:13.316803Z","shell.execute_reply.started":"2021-06-24T10:18:13.311332Z","shell.execute_reply":"2021-06-24T10:18:13.315643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing important packages\nimport cudf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport pickle\nfrom sklearn.model_selection import GridSearchCV  #Perforing grid search\nimport json\nfrom sklearn.metrics import roc_auc_score\nfrom time import process_time","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:13.318732Z","iopub.execute_input":"2021-06-24T10:18:13.319439Z","iopub.status.idle":"2021-06-24T10:18:18.303937Z","shell.execute_reply.started":"2021-06-24T10:18:13.3194Z","shell.execute_reply":"2021-06-24T10:18:18.303083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir result","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:18.305724Z","iopub.execute_input":"2021-06-24T10:18:18.30602Z","iopub.status.idle":"2021-06-24T10:18:18.998017Z","shell.execute_reply.started":"2021-06-24T10:18:18.305994Z","shell.execute_reply":"2021-06-24T10:18:18.996952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n#     'max_depth': 5,\n#     'eta': 0.1,\n#     'min_child_weight': 35,\n#     'subsample': 0.1\n     'tree_method' : 'gpu_hist'\n}\n\n#max depth 15\n#min_child_weight 20\n#subsample 0.9\n#eta 0.1\n\n\n#{'eta': 0.1, 'max_depth': 15, 'min_child_weight': 30, 'subsample': 0.9}\n\n#{'eta': 0.1, 'max_depth': 5, 'min_child_weight': 35, 'subsample': 0.1} for multil model","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:19.000022Z","iopub.execute_input":"2021-06-24T10:18:19.000444Z","iopub.status.idle":"2021-06-24T10:18:19.006639Z","shell.execute_reply.started":"2021-06-24T10:18:19.000388Z","shell.execute_reply":"2021-06-24T10:18:19.00504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/train-test-valid/merge_hdfs_item_valid.csv',header=None,index_col=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:19.008078Z","iopub.execute_input":"2021-06-24T10:18:19.008541Z","iopub.status.idle":"2021-06-24T10:18:25.43742Z","shell.execute_reply.started":"2021-06-24T10:18:19.008503Z","shell.execute_reply":"2021-06-24T10:18:25.436603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:25.438675Z","iopub.execute_input":"2021-06-24T10:18:25.439009Z","iopub.status.idle":"2021-06-24T10:18:25.476409Z","shell.execute_reply.started":"2021-06-24T10:18:25.438974Z","shell.execute_reply":"2021-06-24T10:18:25.475509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_train = []\nlist_test = []\nlist_time = []\nfor i in range(4,10):\n    df_train = pd.read_csv('/kaggle/input/final-features/item_train_' + str(i) + '.csv',index_col=False)\n    \n    x_train = df_train.drop('1',axis=1)\n    y_train = df_train['1']\n    del df_train\n    \n    t1_start = process_time() \n\n    \n    model = xgb.XGBClassifier(**params)\n    model.fit(x_train,y_train)\n    \n    t1_stop = process_time()\n    \n    predict_train = model.predict_proba(x_train)[:, 1]\n\n    # Accuray Score on train dataset\n    accuracy_train = roc_auc_score(y_train,predict_train)\n    print('\\naccuracy_score on train dataset : {:.2f}%'.format(accuracy_train*100))\n    list_train.append(accuracy_train*100)\n    del x_train\n    del y_train\n    \n    x_test = df_test.drop(1,axis=1)\n    y_test = df_test[1]\n    \n    predict_test = model.predict_proba(x_test)[:, 1]\n\n    # Accuracy Score on test dataset\n    accuracy_test = roc_auc_score(y_test,predict_test)\n    print('\\naccuracy_score on test dataset : {:.2f}%'.format(accuracy_test*100))\n    list_test.append(accuracy_test*100)\n    \n    filename = '/kaggle/working/result/xgboost_model_'+ str(i)+'.sav'\n    pickle.dump(model, open(filename, 'wb'))\n    \n    time_train = t1_stop - t1_start\n    list_time.append(time_train)\n    \n    f = open(\"/kaggle/working/result/xgboost_params_test.txt\", \"a\")\n    f.write('\\nmodel_'+ str(i) + \": \" + json.dumps(params) + \"\\t\" + \"train: \" + str(accuracy_train*100) + \"\\t\" + \"test: \"+  str(accuracy_test*100)+ \"\\ttime: \"+ str(time_train)+\"\\n\")\n    f.close()\ndel x_test\ndel y_test","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:59.630682Z","iopub.execute_input":"2021-06-24T10:18:59.631008Z","iopub.status.idle":"2021-06-24T10:22:14.425144Z","shell.execute_reply.started":"2021-06-24T10:18:59.630977Z","shell.execute_reply":"2021-06-24T10:22:14.424183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statistics\n\nf = open(\"/kaggle/working/result/xgboost_params_test.txt\", \"a\")\nf.write(\"\\naverage naccuracy_score on train dataset: %f\" % statistics.mean(list_train))\nf.write(\"\\naverage naccuracy_score on test dataset: %f\\n\" % statistics.mean(list_test))\nf.write(\"\\naverage training time: %f\\n\" % statistics.mean(list_time))\nf.close()\nprint(\"\\naverage naccuracy_score on train dataset: %f\" % statistics.mean(list_train))\nprint(\"\\naverage naccuracy_score on test dataset: %f\" % statistics.mean(list_test))\nprint(\"\\naverage training time: %f\\n\" % statistics.mean(list_time))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:22:14.426643Z","iopub.execute_input":"2021-06-24T10:22:14.427267Z","iopub.status.idle":"2021-06-24T10:22:14.44296Z","shell.execute_reply.started":"2021-06-24T10:22:14.427222Z","shell.execute_reply":"2021-06-24T10:22:14.442066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pwd","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:25.696489Z","iopub.status.idle":"2021-06-24T10:18:25.69705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_test.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:25.698323Z","iopub.status.idle":"2021-06-24T10:18:25.698897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorical_feature_mask = df_test.dtypes==object\n# # Get list of categorical column names\n# categorical_cols = df_test.columns[categorical_feature_mask].tolist()\n# # apply le on categorical feature columns\n# df_test[categorical_cols] = df_test[categorical_cols].apply(lambda col: le.fit_transform(col))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:25.700329Z","iopub.status.idle":"2021-06-24T10:18:25.701021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_test = df_test.drop('1',axis=1)\n# y_test = df_test['1']\n# del df_test","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:25.702519Z","iopub.status.idle":"2021-06-24T10:18:25.703084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = model.predict(x_test)\n# del x_test","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:25.704404Z","iopub.status.idle":"2021-06-24T10:18:25.704991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test,)","metadata":{}},{"cell_type":"code","source":"# from sklearn.metrics import accuracy_score\n# accuracy = accuracy_score(y_pred, y_test)\n# del y_test\n# print(accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T10:18:25.706343Z","iopub.status.idle":"2021-06-24T10:18:25.706964Z"},"trusted":true},"execution_count":null,"outputs":[]}]}