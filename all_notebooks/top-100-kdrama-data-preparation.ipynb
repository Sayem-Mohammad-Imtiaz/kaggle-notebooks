{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n<a id='table-of-contents'></a>\n- [1 Introduction](#1)\n- [2 Data Preparation](#2)\n    - [2.1](#2.1)\n         -[2.1.1](#2.1.1)\n         -[2.1.2](#2.1.2)\n         -[2.1.3](#2.1.3)\n         -[2.1.4](#2.1.4)\n         -[2.1.5](#2.1.5)\n         -[2.1.6](#2.1.6)\n         -[2.1.7](#2.1.7)\n     ","metadata":{}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id='1'></a>\n# 1. Introduction\nIn this notebook the top 100 Kdramas csv will be cleaned and prepped so that I can perform some EDA on it and then eventually build a recommender system for it.\n## 1.1 Preloading packages","metadata":{}},{"cell_type":"code","source":"#core packages\nimport os \nimport numpy as np\nimport pandas as pd\nimport warnings\n\n#visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport plotly.express as px\nimport seaborn as sns\nplt.rcParams['figure.dpi'] = 600\npd.set_option('display.max_rows', None)\npd.set_option('display.max.columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\n\n#reduce memory usage conversions\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T16:25:35.046517Z","iopub.execute_input":"2021-08-10T16:25:35.046942Z","iopub.status.idle":"2021-08-10T16:25:35.067962Z","shell.execute_reply.started":"2021-08-10T16:25:35.046907Z","shell.execute_reply":"2021-08-10T16:25:35.066928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id = '2'></a>\n# 2. Data Preparation","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/top-100-korean-drama-mydramalist/top100_kdrama.csv')\nprint(data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:35.433337Z","iopub.execute_input":"2021-08-10T16:25:35.433649Z","iopub.status.idle":"2021-08-10T16:25:35.471875Z","shell.execute_reply.started":"2021-08-10T16:25:35.43362Z","shell.execute_reply":"2021-08-10T16:25:35.47078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Notes on data prep to be done:**\n- `Aired date` should be split into two columns: `Aired on`, `Final Episode` or something similar\n- `Network` should be split into `Network 1`, `Network 2`, etc..\n- `Duration` should be changed from X hr X min to an integer that is equal to minutes. \n- `Content Rating` just a rumber, maybe an extra column for explanation but not really necessary\n- `Cast` can be split into multiple columns\n- `Genre` split into multiple columns\n- `Tags` into multiple columns \n- Any dates changed to proper datetime format ","metadata":{}},{"cell_type":"code","source":"data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:35.474052Z","iopub.execute_input":"2021-08-10T16:25:35.474495Z","iopub.status.idle":"2021-08-10T16:25:35.484762Z","shell.execute_reply.started":"2021-08-10T16:25:35.474443Z","shell.execute_reply":"2021-08-10T16:25:35.483119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows: {data.shape[0]};  Number of columns: {data.shape[1]}; No of missing values: {sum(data.isna().sum())}')","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:35.486818Z","iopub.execute_input":"2021-08-10T16:25:35.487273Z","iopub.status.idle":"2021-08-10T16:25:35.501061Z","shell.execute_reply.started":"2021-08-10T16:25:35.487227Z","shell.execute_reply":"2021-08-10T16:25:35.499808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No missing values, nice.","metadata":{}},{"cell_type":"markdown","source":"<a id='2.1'></a>\n## 2.1 Data cleaning\n<a id = '2.1.1'></a>\n### 2.1.1 Converting Cast, Genre, and Tags","metadata":{}},{"cell_type":"code","source":"#GENRE Encoding\ng = []\nfor genres in data['Genre']:\n    G = genres.split(',', -1)\n    for i, genre in enumerate(G):\n        if genre.strip() not in g:\n            g.append(G[i].strip())\n        else:\n            pass\ng.sort()\n\nfor genre in g:\n    data[f'Genre_{genre}'] = np.zeros((100,), dtype = int)\ncounter = 0\nfor genres in data['Genre']:\n    G = genres.split(',', -1)\n    for i, genre in enumerate(G):\n        for gen in g:\n            if G[i].strip() == gen:\n                data[f'Genre_{gen}'][counter] = 1 \n            else:\n                pass\n    counter +=1\ndata.drop(['Genre'], axis = 1, inplace = True)\n\n#TAG Encoding\nt = []\nfor tags in data['Tags']:\n    T = tags.split(',', -1)\n    for i, tag in enumerate(T):\n        if tag.strip() not in t:\n            t.append(T[i].strip())\n        else:\n            pass\nt.sort()\n\nfor tag in t:\n    data[f'Tag_{tag}'] = np.zeros((100,), dtype = int)\ncounter = 0\nfor tags in data['Tags']:\n    T = tags.split(',', -1)\n    for i, tag in enumerate(T):\n        for ta in t:\n            if T[i].strip() == ta:\n                data[f'Tag_{ta}'][counter] = 1 \n            else:\n                pass\n    counter +=1\ndata.drop(['Tags'], axis = 1, inplace = True)\n\n#CAST Encoding\nc = []\nfor cast in data['Cast']:\n    C = cast.split(',', -1)\n    for i, cas in enumerate(C):\n        if cas.strip() not in c:\n            c.append(C[i].strip())\n        else:\n            pass\nc.sort()\n\nfor actor in c:\n    data[f'{str(actor).replace(\" \", \"_\").lower()}'] = np.zeros((100,), dtype = int)\ncounter = 0\nfor actor in data['Cast']:\n    C = actor.split(',', -1)\n    for i, act in enumerate(C):\n        for A in c:\n            if C[i].strip() == A:\n                data[f'{str(A).replace(\" \", \"_\").lower()}'][counter] = 1 \n            else:\n                pass\n    counter +=1\ndata.drop(['Cast'], axis = 1, inplace = True)\n\ndata.head()\nprint(data.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T16:25:35.50391Z","iopub.execute_input":"2021-08-10T16:25:35.504339Z","iopub.status.idle":"2021-08-10T16:25:37.498647Z","shell.execute_reply.started":"2021-08-10T16:25:35.504297Z","shell.execute_reply":"2021-08-10T16:25:37.497518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have a very big dataset","metadata":{}},{"cell_type":"markdown","source":"<a id = '2.1.2'></a>\n### 2.1.2 Converting Content Rating\nWe gonna see the unique values for content rating and decide what to do. Maybe change it into a integer encoded column where rather than 15, 18 etc we have like 1, 2 ","metadata":{}},{"cell_type":"code","source":"data['Content Rating'].value_counts() # Yes so after looking at this I want to conver it to a Integer Encoded column. ","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:37.500369Z","iopub.execute_input":"2021-08-10T16:25:37.500659Z","iopub.status.idle":"2021-08-10T16:25:37.510511Z","shell.execute_reply.started":"2021-08-10T16:25:37.500632Z","shell.execute_reply":"2021-08-10T16:25:37.509257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nfrom sklearn.preprocessing import OrdinalEncoder\nenc = OrdinalEncoder()\nRating = np.array(data['Content Rating'])\ndata['Content Rating'] = enc.fit_transform(Rating.reshape(-1,1)) # 2 = 18+, 1 = 15+, 0 = 13+\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:37.513239Z","iopub.execute_input":"2021-08-10T16:25:37.513658Z","iopub.status.idle":"2021-08-10T16:25:37.914774Z","shell.execute_reply.started":"2021-08-10T16:25:37.513623Z","shell.execute_reply":"2021-08-10T16:25:37.913951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '2.1.3'></a>\n### 2.1.3 Converting Duration\nNeed to convert duration from Xhr Ymin to Zmins","metadata":{"execution":{"iopub.status.busy":"2021-08-10T15:48:26.226279Z","iopub.execute_input":"2021-08-10T15:48:26.226836Z","iopub.status.idle":"2021-08-10T15:48:26.237425Z","shell.execute_reply.started":"2021-08-10T15:48:26.226801Z","shell.execute_reply":"2021-08-10T15:48:26.236052Z"}}},{"cell_type":"code","source":"def t_converter(duration):\n    duration = duration.strip(\" min.\").replace(\" hr. \",\":\")\n    # SHould now have a string of this formate'X:YY'\n    T = duration.split(':')\n    if len(T)==2:\n        hours = int(T[0])*60\n        mins = int(T[1])\n        time = hours +mins\n    else:\n        time = int(T[0]) #this only has minutes\n    return time\nfor i, run in enumerate(data['Duration']):\n    data['Duration'][i] = t_converter(run)\ndata.head()\ndata.rename(columns = {'Duration':'Duration/min'}, inplace = True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-10T16:25:37.916081Z","iopub.execute_input":"2021-08-10T16:25:37.916488Z","iopub.status.idle":"2021-08-10T16:25:37.997342Z","shell.execute_reply.started":"2021-08-10T16:25:37.916459Z","shell.execute_reply":"2021-08-10T16:25:37.996515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '2.1.4'></a>\n### 2.1.4 Converting Network\nAm going to assume that the first network in each list is the original air network.","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:02:35.334064Z","iopub.execute_input":"2021-08-10T16:02:35.33468Z","iopub.status.idle":"2021-08-10T16:02:35.342199Z","shell.execute_reply.started":"2021-08-10T16:02:35.33462Z","shell.execute_reply":"2021-08-10T16:02:35.341037Z"}}},{"cell_type":"code","source":"for i, row in enumerate(data['Network']):\n    networks = str(row)\n    networks = networks.split(',')\n    data['Network'][i] = networks[0].strip()\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:37.998509Z","iopub.execute_input":"2021-08-10T16:25:37.998932Z","iopub.status.idle":"2021-08-10T16:25:38.454462Z","shell.execute_reply.started":"2021-08-10T16:25:37.998902Z","shell.execute_reply":"2021-08-10T16:25:38.453361Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Network'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:38.455532Z","iopub.execute_input":"2021-08-10T16:25:38.455991Z","iopub.status.idle":"2021-08-10T16:25:38.464036Z","shell.execute_reply.started":"2021-08-10T16:25:38.45596Z","shell.execute_reply":"2021-08-10T16:25:38.463282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '2.1.5'></a>\n### 2.1.5 Converting Aired On\nNeed to go through this column and; firstly - split it into multiple columns, `Air Date 1`, `Air Date 2` etc.\nAfter that One-Hot Encode all columns. Is easier than trying to Integer encode all three columns and is also easier to intepret.","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:25:38.465051Z","iopub.execute_input":"2021-08-10T16:25:38.465444Z","iopub.status.idle":"2021-08-10T16:25:38.84837Z","shell.execute_reply.started":"2021-08-10T16:25:38.465416Z","shell.execute_reply":"2021-08-10T16:25:38.847517Z"}}},{"cell_type":"code","source":"data['Air Day 1'] = np.zeros((100,))\ndata['Air Day 2'] = np.zeros((100,))\ndata['Air Day 3'] = np.zeros((100,))\nfor i, col in enumerate(data['Aired On']):\n    days = col.split(\", \")\n    if len(days)== 3:\n        data['Air Day 1'][i] = days[0].strip()\n        data['Air Day 2'][i] = days[1].strip()\n        data['Air Day 3'][i] = days[2].strip()\n    elif len(days) == 2:\n        data['Air Day 1'][i] = days[0].strip()\n        data['Air Day 2'][i] = days[1].strip()\n        data['Air Day 3'][i] = np.nan\n    else:\n        data['Air Day 1'][i] = days[0].strip()\n        data['Air Day 2'][i] = np.nan\n        data['Air Day 3'][i] = np.nan\ndata.drop(['Aired On'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:40:37.160287Z","iopub.execute_input":"2021-08-10T16:40:37.160927Z","iopub.status.idle":"2021-08-10T16:40:37.413918Z","shell.execute_reply.started":"2021-08-10T16:40:37.160891Z","shell.execute_reply":"2021-08-10T16:40:37.412777Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['Air Day 1', 'Air Day 2', 'Air Day 3']\ndummies = pd.get_dummies(data[cols])\ndata = pd.concat([data, dummies], axis = 1)\ndata.drop(cols, axis =1, inplace = True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T16:44:45.026179Z","iopub.execute_input":"2021-08-10T16:44:45.026585Z","iopub.status.idle":"2021-08-10T16:44:45.491498Z","shell.execute_reply.started":"2021-08-10T16:44:45.02655Z","shell.execute_reply":"2021-08-10T16:44:45.490353Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '2.1.6'></a>\n### 2.1.6 Converting Aired Date\nNeed to convert the Aired Date column to two columns: `First Aired`, `Last Aired`. Also want to convert that column to datetime. day-month-year","metadata":{}},{"cell_type":"code","source":"import datetime \ndata['First Aired'] = np.nan \ndata['Last Aired'] = np.nan\nfor i, row in enumerate(data['Aired Date']):\n    dates = row.split(' - ')\n    if len(dates)>1:\n        data['First Aired'][i] = datetime.datetime.strptime(dates[0], '%b %d, %Y').strftime('%d/%m/%y')\n        data['Last Aired'][i] = datetime.datetime.strptime(dates[1], '%b %d, %Y').strftime('%d/%m/%y')\n    else:\n        data['First Aired'][i] = datetime.datetime.strptime(dates[0], '%b %d, %Y').strftime('%d/%m/%y')\ndata.drop('Aired Date', axis =1, inplace = True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:03:22.810958Z","iopub.execute_input":"2021-08-10T17:03:22.811311Z","iopub.status.idle":"2021-08-10T17:03:23.397316Z","shell.execute_reply.started":"2021-08-10T17:03:22.81128Z","shell.execute_reply":"2021-08-10T17:03:23.396251Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = '2.1.7'></a>\n### 2.1.7 Last Tidy\nLastly want to get rid of the number symbol in the rank column and drop the synopsis column as it won't be needed for any EDA","metadata":{}},{"cell_type":"code","source":"for i, rank in enumerate(data['Rank']):\n    R = rank.strip('#')\n    data['Rank'][i] = int(R)\ndata.drop('Synopsis', axis = 1, inplace = True)\ndata = reduce_mem_usage(data)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:12:39.561792Z","iopub.execute_input":"2021-08-10T17:12:39.562371Z","iopub.status.idle":"2021-08-10T17:12:40.596646Z","shell.execute_reply.started":"2021-08-10T17:12:39.56232Z","shell.execute_reply":"2021-08-10T17:12:40.595429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv('top_100_k_drama_clean.csv', index = False, header = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T17:12:43.869298Z","iopub.execute_input":"2021-08-10T17:12:43.869756Z","iopub.status.idle":"2021-08-10T17:12:43.945992Z","shell.execute_reply.started":"2021-08-10T17:12:43.869703Z","shell.execute_reply":"2021-08-10T17:12:43.944894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Okay so that has created a cleaned up and much larger csv","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}