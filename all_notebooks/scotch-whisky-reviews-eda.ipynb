{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def read_input():\n    return pd.read_csv('/kaggle/input/22000-scotch-whisky-reviews/scotch_review.csv', index_col=0) # Head column is the index columns.\noriginal = read_input()\noriginal.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Take a look for all columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Why the price column's dtype is not number ?\ntry:\n    original.price.astype(float)\nexcept Exception as e:\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is there any illregular price?\noriginal.loc[~original.price.str.match('^[\\d]+[\\.]*[\\d]*$')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Name column has many informations and some duplicates.\noriginal.name.value_counts()[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Are all descriptions unique?\noriginal.description.value_counts()[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What is the review point distribution like?\noriginal['review.point'].hist(bins=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is there any duplicate?\noriginal[original.duplicated(keep=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What values can currency take ?\noriginal.currency.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What I found so far\n1. Price needs to be number like float or int.\n1. Name has duplicates, so some informations are for same products. If I want product unique statistics, I should take this into considerarion.\n1. Name has many informations like brand, distiller, alcohol content, age, etc. So I will split the informations.\n1. Description is a large text column. So I will process it into BoW.\n1. 2 rows are completely duplicated and needs to be removed.\n1. Review.point has a nice distribution and integer column.\n1. Currency is a needless column."},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleanse(df):\n    def cleanse_str(sr):\n        result = sr.str.normalize('NFKC')\n        result = result.str.replace(\"’\", \"'\")\n        return result.str.lower()\n    result = df.drop(columns='currency') # We don't need it.\n    result = result.drop_duplicates() # We don't need duplicated rows.\n    result.name = cleanse_str(result.name)\n    result.name = result.name.str.replace('^\\s+', '') # Remove the first sapce \n    result.name = result.name.str.replace('^the ', '') # Remove the first 'The' \n    result.price = result.price.str.replace('\\$15,000 or \\$|/[a-z]*|\\,', '').astype(float).astype(np.uint16) # price as int\n    result.rename(columns={'review.point':'review_point'}, inplace=True) # Dot separator is hard to use.\n    result.review_point = result.review_point.astype(np.uint8) # Make it smaller.\n    result.description = cleanse_str(result.description)\n    result.description = result.description.str.replace('\\r\\n', '') # Remove new line chars.\n    result['name_pruned'] = df.name # Copy for prune\n    return result\n# cleansed = cleanse(original)\n# cleansed.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Name Processing\nI will split name into alcohol, age, birth, distilled at, and brand. Because this dataset's size is only 2k and name column is not large like sentences in description, I implemented the processing method trial and error approach with checking the output by my eyes and collecting. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_alcohol(df):\n    # Be careful, 'Kilchoman 100% Islay 3rd Edition, 50%' has two percentages and the first one is not telling about alcohol.\n    result = df.name.str.extract('((?<!\\d)\\d{2}|(?<!\\d)\\d{2}\\.[\\d]+)%')[0].astype(float)\n    df['name_pruned'] = df.name.str.replace('((?<!\\d)\\d{2}|(?<!\\d)\\d{2}\\.[\\d]+)%', '')\n    result.loc[1648] = 57.1 # This row's name contains a word 'ABV' between numeric and '%' which I don't make sence. So I'll do this by hard cording.\n    return result\n# cleansed.loc[extract_alcohol(cleansed).isnull(), 'name'].values # Debug code.\n# extract_alcohol(cleansed).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_age(df):\n    result = df.name.str.extract('(\\d+) [yY]ear')[0].astype(float)\n    df.name_pruned = df.name_pruned.str.replace('(\\d+) [yY]ear( [oO]ld)?', '')\n    return result\n# cleansed.loc[extract_age(cleansed).isnull(), 'name'].values[800:900] # Debug code.\n# extract_age(cleansed).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_birth(df):\n    result = df.name.str.extract('((?<!#)20[01]\\d|(?<!#)19[\\d]{2})')\n    df.name_pruned = df.name_pruned.str.replace('((?<!#)20[01]\\d|(?<!#)19[\\d]{2})', '')\n    return result\n# extract_birth(cleansed)[0].astype(float).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_distilled_at(df):\n    result = df.name.str.extract('[Dd]istilled at (.+?)[,\\);]')\n    df.name_pruned = df.name_pruned.str.replace('\\(?[Dd]istilled at (.+?)[,\\);]', '')\n    return result\n# extract_distilled_at(cleansed)[0].value_counts().index.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I extracted brands by a huristic way with a text editor, because I couldn't find any algorithm to do that. \nbrands = [\"a.d.rattray\",\"aberfeldy\",\"aberlour\",\"abhainn dearg\",\"adelphi\",\"ailsa bay\",\"alexander murray & co.\", \"anchor bay\", \"ancnoc\",\n          \"annasach\",\"antiquary\",\"ardbeg\",\n          \"ardmore\",\"arran\",\"auchentoshan\",\"auchroisk\",\"auld reekie\",\"aultmore\",\"balblair\",\"ballantine's\",\"balvenie\",\"ben nevis\",\"benriach\",\n          \"benrinnes\", \"benromach\",\"berry brothers & rudd\",\"big peat\",\"black bottle\",\"black bull\",\"black grouse\",\"blackadder\",\"bladnoch\",\n          \"blair athol\",\"blue hanger\",\"borders\",\"bowmore\",\"brora\",\"bruichladdich\",\"buchanan's\",\"bunnahabhain\",\"cadenhead's\",\"caledonian\",\n          \"cambus\",\"caol ila\",\"cardhu\",\"carlyle\",\"carn mor\",\"cask & thistle\",\"chapter 7\",\"chieftain's\",\"clan denny\",\"clansman\",\n          \"classic cask\",\"clynelish\",\"collectivum xxviii\",\"compass box\",\"connoisseurs choice\",\"convalmore\",\"cooper's choice\",\"copper dog\",\n          \"coronation\",\"cragganmore\",\"craigellachie\",\"creative whisky co.\",\"cuatro series\",\"cutty sark\",\"cù bòcan\",\"d&m\",\n          \"dailuaine\",\"dalmore\",\"dalwhinnie\",\"darkness!\",\"deanston\",\"deerstalker\",\"deveron\",\"dewar's\",\n          \"distillery select\",\"double barrel\",\"douglas\",\"dun bheagan\",\"duncan taylor\",\"duncansby head\",\"eades\",\"edradour\",\"epicurean\", \"exclusive\",\n          \"famous grouse\",\"famous jubilee\",\"fat trout\",\"feathery\",\"fettercairn\",\"five distinguished and rare\",\"girvan\",\"glen deveron\",\n          \"glen elgin\",\"glen garioch\",\"glen grant\",\"glen moray\",\"glen ord\",\"glen scotia\",\"glen spey\",\"glen turner\",\n          \"glenburgie\",\"glencadam\",\"glendronach\",\"glenfarclas\",\"glenfiddich\",\"glengarioch\",\"glenglassaugh\",\"glengoyne\",\"glenkeir treasures\",\n          \"glenkinchie\",\"glenlivet\",\"glenmorangie\",\"glenrothes\",\"glenturret\",\"glenugie\",\"glenury royal\",\"golden age\",\"gordon & macphail\",\n          \"grand macnish\",\"grangestone\",\"grant's\",\"haig club\",\"half century blend\",\"hankey bannister heritage blend\",\"hart brothers\",\n          \"hazelburn\",\"hepburn's choice\",\"high commissioner\",\"highland journey\",\"highland park\", \"highland queen\",\"house of hazelwood\",\"hunter laing\",\"inchgower\",\n          \"inchmoan\",\"inchmurrin\",\"islay mist\",\"isle of jura\",\"isle of skye\",\"j&b\",\"j.mossman\",\"james brookes\",\"jamie stewart\",\"jura\",\"lombard\",\"jewels of scotland\",\n          \"john barr\",\"john mcdougall's\",\"john walker\",\"johnnie walker\",\"kilchoman\",\"kilkerran\",\"king's crest\",\"kininvie\",\"kirkland signature\",\"knockando\",\n          \"label 5\",\"lady of the glen\",\"ladyburn\",\"lagavulin\",\"langside distillers\",\"laphroaig\",\"last drop\",\"ledaig\",\"linkwood\",\"littlemill\",\n          \"loch lomond\",\"lonach\",\"longmorn\",\"longrow\",\"lord elcho\",\"lost distiller\",\"macallan\",\"macduff\",\"mackillop's choice\",\"mackinlay's\",\n          \"macnamara\",\"macphail's collection\",\"macqueen's\",\"maltman\",\"mannochmore\",\"master of malt\",\"mcdougall's selection\",\"mcgibbons provenance\",\"miltonduff\",\n          \"monarch of the glen\",\"montgomerie's\",\"moon harbour pier\",\"mortlach\",\"murray mcdavid\",\"naked grouse\",\"noss head\",\"oban\",\"octomore islay barley\",\n          \"old malt cask\",\"old masters freemason whisky\",\"old particular\",\"old pulteney\",\"pearls of scotland\",\"peerless\",\"pentland skerries\",\n          \"pittyvaich\",\"poit dhubh blended malt\",\"port askaig\",\"port charlotte\",\"port dundas\",\"port ellen\",\"provenance\",\"pure scot\",\n          \"raasay while we wait\",\"ragnvald\",\"rare cask reserves blended reserve\",\"robert burns\",\"rock oyster\",\"ron burgundy\",\"rosebank\",\n          \"royal brackla\",\"royal lochnagar\",\"royal mile whiskies\",\"royal salute\",\"scallywag\",\"scapa\",\"scotch malt whisky society\",\"scott's selection\",\n          \"shackleton\",\"sheep dip\",\"shieldaig\",\"sia\",\"signatory\",\"sigurd\",\"single cask nation\",\"single malts of scotland\",\"singleton\",\"sir edward's\",\n          \"smokehead\",\"smoking ember\",\"sovereign\",\"spey royal choice\",\"speyburn\",\"speyside\",\"springbank\",\"storm\",\"strathclyde\",\"strathisla\",\n          \"strathmill\",\"stronachie\",\"syndicate\",\"talisker\",\"tamdhu\",\"te bheag blended whisky\",\"teaninich\",\"that boutique-y\",\"thorfinn\",\n          \"timorous beastie\",\"tobermory\",\"tomatin\",\"tomintoul\",\"tormore\",\"trader joe's\",\"treacle chest\",\"tullibardine\",\"tweeddale\",\"usquaebach\",\n          \"wemyss\",\"whisky exchange\",\"whisky galore\",\"wild scotsman\",\"william grant's\",\"wolfburn\"\n         ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_brand(df):\n    df.name_pruned = df.name_pruned.str.replace(',', ' ')\n    df.name_pruned = df.name_pruned.str.replace('\\s{2,}', ' ')\n    df.name_pruned = df.name_pruned.str.replace('\\. ', '.')\n    df.name_pruned = df.name_pruned.str.replace('berry bros\\.', 'berry brothers ')\n    df.name_pruned = df.name_pruned.str.replace(\"berry's|berrys'\", 'berry brothers & rudd')\n    df.name_pruned = df.name_pruned.str.replace(\"black bowmore\", 'bowmore black')\n    df.name_pruned = df.name_pruned.str.replace(\"cadenhead\", \"cadenhead's\")\n    df.name_pruned = df.name_pruned.str.replace(\"gold bowmore\", 'bowmore gold')\n    df.name_pruned = df.name_pruned.str.replace(\"macdougall's\", \"mcdougall's\")\n    df.name_pruned = df.name_pruned.str.replace(\"scott|scott selection\", \"scott's selection\")\n    df.name_pruned = df.name_pruned.str.replace(\"traditional ben nevis\", 'ben nevis traditional')\n    df.name_pruned = df.name_pruned.str.replace(\"white bowmore\", 'bowmore white') \n    df.name_pruned = df.name_pruned.str.replace(\"^“double malt”\", 'eades “double malt”')\n    df.name_pruned = df.name_pruned.str.replace(\"william grant\", \"william grant's\")\n\n    brand_sr = pd.Series(np.repeat('', len(df)), index=df.index)\n    for brand in brands:\n        mask = df.name_pruned.str.startswith(brand)\n        brand_sr[mask] = brand\n        df.loc[mask, 'name_pruned'] = df.loc[mask, 'name_pruned'].str.replace(brand, '')\n    for brand in (\"elements of islay\", \"chivas\", \"john walker & sons\"):\n        mask = df.name_pruned.str.contains(brand)\n        brand_sr[mask] = brand\n        df.loc[mask, 'name_pruned'] = df.loc[mask, 'name_pruned'].str.replace(brand, '')\n    return brand_sr\n# extract_brand(cleansed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_name_df():\n    df = read_input()\n    cleansed = cleanse(df)\n    cleansed['alc'] = extract_alcohol(cleansed)\n    cleansed['age'] = extract_age(cleansed)\n    cleansed['birth'] = extract_birth(cleansed)\n    cleansed['distilled_at'] = extract_distilled_at(cleansed)\n    cleansed.sort_values('name_pruned', inplace=True)\n    cleansed['brand'] = extract_brand(cleansed)\n    cleansed.name_pruned = cleansed.name_pruned.str.replace('\\s{2,}', ' ')\n    cleansed.name_pruned = cleansed.name_pruned.str.replace('^\\s+|$\\s+', '')\n    cleansed.to_csv('/kaggle/working/work.csv', encoding='utf-8 sig')\n    return cleansed\n# cleansed = split_name_df()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What I've done for name\n1. Extracted brand, alcohol, age, birth, distilled_at. And name was pruned to name_pruned.\n1. I intended to know the birth year of the whisky from the birth column, But as a result, it is not a trustful column for that purpose. I will not use it.\n1. Being not null distilled_at column indicates that the product is not from a distiller but a bottler. And the value shows the name of the distiller where the cask came from."},{"metadata":{},"cell_type":"markdown","source":"## Descripsion processing\nA simple count vectorizing caused highly redundant and sparse matrix and difficulties to analyze (7k over dimensions). To avoid this, \n1. Remove stopwords and normalize words with lemmating. \n1. Remove the words below 75 percentile frequecy.\n1. Remove the words useless words like bottle, year, old, etc.\n1. Merge different forms of verb into root."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\n\ntag_dict = {\"J\": wordnet.ADJ,\n            \"N\": wordnet.NOUN,\n            \"V\": wordnet.VERB,\n            \"R\": wordnet.ADV}\n\ndef get_wordnet_pos(word):\n    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n    tag = nltk.pos_tag([word])[0][1][0].upper()\n    return tag_dict.get(tag, wordnet.NOUN)\n\ndef bow(description):\n    stop_words = set(stopwords.words('english'))\n    wordnet_lemmatizer = WordNetLemmatizer()\n    description = description.str.replace(\"[\\,\\.!\\(\\):“”;?%#$€£0-9]\", '')\n    description = description.str.replace(\"[\\/—\\-'‘]| & \", ' ')\n    def preproc(sentences):\n        result = word_tokenize(sentences)\n        result = filter(lambda word: word not in stop_words and len(word) > 2, result)\n        result = ' '.join((wordnet_lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in result))\n        return result\n    \n    count_vectorizer = CountVectorizer()\n    count_matrix = count_vectorizer.fit_transform([preproc(a_desc) for a_desc in description.values])\n    return pd.DataFrame(data=count_matrix.toarray(), columns=count_vectorizer.get_feature_names(), index=description.index)\n\ndef sqeeze_bow_matrix(bow_matrix):\n    freq = bow_matrix.sum(axis=0)\n    lower_freq_bnd = np.quantile(freq, .75)\n    result = bow_matrix.loc[:, (freq > lower_freq_bnd)]\n    words = result.columns\n    drop_words = ['year', 'old', 'bottle', 'whisky', 'ago', 'along', 'alongside', 'already', 'also', 'although', 'among', 'bros', 'brother', \n                  'chivas', 'could', 'date', 'day', 'do', 'dose', 'get', 'give', 'go', 'however', 'john', 'johnnie', 'make', 'may', 'maybe',\n                  'might', 'must', 'na', 'onto', 'otherwise', 'please', 'take', 'though', 'whether', 'whose', 'within', 'would', 'name', \n                  'category', 'price', 'age', 'brand'] + brands\n    result.drop(columns = words[words.isin(drop_words)], inplace=True)\n    # lemmatize again\n    result['allow'] += result['allows']\n    result['become'] += result['becomes']\n    result['blend'] += result['blending']\n    result['bring'] += result['brings'] + result['brought']\n    result['build'] += result['building']\n    result['burn'] += result['burning'] + result['burnt']\n    result['contain'] += result['contains']\n    result['creamy'] += result['creamier']\n    result['dark'] += result['darker']\n    result['deep'] += result['deeper']\n    result['deliver'] += result['delivers']\n    result['develop'] += result['develops']\n    result['dominate'] += result['dominates']\n    result['drink'] += result['drinking']\n    result['drive'] += result['driven']\n    result['emerge'] += result['emerges']\n    result['evolve'] += result['evolves']\n    result['fade'] += result['fading']\n    result['feel'] += result['felt']\n    result['find'] += result['found']\n    result['floral'] += result['florals']\n    result['fresh'] += result['fresher']\n    result['fruity'] += result['fruitier']\n    result['full'] += result['fuller']\n    result['grow'] += result['grown']\n    result['hold'] += result['held']\n    result['keep'] += result['kept']\n    result['linger'] += result['lingers']\n    result['long'] += result['longer']\n    result['marry'] += result['married']\n    result['mix'] += result['mixed']\n    result['north'] += result['northern']\n    result['oak'] += result['oaked']\n    result['offer'] += result['offering']\n    result['open'] += result['opening']\n    result['peat'] += result['peated']\n    result['replace'] += result['replaces']\n    result['reveal'] += result['reveals']\n    result['rich'] += result['richer']\n    result['sherry'] += result['sherried']\n    result['suggest'] += result['suggests']\n    result['surprise'] += result['surprising']\n    result['sweet'] += result['sweeter']\n    result['texture'] += result['textured']\n    result['thick'] += result['thicker']\n    result['toward'] += result['towards']\n    result['wax'] += result['waxed']\n    result.drop(columns = ['allows', 'becomes', 'blending', 'brings', 'brought', 'building','burning', 'burnt', \n                           'contains', 'darker', 'deeper', 'delivers', 'develops', 'dominates', 'drinking', 'driven', 'emerges',\n                           'evolves', 'fading', 'felt', 'found', 'florals', 'fresher', 'fruitier', 'fuller', 'grown', 'held', \n                           'kept', 'lingers', 'longer', 'married', 'mixed', 'northern', 'oaked', 'offering', 'opening', 'peated', \n                           'replaces', 'reveals', 'richer', 'suggests', 'surprising', 'sweeter', 'textured', 'thicker', 'towards', \n                           'waxed', 'sherried', \n                          ], inplace=True)\n    return result\n\ndef description_bow_matrix():\n    df = read_input()\n    cleansed = cleanse(df)\n    desc_bow_mat = bow(cleansed.description)\n    sqeezed = sqeeze_bow_matrix(desc_bow_mat)\n    return sqeezed\n\n# desc_bow_mat = description_bow_matrix()\n# desc_bow_mat.columns.values[:1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = split_name_df().merge(description_bow_matrix(), how='inner', left_index=True, right_index=True)\ndf.info()\ndf.to_csv('all_features.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_df = df[df.columns[:11]]\ndesc_df = df[df.columns[11:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of price"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(base_df['price'].describe())\nsns.distplot(base_df['price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some very expensive whisky and the distribution is very skew. I'll take a logarithm. "},{"metadata":{"trusted":true},"cell_type":"code","source":"base_df['log_price'] = np.log(base_df['price'])\nprint(base_df['log_price'].describe())\nsns.distplot(base_df['log_price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of age"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(base_df['age'].describe())\nsns.distplot(base_df['age'].dropna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution is skew. I'll take a logarithm too. "},{"metadata":{"trusted":true},"cell_type":"code","source":"base_df['log_age'] = np.log(base_df['age'])\nprint(base_df['log_age'].describe())\nsns.distplot(base_df['log_age'].dropna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of alcohol"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(base_df['alc'].describe())\nsns.distplot(base_df['alc'].dropna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot the Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(base_df[['review_point', 'log_price', 'alc', 'log_age']].corr())\nsns.pairplot(base_df[['review_point', 'log_price', 'alc', 'log_age']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What I found\n1. There is a obvious correlation with price and age. This is understandable result.\n1. Review point and price has correlation about 0.3. It's not weak correlation but much weaker than I guess before. Interesting.\n1. Review point and age also has correlation about 0.3. It's very similar magnitude with price and I'm interested in \n1. Alcohol content seems no remarkable correlation with other features."},{"metadata":{},"cell_type":"markdown","source":"## About category"},{"metadata":{},"cell_type":"markdown","source":"### Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nprint(base_df.category.value_counts())\nsns.countplot(data=base_df, x='category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Difference in review points"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.boxplot(data=base_df, y='review_point', x='category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Difference in price"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.boxplot(data=base_df, y='log_price', x='category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What I found\n1. Single malt has many datas and high variance on both review_point and price.\n1. Difference of category does not cause obvious difference in review point. Interesting.\n1. Mean of the price does not varies depending on categories.\n1. I thought the malt whiskies tend to have higher price than the grain whiskies have. But in this case, the mean price does not support my prejudice... "},{"metadata":{},"cell_type":"markdown","source":"## Description and review points"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = desc_df.sum(axis=0)\nfreq.nlargest(100).index.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nsns.heatmap(df[['review_point'] + freq.nlargest(30).index.tolist()].corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What I found\n1. Description has many words related to flavor (names of fruit, spice or sweets) and taste (dry, light, rich, etc).\n1. There is no ward directly correlated with reveiw point. To find the relation with description and review points, I must find other approaches."},{"metadata":{},"cell_type":"markdown","source":"## About brand"},{"metadata":{"trusted":true},"cell_type":"code","source":"bottler_brands = base_df.loc[base_df.distilled_at.notnull(), 'brand'].unique()\ntop20_cnt = base_df.brand.value_counts()[:20]\nprint(top20_cnt)\nprint('{} out of 20 are bottlers'.format(top20_cnt.index.isin(bottler_brands).sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top20_review_point = base_df.groupby('brand')['review_point'].mean().nlargest(20)\nprint(top20_review_point)\nprint('{} out of 20 are bottlers'.format(top20_review_point.index.isin(bottler_brands).sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What I found\n1. I need to study much more about whiskies. There are many brands I don't know.\n1. Means of review points per brand are not trustful if there are few samples behind them. I'll check it later."},{"metadata":{},"cell_type":"markdown","source":"## What I want to do later\n1. Find my interesting whiskies by words in description.\n1. Making the review point regressor with description."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}