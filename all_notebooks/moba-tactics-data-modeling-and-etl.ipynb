{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Before start:\n\nThis analysis presumes some basic knowledges in the PC game League of Legends, so before you preoceed, here is a brief introduction to some of the conepts in the game:\n\n* League of Legends: a MOBA（Multiplayer Online Battle Arena）game which is typically 5V5, meaning 10 users form 2 groups and fight against each other, whichever group destroy the opponent's base first, wins the game\n* Champion: each user controls a unique champion in the game, and often times champions in a team will need to collbaroate well to win\n* Objectives: monsters which both teams will try to slay, as they will bring massive benefits in order to win a game.\n    1. Baron Nashor: Baron Nashor is the most powerful monster in the jungle.\n    2. Drakes(Dragons): Drakes, or dragons, are powerful monsters that grant unique bonuses depending on the element of the drake your team slays.\n* items: purchasble equipment of a champion in game,by using gold earned from various ways\n* vision: in order to see opponents on the map, a team must have visions, which can be done by placing wards\n* wards: a prop to plant by champion, which will give your team vision in a certain area on the map\n\n    \n***\nSource: https://leagueoflegends.fandom.com/wiki/League_of_Legends_Wiki, https://euw.leagueoflegends.com/en-gb/how-to-play/\n***","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Statistically Winning League of Legends\n\n## Project Summary\nHow to win a LOL(League of Legends) game, if you are not a mechanical player like Rookie, Uzi, or Faker? One way to make it, although less creatively, is copying what the winning others are doing.\n\nThis project explores 100,800 high ranked games in the KR(Korean) server, and trying to help to answer few questions that puzzled many players:\n\n* Who are the best buddies in champions?\n* What is the best build(items) of a champion?\n* Which is more important, dragon soul (getting 4 dragons) or Baron Nashor?\n* Does vision control really improve chances of winning?\n\n**In general, the final result will provide input for analysis of a LOL game in 3 dimensions: champion compositions, champion item builds, and team objetives/visions control**\n\nThe project follows the follow steps:\n* Step 1: Scope the Project and Gather Data\n* Step 2: Explore and Assess the Data\n* Step 3: Define the Data Model\n* Step 4: Run ETL to Model the Data\n* Step 5: Complete Project Write Up","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n!pip install psycopg2\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle # data processing, pickle file I/O\nimport json # data processing, json file I/O\nimport random # data quality testing\nimport psycopg2 # establish aws Redshift connection\nimport sqlalchemy # copy pd dataframe to Redshift \nfrom sqlalchemy.types import * # load staging_tables\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Scope the Project and Gather Data\n\n#### Scope \n\nThe end-result is prepared for a backend of game analytics, to give suggestions on winning strategies. The two sources of data are: [League of Legends(LOL) - Ranked Games 2020](https://www.kaggle.com/gyejr95/league-of-legendslol-ranked-games-2020-ver1?select=match_data_version1.csv), a Kaggle dataset; [Data Dragon of Patch 10.15.1](https://ddragon.leagueoflegends.com/cdn/dragontail-10.15.1.tgz), LOL game data and assets from Riot(LOL's monther company).\n\nThe end solution will be a database in aws RDS Postgres, containing the data to full solutions of each question.\n\nSome Python analytic libraries are used in imports.\n\n#### Describe and Gather Data \nThe Kaggle dataset contains 10,800 game data in the KR server, the Data Dragon (meta_champs & meta_items) contains all the in-game data up to patch 10.15.1, which is the latest version of game by Aug. 2, 2020.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"read 3 match data pickle files, `match_df` contains participants for both the winning and losing side of a match; `winnder_df` contains in-game stats and objetives info for the winning team of a match; `loser_df` contains the same info for the losing side","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"match_df = pd.read_pickle('../input/league-of-legendslol-ranked-games-2020-ver1/match_data_version1.pickle')\nwinner_df =  pd.read_pickle('../input/league-of-legendslol-ranked-games-2020-ver1/match_winner_data_version1.pickle')\nloser_df = pd.read_pickle('../input/league-of-legendslol-ranked-games-2020-ver1/match_loser_data_version1.pickle')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match_df['gameVersion'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"winner_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loser_df.info() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"read the meda_*.json files, which contains info about all LOL in-game entities(e.g. champs, items, etc.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_champs = pd.read_json('../input/league-of-legendslol-data-dragon-en-us10151/en_US-10.15.1/meta_champion.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_champs.iloc[0]['data']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"the only info we need from the `meta_champs` is, the key-name mapping of each champion, becuase it is used in all match tables above.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"similarly, we also need the 'key-name' mapping of each item from `meta_items`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/league-of-legendslol-data-dragon-en-us10151/en_US-10.15.1/meta_item.json') as f:\n    data = json.load(f)\nmeta_items = pd.read_json(json.dumps(data['data']), orient='index')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_items.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_items.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 2: Explore and Assess the Data\n#### Explore the Data \n\nProblems:\n1. **NaN** `win` in `loser_df`\n2. `gameMode` in `match_df`, we should only need one of the game mode, **classic**, which is the ranked games we are focusing on\n3. **remake** games in LOL\n\n#### Cleaning Steps\n\n`gameId` is the foreign key in `match_df`, we will use the field to drop records of the same match in 3 dfs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Issue 1*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loser_df['win'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"12 values in the `win` field of `loser_df` is **NaN**, presumably they should be **Fail** instead\n\nwe try to find their opponents by `gameId` (the foreign key in both dfs) in `winnder_df`, and see if these are actually just missing values\n\nalso we can look at the full match in `match_df`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loser_df[loser_df['win'].isna() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missingVals = loser_df[loser_df['win'].isna() == True]['gameId'].tolist()\nwinner_df[winner_df['gameId'].isin(missingVals)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match_df[match_df['gameId'].isin(missingVals)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"all games are in **TUTORIAL_MODULE_1**, which is a tutorial instead of a matched game in LOL\n\nfor comparison, let's look a random set of rows in `loser_df` and `match_df`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"randomlist = []\nfor i in range(10):\n    n = random.randint(0, 108828)\n    randomlist.append(n)\nprint(randomlist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match_df[match_df['gameId'].isin(loser_df.iloc[randomlist]['gameId']).tolist()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"one quick obersvation is the dramatic difference in `gameDuration` between the random set and the win == NaN set, unfortunately I did not find any doc on `gameDuration` in Riot API\n\nthe guess I take here is the **unit** is in `gameDuration` is second(s), it would be reasonable considering the set of `gameDuration` values in the random set we just created:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_gameDuration = np.average(match_df[match_df['gameId'].isin(loser_df.iloc[randomlist]['gameId']).tolist()]['gameDuration'].values)\nprint('if unit in mins: {:.2f} mins'.format(avg_gameDuration))\nprint('if unit in sec: {:.2f} mins'.format(avg_gameDuration/60))\nprint('if unit in milisec: {:.2f} mins'.format(avg_gameDuration * 1.6666666666667E-5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"around **20.00 mins** seems to be a reasonable guess for what an average LOL game would take, the other two seem way short or long","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_NaNgameDura = np.average(match_df[match_df['gameId'].isin(missingVals)]['gameDuration'].values)\nprint('NaN games avg: {:.2f} mins'.format(avg_NaNgameDura/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"these games are way too short to be meaningful in the analysis, and the missing `win` field might have been a direct result of this\n\nwe should drop all these match records","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"winner_df = winner_df[~winner_df['gameId'].isin(missingVals)]\nloser_df = loser_df[~loser_df['gameId'].isin(missingVals)]\nmatch_df = match_df[~match_df['gameId'].isin(missingVals)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"*Issue 2*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"match_df['gameMode'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"only classic games are needed, we should drop all other game modes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gameId_CLASSIC =  match_df[match_df['gameMode'] == 'CLASSIC'].gameId.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"winner_df = winner_df[winner_df['gameId'].isin(gameId_CLASSIC)]\nloser_df = loser_df[loser_df['gameId'].isin(gameId_CLASSIC)]\nmatch_df = match_df[match_df['gameId'].isin(gameId_CLASSIC)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"match_df.gameMode.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"*issue 3*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"if one player disconnected from a game right from the start, the team can choose to **remake** the game, meaning the match will end immediately\n\n**remake** should not be regarded the same as a loss, because the other players in the team just did not want a 4v5 situation\n\nwe should identify the **remake** games from `match_df`, as they affect our win/loss analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"a team can only choose to **reamke** in the first 15 mins of the game, after that the **reamke** attempt becomes an **early surrender**(which is just the same as a loss)\n\nalso in reality, rarely a game at this ranking level would finish before 15 mins, unless someone disconnected\n\nso if `gameDuration` in `match_df` <= **15 mins**, we can almost be certain that the game is a **remake**\n\nwe will drop these games","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gameId_remake = match_df.query('gameDuration <= 15*60').gameId.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"winner_df = winner_df[~winner_df['gameId'].isin(gameId_remake)]\nloser_df = loser_df[~loser_df['gameId'].isin(gameId_remake)]\nmatch_df = match_df[~match_df['gameId'].isin(gameId_remake)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('now the shortest game in df is {:.2f} mins'.format(match_df.gameDuration.min() / 60))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 3: Define the Data Model\n#### 3.1 Conceptual Data Model\n\n[data_modeling.pdf](https://drive.google.com/file/d/1c0jzrDSiblRn2QPkbWr1oUKnhDp8BVD_/view?usp=sharing)\n\nthe fact-dimensional modeling would fit the need of this project well, because the ouput was produced to support the analysis of each match(fact), and dimensions such as champ compositions, vision controls\n\n\n#### 3.2 Mapping Out Data Pipelines\n\nthe original data resides in Kaggle, after fixing some data quality issues, they will be loaded into an aws RDS postgres database\n\n\n- create and connect to postgres\n- crete each fact/dimension in postgres\n- load dimension tables first, then the fact table","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Step 4: Run Pipelines to Model the Data \n#### 4.1 Create the data model\nBuild the data pipelines to create the data model.\n\nthe bulk of data is very time-consuming to load to the postgres database first due to the network constraint, yet the sql dataabse has greater computing power for transforming the database (from staging tables to final tables)\n\nwe will load the staging_tables in Postgres first","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# kaggle's add-in is used to store Postgres database's access info\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ndbname= user_secrets.get_secret(\"dbname\")\nhost = user_secrets.get_secret(\"host\")\npassword = user_secrets.get_secret(\"password\")\nport = user_secrets.get_secret(\"port\")\nuser = user_secrets.get_secret(\"user\")\n\nconn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(host, dbname, user, password, port))\nconn.autocommit = True\ncur = conn.cursor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# in the meta_dfs, we only need the key-name mapping, all other columns are dropped\nmeta_items = meta_items[['name']]\nmeta_champs['key'] = meta_champs.apply(lambda row: row.data['key'], axis=1)\nmeta_champs = meta_champs[['key']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# column name/datatype of each staging table defined, used in loading_staging_tables\nmatch_dict = {'gameCreation': Float(), 'gameDuration': Float(), 'gameId': Float(), 'gameMode': String(), 'gameType': String(), 'gameVersion': String(), \\\n             'mapId': Float(), 'participantIdentities': JSON(), 'participants': JSON(), 'platformId': String(), 'queueId': Float(), 'sessionId': Float(), \\\n             'status.message': String(), 'status.status_code': Float()}\nwinner_dict = {'teamId': Integer(), 'win': String(), 'firstBlood': Boolean(), 'firstTower': Boolean(), 'firstInhibitor': Boolean(), 'firstBaron': Boolean(), \\\n              'firstDragon': Boolean(), 'firstRiftHerald': Boolean(), 'towerKills': Integer(), 'inhibitorKills': Integer(), 'baronKills': Integer(), \\\n              'dragonKills': Integer(), 'vilemawKills': Integer(), 'riftHeraldKills': Integer(), 'dominionVictoryScore': Integer(), 'bans': JSON(), \\\n              'gameId': Float()}\nloser_dict = winner_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop tables outlined in the 'data_modeling.pdf', in case a restart is needed\ndef drop_tables(cur):\n    games_table_drop = \"DROP TABLE IF EXISTS games\"\n    champions_table_drop = \"DROP TABLE IF EXISTS champions\"\n    items_table_drop = \"DROP TABLE IF EXISTS items\"\n    objectives_visions_table_drop = \"DROP TABLE IF EXISTS objectives_visions\"\n    champion_key_table_drop = \"DROP TABLE IF EXISTS champion_key\"\n    item_key_table_drop = \"DROP TABLE IF EXISTS item_key\"\n    \n    # execute all queries defined\n    drop_table_queries = [games_table_drop, champions_table_drop, items_table_drop, objectives_visions_table_drop, champion_key_table_drop, item_key_table_drop]\n    for query in drop_table_queries:\n        cur.execute(query)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop tables outlined in the 'data_modeling.pdf', in case a restart is needed\ndef drop_staging_tables(cur):\n    staging_match_table_drop = \"DROP TABLE IF EXISTS staging_match\"\n    staging_winner_table_drop = \"DROP TABLE IF EXISTS staging_winner\"\n    staging_loser_table_drop = \"DROP TABLE IF EXISTS staging_loser\"\n    staging_meta_champs_table_drop = \"DROP TABLE IF EXISTS staging_meta_champs\"\n    staging_meta_items_table_drop = \"DROP TABLE IF EXISTS staging_meta_items\"\n    \n    # execute all queries defined\n    drop_table_queries = [staging_match_table_drop, staging_winner_table_drop, staging_loser_table_drop, staging_meta_champs_table_drop, staging_meta_items_table_drop]\n    for query in drop_table_queries:\n        cur.execute(query)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create and insert staging tables\ndef load_staging_tables(conn):\n    \n    conn = sqlalchemy.create_engine('postgresql://{}:{}@{}:{}/{}'.format(user, password, host, port, dbname))\n    \n    print('loading staging_match')\n    match_df.to_sql('staging_match', conn, index=False, if_exists='replace', dtype=match_dict)\n    \n    print('loading staging_winner')\n    winner_df.to_sql('staging_winner', conn, index=False, if_exists='replace', dtype=winner_dict)\n    \n    print('loading staging_loser')\n    loser_df.to_sql('staging_loser', conn, index=False, if_exists='replace', dtype=loser_dict)\n    \n    print('loading staging_meta_champs')\n    meta_champs.to_sql('staging_meta_champs', conn, index=True, if_exists='replace')\n    \n    print('creating staging_meta_items')\n    meta_items.to_sql('staging_meta_items', conn, index=True, if_exists='replace')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create tables outlined in the 'data_modeling.pdf'\ndef create_tables(cur):\n    games_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS games(game_id bigint PRIMARY KEY, game_duration float NOT NULL, game_version varchar NOT NULL, participants varchar[10] NOT NULL)\n    \"\"\")\n    champions_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS champions(game_id bigint PRIMARY KEY, champ_1 int NOT NULL, champ_2 int NOT NULL, champ_3 int NOT NULL, champ_4 int NOT NULL, champ_5 int NOT NULL, champ_6 int NOT NULL, champ_7 int NOT NULL, champ_8 int NOT NULL, champ_9 int NOT NULL, champ_10 int NOT NULL)\n    \"\"\")\n    items_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS items(game_id bigint PRIMARY KEY, build_1 int[6] NOT NULL, build_2 int[6] NOT NULL, build_3 int[6] NOT NULL, build_4 int[6] NOT NULL, build_5 int[6] NOT NULL, build_6 int[6] NOT NULL, build_7 int[6] NOT NULL, build_8 int[6] NOT NULL, build_9 int[6] NOT NULL, build_10 int[6] NOT NULL)\n    \"\"\")\n    objectives_visions_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS objectives_visions(game_id bigint PRIMARY KEY, win_dragon_soul boolean NOT NULL, win_baron_nashor boolean NOT NULL, win_ward_placed int NOT NULL, win_ward_destroyed int NOT NULL, lose_dragon_soul boolean NOT NULL, lose_baron_nashor boolean NOT NULL, lose_ward_placed int NOT NULL, lose_ward_destroyed int NOT NULL)\n    \"\"\")\n    champion_key_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS champion_key(champion_key bigint PRIMARY KEY, champion_name varchar NOT NULL)\n    \"\"\")\n    item_key_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS item_key(item_key bigint PRIMARY KEY, item_name varchar NOT NULL)\n    \"\"\")\n\n    # execute all queries defined\n    create_table_queries = [games_table_create, champions_table_create, items_table_create, objectives_visions_table_create, champion_key_table_create, item_key_table_create]\n    for query in create_table_queries:\n        cur.execute(query)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# the next cell should only be ran when running ETL for the first time, as we are recreating all tables ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('drop staging tables')\ndrop_staging_tables(cur)\nprint('dropping fact/dimension tables')\ndrop_tables(cur)\nprint('creating staging tables')\nload_staging_tables(cur)\nprint('creating fact/dimension tables')\ncreate_tables(cur)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all tables created\ncur.execute(\"\"\"SELECT table_name FROM information_schema.tables\n       WHERE table_schema = 'public'\"\"\")\nfor table in cur.fetchall():\n    print(table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"display all staging tables with their columns/datatypes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = 75\ncur.execute(\"\"\"SELECT table_name, column_name, data_type FROM information_schema.columns WHERE table_name LIKE 'staging_%'\"\"\")\npd.DataFrame(cur.fetchall(), columns=['table_name', 'column_name', 'data_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"1. champions table\n\n**champ1 - champion 10**  is stored in `staging_match`, we can retreive them and the **gameId** of each 10 **champX**\n\nthe `champions_table_value` statement looks a bit complicated, due to the nature of json array column in psotgres","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"champions_table_value = \"\"\"\nSELECT tb2.game_id, tb2.champ_ids[1], tb2.champ_ids[2], tb2.champ_ids[3], tb2.champ_ids[4],tb2.champ_ids[5],\ntb2.champ_ids[6], tb2.champ_ids[7], tb2.champ_ids[8], tb2.champ_ids[9], tb2.champ_ids[10]\nFROM\n(SELECT tb.game_id AS game_id, array_agg(tb.c ORDER BY tb.i ASC)::jsonb[]::int[] AS champ_ids FROM \n(SELECT \"gameId\" AS game_id, \njson_array_elements(participants) -> 'championId' AS c, \ncast(json_array_elements(participants) -> 'participantId' as jsonb)::int AS i FROM staging_match) AS tb \nGROUP BY tb.game_id) AS tb2 ORDER BY tb2.game_id\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"champions_table_insert = \"\"\"INSERT INTO champions(game_id, champ_1, champ_2, champ_3, champ_4, champ_5, \nchamp_6, champ_7, champ_8, champ_9, champ_10) {}\"\"\".format(champions_table_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"one issue is noted before the insertion can be completed: some games in the original data have mssing **champ_ids**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(champions_table_value)\na = pd.DataFrame(cur.fetchall())\na[a.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"going through the original `match_df`, we can see these games only have 6 participants\n\n(someone was 1 vs 5 in those games)\n\nthey are not valid for our database, nor the anaysis to be performed\n\ndelete these rows from `staging_match`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"game_with_missing_champ_ids = list(a[a.isnull().any(axis=1)][0].array)\nfor game in range(len(game_with_missing_champ_ids)):\n    total_participants = len(match_df[match_df['gameId'].isin(game_with_missing_champ_ids)].iloc[game].participants)\n    print('game {} has: {} participants'.format(game_with_missing_champ_ids[game], total_participants))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete game with not 10 participants\ncur.execute(\"\"\"DELETE FROM staging_match WHERE \"gameId\" IN %s\"\"\", (tuple(game_with_missing_champ_ids),))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(champions_table_value)\na = pd.DataFrame(cur.fetchall())\na[a.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"all games are valid now, we can proceed with the insertion","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(champions_table_insert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(\"\"\"SELECT * FROM champions LIMIT 3\"\"\")\ncur.fetchall()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. items table\n\nall builds/items info can be retrieved from `staging_match` as well","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"items_table_value = \"\"\"\nSELECT game_id, i[1:1], i[2:2], i[3:3], i[4:4], i[5:5], i[6:6], i[7:7], i[8:8], i[9:9], i[10:] FROM\n(SELECT game_id AS game_id, ((array_agg(array[i0,i1,i2,i3,i4,i5,i6])))::jsonb[]::int[] AS i FROM\n(SELECT game_id AS game_id, p ->'item0' AS i0, p -> 'item1' AS i1, p ->'item2' AS i2, p ->'item3' AS i3, \np ->'item4' AS i4,p ->'item5' AS i5,p ->'item6' AS i6\nFROM  (SELECT \"gameId\" AS game_id, json_array_elements(participants) -> 'stats' AS p FROM staging_match) AS tb1) AS tb2 \nGROUP BY game_id) AS tb3 ORDER BY game_id\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items_table_insert = \"\"\"INSERT INTO items(game_id, build_1, build_2, build_3, build_4, build_5, \nbuild_6, build_7, build_8, build_9, build_10) {}\"\"\".format(items_table_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(items_table_insert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(\"\"\"SELECT * FROM items LIMIT 3\"\"\")\ncur.fetchall()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. objectives_visions table\n\nobjective kills can be retreived from `staging_loser` and `staging_winner`, and visions placed/destroyed can be retreived from `staging_match`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"objectives_visions_table_value = \"\"\"\nSELECT game_id, \nCASE WHEN wdk >= 4 THEN TRUE ELSE FALSE END AS win_dragon_soul,\nCASE WHEN wbk > 0 THEN TRUE ELSE FALSE END AS win_baron_nashor,\nwwp AS win_ward_placed, wwk AS win_ward_killed,\nCASE WHEN ldk >= 4 THEN TRUE ELSE FALSE END AS lose_dragon_soul,\nCASE WHEN lbk > 0 THEN TRUE ELSE FALSE END AS lose_baron_nashor,\nlwp AS lose_ward_placed, lwk AS lose_ward_killed\nFROM \n(SELECT game_id AS game_id,\navg(wdk)::int AS wdk, avg(wbk)::int AS wbk, \nsum(wp::jsonb::int) FILTER (WHERE win::jsonb::boolean IS TRUE) AS wwp,\nsum(wk::jsonb::int) FILTER (WHERE win::jsonb::boolean IS TRUE) AS wwk,\navg(ldk)::int AS ldk, avg(lbk)::int AS lbk,\nsum(wp::jsonb::int) FILTER (WHERE win::jsonb::boolean IS FALSE) AS lwp,\nsum(wk::jsonb::int) FILTER (WHERE win::jsonb::boolean IS FALSE) AS lwk\nFROM (SELECT m.\"gameId\" AS game_id,\njson_array_elements(participants) #> '{stats, win}' AS win,\nw.\"baronKills\" AS wbk, w.\"dragonKills\" AS wdk,\njson_array_elements(participants) #> '{stats, wardsPlaced}' AS wp,\njson_array_elements(participants) #> '{stats, wardsKilled}' AS wk,  \nl.\"baronKills\" AS lbk, l.\"dragonKills\" AS ldk\nFROM staging_match AS m  \nINNER JOIN staging_winner AS w ON (m.\"gameId\" = w.\"gameId\") \nINNER JOIN staging_loser AS l ON (m.\"gameId\" = l.\"gameId\")\nORDER BY game_id\n) AS tb1 GROUP BY game_id) AS tb3\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"objectives_visions_table_insert = \"\"\"INSERT INTO objectives_visions(game_id, win_dragon_soul, win_baron_nashor, win_ward_placed, win_ward_destroyed, \nlose_dragon_soul, lose_baron_nashor, lose_ward_placed, lose_ward_destroyed) \n{}\"\"\".format(objectives_visions_table_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(objectives_visions_table_insert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(\"\"\"SELECT * FROM objectives_visions LIMIT 3\"\"\")\ncur.fetchall()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"4. champion_key table\n\nretreived from `staging_meta_champs`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"champion_key_table_value = \"\"\"SELECT key::int, index FROM staging_meta_champs ORDER BY key::int\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"champion_key_table_insert = \"\"\"INSERT INTO champion_key(champion_key, champion_name) {}\"\"\".format(champion_key_table_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(champion_key_table_insert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(\"\"\"SELECT * FROM champion_key LIMIT 10\"\"\")\ncur.fetchall()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"5. `item_key` table\n\ncan be retreived from `staging_meta_items`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"item_key_table_value = \"\"\"SELECT index, name FROM staging_meta_items ORDER BY index\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_key_table_insert = \"\"\"INSERT INTO item_key(item_key, item_name) {}\"\"\".format(item_key_table_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(item_key_table_insert)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6 `games` table\n\ncan be retreived from `staging_match`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_table_value = \"\"\"\nSELECT game_id, game_duration, game_version, array_agg(a) AS participants FROM\n(SELECT \"gameId\" AS game_id, \"gameDuration\" AS game_duration, \"gameVersion\" AS game_version, \njson_array_elements(\"participantIdentities\") #> '{player, accountId}' AS a\nFROM staging_match) AS tb1\nGROUP BY game_id, game_duration, game_version\nORDER BY game_id\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_table_insert = \"\"\"INSERT INTO games(game_id, game_duration, game_version, participants) {}\"\"\".format(games_table_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(games_table_insert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cur.execute(\"\"\"SELECT * FROM games LIMIT 3\"\"\")\ncur.fetchall()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.2 Data Quality Checks\n * Integrity constraints: satisfied by the **NOT NULL** and **PRIMARY KEY** definition in the table **CREATE** queries\n * Source/Count: all fact/dimension tables should have equal rows and order of ids in this case","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"we first examine the data types of each fact/dimension table","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# print data type of 'games'\ncur.execute(\"\"\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'games' \"\"\")\npd.DataFrame(cur.fetchall(), columns=['column_name', 'data_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print data type of 'champions'\ncur.execute(\"\"\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'champions' \"\"\")\npd.DataFrame(cur.fetchall(), columns=['column_name', 'data_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print data type of 'items'\ncur.execute(\"\"\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'items' \"\"\")\npd.DataFrame(cur.fetchall(), columns=['column_name', 'data_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print data type of 'objectives_visions'\ncur.execute(\"\"\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'objectives_visions' \"\"\")\npd.DataFrame(cur.fetchall(), columns=['column_name', 'data_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print data type of 'champion_key'\ncur.execute(\"\"\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'champion_key' \"\"\")\npd.DataFrame(cur.fetchall(), columns=['column_name', 'data_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print data type of 'item_key'\ncur.execute(\"\"\"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'item_key' \"\"\")\npd.DataFrame(cur.fetchall(), columns=['column_name', 'data_type'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test if fact and dimension tables have equal number of rows","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# count rows of table\ncount_rows = \"\"\"\nSELECT\n(SELECT count(*) FROM games) AS g,\n(SELECT count(*) FROM champions) AS c,\n(SELECT count(*) FROM items) AS i,\n(SELECT count(*) FROM objectives_visions) AS o\n\"\"\"\ncur.execute(count_rows)\ncur.fetchall()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"select some random samples across the fact and 'staging_match' table\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_games_samples = \"\"\"\nSELECT \"gameDuration\" AS sm_gd, gd, \"gameVersion\" AS sm_gv, gv FROM staging_match, \n(SELECT g.game_id AS game_id, g.game_duration AS gd, g.game_version AS gv FROM games AS g ORDER BY random() LIMIT 3) AS tb1\nWHERE \"gameId\" IN (game_id)\n\"\"\"\ncur.execute(random_games_samples)\ncur.fetchall()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the data matched exactly\n\nnow print two **random** rows of each fact/dimension table","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# print two random rows of 'games'\ncur.execute(\"\"\"SELECT column_name FROM information_schema.columns WHERE table_name = 'games' \"\"\")\ncolumns = cur.fetchall()\ncur.execute(\"\"\"SELECT * FROM games ORDER BY random() LIMIT 2\"\"\")\npd.DataFrame(cur.fetchall(), columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print two random rows of 'champions'\ncur.execute(\"\"\"SELECT column_name FROM information_schema.columns WHERE table_name = 'champions' \"\"\")\ncolumns = cur.fetchall()\ncur.execute(\"\"\"SELECT * FROM champions ORDER BY random() LIMIT 2\"\"\")\npd.DataFrame(cur.fetchall(), columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print two random rows of 'items'\ncur.execute(\"\"\"SELECT column_name FROM information_schema.columns WHERE table_name = 'items' \"\"\")\ncolumns = cur.fetchall()\ncur.execute(\"\"\"SELECT * FROM items ORDER BY random() LIMIT 2\"\"\")\npd.DataFrame(cur.fetchall(), columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print two random rows of 'objectives_visions'\ncur.execute(\"\"\"SELECT column_name FROM information_schema.columns WHERE table_name = 'objectives_visions' \"\"\")\ncolumns = cur.fetchall()\ncur.execute(\"\"\"SELECT * FROM objectives_visions ORDER BY random() LIMIT 2\"\"\")\npd.DataFrame(cur.fetchall(), columns=columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"all rows seemed valid\n\nnow the two key-name mapping tables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# print two random rows of 'champion_key'\ncur.execute(\"\"\"SELECT column_name FROM information_schema.columns WHERE table_name = 'champion_key' \"\"\")\ncolumns = cur.fetchall()\ncur.execute(\"\"\"SELECT * FROM champion_key ORDER BY random() LIMIT 2\"\"\")\npd.DataFrame(cur.fetchall(), columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print two random rows of 'item_key'\ncur.execute(\"\"\"SELECT column_name FROM information_schema.columns WHERE table_name = 'item_key' \"\"\")\ncolumns = cur.fetchall()\ncur.execute(\"\"\"SELECT * FROM item_key ORDER BY random() LIMIT 2\"\"\")\npd.DataFrame(cur.fetchall(), columns=columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.3 Data dictionary ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### games - fact table\n\n- **game_id**: game id of each LOL game, loaded from `staging_match`\n- **game_duration**: duration of each LOL game, loaded from `staging_match`\n- **participants**: each accont id of the 10 participants in a game, loaded from `staging_match` -> `player` -> `accountId`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### champions\n\n- **game_id**: same as in fact table\n- **champ_1 - champ_5**: 5 champions from the winning team, order not specified, loaded from `staging_match` -> `participants` -> `championId`\n- **champ_6 - champ_10**: 5 champions from the losing team, same conditions applied ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### items\n\n- **game_id**: same as in fact table\n- **build_1 - build_ 5**: builds from the winning team, each build has 7 items (any 'item' = 0 means the build has less than 7 items), order followed the one in `champions,` loaded from `staging_match` -> `participants` -> `item[0-6]`\n- **build_6 - build_ 10**:builds from the losing team, same conditions applied","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### objectives_visions\n\n- **game_id**: same as in fact table\n- **win_drag_soul**: if a winning team had killed >= 4 dragons, they have a dragon soul; otherwise they don't\n- **win_baron_nashor**: if a winning had killed baron nashor at least once, they have baron nashor: otherwise they don't\n- **win_ward_placed**: sum of wards placed from 5 participants in the winning team, thorughout the game\n- **win_ward_killed**: sum of wards destroyed from 5 participants in the winning team, throughout the game\n- **lose_\\***: same conditions applied\n\n\nnote: all data were from `staging_winner` and `stagin_loser`, but the actual path of each field included some SQL func and agg, and for the sake of readabiity I would not outline them here; pleaser refer back to the query `objectives_visions_value` ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### champion_key\n\n- **champion_key**: integer key used in the `champion` table, loaded from `staging_meta_champions` -> `key`\n- **champion_name**: text mapping of champion_key, loaded from `staging_meta_champions` -> `index`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### item_key\n\n- **item_key**: integer key used in the `items` table, loaded from `staging_meta_items` -> `index`\n- **item_name**: text mapping of item_key, loaded from `staging_meta_items` -> `name`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Step 5: Project Write Up","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**the rationale for the choice of tools and technologies**: Originally the desired tool for data with this scale would be something like AWS Redshift, while Redshift did not offer to stoore column of composite keys (like arrays), and some advanced feature of a relational database was not supported in Redshift either for the sake of efficiency; so it turned out a relational database would be a more reaosnable choice when the data contains composite json field; AWS RDS offered a Postgres database, and while it is not as fast as Redshift in performing analytic jobs, it was easier for the ETL process\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**how often the data should be updated and why**: at least once a week, as the metrics in LOL changed very fast, the game development company relased new version in weekly basis sometimes, and trends are formed among players everyday","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**if the data was increased by 100x**: introduce Apache Spark and Airflow to the ETL process, the distribued databse of Spark would enable the scale, and Airflow would help in monitoring the ETL process since now it takes much longer\n\n**if the data populates a dashboard that must be updated on a daily basis by 7am every day**: run the ETL on a VM (like a AWS EC2) every night by using a cloudWatch, and updates the dashboard \n\n**the database needed to be accessed by 100+ people**: increase availability by using aws RDS's Multi-AZ deployment, or using Apache Spark to increase availability of distributed machines","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}