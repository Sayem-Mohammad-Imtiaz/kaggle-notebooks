{"cells":[{"source":"# 1. Introduction\n[NASA HI-SEAS](https://hi-seas.org/) missions act as a testbed and training ground for humans as we develop the capability to explore Mars. \nA recent NASA Space Apps Challenge hackathon asked participants to use data collected from the HI-SEAS site to predict solar radiation given a set of measurable meteorological conditions.\nKnowing when conditions are most favorable for incident solar radiation is crucial for deciding when and where to deploy solar energy harvesting equipment, especially for colonists or astronauts on the surface of Mars.\n\nThe original Kaggle dataset & competition can be found here: https://www.kaggle.com/dronio/SolarEnergy\n\n## 1.1. Scenario\nWe are participants in a NASA HI-SEAS (Hawaiâ€™i Space Exploration Analog and Simulation) mission, simulating a human settlement on Mars. \n\nA large solar array and battery bank are installed at the settlement and are the only power source available.\nOn sunny days, the array collects enough energy to power the entire settlement and recharge the battery bank.\nThe battery bank is used (sparingly) at night and on overcast days.\nThere is a strict power budget for operations each day to make sure vital equipment stays online, and we also have a number of experiments to run.\n\nWe have been collecting data at our settlement since the end of the last HI-SEAS mission in September, 2016.\nIt is now January, 2017, and our mission is about to begin.\n\nCan we model solar radiation as a function of the information our sensors can gather, based on previously collected data?\n\n## 1.2. About this dataset\nThese datasets are meteorological data from the HI-SEAS weather station from four months (September through December 2016) between Mission IV and Mission V.\n\nFor each dataset, the fields are:\n\nA row number (1-n) is useful in sorting this export's results The UNIX time_t date (seconds since Jan 1, 1970). Useful in sorting this export's results with other export's results The date in `yyyy-mm-dd` format The local time of day in `hh:mm:ss` 24-hour format The numeric data, if any (may be an empty string) The text data, if any (may be an empty string)\n\nThe units of each dataset are:\n\n* Solar radiation: watts per meter^2\n* Temperature: degrees Fahrenheit\n* Humidity: percent\n* Barometric pressure: Hg\n* Wind direction: degrees\n* Wind speed: miles per hour\n* Sunrise/sunset: Hawaii time\n\n## 1.3. About this kernel\nThe purpose of this kernel is to explore this dataset and apply basic machine learning techniques in order to predict solar radiation given a set of weather conditions.\n\n__Assumptions__\n* In an application of this model, predicted meterological data (hourly temperature and humidity, for example) would be used as inputs (rather than using the model as a true predictor).\n* Effects of rain and cloud cover are neglected, except those which are indirectly measured by temperature, pressure, and humidity.\n* The sun angle with regard to the solar array is neglected. While it could be derived from the location of HI-SEAS and date-time data, this adds too much complexity to the problem for now.\n\nThis is my first foray into the world of data science and machine learning (ML). \nAs such, it is expected that the following code will not be optimized for memory, runtime, or readability.\nHowever, the result is still expected to be at worst interesting, at most useful.\n\nI have decided to use Python 3 since it is widely used for data science, a versatile and useful language (even outside of data processing and ML), and a new language to me -- I'd like the practice.\n\n## 1.4. Thanks\nI would like to thank the following groups and individuals for providing the tutorials, resources, and inspiration to conduct this study.\n* [NASA & Kaggle](https://www.kaggle.com/dronio/SolarEnergy), for providing this dataset.\n* [sentdex on YouTube](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v), for his incredible series on machine learning and everything else Python.\n* Sarah Linden, for encouraging me to do engineering projects in my free time.","metadata":{"_uuid":"766f1736869ca9581631057b4287185beaeb3b35","_cell_guid":"00e818a4-b454-4107-94c2-263b87285f9f"},"cell_type":"markdown"},{"source":"# 2. Preprocessing the data\nBefore applying any machine learning techniques, the input data must be ingested and conditioned.\nNot all the data provided is useful!","metadata":{"_uuid":"f5696e16c9c1d1ace509ec020b92cfbd229fe231","_cell_guid":"ebd88f30-26a3-4a25-9e40-85471ae25176"},"cell_type":"markdown"},{"source":"## 2.1. Defining Features and Labels\nMachine learning algorithms operate on _features_ to predict _labels_.\n\n* A __feature__ is an attribute of the system that affects the output. \nFeatures act as \"inputs\" to the model.\nIdeally, features are _independent_ variables.\n* A __label__ is the value being predicted. \nLabels act as \"outputs\" of the model.\n\nNow, let's consider our scenario. \nRecall the available data:\n* Date\n* Time of Day \n* Solar Radiation\n* Temperature\n* Pressure\n* Humidity\n* Wind Direction\n* Wind Speed\n* Time at Sunrise\n* Time at Sunset\n\n### 2.1.1. Features\nAt every timestamp within each day, there are values for all other variables.\nNo other variables impact the values of time or date.\nTherefore __date__ and __time of day__ are _independent_ variables.\n\nFor each date, there is _one_ value for `Time at Sunrise` and `Time at Sunset`. \nThe difference of these values yields the length of a given day, which is directly related to the date.\nMore exploration of the dataset is needed to determine if the length of a given date supersedes `date` in the amount of useful information it provides.\n\nTemperature, pressure, and humidity do not directly affect one another significantly, but since they are all properties which describe the local atmosphere, they do not vary independently from one another.\nSimilarly, all three of these variables have a stong relationship to time of day. \n\nTherefore we consider the following variables to be _features_ to the machine learning algorithm:\n* Date (or Length of Day)\n* Time of day\n* Temperature\n* Pressure\n* Humidity\n* Wind Speed\n* Wind Direction\n\nFurther exploration of the dataset may modify this list, but for now this is our best guess.\n\n### 2.1.2. Labels\nThe goal is to model solar radiation based on the available features, so it makes sense for `radiation` to be the algorithm's label. \nRecorded radiation measurements serve as the truth values to train and test the supervised machine learning algorithm.","metadata":{"_uuid":"08b5892f5c44c03b84ca149bc684f69d96580b47","_cell_guid":"58e518bb-4f8a-4492-bdc6-0743966f0e0f"},"cell_type":"markdown"},{"source":"## 2.2. Importing the Data\nFirst, all of the data is loaded in as the appropriate data types.\nThe column `Data` contains a single, unchanging timestamp. This appears to be the dat the dataset was published, but that is unclear.\nFor our purposes, this is not useful information and the column is removed from the dataset.\n\nTime of day, sunrise, and sunset values are converted to `datetime` objects which are stored as timezone naive UNIX time values (we can always translate it back later).","metadata":{"_uuid":"54c3e1d0847af287f6769e8e8adb4439a9e8a3ad","_cell_guid":"0e6e8905-4d3e-406c-9558-4038afe68e96"},"cell_type":"markdown"},{"source":"## IMPORT LIBRARIES\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pytz # timezones\n\ndef ingest_data(filename):\n    '''Read data from a CSV file and construct a pandas DataFrame\n    Inputs:\n        filename as string\n    Outputs:\n        df as DataFrame\n    '''\n    # read csv file\n    df = pd.read_csv(filename)\n\n    # 'Data' column is unused. All elements contain the same value.\n    # 'Time' is redundant and superseded by UNIXTime.\n    df.drop(['Data','Time'],axis=1,inplace=True)\n\n    # interpret columns as appropriate data types to ensure compatibility\n    df['UNIXTime']      = pd.to_datetime(df['UNIXTime'],unit='s')\n    df['Radiation']     = df['Radiation'].astype(float)\n    df['Temperature']   = df['Temperature'].astype(float) # or int\n    df['Pressure']      = df['Pressure'].astype(float)\n    df['Humidity']      = df['Humidity'].astype(int) # or int\n    df['WindDirection(Degrees)'] = df['WindDirection(Degrees)'].astype(float)\n    df['Speed']         = df['Speed'].astype(float)\n    df['TimeSunRise']   = pd.to_datetime(df['TimeSunRise'],format='%H:%M:%S')\n    df['TimeSunSet']    = pd.to_datetime(df['TimeSunSet'],format='%H:%M:%S')\n    df.rename(columns={'WindDirection(Degrees)': 'WindDirection', 'Speed': 'WindSpeed'}, inplace=True)\n\n    # compute length of each day\n    df['DayLength'] = (df['TimeSunSet']-df['TimeSunRise'])/np.timedelta64(1, 's')\n\n    # we don't need sunrise or sunset times anymore, so drop them\n    df.drop(['TimeSunRise','TimeSunSet'],axis=1,inplace=True)\n\n    # index by UNIX time\n    df.sort_values('UNIXTime', inplace=True) # sort by UNIXTime\n    df.set_index('UNIXTime',inplace=True) # index by UNIXTime\n\n    # Localize the index (using tz_localize) to UTC (to make the Timestamps timezone-aware) and then convert to Eastern (using tz_convert)\n    hawaii=pytz.timezone('Pacific/Honolulu')\n    df.index=df.index.tz_localize(pytz.utc).tz_convert(hawaii)\n\n    # assign unit labels to data keys\n    units={'Radiation':'W/m^2','Temperature':'F','Pressure':'in Hg','Humidity':'\\%','DayLength':'sec'}\n    return df, units","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"ca1af25856ea22340e380ffa2554ec2af7762b76","_cell_guid":"38f3b9fa-cdcd-41f5-a8e9-4176d11b5b41"},"cell_type":"code"},{"source":"df, units = ingest_data('../input/SolarPrediction.csv')\nprint(df.head())","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"b667360c915031347ac073c29afb80b99e78cda2","_cell_guid":"c6373913-ea10-45a7-a334-6bb5bea6e90f"},"cell_type":"code"},{"source":"Note that the `Time` column is dropped in favor of the `UNIXTime` timestamp. \nUNIX time encodes both date and time, so the `Time` column is redundant.\nUNIX time is converted from UTC to Hawaii Standard Time, then data is sorted by UNIX time.","metadata":{"_uuid":"eb6ba26dc260678cf4e641199cc982093b1d5631","_cell_guid":"1dff01a4-b81a-453e-bcf5-ea44d88b097f"},"cell_type":"markdown"},{"source":"## 2.3. Exploring the Data\nPlotting libraries are imported to visualize data.\nThen each measurement is visualized and Pearson correlations are calculated to determine which parameters have the most impact on one another.","metadata":{"_uuid":"313446670ea9d8639736c416e18bc6fd80b02066","_cell_guid":"54e42ae9-106c-427d-ac5e-03eb4d791c95"},"cell_type":"markdown"},{"source":"## IMPORT LIBRARIES\nimport numpy as np # linear algebra\nfrom scipy import stats # statistics\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting tools\nimport seaborn as sns # advanced plotting tools\nsns.set(style=\"white\")\n\n# make IPython render plots inline\n%matplotlib inline ","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"3b4cc74dc5f556b34badff17904df878e980f271","_cell_guid":"9c085f2a-149c-47c4-bbbd-6334a81a3aff"},"cell_type":"code"},{"source":"First, a basic correlation matrix is generated to weed out irrelevant data and identify the most significant features in the set.","metadata":{"_uuid":"09ebafe8b260b84c3bd533f15a0b16000a4ddc62","_cell_guid":"3e05795c-c77a-4af4-91d2-423ec74e6eb3"},"cell_type":"markdown"},{"source":"def corrPairs(df):\n    '''Pairwise correlation matrix'''\n    corr = df.corr() # Compute the correlation matrix\n    mask = np.zeros_like(corr, dtype=np.bool) # make mask\n    mask[np.triu_indices_from(mask)] = True # mask upper triangle\n    sns.heatmap(corr, mask=mask, cmap='coolwarm', center=0, square=True, linewidths=.5, annot=True, cbar=False)\n\ndf['WeekOfYear'] = df.index.week # add week to view correlation\nplt.figure(figsize=(7,7))\ncorrPairs(df)","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"d000cffd091471da59d8f76a097275574a8c7dc1","_cell_guid":"2a21edd2-0c1d-453d-a348-c09dac25cda2"},"cell_type":"code"},{"source":"Examining the stronger correlations more closely:","metadata":{"_uuid":"4e0281b2daebf051d9ba6029579ffff15b818870","_cell_guid":"3ee5b6c6-27de-4921-94e0-85ef4ddd3851"},"cell_type":"markdown"},{"source":"def corrfunc(x, y, **kws):\n    '''add pearsonr correlatioin to plots'''\n    r, _ = stats.pearsonr(x, y)\n    ax = plt.gca()\n    ax.annotate(\"r = {:.2f}\".format(r),xy=(.1, .9), xycoords=ax.transAxes, color='white')\n    return\n\ndef corrMap(df,features):\n    '''plot bivariate correlations'''\n    g = sns.PairGrid(df, vars=features)\n    g.map_upper(plt.scatter, s=10)\n    g.map_diag(sns.distplot, kde=False)\n    g.map_lower(sns.kdeplot, cmap=\"coolwarm\", shade=True, n_levels=30)\n    g.map_lower(corrfunc)\n    g.map_lower(corrfunc)","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"scrolled":true,"_uuid":"fca39d0885ba4654379b9ad35d1a8a7c3f305dc0","_cell_guid":"4cf018d5-1a00-482b-b423-862ef17c2cab"},"cell_type":"code"},{"source":"feature_list=['Radiation','Temperature','Humidity','Pressure']\n# bivariate density matrix\ncorrMap(df,feature_list)\nplt.show()","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"756a563871faa118f3108b9388b59441a9c44608","_cell_guid":"cf1e8c5e-090e-440d-958f-8a0761584fdf"},"cell_type":"code"},{"source":"There are several timescales to consider in this dataset:\n* Monthly\n* Daily\n* Hourly\n\nLooking into data by the minute is too granular to draw broad conclusions at this stage, but something to be considered when constructing the prediction algorithm.\n\nRadiation is expected vary with the date due to seasonal weather changes. \nThe dataset only contains data from autumn and winter, so the model developed from this data may be less capable of predicting radiation during the summer. \nFortunately, the seasonal climate at the HI-SEAS facility in Hawai'i is fairly consistent year-round.\n\nRecalling the most correlated features, we plot Radiation as a function of Temperature, Humidity, and Pressure on the various timescales.","metadata":{"_uuid":"52c9e07ebcd77942a2e1972a74f2c76687eff56d","_cell_guid":"3188048c-892e-4b17-8b5d-0084a49db3ab"},"cell_type":"markdown"},{"source":"def color_y_axis(ax, color):\n    '''Color y axis on two-axis plots'''\n    for t in ax.get_yticklabels():\n        t.set_color(color)\n    ax.yaxis.label.set_color(color)\n    return None\n\ndef plotVs(df,timescale,feature1,feature2,ax1,units):\n    '''Plot feature vs radiation'''\n    ax2=ax1.twinx()\n    df_grouped= df.groupby(timescale)\n\n    df_feature1 = df_grouped[feature1].mean()\n    df_feature1_errorpos =  df_feature1+df_grouped[feature1].std()/2\n    df_feature1_errorneg =  df_feature1-df_grouped[feature1].std()/2\n    ax1.plot(df_feature1)\n    ax1.fill_between(df_feature1.index, df_feature1_errorpos.values, df_feature1_errorneg.values, alpha=0.3, antialiased=True)\n    ax1.set_ylabel(feature1+' '+units[feature1])\n    color_y_axis(ax1, 'b')\n\n    if feature2 == 'Radiation':\n        rad = df_grouped['Radiation'].mean()\n        ax2.plot(rad,'r')\n        ax2.fill_between(df_feature1.index, 0, rad, alpha=0.3, antialiased=True, color='red')\n        ax2.set_ylabel('Radiation'+' '+units['Radiation'])\n        color_y_axis(ax2, 'r')\n    else:\n        df_feature2 = df_grouped[feature2].mean()\n        df_feature2_errorpos =  df_feature2+df_grouped[feature2].std()/2\n        df_feature2_errorneg =  df_feature2-df_grouped[feature2].std()/2\n        ax1.plot(df_feature2)\n        ax1.fill_between(df_feature2.index, df_feature2_errorpos.values, df_feature2_errorneg.values, alpha=0.3, antialiased=True)\n        ax1.set_ylabel(feature2+' '+units[feature2])\n        color_y_axis(ax1, 'g')\n    return ax1, ax2\n\ndef HourlyWeeklyVs(df,feature1,feature2,units):\n    '''Plot a feature vs radiation for time of day and week of year'''\n    plt.figure(figsize=(18, 6))\n    ax=plt.subplot(121) # hourly\n    ax1,ax2 = plotVs(df,df.index.hour,feature1,feature2,ax,units)\n    lines1, labels1 = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines1 + lines2, labels1 + labels2)\n    plt.xlabel('Hour of Day (Local Time)')\n    plt.title('Mean Hourly {0} vs. Mean Hourly {1}'.format(feature1,feature2))\n\n    ax=plt.subplot(122) # weekly\n    ax1, ax2 = plotVs(df,pd.Grouper(freq='W'),feature1,feature2,ax,units)\n    lines1, labels1 = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines1 + lines2, labels1 + labels2)\n    plt.xlabel('Week of Year')\n    plt.title('Mean Weekly {0} vs. Mean Weekly {1}'.format(feature1,feature2))\n    return\n","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"ff2628518d294d2560a70838c37548364a28f72d","_cell_guid":"0b39df73-9c23-4edc-a7c3-9ed27fa761c0"},"cell_type":"code"},{"source":"for feature in feature_list[1:]: # radiation vs feature\n    HourlyWeeklyVs(df,feature,feature_list[0],units)\nplt.show()","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"scrolled":false,"_uuid":"33f56757ee6ed81fd49c9edcf8c7477e47359a00","_cell_guid":"229fa9e0-62a8-417a-8cd3-0a247e3fcfce"},"cell_type":"code"},{"source":"## 2.4. Thoughts So Far\nFrom this exploration of the data, we see the following patterns in this dataset:\n* __Higher temperatures correlate to more radiation throughput.__ This is confirmed by a Pearson R-value of 0.73 and the observed behavior of radiation \"following\" temperature on the daily and weekly time scales.\n* __Humidity has a lesser (but potentially significant) impact on radiation throughput.__ With a Pearson R-value of magnitude above 0.20, humidity cannot be ignored as a potential driver of the system. Evidence for the negative correlation between the two features is found on the weekly time scale.\n* __Pressure doesn't correlate much to radiation, but does correlate to temperature and humidity.__ Weather, basically. Since temperature, pressure, and humidity are all characteristics of the atmosphere it is not surprising that they are correlated.\n* __Wind speed and direction are not relevant in this analysis.__ Though both are characteristics of local weather, they do not make sense as predictors of radiation. Wind direction has a moderate correlation to temperature (-0.26), pressure (-0.23) and radiation (-0.23) but through engineering judgement we know that this is only _correlation_ and not _causation_.\n* __Seasonal changes are significant.__ Even though Hawai'i does not see seasons as drastic as the northern continental United States, seasonal changes in temperature and humidity are still severe enough to be taken into account, as shown by the weekly measurement comparisons.\n* __Weekly timescales are the best predictors.__ Month-to-month variation is too broad to capture seasonal changes within a single year. Daily and hourly measurements have quite a bit of noise when looking for seasonal changes. Since day-to-day weather is dominated by temperature, pressure, and humidity (rather than seasonal changes), week of the year is the best indicator of seasonal trends.","metadata":{"_uuid":"effc58b132d927aa594ff847815d306f4b908905","_cell_guid":"1de2c6c5-19cc-4873-998a-5e986c825bd1"},"cell_type":"markdown"},{"source":"df.drop(['WindDirection','WindSpeed'], axis=1, inplace=True) # drop irrelevant features","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"642ddc9aee30dc9d9f9f969bec89d4b59d07bcb7","_cell_guid":"cab10e47-c408-40ec-9967-b5bd8ad7954d"},"cell_type":"code"},{"source":"Also, though it is obvious, solar radiation has a strong correlation to time of day. \nWe add time of day as a feature so the algorithm can tell day from night. \nAs a side effect, this implicitly accounts for sun angle.","metadata":{"_uuid":"95356c452b0f99441e0675535f3fa30ec496bca5","_cell_guid":"7df564b1-c8b2-4727-970b-33e761fcf048"},"cell_type":"markdown"},{"source":"df['TimeOfDay'] = df.index.hour # add time of day to correlation","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"8d7c3e1362db84272c1e7ef4e0c6afe39202abb2","_cell_guid":"de88ab75-e04b-4faa-b6aa-5e30297f3026"},"cell_type":"code"},{"source":"# 3. Training & Testing\nWe desire an algorithm that will predict values (radiation for a given set of inputs), we have plenty of data to train with, and we have \"unlimited\" time.\nThere are many models to choose from, and more than one may be appropriate.\n\nIn this analysis, we will try several models and compare their performance to evaluate the best algorithm to predict solar radiation.\n* Linear Regression\n* Random Forest Regression\n* Neural Network Regression\n* Support Vector Regression","metadata":{"_uuid":"b38a74e94a7505bd01f830ab61408cbab2bedc80","_cell_guid":"6f6d0739-8918-4381-b7c4-a7d7859d8fe1"},"cell_type":"markdown"},{"source":"# IMPORT ML CLASSIFIERS\nfrom sklearn.linear_model import LinearRegression # Linear regression\nfrom sklearn.ensemble import RandomForestRegressor # random forest regression\nfrom sklearn.neural_network import MLPRegressor # neural network regression\nfrom sklearn.svm import SVR # support vector regression","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"43846b52068098446e67f157a94f6b8db53d9159","_cell_guid":"dce60b82-e7a5-4ffc-9fae-dd28b17e4fef"},"cell_type":"code"},{"source":"## 3.1. Preparing the algorithm\nEven before we downselect to a specific model, we can prepare a prediction algorithm that takes in our data and makes a prediction.\nUsing [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning), it is easy to swap out different models and maintain the same higher-level structure to the program.\n\nTo train the algorithm, we implement a split train/test methodology to prevent bias in the learning.\nThe dataset is split into a randomly sampled pool of datapoints. \n80% of those points are used for training, the remaining 20% is used for validation of the training data. \nSo the test data is not necessarily continuous time, but rather a random selection of points from the set.\n\nFor demonstration purposes, we use the entire dataset (including training and test points) to visualize algorithm performance over time.\nThis is inherently biased, since some of the points we will see will have been points that the algorithm has already trained on and potentially optimized to.\nHowever, we validate the algorithm accuracy against the subset of testing points (which the were not used for training), so we can still be confident in evaluating the performance using the accuracy metric and by keeping this potential bias in mind.","metadata":{"_uuid":"c5da33611149c2110ba9079f07b0bf627419fba2","_cell_guid":"469f9a0e-b1be-4c13-91be-54652ffa1f9a"},"cell_type":"markdown"},{"source":"x = df.drop('Radiation',axis=1).as_matrix()\ny = df['Radiation'].as_matrix()","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"fdadb4ebbd6d4ac744726ca652a29bed3055689f","_cell_guid":"26b10d3a-9865-4385-9707-0f7f2d49d150"},"cell_type":"code"},{"source":"from sklearn import preprocessing # ML tools\nfrom sklearn.model_selection import train_test_split # split data\n\nfrom bokeh.plotting import figure, show, output_notebook\n\ndef plot_test(clf,X_test,y_test):\n    y_predicted = clf.predict(X_test)\n\n    p = figure(tools='pan,box_zoom,reset',x_range=[0, 100], title='Model validation',y_axis_label='radiation')\n    p.grid.minor_grid_line_color = '#eeeeee'\n\n    p.line(range(len(y_test)),y_test,legend='actual',line_color='blue')\n    p.line(range(len(y_test)),y_predicted,legend='prediction',line_color='red')\n    output_notebook()\n    show(p)\n    return\n\ndef plot_real(clf,x,y_actual,index):\n    ''' Plot predictions for actual measurements.\n    inputs:\n        clf         as classifier   the trained algorithm\n        x           as array        timeseries of measurement inputs\n        y_actual    as array        corresponding timeseries of actual results\n    '''\n    y_predicted = clf.predict(x)\n\n    p = figure(toolbar_location='right', title='Predicted vs Actual',y_axis_label='radiation',x_axis_type=\"datetime\")\n    p.grid.minor_grid_line_color = '#eeeeee'\n\n    p.line(index,y_actual,legend='actual',line_color='blue')\n    p.line(index,y_predicted,legend='prediction',line_color='red')\n    output_notebook()\n    show(p)\n    return\n\ndef train_model(X,y,clf,debug=False):\n    ''' Train algorithm.\n    inputs:\n        X       as array        features\n        y       as array        label(s)\n        clf     as scikit-learn classifier (untrained)\n    returns:\n        clf     as trained classifier\n        accuracy  as float\n    '''\n    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n    model = clf.fit(X_train,y_train)\n    accuracy = clf.score(X_test,y_test)\n    return clf, model, accuracy, X_test, y_test\n\ndef go(x,y,algorithm,debug=True):\n    ''' Easy model train and test. '''\n    clf, model, accuracy, X_test, y_test=train_model(x,y,algorithm,debug=True)\n    print('Accuracy: %s percent'%str(accuracy*100))\n\n    if debug:\n        plot_test(clf,X_test,y_test)\n        plot_real(clf,x,y,df.index.values)\n    return","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"cf5ec97ee561d75d353e915c85155df441dc3d99","_cell_guid":"ddbb7c6d-6dff-4e5c-b497-3aa1c738a3ab"},"cell_type":"code"},{"source":"## 3.2. Linear Regression\nLet's implement the first ML algorithm: __Linear regression.__\n\nLinear regression is probably the simplest fit, but weather characteristics are probably quite nonlinear.\nRegardless, let's see how it performs -- it might be good enough.","metadata":{"_uuid":"76f8ba3e905ccaae26930a52873ec859daf7b3d5","_cell_guid":"8a14e758-af90-44ec-b6d7-e5c9dbb84424"},"cell_type":"markdown"},{"source":"go(x,y,LinearRegression())","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"scrolled":false,"_uuid":"b69f855ecaeea4738f4f2c93f23389afdd41d021","_cell_guid":"d2ba4e0c-7e63-4c32-aee0-d006ee5d3b8c"},"cell_type":"code"},{"source":"Not horrible, but the ~60% accuracy is definitely apparent.","metadata":{"_uuid":"47436e08ac9e57408fe4b69b13856b778b286458","_cell_guid":"316cdcf3-49d8-428f-a968-9d439b6f748d"},"cell_type":"markdown"},{"source":"Here's a good example of where the algorithm roughly succeeds and miserably fails.\n\n![figure: linear regression](http://github.com/runphilrun/kaggle-radiation-prediction/blob/master/figs/linreg_plot.png?raw=true)\n\n## 3.3. Random Forest Regression\nAnother algorithm to try is __random forest regression__. \nThis works in a fundamentally different way to linear regression, so maybe we'll have more success.\nMost importantly, this algorithm can handle nonlinear inputs.","metadata":{"collapsed":true,"_uuid":"ff10c3b62666153821c2ea6d9a73ff0a56595807","_cell_guid":"ee610643-90dd-470f-93e4-641c1e8fa368"},"cell_type":"markdown"},{"source":"go(x,y,RandomForestRegressor())","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"9b6bad127250eb5e30ea3be53936198fa15da919","_cell_guid":"4448f6b1-81c6-4f83-86fe-5f06a302aa69"},"cell_type":"code"},{"source":"Wow, 92%! Random forest regression is much more flexible at handling this case where the underlying relationship of the data is nowhere near linear.\nThere are still areas where the algorithm fails, but the accuracy is dramatically improved overall.\n\n![figure: random forest regression](https://github.com/runphilrun/kaggle-radiation-prediction/blob/master/figs/rforest_plot.png?raw=true)","metadata":{"_uuid":"3603d8dee133a3e96295a2d261fa9b648d5f2af1","_cell_guid":"6195b8eb-a810-4085-83ff-694dcc77f03d"},"cell_type":"markdown"},{"source":"## 3.4. Neural Network Regression\nNeural Networks are very tunable to suit a wide variety of problems.\nIn this case, a neural network will be used to optimize squared error.\nSince this is just an exploration, we use default parameters knowing that performance may be much different if these values are tuned to suit our problem.","metadata":{"_uuid":"0a568ba5528ebd73320ee86c960fd7b118c0d901","_cell_guid":"946b40fd-ca77-4741-b56c-89a655169901"},"cell_type":"markdown"},{"source":"go(x,y,MLPRegressor())","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"scrolled":false,"_uuid":"89f90d31c9eb9931d61f452d3623e25c7dbb060c","_cell_guid":"9d0871e4-6328-41c8-aacb-3534cf21b21a"},"cell_type":"code"},{"source":"Wow, worse than linear regression! \nAlthough better results are probably possible with this algorithm, we already have random forest regression performing north of 90% accuracy. \nTuning the neural network is not really worth the trouble at this point.\n\n## 3.5. Support Vector Regression\nThis is another algorithm that comes packaged with scikit-learn.\nLet's implement it without digging into the theory, just to see how it performs out of the box.","metadata":{"_uuid":"6053e76a470334dbcad5e8f515575f0aad7f948e","_cell_guid":"641181e5-7125-4a37-9f25-224baa1a001e"},"cell_type":"markdown"},{"source":"go(x,y,SVR())","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"scrolled":false,"_uuid":"dcb2ab1a26441c7b093460e8802b9f1bf5681fb8","_cell_guid":"0ae9dca8-ebf5-4fda-a439-9b5ed1ee1981"},"cell_type":"code"},{"source":"The runtime for training this algorithm is exceptionally longer than the others. \nAs for accuracy... -32%? \nAccuracy is measured as the R-squared value, and a negative result indicates that the mean is a better predictor than this trained result!\n\nSupport vector regression (SVR) supports different _kernels_, and defaults to [Radial Basis Function (RBF)](http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).\nI attempted to try linear and polynomial kernels before passing judgement on this algorithm, but they took too long to run on my personal machine (more than 15 minutes).\nSVR is worth returning to, but right now we already have better models. \nTinkering with this is not getting us very far.","metadata":{"_uuid":"d751a36eb2b61718246e1dd311a65a9fd50362dd","_cell_guid":"a4a3520b-19cc-4722-aad7-7a07d4b9c6eb"},"cell_type":"markdown"},{"source":"# go(x,y,SVR(kernel='linear'))\n# go(x,y,SVR(kernel='poly'))","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"bb154452d210eedcacfa44032eba9e8474c631b6","_cell_guid":"d4f80597-143d-4b37-9801-259203a5426d"},"cell_type":"code"},{"source":"To recap, recall the accuracy of each algorithm attempted so far:\n* _Linear Regression:_ ~60%\n* **_Random Forest Regression:_ >90%**\n* _Neural Network Regression:_ ~50%\n* _Support Vector Regression:_ <50%\n\nThus we select __Random Forest Regression__ as our algorithm.","metadata":{"_uuid":"ef622f7d5e3b766c53ea13be58a33d5f58c6371d","_cell_guid":"54346a49-6a24-48e2-b299-7907ab0ff7cb"},"cell_type":"markdown"},{"source":"# 4. Tuning the Algorithm\nNow let's consider how we can improve the accuracy of our model. (I watched [this video](https://www.youtube.com/watch?v=YkVscKsV_qk) and read the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) to better understand this algorithm and you should too.)\n\nHere's what [the docs](http://scikit-learn.org/stable/modules/ensemble.html#random-forests) say:\n> In random forests (see RandomForestClassifier and RandomForestRegressor classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.\n\n\n\nOn a high level, regression derived from decision trees often results in low bias, high variance models, and is prone to overfitting.\nWhile the random forest method (which is built upon many decision trees) is more robust against bias and variance, overfitting is still a potential pitfall. \n\nFor random forests, there are three main tuning parameters:\n* __Number of trees.__ (`n_estimators`) More is better, with diminishing returns. Obviously more trees means longer compute times. A critical number of trees must be found where significant accuracy and compute times are optimized.\n* __Number of features to consider at each split.__ (`max_features`) If some trees consider a different subset of features than others, the correlation between those two groups is minimal. This is desirable because it teases out the influence of each individual feature.\n* __Depth of trees.__ (`max_depth`) Having trees go too deep can lead to overfitting. There is a critical depth where the trees split enough to result in useful fit without being too influenced by single values. Depth may instead be constrained by `min_samples_split`, `min_samples_leaf`, `min_weight_fraction_leaf`, or `max_leaf_nodes` rather than specifying tree depth outright.\n   ```python     \n        # DEFAULT VALUES\n        RandomForestRegressor(n_estimators=10, \n                              criterion='mse', \n                              max_depth=None, \n                              min_samples_split=2, \n                              min_samples_leaf=1, \n                              min_weight_fraction_leaf=0.0, \n                              max_features='auto', \n                              max_leaf_nodes=None, \n                              min_impurity_decrease=0.0, \n                              min_impurity_split=None, \n                              bootstrap=True, \n                              oob_score=False, \n                              n_jobs=1, \n                              random_state=None, \n                              verbose=0, \n                              warm_start=False)\n    ```\nStart by seeing if performance improves by simply increasing the number of trees (and letting scikit-learn use all available cores on our PC).","metadata":{"_uuid":"48dba1d8c5701b20be9f2997aef381725e2f4fef","_cell_guid":"4d78458c-cc19-4ce6-ac27-f286d433e118"},"cell_type":"markdown"},{"source":"# default algorithm for reference\nprint('Default random forest regressor:')\ngo(x,y,RandomForestRegressor(),debug=False)\n\n# tuning round 1\nprint('Tuned regressor:')\ngo(x,y,RandomForestRegressor(n_estimators=100, n_jobs=-1),debug=False)","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"a165c0df444a96b3a3abd390f273e4ef7939c05f","_cell_guid":"cd63a3f8-5a69-4b28-b551-1940823cb902"},"cell_type":"code"},{"source":"No real improvement. Trying every possible combination of values for `n_estimators`, `max_features`, and so on would take forever. \nUsing [Gregory Saunders's talk at PyCon Australia](https://youtu.be/YkVscKsV_qk?t=1940) as an example, we can write a function to let Python search for optimal values for us using the `oob_score` (out-of-bag score) to evaluate the accuracy of each combination, and return its best guess.","metadata":{"_uuid":"1940bab7be8db04633ee33d42ae3352f8c8712ce","_cell_guid":"b6cf6d9b-40a1-4e31-9aca-838dd24e2d01"},"cell_type":"markdown"},{"source":"def optimize_randomforest(x,y,try_n=10,try_f='auto',try_s=1):\n    ''' Find best combo of tunable params for random forest regressor. '''\n    best_score = float('-inf') # initialize score\n    for n in try_n:\n        for f in try_f:\n            for s in try_s:\n                clf = RandomForestRegressor(oob_score=True,n_estimators=n,max_features=f,min_samples_leaf=s,n_jobs=-1)\n                clf.fit(x,y)\n                if clf.oob_score_ > best_score:\n                    best_score, best_clf, best_n, best_f, best_s = clf.oob_score_, clf, n, f, s\n    return clf, best_n, best_f, best_s\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\nn=[100,200,300,500]\nf=[2,4,6]\ns=[1,2,4,8,16]\nclf, n, f, s = optimize_randomforest(x_train,y_train,try_n=n,try_f=f,try_s=s)\nprint('n_estimators: '+str(n))\nprint('max_features: '+str(f))\nprint('min_samples_leaf: '+str(s))\ngo(x,y,RandomForestRegressor(n_estimators=n,max_features=f,min_samples_leaf=s,n_jobs=-1))","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_uuid":"ead48f0a878b40ae6f4e2cdc44a79c1b0e6f5b5e","_cell_guid":"89ac11c1-f84b-474d-8467-d47b9acb7934"},"cell_type":"code"},{"source":"Some improvement, but it looks like the default values weren't too bad either.\n\nWe settle for the following optimized values (accuracy: 93.460329455 percent):\n\n| parameter | value |\n| --- | --- |\n| n_estimators | 500 |\n| max_features | 2 |\n| min_samples_leaf | 2 |\n\n![figure: tuned random forest](https://github.com/runphilrun/kaggle-radiation-prediction/blob/master/figs/tuned-rforest_plot.png?raw=true)","metadata":{"_uuid":"31e853bb5bfaf50896a6fa2de046493e547b611a","_cell_guid":"c7785e66-6da4-4077-9d94-c873f3792b70"},"cell_type":"markdown"},{"source":"# 5. Extending this idea\nThis analysis is by no means a complete approach to predicting solar radiation for a HI-SEAS mission, but we still developed a model through machine learning that yields more than 90% accurate predictions, and is thus a valid proof-of-concept.\nA more accurate model could be developed by spending more time in several areas:\n* __Choosing the right algorithm.__ Random forests worked well, and was certainly the best performer out of the four algorithms we tried with default values. But selection of those four algorithms, including random forests, was purely arbitrary. Spending some more time studying regression methods and choosing the most suitable one is surely worth the time.\n* __Tweaking the algorithm (intelligently).__ Iterating through a list of arbitrary values and choosing the one that yielded the best results is not the best approach to optimizing tunable parameters. More time spent tuning, including perhaps an analytical method to determine optimal values, would be beneficial.\n* __Considering feature relationships.__ We know that some features (temperature, pressure, humidity) are not completely independent. If we somehow work their relationships and influences on one another into the algorithm, that could potentially create a more realistic model.\n* __Considering more features.__ Cloud cover and precipitation, for starters. More (relevant) data migh lead to a better model. Desirable features are ones that we know truly impact the transmission of light through the atmosphere, especially at the wavevlengths where the HI-SEAS solar arrays are most sensitive.","metadata":{"_uuid":"6dd62c50f6776cf96dd94c67cd9b29efb3fc9104","_cell_guid":"6a063b5e-6396-462c-8e24-9ba44d2261eb"},"cell_type":"markdown"}],"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","pygments_lexer":"ipython3","version":"3.6.3","file_extension":".py"}},"nbformat":4}