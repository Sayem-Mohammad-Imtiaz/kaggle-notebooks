{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"######################################################################################\n# Lets see what people have to say about zomato's IPO by Applying some nlp skills    #\n######################################################################################\n\n# making neccessary import \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:37.956644Z","iopub.execute_input":"2021-07-18T12:38:37.957098Z","iopub.status.idle":"2021-07-18T12:38:37.964025Z","shell.execute_reply.started":"2021-07-18T12:38:37.957066Z","shell.execute_reply":"2021-07-18T12:38:37.962536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets load and inspect the data\ndataFrame = pd.read_csv('/kaggle/input/tweets-about-zomatoipo/zomato-ipo.csv')\ndataFrame.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:37.966192Z","iopub.execute_input":"2021-07-18T12:38:37.966669Z","iopub.status.idle":"2021-07-18T12:38:38.131991Z","shell.execute_reply.started":"2021-07-18T12:38:37.966629Z","shell.execute_reply":"2021-07-18T12:38:38.131167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets perform some data cleaning to have a better insight!!\nThe parameters the seems relevant for our analysis are date, username (because lets be sure no one is creating hype, by tweeting a particular sentiment message), tweet, language, like_count, retweet count, hashtags(lets take these as well)","metadata":{}},{"cell_type":"code","source":"cleanFrame = dataFrame[['date', 'username', 'tweet', 'language', 'likes_count', 'retweets_count', 'hashtags']]\ncleanFrame.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.133418Z","iopub.execute_input":"2021-07-18T12:38:38.133695Z","iopub.status.idle":"2021-07-18T12:38:38.153082Z","shell.execute_reply.started":"2021-07-18T12:38:38.133668Z","shell.execute_reply":"2021-07-18T12:38:38.1519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleanFrame","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.155262Z","iopub.execute_input":"2021-07-18T12:38:38.155586Z","iopub.status.idle":"2021-07-18T12:38:38.180353Z","shell.execute_reply.started":"2021-07-18T12:38:38.155556Z","shell.execute_reply":"2021-07-18T12:38:38.179323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's first make sure that the data is not baised anyhow by checking the unique usernames.","metadata":{}},{"cell_type":"code","source":"print('A little summary is as follow:')\nprint('* There are {} unique users who tweeted '.format(len (set (cleanFrame['username']))))\nprint('* This means {} % tweets are unique'.format( 100 *len (set (cleanFrame['username'])) / len(cleanFrame)))\nprint('* of these tweets {} % were in English'.format( 100 *len ((cleanFrame[cleanFrame['language'] == 'en'])) / len(cleanFrame)))\n\nmaxLiked = max(dataFrame['likes_count'])\nprint()\nprint( '* The most like tweet was like {} times'.format(maxLiked))\nprint('The most liked tweet is as follows ahem:')\nprint(dataFrame[dataFrame['likes_count'] == maxLiked]['tweet'].values[0])\nprint()\n\nmaxRetweeted = max(dataFrame['retweets_count'])\nprint('* The most retweeted tweet was tweeted {} times'.format(maxRetweeted))\nprint('which read as follows: ')\nprint(dataFrame[dataFrame['retweets_count'] == maxRetweeted]['tweet'].values[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.182388Z","iopub.execute_input":"2021-07-18T12:38:38.182775Z","iopub.status.idle":"2021-07-18T12:38:38.2106Z","shell.execute_reply.started":"2021-07-18T12:38:38.182736Z","shell.execute_reply":"2021-07-18T12:38:38.20953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we proceed to word clouds and data clean lets go through the hashtags firts.","metadata":{}},{"cell_type":"code","source":"# de-emojify \nimport re\ndef deEmojify(text):\n    regrex_pattern = re.compile(pattern = \"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           \"]+\", flags = re.UNICODE)\n    return regrex_pattern.sub(r'',text)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.211623Z","iopub.execute_input":"2021-07-18T12:38:38.211826Z","iopub.status.idle":"2021-07-18T12:38:38.216206Z","shell.execute_reply.started":"2021-07-18T12:38:38.211803Z","shell.execute_reply":"2021-07-18T12:38:38.215728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Assumption to keep this analysis simple we will only be analyzing englis tweets\ncleanFrame = cleanFrame[cleanFrame['language'] == 'en']\n\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : a.replace('[', ''))\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : a.replace(']', ''))\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : a.replace('\\'', ''))\n# Functions for deEmojifying\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : deEmojify(a))\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : re.sub(\"[^a-zA-Z0-9]+\", ' ', a))\n\n# removes hyperlinks\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', a, flags=re.MULTILINE))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.216894Z","iopub.execute_input":"2021-07-18T12:38:38.217074Z","iopub.status.idle":"2021-07-18T12:38:38.308951Z","shell.execute_reply.started":"2021-07-18T12:38:38.217054Z","shell.execute_reply":"2021-07-18T12:38:38.308153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hashTags = []\nfor mem in cleanFrame['hashtags']:\n    mems = mem.split(',')\n    for member in mems:\n        hashTags.append(member)\n\nhashTags = list(set(hashTags))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.312328Z","iopub.execute_input":"2021-07-18T12:38:38.312562Z","iopub.status.idle":"2021-07-18T12:38:38.323745Z","shell.execute_reply.started":"2021-07-18T12:38:38.312539Z","shell.execute_reply":"2021-07-18T12:38:38.322326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets start visualizations by plotting word clouds\n# World Cloud Plotter\nfrom wordcloud import WordCloud, STOPWORDS \nstopwords = set(STOPWORDS) \n\ndef WordCloudForSentiments (corpus, title):\n    wordcloud = WordCloud(width = 800, height = 800,background_color ='grey',\n                          stopwords = stopwords,  min_font_size = 10).generate(corpus)\n    \n    plt.figure(figsize = (12, 12), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.rcParams.update({'font.size': 25})\n    plt.axis(\"off\") \n    plt.title('Word Cloud:  ' + title)\n    plt.tight_layout(pad = 0) \n  \n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.32551Z","iopub.execute_input":"2021-07-18T12:38:38.325832Z","iopub.status.idle":"2021-07-18T12:38:38.340794Z","shell.execute_reply.started":"2021-07-18T12:38:38.325801Z","shell.execute_reply":"2021-07-18T12:38:38.339556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WordCloudForSentiments( ''.join(hashTags),'WordCloud:hashtags' )","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:38.343078Z","iopub.execute_input":"2021-07-18T12:38:38.343482Z","iopub.status.idle":"2021-07-18T12:38:39.670237Z","shell.execute_reply.started":"2021-07-18T12:38:38.343412Z","shell.execute_reply":"2021-07-18T12:38:39.668515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets clean the tweets using the same functions above:\ncleanFrame['tweet'] = cleanFrame['tweet'].apply(lambda a : deEmojify(a))\ncleanFrame['tweet'] = cleanFrame['tweet'].apply(lambda a : re.sub(\"[^a-zA-Z0-9]+\", ' ', a))\ncleanFrame['tweet'] = cleanFrame['tweet'].apply(lambda a : re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', a, flags=re.MULTILINE))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:39.671998Z","iopub.execute_input":"2021-07-18T12:38:39.672372Z","iopub.status.idle":"2021-07-18T12:38:40.051672Z","shell.execute_reply.started":"2021-07-18T12:38:39.672329Z","shell.execute_reply":"2021-07-18T12:38:40.048831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with the tweets data cleaned lets build a corpus\ntweetCorpus = ''\nfor tweet in cleanFrame['tweet']:\n    tweetCorpus +=  (tweet + ' ')    # adding a space to seperate tweets","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:40.053674Z","iopub.execute_input":"2021-07-18T12:38:40.054069Z","iopub.status.idle":"2021-07-18T12:38:40.068988Z","shell.execute_reply.started":"2021-07-18T12:38:40.05403Z","shell.execute_reply":"2021-07-18T12:38:40.06678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting tweet corpus\nWordCloudForSentiments( ''.join(tweetCorpus),'WordCloud:tweets' )","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:40.071179Z","iopub.execute_input":"2021-07-18T12:38:40.071707Z","iopub.status.idle":"2021-07-18T12:38:43.163615Z","shell.execute_reply.started":"2021-07-18T12:38:40.071665Z","shell.execute_reply":"2021-07-18T12:38:43.162707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  A Function for Sentiment Analysis\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\ndef SentimentAnlysis(sentence):\n    sentAnalyzer = SentimentIntensityAnalyzer() \n    sentDict = sentAnalyzer.polarity_scores(sentence)\n    \n    if sentDict['compound'] >= 0.05:\n        return \"positive\"\n    elif sentDict['compound'] <= -0.05 :\n        return \"negative\"\n    else:\n        return \"neutral\"","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:43.164787Z","iopub.execute_input":"2021-07-18T12:38:43.165019Z","iopub.status.idle":"2021-07-18T12:38:43.170528Z","shell.execute_reply.started":"2021-07-18T12:38:43.164986Z","shell.execute_reply":"2021-07-18T12:38:43.169302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets do sentiment analyis now\nfrom tqdm import tqdm\nsentiment = []\n\nfor tweet in  tqdm (cleanFrame['tweet']):\n    sentiment.append(SentimentAnlysis(tweet))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:38:43.171727Z","iopub.execute_input":"2021-07-18T12:38:43.171961Z","iopub.status.idle":"2021-07-18T12:40:08.08003Z","shell.execute_reply.started":"2021-07-18T12:38:43.171932Z","shell.execute_reply":"2021-07-18T12:40:08.0788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets append this to our dataFrame and continue our analysis\ncleanFrame['sentiments'] = sentiment\n\n# A pie chart for understanding postive, negatives and neutral tweets\n\nnumPostives = len(cleanFrame[cleanFrame['sentiments'] == 'positive'])\nnumNegatives = len(cleanFrame[cleanFrame['sentiments'] == 'negative'])\nnumNeutrals  = len(cleanFrame[cleanFrame['sentiments'] == 'neutral'])\n\nplt.figure(figsize = (7, 7))\nplt.pie([numPostives, numNegatives, numNeutrals], labels = ['positives', 'negatives', 'neutrals'], autopct='%1.2f%%')\nplt.title('Twitter Sentiments on Zomato IPO')","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:40:08.081179Z","iopub.execute_input":"2021-07-18T12:40:08.081479Z","iopub.status.idle":"2021-07-18T12:40:08.256865Z","shell.execute_reply.started":"2021-07-18T12:40:08.081404Z","shell.execute_reply":"2021-07-18T12:40:08.255553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems folks have a pretty postive outlook for Zomato IPO, although I believe more neutrals should in be either postive\nor negatives, but this essentially catches the sentiment.","metadata":{}},{"cell_type":"code","source":"# lets do one thing more and try to see who the sentiment in changing with time\ncleanFrame['date']= pd.to_datetime(cleanFrame['date'])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:40:08.25822Z","iopub.execute_input":"2021-07-18T12:40:08.258529Z","iopub.status.idle":"2021-07-18T12:40:08.2719Z","shell.execute_reply.started":"2021-07-18T12:40:08.258496Z","shell.execute_reply":"2021-07-18T12:40:08.270773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now each unique date collect Positive, negative, and neutral tweets\ndates = set(cleanFrame['date'])\npositivesOndate = []\nnegativesOndate = []\nneutralsOndate  = []\nda              = []\n\nfor date in dates:\n    pos = len (cleanFrame[(cleanFrame['date'] == date) & (cleanFrame['sentiments'] == 'positive')])\n    neg = len (cleanFrame[(cleanFrame['date'] == date) & (cleanFrame['sentiments'] == 'negative')])\n    neu = len (cleanFrame[(cleanFrame['date'] == date) & (cleanFrame['sentiments'] == 'neutral')])\n    \n    positivesOndate.append(pos)\n    negativesOndate.append(neg)\n    neutralsOndate.append(neu)\n    da.append( str(date))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:40:08.273481Z","iopub.execute_input":"2021-07-18T12:40:08.273852Z","iopub.status.idle":"2021-07-18T12:40:09.334278Z","shell.execute_reply.started":"2021-07-18T12:40:08.273816Z","shell.execute_reply":"2021-07-18T12:40:09.333613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let plot this info\nplt.figure(figsize=(10, 7))\nplt.plot( positivesOndate, label = 'Postive Sentiments' )\nplt.plot( negativesOndate, label = 'Negative Sentiments')\nplt.plot( neutralsOndate, label = 'Neutral Sentiments ')\nplt.ylabel('Number of tweets on that day')\nplt.xlabel('Days passed')\nplt.title('Zomato IPO Sentiment timeSeries')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T12:40:09.335317Z","iopub.execute_input":"2021-07-18T12:40:09.335612Z","iopub.status.idle":"2021-07-18T12:40:09.586784Z","shell.execute_reply.started":"2021-07-18T12:40:09.335573Z","shell.execute_reply":"2021-07-18T12:40:09.585978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}