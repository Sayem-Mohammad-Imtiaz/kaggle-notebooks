{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import find_peaks\nfrom scipy.stats import kurtosis, skew\nimport scipy.io\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf = pd.read_csv('/kaggle/input/sleep-apnea/a01.csv')\ndf.columns =['Time', 'ECG']\n# print(df) #[2956999 rows x 2 columns]\n\n\ndf1 = pd.read_csv('/kaggle/input/sleep-apnea/a01.txt', delimiter= '\\s+', index_col=False)\ndf1Arr = df1.loc[:,'N']\n# print(df) #[2956999 rows x 2 columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#module for data signals synchronization with labels \nyArr = []\ni = 0\nfor x in df1Arr:\n    for k in range(0,6060):\n        yArr.append(x)\n        i+=1\n\ndf_y = pd.DataFrame(yArr)\ndf = pd.concat([df, df_y], axis=1)\n\ndf = df[:2956999]\ndf.rename(columns = {0 : 'Target'}, inplace = True)\ndf[\"Target\"].replace({\"A\": 1, \"N\": 0}, inplace=True)\n\ny = df.values[:2956999, 2]\n\n\ndf = df.values[:2956999, 1]\nx = df\n\nk = 6000\nstep = 3000\nn = len(x)\n\n# max, min, median, mean, std, kurtosis, skw, target\ndfk = pd.DataFrame(columns=['max', 'min', 'median', 'mean', 'std', 'kts', 'skw', 'target'])\nkk = 0\n# count = 0\n\nwindow = x[0:0 + k]\npeaks, _ = find_peaks(window, distance=150) #to finds r_peaks and finds all local maxima by\n# simple comparison of neighbouring values\n\n\nfor i in range(0, n - k + 1, step): #to iterate within all window segments\n     # count =count+1\n     window = x[i:i + k]\n     windowY = y[i:i + k]\n     peaks, _ = find_peaks(window, distance=150) #to finds r_peaks and finds all local maxima by\n    # simple comparison of neighbouring values\n     ecg_peaks = window[peaks] #to get amplitude information\n     max_index = np.where(ecg_peaks == np.amax(ecg_peaks))\n     windowPeakIdx = peaks[max_index[0]]\n         \n    # print(x[25])\n    # plt.plot(x)\n    # plt.plot(peaks, x[peaks], \".\")\n    # plt.plot(np.zeros_like(x), \"--\", color=\"gray\")\n    # plt.show()\n    \n     if ecg_peaks.size == 0:\n      kk += 1\n      continue\n      \n    # The electrocardiogram in millivolt (mV) sampled at 100 Hz.\n    \n     fs = 100\n    # np.diff(peaks)\n     ecg_sample_time = peaks / fs #sampling data converted into time domain data\n     # print(ecg_sample_time) \n     ecg_sample_time_interval = [ecg_sample_time[i + 1] - ecg_sample_time[i] for i in range(len(ecg_sample_time) - 1)] #time interval between a signal and its previous signal\n     # print(ecg_sample_time_interval) \n     \n    #  feature extraction for every window segment\n     G = max(window[peaks])\n     dfk.at[kk, 'max'] = G #maximum of r_peaks\n     # print(G)\n     L = min(window[peaks]) #minimum of r_peaks\n     dfk.at[kk, 'min'] = L\n     # print(L)\n     mean= np.mean(ecg_sample_time_interval) #mean of r_peaks\n     dfk.at[kk,'mean'] = mean\n     # print(mean)\n     median= np.median(ecg_sample_time_interval) #median of r_peaks\n     dfk.at[kk,'median'] = median\n     # print(median)\n     std= np.std(ecg_sample_time_interval) #std deviation of r_peaks\n     dfk.at[kk,'std'] = std\n     # print(std)\n     kts= kurtosis(ecg_sample_time_interval, fisher=True) #kurtosis of r_peaks\n     dfk.at[kk,'kts'] = kts\n     # print(kts)\n     skw= skew(ecg_sample_time_interval) #skwewness of r_peaks\n     dfk.at[kk,'skw'] = skw\n     # print(skw)\n     \n     dfk.at[kk,'target'] = windowY[windowPeakIdx][0]\n     kk+=1\n# print(dfk)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dft = np.transpose(dfk)\n# print(dft.shape)\n# plt.boxplot(dft)\n# plt.xlabel('feature')\n# plt.ylabel('value')\n# plt.show()\n\nx1 = dft.iloc[0:6,:]\n\ny1 = dft.iloc[7,:]\ny1= y1.astype(int)\n# print(y1.value_counts())\n\nx1 = np.transpose(x1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\n# normalize the data attributes\nx1 = preprocessing.normalize(x1)\n\nx_train_all, x_test, y_train_all, y_test = train_test_split(x1, y1,  \n                                                            test_size=0.2, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, \n                                                  test_size=0.2, random_state=42)\n# print(y_train.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nscaler.fit(x_val)\nx_train = scaler.transform(x_train)\nx_val = scaler.transform(x_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(40,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dropout(0.2))\n\n# BINARY CLASSIFICATION so use sigmoid for the last layer\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x=x_train,y=y_train,epochs=200,validation_data=(x_val,y_val),batch_size=30,callbacks=[early_stop])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict_classes(x_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_val,predictions))\nprint(confusion_matrix(y_val,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neural_net_model = model.save('SleepApnea-predictor.h5') # save model\nmodel_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}