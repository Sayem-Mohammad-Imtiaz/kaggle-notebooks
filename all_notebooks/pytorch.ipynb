{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Learning Pytorch\n1. Basics of Tensors"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# t1 = torch.tensor(4.)\n# t2 = torch.tensor([1.,2.,3.])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# t3 = torch.tensor([[1.,2.],[3.,4.]])\n# t4 = torch.tensor([[[1.,2.],[3.,4.]],[[1.,2.],[3.,4.]]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # tensor created are regular and have uniformity across the dimensions\n# print(t1.shape) # scalar\n# print(t2.shape) # vector \n# print(t3.shape) # 2d matrix\n# print(t4.shape) # 3d matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x= torch.tensor(3.)\n# w = torch.tensor(4., requires_grad=True)\n# b = torch.tensor(5., requires_grad=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y = w*x + b;\n# print(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y.backward() # Calculating partial derivatives wrt each tensor ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(x.grad)  # requires_grad is False, so no gradient calculation wrt x\n# print(w.grad)  # dy/dw \n# print(b.grad)  # dy/db","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# arr = np.array([[5.,6.],[7.,8.]])\n# y = torch.from_numpy(arr)  #  It uses same space in the memory and does not create a copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# arr = y.numpy();  # converting pytorch tensor to numpy used to export or returning the tensor back to some kind of api request etc..","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = np.array([[73,67,43],\n                   [91,88,64],\n                   [87,134,58],\n                   [102,43,37],\n                   [69,96,70]], dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = np.array([[56,70],[81,101],[119,133],[22,37],[103,119]], dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = torch.from_numpy(inputs)\ntargets = torch.from_numpy(targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = torch.randn(2,3, requires_grad=True)\nb = torch.randn(2, requires_grad=True)\nprint(w)\nprint(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(x,w,b):\n    return x @ w.t() + b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model(inputs,w,b)\nprint(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mse(t1,t2):\n    diff = t1-t2;\n    return torch.sum( diff*diff) / diff.numel();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = mse(preds, targets)\nprint(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(500):\n    preds = model(inputs,w,b)\n    loss = mse(preds, targets)\n    loss.backward()\n    with torch.no_grad():\n        w -= w.grad * 1e-5\n        b -= b.grad * 1e-5\n        w.grad.zero_()\n        b.grad.zero_()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model(inputs, w, b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(preds)\nprint(targets)\nprint(mse(preds, targets))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using built in libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = TensorDataset(inputs, targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 5\ntrain_dl = DataLoader(train_ds, batch_size , shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = nn.Linear(3,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.weight)\nprint(model.bias)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_fn = F.mse_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(loss_fn(model(inputs), targets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = torch.optim.SGD(model.parameters(), lr=1e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(num_epochs, train_dl, model, loss_fn, opt):\n    for epoch in range(num_epochs):\n        for xb, yb in train_dl:\n            pred = model(xb)\n            loss = loss_fn(pred, yb)\n            loss.backward()\n            opt.step()\n            opt.zero_grad()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(1000, train_dl, model, loss_fn, opt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model(inputs))\nprint(targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}