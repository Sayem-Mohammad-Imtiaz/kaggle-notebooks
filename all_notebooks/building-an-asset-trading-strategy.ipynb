{"cells":[{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns;sns.set()\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom pandas import read_csv, set_option\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer,RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom catboost import CatBoostClassifier,CatBoostRegressor\nfrom sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest,f_regression\nfrom xgboost import plot_importance,XGBClassifier,XGBRegressor\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn import preprocessing\nimport shap\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import SparsePCA\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.decomposition import MiniBatchDictionaryLearning\nfrom sklearn.decomposition import FastICA\nfrom sklearn.manifold import Isomap\nfrom sklearn.manifold import MDS\nfrom sklearn.manifold import LocallyLinearEmbedding\nfrom sklearn.manifold import TSNE\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\n\n# for dirname, _, filenames in os.walk('/kaggle/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        \nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set(style='whitegrid')\n%matplotlib inline\n\n# time series cross validation\n# https://hub.packtpub.com/cross-validation-strategies-for-time-series-forecasting-tutorial/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pandas Dataframe Memory Reduction**\n***\nIt's possible to optimise (reduce the memory) of a dataframe by adjusting its <code>dtype</code>. Current code by <code>mfjwr1</code> was tried, but it skewed the data a little, created incompatible <code>dtype</code> feaures that were required by some operations. (code hidden)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# reduce memory (@mfjwr1); distorts the data a little (but reduces by 60% memory)\ndef red_mem(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**General Functions**\n***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# One plot type\ndef plot_line(ldf,lst,title='',sec_id=None,size=[350,1000]):\n    \n    # sec_id - list of [False,False,True] values of when to activate supblots; same length as lst\n    \n    if(sec_id is not None):\n        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n    else:\n        fig = go.Figure()\n        \n    if(len(lst) is not 1):\n        ii=-1\n        for i in lst:\n            ii+=1\n            if(sec_id is not None):\n                fig.add_trace(go.Scatter(x=ldf.index, y=ldf[lst[ii]],mode='lines',name=lst[ii],line=dict(width=2.0)),secondary_y=sec_id[ii])\n            else:\n                fig.add_trace(go.Scatter(x=ldf.index, y=ldf[lst[ii]],mode='lines',name=lst[ii],line=dict(width=2.0)))\n    else:\n        fig.add_trace(go.Scatter(x=ldf.index, y=ldf[lst[0]],mode='lines',name=lst[0],line=dict(width=2.0)))\n\n    fig.update_layout(height=size[0],width=size[1],template='plotly_white',title=title,\n                          margin=dict(l=50,r=80,t=50,b=40));fig.show()\n    \n# plot n verticle subplots\ndef plot_vsubplots(ldf,lst,title='',nplots=None,lw_id=None,size=[400,1000]):\n\n    # lw_id list of line widths if added\n        \n    assert(nplots is not None) \n    fig = make_subplots(rows=nplots,shared_xaxes=True)\n    ii=-1\n    for i in lst:\n        ii+=1\n        fig.add_trace(go.Scatter(x=ldf.index,y=ldf[lst[ii]], mode='lines',name=lst[ii],line=dict(width=lw_id[ii])), row=ii+1, col=1) \n\n    fig.update_layout(height=size[0],width=size[1],template='plotly_white',title=title,\n                          margin=dict(l=50,r=80,t=50,b=40));fig.show()\n    \ncolours = ['tab:blue','tab:red','tab:green']\ndef plot_line2(ldf,lst,title=''):\n    \n    ii=-1\n    plt.figure(figsize=(14,5))\n    for i in lst:\n        ii+=1\n        ax = ldf[lst[ii]].plot(color=colours[ii],label=lst[ii],lw=1.5)\n    plt.title(title)\n    plt.legend();plt.show()\n    \ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Plot Correlation to Target Variable only\ndef corrMat(df,target='demand',figsize=(9,0.5),ret_id=False):\n    \n    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n    corr_mat = corr_mat.transpose()\n    corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n    \n    if(ret_id is False):\n        f, ax = plt.subplots(figsize=figsize)\n        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n                     cmap=cmap,square=False,lw=2,annot=True,cbar=False)\n        plt.title(f'Feature Correlation to {target}')\n    \n    if(ret_id):\n        return corr\n    \ndef bar_plot(x, y,palette_len,title='Missing Values (%)', xlim = None, ylim = None, \n             xticklabels = None, yticklabels = None,xlabel = None, ylabel = None, \n             figsize = (10,4),axis_grid = 'y'):\n        \n    cmap = sns.color_palette(\"plasma\")\n    fig, ax = plt.subplots(figsize = figsize)\n    plt.title(title,size = 15, fontweight = 'bold')\n\n    for i in ['top', 'right', 'bottom', 'left']:\n        ax.spines[i].set_color('black')\n    \n    ax.spines['top'].set_visible(True);ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False);ax.spines['left'].set_visible(False)\n\n    sns.barplot(x = x, y = y, edgecolor = 'black', ax = ax,\n                palette = cmap)\n    ax.set_xlim(xlim);ax.set_ylim(ylim)    \n    ax.set_xticklabels(xticklabels);ax.set_yticklabels(yticklabels)\n    plt.xlabel(xlabel);plt.ylabel(ylabel)\n    ax.grid(axis = axis_grid,ls='--',alpha = 0.9)\n    plt.show()\n    \n# Split for TimeSeries\ndef TimeSeries_Split(ldf,split_id=[None,None],test_id=False,cut_id=None):\n    \n    # Reduce the number of used data\n    if(cut_id is not None):\n        print('data reduction used')\n        ldf = ldf.iloc[-cut_id:]\n        t1 = ldf.index.max();t0 = ldf.index.min()\n        print(f'Dataset Min.Index: {t0} | Max.Index: {t1}')\n        \n    if(split_id[0] is not None):\n        # General Percentage Split (Non Shuffle requied for Time Series)\n        train_df,pred_df = train_test_split(ldf,test_size=split_id[0],shuffle=False)\n    elif(split_id[1] is not None):\n        # specific time split \n        train_df = df.loc[:split_id[1]]; pred_df = df.loc[split_id[1]:] \n    else:\n        print('Choose One Splitting Method Only')\n        \n#     y_train = train_df[feature]\n#     X_train = train_df.loc[:, train_df.columns != feature]\n#     if(test_id):\n#         y_test = pred_df[feature]\n#         X_test = pred_df.loc[:, pred_df.columns != feature]\n        \n    return train_df,pred_df # return \n\n# function to plot a two PCA Feature Plot using Pandas \ndef scatterPlot(xDF, yDF, algoName):\n    \n    sns.set_style('whitegrid')\n    fig, ax = plt.subplots()\n    tempDF = pd.DataFrame(data=xDF.loc[:,0:1], index=xDF.index)\n    tempDF = pd.concat((tempDF,yDF), axis=1, join=\"inner\")\n    tempDF.columns = [\"Component 1\",\"Component 2\",\"Label\"]\n    g = sns.scatterplot(x=\"Component 1\",y=\"Component 2\",data=tempDF,hue=\"Label\",\n                        linewidth=0.5,alpha=0.5,s=15,edgecolor='k')\n    plt.title(algoName);plt.legend()\n    \n    for i in ['top', 'right', 'bottom', 'left']:\n        ax.spines[i].set_color('black')\n    \n    ax.spines['top'].set_visible(False);ax.spines['right'].set_visible(False)\n    ax.spines['bottom'].set_visible(False);ax.spines['left'].set_visible(False)\n    ax.grid(axis = 'both',ls='--',alpha = 0.9)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preword**\n***\n- Recently (2020 alone), <code>Bitcoin</code> has increased over 200% in value alone, and having reached new heights (just today at $23k ), after which it dropped back down again (by 6%), really shows how <code>volatile</code> this asset is, which makes it one of the more interesting time series to explore.\n- It's quite interesting to see how this <code>digital</code> asset has resurged in value after a recent dip, especially in the current financial climate & the notebook is mainly used for my own time series training & coding training.\n- This is a <b>WIP</b>, if you find anything useful, please consider upvoting/commenting, it would be really appreciated, thank you."},{"metadata":{"_cell_guid":"83708667-4fdc-1563-7b3a-06b6575d2865"},"cell_type":"markdown","source":"# 1.<span style='color:#273746'> Introduction </span>\n\n## 1.1.<span style='color:#F1C40F'>  Background: Dataset Context</span>\n\n> Bitcoin is the longest running and most well known cryptocurrency, first released as open source in 2009 by the anonymous Satoshi Nakamoto. Bitcoin serves as a decentralized medium of digital exchange, with transactions verified and recorded in a public distributed ledger (the blockchain) without the need for a trusted record keeping authority or central intermediary. Transaction blocks contain a SHA-256 cryptographic hash of previous transaction blocks, and are thus \"chained\" together, serving as an immutable record of all transactions that have ever occurred. As with any currency/commodity on the market, bitcoin trading and financial instruments soon followed public adoption of bitcoin and continue to grow. Included here is historical bitcoin market data at 1-min intervals for select bitcoin exchanges where trading takes place. Happy (data) mining! \n\n## 1.2.<span style='color:#F1C40F'>  Background: Stock Price Influencers </span>\n\nFeatures that can be useful for `stock price` prediction as outlined by <b>Tatsat et al (2020)</b>\n\n<span style='color:#5D6D7E'><b>Correlated Assets</b></span>\n> An organization depends on and interacts with many external factors, including its competitors, clients, the global economy, the geopolitical situation, fiscal and monetary policies, access to capital, and so on. Hence, its stock price may be correlated not only with the stock price of other companies but also with other assets such as commodities, FX, broad-based indices, or even fixed income securities.\n\n<span style='color:#5D6D7E'><b>Technical Indicators</b></span>\n> A lot of investors follow technical indicators. Moving average, exponential moving average, and momentum are the most popular indicators. \n\n<span style='color:#5D6D7E'><b>Fundamental Analysis (Performance Reports)</b></span>\n> Annual and quarterly reports of companies can be used to extract or determine key metrics, such as ROE (Return on Equity) and P/E (Price-toEarnings).\n\n<span style='color:#5D6D7E'><b>Fundamental Analysis (News)</b></span>\n> News can indicate upcoming events that can potentially move the stock price in a certain direction.\n\n- When focusing on <code>stock price prediction</code>, one can utilise a few approaches when it comes to feature building/assembly (factors that affect the predicted variable) as shown above.\n- As indicated by ([source](https://cryptobriefing.com/is-bitcoin-stock-commodity/)), <code>Bitcoin</code> is more of a <code>digital asset</code>, than a <code>stock</code> or a <code>currency</code>, thus it's not quite certain whether factors outlined are completely relevant to analyses involving <code>Bitcoins</code>.\n- However, ([source]( https://www.mycryptopedia.com/best-8-bitcoin-indicators-for-cryptocurrency-trading/)) does outline various <code>indicators</code> that are useful specifically for <code>Bitcoin</code>price directivity prediction, which is a reasurence that <code>technical indicators</code> play and important role in <code>Bitcoin</code> time-series as well.\n\n## 1.3. <span style='color:#F1C40F'>Problem Relevance & Definition</span>\n\n- A major drawback of crypocurrency trading is the <code>volatility</code> of the market.\n- The currency trades can occur 24/7 & tracking crypto position can be an impossible task to manage without automation.\n- Automated Machine Learning trading algorithms can assist in managing this task, in order to predict the market's movement.\n- We can use models to classify future movements into three categries: \n\n> <code>(1) The market will rise (take long position)</code>, <br>\n> <code>(2) The market will fall (take short position)</code> <br>\n> <code>(3) The market will move sideways (take no position)</code>.\n    \n    \n- The problem of predicting a buy (<code>value=1</code>) or sell (<code>value=0</code>) signal for a <b>trading strategy</b> is defined in the\nclassification framework. \n- The buy or sell signal are decided on the basis of a comparison of short term vs. long\nterm price & is defined in <code>Section 2.2</code>\n- Data harvesting (just data collection here) & <code>feature engineering</code> are relevant factors in time series model improvement. It's interesting to investigate whether traditionally stock orientated feature engineering modifications are relevant to <code>digital assets</code>, and if so which ones.\n- Last but not least, <code>model generation efficiency</code> becomes much more significant when dealing with <code>High Frequency</code> tick data as each added feature can have a substatial impact on the turnaround time of a model & balancing model accuracy & model output turnaround time is definitely worth managing."},{"metadata":{},"cell_type":"markdown","source":"## 1.4.<span style='color:#F1C40F'>  Loading & Data Assembly </span>\n- Current dataset : CSV file for select bitcoin exchanges for the time period of Jan 2012 to September 2020, <code>1-min interval data</code> ([dataset](https://www.kaggle.com/mczielinski/bitcoin-historical-data))\n- The feature <code>timestamp</code> can be parsed into a more conventional time index using the <code>pytz</code> library.\n- The <code>Baseline Features</code> include: the asset's minute's <code>open</code>,<code>high</code>,<code>low</code>,<code>close</code>,<code>Volume_(BTC)</code>,<code>Volume_(Currency)</code> & <code>Weighted_Price</code>\n- The loaded dataset, contains a specific start and end time index, in order to use models on unseen data, we need to split the dataset and not inspect it, the code used is hidden below."},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime, pytz\n#define a conversion function for the native timestamps in the csv file\ndef dateparse (time_in_secs):    \n    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n\nperiod = slice('2020-7-7 0:00','2020-7-7 8:00') # for plot only\npath = '/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv'\n# path = 'bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv'\ndf = pd.read_csv(path,parse_dates=[0], date_parser=dateparse,index_col='Timestamp')\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It's possible to reduce the dataframe memory by 62% (if you need)\n# red_df = red_mem(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr,df_te = TimeSeries_Split(df,split_id=[0.2,None],cut_id=100000) # Use only 100,000 data points -> Train/Test Split (0.8/0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Due to the excess ammount of index data available to us, training of models can become quite long, especialy when it comes to cross validaiton.\n- Let's limit the dataset to <code>100,000</code> (compared to 4.5M) recent data points in this notebook, which are assumed to be the most relevant to what we want to predict (future events)\n- A <code>training data</code> period of only two months may not be sufficient to obtain a very accurate model (it's a short period of time, but contains quite a lot of data, nevertheless some trends may be missed), so you could try using even more points, if you have a more powerful PC.\n- Some interesting applications to deal with larger datasets are of course <code>GPU</code> capable models which you could try. A very simple and easy to graps to use <code>XGBoost</code>'s GPU capable model example is provided by [hamditarek](https://www.kaggle.com/hamditarek/market-prediction-xgboost-with-gpu-fit-in-1min?q=XGboost+GPU)."},{"metadata":{},"cell_type":"markdown","source":"## 1.5.<span style='color:#F1C40F'> Clearning Data </span>\n- The missing data is visualised and is shown to be consisten amongst features.\n- Fill the data of indices during which there were no trades occuring, single-event. <code>value=0</code> (<b>Ignored</b>)\n- Modify features <code>open</code>,<code>high</code>,<code>low</code>,<code>close</code> as the time series is continuous, using forward filling, <code>ffil</code>"},{"metadata":{"trusted":true},"cell_type":"code","source":"NaN_values = (df_tr.isnull().sum()/len(df_tr)*100).sort_values(ascending = False)\nbar_plot(x = NaN_values,y = NaN_values.index,palette_len = NaN_values.index, \n         xlim = (0,100),xticklabels = range(0,101,20),yticklabels = NaN_values.index,\n         figsize = (10,5), axis_grid = 'x')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr[df_tr.isna().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction with non events <code>.fillna(0)</code> can be interesting to include in signal modelling, but excluded here to have a more visible stock fluctuation history."},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_fill_na(ldf):\n    # ldf['Volume_(BTC)'].fillna(0, inplace=True)\n    # ldf['Volume_(Currency)'].fillna(0, inplace=True)\n    # ldf['Weighted_Price'].fillna(0, inplace=True)\n    ldf['Open'].fillna(method='ffill', inplace=True)\n    ldf['High'].fillna(method='ffill', inplace=True)\n    ldf['Low'].fillna(method='ffill', inplace=True)\n    ldf['Close'].fillna(method='ffill', inplace=True)\n    \nforward_fill_na(df_tr)  # modification of training set\nforward_fill_na(df_te) # modification of test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = df.drop_duplicates(keep=False,inplace=True) \ndf_tr = df_tr.dropna() \ndf_te = df_te.dropna()     # replicate on test set","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"df6a4523-b385-69ee-c933-592826d81431"},"cell_type":"markdown","source":"# 2.<span style='color:#273746'> Exploratory Data Analysis </span>\n## 2.1.<span style='color:#F1C40F'> Descriptive Statistics </span>"},{"metadata":{"_cell_guid":"7bffeec0-5bbc-fffb-18f2-3da56b862ca3","trusted":true},"cell_type":"code","source":"set_option('precision',2)\ndf_tr.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2.<span style='color:#F1C40F'> Target Variable  </span>\n- We need to define our prediction variable <code>signal</code>, which will be done via <code>.rolling</code> & <code>.mean()</code> using the <code>Close</code> feature.\n- A short term (window) moving average, <code>SMA1</code> & a long term (window) moving average, <code>SMA2</code> are used to create the target variable, <code>signal</code>.\n- The trading stratergy is as follows; where the <code>Short Term (SMA1)</code> > <code>Long Term (SMA2)</code>, the signal value = 1 <code>(buy)</code>, otherwise it is set to 0 <code>(sell)</code>.\n- The <code>Short Term (SMA1)</code> & <code>Long Term (SMA2)</code> Moving Average value are set to <b>window values of 10 and 60</b> respectively, both of which are arbitrary, and can affect the results, ideally an optimisation study needs to be carried out to find optimum values."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def create_target(ldf,tr_id=False):\n    ldf['SMA1'] = ldf['Close'].rolling(window=10, min_periods=1, center=False).mean() #  short simple moving average window\n    ldf['SMA2'] = ldf['Close'].rolling(window=60, min_periods=1, center=False).mean() #  long simple moving average window\n    ldf['signal'] = np.where(ldf['SMA1'] > ldf['SMA2'], 1.0, 0.0) # Create signals\n    if(tr_id is not True):\n        display(ldf['signal'].value_counts())\n    \ndf_tr1 = df_tr.copy()  # Save the Baseline Model Dataframe [Training Set]\ndf_te1 = df_te.copy() # Save the Baseline Model Dataframe [Test Set]\ncreate_target(df_tr1)  # Add target variable to Training Set \ncreate_target(df_te1,tr_id=True)  # Add target variable to Test Set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We have a relatively even (buy/sell) (40k/38k) target variable <code>signal</code> distribution;\n- We don't really have to emphasise issues associated with <code>class imbalance</code> in this problem.\n- Simple metrics like <code>accuracy,recall,precision</code> might suffice as <code>classification</code> metrics, instead of detailed ROC & PR curves of classifier models."},{"metadata":{},"cell_type":"markdown","source":"## 2.3.<span style='color:#F1C40F'> Dataset Timeseries Visualisation </span>\nLet's visualise the overall asset price history during the <code>training data</code> period & the associated <code>signal</code> as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_vsubplots(df_tr1,['Close','signal'],title='Weighted Price & Signal Training Data',nplots=2,lw_id=[2,0.4],size=[500,1000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- It's interesting to note the general upward trend of the <code>weighted</code>asset price, having gone up from 9.2k at the start of this period and reaching 11.73k only within a span of a couple of months.\n- Not quite easy to visualise it, but the signal (what we will be modelling) is also plotted , and we can observe how much the shorter and longer period MA interchange in this short time period alone."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualise Training Set Target Variable Related Features\nlst_MAV = ['SMA1','SMA2','signal']\nldf = df_tr1.loc[period,lst_MAV]\nplot_line(ldf,lst_MAV,title='SM1, SMA2 & Signal created from Closing Price',sec_id=[False,False,True])   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are quite a number of periods during which the shorter and longer moving average values interchange, even for only an <b>8 hour</b> period, during which the cost varied in the range of <code>9240:9400</code> during the observed period, which is indicative of a highly volatile asset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr1=df_tr1.drop(['SMA1','SMA2'], axis=1)\ndf_te1=df_te1.drop(['SMA1','SMA2'], axis=1)   # replicate on test data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4.<span style='color:#F1C40F'> Baseline Features: Linear Correlation  </span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMat(df_tr1,'signal',figsize=(7,0.5)) # Baseline Dataframe feature correlation to Signal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The linear correlation values of our current features <code>open</code>,<code>high</code>,<code>low</code>,<code>close</code>,<code>volumes</code>,<code>weighted_price</code> to the target variable is very minimal; \n- which could suggest a number of things; <code>high nonlinearity</code>, <code>stable oscillation relative to stationary value</code> (circular scatter) or perhaps they are not the most ideal to model the target, <code>signal</code>, and can be improved, so attention shifts to <code>feature engineering</code>."},{"metadata":{},"cell_type":"markdown","source":"## 2.5.<span style='color:#F1C40F'> Feature Engineering </span>\n\n- As indicated in the introduction, in the current problem, we will focus on <code>technical indicators</code> as part of our <code>feature engineering</code> approach in an attempt to introduce more relevant features into the <code>feature matrix</code>.\n- It's interesting to know (in the context of a <code>digital asset</code> ), which features have impact on the model's performance, if any.\n\n<b>Specifically:</b>\n***\n\n- <code>Moving Average</code> : A moving average provides an indication of the trend of the price movement by reducing the amount of noise. <br>\n- <code>Stochastic Oscillator %K and %D</code> : A stochastic oscillator is a momentum indicator comparing a particular closing price of a security to a range of its prices over a certain period of time. %K and %D are slow and fast indicators. <br>\n- <code>Relative Strength Index(RSI)</code> : It is a momentum indicator that measures the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of a stock or other asset. Ranging from [0,100]. <b>Asset -> 70: asset deemed overbought</b>. <b>Asset -> 30: asset getting undersold & undervalued.</b><br>\n- <code>Rate Of Change(ROC)</code>: It is a momentum oscillator, which measures the percentage change between the current price and the n period past price. Assets with <b>higher ROC values</b> are considered more likely to be overbought & <b>lower ROC</b>; more likely to be oversold.<br>\n- <code>Momentum (MOM)</code> : It is the rate of acceleration of a security's price or volume; the speed at which the price is changing. <br>\n\nCan be all be potentially useful to model the target variable, <code>signal</code>, with of course varing degress of influence."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr2 = df_tr1.copy()  # Create duplicate dataframe & add features to it\ndf_te2 = df_tr2.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"''' Technical Indicators '''\n\n#Calculation of moving average\ndef ma(df, n):\n    return pd.Series(df['Close'].rolling(n, min_periods=n).mean(), name='MA_' + str(n))\n\n# exponentially weighted moving average \ndef ema(df, n):\n    return pd.Series(df['Close'].ewm(span=n,min_periods=n).mean(), name='EMA_' + str(n))\n\n#Calculation of price momentum\ndef mom(df, n):     \n    return pd.Series(df.diff(n), name='Momentum_' + str(n))  \n\n# rate of change\ndef roc(df, n):  \n    M = df.diff(n - 1) ; N = df.shift(n - 1)  \n    return pd.Series(((M / N) * 100), name = 'ROC_' + str(n)) \n\n# relative strength index\ndef rsi(df, period):\n    delta = df.diff().dropna()\n    u = delta * 0; d = u.copy()\n    u[delta > 0] = delta[delta > 0]; d[delta < 0] = -delta[delta < 0]\n    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n    u = u.drop(u.index[:(period-1)])\n    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n    d = d.drop(d.index[:(period-1)])\n    rs = u.ewm(com=period-1, adjust=False).mean() / d.ewm(com=period-1, adjust=False).mean()\n    return 100 - 100 / (1 + rs)\n\n# stochastic oscillators slow & fast\ndef sto(close, low, high, n,id): \n    stok = ((close - low.rolling(n).min()) / (high.rolling(n).max() - low.rolling(n).min())) * 100\n    if(id is 0):\n        return stok\n    else:\n        return stok.rolling(3).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def tech_indi(ldf,tr_id=True):\n\n    ''' Moving Average '''\n    ldf['MA21'] = ma(ldf,10)\n    ldf['MA63'] = ma(ldf, 30)\n    ldf['MA252'] = ma(ldf, 200)\n    lst_MA = ['MA21','MA63','MA252']\n\n    ''' Exponentially Weighted Moving Average '''\n    ldf['EMA10'] = ema(ldf, 10)\n    ldf['EMA30'] = ema(ldf, 30)\n    ldf['EMA200'] = ema(ldf, 200)\n    lst_EMA = ['EMA10','EMA30','EMA200']\n\n    ''' Momentum '''\n    ldf['MOM10'] = mom(ldf['Close'], 10)\n    ldf['MOM30'] = mom(ldf['Close'], 30)\n    lst_MOM = ['MOM10','MOM30']\n\n    ''' Relative Strength Index '''\n    ldf['RSI10'] = rsi(ldf['Close'], 10)\n    ldf['RSI30'] = rsi(ldf['Close'], 30)\n    ldf['RSI200'] = rsi(ldf['Close'], 200)\n    lst_RSI = ['RSI10','RSI30','RSI200']\n\n    ''' Slow Stochastic Oscillators '''\n    ldf['%K10'] = sto(ldf['Close'], ldf['Low'], ldf['High'],5,0)\n    ldf['%K30'] = sto(ldf['Close'], ldf['Low'], ldf['High'],10,0)\n    ldf['%K200'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 20,0)\n    lst_pK = ['%K10','%K30','%K200']\n\n    ''' Fast Stochastic Oscillators '''\n    ldf['%D10'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 10,1)\n    ldf['%D30'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 30,1)\n    ldf['%D200'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 200,1)\n    lst_pD = ['%D10','%D30','%D200']\n    \n    # Plot Training Data\n    if(tr_id):\n        plot_line(ldf.loc[period,lst_MA],lst_MA,title='Moving Average (window=21,63,252)')\n        plot_line(ldf.loc[period,lst_EMA],lst_EMA,title='Exponential Moving Average (window=10,30,200)')\n        plot_line(ldf.loc[period,lst_MOM],lst_MOM,title='Momentum')\n        plot_line(ldf.loc[period,lst_RSI],lst_RSI,title='Relative Strength Index')\n        plot_line(ldf.loc[period,lst_pK],lst_pK,title='Stochastic Oscillators (slow)')\n        plot_line(ldf.loc[period,lst_pD],lst_pD,title='Stochastic Oscillators (Fast)')\n    \ntech_indi(df_tr2) # add technical features to training set\ntech_indi(df_te2,tr_id=False) # add technical features to test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All the current features\ndf_tr2.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.6.<span style='color:#F1C40F'> Updated Features: Linear Correlation  </span>\nHaving created new features; <code>MA</code>,<code>EMA</code>,<code>MOM</code>,<code>RSI</code>,<code>%K/%D</code>,\nlet's investigate the linear correlation of these new featuers to the target variable & compare to the <code>baseline dataset</code> features."},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMat(df_tr2,'signal',figsize=(15,0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see the significanly more linearly correlated group of features that were created as a result of <code>feature engineering</code>.\n- It's likely that the <code>base</code> dataset features will have little to no impact on target variable variation if used in the <code>feature matrix</code>.\n- On the otherhand, the newly created features have a reasonably wide range of correlated values, and quite important; are not too highly correlated to the target variable, <code>signal</code>."},{"metadata":{"trusted":true},"cell_type":"code","source":"def drp_feat(ldf):\n    ldf = ldf.drop(['High','Low','Open','Volume_(Currency)'], axis=1) # let's drop most of the original feature\n    \ndrp_feat(df_tr2)\ndrp_feat(df_te2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having applied functions to our <code>feature matrix</code>, we need to recheck for missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"NaN_values = (df_tr2.isnull().sum() / len(df_tr2) * 100).sort_values(ascending = False)\nbar_plot(x = NaN_values,y = NaN_values.index,palette_len = NaN_values.index, \n         xlim = (0,1),xticklabels = range(0,10),yticklabels = NaN_values.index,\n         figsize = (10,5), axis_grid = 'x')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr2 = df_tr2.dropna() \ndf_te2 = df_te2.dropna()\ndf_tr2.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.<span style='color:#273746'> Model Generation </span>\n- Having defined a clear <code>target variable</code> & <code>feature matrix</code>, let's review what we have: <br><br>\n    - df_tr1/df_te1 : <code>Training/Test dataframe of baseline features associated to the asset</code>\n    - df_tr2/df_te2 : <code>Training/Test dataframe of newly created features created in feature engineering stage </code>\n\nAnd we can start making models to predict the target variable <code>signal</code> (market directivity), using the evaluation function below.\n\n<b>The Evaluation Function is (hidden below):</b><br><br>\nThe aim of the evaluation function is to evaluate how well the model performs on different data split & evaluation approaches.\n\n<b>(1)</b> The function takes in a <code>dataframe</code> which contains both the <code>feature matrix, X</code> & <code>target variable, y</code>. <br>\n<b>(2)</b> The data is split into two parts; <code>train_df</code> & <code>eval_df</code> <br>\n<b>(3)</b> A 5-Fold <code>cross validation</code> evaluation of the imported dataframe is evaluated to get a picture of how well the model performs on the training data (both little and big chunks)<br>\n<b>(4)</b> A standard Two-Way Split (without data shuffling) is made, and trained on <code>X_train/y_train</code> & <code>X_eval/y_eval</code>"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\n# Lightweight Models \nmodels.append(('LR', LogisticRegression(n_jobs=-1)))  # Linear Supervised Model\nmodels.append(('LDA', LinearDiscriminantAnalysis()))  # Unsupervised Model \nmodels.append(('KNN', KNeighborsClassifier()))  # Unsupervised Model\nmodels.append(('TREE', DecisionTreeClassifier())) # Supervised Model\nmodels.append(('NB', GaussianNB())) # Unsupervised Model\n\n# More Advanced Models\n# models.append(('ANN', MLPClassifier(hidden_layer_sizes=(5,5)))) # default (100,) is way too long, even (5,5) is quite long \nmodels.append(('GBM', GradientBoostingClassifier(n_estimators=25)))\nmodels.append(('XGB',XGBClassifier(n_estimators=25)))\nmodels.append(('CAT',CatBoostClassifier(silent=True,n_estimators=25)))\nmodels.append(('RF', RandomForestClassifier(n_estimators=25)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# eval_id (T/F): [CV,Train,Test,all]\n\ndef modelEval(ldf,feature='signal',split_id=[None,None],eval_id=[True,True,True,True],\n              n_fold=5,scoring='accuracy',plot_id=[False,True],cv_yrange=None,hm_vvals=[0.5,1.0,0.75]):\n    \n    print('Evaluation Function')\n    print(f'Cross Validation Activated, n_splits : {n_fold}, scoring metric: {scoring}')\n    if(eval_id[2]):\n        if(split_id[0] is not None):\n            print(f'Train/Evaluation Set Spit Activated: {split_id[0]}')\n        if(split_id[1] is not None):\n            print(f'Train/Evaluation Set Split made at {split_id[1]}')\n    \n    ''' 1. Split Train/Evaluation <DataFrame> Set Split '''\n    \n    # split_id : Train/Test split [%,timestamp], whichever is not None\n    # test_id : Evaluate trained model on test set only\n    \n    if(split_id[0] is not None):\n        # General Percentage Split (Non Shuffle requied for Time Series)\n        train_df,eval_df = train_test_split(ldf,test_size=split_id[0],shuffle=False)\n    elif(split_id[1] is not None):\n        # specific time split \n        train_df = df.loc[:split_id[1]]; eval_df = df.loc[split_id[1]:] \n    else:\n        print('Choose One Splitting Method Only')\n        \n    ''' 2. Train/Test Feature Matrices + Target Variables Split'''\n    \n    y_train = train_df[feature]\n    X_train = train_df.loc[:, train_df.columns != feature]\n    y_eval = eval_df[feature]\n    X_eval = eval_df.loc[:, eval_df.columns != feature]\n    X_one = pd.concat([X_train,X_eval],axis=0)\n    y_one = pd.concat([y_train,y_eval],axis=0)\n    \n    print('');print(f'Using Features: {X_train.columns}')\n    print(f'Target Variable: {feature}');print('')\n        \n    ''' 3. Visualise Training/Test Data'''\n    if(plot_id[0]):\n        \n        # plot the training data\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=train_df.index, y=train_df['signal'],mode='lines',name='Training Data', line={'width': 0.25}))\n        fig.update_layout(height=300,width=800,template='plotly_white',title='Training Signal Visualisation',\n                          margin=dict(l=50,r=80,t=50,b=40))\n        \n        # Plot the test data as well \n        if(eval_id[2]):\n            fig.add_trace(go.Scatter(x=eval_df.index, y=eval_df['signal'],mode='lines',name='Test Data',line={'width': 0.25}))\n            fig.update_layout(title='Training/Test Signal Visualisation')\n        fig.show()\n    \n    ''' 4. Cross Validation, Training/Evaluation, one evaluation'''\n    lst_res = []; names = []; lst_train = []; lst_eval = []; lst_one = []; lst_res_mean = []\n    if(any(eval_id)):\n        for name, model in models:  # cycle through models & evaluate either cv or train/test\n            names.append(name)\n            \n            # Cross Validation Model on Training Se\n            if(eval_id[0]):\n                t0=time.time()\n                kfold = KFold(n_splits=n_fold, random_state=10)\n                cv_res = cross_val_score(model,X_train,y_train, cv=kfold, scoring=scoring)\n                t1 = time.time()\n                lst_res.append(cv_res)\n                tt1 = t1-t0 # total time for n_fold cross evaluation\n                \n            # Evaluate Fit Model on Training Data\n            t2 = time.time()\n            if(eval_id[1]):\n                t2 = time.time()\n                res = model.fit(X_train,y_train)\n                train_res = accuracy_score(res.predict(X_train),y_train); lst_train.append(train_res)\n            if(eval_id[2]):\n                if(eval_id[1] is False):  # If training hasn't been called yet\n                    res = model.fit(X_train,y_train)\n                eval_res = accuracy_score(res.predict(X_eval),y_eval); lst_eval.append(eval_res)\n            t3 = time.time()\n            tt2 = t3-t2 # total time for training/evaluation train/prediction\n            \n            # Evaluate model on entire dataset\n            if(eval_id[3]):\n                t4 = time.time()\n                res = model.fit(X_one,y_one)\n                one_res = accuracy_score(res.predict(X_one),y_one); lst_one.append(one_res)\n                t5 = time.time()\n                tt3 = t5-t4 # total time for training & evaluation on whole dataframe\n            \n            ''' [out] Verbal Outputs '''\n            # Cross Validation / Training / Evaluation Model Evaluation / Section Times\n            lst_res_mean.append(cv_res.mean())\n            fn1 = cv_res.mean(); fn2 = cv_res.std();\n            fn3 = train_res; fn4 = eval_res; fn5 = one_res\n            print(f\"{name} : {fn1:.3f}({fn2:.3f}) -> {tt1:.2f}s | {fn3:.3f} & {fn4:.3f} -> {tt2:.2f}s | {fn5:.3f} -> {tt3:.2}s\")\n      \n    s0 = pd.Series(np.array(lst_res_mean),index=names)\n    s1 = pd.Series(np.array(lst_train),index=names)\n    s2 = pd.Series(np.array(lst_eval),index=names)\n    s3 = pd.Series(np.array(lst_one),index=names)\n    pdf = pd.concat([s0,s1,s2,s3],axis=1)\n    pdf.columns = ['cv_average','train','test','all']\n    s4 = pd.Series([tt1,tt2,tt3],index=['cv','train/test','all'])\n        \n    ''' 5. Visual Ouputs '''\n    if(plot_id[1]): \n        \n        sns.set(style=\"whitegrid\")\n        fig,ax = plt.subplots(1,2,figsize=(15,4))\n        ax[0].set_title(f'{n_fold} Cross Validation Results')\n        sns.boxplot(data=lst_res, ax=ax[0], orient=\"v\",width=0.3)\n        ax[0].set_xticklabels(names)\n        sns.stripplot(data=lst_res,ax=ax[0], orient='v',color=\".3\",linewidth=1)\n        ax[0].set_xticklabels(names)\n        ax[0].xaxis.grid(True)\n        ax[0].set(xlabel=\"\")\n        if(cv_yrange is not None):\n            ax[0].set_ylim(cv_yrange)\n        sns.despine(trim=True, left=True)\n    \n        sns.heatmap(pdf,vmin=hm_vvals[0],vmax=hm_vvals[1],center=hm_vvals[2],\n                    ax=ax[1],square=False,lw=2,annot=True,fmt='.3f',cmap='Blues')\n        ax[1].set_title('Accuracy Scores')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1.<span style='color:#F1C40F'> Baseline Feature Model Evaluation</span> \n- The <code>Baseline Features</code> include: the asset's minute's <code>open</code>,<code>high</code>,<code>low</code>,<code>close</code>,<code>Volume_(BTC)</code>,<code>Volume_(Currency)</code> & <code>Weighted_Price</code>\n- As I found out, in time series applications, it's not very common to use base features associated with one asset only, but let's see how it fairs anyway, let's also plot the training data to get a visual idea of what we are attempting to model."},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr1,split_id=[0.2,None],plot_id=[False,True])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see that the <code>cross_val_score</code> is hovering in the region of <code>accuracy = 0.5</code>, which suggests that using only <code>baseline features</code> associated with one asset isn't quite suitable to predict accurate asset directivity.\n- Most models tended to have a higher <code>training score</code> than the <code>cross validation score</code>\n- It was interesting to see that the <code>DecisionTreeClassifier</code> & <code>RandomForest</code>, even with very few estimators are able to achieve very high scores (be it overfitted), suggesting tree based models could be very useful in this problem & <code>kNN</code> can also be added to the list of someone overfitting models on the training data as they tend to have lower cross validation scores.\n\n<code>Training & Evaluation time</code> also is quite important in this problem:\n***\n   - Having used only (100k/4.5M), the cost even with 7 features is quite high for the more advanced models, (<code>esp.GBM & ANN</code>); \n   - More advanced models had to be tuned down significantly to reduce the training time to comparable levels, therefore it's desirable to optimise the feature selection process.\n   - <code>XGB</code> & <code>CAT</code>, surprising were quite quick for quite advanced model, indicating it's quite well optimised for being used right out of the box. <code>RandomForest</code> being a similar model to XGB is much slower."},{"metadata":{},"cell_type":"markdown","source":"## 3.2.<span style='color:#F1C40F'> Updated Feature Model Evaluation</span> \nWe created new features in the <code>feature engineering</code> in <code>Section 2.5</code>, generating the updated features: <code>df_feat</code> dataframe, let's retry with these new features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr2,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"- We can see a very significant improvement in the <code>accuracy</code> scores, when compared to the <code>baseline model</code>.\n- <code>LinearDiscriminantAnalysis()</code> performs surprising well, for not only on the training set but also in the cross validation, it's also one of the fastest approaches, making it one of the most efficient approaches for large datasets.\n- Among the higher scoring model <code>LDA</code>, are not surprisingly more advanced models, <code>GBM</code>,<code>XGB</code>,<code>CAT</code>,<code>RF</code> as well.\n- <code>kNN()</code> and <code>GaussianNB()</code> unsupervised models performed slightly worse, in comparison to supervised learning models."},{"metadata":{},"cell_type":"markdown","source":"# 4.<span style='color:#273746'> Model Efficiency Optimisation </span>\n- A big issue encounted when trying to reach the objective in the problem is the large number of tick data (every minute) in the entire dataset, which increases the computational training & evaluation cost quite a bit.\n- Since the <code>feature matrices</code> are dependent on the number of features & instances, a reduction of even one unnecessary feature woud have a visible impact on the computational cost.\n- It is therefore of upmost importance to <b>reduce unnecessary features</b> as much as possible, to the problem \nbalancing act between model accuracy and training/prediction speed.\n\n<b>Let's look at two approaches one might take:</b>\n***\n<b>(1) Dimensionality Reduction via Feature Importance Evaluation (which is a more manual process) </b>\n\nAlthough this is more of a manual process since all libraries are not combine, let's try to find common ground between all approaches and combine them into one <code>feature importance</code> evaluation approach function to allow us to identify, evaluate and remove features to speed up our approach.\n\n<b>(2) Dimensionality Reduction using Unsupervised Learning Algorithms (more automated process)</b>\n\nA rather straightforward <code>fit & transform</code> collection of powerful <code>dimension reduction</code> algorithms are available to us in the <code>sklearn</code> library, the only issue I can think of is that; explaining what the resultant features mean may be a little problematic.\n\n## 4.1.<span style='color:#F1C40F'> Dimensionality Reduction via Feature Importance  </span> \nOther than the linear correlation metric, let's look at a few other approaches that can be used to evaluated the <code>relative importance</code> of features in our <code>feature matrix</code>. There are quite a few libraries we can explore, I've picked out four quite commonly used onces.\n\n<b>Let's look at these libraries in the next function:</b>\n***\n- Linear Correlation w/ ABS()\n- SHAP Values of Catboost Model (n_est=100)\n- RandomForest (n_est=100)\n- XGBoost (n_est=100)\n- K_Best (k=5)\n***\n<code>Linear Correlation</code> | We can interpret smaller linear correlation values as being less impactful & visa versa. <br>\n<code>SHAP</code> | A very well rounded description of the approach can be found on [Github](https://christophm.github.io/interpretable-ml-book/shap.html) <br>\n<code>RandomForest</code> | One of the more common approaches to evaluate relative feature importance is to use <code>RandomForest()</code>.<br>\n<code>XGBoost</code> | Similar to tree based algorithms, <code>XGBoost</code> has a model based feature importance option. <br>\n<code>K-Best</code> | Detailed explanation of how the features are ranked can be found on [Stack Overflow](https://stackoverflow.com/questions/57273694/how-selectkbest-chi2-calculates-score).\n\n***\n\n- The indivual scores are combined and scaled using <code>MinMaxScaler()</code>, output in Plotly\n- The y-axis represents the total score (higher score is better, max -> Number of approaches).\n- The x-axis represents the corresponding features of input dataframe."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def feature_importance(ldf,feature='signal',n_est=100):\n\n    # Input dataframe containing feature & target variable\n    X = ldf.copy()\n    y = ldf[feature].copy()\n    del X[feature]\n    \n#   CORRELATION\n    imp = corrMat(ldf,feature,figsize=(15,0.5),ret_id=True)\n    del imp[feature]\n    s1 = imp.squeeze(axis=0);s1 = abs(s1)\n    s1.name = 'Correlation'\n#     display(s1)\n        \n#   SHAP\n    model = CatBoostRegressor(silent=True,n_estimators=n_est).fit(X,y)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X)\n    shap_sum = np.abs(shap_values).mean(axis=0)\n    s2 = pd.Series(shap_sum,index=X.columns,name='Cat_SHAP').T\n#     display(s2)\n    \n#   RANDOMFOREST\n    model = RandomForestRegressor(n_est,random_state=0, n_jobs=-1)\n    fit = model.fit(X,y)\n    rf_fi = pd.DataFrame(model.feature_importances_,index=X.columns,\n                                         columns=['RandForest']).sort_values('RandForest',ascending=False)\n    s3 = rf_fi.T.squeeze(axis=0)\n#     display(s3)\n\n#   XGB \n    model=XGBRegressor(n_estimators=n_est,learning_rate=0.5,verbosity = 0)\n    model.fit(X,y)\n    data = model.feature_importances_\n    s4 = pd.Series(data,index=X.columns,name='XGB').T\n#     display(s4)\n    \n#   KBEST\n    model = SelectKBest(k=5, score_func=f_regression)\n    fit = model.fit(X,y)\n    data = fit.scores_\n    s5 = pd.Series(data,index=X.columns,name='K_best')\n#     display(s5)\n\n    # Combine Scores\n    df0 = pd.concat([s1,s2,s3,s4,s5],axis=1)\n    df0.rename(columns={'target':'lin corr'})\n\n    x = df0.values \n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df = pd.DataFrame(x_scaled,index=df0.index,columns=df0.columns)\n    df = df.rename_axis('Feature Importance via', axis=1)\n    df = df.rename_axis('Feature', axis=0)\n    \n    pd.options.plotting.backend = \"plotly\"\n    fig = df.plot(kind='bar',title='Scaled Feature Importance')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance(df_tr2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can note that for a lot of features, a small value in <code>correlation</code> magnitude (Pearson's value) also gives small score values in other approaches. Similarly high <code>correlated</code> features tend to have high scores in other <code>feature importance</code> methods, which is quite interesting. There are some exceptions, like <code>%D10</code> & <code>MOM10</code>.\n- Whilst there are a few features which show some slight dissagreement when it comes to feature importance, overall, <b>feature score similarity can be observed  for most approaches</b>.\n\n- It's interesting to note scores of identical feature cases (eg. <code>MOM10</code>, <code>MOM30</code>); we can get an idea of potentially new features that could we could try out ( perhaps <code>MOM20</code> would have worked better than <code>MOM10</code> )\n- We can observe a lot of features that have a <b>very low relative score value</b> for most methods, and hence probably have little to no impact, even if they were to be removed.\n- Removing potentially unimpactful features (which is around 50% of them) would make our whole approach much more efficient, and allow us to focus on more lengthy and in depth <code>hyperparameter</code> gridsearches that hopefully will be more accurate than any of our current models."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr2_FI = df_tr2.drop(columns=['Open','High','Low','Close','Volume_(BTC)','Volume_(Currency)','Weighted_Price','MA63','EMA10','%K10'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr2_FI,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2.<span style='color:#F1C40F'> Dimensionality Reduction using Unsupervised Learning Algorithms</span>\n\nAn alternative approach to <code>dimension/feature</code> reduction is the utilisation of <b>Unsupervised Learning</b> methods.\n- We need to select an algorithm (it's best to look at quite a few and see how they perform), \n- Perhaps apply some <code>scaling</code> & simply <code>fit_transform</code> to get the modified <code>feature matrix</code> which will have the selected dimension.\n\nThe next function contains the following selectable <code>Unsupervised Learning</code> algorithms to achieve dimensionaliy reduction:\n***\n- <code>PCA</code>, <code>Sparse PCA</code>, <code>Kernel PCA</code>, <code>Incremental PCA</code>, <code>Truncated SVD</code>\n- <code>Fast ICA</code>, <code>Gaussian Random Projection</code>, <code>Sparse Random Projection</code>\n- <code>IsoMap (Manifold)</code>,<code>MDS (Manifold)</code>,<code>TSNE (Manifold)</code>\n- <code>Locally Linear Embedding</code>, <code>Mini Batch Dictionary Learning</code>\n\nNot all of them are realisable on Kaggle due to the limited computational memory (esp. <b>Manifold</b> approaches), even with the <code>red_mem</code> function, so we'll use approaches that are requite less computational resources to run."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def dimRed(ldf,feature='signal',split_id=[None,None],n_comp=5,plot_id=True,\n           model_id='sparserandomprojection',scaler_id=[False,None]):\n    \n    # Given a dataframe, split feature/target variable\n    X = ldf.copy()\n    y = ldf[feature].copy()\n    del X[feature]\n    \n    n_jobs = -1; rs = 32\n    \n    if(model_id is 'pca'):\n        whiten = False\n        model = PCA(n_components=n_comp,whiten=whiten,random_state=rs)\n    if(model_id is 'sparsepca'):\n        alpha = 1\n        model = SparsePCA(n_components=n_comp,alpha=alpha,random_state=rs,n_jobs=n_jobs)\n    elif(model_id is 'kernelpca'):\n        kernel = 'rbf'; gamma = None\n        model = KernelPCA(n_components=n_comp,kernel=kernel,gamma=gamma,n_jobs=n_jobs,random_state=rs)\n    elif(model_id is 'incrementalpca'):\n        batch_size = None\n        model = IncrementalPCA(n_components=n_comp,batch_size=batch_size)\n    elif(model_id is 'truncatedsvd'): \n        algorithm = 'randomized';n_iter = 5\n        model = TruncatedSVD(n_components=n_comp,algorithm=algorithm,n_iter=n_iter,random_state=rs)\n    elif(model_id is 'gaussianrandomprojection'):\n        eps = 0.5\n        model = GaussianRandomProjection(n_components=n_comp,eps=eps,random_state=rs)\n    elif(model_id is 'sparserandomprojection'):\n        density = 'auto'; eps = 0.5; dense_output = True\n        model = SparseRandomProjection(n_components=n_comp,density=density, \n                                       eps=eps, dense_output=dense_output,random_state=rs)\n    if(model_id is 'isomap'):\n        n_neigh = 2\n        model = Isomap(n_neighbors=n_neigh,n_components=n_comp, n_jobs=n_jobs)    \n    elif(model_id is 'mds'):\n        n_init = 1; max_iter = 50; metric = False\n        model = MDS(n_components=n_comp,n_init=n_init,max_iter=max_iter,metric=True,\n                    n_jobs=n_jobs, random_state=rs)\n    elif(model_id is 'locallylinearembedding'):\n        n_neigh = 10; method = 'modified'\n        model = LocallyLinearEmbedding(n_neighbors=n_neigh,n_components=n_comp, method=method, \\\n                                    random_state=rs, n_jobs=n_jobs)\n    elif(model_id is 'tsne'):\n        learning_rate = 300; perplexity = 30; early_exaggeration = 12; init = 'random'\n        model = TSNE(n_components=n_comp, learning_rate=learning_rate, \\\n                    perplexity=perplexity, early_exaggeration=early_exaggeration, \\\n                    init=init, random_state=rs)\n    elif(model_id is 'minibatchdictionarylearning'):\n        alpha = 1; batch_size = 200; n_iter = 25\n        model = MiniBatchDictionaryLearning(n_components=n_comp,alpha=alpha,\n                                            batch_size=batch_size,n_iter=n_iter,random_state=rs)\n    elif(model_id is 'fastica'):\n        algorithm = 'parallel'; whiten = True; max_iter = 100\n        model = FastICA(n_components=n_comp, algorithm=algorithm,whiten=whiten, \n                          max_iter=max_iter, random_state=rs)\n    \n    # Scaling \n    if(scaler_id[0]):\n        \n        opts = [StandardScaler(),RobustScaler(),MinMaxScaler(), Normalizer(norm='l2')]\n        scaler = opts[scaler_id[1]].fit(X) \n        X_sca = pd.DataFrame(scaler.fit_transform(X),\n                                       columns = X.columns,\n                                       index = X.index) # summarize transformed data \n    \n    # Unsupervised Dimension Reduction \n    if(scaler_id[0]):\n        X_red = model.fit_transform(X_sca)\n    else:\n        X_red = model.fit_transform(X)\n    X_red = pd.DataFrame(data=X_red, index=X.index)\n    if(plot_id):\n        scatterPlot(X_red, y,model_id)\n    X_red[feature] = y\n    \n    return X_red # return new feature matrix\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard ICA (no scaling)\ndf_tr2_ICA = dimRed(df_tr2,split_id=[0.2,None],model_id='fastica',n_comp=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr2_ICA,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# StandardScaler ICA\ndf_tr2_ICA_sca0 = dimRed(df_tr2,split_id=[0.2,None],model_id='fastica',n_comp=5,scaler_id=[True,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr2_ICA_sca0,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RobustScaler ICA\ndf_tr2_ICA_sca1 = dimRed(df_tr2,split_id=[0.2,None],model_id='fastica',n_comp=5,scaler_id=[True,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr2_ICA_sca1,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MinMaxScaler ICA\ndf_tr2_ICA_sca2 = dimRed(df_tr2,split_id=[0.2,None],model_id='fastica',n_comp=5,scaler_id=[True,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr2_ICA_sca2,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normaliser ICA\ndf_tr2_ICA_sca3 = dimRed(df_tr2,split_id=[0.2,None],model_id='fastica',n_comp=5,scaler_id=[True,3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelEval(df_tr2_ICA_sca3,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}