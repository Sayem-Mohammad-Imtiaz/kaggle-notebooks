{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Understanding Business Use case for Sentiment Analysis\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Understanding peopleâ€™s emotions is essential for businesses since customers are able to express their thoughts and feelings more openly than ever before.\nFor example , it helps companies who have online presence like twitter and facebook to know if people are happy about their products or is there a need for further improvement.\n\n**NLP (Natural Language Processor) is a machine-learning strategy which processes textual data and converts it into numeric or vectorized formats. \nWe then feed this numeric data into out ML Model and make an analysis report.**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a dataframe object from out train csv file\ntweets_df=pd.read_csv('/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.info()\n#label=0 tells the tweet is positive and 1 tells that it was a negative tweet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here, we can see , we do not need the coloumn id , since it is not required for analysis, so we drop it\ntweets_df=tweets_df.drop(['id'],axis=1) #axis=1 because we want to drop the entire column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring our dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.isnull().sum()\n#there are no null entries or NaN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(tweets_df.isnull(),yticklabels=False,cbar=False,cmap='Blues')\n#Everything is blue , there are no null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['label'].hist(bins=30,figsize=(13,5),color='g')\n#positive tweets are around 29000 and negative tweets are around 2400","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(tweets_df['label'])\n#this gives a clearer and prioritized picture.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's find the length of tweets and see their popularity\n# creating a column for length of tweets in our data set\ntweets_df['length']=tweets_df['tweet'].apply(len) # apply len will return the length of each tweet and assign it to our new column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's plot the length description data\ntweets_df['length'].plot(bins=100,kind='hist',color='g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.describe()\n#minimum length of tweets is 11 and max is 274 while avg is 85","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's see the what is the tweet with min and max lengths\nprint(tweets_df[tweets_df['length']==11].iloc[0:])\nprint('-------------------------------------------------------------------------------------------------')\nprint(tweets_df[tweets_df['length']==274].iloc[0:])\n#both are positive/harmless tweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#most common length tweets are...\nprint(tweets_df[tweets_df['length']==85].iloc[0:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive=tweets_df[tweets_df['label']==0]\nnegative=tweets_df[tweets_df['label']==1]\n#gets the object for pos and neg tweets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting the word cloud\n\nA word cloud contains collection of all possible words used in our dataset and represents them in pictorial form","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#grab the tweet column and convert into one massive string\nsentences=tweets_df['tweet'].tolist()\nsentences=''.join(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nplt.figure(figsize=(20,20))\nplt.imshow(WordCloud().generate(sentences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's see the positive tweets' words\nplt.figure(figsize=(20,20))\nplt.imshow(WordCloud().generate(''.join(positive['tweet'].tolist())))\n#LOVE HAPPY USER THANKFUL POSITIVE TIME GIRL etc are the words used in positive tweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#similarly, for negative tweets\nplt.figure(figsize=(20,20))\nplt.imshow(WordCloud().generate(''.join(negative['tweet'].tolist())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DATA CLEANING\n\nfor efficient data analysis, we only need those words which add value to our predictions. Unneccesary punctuation marks and stop words are to be removed\n\nStopWords are most commonly used words like 'I','We','They','and' etc etc.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import string #for punctuation\nimport nltk #natural language tool kit\nfrom nltk.corpus import stopwords\n\nprint(string.punctuation)\nprint('------------------------------------------------------------------------------------------------------------------------')\nprint(stopwords.words('english'))\ndef text_cleaning(sentence):\n    sentence_punc_removed=[letter for letter in sentence if letter not in string.punctuation]\n    sentence_punc_removed=''.join(sentence_punc_removed)\n    sentence_clean=[word for word in sentence_punc_removed.split() if word.lower() not in stopwords.words('english')]\n    return sentence_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NO NEED TO RUN THIS>>>>> JUST TO GET THE IDEA\n# tweets_df_clean=tweets_df['tweet'].apply(text_cleaning)\n# #we get list of clean messages\n# print(tweets_df_clean.head)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FEATURE EXTRACTION\n\n### TOKENIZATION / COUNT VECTORIZER\n\n##### tokenization is a beautiful concept that helps to convert our textual data into some vectorized numeric form\n##### our count vectorizer is going to pick up unique words from our text and then find out the frequency of that particular word for each row and make a 2D vector accordingly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n#here, we performed data cleaning and count vectorization sequentially altogether !\n\ntweets_vectorizer=CountVectorizer(analyzer=text_cleaning,dtype='uint8').fit_transform(tweets_df['tweet']) #transforms text into numeric vectorized format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=tweets_vectorizer.toarray()\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=tweets_df['label']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MAKING OUR ML MODEL Using NAIVE BAYES CLASSIFIER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's first predict our accuracy by splitting our train data into test(say, 20 % of train) and train \nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2) #setting up train and test datasets\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nNB_classifier=MultinomialNB()\nNB_classifier.fit(X_train,y_train) #training our model using test datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Assessing Performance and making Report\n\nWe are going to use confusion matrix which is going to tell how **OFTEN** our predictions are right in terms true class\n\n#### It lists both false positive and false negatives ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix , classification_report\n\ny_test_predictions=NB_classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,y_test_predictions)\nsns.heatmap(cm,annot=True)\n# this means 5700+250 are correctly predicted whereas 220+180 are falsely predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_test_predictions))\n# accuracy - 0.94 (okay !)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LET'S WORK WITH OUR GIVEN TEST DATASET","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_test_df=pd.read_csv('/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv')\n\ntweets_test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_test_df=tweets_test_df.drop(['id'],axis=1)\nprint(tweets_test_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ntweets_test_classifier=CountVectorizer(analyzer=text_cleaning,dtype='uint8').fit_transform(tweets_test_df['tweet'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1=tweets_test_classifier.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nNB_test_classifier=MultinomialNB()\nNB_test_classifier.fit(X[:,0:31242],y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final_predictions=NB_test_classifier.predict(X1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_column=y_final_predictions.T\ntweets_test_df['label']=new_column\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X[:,0:31242])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_test_df.head","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AND WE ARE DONE :)\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}