{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font style=\"color:red;\"> <center>Deep Learning Hybrid Classification Model for Web Content <br> (Balanced Using Weights, Initialized with Output Bias) </center></font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'>Basic Initialisation</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Note the code in this Notebook requires tensorflow version 2.1.0rc0\n#!pip install grpcio==1.27.2 #This version of grpcio is reqd for tensorflow 2.1\n#!pip install tensorflow==2.1.0rc0\n#tf.__version__\n#!pip install tensorflow-hub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common imports\nimport pandas as pd\nimport numpy as np\nimport time\nimport os\nimport warnings\n\n#Time/CPU Profiling\noverall_start_time= time.time()\n\n# Load the TensorBoard notebook extension.\n%load_ext tensorboard\n\n# Clear any logs from previous runs\n!rm -rf ./logs/ \n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n#Disabling Warnings\nwarnings.filterwarnings('ignore')\n\n# To plot figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Loading Dataset </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying pathname of dataset before loading - for Kaggle\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));\n        print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Datasets\ndef loadDataset(file_name):\n    df = pd.read_csv(file_name,engine = 'python')\n    return df\nstart_time= time.time()\ndf_train = loadDataset(\"/kaggle/input/dataset-of-malicious-and-benign-webpages/Webpages_Classification_train_data.csv/Webpages_Classification_train_data.csv\")\ndf_test = loadDataset(\"/kaggle/input/dataset-of-malicious-and-benign-webpages/Webpages_Classification_test_data.csv/Webpages_Classification_test_data.csv\")\n#Ensuring correct sequence of columns \ndf_train = df_train[['url','content','label']]\ndf_test = df_test[['url','content','label']]\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## <font color='blue'>Preprocessing the Dataset </font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Cleaning the Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time= time.time()\ndf_test['content'] = df_test['content'].str.lower()\ndf_test.drop(columns=['url'],inplace=True)\ndf_test.rename(columns={'content':'text'},inplace=True)\ndf_train['content'] = df_train['content'].str.lower()\ndf_train.drop(columns=['url'],inplace=True)\ndf_train.rename(columns={'content':'text'},inplace=True)\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))\n#Looking for NaN, if any\n#print(df_train.isnull().sum())\n#print(df_test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_test\n#df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Converting Label Value to 0,1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting 'label' to numerical value (0-Malicious,1-Benign)\nstart_time= time.time()\ndf_test['label'].replace(to_replace =\"good\", value =1, inplace=True)\ndf_train['label'].replace(to_replace =\"good\", value =1, inplace=True)\ndf_test['label'].replace(to_replace =\"bad\", value =0, inplace=True)\ndf_train['label'].replace(to_replace =\"bad\", value =0, inplace=True)\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'>Analysis of Class Imbalance </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# No of Classes in Label\ndf_train['label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class Distribution of Labels\ndf_train.groupby('label').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analysis of Postives and Negatives in the Dataset\nneg, pos = np.bincount(df_train['label'])\ntotal = neg + pos\nprint ('Total of Samples: %s'% total)\nprint('Positive: {} ({:.2f}% of total)'.format(pos, 100 * pos / total))\nprint('Negative: {} ({:.2f}% of total)'.format(neg, 100 * neg / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Representation of Labels in the Stack form\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\n\n# create dummy variable then group by that\n# set the legend to false because we'll fix it later\ndf_train.assign(dummy = 1).groupby(['dummy','label']).size().groupby(level=0).apply(\n    lambda x: 100 * x / x.sum()).to_frame().unstack().plot(kind='bar',\n    stacked=True,legend=False, color={'red','green'})\n# or it'll show up as 'dummy' \nplt.xlabel('good/bad Websites')\n# disable ticks in the x axis\nplt.xticks([])\n# fix the legend or it'll include the dummy variable\ncurrent_handles, _ = plt.gca().get_legend_handles_labels()\nreversed_handles = reversed(current_handles)\ncorrect_labels = reversed(['bad','good'])\nplt.legend(reversed_handles,correct_labels)\nplt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())\n#plt.savefig(\"/img/C4.1/Fig1.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Earmarking Validation, Train & Test Sets </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Segregating Validation Set away from the Training Set\ntrain= df_train.iloc[:1000000,]\nval= df_train.iloc[1000001:,]\ntest= df_test.iloc[:,]\n\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')\nprint(len(test), 'test examples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the dataframes into X, y numpy arrays \nX_train = train['text'].to_numpy()\ny_train = train['label'].astype(int).to_numpy()\nX_val = val['text'].to_numpy()\ny_val = val['label'].astype(int).to_numpy()\nX_test = test['text'].to_numpy()\ny_test = test['label'].astype(int).to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> Making the Tensor Flow Deep Learning Model </font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Using Transfer Learning - making use of Text Embedding Model from Tensorflow Hub","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Transfer Learning from Tensorflow hub- Universal Text Encoder\nimport tensorflow_hub as hub\nfrom tensorflow import keras \n\nstart_time= time.time()\n# Use the saved ecoder from Stage I\nencoder = keras.models.load_model(\"/kaggle/input/savedmodel/PretrainedTFModel/1\")\n#encoder = hub.load(\"/kaggle/input/savedmodel/PretrainedTFModel/1\")\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))\nencoder(['Hello World']) #For Testing the Encoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making Class Specific Weights (for handling the Imbalance)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Scaling by total/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 / neg)*(total)/2.0 \nweight_for_1 = (1 / pos)*(total)/2.0\nclass_weight = {0: weight_for_0, 1: weight_for_1}\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting the Initial Bias","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The correct bias to set can be derived from:\n\n$$ p_0 = pos/(pos + neg) = 1/(1+e^{-b_0}) $$\n$$ b_0 = -log_e(1/p_0 - 1) $$\n$$ b_0 = log_e(pos/neg)$$","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"With this initialization the initial loss should be approximately:\n\n$$-p_0log(p_0)-(1-p_0)log(1-p_0) = 0.01317$$","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This loss is about 50 times less than a naive initialisation","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Using Initial Bias to overcome Class Imbalance\ninitial_bias = np.log([pos/neg])\ninitial_bias","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making and Initializing the TensorFlow Model","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Making a Tensorflow Model\nfrom tensorflow import keras\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc')]\ndef make_model(metrics = METRICS, output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    model = keras.Sequential([\n        #First layer is of Universal Text Encoder Deep Averaging Network (DAN) using Transfer Learning\n        hub.KerasLayer(encoder, input_shape=[],dtype=tf.string,trainable=True),\n        keras.layers.Dense(128, activation='relu'),\n        keras.layers.Dense(64, activation='relu'),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(32, activation='relu'),\n        keras.layers.Dense(16, activation='relu'),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(1, activation='sigmoid',\n        bias_initializer=output_bias),\n    ])\n    model.compile(optimizer=keras.optimizers.Adam(0.001),loss='binary_crossentropy',metrics=metrics)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Initialize the Model\nmodel_zero_bias = make_model()\nmodel_initial_bias = make_model(output_bias = initial_bias)\nmodel_zero_bias.summary() # print model summary with zeor bias\nmodel_initial_bias.summary() # print model summary with initial bias","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color =blue> Training the Model </font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Defining Early Stopping and Keras Tensorboard","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Fitting the Model with Class Weights\nfrom datetime import datetime\n\n#Defining Early Stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', \n    verbose=1,\n    patience=70,\n    mode='max',\n    restore_best_weights=True)\n\n# Define the Keras TensorBoard callback.\nlogdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting and Training without Initial Bias","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Fitting the Model without Inital Bias, but with Class weights\nstart_time= time.time()\nzero_bias_history = model_zero_bias.fit(X_train,y_train,batch_size=2048, epochs=100,validation_data=(X_val, y_val),\n          callbacks=[early_stopping,tensorboard_callback],\n          class_weight=class_weight)\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation of Model & Results: With Zero Bias","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Accuracy over Test Dataset\nresults = model_zero_bias.evaluate(X_test,y_test)\nprint(\"Loss: {0}, Accuracy: {1}\".format(results[0], results[5]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting and Training with Initial Bias","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Fitting the Model without Inital Bias, but with Class weights\nstart_time= time.time()\ninitial_bias_history = model_initial_bias.fit(X_train,y_train,batch_size=2048, epochs=100,validation_data=(X_val, y_val),\n          callbacks=[early_stopping,tensorboard_callback])\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation of Model & Results: With Initial Bias","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Accuracy over Test Dataset\nresults = model_initial_bias.evaluate(X_test,y_test)\nprint(\"Loss: {0}, Accuracy: {1}\".format(results[0], results[5]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix: Initial Bias Model","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Confusion Matrix\nr=results\ncon_mat_norm= [[r[3]/(r[3]+r[4]),r[2]/(r[2]+r[3])],[r[4]/(r[4]+r[1]),r[1]/(r[1]+r[4])]]\ncon_mat_df = pd.DataFrame(con_mat_norm,index = ['Malicious','Benign'], columns = ['Malicious','Benign'])\ncon_mat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plotting the Confusion Matrix Using Matploit & Seaborn\nimport seaborn as sns\n\nstart_time= time.time()\nfigure = plt.figure(figsize=(6,6))\nsns.heatmap(con_mat_df,annot=True,cmap=plt.cm.binary,fmt='g',linewidths=0.50,linecolor='black')\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n#plt.savefig(\"/img/C4.1/Fig2:ConfusionMatrix_B&W.png\")\nplt.show()\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=blue> Showing the Influence of Initial Bias </font>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"mpl.rcParams['figure.figsize'] = (12, 10)\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\ndef plot_loss(history, label, n):\n    # Use a log scale to show the wide range of values.\n    plt.semilogy(history.epoch,  history.history['loss'],\n               color=colors[n], label='Train '+label)\n    plt.semilogy(history.epoch,  history.history['val_loss'],\n          color=colors[n], label='Val '+label,\n          linestyle=\"--\")\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_loss(zero_bias_history, \"Zero Bias\", 0)\nplot_loss(initial_bias_history, \"Initial Bias\", 1)\n#plt.savefig(\"/img/C4.1/Fig3:Bias Plot.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=blue> Plotting of Metrics: Loss, AUC, Precision & Recall </font>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_metrics(history):\n    metrics =  ['loss', 'auc', 'precision', 'recall']\n    for n, metric in enumerate(metrics):\n        name = metric.replace(\"_\",\" \").capitalize()\n        plt.subplot(2,2,n+1)\n        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n        plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n            plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n            plt.ylim([0.8,1])\n        else:\n            plt.ylim([0,1])\n\n        plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_metrics(initial_bias_history)\n#plt.savefig(\"/img/C4.1/Fig4:Loss, AuC, Precision & Recall.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ROC Plot","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import sklearn\nfrom sklearn import metrics\n\ndef plot_roc(name, labels, predictions, **kwargs):\n    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n\n    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n    plt.xlabel('False Positive Rate [%]')\n    plt.ylabel('True Positive Rate [%]')\n    plt.xlim([-0.5,20])\n    plt.ylim([80,100.5])\n    plt.grid(True)\n    ax = plt.gca()\n    ax.set_aspect('equal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_predictions_baseline = model_initial_bias.predict(X_train, batch_size=2048)\ntest_predictions_baseline = model_initial_bias.predict(X_test, batch_size=2048)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_roc(\"Train\", y_train, train_predictions_baseline, color=colors[0])\nplot_roc(\"Test\", y_test, test_predictions_baseline, color=colors[0], linestyle='--')\nplt.legend(loc='lower right')\n#plt.savefig(\"/img/C4.1/Fig5:ROC Curve.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display Tensorboard Graphs","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"tensorboard --logdir logs  --port=8050","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=blue> Run Time Profiling Statistics of this Notebook </font>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Total Runtime of this Notebook\nprint(\"***Total Time taken --- %s mins ---***\" % ((time.time() - overall_start_time)/60))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Miscellaneous Maintenance Code: Run this for Selected Variables to Clear RAM Space\n(Note: Run this selectively only if you are Running Short of Memory)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Clearing Additional load of variables: Creating More RAM Space\nimport gc\n\n#del df_train_good\n#del df_train_bad\n#del df_trial\n#gc.collect()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}