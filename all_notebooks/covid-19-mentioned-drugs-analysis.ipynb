{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mentioned drugs in the COVID-19 articles.\n\nIn this work i will try to find drugs that mentioned in all article and try to understand those drugs.\nI will use a small dataset.\n### Update 1:\n1-I have found another useful dataset which is richer. The source can be found below.\n2-I checked drugs with their class and will do some wordcloud next.\n### Update 2:\n1- I  created a wordcloud on all sentence that mentioned about antivirals.\n2- I merge sentences and mentioned antivirals as a single dataframe.\n3- As a beta feature, i applied a sentiment analysis method but it will need some update due to week performance(some sentence gives no result, may be it is because sentences doesn't contain enough words to understand if the sentence postive or negative).\n### Update 3:\n1- I have done working on sentiment analysis of sentences of antiviral mentioned. \n2-I did weighted average on order by polarity-subjectivity scores including value counts of antiviral.\n3 The same work can also be done for other drug categories."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom glob import glob\nimport json\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\nfrom textblob import TextBlob\nfrom tqdm.notebook import tqdm\npd.set_option('display.max_colwidth', -1)\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dir_list = [\n    '/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv',\n    '/kaggle/input/CORD-19-research-challenge/comm_use_subset/comm_use_subset',\n    '/kaggle/input/CORD-19-research-challenge/custom_license/custom_license',\n    '/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset'\n]\nresults_list = list()\nfor target_dir in dir_list:\n    \n    print(target_dir)\n    \n    for json_fp in tqdm(glob(target_dir + '/*.json')):\n\n        with open(json_fp) as json_file:\n            target_json = json.load(json_file)\n\n        data_dict = dict()\n        data_dict['doc_id'] = target_json['paper_id']\n        data_dict['title'] = target_json['metadata']['title']\n\n        abstract_section = str()\n        for element in target_json['abstract']:\n            abstract_section += element['text'] + ' '\n        data_dict['abstract'] = abstract_section\n\n        full_text_section = str()\n        for element in target_json['body_text']:\n            full_text_section += element['text'] + ' '\n        data_dict['full_text'] = full_text_section\n        \n        results_list.append(data_dict)\n        \n    \ndf_results = pd.DataFrame(results_list)\ndf_results.head()        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading Drug dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdrugs=pd.read_csv('/kaggle/input/drug-data/drugsComTest_raw.csv')\ndfdrugs.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will split every word in all articles. To join it let's call the column drugName"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq = pd.DataFrame(' '.join(df_results['full_text']).split(), columns=['drugName']).drop_duplicates()\nfreq.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will split all texts of all article."},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.merge(freq, dfdrugs, on=['drugName'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.drugName.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results show us that drugs had been used for different cases and rated based on effects."},{"metadata":{},"cell_type":"markdown","source":"Let's do some filter:\n* removing drugs that has lower then 7 rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"result=result.where(result['rating']>7.0).dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 13891 column left."},{"metadata":{},"cell_type":"markdown","source":"We know that one of the main condition for Covid-19 is Cough so lets try to see drugs that been used for this purpose. I also Included headache so you can try yourself."},{"metadata":{"trusted":true},"cell_type":"code","source":"result.where(result['condition'].str.contains('Cough')).dropna().sample(5)\n#result.where(result['condition'].str.contains('Headache')).dropna()\n#result.where(result['condition'].str.contains('Cluster Headaches')).dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An example: lets see where Benzonatate mentioned in the articles."},{"metadata":{"trusted":true},"cell_type":"code","source":"articles=df_results['full_text'].values\nfor text in articles:\n    for sentences in text.split('.'):\n        if 'Benzonatate' in sentences:\n            print(sentences)        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another drug called Codeine."},{"metadata":{"trusted":true},"cell_type":"code","source":"for text in articles:\n    for sentences in text.split('.'):\n        if 'Codeine' in sentences:\n            print(sentences)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will use another dataset here, the source can be found below."},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdrugs2=pd.read_csv('../input/usp-drug-classification/usp_drug_classification.csv')\ndfdrugs2['drugName']=dfdrugs2['drug_example']\ndfdrugs2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result2 = pd.merge(freq, dfdrugs2, on=['drugName'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mentioned drugs category.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"result2['usp_category'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Antivirals**"},{"metadata":{"trusted":true},"cell_type":"code","source":"antivirals=list(result2.drugName.where(result2['usp_category']=='Antivirals').dropna().unique())\nantivirals[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An example of sentences that mention an antiviral named entecavir. Next work will be try to analyze if this drug mentioned in a positive or negative way."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for text in articles:\n    for sentences in text.split('.'):\n        if 'entecavir' in sentences:\n            print(sentences) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CA=list(result2.drugName.where(result2['usp_category']=='Cardiovascular Agents').dropna().unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" A wordcloud on all sentences for Cardiovascular Agents."},{"metadata":{"trusted":true},"cell_type":"code","source":"Cardiovascular_Agents =[]\nfor text in articles:\n    for sentences in text.split('.'):\n        if any(word in sentences for word in CA):\n            Cardiovascular_Agents .append(sentences)\n            #print(sentences) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = set(STOPWORDS)\nwordcloud = WordCloud(stopwords =stopwords, width=1000, height=500).generate(\"+\".join(Cardiovascular_Agents))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A wordcloud on all sentences for antivirals."},{"metadata":{"trusted":true},"cell_type":"code","source":"antivirals_all=[]\nfor text in articles:\n    for sentences in text.split('.'):\n        if any(word in sentences for word in antivirals):\n            antivirals_all.append(sentences)\n            #print(sentences) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(stopwords =stopwords, width=1000, height=500).generate(\"+\".join(antivirals_all))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Antivirals wordcloud&sentiment analysis."},{"metadata":{},"cell_type":"markdown","source":"I matched drugs and the sentences that include that drug. Note that at same cases one sentences may include many drugs."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(antivirals_all, columns=['sentence']) \ndef matcher(x):\n    for i in antivirals:\n        if i.lower() in x.lower():\n            return i\n    else:\n        return np.nan\n    \ndf['Match'] = df['sentence'].apply(matcher)    \ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Match'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentence'] = df['sentence'].astype(str)\ndf['sentence'] = df['sentence'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ndf['sentence'] = df['sentence'].str.replace('[^\\w\\s]','')\n\nstop = stopwords.words('english')\ndf['sentence'] = df['sentence'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\nst = PorterStemmer()\ndf['sentence'] = df['sentence'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n\ndef senti(x):\n    return TextBlob(x).sentiment  \n \ndf['senti_score'] = df['sentence'].apply(senti)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"polarity=[]\nsubjectivity=[]\nfor i, j in df.senti_score:\n    polarity.append(i)\n    subjectivity.append(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now finally we can see which antivirals mentioned positive with our sentiment analysis method. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['subjectivity']=subjectivity\ndf['polarity']=polarity\ndf.where(df['polarity']==1).dropna().head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We will use weighted rating to balance the polarity and subjectivity then we can see which one has the best score on those values including number mentions.\n[source](http://github.com/pytmar/Python-Code-Collection/blob/master/weighted-ratings.py)"},{"metadata":{"trusted":true},"cell_type":"code","source":"vote_data=df[['Match', 'polarity']]\nitems=vote_data['Match']#item's column\nvotes=vote_data['polarity']#vote's column\nnum_of_votes=len(items)\n    \nm=min(votes)\navg_votes_for_item=vote_data.groupby('Match')['polarity'].mean()#mean of each item's vote\nmean_vote=np.mean(votes)#mean of all votes\npol=pd.DataFrame(((num_of_votes/(num_of_votes+m))*avg_votes_for_item)+((m/(num_of_votes+m))*mean_vote))\npol.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vote_data=df[['Match', 'subjectivity']]\nitems=vote_data['Match']#item's column\nvotes=vote_data['subjectivity']#vote's column\nnum_of_votes=len(items)\n    \nm=min(votes)\navg_votes_for_item=vote_data.groupby('Match')['subjectivity'].mean()#mean of each item's vote\nmean_vote=np.mean(votes)#mean of all votes\nsub=pd.DataFrame(((num_of_votes/(num_of_votes+m))*avg_votes_for_item)+((m/(num_of_votes+m))*mean_vote))\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"on_weighted_score=pd.concat([pol, sub.reindex(pol.index)], axis=1).sort_values(by=['polarity', 'subjectivity'], ascending=False)\nvalue_count=pd.DataFrame(df['Match'].value_counts())\nbests=pd.concat([value_count, on_weighted_score.reindex(value_count.index)], axis=1).sort_values(by=['polarity', 'subjectivity'], ascending=False)\nbests.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## resources:\n* https://www.cdc.gov/coronavirus/2019-ncov/symptoms-testing/symptoms.html\n* https://www.kaggle.com/iancornish/drug-data\n* https://www.youtube.com/watch?v=S6GVXk6kbcs&lc=z23czv4rezzqspkcnacdp434abyko0xfj3zyelkza01w03c010c\n* https://www.kaggle.com/bgoss541/training-set-labeling-jump-start-umls-linking\n* https://www.kaggle.com/danofer/usp-drug-classification\n* https://data-science-blog.com/blog/2018/11/04/sentiment-analysis-using-python/"},{"metadata":{},"cell_type":"markdown","source":"**Final Note**:  I am not an expert on medicine just tried to do some text mining and crossing my borders on text mining. Please type down if we found any issue or have suggestion.\nThanks."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}