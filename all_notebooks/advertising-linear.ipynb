{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"Hi Friends!! \n\nThe main intension here is to provide steps on how a Linear Regression can be performed\n\nThis is purely based on my undestanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Problem Statement: on the basis of the expenditure incurred on each type of advertisement we need to predict the increse in sales                  "},{"metadata":{},"cell_type":"markdown","source":"### Understanding Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(r\"../input/advertising-data/Advertising.csv\",index_col=0,header=0)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(data.dtypes,\"\\n\")\nprint(data.shape,\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dependent/Target Variable : Sales, dtype as float(continuous) \n\nNo predictor is of data type Object\n\nModel : Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"### Steps :\n\n1. Pre model building Assumptions(Since Linear Regression)\n\n2. EDA and Data Cleanning\n\n3. Model building - Linear Regression\n\n4. Post Model building Assumptions\n\n5. Ridge Model\n\n6. Lasso Model\n\n7. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"### Step 1: Pre Model Buiding Assumptions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assumption 1 - No outliers in the data\n#can be checked using box plot\nf,axes=plt.subplots(2,2,figsize=(7,7))\nsns.boxplot(y=\"TV\",data=data,ax=axes[0,0],color=\"orange\")\nsns.boxplot(y=\"Radio\",data=data,ax=axes[0,1],color=\"pink\")\nsns.boxplot(y=\"Newspaper\",data=data,ax=axes[1,0],color=\"grey\")\nsns.boxplot(y=\"Sales\",data=data,ax=axes[1,1],color=\"brown\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plots we can see that only Newspaper has Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assumption 2 (Assumption of Linearity):\n#Every independent variable should have a linear relationship with dependent variable\n\nsns.pairplot(data,x_vars=[\"TV\",\"Radio\",\"Newspaper\"],y_vars=\"Sales\",kind=\"reg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TV vs. sales - strong positive linear relatioship\n\nRadio vs. sales - weak positive relationship(comparitively)\n\nNewspaper vs. sales - no relationship(we can discard such kind of variables which donot have a linear relationship)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assumption 3:\n#The dependent variable should follow an approx. normal distribution\n#can be checked using a distplot\n\nsns.distplot(data.Sales,bins=10,color=\"green\",hist=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above distribution plot for Sales is approximately normal\n\nIn case if the data is not normally distributed - we need to tranform data using log func or square root func\n\nLog Tranformation - since it smoothens the peaks\n\nimport numpy as np\n\nY_log = np.log(Y)\n\nsns.distplot(Y_log,hist=True)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assumption 4-There should no multi collinearity in the data\n#Can be checked using correlation and VIF(Variance inflation factor)\n#Relationship between the independent variables should not exsit\n\nind = data[[\"TV\",\"Radio\",\"Newspaper\"]]\n\ncorr_df = ind.corr(method = \"pearson\")\nprint(corr_df,\"\\n\")\n\nsns.heatmap(corr_df,vmax =1.0,vmin=-1.0,annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+1 : positively correlated\n\n-1 : negatively correlated\n\n0 : no correlation\n\nWe can see that there is no multi collinearity amng independent/predictor variables\n\nIf we have any multi collinearity :\n\nTechnique 1- drop either of them\n\nTechnique 2-check the correlation values of both variables with all the other values and drop that one which has high collinearity values with the others\n\nBut always these techniques might not help - so we go with VIF(Variance Inflation Factor), for more accurate results"},{"metadata":{"trusted":true},"cell_type":"code","source":"#VIF - 1/(1-R^2)\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n\nvif_df = pd.DataFrame()\nvif_df[\"features\"] = ind.columns\nvif_df[\"VIF Factor\"] = [vif(ind.values, i) for i in range(ind.shape[1])]\nvif_df.round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 2 : EDA and Data Cleaning"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.info()\n#No Null's in the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.boxplot(column=\"Newspaper\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data.hist(bins = 20,figsize=(10,7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is a good practise to check skewness in data\n\nNewspaper is highly skewed\n\nIf the skewness is not acceptable - transform the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforming data based on Skewness\n\nfrom scipy.stats import skew\ndata_num_skew = data.apply(lambda x: skew(x.dropna()))\ndata_num_skewed = data_num_skew[(data_num_skew > .75) | (data_num_skew < -.75)]\n\nprint(data_num_skew,\"\\n\")\nprint(data_num_skewed)\n\nimport numpy as np\ndata[data_num_skewed.index] = np.log1p(data[data_num_skewed.index])\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data.hist(bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The transformation didn't make much difference, Newspaper might not be a good variable for the model"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = data.copy()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 3 : Model Building(Linear Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating x and Y:\nX=data[[\"TV\",\"Radio\",\"Newspaper\"]]\nY=data[\"Sales\"]\nprint(X.head(),\"\\n\")\nprint(Y.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using sklearn"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size =0.2,random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,\"\\n\")\nprint(Y_train.shape,\"\\n\")\nprint(X_test.shape,\"\\n\")\nprint(Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\n\nlm.fit(X_train,Y_train)\n\nprint(lm.intercept_,\"\\n\")\nprint(list(zip(X.columns,lm.coef_)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction\nY_pred = lm.predict(X_test)\nprint(Y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EVALUATING model manually, just to cross check sice the data is very small\n#by comparing the actual Y values and predicted Y values\n\nnew_df = pd.DataFrame()\nnew_df =X_test\n\nnew_df[\"Actual Sales\"] =Y_test\nnew_df[\"Predicted Sales\"] = Y_pred\nnew_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By comparing the values from the above data frame we can say that model is a good one; but how good?\n\nSo we need to pass our model through some performance metrics -  R^2, adjusted R^2, RMSE, p-value, VIF(we have already calculated the values above)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score,mean_squared_error\n\nimport numpy as np\n\nr2 = r2_score(Y_test,Y_pred)\nprint(\"R^2 = \",r2,\"\\n\")\n\nadjusted_r_squared = 1 - (1-r2)*(len(Y)-1)/(len(Y)-X.shape[1]-1) #formula for adjusted R2\nprint(\"Adjusted R^2 = \",adjusted_r_squared,\"\\n\")\n\nrmse = np.sqrt(mean_squared_error(Y_test,Y_pred))#sqrt(SME) = RMSE\nprint(\"RMSE = \",rmse,\"\\n\")\n\n#Checking whether RMSE is a good value or not\n\nper=str(round(((rmse/max(Y_test))*100),2)) + \"%\"\nprint(\"Y_min = \",min(Y_test),\",  Y_max = \",max(Y_test), \", Percentage of Errors :\", per)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got good value for R2(towards 1)\n\nAdjusted R^2 will always be slightly lower that R^2\n\nValue for RMSE is also good since it is closer to Y_min value thus the errors are neglectable (10%)"},{"metadata":{},"cell_type":"markdown","source":"### Using statsmodel\n\nWe can get p-values only from statsmodel"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = pd.DataFrame()\nnew_df = X_train\n\nnew_df[\"Sales\"] = Y_train\nnew_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as sm\n\nlm_model = sm.ols(formula=\"Sales ~ TV + Radio + Newspaper\",data=new_df).fit()\n\nprint(lm_model.params,\"\\n\")\nprint(lm_model.summary())\n\n#Since p-value of Newspaper > 0.05, we can drop it","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"AIC(Akile Information Criteria) - when we have to compare different models with same algorithm. When the variables are added or deleted we will get different AIC's for every modep built - lowest AIC give the best model \n\nBIC(Bayes Information Criteria)\n\np-value => logic is hypothesis testing\n\nH0:There is no significant relationship between X and Y\n\nH1:There is a significant relationship between X and Y\n\nThreshold by default 0.05\n\nIf the p-val is <= 0.05(less), then Reject H0\n\nIf the p-val is > 0.05(High), then Select H0\n\nDrop the variable which have p values high(> 0.05)\n\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_new = lm_model.predict(X_test)\n\nfrom sklearn.metrics import r2_score,mean_squared_error\nimport numpy as np\n\nr2 = r2_score(Y_test,Y_pred_new)\nprint(\"R^2 :\",r2,\"\\n\")#good value of R2(towards 1)\n\nrmse = np.sqrt(mean_squared_error(Y_test,Y_pred_new))#sqrt(SME) => RMSE\nprint(\"RMSE :\", rmse,\"\\n\")\n\nadjusted_r_squared = 1 - (1-r2)*(len(Y)-1)/(len(Y)-X.shape[1]-1)#formula for adjusted R2\nprint(\"Adjusted R^2 :\",adjusted_r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model after Newspaper is removed from the formula"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as sm\n\nlm_model = sm.ols(formula=\"Sales ~ TV + Radio\",data=new_df).fit()\n\nprint(lm_model.params,\"\\n\")\nprint(lm_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Y_pred_new = lm_model.predict(X_test)\n\nfrom sklearn.metrics import r2_score,mean_squared_error\nimport numpy as np\n\nr2 = r2_score(Y_test,Y_pred_new)\nprint(\"R^2 :\",r2,\"\\n\")#good value of R2(towards 1)\n\nrmse = np.sqrt(mean_squared_error(Y_test,Y_pred_new))#sqrt(SME) => RMSE\nprint(\"RMSE :\", rmse,\"\\n\")\n\nadjusted_r_squared = 1 - (1-r2)*(len(Y)-1)/(len(Y)-X.shape[1]-1)#formula for adjusted R2\nprint(\"Adjusted R^2 :\",adjusted_r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can notice that R^2 has been slightly increased after removing Newspaper from the model "},{"metadata":{},"cell_type":"markdown","source":"### Step 4 : Post Model Building Assumptions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assumption 5 : No Auto Correlation in the data\n#Can be checked by Durbin Watson Test\n\n#Threshold - [0,4]\n#close to 2 - no auto correlation\n#close to 0 - positive auto correlation\n#close to 4 - negative auto correlation\n\n#From the above Summary DWT = 2.1 (No Auto Correlation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assumption 6 :Errors should be random \n#Can be checked using Residuals(Errors) Vs. Fitted values(actual) plot\n\nplot_lm_1 = plt.figure(1)\nplot_lm_1.set_figheight(8)\nplot_lm_1.set_figwidth(12)\n\nmodel_fitted_y = lm_model.fittedvalues\n\nplot_lm_1.axes[0] = sns.residplot(model_fitted_y, 'Sales', data=new_df, lowess=True)\n\nplot_lm_1.axes[0].set_title('Residuals vs Fitted')\nplot_lm_1.axes[0].set_xlabel('Fitted values')\nplot_lm_1.axes[0].set_ylabel('Residuals')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpreting the graph :\n\n1. We need a random line or a cure\n\n2. It should not follow a cyclic pattern, or a line/curve like pattern - if so then the errors are not random"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Assumption 7: Errors should follow an approximate normal distribution\n#can be checked using the normal Quantile-Quantile plot (normal qq plot)\n\n\nres = lm_model.resid\nimport statsmodels.api as stm\nimport scipy.stats as stats\nfig = stm.qqplot(res, fit=True, line='45')\nplt.title('Normal Q-Q')\nplt.xlabel('Theoretical Quantiles')\nplt.ylabel('Standardized Residuals')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpreting the graph:\n\nIf the error points are falling on the 45 degree red line then we can say that the errors are normally distributed"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Assumption 8 : Errors should follow a constant variance (Homoskedasticity)\n#Can be checked using the scale location plot\n\n# normalized residuals\nmodel_norm_residuals = lm_model.get_influence().resid_studentized_internal\n# absolute squared normalized residuals\nmodel_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n\nplot_lm_3 = plt.figure(3)\nplot_lm_3.set_figheight(8)\nplot_lm_3.set_figwidth(12)\nplt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5)\nsns.regplot(model_fitted_y, model_norm_residuals_abs_sqrt, lowess=True)\n\n\nplot_lm_3.axes[0].set_title('Scale-Location')\nplot_lm_3.axes[0].set_xlabel('Fitted values')\nplot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interpreting the graph :\n\n1. When we get an approximately horizontal line on the graph we can say that errors are following a constant variance\n\n2. There can be a little curve, we dont want a steep curve\n\n3. When we consider any part of the plot and find the variance it should be the same(approx.)"},{"metadata":{},"cell_type":"markdown","source":"### Step 5 : Ridge Model"},{"metadata":{},"cell_type":"markdown","source":"1. RIDGE MODEL(L2 panelty)\n\n2. Ridge just adjusts the b coefficients\n\n3. When compared to the previous model the coefficient values have changed slightly"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X=df[[\"TV\",\"Radio\",\"Newspaper\"]]\nY=df[\"Sales\"]\nprint(X.head(),\"\\n\")\nprint(Y.head())\n\n#Newspaper variable is considered just to understand Ridge Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size =0.2,random_state =10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,\"\\n\")\nprint(X_test.shape,\"\\n\")\nprint(Y_train.shape,\"\\n\")\nprint(Y_test.shape,\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nlm = Ridge()\nlm.fit(X_train,Y_train)\n\nprint(lm.intercept_,\"\\n\")\nprint(lm.coef_)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The coefficient of the variale which is not contributing more to the model will be the least\n\nCoefficient of Newspaper = -0.048(least)"},{"metadata":{},"cell_type":"markdown","source":"### Step 6 : Lasso Model"},{"metadata":{},"cell_type":"markdown","source":"1. LASSO MODEL(L1 panelty)\n\n2. Lasso zero's down the b coefficients whose variables are insignificant - can be used as feature extraction\n\n3. When compared to the Ridge model Lasso has slight change in the coefficient values "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nlm = Lasso()\nlm.fit(X_train,Y_train)\n\nprint(lm.intercept_,\"\\n\")\nprint(lm.coef_)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since Newspaper is not contributing to the model it's coefficient is replaced with \"0\" "},{"metadata":{},"cell_type":"markdown","source":"### Step 7 : Conclusion"},{"metadata":{},"cell_type":"markdown","source":"1. R^2 =  0.8354496662944217 (good value)\n\n2. Adjusted R^2 =  0.8337791045309133 (good value)\n\n3. RMSE =  2.5878817077378105 (good value w.r.t. the minimum and maximum values of target variable)\n\nSo we can conclude that the Linear Regression model built is a good one.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sales = X_test.copy()\n\ntest_sales[\"Sales\"] = Y_pred\ntest_sales[\"Predicted_Sales\"] = round(test_sales.Sales,2)\ntest_sales.drop(\"Sales\",axis=1,inplace=True)\ntest_sales.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}