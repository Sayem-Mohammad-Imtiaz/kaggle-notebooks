{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment analysis comparison: text features, LSTM and RoBERTa\n\n0. [Introduction](#0)\n\n1. [Preparation](#1)\n\n    1.1 [Packages](#1.1)\n    \n    1.2 [Data](#1.2)\n    \n2. [Text features](#2)\n\n3. [Deep Learning](#3)\n\n    3.1 [LSTM](#3.1)\n    \n    3.2 [RoBERTa](#3.2)","metadata":{}},{"cell_type":"markdown","source":"## 0. Introduction <a id=0></a>\n\nSentiment analysis is a NLP task which aims to classify a text based on the sentiment it conveys, aka its *polarity* (whether it is positive, neutral or negative). A typical business-oriented application is to analyze product reviews and customer feedbacks.\n\nThe dataset which we investigate contains tens of thousands of Amazon reviews, which have been labeled as positive or negative by looking at the score given by users. We show different approaches to the problem of sorting them in the correct class based on the content of the review, both using text-feature extraction and deep learning. ","metadata":{}},{"cell_type":"markdown","source":"## 1. Preparation <a id=1></a>\n\n### 1.1 Packages <a id=1.1></a>","metadata":{}},{"cell_type":"code","source":"!pip install -Uqq fastbook\n\n!pip install git+https://github.com/ohmeow/blurr/\n!pip install fsspec==2021.6.0\n!pip uninstall torchaudio --y\n!pip uninstall transformers --y\n!pip install transformers==4.6.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns; sns.set()\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, precision_recall_fscore_support\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\n\nimport nltk\nfrom nltk.corpus import stopwords\nimport spacy\nimport langid\n\nimport plotly\nimport plotly.express as px\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\n\ninit_notebook_mode(connected=True)\ncf.set_config_file(sharing='public',theme='white',offline=True)\n\nimport fastbook\nfastbook.setup_book()\n\nfrom fastai.text.all import *\nfrom fastbook import *\n    \nwarnings.filterwarnings(action='ignore', category=UserWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T15:41:17.900347Z","iopub.execute_input":"2021-06-14T15:41:17.900778Z","iopub.status.idle":"2021-06-14T15:41:25.417747Z","shell.execute_reply.started":"2021-06-14T15:41:17.900712Z","shell.execute_reply":"2021-06-14T15:41:25.416593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Data <a id=1.2></a>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/amazon-reviews/train.csv', header=None, names=['label', 'title', 'text'])\ntest_df = pd.read_csv('../input/amazon-reviews/test.csv', header=None, names=['label', 'title', 'text'])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:41:32.282032Z","iopub.execute_input":"2021-06-14T15:41:32.282382Z","iopub.status.idle":"2021-06-14T15:42:14.018122Z","shell.execute_reply.started":"2021-06-14T15:41:32.282352Z","shell.execute_reply":"2021-06-14T15:42:14.016995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The two dataframes have three columns:\n\n`label` - Target variable with two categorical levels: 1 if the review is negative (1/2 stars rating); 2 if the review is positive (4/5 stars rating).\n\n`title` - Heading of the review.\n\n`text` - Body of the review.\n\nSince the original dataset is huge, for time and memory contsraints **we will restrict to a random subset of 50000 rows from `train_df` and 10000 rows from `test_df`**, which will be respectively our training and validation set. We select such subsets randomly and so that their are both perfectly balanced. We also merge the `title` and `text` features in a single `text` column.","metadata":{}},{"cell_type":"code","source":"train_df['title'].fillna('', inplace=True)\ntest_df['title'].fillna('', inplace=True)\n\ntrain_len = 50000\ntest_len = 10000\nrs = 42\n\ndf = pd.concat([train_df.loc[train_df['label'] == 1].sample(train_len//2, random_state=rs),\n                train_df.loc[train_df['label'] == 2].sample(train_len//2, random_state=rs),\n                test_df.loc[test_df['label'] == 1].sample(test_len//2, random_state=rs),\n                test_df.loc[test_df['label'] == 2].sample(test_len//2, random_state=rs)]).reset_index(drop=True)\ndf['text'] = df['title'] + '. ' + df['text']\ndf.drop('title', axis=1, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:20:55.576782Z","iopub.execute_input":"2021-06-14T16:20:55.577207Z","iopub.status.idle":"2021-06-14T16:20:56.702932Z","shell.execute_reply.started":"2021-06-14T16:20:55.577174Z","shell.execute_reply":"2021-06-14T16:20:56.701872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Label counts - training set:\\n{df[:train_len].label.value_counts()}')\nprint(f'\\nLabel counts - validation set:\\n{df[train_len:].label.value_counts()}')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:45:22.535395Z","iopub.execute_input":"2021-06-14T15:45:22.535795Z","iopub.status.idle":"2021-06-14T15:45:22.55048Z","shell.execute_reply.started":"2021-06-14T15:45:22.535763Z","shell.execute_reply":"2021-06-14T15:45:22.548831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Text Features <a id=2></a>\n\nWe first try classifying reviews using **text vectorization**: we split the text into tokens and, for each token in the corpus, we count how many times it appears in a review. The counts for each token become the numerical features which we feed to the model. As tokens we will use not only single words, aka 1-grams, but also 2-grams and 3-grams, i.e. sequences of contiguous words of length 2 and 3 respectively.","metadata":{}},{"cell_type":"code","source":"cv = CountVectorizer(ngram_range=(1,3))\ncv.fit(df['text'])\nprint(f\"Number of n-grams in the corpus: {len(cv.vocabulary_)}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:46:31.590346Z","iopub.execute_input":"2021-06-14T15:46:31.59073Z","iopub.status.idle":"2021-06-14T15:47:15.535416Z","shell.execute_reply.started":"2021-06-14T15:46:31.590696Z","shell.execute_reply":"2021-06-14T15:47:15.534268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that our corpus contains more than four milion n-grams (for n = 1,2,3). Which are the most frequent ones?","metadata":{}},{"cell_type":"code","source":"fts = cv.get_feature_names()\nfreq = cv.transform(df['text'])\ngram_counts = np.array(freq.sum(0)).squeeze()\n\ngram_counts_df = pd.DataFrame({'n-gram': [fts[i] for i in gram_counts.argsort()],\n                               'count': sorted(gram_counts)})\n\npx.bar(gram_counts_df[-20:], y='n-gram', x='count', title='Most frequent n-grams', orientation='h', height=600)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:47:43.304434Z","iopub.execute_input":"2021-06-14T15:47:43.304792Z","iopub.status.idle":"2021-06-14T15:48:23.18788Z","shell.execute_reply.started":"2021-06-14T15:47:43.304761Z","shell.execute_reply":"2021-06-14T15:48:23.18689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 1-grams which appears more frequently in the corpus are unlikely to be particularly meaningful for the classification task at hand. This problem is usually tackled in two ways: we can either remove **stopwords** (i.e. the most frequent words in the language the review is written in, such as pronouns and conjunctions), or normalize the frequency counts based on how often each n-gram appears across the documents in the corpus, e.g. by using **tf-idf** vectorization, in order to penalize tokens that are common in both positive and negative reviews. \n\nBefore trying any of these approaches, let us consider as baseline a simple multinomial naive Bayes model which uses the n-gram frequencies (n=1,2,3) from count vectorization as features.","metadata":{}},{"cell_type":"code","source":"cv_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), MultinomialNB())\n\nx_train, y_train = df['text'][:train_len], df['label'][:train_len].values.reshape(-1,1)\nx_test, y_test = df['text'][train_len:], df['label'][train_len:].values.reshape(-1,1)\n\ncv_model.fit(x_train, y_train)\npreds = cv_model.predict(x_test)\n\nprint(\"Model: CountVectorizer + MultinomialNB\")\nprint(f\"Number of features: {len(cv_model[0].vocabulary_)}\")\nprint(\"Accuracy: {:.4f}\\n\".format(accuracy_score(y_test, preds)))\nmat = confusion_matrix(y_test, preds)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, xticklabels=cv_model.classes_, yticklabels=cv_model.classes_)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\n\nprint(classification_report(y_test, preds, labels=cv_model.classes_))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:21:20.629123Z","iopub.execute_input":"2021-06-14T16:21:20.629553Z","iopub.status.idle":"2021-06-14T16:22:02.182332Z","shell.execute_reply.started":"2021-06-14T16:21:20.62952Z","shell.execute_reply":"2021-06-14T16:22:02.181201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check now how tf-idf vectorization performs.","metadata":{}},{"cell_type":"code","source":"tfidf_model = make_pipeline(TfidfVectorizer(ngram_range=(1,3)), MultinomialNB())\n\ntfidf_model.fit(x_train, y_train)\npreds = tfidf_model.predict(x_test)\n\nprint(\"Model: TfidfVectorizer + MultinomialNB\")\nprint(f\"Number of features: {len(tfidf_model[0].vocabulary_)}\")\nprint(\"Accuracy: {:.4f}\\n\".format(accuracy_score(y_test, preds)))\nmat = confusion_matrix(y_test, preds)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, xticklabels=tfidf_model.classes_, yticklabels=tfidf_model.classes_)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\n\nprint(classification_report(y_test, preds, labels=tfidf_model.classes_))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:22:25.639301Z","iopub.execute_input":"2021-06-14T16:22:25.639776Z","iopub.status.idle":"2021-06-14T16:23:06.614327Z","shell.execute_reply.started":"2021-06-14T16:22:25.639744Z","shell.execute_reply":"2021-06-14T16:23:06.613063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The two types of vectorization give very similar results. We can try removing stopwords before vectorizing: in order to do so, we need to understand which languages are present in the corpus of reviews. The most frequent n-grams all come from english, but there might also be reviews written in other languages. We use the `langid` library to predict the language of each review in our dataset.","metadata":{}},{"cell_type":"code","source":"langs = [langid.classify(s)[0] for s in df['text']]\nCounter(langs)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:51:13.7046Z","iopub.execute_input":"2021-06-14T15:51:13.705181Z","iopub.status.idle":"2021-06-14T15:54:08.966482Z","shell.execute_reply.started":"2021-06-14T15:51:13.705149Z","shell.execute_reply":"2021-06-14T15:54:08.965153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Non-english reviews appear to be a very small minority, so we'll simply drop such samples from our dataset.","metadata":{}},{"cell_type":"code","source":"df = df[[l=='en' for l in langs]]\n\nx_train, y_train = df['text'][:train_len], df['label'][:train_len].values.reshape(-1,1)\nx_test, y_test = df['text'][train_len:], df['label'][train_len:].values.reshape(-1,1)\n\nprint(f'Label counts - training set:\\n{df[:train_len].label.value_counts()}')\nprint(f'\\nLabel counts - validation set:\\n{df[train_len:].label.value_counts()}')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:23:23.195802Z","iopub.execute_input":"2021-06-14T16:23:23.196225Z","iopub.status.idle":"2021-06-14T16:23:23.231507Z","shell.execute_reply.started":"2021-06-14T16:23:23.196194Z","shell.execute_reply":"2021-06-14T16:23:23.229681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now try removing english stopwords from the corpus of reviews.","metadata":{}},{"cell_type":"code","source":"nltk.download('stopwords')\nsw = stopwords.words('english')\n\ncv = CountVectorizer(ngram_range=(1,3), stop_words=frozenset(sw))\ncv.fit(df['text'])\nprint(f\"Number of ngrams in the corpus w/o stopwords: {len(cv.vocabulary_)}\")\n\nfts = cv.get_feature_names()\nfreq = cv.transform(df['text'])\ngram_counts = np.array(freq.sum(0)).squeeze()\n\ngram_counts_df = pd.DataFrame({'n-gram': [fts[i] for i in gram_counts.argsort()],\n                               'count': sorted(gram_counts)})\n\npx.bar(gram_counts_df[-20:], y='n-gram', x='count', title='Most frequent n-grams w/o stopwords',\n       orientation='h', height=600)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:54:40.112986Z","iopub.execute_input":"2021-06-14T15:54:40.113375Z","iopub.status.idle":"2021-06-14T15:55:42.102959Z","shell.execute_reply.started":"2021-06-14T15:54:40.113344Z","shell.execute_reply":"2021-06-14T15:55:42.101867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The resulting features are now much more likely to be meaningful to sentiment analysis for the reviewed products, in particular when considering 2-grams and 3-grams.","metadata":{}},{"cell_type":"code","source":"cv2 = CountVectorizer(ngram_range=(2,3), stop_words=frozenset(sw))\ncv2.fit(df['text'])\nfts2 = cv2.get_feature_names()\n\nfreq_pos = cv2.transform(df.loc[df['label'] == 2, 'text'])\ngram_counts_pos = np.array(freq_pos.sum(0)).squeeze()\n\ngram_counts_pos_df = pd.DataFrame({'n-gram': [fts2[i] for i in gram_counts_pos.argsort()],\n                               'count': sorted(gram_counts_pos)})\n\npx.bar(gram_counts_pos_df[-20:], y='n-gram', x='count', title='Most frequent 2/3-grams w/o stopwords - Positive reviews',\n       orientation='h', height=600)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:55:56.976539Z","iopub.execute_input":"2021-06-14T15:55:56.976984Z","iopub.status.idle":"2021-06-14T15:56:47.577206Z","shell.execute_reply.started":"2021-06-14T15:55:56.976951Z","shell.execute_reply":"2021-06-14T15:56:47.576001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_neg = cv2.transform(df.loc[df['label'] == 1, 'text'])\ngram_counts_neg = np.array(freq_neg.sum(0)).squeeze()\ngram_counts_neg_df = pd.DataFrame({'n-gram': [fts2[i] for i in gram_counts_neg.argsort()],\n                               'count': sorted(gram_counts_neg)})\n\npx.bar(gram_counts_neg_df[-20:], y='n-gram', x='count', title='Most frequent 2/3-grams w/o stopwords - Negative reviews',\n       orientation='h', height=600)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:57:20.58916Z","iopub.execute_input":"2021-06-14T15:57:20.589559Z","iopub.status.idle":"2021-06-14T15:57:34.210549Z","shell.execute_reply.started":"2021-06-14T15:57:20.589525Z","shell.execute_reply":"2021-06-14T15:57:34.209366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We need to be careful when removing stopwords. For instance, we see from the charts that 'would recommend' is a frequent 2-gram in both types of reviews, since 'not' is currently included in our stopword list and therefore 'would recommend' and 'would not recommend' become the same token! This is clearly something we do not want to happen: let us fix the problem by modifying the stopword list.","metadata":{}},{"cell_type":"code","source":"for a in [l for l in sw if l.endswith('n') or l.endswith(\"n't\")][12:]:\n    sw.remove(a)\nsw.remove('no')\nsw.remove('nor')\nsw.remove('not')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T15:57:54.509998Z","iopub.execute_input":"2021-06-14T15:57:54.510442Z","iopub.status.idle":"2021-06-14T15:57:54.516577Z","shell.execute_reply.started":"2021-06-14T15:57:54.510409Z","shell.execute_reply":"2021-06-14T15:57:54.515295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvwosw_model = make_pipeline(CountVectorizer(ngram_range=(1,3), stop_words=frozenset(sw)), MultinomialNB())\n\ncvwosw_model.fit(x_train, y_train)\npreds = cvwosw_model.predict(x_test)\n\nprint(\"Model: CountVectorizer + MultinomialNB w/o stopwords\")\nprint(f\"Number of features: {len(cvwosw_model[0].vocabulary_)}\")\nprint(\"Accuracy: {:.4f}\\n\".format(accuracy_score(y_test, preds)))\nmat = confusion_matrix(y_test, preds)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, xticklabels=cvwosw_model.classes_, yticklabels=cvwosw_model.classes_)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\n\nprint(classification_report(y_test, preds, labels=cvwosw_model.classes_))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:23:54.138493Z","iopub.execute_input":"2021-06-14T16:23:54.138932Z","iopub.status.idle":"2021-06-14T16:24:23.959635Z","shell.execute_reply.started":"2021-06-14T16:23:54.138898Z","shell.execute_reply":"2021-06-14T16:24:23.958444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidfwosw_model = make_pipeline(TfidfVectorizer(ngram_range=(1,3), stop_words=frozenset(sw)), MultinomialNB())\n\ntfidfwosw_model.fit(x_train, y_train)\npreds = tfidfwosw_model.predict(x_test)\n\nprint(\"Model: TfidfVectorizer + MultinomialNB w/o stopwords\")\nprint(f\"Number of features: {len(tfidfwosw_model[0].vocabulary_)}\")\nprint(\"Accuracy: {:.4f}\\n\".format(accuracy_score(y_test, preds)))\nmat = confusion_matrix(y_test, preds)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, xticklabels=tfidfwosw_model.classes_, yticklabels=tfidfwosw_model.classes_)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\n\nprint(classification_report(y_test, preds, labels=tfidfwosw_model.classes_))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:24:28.963532Z","iopub.execute_input":"2021-06-14T16:24:28.963953Z","iopub.status.idle":"2021-06-14T16:24:59.251626Z","shell.execute_reply.started":"2021-06-14T16:24:28.963921Z","shell.execute_reply":"2021-06-14T16:24:59.25051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vectorization using all n-grams in the original corpus still provides a model with better accuracy. However, removing stopwords has the advantage of reducing the number of features. To this end, another approach which can be tried is **lemmatization**, i.e. substituting all words in the corpus with their lemma, grouping together all inflected forms of the same word.","metadata":{}},{"cell_type":"code","source":"spcy = spacy.load('en_core_web_sm')\n\nx_train_lemm = x_train.apply(lambda x: ' '.join([w.lemma_ for w in spcy(x)]))\nx_test_lemm = x_test.apply(lambda x: ' '.join([w.lemma_ for w in spcy(x)]))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:00:01.038682Z","iopub.execute_input":"2021-06-14T16:00:01.039276Z","iopub.status.idle":"2021-06-14T16:20:32.730142Z","shell.execute_reply.started":"2021-06-14T16:00:01.039216Z","shell.execute_reply":"2021-06-14T16:20:32.728992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvlemm_model = make_pipeline(CountVectorizer(ngram_range=(1,3)), MultinomialNB())\n\ncvlemm_model.fit(x_train_lemm, y_train)\npreds = cvlemm_model.predict(x_test_lemm)\n\nprint(\"Model: CountVectorizer + MultinomialNB lemmatized\")\nprint(f\"Number of features: {len(cvlemm_model[0].vocabulary_)}\")\nprint(\"Accuracy: {:.4f}\\n\".format(accuracy_score(y_test, preds)))\nmat = confusion_matrix(y_test, preds)\nsns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, xticklabels=cvlemm_model.classes_, yticklabels=cvlemm_model.classes_)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\n\nprint(classification_report(y_test, preds, labels=cvlemm_model.classes_))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:25:14.188169Z","iopub.execute_input":"2021-06-14T16:25:14.188562Z","iopub.status.idle":"2021-06-14T16:25:50.928874Z","shell.execute_reply.started":"2021-06-14T16:25:14.188531Z","shell.execute_reply":"2021-06-14T16:25:50.927604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lemmatizing gives better results than removing stopwords, and it further reduces the number of features. However, the accuracy is still not as good as compared to using the original text.","metadata":{}},{"cell_type":"markdown","source":"## 3. Deep Learning <a id=3></a>\n\nNeural networks have proved to be extremely effective tools for NLP tasks. They generally provide significant improvements compared to standard ML models based on text features, even with minimal preprocessing (tokenization and numericalization of tokens is often enough). We will deploy two different models: one based on a Long Short-Term Memory (LSTM) recurrent neural network architecture and one using a state of the art transformer architecture. We will use PyTorch + fastai for implementation, together with huggingface Transformers library.\n\n### 3.1 LSTM <a id=3.1></a>\n\nWe use the `AWD-LSTM` architecture by [Smerity et al.](https://arxiv.org/pdf/1708.02182.pdf) \n\nWe first finetune on our corpus the **language model** (whose task is predicting the next token in the text based on the previous ones), before using it to build a classifier (*transfer learning*). Preprocessing is done by tokenizing with SpaCy and adding special tokens for capitalization, repetitions, beginning of strings, etc.","metadata":{}},{"cell_type":"code","source":"lm_dblock = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),\n                   get_x=ColReader('text'),\n                   splitter=IndexSplitter(range(train_len, len(df))))\nlm_dls = lm_dblock.dataloaders(df, bs=32, seq_len=72)\n\nlm_dls.show_batch(dataloaders=lm_dls, max_n=4)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:27:34.070292Z","iopub.execute_input":"2021-06-14T16:27:34.070708Z","iopub.status.idle":"2021-06-14T16:29:56.922981Z","shell.execute_reply.started":"2021-06-14T16:27:34.070662Z","shell.execute_reply":"2021-06-14T16:29:56.921697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fastai provides a very convenient *learning rate finder* to determine the best learning rate. The training of the neural network will be then performed using the **1cycle** policy (each epoch features a *warmup phase*, where the learning rate is gradually increased, followed by an *annealing phase*, where the lr decreases back to the minimum).","metadata":{}},{"cell_type":"code","source":"lm_learn = language_model_learner(lm_dls, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, perplexity])\nlm_learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:30:49.982672Z","iopub.execute_input":"2021-06-14T16:30:49.983138Z","iopub.status.idle":"2021-06-14T16:31:18.100475Z","shell.execute_reply.started":"2021-06-14T16:30:49.983105Z","shell.execute_reply":"2021-06-14T16:31:18.099305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm_learn.fit_one_cycle(3, lr_max=1e-2)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T16:44:16.855788Z","iopub.execute_input":"2021-06-14T16:44:16.85627Z","iopub.status.idle":"2021-06-14T17:06:03.865702Z","shell.execute_reply.started":"2021-06-14T16:44:16.856237Z","shell.execute_reply":"2021-06-14T17:06:03.86416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We save the weights in the body of the RNN and then move on to building the classifier.","metadata":{}},{"cell_type":"code","source":"lm_learn.save_encoder('lstm_finetuned')\n\nclas_dblock = DataBlock(blocks=(TextBlock.from_df('text', vocab=lm_dls.vocab), CategoryBlock),\n                        get_x=ColReader('text'), get_y=ColReader('label'),\n                        splitter=IndexSplitter(range(train_len, len(df))))\n\nclas_dls = clas_dblock.dataloaders(df, bs=32, seq_len=72, dl_type=SortedDL)\n\nclas_dls.show_batch(dls=clas_dls, max_n=5)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:07:07.779067Z","iopub.execute_input":"2021-06-14T17:07:07.779492Z","iopub.status.idle":"2021-06-14T17:10:21.599733Z","shell.execute_reply.started":"2021-06-14T17:07:07.779459Z","shell.execute_reply":"2021-06-14T17:10:21.598418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We load the language model weights in our classifier and then look for the best learning rate.","metadata":{}},{"cell_type":"code","source":"clas_learn = text_classifier_learner(clas_dls, AWD_LSTM, seq_len=72, metrics=accuracy)\nclas_learn.load_encoder('lstm_finetuned')\nclas_learn.freeze()\n\nclas_learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:10:25.821178Z","iopub.execute_input":"2021-06-14T17:10:25.821605Z","iopub.status.idle":"2021-06-14T17:10:37.341638Z","shell.execute_reply.started":"2021-06-14T17:10:25.821571Z","shell.execute_reply":"2021-06-14T17:10:37.340373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to train the classifier it is often a good choice to **gradually unfreeze** the layers of the NN, starting from training just the head (which at the moment contains random weights).","metadata":{}},{"cell_type":"code","source":"clas_learn.fit_one_cycle(1, lr_max=3e-3)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:13:25.527057Z","iopub.execute_input":"2021-06-14T17:13:25.527502Z","iopub.status.idle":"2021-06-14T17:15:50.807052Z","shell.execute_reply.started":"2021-06-14T17:13:25.527464Z","shell.execute_reply":"2021-06-14T17:15:50.805691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clas_learn.freeze_to(-2)\nclas_learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:16:26.943772Z","iopub.execute_input":"2021-06-14T17:16:26.9442Z","iopub.status.idle":"2021-06-14T17:16:37.105146Z","shell.execute_reply.started":"2021-06-14T17:16:26.944164Z","shell.execute_reply":"2021-06-14T17:16:37.10384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clas_learn.fit_one_cycle(1, lr_max=1e-4)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:18:00.413975Z","iopub.execute_input":"2021-06-14T17:18:00.41436Z","iopub.status.idle":"2021-06-14T17:20:32.786238Z","shell.execute_reply.started":"2021-06-14T17:18:00.414324Z","shell.execute_reply":"2021-06-14T17:20:32.784933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clas_learn.freeze_to(-3)\nclas_learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:20:43.356023Z","iopub.execute_input":"2021-06-14T17:20:43.356445Z","iopub.status.idle":"2021-06-14T17:20:55.536676Z","shell.execute_reply.started":"2021-06-14T17:20:43.356406Z","shell.execute_reply":"2021-06-14T17:20:55.535548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clas_learn.fit_one_cycle(1, lr_max=3e-5)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:21:03.450695Z","iopub.execute_input":"2021-06-14T17:21:03.451112Z","iopub.status.idle":"2021-06-14T17:24:16.136581Z","shell.execute_reply.started":"2021-06-14T17:21:03.451076Z","shell.execute_reply":"2021-06-14T17:24:16.135266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now unfreeze all remaining layers and train for a few more epochs with discriminative learning rates (lower lr for early layers, higher lr for later ones).","metadata":{}},{"cell_type":"code","source":"clas_learn.unfreeze()\nclas_learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:24:18.229636Z","iopub.execute_input":"2021-06-14T17:24:18.230226Z","iopub.status.idle":"2021-06-14T17:24:33.679603Z","shell.execute_reply.started":"2021-06-14T17:24:18.23017Z","shell.execute_reply":"2021-06-14T17:24:33.678041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clas_learn.fit_one_cycle(3, lr_max=slice(1e-6, 1e-4))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:24:41.996169Z","iopub.execute_input":"2021-06-14T17:24:41.996614Z","iopub.status.idle":"2021-06-14T17:36:40.134556Z","shell.execute_reply.started":"2021-06-14T17:24:41.996576Z","shell.execute_reply":"2021-06-14T17:36:40.1334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(clas_learn)\n\ninterp.print_classification_report()\ninterp.plot_confusion_matrix()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:36:53.40985Z","iopub.execute_input":"2021-06-14T17:36:53.410433Z","iopub.status.idle":"2021-06-14T17:37:19.024123Z","shell.execute_reply.started":"2021-06-14T17:36:53.410358Z","shell.execute_reply":"2021-06-14T17:37:19.022981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The LSTM model has reached an accuracy of 91.3%, significantly higher than the baseline obtained by using text features and with much more homogeneous precision and recall for the two classes. It is worth observing that the validation dataset contains wrongly labeled samples, as we can see by analyzing the top losses.","metadata":{}},{"cell_type":"code","source":"interp.plot_top_losses(k=8)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:38:59.633259Z","iopub.execute_input":"2021-06-14T17:38:59.633656Z","iopub.status.idle":"2021-06-14T17:38:59.716614Z","shell.execute_reply.started":"2021-06-14T17:38:59.633611Z","shell.execute_reply":"2021-06-14T17:38:59.715017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 RoBERTa <a id=3.2></a>\n\nLet's see whether a transformer NN can further improve results. We use [RoBERTa](https://arxiv.org/abs/1907.11692), based on BERT architecture; I highly recommend the [blurr library](https://github.com/ohmeow/blurr) to integrate huggingface Transformers with fastai.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification\nfrom blurr.data.all import *\nfrom blurr.modeling.all import *\n\npretrained_model_name = \"roberta-base\"\nmodel_cls = AutoModelForSequenceClassification\nhf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:39:08.243869Z","iopub.execute_input":"2021-06-14T17:39:08.244263Z","iopub.status.idle":"2021-06-14T17:39:45.527596Z","shell.execute_reply.started":"2021-06-14T17:39:08.244229Z","shell.execute_reply":"2021-06-14T17:39:45.526322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dblock = DataBlock(blocks=(HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock), \n                   get_x=ColReader('text'), get_y=ColReader('label'),\n                   splitter=IndexSplitter(range(train_len, len(df))))\n\ndls = dblock.dataloaders(df, bs=4, dl_type=SortedDL)\n\ndls.show_batch(dataloaders=dls)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:39:47.48798Z","iopub.execute_input":"2021-06-14T17:39:47.488376Z","iopub.status.idle":"2021-06-14T17:40:53.915447Z","shell.execute_reply.started":"2021-06-14T17:39:47.488341Z","shell.execute_reply":"2021-06-14T17:40:53.914303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_model = HF_BaseModelWrapper(hf_model)\n\nroberta_learn = Learner(dls, \n                roberta_model,\n                opt_func=partial(Adam, decouple_wd=True),\n                loss_func=CrossEntropyLossFlat(),\n                metrics=accuracy,\n                cbs=[HF_BaseModelCallback],\n                splitter=hf_splitter)\n\nroberta_learn.freeze()\n\nroberta_learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:03.110992Z","iopub.execute_input":"2021-06-14T17:41:03.111398Z","iopub.status.idle":"2021-06-14T17:41:12.530201Z","shell.execute_reply.started":"2021-06-14T17:41:03.111363Z","shell.execute_reply":"2021-06-14T17:41:12.528808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_learn.fit_one_cycle(1, lr_max=3e-4)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:41:20.711065Z","iopub.execute_input":"2021-06-14T17:41:20.711465Z","iopub.status.idle":"2021-06-14T17:56:59.750578Z","shell.execute_reply.started":"2021-06-14T17:41:20.711425Z","shell.execute_reply":"2021-06-14T17:56:59.749354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_learn.freeze_to(-2)\nroberta_learn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:59:01.564444Z","iopub.execute_input":"2021-06-14T17:59:01.564943Z","iopub.status.idle":"2021-06-14T17:59:12.082179Z","shell.execute_reply.started":"2021-06-14T17:59:01.564893Z","shell.execute_reply":"2021-06-14T17:59:12.081152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_learn.fit_one_cycle(1, lr_max=3e-6)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:08:02.875305Z","iopub.execute_input":"2021-06-14T18:08:02.875751Z","iopub.status.idle":"2021-06-14T18:32:43.241414Z","shell.execute_reply.started":"2021-06-14T18:08:02.875713Z","shell.execute_reply":"2021-06-14T18:32:43.240093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roberta_learn.unfreeze()\nroberta_learn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-5))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:33:22.324541Z","iopub.execute_input":"2021-06-14T18:33:22.325Z","iopub.status.idle":"2021-06-14T19:24:25.047028Z","shell.execute_reply.started":"2021-06-14T18:33:22.324956Z","shell.execute_reply":"2021-06-14T19:24:25.045825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = roberta_learn.blurr_predict(dls.valid.items)\n\npred_proc = np.array([int(dls.categorize.decode(a)) for i in list(zip(*preds))[1] for a in i])\n\ntrue_y = dls.valid.items['label'].values\n\nprint(classification_report(true_y, pred_proc))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T19:32:02.804133Z","iopub.execute_input":"2021-06-14T19:32:02.804581Z","iopub.status.idle":"2021-06-14T19:33:13.875494Z","shell.execute_reply.started":"2021-06-14T19:32:02.80453Z","shell.execute_reply":"2021-06-14T19:33:13.874266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finetuning a pretrained transformer architecture leads to an accuracy of **96.5%**, much better than what we achieved with a LSTM RNN. ","metadata":{}}]}