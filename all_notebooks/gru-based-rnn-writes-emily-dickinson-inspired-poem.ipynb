{"cells":[{"metadata":{},"cell_type":"markdown","source":"# GRU-based RNN gets inspired by Emily Dickinson and writes poems\n\nWe will use a Recurrent Neural Network (RNN) made with Gated Recurrent Unit (GRU) to generate poetry after learning using the **597 poems by Emily Dickinson** dataset.\n\nWe use character-based prediction, wherein given a string, the model would output the next character that should follow the given string. We use this strategy to iteratively predict characters until 15 lines of poetry is generated, hoping that neural network outputs resemble a poem by Emily Dickinson.\n\nNotice that because of character-based prediction sometimes meaningless words are also generated while generating the poetry. The generation of meaningless words can be removed by using a word-based prediction scheme (which we will undertake in another notebook).\n\nThis notebook uses the concepts described and demonstrated in the Tensorflow documentation ([Text generation with an RNN](https://www.tensorflow.org/tutorials/text/text_generation)). Please refer to the tutorial for better understanding of the notebook.\n\n\n### Import required modules and load dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport numpy as np\nimport os\nimport time\n\ndata = open('../input/597-poems-by-emily-dickinson/final-emily.csv','rb')\ncorpus = data.read().decode(encoding='utf-8').strip()\nvocab = sorted(set(corpus))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Total and unique character counts"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print ('Total characters:', len(corpus))\nprint ('Unique characters', len(vocab))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create dictionary mapping characters to integers, and vice versa"},{"metadata":{"trusted":true},"cell_type":"code","source":"character_to_index = {u:i for i, u in enumerate(vocab)}\nindex_to_character = np.array(vocab)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert text corpus to integer representation"},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus_int = np.array([character_to_index[c] for c in corpus])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert text corpus to dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length = 100\nexamples_per_epoch = len(corpus)//(seq_length+1)\n\nchar_dataset = tf.data.Dataset.from_tensor_slices(corpus_int)\nsequences = char_dataset.batch(seq_length+1, drop_remainder=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert dataset to input->output pairs"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_input_target(chunk):\n  input_text = chunk[:-1]\n  target_text = chunk[1:]\n  return input_text, target_text\n\ndataset = sequences.map(split_input_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set hyperparameters for GRU model"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nBUFFER_SIZE = 10000\nvocab_size = len(vocab)\nembedding_dim = 256\nrnn_units = 1024","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shuffle the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create GRU model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n                              batch_input_shape=[BATCH_SIZE, None]),\n    tf.keras.layers.GRU(rnn_units,\n                        return_sequences=True,\n                        stateful=True,\n                        recurrent_initializer='glorot_uniform'),\n    tf.keras.layers.Dense(len(vocab))\n])\n    \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set checkpoint directory and filename"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_dir = './tmp'\n\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n\ncheckpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(labels, logits):\n    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compile model and train on dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss=loss_fn)\nhistory = model.fit(dataset, epochs=100, callbacks=[checkpoint_callback])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Procedure to generate text given starting string"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_text(model, start_string):\n  num_generate = 15\n\n  input_eval = [character_to_index[s] for s in start_string]\n  input_eval = tf.expand_dims(input_eval, 0)\n\n  text_generated = []\n\n  temperature = 1.0\n\n  model.reset_states()\n    \n  while(num_generate > 0):\n    predictions = model(input_eval)\n    predictions = tf.squeeze(predictions, 0)\n\n    predictions = predictions / temperature\n    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n\n    input_eval = tf.expand_dims([predicted_id], 0)\n    text_generated.append(index_to_character[predicted_id])\n    if index_to_character[predicted_id]=='\\n':\n        num_generate -= 1\n\n  return (start_string + ''.join(text_generated)).strip()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load model and change input shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(len(vocab), embedding_dim,\n                              batch_input_shape=[1, None]),\n    tf.keras.layers.GRU(rnn_units,\n                        return_sequences=True,\n                        stateful=True,\n                        recurrent_initializer='glorot_uniform'),\n    tf.keras.layers.Dense(len(vocab))\n])\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\nmodel.build(tf.TensorShape([1, None]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n### Generate poem starting with string 'Love'"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(generate_text(model, start_string=u\"Love \"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate poem starting with string 'Flower'"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(generate_text(model, start_string=u\"Flower \"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}