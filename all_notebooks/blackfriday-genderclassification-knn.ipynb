{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/black-friday/train.csv\")\n\n\n#limiting the amount of data we use to keep computation fast \ndf = df.iloc[:]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FIRST QUICK LOOK AT THE DATA "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data columns\")\nprint(\"--------------------------------------------\")\nprint(pd.DataFrame(df.info()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## we can see that these colums have some null values\n    Product_Category_2           \n    Product_Category_3            "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HANDLING MISSING DATA "},{"metadata":{},"cell_type":"markdown","source":"## percentage of missing data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf.isnull().sum()/df.isnull().count()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## we can delete Product_Category_3 column  because missing data in this columns more than 60% of the observations"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('Product_Category_3', axis=1)\n\n## also dropping user id category \ndf = df.drop('User_ID', axis=1)\ndf = df.drop('Product_ID', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Marital_Status'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# IMPUTING \n\n## for Product_Category_2 we can impute the 31.5 % of missing data \n## lets use simple imputer for now, later we can take care of these missing data with other methods as well, to perhaps boost our accuracy "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_2'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['Product_Category_2'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nimputer = imputer.fit(pd.DataFrame(df['Product_Category_2']))\n\n\ndf['Product_Category_2'] = imputer.transform(pd.DataFrame(df['Product_Category_2']))\n#data_train['Product_Category_2'] = np.round(data_train['Product_Category_2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = imputer.fit(pd.DataFrame(df['Marital_Status']))\ndf['Marital_Status'] = imputer.transform(pd.DataFrame(df['Marital_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['Product_Category_2'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## confirming no missing values "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()/df.isnull().count()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mean purchase for men Vs women\n###  males buying higher value purchases than females, But the difference not large."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"average purchase for male purchasers = \",\nnp.mean(df['Purchase'].loc[df['Gender'] == 'M']),'\\n')\nprint(\"-\"*115,'\\n')\nprint(\"average purchase for female purchasers = \",\nnp.mean(df['Purchase'].loc[df['Gender'] == 'F']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfig= plt.figure(figsize=(12,7))\n\n\nsns.set(style=\"darkgrid\")\n\n\nx = pd.DataFrame({\"male average purchase\": [9437], \"Female average purchase\": [8734]})\n\nsns.barplot(data=x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# number of observations of female individuals vs male "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of Female purchasers = ',df['Gender'][df['Gender'] == 'F'].count())\nprint('Number of male purchasers   = ',df['Gender'][df['Gender'] == 'M'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FEATURE ENGINEERING FOR BUILDING MODELS\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#change gender from 'm' and 'f' to binary \ndf.loc[:, 'Gender'] = np.where(df['Gender'] == 'M', 1, 0)\n\n#renaming some columns \ndf = df.rename(columns={\n                #'Product_ID': 'ProductClass',\n                'Product_Category_1': 'Category1',\n                'Product_Category_2': 'Category2',\n                'City_Category': 'City',\n                'Stay_In_Current_City_Years': 'City_Stay'\n})\n#y = train.pop('Purchase')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ENCODING CATEGORICAL VARIABLES \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(df['ProductClass'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LABEL ENCODING FOR PRODUCT CLASS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\n# L_encoder =  LabelEncoder()\n# for col in ['ProductClass']:    \n#     df.loc[:, col] =L_encoder.fit_transform(df[col])\n# df[['ProductClass']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OneHotEncoder for other Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import  OneHotEncoder\ncats = ['Occupation', 'Age', 'City', 'Category1','Category2','City_Stay']\n\n#creating the encoder, fit it to our data \nencoder = OneHotEncoder().fit(df[cats])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generating feature names for our encoded data\nencoder.get_feature_names(cats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building dataframe with encoded catgegoricals \n\n## we use index values from our original data \n## we GENERATE feature names using our encoder\n\nendcoded_data = pd.DataFrame(encoder.transform(df[cats]).toarray(),index=df.index, columns=encoder.get_feature_names(cats))\nendcoded_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## dropping categorical data, adding the encoded data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, endcoded_data],sort=False,axis=1)\n\ndf=df.drop(cats, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## REPLACING NANS(after OH encoding) with 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.fillna(0)\ndf.head(15)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DEFINING FEATURES AND LABELS "},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Gender',axis=1)\ny = df.pop('Gender')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X=np.nan_to_num(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SCALING"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAIN TEST SPLIT "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size= 0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FITTING OUR MODEL\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FIRST SCORE"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HYPER PARAMETER TUNING\n# WITH GridSearchCV "},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters = { 'algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n#                'leaf_size' : [18,20,25,27,30,32,34],\n#                'n_neighbors' : [3,5,7,9,10,11,12,13]\n#               }\n\n# from sklearn.model_selection import GridSearchCV\n# gridsearch = GridSearchCV(knn, parameters,verbose=3)\n# gridsearch.fit(X_train,y_train)\n# gridsearch.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CREATING the TUNED THE MODEL AGAIN"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(algorithm = 'auto', leaf_size =35, n_neighbors =5)\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MAKING A PREDICTION "},{"metadata":{},"cell_type":"markdown","source":"## Using, and transforming available data to make a prediction, user input will need to be transformed also "},{"metadata":{},"cell_type":"markdown","source":"# OUR INPUT DATA FOR PREDICTION NEEDS TO LOOK LIKE OUR FEATURES FOR TRAINING\n\n## this means, we have to : \n    drop the same caolumns \n    encode the categorical features in the same way, \n    etc. \n    \n## basically our input data needs to go through all the things we did to our training data, \n## this exercise will also help us find what all inputs to take from the user "},{"metadata":{},"cell_type":"markdown","source":"> ## drop columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = pd.read_csv(\"/kaggle/input/black-friday/test.csv\")\n\ndft = dft.drop('Product_Category_3', axis=1)\n\n## also dropping user id category \ndft = dft.drop('User_ID', axis=1)\ndft = dft.drop('Product_ID', axis=1)\n\n#Product_ID\ndft.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = dft.iloc[:1]\ndft","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Rename similarly"},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = dft.rename(columns={\n                #'Product_ID': 'ProductClass',\n                'Product_Category_1': 'Category1',\n                'Product_Category_2': 'Category2',\n                'City_Category': 'City',\n                'Stay_In_Current_City_Years': 'City_Stay'\n})\ndft","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dft['ProductClass']='P00248942'\n# dft","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# THESE ARE THE INPUTS THAT WE REQUIRE FROM THE USER, AFTER TAKING THE INPUT, WE NEED TO DO OUR TRANSFORMATIONS TO GET A PREDICTION\n\nGender \tAge \tOccupation \tCity \tCity_Stay \tMarital_Status \tCategory1 \tCategory2\n\n\n## SINCE THESE ARE CATEGORICAL WE NEED TO PUT A LEGEND SO THAT THE USER CAN PUT THE CORRECT INPUTS"},{"metadata":{"trusted":true},"cell_type":"code","source":"#change gender from 'm' and 'f' to binary \ndft['Gender'] = 9851\ndft","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IMP*\n> ## encode all required fequres with the exact same encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"p =pd.DataFrame(encoder.transform(dft[cats]).toarray(),columns=encoder.get_feature_names(cats))\np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft=dft.drop(cats, axis=1)\ndft","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CREATE THE FINAL INPUT FOR PREDICTION "},{"metadata":{"trusted":true},"cell_type":"code","source":"dft = pd.concat([dft, p],sort=False,axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dft['ProductClass'] =L_encoder.transform(dft['ProductClass'])\n# p","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# get prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.predict(dft)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}