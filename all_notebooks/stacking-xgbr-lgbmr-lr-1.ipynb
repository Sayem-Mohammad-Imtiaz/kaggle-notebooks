{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install category-encoders","metadata":{"execution":{"iopub.status.busy":"2021-08-29T18:14:33.264399Z","iopub.execute_input":"2021-08-29T18:14:33.26486Z","iopub.status.idle":"2021-08-29T18:14:33.270087Z","shell.execute_reply.started":"2021-08-29T18:14:33.264763Z","shell.execute_reply":"2021-08-29T18:14:33.269207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport optuna \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom category_encoders import MEstimateEncoder, TargetEncoder\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression, ElasticNet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-31T15:32:09.426361Z","iopub.execute_input":"2021-08-31T15:32:09.42674Z","iopub.status.idle":"2021-08-31T15:32:12.977941Z","shell.execute_reply.started":"2021-08-31T15:32:09.42666Z","shell.execute_reply":"2021-08-31T15:32:12.977149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/30days-10folds/train_10_folds.csv')\ndf_test = pd.read_csv('../input/30-days-of-ml/test.csv')\ndf_submission = pd.read_csv('../input/30-days-of-ml/sample_submission.csv')\n\n# categorical columns\ncat_cols = [c for c in df.columns if c.startswith('cat')]\n\n# numerical columns apart from 'id', 'target' and 'kfold'\nnum_cols = [c for c in df.columns if c.startswith('cont')]\n\nuseful_features = [c for c in df.columns if c not in ['id', 'target', 'kfold']]\n\ndf_ohe = pd.get_dummies(df, columns=cat_cols)\ndf_test_ohe = pd.get_dummies(df_test, columns=cat_cols)\n\ncat_cols2 = [c for c in df_ohe.columns if c.startswith('cat')]\nuseful_features2 = [c for c in df_ohe.columns if c not in ['id', 'target', 'kfold']]","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:32:17.695384Z","iopub.execute_input":"2021-08-31T15:32:17.695696Z","iopub.status.idle":"2021-08-31T15:32:21.64585Z","shell.execute_reply.started":"2021-08-31T15:32:17.695669Z","shell.execute_reply":"2021-08-31T15:32:21.645057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_FOLDS = 10","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:32:23.705378Z","iopub.execute_input":"2021-08-31T15:32:23.705692Z","iopub.status.idle":"2021-08-31T15:32:23.709576Z","shell.execute_reply.started":"2021-08-31T15:32:23.705662Z","shell.execute_reply":"2021-08-31T15:32:23.708559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBRegressor Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"def run_xgbr(trial):\n    fold = 6\n    \n    xgbr_params = {\n        'random_state': trial.suggest_int(\"random_state\", 1, 39501, step=500),\n        'n_estimators': trial.suggest_int(\"n_estimators\", 500, 40000, step=500),\n        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n        'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0),\n        'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0),\n        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n        'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n        'max_depth': trial.suggest_int(\"max_depth\", 1, 15),\n    }\n    \n    X_train = df_ohe[df_ohe.kfold != fold][useful_features2].copy()\n    y_train = df_ohe[df_ohe.kfold != fold]['target'].copy()\n    \n    X_valid = df_ohe[df_ohe.kfold == fold][useful_features2].copy()\n    y_valid = df_ohe[df_ohe.kfold == fold]['target'].copy()\n\n\n#     oe = MEstimateEncoder()\n\n#     X_train[cat_cols] = oe.fit_transform(X_train[cat_cols], y_train)\n#     X_valid[cat_cols] = oe.transform(X_valid[cat_cols])\n\n    xgbr = XGBRegressor(\n        tree_method=\"gpu_hist\",\n        gpu_id=0,\n        predictor=\"gpu_predictor\",\n        n_jobs=-1,\n        **xgbr_params\n    )\n\n    xgbr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    valid_pred = xgbr.predict(X_valid)\n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:26:01.499935Z","iopub.execute_input":"2021-08-31T09:26:01.500403Z","iopub.status.idle":"2021-08-31T09:26:01.524699Z","shell.execute_reply.started":"2021-08-31T09:26:01.500361Z","shell.execute_reply":"2021-08-31T09:26:01.523598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(run_xgbr, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:26:31.378207Z","iopub.execute_input":"2021-08-31T09:26:31.378569Z","iopub.status.idle":"2021-08-31T09:52:15.977838Z","shell.execute_reply.started":"2021-08-31T09:26:31.378532Z","shell.execute_reply":"2021-08-31T09:52:15.97688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:53:05.474653Z","iopub.execute_input":"2021-08-31T09:53:05.475074Z","iopub.status.idle":"2021-08-31T09:53:05.482686Z","shell.execute_reply.started":"2021-08-31T09:53:05.475039Z","shell.execute_reply":"2021-08-31T09:53:05.481848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBMRegressor Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"def run_lgbmr(trial):\n    fold = 6\n\n    lgbmr_params = {\n        'random_state': trial.suggest_int(\"random_state\", 1, 39501, step=500),\n        'metric': 'rmse',\n        'objective': 'regression',\n        'n_estimators': trial.suggest_int(\"n_estimators\", 500, 30000, step=500),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n        'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n        'max_depth': trial.suggest_int(\"max_depth\", 1, 100),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 1, 100)\n    }\n\n    X_train = df[df.kfold != fold][useful_features].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    \n    oe = OrdinalEncoder()\n    \n    X_train[cat_cols] = oe.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = oe.transform(X_valid[cat_cols])\n    \n    lgbmr = LGBMRegressor(\n        device = 'gpu',\n        gpu_platform_id = 0,\n        gpu_device_id = 0,\n        n_jobs=-1,\n        **lgbmr_params\n    )\n    \n    lgbmr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    valid_pred = lgbmr.predict(X_valid)\n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:56:14.940851Z","iopub.execute_input":"2021-08-31T09:56:14.941232Z","iopub.status.idle":"2021-08-31T09:56:14.951766Z","shell.execute_reply.started":"2021-08-31T09:56:14.9412Z","shell.execute_reply":"2021-08-31T09:56:14.950885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(run_lgbmr, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T09:56:25.690168Z","iopub.execute_input":"2021-08-31T09:56:25.690509Z","iopub.status.idle":"2021-08-31T10:18:56.340298Z","shell.execute_reply.started":"2021-08-31T09:56:25.690477Z","shell.execute_reply":"2021-08-31T10:18:56.339593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-08-31T10:24:22.911338Z","iopub.execute_input":"2021-08-31T10:24:22.911869Z","iopub.status.idle":"2021-08-31T10:24:22.922365Z","shell.execute_reply.started":"2021-08-31T10:24:22.911816Z","shell.execute_reply":"2021-08-31T10:24:22.921361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBRegressor Predictions","metadata":{}},{"cell_type":"markdown","source":"### OneHotEncoder","metadata":{}},{"cell_type":"code","source":"valid_preds = {}\ntest_preds = []\nrmse_scores = []\n\n# Optimized params\nxgbr_params = {'random_state': 1,\n 'n_estimators': 24000,\n 'learning_rate': 0.010570184115565436,\n 'reg_alpha': 0.011885501879436232,\n 'reg_lambda': 83.0988767019388,\n 'colsample_bytree': 0.10582207063540948,\n 'subsample': 0.6505186664831886,\n 'max_depth': 7}\n\nfor fold in range(N_FOLDS):\n    X_train = df_ohe[df_ohe.kfold != fold][useful_features2].copy()\n    y_train = df_ohe[df_ohe.kfold != fold]['target'].copy()\n    \n    X_valid = df_ohe[df_ohe.kfold == fold][useful_features2].copy()\n    y_valid = df_ohe[df_ohe.kfold == fold]['target'].copy()\n    \n    X_test = df_test_ohe[useful_features2].copy()\n    \n    valid_ids = df_ohe[df_ohe.kfold == fold].id.values.tolist()\n    \n    \n    xgbr = XGBRegressor(\n        n_jobs=-1,\n        **xgbr_params\n    )\n    \n    xgbr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    \n    valid_pred = xgbr.predict(X_valid)\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    \n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    rmse_scores.append(rmse)\n    \n    test_pred = xgbr.predict(X_test)\n    test_preds.append(test_pred)\n    \n    print(fold, rmse)\n\nprint(\"Mean RMSE: {}\".format(np.mean(rmse_scores)))\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\nvalid_preds.columns = [\"id\", \"pred_1\"]\nvalid_preds.to_csv(\"train_pred_1.csv\", index=False)\n\ndf_submission_xgbr = df_submission.copy()\ndf_submission_xgbr['target'] = np.mean(np.column_stack(test_preds), axis=1)\ndf_submission_xgbr.columns = [\"id\", \"pred_1\"]\ndf_submission_xgbr.to_csv('test_pred_1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T11:01:18.123682Z","iopub.execute_input":"2021-08-31T11:01:18.124135Z","iopub.status.idle":"2021-08-31T15:23:53.3464Z","shell.execute_reply.started":"2021-08-31T11:01:18.124097Z","shell.execute_reply":"2021-08-31T15:23:53.34529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OrdinalEncoder","metadata":{}},{"cell_type":"code","source":"valid_preds = {}\ntest_preds = []\nrmse_scores = []\n\n# Optimized params\nxgbr_params = {'n_estimators': 25000,\n 'learning_rate': 0.04131767863898798,\n 'reg_alpha': 0.00426659506577938,\n 'reg_lambda': 9.993333999320106,\n 'colsample_bytree': 0.12151130135748905,\n 'subsample': 0.7321334740173127,\n 'max_depth': 2}\n\nfor fold in range(N_FOLDS):\n    X_train = df[df.kfold != fold][useful_features].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    X_test = df_test[useful_features].copy()\n    \n    valid_ids = df[df.kfold == fold].id.values.tolist()\n    \n    oe = OrdinalEncoder()\n    \n    X_train[cat_cols] = oe.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = oe.transform(X_valid[cat_cols])\n    X_test[cat_cols] = oe.transform(X_test[cat_cols])\n    \n    xgbr = XGBRegressor(\n        random_state=42,\n        n_jobs=-1,\n        **xgbr_params\n    )\n    \n    xgbr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    \n    valid_pred = xgbr.predict(X_valid)\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    \n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    rmse_scores.append(rmse)\n    \n    test_pred = xgbr.predict(X_test)\n    test_preds.append(test_pred)\n    \n    print(fold, rmse)\n\nprint(\"Mean RMSE: {}\".format(np.mean(rmse_scores)))\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\nvalid_preds.columns = [\"id\", \"pred_2\"]\nvalid_preds.to_csv(\"train_pred_2.csv\", index=False)\n\ndf_submission_xgbr = df_submission.copy()\ndf_submission_xgbr['target'] = np.mean(np.column_stack(test_preds), axis=1)\ndf_submission_xgbr.columns = [\"id\", \"pred_2\"]\ndf_submission_xgbr.to_csv('test_pred_2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:23:53.348384Z","iopub.execute_input":"2021-08-31T15:23:53.348756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MEstimateEncoder","metadata":{}},{"cell_type":"code","source":"valid_preds = {}\ntest_preds = []\nrmse_scores = []\n\n# Optimized params\nxgbr_params = {'random_state': 36001,\n 'n_estimators': 31500,\n 'learning_rate': 0.06662729228509383,\n 'reg_alpha': 1.7300508237054107e-08,\n 'reg_lambda': 0.0228401079048692,\n 'colsample_bytree': 0.10765459397825078,\n 'subsample': 0.9961467305926972,\n 'max_depth': 2}\n\nfor fold in range(N_FOLDS):\n    X_train = df[df.kfold != fold][useful_features].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    X_test = df_test[useful_features].copy()\n    \n    valid_ids = df[df.kfold == fold].id.values.tolist()\n    \n    mee = MEstimateEncoder()\n    \n    X_train[cat_cols] = mee.fit_transform(X_train[cat_cols], y_train)\n    X_valid[cat_cols] = mee.transform(X_valid[cat_cols])\n    X_test[cat_cols] = mee.transform(X_test[cat_cols])\n    \n    xgbr = XGBRegressor(\n        n_jobs=-1,\n        **xgbr_params\n    )\n    \n    xgbr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    \n    valid_pred = xgbr.predict(X_valid)\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    \n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    rmse_scores.append(rmse)\n    \n    test_pred = xgbr.predict(X_test)\n    test_preds.append(test_pred)\n    \n    print(fold, rmse)\n\nprint(\"Mean RMSE: {}\".format(np.mean(rmse_scores)))\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\nvalid_preds.columns = [\"id\", \"pred_3\"]\nvalid_preds.to_csv(\"train_pred_3.csv\", index=False)\n\ndf_submission_xgbr = df_submission.copy()\ndf_submission_xgbr['target'] = np.mean(np.column_stack(test_preds), axis=1)\ndf_submission_xgbr.columns = [\"id\", \"pred_3\"]\ndf_submission_xgbr.to_csv('test_pred_3.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBM Predictions","metadata":{}},{"cell_type":"markdown","source":"### OrdinalEncoder","metadata":{}},{"cell_type":"code","source":"valid_preds = {}\ntest_preds = []\nrmse_scores = []\n\n# Optimized params\nlgbmr_params = {'random_state': 15501,\n 'n_estimators': 11500,\n 'reg_alpha': 1.0923032842333036,\n 'reg_lambda': 0.0011961670045703618,\n 'colsample_bytree': 0.10678842002938174,\n 'subsample': 0.36744208881458135,\n 'learning_rate': 0.04337334530673734,\n 'max_depth': 91,\n 'num_leaves': 7,\n 'min_child_samples': 264,\n 'cat_smooth': 36}\n\nfor fold in range(N_FOLDS):\n    X_train = df[df.kfold != fold][useful_features].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    X_test = df_test[useful_features].copy()\n    \n    valid_ids = df[df.kfold == fold].id.values.tolist()\n    \n    oe = OrdinalEncoder()\n    \n    X_train[cat_cols] = oe.fit_transform(X_train[cat_cols])\n    X_valid[cat_cols] = oe.transform(X_valid[cat_cols])\n    X_test[cat_cols] = oe.transform(X_test[cat_cols])\n    \n    lgbmr = LGBMRegressor(\n        n_jobs=-1,\n        **lgbmr_params\n    )\n    \n    lgbmr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    \n    valid_pred = lgbmr.predict(X_valid)\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    \n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    rmse_scores.append(rmse)\n    \n    test_pred = lgbmr.predict(X_test)\n    test_preds.append(test_pred)\n    \n    print(fold, rmse)\n\nprint(\"Mean RMSE: {}\".format(np.mean(rmse_scores)))\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\nvalid_preds.columns = [\"id\", \"pred_4\"]\nvalid_preds.to_csv(\"train_pred_4.csv\", index=False)\n\ndf_submission_lgbmr = df_submission.copy()\ndf_submission_lgbmr['target'] = np.mean(np.column_stack(test_preds), axis=1)\ndf_submission_lgbmr.columns = [\"id\", \"pred_4\"]\ndf_submission_lgbmr.to_csv('test_pred_4.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Train and Test Predictions","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv(\"../input/30days-blend-data/train_pred_1.csv\")\ndf2 = pd.read_csv(\"../input/30days-blend-data/train_pred_2.csv\")\ndf3 = pd.read_csv(\"../input/30days-blend-data/train_pred_3.csv\")\ndf4 = pd.read_csv(\"../input/30days-blend-data/train_pred_4.csv\")\n# df5 = pd.read_csv(\"train_pred_5.csv\")\n# df6 = pd.read_csv(\"train_pred_6.csv\")\n# df7 = pd.read_csv(\"train_pred_7.csv\")\n# df8 = pd.read_csv(\"train_pred_8.csv\")\n# df9 = pd.read_csv(\"train_pred_9.csv\")\n# df10 = pd.read_csv(\"train_pred_10.csv\")\n\ndf_test1 = pd.read_csv(\"../input/30days-blend-data/test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"../input/30days-blend-data/test_pred_2.csv\")\ndf_test3 = pd.read_csv(\"../input/30days-blend-data/test_pred_3.csv\")\ndf_test4 = pd.read_csv(\"../input/30days-blend-data/test_pred_4.csv\")\n# df_test5 = pd.read_csv(\"test_pred_5.csv\")\n# df_test6 = pd.read_csv(\"test_pred_6.csv\")\n# df_test7 = pd.read_csv(\"test_pred_7.csv\")\n# df_test8 = pd.read_csv(\"test_pred_8.csv\")\n# df_test9 = pd.read_csv(\"test_pred_9.csv\")\n# df_test10 = pd.read_csv(\"test_pred_10.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\ndf = df.merge(df4, on=\"id\", how=\"left\")\n# df = df.merge(df5, on=\"id\", how=\"left\")\n# df = df.merge(df6, on=\"id\", how=\"left\")\n# df = df.merge(df7, on=\"id\", how=\"left\")\n# df = df.merge(df8, on=\"id\", how=\"left\")\n# df = df.merge(df9, on=\"id\", how=\"left\")\n# df = df.merge(df10, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test5, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test6, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test7, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test8, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test9, on=\"id\", how=\"left\")\n# df_test = df_test.merge(df_test10, on=\"id\", how=\"left\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:33:46.392088Z","iopub.execute_input":"2021-08-31T15:33:46.392425Z","iopub.status.idle":"2021-08-31T15:33:48.201476Z","shell.execute_reply.started":"2021-08-31T15:33:46.392394Z","shell.execute_reply":"2021-08-31T15:33:48.200439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:34:44.631028Z","iopub.execute_input":"2021-08-31T15:34:44.631371Z","iopub.status.idle":"2021-08-31T15:34:44.66164Z","shell.execute_reply.started":"2021-08-31T15:34:44.631342Z","shell.execute_reply":"2021-08-31T15:34:44.66075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape, df1.shape, df_test1.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:33:56.30609Z","iopub.execute_input":"2021-08-31T15:33:56.306444Z","iopub.status.idle":"2021-08-31T15:33:56.312983Z","shell.execute_reply.started":"2021-08-31T15:33:56.306416Z","shell.execute_reply":"2021-08-31T15:33:56.312091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"pred_5\", \"pred_6\", \"pred_7\", \"pred_8\", \"pred_9\", \"pred_10\"\nuseful_features3 = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:34:53.305801Z","iopub.execute_input":"2021-08-31T15:34:53.306102Z","iopub.status.idle":"2021-08-31T15:34:53.311116Z","shell.execute_reply.started":"2021-08-31T15:34:53.306075Z","shell.execute_reply":"2021-08-31T15:34:53.308895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBRegressor Hyperparameter Tuning for Blended Dataset","metadata":{}},{"cell_type":"code","source":"def run_xgbr(trial):\n    fold = 6\n    \n    xgbr_params = {\n        'random_state': trial.suggest_int(\"random_state\", 1, 39501, step=500),\n        'n_estimators': trial.suggest_int(\"n_estimators\", 500, 40000, step=500),\n        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n        'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0),\n        'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0),\n        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n        'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n        'max_depth': trial.suggest_int(\"max_depth\", 1, 15),\n        'booster': 'gbtree'\n    }\n    \n    X_train = df[df.kfold != fold][useful_features3].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features3].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n\n    xgbr = XGBRegressor(\n        tree_method=\"gpu_hist\",\n        gpu_id=0,\n        predictor=\"gpu_predictor\",\n        n_jobs=-1,\n        **xgbr_params\n    )\n\n    xgbr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    valid_pred = xgbr.predict(X_valid)\n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:39:52.465596Z","iopub.execute_input":"2021-08-31T15:39:52.465925Z","iopub.status.idle":"2021-08-31T15:39:52.484067Z","shell.execute_reply.started":"2021-08-31T15:39:52.465896Z","shell.execute_reply":"2021-08-31T15:39:52.483039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(run_xgbr, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:40:21.826104Z","iopub.execute_input":"2021-08-31T15:40:21.826489Z","iopub.status.idle":"2021-08-31T15:46:14.161767Z","shell.execute_reply.started":"2021-08-31T15:40:21.826458Z","shell.execute_reply":"2021-08-31T15:46:14.161111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:50:34.095921Z","iopub.execute_input":"2021-08-31T15:50:34.096376Z","iopub.status.idle":"2021-08-31T15:50:34.103124Z","shell.execute_reply.started":"2021-08-31T15:50:34.09634Z","shell.execute_reply":"2021-08-31T15:50:34.101812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBMRegressor Hyperparameter Tuning for Blended Dataset","metadata":{}},{"cell_type":"code","source":"def run_lgbmr(trial):\n    fold = 6\n\n    lgbmr_params = {\n        'random_state': trial.suggest_int(\"random_state\", 1, 39501, step=500),\n        'metric': 'rmse',\n        'objective': 'regression',\n        'n_estimators': trial.suggest_int(\"n_estimators\", 500, 30000, step=500),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n        'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n        'max_depth': trial.suggest_int(\"max_depth\", 1, 100),\n        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 1, 100)\n    }\n\n    X_train = df[df.kfold != fold][useful_features3].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features3].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    lgbmr = LGBMRegressor(\n        device = 'gpu',\n        gpu_platform_id = 0,\n        gpu_device_id = 0,\n        n_jobs=-1,\n        **lgbmr_params\n    )\n    \n    lgbmr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    valid_pred = lgbmr.predict(X_valid)\n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:54:54.271383Z","iopub.execute_input":"2021-08-31T15:54:54.271692Z","iopub.status.idle":"2021-08-31T15:54:54.281773Z","shell.execute_reply.started":"2021-08-31T15:54:54.271665Z","shell.execute_reply":"2021-08-31T15:54:54.280974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\nstudy.optimize(run_lgbmr, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:54:59.446071Z","iopub.execute_input":"2021-08-31T15:54:59.446423Z","iopub.status.idle":"2021-08-31T16:03:14.561019Z","shell.execute_reply.started":"2021-08-31T15:54:59.446394Z","shell.execute_reply":"2021-08-31T16:03:14.560239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:05:48.276592Z","iopub.execute_input":"2021-08-31T16:05:48.276914Z","iopub.status.idle":"2021-08-31T16:05:48.283274Z","shell.execute_reply.started":"2021-08-31T16:05:48.276884Z","shell.execute_reply":"2021-08-31T16:05:48.282219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBRegressor Predictions for Blended Dataset","metadata":{}},{"cell_type":"code","source":"valid_preds = {}\ntest_preds = []\nrmse_scores = []\n\n# Optimized params\nxgbr_params = {'random_state': 501,\n 'n_estimators': 13500,\n 'learning_rate': 0.016009131284386868,\n 'reg_alpha': 8.934466248992485e-08,\n 'reg_lambda': 1.889567898176322e-07,\n 'colsample_bytree': 0.8819901735790897,\n 'subsample': 0.3510814160409993,\n 'max_depth': 1,\n 'booster': 'gbtree'}\n\nfor fold in range(N_FOLDS):\n    X_train = df[df.kfold != fold][useful_features3].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features3].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    X_test = df_test[useful_features3].copy()\n    \n    valid_ids = df[df.kfold == fold].id.values.tolist()\n    \n    xgbr = XGBRegressor(\n        n_jobs=-1,\n        **xgbr_params\n    )\n\n    xgbr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    \n    valid_pred = xgbr.predict(X_valid)\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    \n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    rmse_scores.append(rmse)\n    \n    test_pred = xgbr.predict(X_test)\n    test_preds.append(test_pred)\n    \n    print(fold, rmse)\n\nprint(\"Mean RMSE: {}\".format(np.mean(rmse_scores)))\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\nvalid_preds.columns = [\"id\", \"blend_pred_1\"]\nvalid_preds.to_csv(\"blend_train_pred_1.csv\", index=False)\n\ndf_submission_xgbr = df_submission.copy()\ndf_submission_xgbr['target'] = np.mean(np.column_stack(test_preds), axis=1)\ndf_submission_xgbr.columns = [\"id\", \"blend_pred_1\"]\ndf_submission_xgbr.to_csv('blend_test_pred_1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:16:17.321437Z","iopub.execute_input":"2021-08-31T16:16:17.321753Z","iopub.status.idle":"2021-08-31T16:24:16.54167Z","shell.execute_reply.started":"2021-08-31T16:16:17.321724Z","shell.execute_reply":"2021-08-31T16:24:16.540769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBMRegressor Predictions for Blended Dataset","metadata":{}},{"cell_type":"code","source":"valid_preds = {}\ntest_preds = []\nrmse_scores = []\n\n# Optimized params\nlgbmr_params = {'random_state': 31501,\n 'n_estimators': 6500,\n 'reg_alpha': 0.05821336452138286,\n 'reg_lambda': 0.020420330390252723,\n 'colsample_bytree': 0.4510821411914482,\n 'subsample': 0.24089341054929064,\n 'learning_rate': 0.010884158656739853,\n 'max_depth': 84,\n 'num_leaves': 10,\n 'min_child_samples': 143,\n 'cat_smooth': 19}\n\nfor fold in range(N_FOLDS):\n    X_train = df[df.kfold != fold][useful_features3].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features3].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    X_test = df_test[useful_features3].copy()\n    \n    valid_ids = df[df.kfold == fold].id.values.tolist()\n    \n    lgbmr = LGBMRegressor(\n        n_jobs=-1,\n        **lgbmr_params\n    )\n    \n    lgbmr.fit(\n        X_train, y_train,\n        early_stopping_rounds=300,\n        eval_set=[(X_valid, y_valid)],\n        verbose=2000\n    )\n    \n    valid_pred = lgbmr.predict(X_valid)\n    valid_preds.update(dict(zip(valid_ids, valid_pred)))\n    \n    rmse = mean_squared_error(y_valid, valid_pred, squared=False)\n    rmse_scores.append(rmse)\n    \n    test_pred = lgbmr.predict(X_test)\n    test_preds.append(test_pred)\n    \n    print(fold, rmse)\n\nprint(\"Mean RMSE: {}\".format(np.mean(rmse_scores)))\n\nvalid_preds = pd.DataFrame.from_dict(valid_preds, orient=\"index\").reset_index()\nvalid_preds.columns = [\"id\", \"blend_pred_2\"]\nvalid_preds.to_csv(\"blend_train_pred_2.csv\", index=False)\n\ndf_submission_lgbmr = df_submission.copy()\ndf_submission_lgbmr['target'] = np.mean(np.column_stack(test_preds), axis=1)\ndf_submission_lgbmr.columns = [\"id\", \"blend_pred_2\"]\ndf_submission_lgbmr.to_csv('blend_test_pred_2.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Blended Train and Test Predictions","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv(\"../input/30days-stack-data/blend_train_pred_1.csv\")\ndf2 = pd.read_csv(\"../input/30days-stack-data/blend_train_pred_2.csv\")\n\ndf_test1 = pd.read_csv(\"../input/30days-stack-data/blend_test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"../input/30days-stack-data/blend_test_pred_2.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:28:42.556518Z","iopub.execute_input":"2021-08-31T16:28:42.556861Z","iopub.status.idle":"2021-08-31T16:28:43.498798Z","shell.execute_reply.started":"2021-08-31T16:28:42.55683Z","shell.execute_reply":"2021-08-31T16:28:43.497971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:28:58.767172Z","iopub.execute_input":"2021-08-31T16:28:58.767499Z","iopub.status.idle":"2021-08-31T16:28:58.794928Z","shell.execute_reply.started":"2021-08-31T16:28:58.767469Z","shell.execute_reply":"2021-08-31T16:28:58.793716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape, df1.shape, df_test1.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:29:05.765386Z","iopub.execute_input":"2021-08-31T16:29:05.7657Z","iopub.status.idle":"2021-08-31T16:29:05.771471Z","shell.execute_reply.started":"2021-08-31T16:29:05.765672Z","shell.execute_reply":"2021-08-31T16:29:05.770498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features4 = [\"blend_pred_1\", \"blend_pred_2\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:29:15.325939Z","iopub.execute_input":"2021-08-31T16:29:15.326279Z","iopub.status.idle":"2021-08-31T16:29:15.330446Z","shell.execute_reply.started":"2021-08-31T16:29:15.326243Z","shell.execute_reply":"2021-08-31T16:29:15.329436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LinearRegression Predictions on Stacked Dataset","metadata":{}},{"cell_type":"code","source":"final_predictions = []\nscores = []\nfor fold in range(N_FOLDS):\n    X_train = df[df.kfold != fold][useful_features4].copy()\n    y_train = df[df.kfold != fold]['target'].copy()\n    \n    X_valid = df[df.kfold == fold][useful_features4].copy()\n    y_valid = df[df.kfold == fold]['target'].copy()\n    \n    X_test = df_test[useful_features4].copy()\n    \n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    \n    preds_valid = model.predict(X_valid)\n    test_preds = model.predict(X_test)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(y_valid, preds_valid, squared=False)\n    scores.append(rmse)\n    print(fold, rmse)\n\nprint(np.mean(scores), np.std(scores))\n\ndf_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\ndf_submission.to_csv(\"stack_submission_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:29:23.236252Z","iopub.execute_input":"2021-08-31T16:29:23.236566Z","iopub.status.idle":"2021-08-31T16:29:25.787502Z","shell.execute_reply.started":"2021-08-31T16:29:23.236539Z","shell.execute_reply":"2021-08-31T16:29:25.786651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}