{"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","version":"3.6.3","file_extension":".py","nbconvert_exporter":"python"}},"cells":[{"cell_type":"markdown","source":"# Introduction\n    Feature selection을 진행한 후 Linear regression 모델을 baseline으로 하여 DecisionTree, MLP, Ensemble과 같은 modeling기법을 통해 가장 높은 정확도를 나타내는 model을 찾아낼 것이다.","metadata":{"_cell_guid":"9ea825d0-2940-4b22-97e4-2e0334b0e246","_uuid":"d180f31c308c90819e44011aa6e223a9752fb98e"}},{"cell_type":"markdown","source":"## 1) Feature selection\n    Feature들의 수가 많으면 sample의 수에 따라서 complexity가 높아지기 때문에 overfitting이 일어날 확률이 높다. 따라서 Irrelevant feature와 Redundant Feature들을 제거하여 원래 Feature와의 차이점을 볼 것이다. ","metadata":{"_cell_guid":"e353758a-23e4-4f94-a7b4-76dd07ebdd04","_uuid":"d3a0dcd29f0cfd9568e8a401a7894afb69e44658"}},{"cell_type":"markdown","source":"###### - Pandas로 training dataset, test dataset 불러오기","metadata":{"_cell_guid":"4a708a81-c556-45ec-987a-8cd4a4c09dcd","_uuid":"6c1b5ccc179140f6f8fc83ccaace4d84d2a91cbe"}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as matplot\nimport numpy as np\n\nimport re\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n\ndf_train = pd.read_csv('../input/Train_data.csv')\ndf_test = pd.read_csv('../input/test_data.csv')\ndf_test = df_test.drop('Unnamed: 0', axis=1)","execution_count":null,"metadata":{"_cell_guid":"936dcd83-e109-4078-bde8-2c1d616f61ef","_uuid":"f208d6751b1a1c39f3e7d77e17e822136f254104","collapsed":true},"outputs":[]},{"cell_type":"code","source":"df_train.head()","execution_count":null,"metadata":{"_cell_guid":"b81cd6e4-7b43-46f0-a619-a2732816f259","_uuid":"3adf147fed7b86527bae09791bd55c6a2a555e86"},"outputs":[]},{"cell_type":"code","source":"df_test.head()","execution_count":null,"metadata":{"_cell_guid":"0f5ba59d-72f7-4edc-8d75-492a9f70cbe9","_uuid":"9370a0518fe52406fd3224eaff704a50a0428f83"},"outputs":[]},{"cell_type":"markdown","source":"###### - training dataset과 test dateaset을 각각의 df에 저장해주고 X와 Y를 나눠준다(xAttack인지, 분석 feature 들인지)","metadata":{"_cell_guid":"61fc250e-ce7d-4046-adc6-7943f694d319","_uuid":"bc7fa31bd05d3c7e0f08faae251b4018adedd6ba"}},{"cell_type":"code","source":"X_train = df_train.drop('xAttack', axis=1)\nY_train = df_train.loc[:,['xAttack']]\nX_test = df_test.drop('xAttack', axis=1)\nY_test = df_test.loc[:,['xAttack']]","execution_count":null,"metadata":{"_cell_guid":"79ae1b78-ad06-4ff8-964f-5d64d206d11d","_uuid":"8b82bcc8a65e3b04cfbd11931620fbffbdac52c3","collapsed":true},"outputs":[]},{"cell_type":"markdown","source":"###### - preprocessing과 one hot encoding 을 적용시켜준다, X는 onehotencoder, Y는 LabelBinarizer","metadata":{"_cell_guid":"b07e8a58-085a-4c04-9713-488bd0c50fea","_uuid":"2035930bb9eafd19e2cb5906cb06ef6a0e50a619"}},{"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder","execution_count":null,"metadata":{"_cell_guid":"10694d3e-addd-49f8-be5b-25f3e9cc63a0","_uuid":"0f2e3a1aa95525075b8eb064b9173b36f4b651f2","collapsed":true},"outputs":[]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nenc = OneHotEncoder()\nlb = preprocessing.LabelBinarizer()","execution_count":null,"metadata":{"_cell_guid":"58b70f7f-6ead-4b5e-8424-04660069681b","_uuid":"193805a6a0e138e119a5d456b16fe468e84a683e","collapsed":true},"outputs":[]},{"cell_type":"markdown","source":"- X OneHotEncoding","metadata":{"_cell_guid":"e77eb2f4-abf2-4aa9-9d0c-25b311178cad","_uuid":"0f641714525c947ac7a47103effad55c69f4a8be"}},{"cell_type":"code","source":"X_train['protocol_type'] = le.fit_transform(X_train['protocol_type'])\n# enc.fit_transform(X_train['protocol_type'])\n\nX_test['protocol_type'] = le.fit_transform(X_test['protocol_type'])\n# enc.fit_transform(X_test['protocol_type'])\n\nX_train.head()","execution_count":null,"metadata":{"_cell_guid":"95e6a442-3cb5-452a-b0a8-23eadf29418c","_uuid":"ce401e8dbf4fa966d0fbc8a103fd795f0bf0a781"},"outputs":[]},{"cell_type":"markdown","source":"- Y LabelBinarizer","metadata":{"_cell_guid":"165c6f9f-0e10-49e5-90f6-0be9d69fd907","_uuid":"a2ed1559ce7d786d5fe0b1a088872bbf688dd1de"}},{"cell_type":"code","source":"Y_train['xAttack'] = le.fit_transform(Y_train['xAttack'])\nlb.fit_transform(Y_train['xAttack'])\n\nY_test['xAttack'] = le.fit_transform(Y_test['xAttack'])\nlb.fit_transform(Y_test['xAttack'])\n\nY_train.describe()","execution_count":null,"metadata":{"_cell_guid":"81579637-fd13-4f26-be25-bc4add67fd9b","_uuid":"40c2c9b5a73c6c014eb9abc889b6cdfdd5798a83"},"outputs":[]},{"cell_type":"markdown","source":"### 1. Standard deviation\n    standard deviation이 작은(편차가 작은) feature들을 제외시키는 방법을 적용해 보았다. 하지만 feature type이 discrete한 경우에는 deviation이 작을 수밖에 없기 때문에 불합리하다고 판단, continuous한 경우에만 생각하기로 하였다.","metadata":{"_cell_guid":"a01dff4a-5413-4111-be29-053ebbd939c1","_uuid":"39744b8a0505221bf7f9eda3f3a90858be748be0"}},{"cell_type":"code","source":"#except continuous feature\ncon_list = ['protocol_type', 'service', 'flag', 'land', 'logged_in', 'su_attempted', 'is_host_login', 'is_guest_login']\ncon_train = X_train.drop(con_list, axis=1)\n\n#drop n smallest std features\nstdtrain = con_train.std(axis=0)\nstd_X_train = stdtrain.to_frame()\nstd_X_train.nsmallest(10, columns=0).head(10)","execution_count":null,"metadata":{"_cell_guid":"b2bd6692-0d3a-41c4-a270-1ea0cbee38a1","_uuid":"f20d04d85758220bc28114b389dfaabf304a6171"},"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{"_cell_guid":"d6fcbd56-1683-4a97-97fc-fc5de423a3a5","_uuid":"28970ee3fa8c613b2c065674483d0de465bffbbc"}},{"cell_type":"markdown","source":"#### num_outbound_cmds 는 standard deviation이 0이므로 우선 이것부터 제거해 준다.","metadata":{"_cell_guid":"89f0397c-71c3-49ab-8322-e761dd250e5c","_uuid":"5f60d8d834b4c5ac67da3cf58c4a8433a3362a47"}},{"cell_type":"code","source":"X_train = X_train.drop(['num_outbound_cmds'], axis=1)\nX_test = X_test.drop(['num_outbound_cmds'], axis=1)\n\ndf_train = pd.concat([X_train, Y_train], axis=1)\ndf_train.head()\n\nX_train.head()","execution_count":null,"metadata":{"_cell_guid":"cad79de8-8cb0-4afc-b4dc-19a63487dbfd","_uuid":"b12365a86a883362a443fbbf50bb1bae05fc1831"},"outputs":[]},{"cell_type":"markdown","source":"#### std가 낮은 10개를 고른후 feature들을 drop -> X_train_stdrop에 저장해준다. (Ensemble feature selection 이후에 사용 예정)","metadata":{"_cell_guid":"0ae413eb-04f4-411c-8779-63ce346e5445","_uuid":"de438268e23aa121bb31424d42c00f150d7db5b5"}},{"cell_type":"code","source":"stdrop_list = ['urgent', 'num_shells', 'root_shell',\n        'num_failed_logins', 'num_access_files', 'dst_host_srv_diff_host_rate',\n        'diff_srv_rate', 'dst_host_diff_srv_rate', 'wrong_fragment']\n\nX_test_stdrop = X_test.drop(stdrop_list, axis=1)\n\nX_train_stdrop = X_train.drop(stdrop_list, axis=1)\n\ndf_train_stdrop = pd.concat([X_train_stdrop, Y_train], axis=1)\n\ndf_train_stdrop.head()","execution_count":null,"metadata":{"_cell_guid":"b5910eb2-a2f0-48d2-8dbe-bc79060b5723","_uuid":"d354b008daa466e55e63cc75727720bb0c2e2510"},"outputs":[]},{"cell_type":"markdown","source":"### Baseline - Linear regression으로 성능 알아보기","metadata":{"_cell_guid":"b3ead6de-6e65-4150-aee3-48c2237e0c89","_uuid":"37852d92d7edb4ffab7e7eefd919f9862670b8a3"}},{"cell_type":"markdown","source":"- Linear regression","metadata":{"_cell_guid":"3f4204d1-84ef-438b-be32-1529d3ffa1b8","_uuid":"a88236cb7fb27803dfb3b2f145e58518542b91f0"}},{"cell_type":"code","source":"from sklearn import linear_model","execution_count":null,"metadata":{"_cell_guid":"2bea2710-d18d-499a-aa5c-bc96caee6b4b","_uuid":"d89de686669eebd8d37e161f1794e9a8676f95ad","collapsed":true},"outputs":[]},{"cell_type":"code","source":"LR = linear_model.LinearRegression()","execution_count":null,"metadata":{"_cell_guid":"4f3b1c0f-122b-4df0-b4a7-bfd0dde259a4","_uuid":"368bcf954e102e2ea34a10f4f9d0b4816b19fef1","collapsed":true},"outputs":[]},{"cell_type":"code","source":"LR.fit(X_train, Y_train)","execution_count":null,"metadata":{"_cell_guid":"e96da0f8-19c2-429c-9f73-a097a0f5de18","_uuid":"7babbd4a1225e7f80ba3bac8978c330cd18551ae"},"outputs":[]},{"cell_type":"code","source":"lr_score = LR.score(X_test, Y_test)\nprint('Linear regression processing ,,,')\nprint('Linear regression Score: %.2f %%' % lr_score)","execution_count":null,"metadata":{"_cell_guid":"b8f0a17e-671f-476e-bd7b-6f28f96ce535","_uuid":"5df91861fee8df64e9c0655e2252647e14707bac"},"outputs":[]},{"cell_type":"markdown","source":"##### linear regression은 33%의 확률밖에 내지 못한다.","metadata":{"_cell_guid":"8200920f-d69b-487b-8e19-19a998cd22b4","_uuid":"fce5178f0791e2b90cc53ec020b2ac5915a84cd9"}},{"cell_type":"markdown","source":" ","metadata":{"_cell_guid":"fca47cc0-28fa-4b41-b531-a5057d7024ed","_uuid":"7c7885fed49a0aba2a2851391b12160496114f86"}},{"cell_type":"markdown","source":"  ","metadata":{"_cell_guid":"64e8bea6-8bc6-44f5-8df5-e21adb131bc3","_uuid":"2ebed4ad2c428097ef11fe1a82678e631291dace"}},{"cell_type":"markdown","source":"### 2. Ensemble feature selection\n    Ensemble Modeling은 각 모델에서 feature가 얼마나 영향을 미쳤는지를 확인 할 수 있다. 따라서 그 Feature들을 중심으로 feature selection을 진행해 보았다(Irrelevant 한 feature를 제거하려는 시도).","metadata":{"_cell_guid":"2f3b3e66-a2bf-4339-916c-fc2d36aa8893","_uuid":"0ba8a51a9459b8611d2987dc7bd401bde3e17520"}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"metadata":{"_cell_guid":"87393777-760d-46ef-953a-3907d983f5c7","_uuid":"841c09d39671098d22423f7db1277a0842e4f223","collapsed":true},"outputs":[]},{"cell_type":"code","source":"AB = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, learning_rate=1.0)\nRF = RandomForestClassifier(n_estimators=10, criterion='entropy', max_features='auto', bootstrap=True)\nET = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False)\nGB = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, max_features='auto')","execution_count":null,"metadata":{"_cell_guid":"dc0750ec-89bc-4848-92c2-bfab118cd616","_uuid":"d2302e128c80fec4a89f6289464aec7574127f2f","collapsed":true},"outputs":[]},{"cell_type":"code","source":"y_train = Y_train['xAttack'].ravel()\nx_train = X_train.values\nx_test = X_test.values","execution_count":null,"metadata":{"_cell_guid":"662c7500-15c9-4d64-a98d-1539e1884837","_uuid":"c863818c7db7bda6bd46862a56bdd973faf7b852","collapsed":true},"outputs":[]},{"cell_type":"markdown","source":"### feature importances를 알아보면서 기본적인 feature로는 얼마만큼의 정확도를 내는지도 미리 확인해본다.","metadata":{"_cell_guid":"5bf64821-e1cb-4566-bd21-47b40fe5049d","_uuid":"99a62ea1400e32f8f954f8aa2d199a16c4c5e66d"}},{"cell_type":"code","source":"AB.fit(X_train, Y_train)","execution_count":null,"metadata":{"_cell_guid":"600860d2-fd41-44b5-a925-608383918cc7","_uuid":"185f7b04f0d6969b7f7fd93ed791d1c07430864d"},"outputs":[]},{"cell_type":"code","source":"AB_feature = AB.feature_importances_\nAB_feature\n\nab_score = AB.score(X_test, Y_test)\n\nprint('AdaBoostClassifier processing ,,,')\nprint('AdaBoostClassifier Score: %.3f %%' % ab_score)","execution_count":null,"metadata":{"_cell_guid":"c91d81f6-ffa2-40e9-bcfc-c1e47dd7f059","_uuid":"a94eba48c02912eea57bddab2911538a5eb6744c"},"outputs":[]},{"cell_type":"code","source":"RF.fit(X_train, Y_train)","execution_count":null,"metadata":{"_cell_guid":"a64f7edf-0090-452f-bc09-c5b10d1758e5","_uuid":"92dd5f4652338ea01067bd588049c4de29b38b06"},"outputs":[]},{"cell_type":"code","source":"RF_feature = RF.feature_importances_\nRF_feature\n\nrf_score = RF.score(X_test, Y_test)\n\nprint('RandomForestClassifier processing ,,,')\nprint('RandomForestClassifier Score: %.3f %%' % rf_score)","execution_count":null,"metadata":{"_cell_guid":"47ce98f8-4fd0-4b0f-a355-84f170ee293a","_uuid":"2522e18edc1332f9383550d66ca4385f8f6254ac"},"outputs":[]},{"cell_type":"code","source":"ET.fit(X_train, Y_train)","execution_count":null,"metadata":{"_cell_guid":"6afa8afd-9e8b-443d-aa04-ee9e46a61026","_uuid":"66d759d3d00af2e028306a832ef2b65a3b92ae97"},"outputs":[]},{"cell_type":"code","source":"ET_feature = ET.feature_importances_\nET_feature\n\net_score = ET.score(X_test, Y_test)\n\nprint('ExtraTreesClassifier processing ,,,')\nprint('ExtraTreeClassifier: %.3f %%' % et_score)","execution_count":null,"metadata":{"_cell_guid":"9453484a-3364-4674-91ad-007cbcae9a82","_uuid":"8bd2d89127cf14f1b2f7cfef20e9d7c0154d9c08"},"outputs":[]},{"cell_type":"code","source":"GB.fit(X_train, Y_train)","execution_count":null,"metadata":{"_cell_guid":"7807d34a-9a2a-4d83-8685-d90c893c06a2","_uuid":"96410fef5c90a6d2a23154e588bf1b81d362e816"},"outputs":[]},{"cell_type":"code","source":"GB_feature = GB.feature_importances_\nGB_feature\n\ngb_score = GB.score(X_test, Y_test)\n\nprint('GradientBoostingClassifier processing ,,,')\nprint('GradientBoostingClassifier Score: %.3f %%' % gb_score)","execution_count":null,"metadata":{"_cell_guid":"89511522-d2b9-4bed-ba12-163f4b9aae1f","_uuid":"1db270130b8d0a6ccf918ffd4c2857ff85e3a144"},"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{"_cell_guid":"ba855d1d-6ec7-41fd-8be0-273dabf7d97d","_uuid":"e4d1ca5200a2f5c2fda8d0498d1a7b29b6750fb4"}},{"cell_type":"markdown","source":" ","metadata":{"_cell_guid":"967900a5-7fb5-45c5-b80c-c22be7ae7779","_uuid":"9ab6285272ed790dad07e88643e6b64d8fbf1b8b"}},{"cell_type":"markdown","source":"### 앞에서 진행한 Ensemble을 통해서 각 feature들이 어떠한 영향을 주는지를 알아보자","metadata":{"_cell_guid":"38dafed5-3f47-4dcc-ab97-7d3faff4a631","_uuid":"4b25db45c88fc8927c1dbe753f0515095da51a0f"}},{"cell_type":"code","source":"cols = X_train.columns.values\n\nfeature_df = pd.DataFrame({'features': cols,\n                           'AdaBoost' : AB_feature,\n                           'RandomForest' : RF_feature,\n                           'ExtraTree' : ET_feature,\n                           'GradientBoost' : GB_feature\n                          })\nfeature_df.head(8)","execution_count":null,"metadata":{"_cell_guid":"c06af718-3e5a-4439-9808-0eb0a9fa0c74","_uuid":"3013e38f34f0671d6a9dee1041f566eec6abf989"},"outputs":[]},{"cell_type":"markdown","source":"- Feature들의 영향력을 그래프로 표현","metadata":{"_cell_guid":"a673d858-c84f-4d65-b21a-ecdbfb0242e7","_uuid":"36c2ba8b67a39e470f8d65efe09a305115b56969"}},{"cell_type":"code","source":"from matplotlib.ticker import MaxNLocator\nfrom collections import namedtuple\n\ngraph = feature_df.plot.bar(figsize = (18, 10), title = 'Feature distribution', grid=True, legend=True, fontsize = 15, \n                            xticks=feature_df.index)\ngraph.set_xticklabels(feature_df.features, rotation = 80)","execution_count":null,"metadata":{"_cell_guid":"b85a5513-dae3-4bc2-8b78-9f8e6661c69f","_uuid":"b5528668f63a93dc5469c218a88dff22bba4a4db"},"outputs":[]},{"cell_type":"markdown","source":"#### 각 Ensemble model에서 12개씩 feature를 뽑아낸다","metadata":{"_cell_guid":"abec513b-02cb-4d07-874e-12765db13f98","_uuid":"3c472cd98a2601e78546275d5e18c9dfdd27c2a9"}},{"cell_type":"code","source":"a_f = feature_df.nlargest(12, 'AdaBoost')\ne_f = feature_df.nlargest(12, 'ExtraTree')\ng_f = feature_df.nlargest(12, 'GradientBoost')\nr_f = feature_df.nlargest(12, 'RandomForest')","execution_count":null,"metadata":{"_cell_guid":"2b861c0c-454e-4f85-b7db-a56fa8a9f4aa","_uuid":"38b3e44e8794957e441561b28e9dda2e669501d5","collapsed":true},"outputs":[]},{"cell_type":"markdown","source":"duplicate한것을 삭제","metadata":{"_cell_guid":"d7fb1398-b03f-4b02-8186-60c58db2f9c4","_uuid":"dfe107880c4b18d82062a6d068fdd5d40ec2cb81"}},{"cell_type":"code","source":"result = pd.concat([a_f, e_f, g_f, r_f])\nresult = result.drop_duplicates() # duplicate feature삭제\nresult","execution_count":null,"metadata":{"_cell_guid":"9f203942-69bc-4af3-a607-c69a91f67a61","_uuid":"25b3b9f96cd8dd0e3e5d1762136e922c2b5623ae","scrolled":false},"outputs":[]},{"cell_type":"code","source":"selected_features = result['features'].values.tolist()\nselected_features","execution_count":null,"metadata":{"_cell_guid":"a6e3bfba-4dba-43fa-b364-07a9378377da","_uuid":"5dc58fd0a44b69a5b54e3a58a0a738bdb87bdda2","scrolled":false},"outputs":[]},{"cell_type":"markdown","source":"  ","metadata":{"_cell_guid":"c9b2ed2b-06cd-4b08-822d-50c9828e0078","_uuid":"e25e9879435421a072ab3d510c191dd9ba51f98a"}},{"cell_type":"markdown","source":"\n\n","metadata":{"_cell_guid":"df1163df-e894-4d97-953b-3fd4bd6e5042","_uuid":"ff264ffff9eee58536f79b11ad9fb360b9851b07"}},{"cell_type":"markdown","source":"### 아래는 standard deviation이 작은 feature들을 제외하고 training한 결과이다.","metadata":{"_cell_guid":"643b3d53-660b-4381-8075-bece770d15ac","_uuid":"485a0247c1ce3e1c754dfe1287beea3d8bb34c55"}},{"cell_type":"code","source":"AB.fit(X_train_stdrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"5b7a01d5-9560-468c-a31f-8dd70aeeac11","_uuid":"5896caa58b65ddd20e7140a707e0b26a508f7a69"},"outputs":[]},{"cell_type":"code","source":"ab2_score = AB.score(X_test_stdrop, Y_test)\n\nprint('AdaBoostClassifier_stdrop processing ,,,')\nprint('AdaBoostClasifier Score: %.3f %%' % ab2_score)","execution_count":null,"metadata":{"_cell_guid":"47adb753-5d6d-4d14-a4e3-36112a56b125","_uuid":"447a55f24b34603b0e29fafa5cd0fc34e0f54f96"},"outputs":[]},{"cell_type":"code","source":"RF.fit(X_train_stdrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"b7b2d4bc-d577-48f9-aca7-f65d37fa006a","_uuid":"a0f73db1d1d23e920c0120986168e166adbf9495"},"outputs":[]},{"cell_type":"code","source":"rf2_score = RF.score(X_test_stdrop, Y_test)\n\nprint('RandomForestClassifier_stdrop processing ,,,')\nprint('RandomForestClassifier Score: %.3f %%' % rf2_score)","execution_count":null,"metadata":{"_cell_guid":"fbf43d5c-5668-45d1-a664-20bcc64f197f","_uuid":"67259e4de30174ad21b5d41214b5882dad691746"},"outputs":[]},{"cell_type":"code","source":"ET.fit(X_train_stdrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"d3cc1b5e-c80a-4839-a543-f40377a3f897","_uuid":"c00ac7456975a9af2bd7e11c6daadb05121a6a3c"},"outputs":[]},{"cell_type":"code","source":"et2_score = ET.score(X_test_stdrop, Y_test)\n\nprint('ExtraTreesClassifier_stdrop processing ,,,')\nprint('ExtraTreesClassifier Score: %.3f %%' % et2_score)","execution_count":null,"metadata":{"_cell_guid":"b8c50fbd-2f13-4da0-b729-77ee986a0aec","_uuid":"686b33dbf7c1c0558ac090cecb63321243a096a1"},"outputs":[]},{"cell_type":"code","source":"GB.fit(X_train_stdrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"d34879e9-deb8-42c9-8c20-878af09fedbf","_uuid":"1c1e152c42ee8151a46786f444a810b8a5c1dc8f"},"outputs":[]},{"cell_type":"code","source":"gb2_score = GB.score(X_test_stdrop, Y_test)\n\nprint('GradientBoostingClassifier_stdrop processing ,,,')\nprint('GradientBoostingClassifier Score: %.2f %%' % gb2_score)","execution_count":null,"metadata":{"_cell_guid":"d7e775f9-23ab-4b20-90fb-727d2b9a3cf5","_uuid":"7055d363c7f10372b7ec8eb0b30d611b92d3dcd9"},"outputs":[]},{"cell_type":"markdown","source":"- ensemble을 통해 얻어낸 feature만 가지고 진행","metadata":{"_cell_guid":"93c1a550-8662-4f12-a24b-6ad9f14df882","_uuid":"b794a179db6d8ae9ac47dccb1fd74492669d0f11"}},{"cell_type":"code","source":"X_train_ens = X_train[selected_features]\nX_train_ens.head()\n\nX_test_ens = X_test[selected_features]\nX_test_ens.head()","execution_count":null,"metadata":{"_cell_guid":"35de61e3-c3ff-4c8d-9241-de794d481b1d","_uuid":"e0d9dd7e7e566c20aa8023ea781db3e8da038713"},"outputs":[]},{"cell_type":"markdown","source":"### 3. Correlation\n    여러개의 Feature들 중에서 correlation이 큰 feature들(redundant한 feature)은 병합하거나 삭제시켰다. 왜냐하면 이러한 feature들의 상관관계가 크다면 굳이 feature의 수를 늘릴 필요가 없기 때문이다.","metadata":{"_cell_guid":"cf28a870-2701-4887-ac89-a5250d52e19a","_uuid":"2754765183612de6d7cb33d010886791d23f2eed"}},{"cell_type":"code","source":"sample = X_train_ens[:10000]\n\ncolormap = plt.cm.viridis\nplt.figure(figsize=(20, 20))\nsns.heatmap(sample.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=True)","execution_count":null,"metadata":{"_cell_guid":"a2c8bd16-25b4-477e-bf5d-c762243079f2","_uuid":"b10e7c3523f29bc884fc9e20748ebcba7d7c0f55"},"outputs":[]},{"cell_type":"markdown","source":"- 위의 그래프 분석 결과 아래와 같은 feature에 dependency가 높다는 것을 알아냈고 이후 추출","metadata":{"_cell_guid":"8b1afd46-b34f-4023-baff-5910a50042a3","_uuid":"caf82815aee36b2a4983dd9b5dd27e4628b9e9ee"}},{"cell_type":"code","source":"selected2 = ['flag', 'dst_host_serror_rate', 'serror_rate']\nX_train_cordrop = X_train_ens.drop(selected2, axis=1)\nX_train_cordrop.describe()\n\nX_test_cordrop = X_test_ens.drop(selected2, axis=1)\nX_test_cordrop.describe()","execution_count":null,"metadata":{"_cell_guid":"c460679f-30ad-482d-bb94-3d04203283af","_uuid":"4424fb798329958c7fb825bd2be21bb07352edc0"},"outputs":[]},{"cell_type":"markdown","source":"## 2) Modeling","metadata":{"_cell_guid":"bca84307-e401-4c50-9437-990f23354504","_uuid":"437afad9f3871fa8587de8aa3e8c26ca7aea5c82"}},{"cell_type":"markdown","source":"### Feature selection과정을 모두 마친 후의 modeling (low deviation, high correlation 제거)","metadata":{"_cell_guid":"99a7ea76-d290-4cba-9db2-5e32fd4ef880","_uuid":"5a62f476a6d659f77dbb50316f2c8d315eb0b81f"}},{"cell_type":"markdown","source":"### Ensemble modeling에 영향을 많이 주는 feature들을 가지고 최종 modeling 결과 비교","metadata":{"_cell_guid":"99fe485a-9166-4981-9b43-4e4870bb8b61","_uuid":"aa98e8b43c274dce6059e103f8e21f9f3b102ca1"}},{"cell_type":"code","source":"AB.fit(X_train_cordrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"c23bd60e-53b1-4c86-86d6-3c17a3d68559","_uuid":"a246e57258d14976d35c4dbdabc7ca3f483b34ed"},"outputs":[]},{"cell_type":"code","source":"ab_finalscore = AB.score(X_test_cordrop, Y_test)\n\nprint('AdaBoostClassifier_final processing ,,,')\nprint('AdaBoostClassifier_final Score: %.3f %%' % ab_finalscore)","execution_count":null,"metadata":{"_cell_guid":"b10f4e16-ec4c-4282-b220-4b89890beafd","_uuid":"727fda72f8d042aceeeb3ec34ddb31ecd89cfdff"},"outputs":[]},{"cell_type":"code","source":"RF.fit(X_train_cordrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"6c5110b5-31be-481c-851b-61ddd2805af9","_uuid":"68f083e6cd6b486f0d9f8abac38f71c5b7c94c71"},"outputs":[]},{"cell_type":"code","source":"rf_finalscore = RF.score(X_test_cordrop, Y_test)\n\nprint('RandomForestClassifier_final processing ,,,')\nprint('RandomForestClassifier_final Score: %.3f %%' % rf_finalscore)","execution_count":null,"metadata":{"_cell_guid":"52819ba1-5003-4d17-92a2-18088987b29f","_uuid":"7c00767e23202dbbeafc7bf1413f64602d516320"},"outputs":[]},{"cell_type":"code","source":"ET.fit(X_train_cordrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"2f5acd58-35ae-48ec-84b8-ade75c908c17","_uuid":"855df2c7826cc5cfe6fe4552dc5f2d22fea395cd"},"outputs":[]},{"cell_type":"code","source":"et_finalscore = ET.score(X_test_cordrop, Y_test)\n\nprint('ExtraTreesClassifier_final processing ,,,')\nprint('ExtraTreesClassifier_final Score: %.3f %%' % et_finalscore)","execution_count":null,"metadata":{"_cell_guid":"eb176ae8-b82e-492b-a72c-ddfb2ddf5124","_uuid":"c2ecd7d47b8ae0c242632d1c9d470c37cf2c6847"},"outputs":[]},{"cell_type":"code","source":"GB.fit(X_train_cordrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"dc93742b-4c34-49b1-8a5e-4c8011036914","_uuid":"115417bc401ba9fc71796b1d05b37dcc12ee5366"},"outputs":[]},{"cell_type":"code","source":"gb_finalscore = GB.score(X_test_cordrop, Y_test)\n\nprint('GradientBoostClassifier_final processing ,,,')\nprint('GradientBoostClassifier_final Score: %.3f %%' % gb_finalscore)","execution_count":null,"metadata":{"_cell_guid":"dd95914e-f3fd-42ef-a0a3-3c53d86ee32b","_uuid":"f9e2d9c47a0af6192dd9ba4fa6ab954355751e3f"},"outputs":[]},{"cell_type":"code","source":"LR.fit(X_train_cordrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"549bf09c-09d5-4f8d-b0ca-0b74b89a7880","_uuid":"ba400a5487c87ce330963b119ab56e5229f74595"},"outputs":[]},{"cell_type":"code","source":"lr_finalscore = LR.score(X_test_cordrop, Y_test)\n\nprint('LinearRegression_final processing ,,,')\nprint('LinearRegression_final Score: %.3f %%' % lr_finalscore)","execution_count":null,"metadata":{"_cell_guid":"9f9b879c-21e0-4d1d-9e80-0354a1532143","_uuid":"d81105f2fc8b095ab0d7934a805a3c41ed59510d"},"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier","execution_count":null,"metadata":{"_cell_guid":"3cb65a03-8abd-464c-8b2d-5dbb7dc860a4","_uuid":"8a9485ce301f024f8463fa91dd0f39873e661b4f","collapsed":true},"outputs":[]},{"cell_type":"code","source":"MLP = MLPClassifier(hidden_layer_sizes=(1000, 300, 300), solver='adam', shuffle=False, tol = 0.0001)","execution_count":null,"metadata":{"_cell_guid":"c950918b-b173-4740-862c-0c3b708a9235","_uuid":"cd31d2134b4717f323c45cd31b6f1db63ca46d4a","collapsed":true},"outputs":[]},{"cell_type":"code","source":"MLP.fit(X_train_cordrop, Y_train)","execution_count":null,"metadata":{"_cell_guid":"46881ae7-400a-4a75-8591-15328d0e6710","_uuid":"1572769ae4717ab069b458d10cd0fd5853e4d679"},"outputs":[]},{"cell_type":"code","source":"mlp_finalscore = MLP.score(X_test_cordrop, Y_test)\n\nprint('MLP_final processing ,,,')\nprint('MLP_final Score: %.3f %%' % mlp_finalscore)","execution_count":null,"metadata":{"_cell_guid":"9decad79-3473-4864-a492-28706f6e21a2","_uuid":"c4319c1619926844ac840bd07d709dbe6a005e71"},"outputs":[]},{"cell_type":"markdown","source":"## 3) Result","metadata":{"_cell_guid":"43f36342-876f-4a20-99d0-ab8234114d35","_uuid":"f13128bb7b5d80477a6fa37be02cd133c82c22f2"}},{"cell_type":"markdown","source":"결과적으로 feature selection, extraction이 높은 확률의 성과를 가져다 주지는 않았다. 1~2퍼센트 정도의 정확도 증가율을 보였지만 feature가 줄어서 조금 더 빠른 연산이 가능했고 새로운 Data가 들어왔을때 overfitting이 되는것을 막아줄 것이라고 생각한다.","metadata":{"_cell_guid":"8f682c88-9c33-4fd8-a2ce-1a8d22d3bfdd","_uuid":"87dbe5f8f85a766174de6dd17fd23e6a3118463b"}},{"cell_type":"markdown","source":"### 각 모델별 score비교","metadata":{"_cell_guid":"091ef466-7c39-4968-a207-2acfe43e0ef5","_uuid":"7787771bb862c32bf2f9d8aef64bc1b1f41f5ac2","collapsed":true}},{"cell_type":"markdown","source":"- first models","metadata":{"_cell_guid":"21cf9ef4-b728-473d-ab5c-9fc750d3b6d0","_uuid":"5a8962af1fe83734dd1306b25f014a9a224b37f1"}},{"cell_type":"code","source":"first_model = {'Model': ['Linear Regression', 'Adaboost', 'RandomForest', 'ExtraTrees', 'GradientBoost'],\n               'accuracy' : [lr_score, ab_score, rf_score, et_score, gb_score]}\n\nresult_df = pd.DataFrame(data = first_model)\nresult_df","execution_count":null,"metadata":{"_cell_guid":"62c2bfc6-4371-425f-8122-ebbcde01d793","_uuid":"2addbacc5e659767afd22b7ba6019642bf8dd891"},"outputs":[]},{"cell_type":"code","source":"r1 = result_df.plot(x='Model', y='accuracy', kind='bar', figsize=(8, 8), grid=True, title='FIRST MODEL ACCURACY', colormap=plt.cm.viridis,\n               sort_columns=True)\nr1.set_xticklabels(result_df.Model, rotation = 45)","execution_count":null,"metadata":{"_cell_guid":"1593e71a-2376-4ce0-aeed-9496d6a34033","_uuid":"9a4819e0776ce7f2b4084db5fdecd50a7f005285"},"outputs":[]},{"cell_type":"markdown","source":"- second models","metadata":{"_cell_guid":"ac55b83e-45ca-4ebe-8b07-fe2cb8c75401","_uuid":"48d088678664594035957f8eb9907f5695b0768d"}},{"cell_type":"code","source":"second_model = {'Model': ['Adaboost', 'RandomForest', 'ExtraTrees', 'GradientBoost'],\n               'accuracy' : [ab2_score, rf2_score, et2_score, gb2_score]}\n\nresult_df = pd.DataFrame(data = second_model)\nresult_df","execution_count":null,"metadata":{"_cell_guid":"30f3c2a5-5580-4a5e-9d26-3c8987b96285","_uuid":"a51fb147aa97a7fd947ca426e2dce59f746ccd75"},"outputs":[]},{"cell_type":"code","source":"r2 = result_df.plot(x='Model', y='accuracy', kind='bar', figsize=(8, 8), grid=True, title='SECOND MODEL ACCURACY', colormap=plt.cm.viridis,\n               sort_columns=True)\nr2.set_xticklabels(result_df.Model, rotation = 45)","execution_count":null,"metadata":{"_cell_guid":"d0dc189a-81b0-43ad-a816-95dd1d5de5c9","_uuid":"03e9c7e9235421489641d77913f2883ee35237ef"},"outputs":[]},{"cell_type":"markdown","source":"- final models","metadata":{"_cell_guid":"f26eaffe-1b6f-4faa-ad93-8d5e7fa1cfd6","_uuid":"71b6d0ca5a693995bc1e72150b033c526fd904fc"}},{"cell_type":"code","source":"final_model = {'Model': ['Linear Regression', 'Adaboost', 'RandomForest', 'ExtraTrees', 'GradientBoost', 'MLP'],\n               'accuracy' : [lr_finalscore, ab_finalscore, rf_finalscore, et_finalscore, gb_finalscore, mlp_finalscore]}\n\nresult_df = pd.DataFrame(data = final_model)\nresult_df","execution_count":null,"metadata":{"_cell_guid":"6fa5246c-5390-4544-8395-21cd4631d4ad","_uuid":"72b23787083c06d972b41872315c40196b9cc539"},"outputs":[]},{"cell_type":"code","source":"r3 = result_df.plot(x='Model', y='accuracy', kind='bar', figsize=(8, 8), grid=True, title='FINAL MODEL ACCURACY', colormap=plt.cm.viridis,\n               sort_columns=True)\nr3.set_xticklabels(result_df.Model, rotation = 45)","execution_count":null,"metadata":{"_cell_guid":"1f5066b8-b3e2-4037-bf27-b28a4564fe43","_uuid":"508e632d6f8c00799d6eb92f32ff04a63ca1453b"},"outputs":[]},{"cell_type":"markdown","source":"## FASTEST AND ACCURATE MODEL - final model의 ExtraTrees(76.4%)\n## STRONGEST AND THE MOST ACCURATE MODEL - final model의 GradientBoost(77.1%)","metadata":{"_cell_guid":"b33537a6-cd41-47ef-b125-f911f1d18325","_uuid":"154d61d4c43be116567977d0ca829604a43fb62d"}},{"cell_type":"markdown","source":"Gradient boost가 77퍼센트의 확률을 보이지만 속도는 ExtraTress가 월등하게 빠르다.","metadata":{"_cell_guid":"2097cca2-a6a0-4078-9d88-e0f2414e1879","_uuid":"bc95b5b49eb5471639c6561e6968ca1acc62955b"}},{"cell_type":"code","source":"","execution_count":null,"metadata":{"collapsed":true},"outputs":[]}],"nbformat":4}