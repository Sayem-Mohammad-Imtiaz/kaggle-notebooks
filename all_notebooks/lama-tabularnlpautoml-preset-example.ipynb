{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 0. Install LAMA","metadata":{}},{"cell_type":"code","source":"pip install lightautoml","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers -U","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install navec","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.1. Import necessary libraries ","metadata":{}},{"cell_type":"code","source":"# Standard python libraries\nimport os\nimport time\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport matplotlib.pyplot as plt\nfrom navec import Navec\n\n# Imports from our package\nfrom lightautoml.automl.presets.text_presets import TabularNLPAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.2. Parameters ","metadata":{}},{"cell_type":"code","source":"N_THREADS = 4 # threads cnt for lgbm and linear models\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 9000 # Time in seconds for automl run\nTARGET_NAME = 'sentiment' # Target column name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.3. Fix torch number of threads and numpy seed ","metadata":{}},{"cell_type":"code","source":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.4. Example data load ","metadata":{}},{"cell_type":"markdown","source":"Dataset from https://github.com/sismetanin/rureviews","metadata":{}},{"cell_type":"code","source":"%%time\n\ndata = pd.read_csv('../input/lama-datasets/rureviews.csv', sep='\\t')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.5. Some user feature preparation ","metadata":{}},{"cell_type":"markdown","source":"Cell below shows some user feature preparations to create task more difficult (this block can be omitted if you don't want to change the initial data):","metadata":{}},{"cell_type":"code","source":"data.sentiment.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['review'].str.split(' ').apply(len).hist(bins=100)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.6. (Optional) Data splitting for train-test ","metadata":{}},{"cell_type":"markdown","source":"Block below can be omitted if you are going to train model only or you have specific train and test files:","metadata":{}},{"cell_type":"code","source":"%%time\n\ntrain_data, test_data = train_test_split(data, \n                                         test_size=TEST_SIZE, \n                                         stratify=data[TARGET_NAME], \n                                         random_state=RANDOM_STATE)\n\ntrain_data = train_data.sample(n=25_000, random_state=RANDOM_STATE)\nprint('Data splitted. Parts sizes: train_data = {}, test_data = {}'\n              .format(train_data.shape, test_data.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(train_data, \n                                         test_size=TEST_SIZE, \n                                         stratify=train_data[TARGET_NAME], \n                                         random_state=RANDOM_STATE)\n\nprint('Data splitted. Parts sizes: train = {}, valid = {}'\n              .format(train.shape, valid.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.7. (Optional) Load RU text embeddings","metadata":{}},{"cell_type":"code","source":"!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\nnavec = Navec.load(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  ==== AutoML preset usage ====\n\n\n## Step 1. Create Task","metadata":{}},{"cell_type":"code","source":"def f1_macro(y_true, y_pred):\n    return f1_score(y_true, np.argmax(y_pred, axis=1), average='macro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntask = Task('multiclass', metric=f1_macro)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2. Setup columns roles","metadata":{}},{"cell_type":"code","source":"%%time\n\nroles = {'target': TARGET_NAME, 'text': ['review']}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3. Create AutoML from preset","metadata":{}},{"cell_type":"markdown","source":"To create AutoML model here we use `TabularNLPAutoML` preset.\n\n\nAll params we set above can be send inside preset to change its configuration:","metadata":{}},{"cell_type":"code","source":"%%time\n      \nstart = time.time()\nautoml = TabularNLPAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb']]},\n                       linear_pipeline_params = {'text_features': \"tfidf\"},\n                       gbm_pipeline_params = {'text_features': 'embed'},\n                       text_params = {'lang': 'ru', 'bert_model': 'DeepPavlov/rubert-base-cased-conversational'},\n                       autonlp_params = {'model_name': 'random_lstm',\n                                         'embedding_model': navec,\n                                         'transformer_params': {'dataset_params': {\n                                                                                  'max_length': 150,\n                                                                                  'embed_size': 300}, \n                                                              }\n                                        },\n                       tfidf_params = {'svd': True, 'tfidf_params': {'ngram_range': (1, 1)} }\n                       \n                    )\n\noof_pred = automl.fit_predict(train, valid_data = valid, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\ntime_automl = time.time() - start","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4. Predict to test data and check scores","metadata":{}},{"cell_type":"code","source":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))\n\nprint('Check scores...')\nprint('VALID score: {}'.format(f1_macro(valid[TARGET_NAME].map(automl.reader.class_mapping).values,\n                                           oof_pred.data)))\ntest_automl = f1_macro(test_data[TARGET_NAME].map(automl.reader.class_mapping ).values, test_pred.data)\nprint('TEST score: {}'.format(test_automl))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5. Same Preset with Bert.","metadata":{}},{"cell_type":"code","source":"%%time \nstart = time.time()\nautoml = TabularNLPAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'nested_cv': False, 'use_algos': [['nn']]},\n                       text_params = {'lang': 'ru', 'bert_model': 'DeepPavlov/rubert-base-cased-conversational'},\n                       nn_params = {'opt_params': { 'lr': 1e-5},\n                                    'max_length': 150, 'bs': 32, 'epoch': 1\n                                    },\n                       )\n\noof_pred = automl.fit_predict(train, valid_data = valid, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\ntime_automl_sbert = time.time() - start","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"automl.levels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Check scores...')\nprint('VALID score: {}'.format(f1_macro(valid[TARGET_NAME].map(automl.reader.class_mapping).values,\n                                           oof_pred.data)))\ntest_automl_sbert = f1_macro(test_data[TARGET_NAME].map(automl.reader.class_mapping ).values, test_pred.data)\nprint('TEST score: {}'.format(test_automl_sbert))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}