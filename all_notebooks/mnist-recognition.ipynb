{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\n\n# set image resolution to 28x28 pixels\nimg_rows, img_cols = 28, 28\n\n# number of classes = number of possible digits\nnum_classes = 10\n\ndef prep_data(raw):\n    #target variable is in first column (0-9)\n    y = raw[:,0]\n    # OHE from numerical to categorical values\n    out_y = keras.utils.to_categorical(y, num_classes)\n    # extract all feature variables (as matrix X)\n    X = raw[:, 1:]\n    num_images = raw.shape[0]\n    #all images stacked on top of each other with 2 dim (rows and cols). 1 stands for 1 channel/filer (greyscale). Color images has 3 instead.\n    out_x = X.reshape(num_images, img_rows, img_cols, 1)\n    out_x = out_x / 255\n    return out_x, out_y\n\nmnist_file = '../input/digit-recognizer/train.csv'\nmnist_data = np.loadtxt(mnist_file, skiprows=1, delimiter=',')\n\nx, y = prep_data(mnist_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## With a model built from scratch ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel = Sequential()\n\n# First layer\nmodel.add(Conv2D(12,\n                activation='relu',\n                kernel_size=3,\n                input_shape=(img_rows, img_cols, 1)))\n\n# 2nd & 3rd layer\nmodel.add(Conv2D(20,\n                activation='relu',\n                kernel_size=3))\nmodel.add(Conv2D(20,\n                activation='relu',\n                kernel_size=3))\n\n# Flatten out into 1D vector\nmodel.add(Flatten())\n\n# Dense layers, turn values into probabilities with softmax function\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# compile model, adam stands for AdaGrad and RMSProp, generally faster than working with a fixed learning rate (like SGD)\nmodel.compile(loss='categorical_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### fit model - this is the part that is compute intensive ###"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit model\nmodel.fit(x, y,\n         batch_size=100,\n         epochs=4,\n         validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cats or pokemon (or what) with transfer learning (using ResNet50 algorithm) ##"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\n\n\nnum_classes = 2\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# create model\nres_model = Sequential()\n\n# first layer is the transfered model ResNet50\n# include top=False, because top layer (last layer) is the prediction layer\nres_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n\n# predicition layer\nres_model.add(Dense(num_classes, activation='softmax'))\n\n# we exclude the first layer (i.e. Resnet50 ) because it has already been trained\nres_model.layers[0].trainable=False\n\n# compile model\nres_model.compile(optimizer='sgd',\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\n# compile model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom os.path import join\n\nprint(os.listdir(\"../input\"))\n\npokemon_image_dir = '../input/pokemon-images-and-types/images/images'\n\npokemon_paths = [join(pokemon_image_dir,filename) for filename in \n                            ['araquanid.jpg',\n                             'ambipom.png',\n                             'arbok.png',\n                             'alomomola.png']]\n\ncat_image_dir = '../input/animals10/raw-img/gatto'\ncat_paths = [join(cat_image_dir, filename) for filename in\n                            ['1007.jpeg',\n                             '10.jpeg',\n                             '1017.jpeg',\n                             '1001.jpeg']]\n\nimg_paths = pokemon_paths + cat_paths\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new directory and file structure & move pictures into this one"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, display\nfrom learntools.deep_learning.decode_predictions import decode_predictions\nimport numpy as np\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n\nimage_size = 224\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    output = preprocess_input(img_array)\n    return(output)\n\n\nmy_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\ntest_data = read_and_prep_images(img_paths)\npreds = my_model.predict(test_data)\n\nmost_likely_labels = decode_predictions(preds, top=3)\n\nfor i, img_path in enumerate(img_paths):\n    display(Image(img_path))\n    print(most_likely_labels[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pokemon or Cats with own model ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\n\nshutil.rmtree('/kaggle/working/poke')\nos.mkdir('/kaggle/working/poke/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catpath = '../input/animals10/raw-img/gatto/'\npokepath = '../input/pokemon-images-and-types/images/images/'\nnew_path = '/kaggle/working/poke'\n\npokefileList = os.listdir(pokepath)\n\nanimaldict={}\nfor f in pokefileList:\n    shutil.copy(pokepath + str(f), new_path)\n    animaldict[f] = 'poke'\n\ncatfileList = os.listdir(catpath)\n\nfor f in catfileList[0:len(pokefileList)]:\n    shutil.copy(catpath + str(f), new_path)\n    animaldict[f] = 'cat'\n\n# print(list(animaldict.items()))\ntrain = pd.DataFrame(list(animaldict.items()))\ntrain.columns = ['title', 'target']\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_dataGen = ImageDataGenerator(rescale = 1.0/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.0/255)\n\ntrain_generator = train_dataGen.flow_from_dataframe(dataframe = training_set,\n                                                    directory = '..')\n\n\n# set image resolution to 28x28 pixels\nimg_rows, img_cols = 28, 28\n\n# number of classes = number of possible digits\nnum_classes = 10\n\ndef prep_data(raw):\n    #target variable is in first column (0-9)\n    y = raw[:,0]\n    # OHE from numerical to categorical values\n    out_y = keras.utils.to_categorical(y, num_classes)\n    # extract all feature variables (as matrix X)\n    X = raw[:, 1:]\n    num_images = raw.shape[0]\n    #all images stacked on top of each other with 2 dim (rows and cols). 1 stands for 1 channel/filer (greyscale). Color images has 3 instead.\n    out_x = X.reshape(num_images, img_rows, img_cols, 1)\n    out_x = out_x / 255\n    return out_x, out_y\n\nmnist_file = '../input/digit-recognizer/train.csv'\nmnist_data = np.loadtxt(mnist_file, skiprows=1, delimiter=',')\n\nx, y = prep_data(mnist_data)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}