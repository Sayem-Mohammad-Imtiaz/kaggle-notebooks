{"cells":[{"metadata":{},"cell_type":"markdown","source":"# imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# data"},{"metadata":{},"cell_type":"markdown","source":"get the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/all-trumps-twitter-insults-20152021/trump_insult_tweets_2014_to_2021.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"put it into 2 arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_raw = []\ndate = []\n\nfor i in range(len(dataset)-2):\n    tweets_raw.append(dataset[\"tweet\"][i+2])\n    date.append(dataset[\"date\"][i+2][:4])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"tokenisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(tweets_raw)\ntweets = tokenizer.texts_to_sequences(tweets_raw)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"number of unique words in all tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(tokenizer.word_index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# number of tweets per year"},{"metadata":{"trusted":true},"cell_type":"code","source":"years = {2015:0, 2016:0, 2017:0, 2018:0, 2019:0, 2020:0, 2021:0}\n\nfor i in date:\n    years[int(i)] += 1\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nyear = ['2015', '2016', '2017', '2018', '2019', '2020', '2021']\nnums = [years[2015], years[2016], years[2017], years[2018], years[2019], years[2020], years[2021]]\nax.bar(year,nums)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# wordclouds"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_cloud(wordcloud):\n    plt.figure(figsize=(40, 30))\n    plt.imshow(wordcloud) \n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"wordcloud for most common words overall, they have alot of simple words like \"I\" and \"and\", but this is expected"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=0\n\nfor i in years:\n    total_tweets+=years[i]\n\noverallfreqs={}\n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] = 0\n    \nfor i in tweets:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            overallfreqs[word] += 1\n            break\n    \n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] /= total_tweets\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(overallfreqs)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"words more proportionally common in 2015"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=years[2015]\n\ntweets2015 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2015[word] = 0\n    \nfor i in tweets[:years[2015]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2015[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2015[word] /= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2015[word] != 0 and overallfreqs[word] != 0:\n        tweets2015[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2015)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"words more proportionally common in 2016"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=years[2016]\n\ntweets2016 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2016[word] = 0\n    \nfor i in tweets[years[2015]:years[2015]+years[2016]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2016[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2016[word] /= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2016[word] != 0 and overallfreqs[word] != 0:\n        tweets2016[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2016)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"words more proportionally common in 2017"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=years[2017]\n\ntweets2017 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2017[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]:years[2015]+years[2016]+years[2017]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2017[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2017[word] /= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2017[word] != 0 and overallfreqs[word] != 0:\n        tweets2017[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2017)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"words more proportionally common in 2018"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=years[2018]\n\ntweets2018 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2018[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]:years[2015]+years[2016]+years[2017]+years[2018]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2018[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2018[word] /= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2018[word] != 0 and overallfreqs[word] != 0:\n        tweets2018[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2018)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"words more proportionally common in 2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=years[2019]\n\ntweets2019 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2019[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]+years[2018]:years[2015]+years[2016]+years[2017]+years[2018]+years[2019]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2019[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2019[word] /= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2019[word] != 0 and overallfreqs[word] != 0:\n        tweets2019[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2019)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"words more proportionally common in 2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=years[2020]\n\ntweets2020 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2020[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]+years[2018]+years[2019]:years[2015]+years[2016]+years[2017]+years[2018]+years[2019]+years[2020]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2020[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2020[word] /= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2020[word] != 0 and overallfreqs[word] != 0:\n        tweets2020[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2020)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"words more proportionally common in 2021"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_tweets=years[2021]\n\ntweets2021 = {}\n\nfor word, index in tokenizer.word_index.items():\n      tweets2021[word] = 0\n    \nfor i in tweets[years[2015]+years[2016]+years[2017]+years[2018]+years[2019]+years[2020]:years[2015]+years[2016]+years[2017]+years[2018]+years[2019]+years[2020]+years[2021]]:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            tweets2021[word] += 1\n            break    \n    \nfor word, index in tokenizer.word_index.items():\n      tweets2021[word] /= total_tweets\n        \nfor word, index in tokenizer.word_index.items():\n    if tweets2021[word] != 0 and overallfreqs[word] != 0:\n        tweets2021[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(tweets2021)\n\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# can a machine learning model tell what year they are from"},{"metadata":{},"cell_type":"markdown","source":"data"},{"metadata":{"trusted":true},"cell_type":"code","source":"format_date = [[0 for col in range(7)] for row in range(len(date))]\nfor i in range(len(date)):\n    format_date[i][int(date[i])-2015] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_train = []\ndate_train = []\ntweets_test = []\ndate_test = []\ntweets_val = []\ndate_val = []\n\nfor i in range(len(tweets_raw)):\n    if i % 10 == 1:\n        tweets_test.append(tweets_raw[i])\n        date_test.append(format_date[i])\n    elif i % 10 == 2:\n        tweets_val.append(tweets_raw[i])\n        date_val.append(format_date[i])\n    else:\n        tweets_train.append(tweets_raw[i])\n        date_train.append(format_date[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"model and training"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = tf.keras.layers.experimental.preprocessing.TextVectorization()\n\nencoder.adapt(tweets_raw)\n\nmodel = tf.keras.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),\n        output_dim=64,\n        # Use masking to handle the variable sequence lengths\n        mask_zero=True),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(7)\n])\n\nmodel.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\n\nhistory = model.fit(x=tweets_train, y=date_train, batch_size=5, epochs=10,\n                    validation_data=(tweets_val, date_val), callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True\n))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"accuracy history"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"loss history"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### test results"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(\n    x=tweets_test, y=date_test, use_multiprocessing=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# conclusion"},{"metadata":{},"cell_type":"markdown","source":"74.5% accuracy is a high percentage. This could be compared to under what would be under 15% accuracy over the 7 years if it was random. This goes to show that onald Trumps tweets change in strong correlation to the times, focussing on words and phrases more to do with the times, perhaps more controversial in  2020 and 2021.\n\nOverall some words like fake news were particularly common which is interesting too.\n\nIf you have feedback please leave it as a comment."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}