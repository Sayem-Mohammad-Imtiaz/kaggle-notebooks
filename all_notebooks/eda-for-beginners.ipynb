{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Author: Kazi Amit Hasan\n\nDepartment of Computer Science & Engineering, <br>\nRajshahi University of Engineering & Technology (RUET) <br>\nWebsite: https://amithasanshuvo.github.io/ <br>\nLinkedin: https://www.linkedin.com/in/kazi-amit-hasan-514443140/ <br>\nEmail: kaziamithasan89@gmail.com <br>\n\n\n### Comment: \nThis notebook represents EDA. I tried to implemented each examples while I was reading and practicing the book (in reference). <br>\n<b>Please give your feedback how I can improve the notebook and please upvote to support. Happy Learning!\n\n\n##### Reference \nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems book (The best book I ever got on Data Science <3) <br>\n\nLanguage: Python\n\n##### Topics Covered:\n1. Downloading and playing with the dataset\n2. Data Visualization\n3. Correlation Analysis\n4. Data Cleaning and Handling Missing Values\n5. Handling text and Categorical attributes\n\n\n\n##### Todo list:\n1. Feature Scaling\n2. Pipelines\n3. Train and Evaluating\n4. Cross Validation\n5. Tuning\n6. Grid Search\n7. Randomized Search\n8. Ensemble method\n9. Do the exercises"},{"metadata":{},"cell_type":"markdown","source":"## Downloading and playing with the dataset"},{"metadata":{"id":"-oUXTWz-hPCP","trusted":true},"cell_type":"code","source":"\nimport pandas as pd\n\nhousing = pd.read_csv(\"../input/hands-on-machine-learning-housing-dataset/housing.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"_jocr97PhaFx","outputId":"952acdbd-08d4-4e2b-c2a7-89a7c36873d8","trusted":true},"cell_type":"code","source":"#Showing the first 5 rows\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ZQ58sAlOhanF","outputId":"f291f158-d76d-4859-cd71-1c488789ed3a","trusted":true},"cell_type":"code","source":"#info of dataset\nhousing.info","execution_count":null,"outputs":[]},{"metadata":{"id":"T6Fuh8D7hedj","outputId":"5683a7de-f991-4a81-9a2a-d998fc086eaf","trusted":true},"cell_type":"code","source":"#Value counts of ocean_proximity column\nhousing['ocean_proximity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"fm0TgGoNhlwv","outputId":"1f0e5dcf-4d92-48b4-9c8f-3a73f5439a6e","trusted":true},"cell_type":"code","source":"#shape of our data\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"j9c6hARVhpbk","outputId":"2f88c307-626b-4479-d2dd-9b9f31b183ab","trusted":true},"cell_type":"code","source":"#Summary of each numerical attributes\nhousing.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"sEOu76lghurN","outputId":"8c4b067b-7b1d-49de-cc0c-d7c7503130db","trusted":true},"cell_type":"code","source":"#Showwing the correlations\nhousing.corr()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"K9lq5cmrh16K","outputId":"35a83ccc-dbf7-4867-cf43-0df2af4beb31","trusted":true},"cell_type":"code","source":"#Showing the columns\nhousing.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"RQPoE9ltVxh5","outputId":"b8036f29-30a9-4a98-f10e-d74f1c6a2e93","trusted":true},"cell_type":"code","source":"#Plotting histograms for each numerical attributes\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nhousing.hist(bins =50, figsize=(20,15))\n\nplt.show()\n\n#Slighly over 1000 distrcts have a median_house_value about 500000 usd","execution_count":null,"outputs":[]},{"metadata":{"id":"89HrePn1WN8Z","outputId":"e2ee36db-0c2c-4abe-d07b-c5b5e7e07f4b","trusted":true},"cell_type":"code","source":"housing.hist(column='population')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"sfBdLRYVZqXX","trusted":true},"cell_type":"code","source":"# random_state parameter always generate the same shuffle indices. If the dataset \n# is not big enough then there's a chance of sampling bias\nfrom sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(housing, test_size = 0.2, random_state=42)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"nqHgGRtFsw_b"},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"id":"NmyoJKOi273L","outputId":"7fcf00ed-948a-4548-d1c1-c5594af59ca0","trusted":true},"cell_type":"code","source":"# Geographical data of all districts\nhousing.plot (kind ='scatter', x='longitude', y= 'latitude')","execution_count":null,"outputs":[]},{"metadata":{"id":"t-n8OkB9tgFR","outputId":"cca41bdc-d0c1-4624-e40f-f72fbed5a176","trusted":true},"cell_type":"code","source":"housing.plot (kind ='scatter', x='longitude', y= 'latitude', alpha = 0.1)\n# adding alpha for better visualization. This helps to visualize the high density data points","execution_count":null,"outputs":[]},{"metadata":{"id":"umrPo9UPt6fx","outputId":"f1e595d6-2e67-4989-e335-fb7e1ef4b271","trusted":true},"cell_type":"code","source":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n    s=housing[\"population\"]/100, label=\"population\", figsize=(10,10),\n    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.legend()\n\n# This represents that housing prices are varies with locations and population density\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correaltion Analysis"},{"metadata":{"id":"mK3HZsBhu_ja","trusted":true},"cell_type":"code","source":"corr_matrix = housing.corr()","execution_count":null,"outputs":[]},{"metadata":{"id":"J9LEhjGpvuc2","outputId":"41d2aa97-c89f-4c1e-94bb-e761fe3229c3","trusted":true},"cell_type":"code","source":"print (corr_matrix)","execution_count":null,"outputs":[]},{"metadata":{"id":"5TyHNyXNvySt","outputId":"baca64b6-8d38-4e5e-91eb-6e504593896c","trusted":true},"cell_type":"code","source":"# Correlation of median_house_value with other attributes\ncorr_matrix['median_house_value'].sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"id":"vmJBRzKFv9i1","trusted":true},"cell_type":"code","source":"# another way to check correlation using pandas\n\nfrom pandas.plotting import scatter_matrix\nattributes = ['median_house_value', 'median_income','total_rooms','housing_median_age']\nscatter_matrix(housing[attributes], figsize = (12,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.plot (kind='scatter', x=\"median_income\",y='median_house_value',alpha = 0.1)\n\n# It means corr is very strong. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating new attributes\n\nhousing['room_per-_household'] = housing['total_rooms']/housing['households']\nhousing['bedrooms_per_rooms'] = housing['total_bedrooms']/housing['total_rooms']\nhousing['population_per_household'] = housing['population']/housing['households']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now the corr matrix will look something like this\ncorr_matrix = housing.corr()\ncorr_matrix['median_house_value'].sort_values(ascending = False)\n\n\n# This means bedrooms_per_room attributee is much more correlated with mediamn house value than total num of rooms\n# Lower bedrooms has high price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.plot(kind=\"scatter\",\n             x=\"room_per-_household\",\n             y=\"median_house_value\",\n             alpha=0.2)\nplt.axis([0, 5, 0, 520000])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning and Handling Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Cleaning and handling missing values\n\n#housing.dropna(subset=['total_bedrooms'])\n\n# we can use this. but sklearn also provide e good function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy ='median')\n\n\n# this help to take care of missing values. \n# medians only be computed on numerical values ,so we need a copy of data without text attributes i.e ocean_proximity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_num = housing.drop('ocean_proximity', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer.fit(housing_num)\n# fitting the imputer instances to training data. It only computed the median of each attributes.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_num.median().values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = imputer.transform(housing_num)\n\n# Transforming the train set by replacing the missing values with new medians","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer.strategy\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_tr.loc[housing_num.index.values]\n# Putting back into Pandas df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index=housing_num.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_tr.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling text and Categorical attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_cat = housing[[\"ocean_proximity\"]]\nhousing_cat.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Earlier we left the text attribute (ocean_proximity), now we have to work on that\n\n# Converting them into labels\n\nfrom sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\nhousing_cat_encoded[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_encoder.categories_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert int to categorical values into onehot vectors\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder()\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_cat_1hot.toarray()\n","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"End to end Full ML project (Under Construction).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":4}