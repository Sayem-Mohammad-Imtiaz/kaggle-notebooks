{"cells":[{"metadata":{},"cell_type":"markdown","source":"<!-- wp:paragraph -->\n<p>Nous allons créer un modèle de prédiction avec un Random Forest en passant par l'ensemble de ces étapes : </p>\n<!-- /wp:paragraph -->\n\n<!-- wp:list -->\n<ul><li>Chargement des données</li><li>Exploration et visualisation des données</li><li>Création d'un échantillon d'apprentissage et de test</li><li>Phase d'apprentissage avec un algorithme Random Forest</li><li>Évaluation de la performance sur l'échantillon de test</li><li>Interprétation des résultats </li></ul>\n<!-- /wp:list -->\n\nVous pouvez retrouver l'ensemble de l'article sur [lovelyanalytics.com](http://lovelyanalytics.com)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Set up","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd  \nimport numpy as np\nimport pandas_profiling\nimport seaborn as sns\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chargement des données","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = pd.read_csv(\"C:/Users/Marie-JeanneVieille/Documents/Happiness_2017.csv\")\ndf = pd.read_csv(\"../input/world-happiness/2017.csv\")\nprint(\"Le fichier a \" + str(df.shape[0]) + \" lignes et \" + str(df.shape[1]) + \" colonnes\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploration","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Liste et type de données","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On analyse le contenu du fichier, le nom des colonnes et leur type, on explore les premières lignes du fichier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Liste des colonnes et leur type \ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5 premières lignes du dataset\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Analyse de la qualité des données : pandas_profiling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On fait un état des lieux de la qualité des données : \n    - Données manquantes\n    - Données corrélées\n    - Valeurs extrêmes\n    - Statistiques descriptives (moyenne, écart-type, ...)\n    - Distribution des variables\n    \nRien de tel que la librairie pandas_profiling pour calculer tout cela automatiquement","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bilan pandas_profiling : \n    - pandas_profiling a éliminé 2 variables : Whisker.high et Whisker.low qui sont fortement corrélées avec Happiness.Score. Effectivement, quand on regarde la définition de ces 2 variables on voit que ces 2 variables correspondent à l'intervalle de confiance de Happiness.Score. On peut donc les écarter pour notre analyse. On peut également supprimer Happiness.Rank\n    - Aucune valeur manquante\n    - 9 variables numériques et 1 variable textuelle (on avait déjà calculé cette info un peu plus haut) \n    \n=> Globalement ce dataset est propre.\n\nOn regarde ensuite dans le détail chaque variable","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Exploration & Visualisation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Avant de coder l'algorithme de prédiction du score de bonheur nous allons faire un peu d'exploration du jeu de données. L'idée est de mieux comprendre les liens entre les différentes variables et leur lien avec la variable à prédire Happiness.Score. Cette première étape descriptive est importante, elle vous permettra de mieux comprendre les résultats de votre algorithme et vous pourrez vous assurer que tout est cohérent. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Analyse des corrélations ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matrice des corrélations : \ncor = df.corr() \nsns.heatmap(cor, square = True, cmap=\"coolwarm\",linewidths=.5,annot=True )\n#Pour choisr la couleur du heatmap : https://matplotlib.org/examples/color/colormaps_reference.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le heatmap permet de représenter visuellement les corrélations entre les variables. \nPlus la valeur est proche de 1 (couleur rouge foncée) plus la corrélation est positive et forte. Au contraire plus la corrélation est proche de 0 (bleu foncée) plus la corrélation est négative et forte. \n\nConstats : \n\nCorrélations avec la variable cible Happiness.score : \n     - Happiness.score est correlé positivement avec Economy.GDP.per.Capita., Family et Health..Life.Expectancy. (donc globalement quand l'indicateur family augmente, Happiness.score augmente aussi) \n     - Happiness.score est correlé négativement avec Generosity\n     - Pour les autres variables la corrélation est plus faible \n     \nCorrélations entre les autres variables : \n     - 2 variables semblent assez correlées positivement : Health..Life.Expectancy. et Economy..GDP.per.Capita.\n     - Générosite et Dystopia.Residual sont correlées négativement avec la plupart des variables ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Géolocalisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Chargement du fonds de carte \n# Dispo ici https://tapiquen-sig.jimdofree.com/english-version/free-downloads/world/\nmap_df = gpd.read_file('../input/world-country/World_Countries.shp')\n\n#Jointure avec nos données (on ne conserve que Country et Happiness.Rank)\nmap_df = map_df.set_index('COUNTRY').join(df[['Country','Happiness.Score']].set_index('Country'))\nmap_df.dropna(inplace=True)\nmap_df.reset_index(inplace=True)\n\n#Préparation de la carte\n# on fixe les seuils pour la couleur\nvmin, vmax = 0, 8\n# création de la figure et des axes\nfig, ax = plt.subplots(1, figsize=(18, 5))\n\n# Création de la carte\nmap_df.plot(column='Happiness.Score', cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n# On supprime l'axe des abscisses\nax.axis('off')\n\n# On ajoute un titre\nax.set_title('Happiness.Score par pays', fontdict={'fontsize': '16', 'fontweight' : '2'})\n\n# On créé la légende\nsm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=vmin, vmax=vmax))\nsm._A = []\n\n# On ajoute la légende\ncbar = fig.colorbar(sm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Prep","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Le Dataset est de bonne qualité, il y a peu de travail à faire ici :\n    - Transformer country en index puisqu'il s'agit de l'identifiant unique \n    - Supprimer Happiness.Rank, Whisker.high et Whisker.low","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# On transforme Country en index\npd.DataFrame.set_index(df, 'Country',inplace=True)\n\n# On supprime 3 colonnes\ndf.drop(columns =['Happiness.Rank','Whisker.high', 'Whisker.low' ], inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modélisation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On transforme les données en Numpy arrays pour pouvoir les utiliser dans le modèle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#On stocke Happiness.Score (la variable à prédire) dans cible\ncible = np.array(df['Happiness.Score'])\n\n#On supprime Happiness.Score du dataset\ndf= df.drop('Happiness.Score', axis = 1)\n\n#On conserve les noms de variable à part\nliste_variables = list(df.columns)\n\n#On convertit le dataset en array\ndf = np.array(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Split du dataset en train et test","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On choisit de faire l'apprentissage sur un échantillon d'apprentissage de 75% des données et de faire le test sur 25% des données. On va également séparer la variable à prédire Happiness.Score des variables de prédiction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#On créé 4 dataset : \n#   - x_train contient 75% de x  \n#   - y_train contient le appiness.Score associé à x_train\n# => x_train et y_train permettront d'entraîner l'algorithme\n#\n#   - x_test contient 25% de x  \n#   - y_test contient le appiness.Score associé à x_test\n# => x_test et y_test permettront d'évaluer la performance de l'algorithme une fois entrainé sur le train\n\nx_train,x_test,y_train,y_test=train_test_split(df,cible,test_size=0.25, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Apprentissage","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#On importe l'algorithme à partir de sklearn\nfrom sklearn.ensemble import RandomForestRegressor\n\n#On créé un Random Forest de 100 arbres \nrf = RandomForestRegressor(n_estimators = 100, random_state = 2020)\n\n#Et on lance le training sur notre dataset de train\nrf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#On applique le modèle que l'on vient d'entraîner sur l'échantillon de test\npredictions = rf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#On va calculer plusieurs erreurs entre la valeur prédite et le score de bonheur réel (que nous avions stocké dans y_test)\n#     - MAE : Mean Asolute Error\n#     - MAPE : Mean Absolute Percentage Error \n\n# MAE \nerreurs = abs(predictions - y_test)\nprint('Mean Absolute Error:', round(np.mean(erreurs), 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La moyenne des erreurs est de 0,32 donc en moyenne on arrive à prédire le score de bonheur à 0.32 près","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAPE\nmape = 100 * (erreurs / y_test)\nprint('Mean Absolute Percentage Error :', round(np.mean(mape), 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Interprétation des résultats","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On calcule les variables d'importance du modèle, c'est à dire celles qui contribuent le plus ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf.feature_importances_\nindices = np.argsort(importances)\n\n# style du graphique \nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\nplt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [liste_variables[i] for i in indices])\nplt.xlabel('Relative Importance')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}