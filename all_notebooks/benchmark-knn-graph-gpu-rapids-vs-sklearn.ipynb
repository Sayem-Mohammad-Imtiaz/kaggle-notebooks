{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** For large dimensional + big size datasets RAPIDS might be 500 times faster than sklearn NN graph \n\nWarning: TURN ON GPU to run that notebook. \n\n\nNotebook uses rapids - https://www.kaggle.com/cdeotte/rapids - some GPU acceleration for many algorithms\n\n\nCurrent notebook  is based on Dmitry Simakov notebook: https://www.kaggle.com/simakov/rapids-knn-cugraph-test\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"if 0: # It was necessary to do in the past - now one can just import cuml on kaggle\n    \n    # That cell may run 1-3-5 minutes. (And sometimes may hang on - if so - restart notebook and run again )\n    import sys\n    #!cp ../input/rapids/rapids.0.****put correct vesion **** .0 /opt/conda/envs/rapids.tar.gz\n    !cp ../input/rapids/rapids.0.16.0 /opt/conda/envs/rapids.tar.gz\n    !cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n    sys.path = [\"/opt/conda/envs/rapids/lib/python3.6/site-packages\"] + sys.path\n    sys.path = [\"/opt/conda/envs/rapids/lib/python3.6\"] + sys.path\n    sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n    !cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n    \nimport cuml\nimport cudf\nprint('RAPIDS',cuml.__version__)\n\nfrom cuml.neighbors import NearestNeighbors as cuNearestNeighbors\nimport numpy as np\n#import igraph\nimport time    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check different methods for NN graph give exactly the same graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np\nimport pandas as pd\n\n\n#dim = 10\nc = 0 \n#method = 'kd_tree'\ndf_stat = pd.DataFrame()\n\nfor dim in [5,10,20]:\n  for n_sample in [1e5,2e5]:\n    n_sample = int(n_sample)\n\n    n_neighbors = 2\n    res = []\n    for i in range(1): # Repeat test several times\n        np.random.seed(n_sample + i)\n        X = np.random.rand(n_sample, dim)\n        \n        for method in ['brute','kd_tree','ball_tree','GPU']:\n            c += 1\n\n            df_stat.loc[c, 'Method'] = method\n            df_stat.loc[c, 'Dim'] = dim\n            df_stat.loc[c, 'N_sample'] = n_sample\n            t0 = time.time()\n            t00 = t0\n            if method == 'GPU':\n              device_data = cudf.DataFrame.from_gpu_matrix(X)\n              knn_cuml = cuNearestNeighbors(n_neighbors)\n              knn_cuml.fit(device_data)\n              D_cuml, I_cuml = knn_cuml.kneighbors(device_data, n_neighbors)\n              indices = I_cuml.to_pandas().values\n            else:\n              nbrs = NearestNeighbors(n_neighbors=2, algorithm=method  ).fit(X) # 'ball_tree'\n              distances, indices = nbrs.kneighbors(X)\n            df_stat.loc[c, 'Time NN'] = time.time()-t0\n            \n            if method == 'brute':\n              indices_save = indices.copy()\n            difr = indices_save - indices\n            df_stat.loc[c, 'Coincide with Brute'] = (np.sum( np.abs(difr)) == 0) \n            print('c',c,'Dim',dim,'Finished.',method, np.round(time.time()-t0,2),'secs passed')\n\ndf_stat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Speed test for GPU - for big sample sizes, time growth is about quadratic (as expected). Time growth with respect to dimension seems to be quite small for small dimensions, but near linear for higher D (above about 100)"},{"metadata":{"trusted":false},"cell_type":"code","source":"import time\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np\nimport pandas as pd\n\n\n#dim = 10\nc = 0 \n#method = 'kd_tree'\ndf_stat = pd.DataFrame()\n\nfor dim in [5,10,20,100, 200]:\n  for n_sample in [1e5,5e5,1e6]:\n    \n    n_sample = int(n_sample)\n\n    n_neighbors = 2\n    res = []\n    for i in range(1): # Repeat test several times\n        np.random.seed(n_sample + i)\n        X = np.random.rand(n_sample, dim)\n        \n        for method in ['GPU']:\n            c += 1\n\n            df_stat.loc[c, 'Method'] = method\n            df_stat.loc[c, 'Dim'] = dim\n            df_stat.loc[c, 'N_sample'] = n_sample\n            t0 = time.time()\n            t00 = t0\n            if method == 'GPU':\n              device_data = cudf.DataFrame.from_gpu_matrix(X)\n              knn_cuml = cuNearestNeighbors(n_neighbors)\n              knn_cuml.fit(device_data)\n              D_cuml, I_cuml = knn_cuml.kneighbors(device_data, n_neighbors)\n              indices = I_cuml.to_pandas().values\n            else:\n              nbrs = NearestNeighbors(n_neighbors=2, algorithm=method  ).fit(X) # 'ball_tree'\n              distances, indices = nbrs.kneighbors(X)\n            df_stat.loc[c, 'Time NN'] = time.time()-t0\n            print(df_stat.tail(1))\n            \n\ndf_stat","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}