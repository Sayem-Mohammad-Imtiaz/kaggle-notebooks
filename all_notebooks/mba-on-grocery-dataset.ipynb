{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T05:46:09.688576Z","iopub.execute_input":"2021-06-29T05:46:09.688999Z","iopub.status.idle":"2021-06-29T05:46:09.69443Z","shell.execute_reply.started":"2021-06-29T05:46:09.688964Z","shell.execute_reply":"2021-06-29T05:46:09.69304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/groceries-dataset-for-market-basket-analysismba/Groceries data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:46:10.19029Z","iopub.execute_input":"2021-06-29T05:46:10.190661Z","iopub.status.idle":"2021-06-29T05:46:10.261604Z","shell.execute_reply.started":"2021-06-29T05:46:10.190629Z","shell.execute_reply":"2021-06-29T05:46:10.260786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Dataset**\n\n> **We'll be dealing with the Groceries dataset provided by Kaggle to perform the Market Basket Analysis. This analysis can be used as a way to offer products based on items that has been purchased often together, or to infer the rate which products that should be bought together, in fact are. As an example, suppose a companny offers a combo shirt+shorts, with this analysis, you may know how good the combo is performing.**","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:46:10.278709Z","iopub.execute_input":"2021-06-29T05:46:10.279402Z","iopub.status.idle":"2021-06-29T05:46:10.308748Z","shell.execute_reply.started":"2021-06-29T05:46:10.27936Z","shell.execute_reply":"2021-06-29T05:46:10.30794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **We'll be creating a date column by collapsing the columns year, month and day to help us manage the data.**","metadata":{}},{"cell_type":"code","source":"df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:46:10.337903Z","iopub.execute_input":"2021-06-29T05:46:10.338586Z","iopub.status.idle":"2021-06-29T05:46:10.381124Z","shell.execute_reply.started":"2021-06-29T05:46:10.338544Z","shell.execute_reply":"2021-06-29T05:46:10.379928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **We need to perform a grouping on Member_number and date of purchase by putting them in a tuple, to impose that a purchase is defined by a combination of the Member going to the store on a specific day. This would be easier if we had an orderId field, but in this case, we had to construct the member_date field, which is our own orderId in this case. We are also creating a redundant field \"quantity\" which means each product was bought in 1 unit.**","metadata":{}},{"cell_type":"code","source":"df['member_date'] = list(zip(df['Member_number'], df['date'].dt.date))\ndf['quantity'] = 1","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:46:10.406706Z","iopub.execute_input":"2021-06-29T05:46:10.407106Z","iopub.status.idle":"2021-06-29T05:46:10.475408Z","shell.execute_reply.started":"2021-06-29T05:46:10.407071Z","shell.execute_reply":"2021-06-29T05:46:10.47447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:46:10.476751Z","iopub.execute_input":"2021-06-29T05:46:10.477225Z","iopub.status.idle":"2021-06-29T05:46:10.482493Z","shell.execute_reply.started":"2021-06-29T05:46:10.477193Z","shell.execute_reply":"2021-06-29T05:46:10.481737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Here we can see, on descending order, the more often products bought on the given shop, and also we see that the shop has 167 products. Next, we'll build the structure to make the analysis, grouping the items in the same Member_number, year, month and day. It is import to note that, by grouping Membernumber, year, month and day, we are considering that a Member made 1 purchase on that specific day, with 1 or more items on that purchase.**","metadata":{}},{"cell_type":"code","source":"df.groupby('itemDescription').size().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:46:10.487686Z","iopub.execute_input":"2021-06-29T05:46:10.488286Z","iopub.status.idle":"2021-06-29T05:46:10.508199Z","shell.execute_reply.started":"2021-06-29T05:46:10.488251Z","shell.execute_reply":"2021-06-29T05:46:10.507199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basket = df.groupby(['member_date', 'itemDescription'])['quantity'].count().unstack().fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:47:20.208422Z","iopub.execute_input":"2021-06-29T05:47:20.20885Z","iopub.status.idle":"2021-06-29T05:47:20.322789Z","shell.execute_reply.started":"2021-06-29T05:47:20.208813Z","shell.execute_reply":"2021-06-29T05:47:20.321818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_values(value):\n    if value >= 1:\n        return 1\n    else:\n        return 0 ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:47:20.865691Z","iopub.execute_input":"2021-06-29T05:47:20.866336Z","iopub.status.idle":"2021-06-29T05:47:20.871883Z","shell.execute_reply.started":"2021-06-29T05:47:20.86628Z","shell.execute_reply":"2021-06-29T05:47:20.870654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basket = basket.applymap(convert_values)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:47:21.240117Z","iopub.execute_input":"2021-06-29T05:47:21.240524Z","iopub.status.idle":"2021-06-29T05:47:22.890163Z","shell.execute_reply.started":"2021-06-29T05:47:21.240489Z","shell.execute_reply":"2021-06-29T05:47:22.888997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Wel'll be using MLXtend package which offers us tools to make the calculations needed for the association rules.**","metadata":{}},{"cell_type":"code","source":"from mlxtend.frequent_patterns import apriori \nfrom mlxtend.frequent_patterns import association_rules","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:47:24.489687Z","iopub.execute_input":"2021-06-29T05:47:24.490139Z","iopub.status.idle":"2021-06-29T05:47:24.494824Z","shell.execute_reply.started":"2021-06-29T05:47:24.4901Z","shell.execute_reply":"2021-06-29T05:47:24.493713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basket_items = apriori(basket, min_support = 0.005, use_colnames = True, max_len = 2)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:47:25.336136Z","iopub.execute_input":"2021-06-29T05:47:25.336739Z","iopub.status.idle":"2021-06-29T05:47:25.953385Z","shell.execute_reply.started":"2021-06-29T05:47:25.336688Z","shell.execute_reply":"2021-06-29T05:47:25.952457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules = association_rules(basket_items, metric = 'lift')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:47:26.045064Z","iopub.execute_input":"2021-06-29T05:47:26.045725Z","iopub.status.idle":"2021-06-29T05:47:26.057091Z","shell.execute_reply.started":"2021-06-29T05:47:26.045673Z","shell.execute_reply":"2021-06-29T05:47:26.055918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **And here we have our association rules for the MBA Analysis. Note that we are giving more importance to the \"confidence\" field here, which is the chance of buying the second product(consequent) given the first one(antecedent) was bought. Since the 'whole milk' is the most purchased product in this shop, it'll be the consequent for most antecedents, but we can see in the 6ยบ line of the table that someone who buys 'frankfurter' has a 13% chance of buying 'other vegetables'.**","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:50:27.747824Z","iopub.execute_input":"2021-06-29T05:50:27.748383Z","iopub.status.idle":"2021-06-29T05:50:27.758679Z","shell.execute_reply.started":"2021-06-29T05:50:27.748343Z","shell.execute_reply":"2021-06-29T05:50:27.757153Z"}}},{"cell_type":"code","source":"rules.sort_values(\"confidence\", ascending=False).head(15)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T05:47:27.433611Z","iopub.execute_input":"2021-06-29T05:47:27.434014Z","iopub.status.idle":"2021-06-29T05:47:27.466062Z","shell.execute_reply.started":"2021-06-29T05:47:27.433971Z","shell.execute_reply":"2021-06-29T05:47:27.465252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **This analysis can also be used to make product recomendation, or to verify if certain product combos are behaving as expected(people are really buying the white shirt+pants combo instead of buying a purple shirt and white pants).**","metadata":{}}]}