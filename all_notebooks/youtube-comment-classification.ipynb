{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Psy = pd.read_csv('../input/youtube-spam-classifiedcomments/Youtube01-Psy.csv')\nKaty = pd.read_csv('../input/youtube-spam-classifiedcomments/Youtube02-KatyPerry.csv')\nEminem = pd.read_csv('../input/youtube-spam-classifiedcomments/Youtube04-Eminem.csv')\nShakira = pd.read_csv('../input/youtube-spam-classifiedcomments/Youtube05-Shakira.csv')\nLMFAO = pd.read_csv('../input/youtube-spam-classifiedcomments/Youtube03-LMFAO.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([Shakira, Eminem, Katy, Psy, LMFAO])\ndf.drop('DATE', axis=1, inplace=True)\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CLASS'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = df['CLASS']\nprint(classes.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_messages = df[\"CONTENT\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n\n# Replace email addresses with 'email'\nprocessed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n                                 'emailaddress')\n\n# Replace URLs with 'webaddress'\nprocessed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n                                  'webaddress')\n\n# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\nprocessed = processed.str.replace(r'£|\\$', 'moneysymb')\n    \n# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\nprocessed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n                                  'phonenumbr')\n    \n# Replace numbers with 'numbr'\nprocessed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(text_messages[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n\n# Replace whitespace between terms with a single space\nprocessed = processed.str.replace(r'\\s+', ' ')\n\n# Remove leading and trailing whitespace\nprocessed = processed.str.replace(r'^\\s+|\\s+?$', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change words to lower case - Hello, HELLO, hello are all the same word\nprocessed = processed.str.lower()\nprint(processed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\n\n# remove stop words from text messages\n\nstop_words = set(stopwords.words('english'))\n\nprocessed = processed.apply(lambda x: ' '.join(\n    term for term in x.split() if term not in stop_words))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove word stems using a Porter stemmer\nps = nltk.PorterStemmer()\n\nprocessed = processed.apply(lambda x: ' '.join(\n    ps.stem(term) for term in x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\n# create bag-of-words\nall_words = []\n\nfor message in processed:\n    words = word_tokenize(message)\n    for w in words:\n        all_words.append(w)\n        \nall_words = nltk.FreqDist(all_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the total number of words and the 15 most common words\nprint('Number of words: {}'.format(len(all_words)))\nprint('Most common words: {}'.format(all_words.most_common(15)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the 1500 most common words as features\nword_features = list(all_words.keys())[:1500]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The find_features function will determine which of the 1500 word features are contained in the review\ndef find_features(message):\n    words = word_tokenize(message)\n    features = {}\n    for word in word_features:\n        features[word] = (word in words)\n\n    return features\n\n# Lets see an example!\nfeatures = find_features(str(processed[0]))\nfor key, value in features.items():\n    if value == True:\n        print (key)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets do it for all the messages\nmessages = list(zip(processed, classes))\n\n# define a seed for reproducibility\nseed = 1\nnp.random.seed = seed\nnp.random.shuffle(messages)\n\n# call find_features function for each SMS message\nfeaturesets = [(find_features(text), label) for (text, label) in messages]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can split the featuresets into training and testing datasets using sklearn\nfrom sklearn import model_selection\n\n# split the data into training and testing datasets\ntraining, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(training))\nprint(len(testing))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can use sklearn algorithms in NLTK\nfrom nltk.classify.scikitlearn import SklearnClassifier\nfrom sklearn.svm import SVC\n\nmodel = SklearnClassifier(SVC(kernel = 'linear'))\n\n# train the model on the training data\nmodel.train(training)\n\n# and test on the testing dataset!\naccuracy = nltk.classify.accuracy(model, testing)*100\nprint(\"SVC Accuracy: {}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Define models to train\nnames = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n         \"Naive Bayes\", \"SVM Linear\"]\n\nclassifiers = [\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    LogisticRegression(),\n    SGDClassifier(max_iter = 100),\n    MultinomialNB(),\n    SVC(kernel = 'linear')\n]\n\nmodels = zip(names, classifiers)\nnames1 = []\nresults = []\n\nfor name, model in models:\n    nltk_model = SklearnClassifier(model)\n    nltk_model.train(training)\n    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n    print(\"{} Accuracy: {}\".format(name, accuracy))\n    names1.append(name)\n    results.append(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt_features, labels = zip(*testing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = nltk_model.classify_many(txt_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print a confusion matrix and a classification report\nprint(classification_report(labels, prediction))\n\npd.DataFrame(\n    confusion_matrix(labels, prediction),\n    index = [['actual', 'actual'], ['ham', 'spam']],\n    columns = [['predicted', 'predicted'], ['ham', 'spam']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}