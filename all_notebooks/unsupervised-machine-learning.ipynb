{"cells":[{"metadata":{"id":"6X8A-SDW0W2X","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"id":"n5ka4SsKkGe5"},"cell_type":"markdown","source":"#**Data** **Preprocessing**","execution_count":null},{"metadata":{"id":"h2FP1n7VB91d","trusted":true},"cell_type":"code","source":"#import statements\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve, KFold\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\nimport random\nfrom sklearn.svm import SVC\nimport sklearn.metrics as sk\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import recall_score,auc, roc_auc_score, roc_curve,confusion_matrix,classification_report","execution_count":null,"outputs":[]},{"metadata":{"id":"8BA8YEtm7jBG","outputId":"c3cc1197-b50a-4b04-e0be-57005f8b1ba1","trusted":true},"cell_type":"code","source":"#change the dataset location\ndf = pd.read_csv('/kaggle/input/bank-marketing/bank-additional-full.csv', sep = ';')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"STEMeQrf0sPb","outputId":"51482534-efb0-4313-dcc0-18afffe65e6d","trusted":true},"cell_type":"code","source":"#viewing data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"eS3kDX710wSt","outputId":"6bc8fffa-b93a-46bd-ed70-96524d179e89","trusted":true},"cell_type":"code","source":"#checking descriptive stats\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"-qJMXO6Qi6TZ","outputId":"3d21e5fc-dee0-43ca-bb87-4c66d40a09d0","trusted":true},"cell_type":"code","source":"#data info\ndf.info()\n#No null values in the data","execution_count":null,"outputs":[]},{"metadata":{"id":"1dGcQI5V0ykI","outputId":"847a24e1-cff1-43cf-c49b-feaa794ad14a","trusted":true},"cell_type":"code","source":"#Removing non-relevant variables\ndf1=df.drop(columns=['day_of_week','month','contact','poutcome'],axis=1)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"id":"1PeHDptF00dF","outputId":"0d9ef056-5330-405f-b015-b0bcf426609d","trusted":true},"cell_type":"code","source":"#Replacing all the binary variables to 0 and 1\ndf1.y.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.default.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.housing.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.loan.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"id":"T5cvJJ6W02WX","outputId":"2e35a600-f9cf-4549-d8f4-7a72b7f27134","trusted":true},"cell_type":"code","source":"#creating Dummies for categorical variables\ndf2 = pd.get_dummies(df1)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"rX5Ag9qwi41Q","outputId":"4f130173-d80c-4c29-8535-20c3fc53ed6d","trusted":true},"cell_type":"code","source":"#Removing extra dummy variables & checking descriptive stats\ndf3=df2.drop(columns=['job_unknown','marital_divorced','education_unknown'],axis=1)\ndf3.describe().T","execution_count":null,"outputs":[]},{"metadata":{"id":"bdNWm8k504VI","outputId":"d657f56f-664a-4f0a-8617-84ce5f4cfcb2","trusted":true},"cell_type":"code","source":"#Correlation plot\nplt.figure(figsize=(14,8))\ndf3.corr()['y'].sort_values(ascending = False).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"id":"hLDgATXIjRR9","trusted":true},"cell_type":"code","source":"#Creating binary classification target variable\ndf_target=df3[['y']].values\ndf_features=df3.drop(columns=['y'],axis=1).values\ndf_target1=df3[['y']]\ndf_features1=df3.drop(columns=['y'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"guJzhm2vVyLS"},"cell_type":"markdown","source":"##Feature Selection","execution_count":null},{"metadata":{"id":"yvyVGDmjV1_T","outputId":"9f3d9906-c9ed-4ac8-b1e0-8d17edfbf3ea","trusted":true},"cell_type":"code","source":"##Feature Selection\nfrom mlxtend.feature_selection import SequentialFeatureSelector\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier  \nfeature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),  \n           k_features=12,\n           forward=True,\n           verbose=2,\n           scoring='roc_auc',\n           cv=2)\nfeatures = feature_selector.fit(df_features1,df_target1)\nfiltered_features= df_features1.columns[list(features.k_feature_idx_)] \nfiltered_features","execution_count":null,"outputs":[]},{"metadata":{"id":"jB3fJ5Pehk6x"},"cell_type":"markdown","source":"##PCA","execution_count":null},{"metadata":{"id":"FEeBunLphoMQ","outputId":"1fe53b52-f913-4cdc-965c-968806b8c39b","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\npca = PCA()\npca_X=pca.fit_transform(df_features)\npca.get_covariance()","execution_count":null,"outputs":[]},{"metadata":{"id":"7MlzrdKUid5b","outputId":"88696684-c235-49f9-eab1-efbb97e47d41","trusted":true},"cell_type":"code","source":"explained_variance=pca.explained_variance_ratio_\nexplained_variance.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"jC-xJA2Yiouh","outputId":"02c14ea2-4e11-4a9c-8e0d-0f77a4f5ba80","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nplt.bar(range(40), explained_variance, alpha=0.5, align='center',label='individual explained variance')\nplt.ylabel('Explained variance ratio')\nplt.xlabel('Principal components')\nplt.legend(loc='best')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"id":"VRiG-OZSqWxc","outputId":"261e421a-8de8-4c51-9743-3e9a793c46c4","trusted":true},"cell_type":"code","source":"pca = PCA(n_components=2)\npca_X=pca.fit_transform(df_features)\npca.get_covariance()","execution_count":null,"outputs":[]},{"metadata":{"id":"pj6IvRrLrFMe","outputId":"4087249d-01f2-4b3d-fb9e-cf0bad1539b4","trusted":true},"cell_type":"code","source":"explained_variance=pca.explained_variance_ratio_\nexplained_variance","execution_count":null,"outputs":[]},{"metadata":{"id":"9Bv5sYEC-Ho6","outputId":"8831e853-5e00-49c7-fe31-253eeb57d5fe","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.title('PCA Components')\nplt.scatter(pca_X[:,0], pca_X[:,1])","execution_count":null,"outputs":[]},{"metadata":{"id":"vfkp4TxbscoU"},"cell_type":"markdown","source":"##ICA","execution_count":null},{"metadata":{"id":"NbxNOShDsbrr","outputId":"1de97fed-8013-466f-b9a7-f5f20c1562ce","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import FastICA \nica = FastICA(n_components=3, random_state=2) \nica_X=ica.fit_transform(df_features)\nica_X.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"BgiIoQrC-LJO","outputId":"82aac747-99a0-479c-a8c1-03baa2d49e20","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nplt.title('ICA Components')\nplt.scatter(ica_X[:,0], ica_X[:,1])\nplt.scatter(ica_X[:,1], ica_X[:,2])\nplt.scatter(ica_X[:,2], ica_X[:,0])","execution_count":null,"outputs":[]},{"metadata":{"id":"qued0LK8Q3Fa"},"cell_type":"markdown","source":"##RCA","execution_count":null},{"metadata":{"id":"4hjuMoimQ6FM","outputId":"a7d8e3f4-ce36-41b2-9db0-47e8cf61d7b4","trusted":true},"cell_type":"code","source":"from sklearn.random_projection import GaussianRandomProjection\nrca = GaussianRandomProjection(n_components=3, eps=0.1, random_state=2)\nrca_X=rca.fit_transform(df_features)\nrca_X.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"diAGVRd7Uidu","outputId":"a03b593e-c764-4206-83b3-4009290800f9","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.title('RCA Components')\nplt.scatter(rca_X[:,0], rca_X[:,1])\nplt.scatter(rca_X[:,1], rca_X[:,2])\nplt.scatter(rca_X[:,2], rca_X[:,0])","execution_count":null,"outputs":[]},{"metadata":{"id":"xAKQSGpqwwAG"},"cell_type":"markdown","source":"#K-Means","execution_count":null},{"metadata":{"id":"WxzSjvMJwvWA","outputId":"9d81e39a-a348-455b-e94b-6728c1ad294d","trusted":true},"cell_type":"code","source":"# plot data\nplt.scatter(\n   df_features[:, 0], df_features[:, 1],\n   c='white', marker='o',\n   edgecolor='black', s=50\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"unn_wtJ3w08y","outputId":"c8628474-bc46-4d76-b5dc-c6ae43c446c5","trusted":true},"cell_type":"code","source":"##Determining number of clusters\nfrom sklearn.cluster import KMeans \nSum_of_squared_distances = []\nK = range(1,16)\nfor k in K:\n    km = KMeans(n_clusters=k, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\n    km=km.fit(df_features)\n    Sum_of_squared_distances.append(km.inertia_)\n##Checking out which SSE is low for different types of k means value\nplt.plot(K,Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow method for optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"AXntBAaew6Zj","outputId":"f46253c4-ca4a-4275-a54b-aef1a705a05e","trusted":true},"cell_type":"code","source":"# Fitting K-Means to the dataset\nfrom scipy import stats\n\nkmeans = KMeans(n_clusters = 2, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\nprediction = kmeans.fit_predict(df_features)\nprint(prediction)\n\nplt.scatter(df_features[:, 0], df_features[:, 1], c=prediction, s=50)\ncenters = kmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"id":"OmRGwiEy9PKs","outputId":"5ad3b396-64c5-45eb-c49c-b1f0e9afb9bf","trusted":true},"cell_type":"code","source":"centers = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"id":"0XWPeUfZAzJT"},"cell_type":"markdown","source":"##With Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features1","execution_count":null,"outputs":[]},{"metadata":{"id":"TH4wjuGvA8WN","outputId":"e11966af-f5cf-4fb4-c48e-cf87c11a81ed","trusted":true},"cell_type":"code","source":"df_fs=df_features1[['age', 'housing_0','housing_1','housing_unknown', 'loan_0','loan_1','loan_unknown', 'duration', 'campaign',\n       'job_admin.', 'job_self-employed', 'job_technician', 'marital_single',\n       'education_university.degree']].values\ndf_fs","execution_count":null,"outputs":[]},{"metadata":{"id":"aHR4S99qGnrp","outputId":"28d651d1-8eae-4ba5-8b09-8b351b08e7a4","trusted":true},"cell_type":"code","source":"##Determining number of clusters\nfrom sklearn.cluster import KMeans \nSum_of_squared_distances = []\nK = range(1,16)\nfor k in K:\n    km = KMeans(n_clusters=k, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\n    km=km.fit(df_fs)\n    Sum_of_squared_distances.append(km.inertia_)\n##Checking out which SSE is low for different types of k means value\nplt.plot(K,Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow method for optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"OrYjQ6ADHF1d","outputId":"36778d2c-a1eb-4f27-fdd5-3497258a659a","trusted":true},"cell_type":"code","source":"# Fitting K-Means to the dataset\nfrom scipy import stats\n\nkmeans = KMeans(n_clusters = 2, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\nprediction = kmeans.fit_predict(df_fs)\nprint(prediction)\n\nplt.scatter(df_fs[:, 0], df_fs[:, 1], c=prediction, s=50, cmap='viridis_r')","execution_count":null,"outputs":[]},{"metadata":{"id":"mS7erpXUHKiW","outputId":"c7f8fd99-fc8b-49a5-a408-36c6139904e3","trusted":true},"cell_type":"code","source":"centers = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"id":"1GhrxCjtriTc"},"cell_type":"markdown","source":"##With PCA","execution_count":null},{"metadata":{"id":"wPeO-fV5rh_d","outputId":"15cc0d17-70ca-4321-c1cf-491e00a3a106","trusted":true},"cell_type":"code","source":"##Determining number of clusters\nfrom sklearn.cluster import KMeans \nSum_of_squared_distances = []\nK = range(1,16)\nfor k in K:\n    km = KMeans(n_clusters=k, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\n    km=km.fit(pca_X)\n    Sum_of_squared_distances.append(km.inertia_)\n##Checking out which SSE is low for different types of k means value\nplt.plot(K,Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow method for optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"vjOAtJ6usTUm","outputId":"08e9e133-c71d-414c-fc77-aa3552441005","trusted":true},"cell_type":"code","source":"# Fitting K-Means to the dataset\nfrom scipy import stats\n\nkmeans = KMeans(n_clusters = 2, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\nprediction = kmeans.fit_predict(pca_X)\nprint(prediction)\n\nplt.scatter(pca_X[:, 0], pca_X[:, 1], c=prediction, s=50, cmap='viridis_r')\ncenters = kmeans.cluster_centers_\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"id":"eCL4Or4BN5JW"},"cell_type":"markdown","source":"##With ICA","execution_count":null},{"metadata":{"id":"z5CqO12qPWWZ","outputId":"f0603282-29ad-499d-81f3-938f90c85675","trusted":true},"cell_type":"code","source":"##Determining number of clusters\nfrom sklearn.cluster import KMeans \nSum_of_squared_distances = []\nK = range(1,16)\nfor k in K:\n    km = KMeans(n_clusters=k, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\n    km=km.fit(ica_X)\n    Sum_of_squared_distances.append(km.inertia_)\n##Checking out which SSE is low for different types of k means value\nplt.plot(K,Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow method for optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Hpq7po3UPeVy","outputId":"2b06a6dc-e95a-4abb-eddc-9aa45a1ab9ad","trusted":true},"cell_type":"code","source":"# Fitting K-Means to the dataset\nfrom scipy import stats\n\nkmeans = KMeans(n_clusters = 2, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\nprediction = kmeans.fit_predict(ica_X)\nprint(prediction)\n\nplt.scatter(ica_X[:, 0], ica_X[:, 1], c=prediction, s=50, cmap='viridis_r')\ncenters = kmeans.cluster_centers_\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"id":"N_YpUzP5U15i"},"cell_type":"markdown","source":"##With RCA","execution_count":null},{"metadata":{"id":"E15NXUvnU1aJ","outputId":"4757c80a-e07a-4ed1-905a-808f5e48827b","trusted":true},"cell_type":"code","source":"##Determining number of clusters\nfrom sklearn.cluster import KMeans \nSum_of_squared_distances = []\nK = range(1,16)\nfor k in K:\n    km = KMeans(n_clusters=k, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\n    km=km.fit(rca_X)\n    Sum_of_squared_distances.append(km.inertia_)\n##Checking out which SSE is low for different types of k means value\nplt.plot(K,Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow method for optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"n3vQx6QbVjl_","outputId":"5efb2775-e12e-48ab-fdd1-dd9b57da8a2f","trusted":true},"cell_type":"code","source":"# Fitting K-Means to the dataset\nfrom scipy import stats\n\nkmeans = KMeans(n_clusters = 2, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\nprediction = kmeans.fit_predict(rca_X)\nprint(prediction)\n\nplt.scatter(rca_X[:, 0], rca_X[:, 1], c=prediction, s=50, cmap='viridis_r')\ncenters = kmeans.cluster_centers_\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"id":"gcwsN5gNaOTZ"},"cell_type":"markdown","source":"#Expectation Maximization","execution_count":null},{"metadata":{"id":"8wG2T4BiaN3J","outputId":"3eed2bda-73bf-42e8-8f5f-53f22ec19e36","trusted":true},"cell_type":"code","source":"## Expectation maximization analysis\nfrom sklearn.mixture import GaussianMixture\nem = GaussianMixture(n_components=2,random_state=2,covariance_type='tied')\nem_pred = em.fit_predict(df_features)\nem_probs = em.predict_proba(df_features)\n#em.means_\n#em.covariances_\nplt.scatter(df_features[:, 0], df_features[:, 1], c=em_pred, s=50, cmap='viridis_r')","execution_count":null,"outputs":[]},{"metadata":{"id":"H5xfZO-cA6b7"},"cell_type":"markdown","source":"##With Feature Selection","execution_count":null},{"metadata":{"id":"68OBFJfjA7s2","outputId":"36ba31d1-e56a-4303-8af6-58686c4b3f57","trusted":true},"cell_type":"code","source":"## Expectation maximization analysis\nfrom sklearn.mixture import GaussianMixture\nem = GaussianMixture(n_components=2,random_state=2,covariance_type='tied')\nem_pred = em.fit_predict(df_fs)\nem_probs = em.predict_proba(df_fs)\n#em.means_\n#em.covariances_\nplt.scatter(df_fs[:, 0], df_fs[:, 1], c=em_pred, s=50, cmap='viridis_r')","execution_count":null,"outputs":[]},{"metadata":{"id":"oW7LEJprhVWE"},"cell_type":"markdown","source":"##With PCA","execution_count":null},{"metadata":{"id":"UzrdQ54DhVDp","outputId":"bf7a667c-ed53-4b10-9607-db3261fa8813","trusted":true},"cell_type":"code","source":"## Expectation maximization analysis\nfrom sklearn.mixture import GaussianMixture\nem = GaussianMixture(n_components=2,random_state=2,covariance_type='tied')\nem_pred = em.fit_predict(pca_X)\nem_probs = em.predict_proba(pca_X)\n#em.means_\n#em.covariances_\nplt.scatter(pca_X[:, 0], pca_X[:, 1], c=em_pred, s=50, cmap='viridis_r')","execution_count":null,"outputs":[]},{"metadata":{"id":"d1bRXS0YhsuN"},"cell_type":"markdown","source":"##With ICA","execution_count":null},{"metadata":{"id":"RN4ojSjghvDG","outputId":"68422d8d-d00c-43f6-f5a3-65fd9a487281","trusted":true},"cell_type":"code","source":"## Expectation maximization analysis\nfrom sklearn.mixture import GaussianMixture\nem = GaussianMixture(n_components=2,random_state=2,covariance_type='tied')\nem_pred = em.fit_predict(ica_X)\nem_probs = em.predict_proba(ica_X)\n#em.means_\n#em.covariances_\nplt.scatter(ica_X[:, 0], ica_X[:, 1], c=em_pred, s=50, cmap='viridis_r')","execution_count":null,"outputs":[]},{"metadata":{"id":"6f0zvr5vhviJ"},"cell_type":"markdown","source":"##With RCA","execution_count":null},{"metadata":{"id":"19Ty1iP_h5G8","outputId":"64d02201-19a1-42bb-8983-3f17ec9254b1","trusted":true},"cell_type":"code","source":"## Expectation maximization analysis\nfrom sklearn.mixture import GaussianMixture\nem = GaussianMixture(n_components=2,random_state=2,covariance_type='tied')\nem_pred = em.fit_predict(rca_X)\nem_probs = em.predict_proba(rca_X)\n#em.means_\n#em.covariances_\nplt.scatter(rca_X[:, 0], rca_X[:, 1], c=em_pred, s=50, cmap='viridis_r')","execution_count":null,"outputs":[]},{"metadata":{"id":"XnHDFv2VeHZC"},"cell_type":"markdown","source":"#ANN after PCA","execution_count":null},{"metadata":{"id":"pnb_4LdW9RF4","trusted":true},"cell_type":"code","source":"x1_train, x1_test, y1_train, y1_test = train_test_split(pca_X, df_target, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"jeZgHCtqeKOS","outputId":"2efa2261-cd67-489c-d2ee-1f31d5787711","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"softmax\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"softmax\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)","execution_count":null,"outputs":[]},{"metadata":{"id":"v0bZIPzVAD8v","trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix\ndef confusionmat(y,y_hat):\n  from sklearn.metrics import confusion_matrix,accuracy_score\n  cm = confusion_matrix(y, y_hat)\n  accu=accuracy_score(y,y_hat)\n  print(cm,\"\\n\")\n  print(\"The accuracy is\",accu)\n\n#Accuracy and Loss Curves\ndef learningcurve(history):\n  # list all data in history\n  print(history.history.keys())\n  # summarize history for accuracy\n  plt.plot(history.history['accuracy'])\n  plt.plot(history.history['val_accuracy'])\n  plt.title('model accuracy')\n  plt.ylabel('accuracy')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()\n  # summarize history for loss\n  plt.plot(history.history['loss'])\n  plt.plot(history.history['val_loss'])\n  plt.title('model loss')\n  plt.ylabel('loss')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"fpbI8-Ex9Vhd","outputId":"c7bd442f-778f-4f2e-facf-f00f78bd7e4a","trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"3HhzrLU_AjGn"},"cell_type":"markdown","source":"#Task 5","execution_count":null},{"metadata":{"id":"DgAvyb2v_Fi6","outputId":"83407a62-2acc-402b-858d-e394f86046e4","trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters = 2, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\nprediction = kmeans.fit_predict(x1_train)\n\nem = GaussianMixture(n_components=2,random_state=2,covariance_type='tied')\nem_pred = em.fit_predict(x1_train)\nem_probs = em.predict_proba(x1_train)\n\ntrain_df = pd.DataFrame()\ntrain_df['KM_Pred']=prediction\ntrain_df['EM_Prob']=em_probs[:,1]\ntrain_df['y']=y1_train\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{"id":"qtiC-AlkI_RS","outputId":"26de15a9-8579-4ec0-c324-e64c9f8affb3","trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters = 2, n_init=10, max_iter=300, init = 'k-means++', random_state = 2)\nprediction = kmeans.fit_predict(x1_test)\n\nem = GaussianMixture(n_components=2,random_state=2,covariance_type='tied')\nem_pred = em.fit_predict(x1_test)\nem_probs = em.predict_proba(x1_test)\n\ntest_df = pd.DataFrame()\ntest_df['KM_Pred']=prediction\ntest_df['EM_Prob']=em_probs[:,1]\ntest_df['y']=y1_test\ntest_df","execution_count":null,"outputs":[]},{"metadata":{"id":"ZXJsMNCTQdoj","trusted":true},"cell_type":"code","source":"#Creating binary classification target variable\ntrain_y=train_df[['y']].values\ntrain_x=train_df.drop(columns=['y'],axis=1).values\ntest_y=test_df[['y']]\ntest_x=test_df.drop(columns=['y'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"pUIP7trtJGYY","outputId":"d97c32a7-5d0d-4c7a-830a-602022af2193","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"softmax\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"softmax\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(train_x, train_y, batch_size = 10, epochs=100,validation_split=0.3)","execution_count":null,"outputs":[]},{"metadata":{"id":"J-4h_elCSFiA","outputId":"aefb3a6d-cca9-495e-9f20-916a798de715","trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict_classes(test_x)\npre_score = sk.average_precision_score(test_y, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(test_x, test_y)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(test_y,y_pred)\nlearningcurve(history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}