{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a href=\"https://www.facebook.com/codemakerz\"><img src=\"https://scontent.ffjr1-4.fna.fbcdn.net/v/t1.0-9/36189148_736466693143793_2172101683281133568_n.png?_nc_cat=107&_nc_eui2=AeHzxv3SUcQBOfijLP-cEnHkX4z9XQXdeau__2MlErWZ1x07aZ1zx1PzJUDDxL6cpr7oPqYiifggXDptgtP8W5iCoDRjcdILDBYZ5Ig40dqi8Q&_nc_oc=AQmMCNXdzelFB2rdtpk8wN8nC410Wm2yKupYfYS1FxHNejTF0Jhr1G3WIZORKRF3TvFpohMB8Puw29Txxan8CW05&_nc_ht=scontent.ffjr1-4.fna&oh=7b13627e991a4d1b508923041bd7bc22&oe=5D8A7B03\" />\n</a>\n\nYou can download:\n> Git Repo for dataset: https://github.com/martandsingh/datasets.git <br/>\n\nFollow Us:\nFacebook: https://www.facebook.com/codemakerz\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What is polynomial?\nA. If we talk about linear regression, It provide you a linear and straight relationship between two variables. \n![](https://github.com/martandsingh/images/blob/master/Scatter-Plot-of-SVD-Solution-to-the-Linear-Regression-Problem.png?raw=true)\n\n> So in above example we can see both variables are linearly related, AS one increases, other increases. This is the exmaple of linear regression.\n\nBut in case of polynomial regression, we do not have this kind of linear relationship. It can be any kind or curve or non -linear. We are going to see it now.\n\n## Equation\nLinear: Y = mx+c\nPolynomial: Y=c+ m1*x + m2*x^2 + m3*x^3 .... So on. "},{"metadata":{},"cell_type":"markdown","source":"## Load Data & Details"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/Position_Salaries.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization - Relation between Level Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Following plot the relationship between Level and Salary\nplt.figure(figsize=(15, 10))\nplt.scatter(x=df[\"Level\"], y=df[\"Salary\"])\nplt.xlabel(\"Level\");\nplt.ylabel(\"Salary\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, 1:2].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df.iloc[:, -1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Linear and Polynomial Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will create both the models, So that we can compare th prediction.\n# As we know we have very less number of observations so we will not split our data into train and test \n# Though if you have big data, you can do it using train_test_split class.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets import model class\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# linear regression model\nlr_normal = LinearRegression()\nlr_normal.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import Polynomial Features\nfrom sklearn.preprocessing import PolynomialFeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# polynomial regression model\n# degree 2 means it will add one more column to your dataset with X to the power 2. X^2.\n# You will observer, there is one more column on X_poly at the 0th position(1st column) which has value 1 for\n# all rows. It is added by PolynomialFeatures. It is the intercept value 'c' in Y=c+ m1*x + m2*x^2\nlr_poly = LinearRegression()\npoly_reg = PolynomialFeatures(degree = 2) \nX_poly = poly_reg.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_poly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_poly.fit(X_poly, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot Linear Vs Polynomial Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualising the Linear Regression results\nplt.figure(figsize=(15, 10))\nplt.scatter(X, y, color = 'red')\nplt.plot(X, lr_normal.predict(X), color = 'blue')\nplt.title('Truth or Bluff (Linear Regression)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()\n\n# Red is actual Salaries and blue line is predicted salaries.\n# So here we can see that best fitted line is also not a good regressor for the output. You can compare that\n# Mostly Salaries are very far from actual values. Now lets see what our polynomial model shows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Visualising the Polynomial Regression results\nplt.figure(figsize=(15, 10))\nplt.scatter(X, y, color = 'red')\nplt.plot(X, lr_poly.predict(poly_reg.fit_transform(X)), color = 'blue')\nplt.title('Position Level Vs Salary (Polynomial Regression-Degree 2)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So we can see our polynomial model of degree 2 is very simillar to actual result.\n# lets try for higher degree polynomial. Very simple to do, We just have to change the degree parameter\n# of PolynomialFeatures() constructor\n# polynomial regression model\nlr_poly = LinearRegression()\npoly_reg = PolynomialFeatures(degree = 3) # change form 2 to 3\nX_poly = poly_reg.fit_transform(X)\nlr_poly.fit(X_poly, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualising the Polynomial Regression results\nplt.figure(figsize=(15, 10))\nplt.scatter(X, y, color = 'red')\nplt.plot(X, lr_poly.predict(poly_reg.fit_transform(X)), color = 'blue')\nplt.title('Position Level Vs Salary (Polynomial Regression- Degree 3)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()\n\n# So now you can see as we increaed our degree parameter from 2 to 3, salary predictions are even better.\n# Lets just check for 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So we can see our polynomial model of degree 2 is very simillar to actual result.\n# lets try for higher degree polynomial. Very simple to do, We just have to change the degree parameter\n# of PolynomialFeatures() constructor\n# polynomial regression model\nlr_poly = LinearRegression()\npoly_reg = PolynomialFeatures(degree = 4) # change form  3 to 4\nX_poly = poly_reg.fit_transform(X)\nlr_poly.fit(X_poly, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualising the Polynomial Regression results\nplt.figure(figsize=(15, 10))\nplt.scatter(X, y, color = 'red')\nplt.plot(X, lr_poly.predict(poly_reg.fit_transform(X)), color = 'blue')\nplt.title('Position Level Vs Salary  (Polynomial Regression-Degree 4)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.show()\n# Wow!! so now our model is even more accurate than polynomial curve with degree 3.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## So here we can see as we increased the degree of polynomial, our curve acuracy increased. So you should\n# try different degree to find out best fitted curve.\n# Now lets predict some values\nlr_normal.predict([[8.5]]) # As per our linear regresion model salary.of 8.5 level should be 492136.\n# but according to curve it should be somewhere lesser than 400000.\n# lets see what our polynomial model says","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_poly.predict(poly_reg.fit_transform([[8.5]]))  # According to this it should be 387705\n# if you will see the figure you will find this prediction is almost same as what we are expecting.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Thank You","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}