{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IN THIS NOTEBOOK :\n* Exploratory Data Analysis \n* Feature Visualizaion and Engineering\n* Feature Selection\n* Modeling \n* Model Evaluation\n* Hyper Parameter Tuning"},{"metadata":{},"cell_type":"markdown","source":"****Task Details****\n\n\n\nYour client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called ‘sum assured’) to the customer.\n\nBuilding a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n\nNow, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.\n\n***Evaluation Metric***\nThe evaluation metric for this hackathon is ROC_AUC score."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nsns.set_style(style=\"darkgrid\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data loading"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train=pd.read_csv('../input/health-insurance-cross-sell-prediction/train.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data dimensions,information,null values check."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data info\ndata_dims=df_train.shape\ndata_info=df_train.info()\nprint(data_dims,data_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Null Check\n\nnull_data=df_train.isnull().sum()\nnull_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separate Numerical and Categorical features\n\nnum_feats=df_train.select_dtypes(['int64','float64']).columns\ncat_feats=df_train.select_dtypes(['object']).columns\n\nfeats=[num_feats,cat_feats]\nfeats\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target Features Balancing and Imbalancing."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check Imbalancing of data \nsns.countplot(df_train['Response'],palette=\"twilight\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering**"},{"metadata":{},"cell_type":"markdown","source":"*Handling Categorical Features in the data using Dummies or ONEHOTENCODER\nand dropping 1st encoded column*"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Exploration - > Categorical Types \n\n#1.Gender\nsns.countplot(df_train['Gender'],palette='Set3')\n\n\n#One Hot Encoding on Gender\ndf_train['Gender']=pd.get_dummies(df_train['Gender'],drop_first=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2.Vehicle_Damage\n\n\nsns.countplot(df_train['Vehicle_Damage'],palette='brg')\n\n\n#One Hot Encoding on Vehicle_Damage\ndf_train['Vehicle_Damage']=pd.get_dummies(df_train['Vehicle_Damage'],drop_first=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Vehicle Age feature is divided into 3 categories :\n\n\n*  0-1 ->0\n*  1-2 ->1  \n*  above 2 ->2\n\n(LABEL ENCODING)*"},{"metadata":{"trusted":true},"cell_type":"code","source":"#3.Vehicle_Age\n\n\nva_counts=df_train['Vehicle_Age'].value_counts()\n\n#3.1 String Handling\n#3.2 Convert this feature into 3 distinct categories  0-1,1-2,>2 -> 0,1,2 (Label Encoding)\n\n\n\n\ndef string_extract(x):\n    X=x.split()\n    \n    if(len(X)==2):\n        return 1\n    if(X[0]=='<'):\n        return 0\n    if(X[0]=='>'):\n        return 2\n    \n\ndf_train['Vehicle_Age_n']=df_train['Vehicle_Age'].apply(lambda x:string_extract(x))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizations using\n* Countplots\n* Dist Plot \n* Scatter Plot\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['Vehicle_Age'],palette='brg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['Vehicle_Damage'],palette='twilight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['Previously_Insured'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['Previously_Insured'],hue=df_train['Vehicle_Damage'],palette='twilight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['Previously_Insured'],hue=df_train['Vehicle_Age'],palette='twilight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_train['Vehicle_Damage'],hue=df_train['Vehicle_Age'],palette='Set3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Exploration - > Numerical Types \n\n#1.Age \nsns.distplot(df_train['Age'],color='r')\nage_desc=df_train['Age'].describe()\nage_desc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2.Annual_Premium\nsns.distplot(df_train['Annual_Premium'])\nprem_desc=df_train['Annual_Premium'].describe()\nprem_desc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_train['Vintage'],df_train['Annual_Premium'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(['id','Vehicle_Age'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Selection**"},{"metadata":{},"cell_type":"markdown","source":"*1. Correlation Matrix* "},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_features=pd.DataFrame(df_train.corr()['Response'].sort_values(ascending=False))\nimp_features.columns=['IMP']\nindx=imp_features.index\n\n\n\nplt.figure(figsize=(25,10))\nb=sns.barplot(x=indx,y=imp_features['IMP'])\nb.set_xlabel(\"Features\",fontsize=20)\nb.set_ylabel(\"Co-Relation\" ,fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*2.Feature Selection - SelectKBest ,chi2*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest,f_classif\n\nX=df_train.drop('Response',axis=1)\nY=df_train['Response']\n\n\n\nselector_model=SelectKBest(score_func=f_classif,k='all')\nselector=selector_model.fit(X,Y)\n\ncols=X.columns\ndf_features = pd.DataFrame(cols)\ndf_scores = pd.DataFrame(selector.scores_)\n\ndf_new = pd.concat([df_features, df_scores], axis=1)\ndf_new.columns = ['Features', 'Score']\n\ndf_new = df_new.sort_values(by='Score', ascending=False)\ndf_new\nimp_feature=df_new['Features']\n\n\nindx=df_new['Features']\nplt.figure(figsize=(25,10))\nb=sns.barplot(x=indx,y=df_new['Score'])\nb.set_xlabel(\"Features\",fontsize=20)\nb.set_ylabel(\"Co-Relation\" ,fontsize=20)\n\n\nimp_feature\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_f=imp_feature[:6]\ndf_train[imp_f].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Modeling and Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*TEST-TRAIN SPLITS*"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df_train[imp_f]\nY=df_train['Response']\n\nx_train,x_test,y_train,y_test = train_test_split(X,Y, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1.Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg=LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred = logreg.predict_proba(x_test)[:,1]\nroc_auc_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.XGBoost without Hyperparamter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb1=xgboost.XGBClassifier()\nxgb1.fit(x_train,y_train)\ny_pred = xgb1.predict_proba(x_test)[:,1]\nroc_auc_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> *Hyperparameter Boosting -> XGBOOST*"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"''''\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n\nparamss= {\n        \"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n        \"max_depth\": [3, 4, 5, 6, 8, 10, 12, 15],\n        \"min_child_weight\": [1, 3, 5, 7],\n        \"gamma\": [0.0, 0.1, 0.2, 0.3, 0.4],\n        \"colsample_bytree\": [0.3, 0.4, 0.5, 0.7]\n\n    }\n\n\ngbc=xgboost.XGBClassifier()\nmodel2=RandomizedSearchCV(estimator=gbc,param_distributions=paramss,\n                cv=5,scoring=\"roc_auc\",\n                verbose=10,n_jobs=-1)\n\nmodel2.fit(X,Y)\n\nprint(model2.best_params_)\nprint(model2.best_index_)\n\n''''\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb1=xgboost.XGBClassifier(min_child_weight= 5, max_depth= 4, learning_rate = 0.25, \n                           gamma= 0.2, colsample_bytree= 0.7)\nxgb1.fit(x_train,y_train)\ny_pred = xgb1.predict_proba(x_test)[:,1]\nroc_auc_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**End of Notebook**\n* Please Upvote if you like it!!\n* Comment down about the NoteBook.\nThankyou!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}