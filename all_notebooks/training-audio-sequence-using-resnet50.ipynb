{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!ls '../input'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import metrics\n\nfrom sklearn.utils import class_weight\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\n\nfrom os import listdir\nfrom os.path import isfile, join\n\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_loc = '../input/specimages/train_test_split/train/'\ntest_loc = '../input/specimages/train_test_split/val/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata = ImageDataGenerator()\ntraindata = trdata.flow_from_directory(directory=train_loc, target_size=(180,180))\ntsdata = ImageDataGenerator()\ntestdata = tsdata.flow_from_directory(directory=test_loc, target_size=(180,180))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diagnosis_csv = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv'\ndiagnosis = pd.read_csv(diagnosis_csv, names=['pId', 'diagnosis'])\ndiagnosis.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = diagnosis['diagnosis'].unique()\ncategories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rn = ResNet50(weights='imagenet')\nrn.summary()\n\nx  = rn.output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = Dense(8, activation='softmax', name='predictions')(x)\nmodel = Model(inputs=rn.input, outputs=prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False\n\nfor layer in model.layers[-25:]:\n    layer.trainable = True\n    print(\"Layer '%s' is trainable\" % layer.name)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(lr=0.0000001)\nmodel.compile(optimizer=opt, loss=categorical_crossentropy, \n              metrics=['accuracy', 'mae'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"rn_base_res.h5\", monitor='val_accuracy', verbose=2, \n                             save_best_only=True, save_weights_only=False, mode='auto')\nearly = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=2, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = Counter(traindata.classes)                       \nmax_val = float(max(counter.values()))   \nclass_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(traindata, steps_per_epoch=traindata.samples//traindata.batch_size, validation_data=testdata, \n                 class_weight=class_weights, validation_steps=testdata.samples//testdata.batch_size, \n                 epochs=35,callbacks=[checkpoint,early])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='val')\nplt.title('ResNet50: Loss and Validation Loss (0.000001 = Adam LR)')\nplt.legend();\nplt.show()\n\nplt.plot(hist.history['accuracy'], label='train')\nplt.plot(hist.history['val_accuracy'], label='val')\nplt.title('ResNet50: Accuracy and Validation Accuracy (0.000001 = Adam LR)')\nplt.legend();\nplt.show()\n\nplt.plot(hist.history['mae'], label='train')\nplt.plot(hist.history['val_mae'], label='val')\nplt.title('ResNet50: MAE and Validation MAE (0.000001 = Adam LR)')\nplt.legend();\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}