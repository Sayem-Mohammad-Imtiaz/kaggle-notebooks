{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nimport glob\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nfrom torch.autograd.variable import Variable\nfrom torchvision import datasets, transforms\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(sys.version)\ndevice='cuda'\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" folder_data = glob.glob(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/*.jpg\")\n len_data = len(folder_data)\n print(len_data)\n\n train_image_paths = folder_data[0:200000]\n\n class TrainDataset(Dataset):\n   def __init__(self, image_paths, train=True):\n     self.image_paths = image_paths\n     self.transforms = transforms.Compose([\n                               transforms.Resize(64),\n                               transforms.CenterCrop(64),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ])\n     \n   def __getitem__(self, index):\n     image = Image.open(self.image_paths[index])\n     t_image = self.transforms(image)\n     return t_image\n\n   def __len__(self):\n     return len(self.image_paths)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TrainDataset(train_image_paths,train = True)\nprint(len(train_dataset))\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GeneratorNet(torch.nn.Module):\n  def __init__(self):\n    super(GeneratorNet, self).__init__()\n    self.main = nn.Sequential(\n        nn.ConvTranspose2d(100, 1024, kernel_size = 4, stride = 1, padding = 0, bias = False),\n        nn.BatchNorm2d(1024),\n        nn.ReLU(inplace = True),\n\n        nn.ConvTranspose2d(1024, 512, kernel_size = 4, stride = 2, padding = 1, bias =False),\n        nn.BatchNorm2d(512),\n        nn.ReLU(inplace = True),\n\n        nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias=False),\n        nn.BatchNorm2d(256),\n        nn.ReLU(inplace = True),\n\n        nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1, bias=False),\n        nn.BatchNorm2d(128),\n        nn.ReLU(inplace = True),\n\n        nn.ConvTranspose2d(128, 3, kernel_size = 4, stride = 2, padding = 1, bias=False),\n        nn.Tanh()\n    )\n    \n\n  def forward(self, x):\n    #print(x)\n    x = self.main(x)\n    #print(x.shape)\n    return x\n\ngenerator = GeneratorNet()\ngenerator.float()\ngenerator = generator.to(device)\n\ngenerator.apply(weights_init)\n\nprint(generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DiscriminatorNet(torch.nn.Module):\n  def __init__(self):\n    super(DiscriminatorNet, self).__init__()\n    self.main = nn.Sequential(\n      nn.Conv2d(3, 128, kernel_size = 5, stride = 2, padding = 2, bias = False),\n      nn.LeakyReLU(0.2, inplace=True),\n\n      nn.Conv2d(128, 256, kernel_size = 5, stride = 2, padding = 2, bias = False),\n      nn.BatchNorm2d(256),\n      nn.LeakyReLU(0.2, inplace=True),\n\n      nn.Conv2d(256, 512, kernel_size = 5, stride = 2, padding =2, bias = False),\n      nn.BatchNorm2d(512),\n      nn.LeakyReLU(0.2, inplace=True),\n\n      nn.Conv2d(512, 1024, kernel_size = 5, stride = 2, padding = 2, bias = False),\n      nn.BatchNorm2d(1024),\n      nn.LeakyReLU(0.2, inplace=True),\n\n      nn.Conv2d(1024, 1, kernel_size = 4, stride = 1, padding = 0, bias = False)\n    )\n    \n  def forward(self, x):\n    x = self.main(x)\n    return x\n\ndiscriminator = DiscriminatorNet()\ndiscriminator.float()\ndiscriminator = discriminator.to(device)\n\ndiscriminator.apply(weights_init)\n\nprint(discriminator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizerG = optim.Adam(generator.parameters(), lr = 0.0002, betas = (0.5, 0.999))\noptimizerD = optim.Adam(discriminator.parameters(), lr = 0.0002, betas = (0.5, 0.999))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def noise(size):\n  n = Variable(torch.randn(size, 100, 1, 1))\n  n = n.to(device)\n  return n\n\nsamples = 16\nfixed_noise = noise(samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lossesD = []\nlossesG = []\n\nnum_epochs = 30\nfor epoch in range(num_epochs):\n  discriminator.train()\n  generator.train()\n  lossD = 0\n  lossG = 0\n  prob_real = 0\n  prob_fake = 0 \n  for num_iter, (real_batch) in enumerate(train_loader):\n\n    x_real = Variable(real_batch).to(device)\n    optimizerD.zero_grad()\n    pred_real = discriminator(x_real)\n    loss_real = criterion(pred_real.view(-1,1), torch.ones((x_real.size(0),1),device='cuda'))\n    loss_real.backward()\n    z = noise(x_real.size(0))\n    x_fake = generator(z)\n    x_fake.detach()\n    pred_fake = discriminator(x_fake)\n    loss_fake = criterion(pred_fake.view(-1,1), torch.zeros((x_real.size(0),1),device='cuda'))\n    loss_fake.backward()\n    optimizerD.step()\n    lossD = lossD + loss_real + loss_fake\n\n    fake_x = generator(z)\n    optimizerG.zero_grad()\n    fake_pred = discriminator(fake_x)\n    loss_gen = criterion(fake_pred.view(-1,1), torch.ones((x_real.size(0),1),device='cuda'))\n    loss_gen.backward()\n    optimizerG.step()\n    lossG = lossG + loss_gen\n\n  lossesD.append(lossD/len(train_loader))\n  lossesG.append(lossG/len(train_loader))\n  print(\"Epoch No. = \"+ str(epoch+1))\n  print(\"Discriminator Loss = \"+ str(lossesD[epoch].item()), \"Generator Loss = \"+ str(lossesG[epoch].item()))\n  if (epoch+1)%5==0 or (epoch+1)>25:\n    torch.save(generator.state_dict(),'g_epoch-{}.pth'.format(epoch+1))\n    torch.save(discriminator.state_dict(), 'd_epoch-{}.pth'.format(epoch+1))\n\n  with torch.no_grad():\n    generated_images = generator(fixed_noise.detach())\n    for i in range(16):\n      plt.subplot(4, 4, 1 + i)\n      plt.axis('off')\n      plt.imshow(np.transpose(generated_images.cpu().numpy()[i],(1,2,0)))\n    plt.show()  \n\nplt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(lossesG,label=\"G\")\nplt.plot(lossesD,label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_noise = noise(4)\nwith torch.no_grad():\n  test_images = generator(test_noise.detach())\n  for i in range(4):\n\t  plt.subplot(2, 2, 1 + i)\n\t  plt.axis('off')\n\t  plt.imshow(np.transpose(test_images.cpu().numpy()[i],(1,2,0)))\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_noise = noise(4)\nwith torch.no_grad():\n  test_images = generator(test_noise.detach())\n  for i in range(4):\n\t  plt.subplot(2, 2, 1 + i)\n\t  plt.axis('off')\n\t  plt.imshow(np.transpose(test_images.cpu().numpy()[i],(1,2,0)))\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_noise = noise(4)\nwith torch.no_grad():\n  test_images = generator(test_noise.detach())\n  for i in range(4):\n\t  plt.subplot(2, 2, 1 + i)\n\t  plt.axis('off')\n\t  plt.imshow(np.transpose(test_images.cpu().numpy()[i],(1,2,0)))\n  plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}