{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nprint(os.listdir(\"../input\"))\ndataset = pd.read_csv(\"../input/covtype.csv\")\ndataset.head(10)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"labels = dataset[\"Cover_Type\"]\ndel dataset[\"Cover_Type\"]\n\n\n\n\nX = dataset.values# la matrice de donnees\n\n\n#instanciation\nsc = StandardScaler()\n#transformation–centrage-réduction\nZ = sc.fit_transform(X)\nprint(Z)\n\n#moyenne\nprint(np.mean(Z,axis=0))\n\n#écart-type\nprint(np.std(Z,axis=0,ddof=0))\n\n#instanciation\nacp = PCA(svd_solver='full')\n\n#calculs\ncoord = acp.fit_transform(Z)# les coordonnees factorielles\n#nombre de composantes calculées\nprint(acp.n_components_) \n#variance expliquée\nprint(acp.explained_variance_)\n\neigval = acp.explained_variance_\n\n#proportion de variance expliquée,l'info expliquee par les axes\nprint(acp.explained_variance_ratio_)\n#valeur corrigée\n#j = X.shape[0]\n#eigval = (j-1)/j*acp.explained_variance_\n#print(eigval)\n\n#critere du coude\nmu = X.shape[1]# ( j'ai remplacé p par mu)\nplt.plot(np.arange(1,mu+1),eigval)\nplt.title(\"critère du coude\")\nplt.ylabel(\"valeurs propres\")\nplt.xlabel(\"nombre de facteurs\")\nplt.show()\n\n\n#cumul de variance expliquée\nplt.plot(np.arange(1,mu+1),np.cumsum(acp.explained_variance_ratio_))\nplt.title(\"variance expliquée\")\nplt.ylabel(\"ratio variance cumulée\")\nplt.xlabel(\"nombre de facteurs\")\nplt.show()\n\n##################################################################################\n\npca = PCA(n_components=20)\nprint(pca.fit(X))\npca.explained_variance_ratio_\n\nplt.bar(np.arange(len(pca.explained_variance_ratio_)), pca.explained_variance_ratio_)\nplt.title(\"Variance expliquée\")\n\n\npca.components_\n\nsum(pca.explained_variance_ratio_)\n\n\n\nX_pca = pca.fit_transform(X)\n\nn=581012  # nombre de composantes\nk=20   # nombre de features\nn_a=10  # nombre d'actions\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee01945a78d852399a2306e03c36ecbd36b86f51"},"cell_type":"code","source":"D=X_pca # data\n\ntheta=np.random.random( (n_a,k) ) + 0.00001 # le theta à prédire\n\n\n\n\nchoix=np.zeros(n)\nrecomp=np.zeros(n)\nexplore=np.zeros(n)\nnorms  =np.zeros(n)\nb      =np.zeros_like(theta)\nA      =np.zeros( (n_a, k,k)  )\nfor a in range (0,n_a):\n    A[a]=np.identity(k)\n\nA_inv = [np.identity(k) for i in range (0,n_a)]\n\ntheta_hat =np.zeros_like(theta) # features temporaires, meilleures suppositions actuelles\np      =np.zeros(n_a)\nalpha   =5\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e8a3b2716c1392d9cb5b51d0c41086b840a2bca"},"cell_type":"code","source":"# LinUCB\n\nfor i in range(0,n):\n \n    x_i = D[i]   # vect du contexte\n    \n    for a in range (0,n_a):        \n        theta_hat[a]  = A_inv[a].dot(b[a])      \n        ta         = x_i.T.dot(A_inv[a]).dot(x_i) \n        a_upper_ci = alpha * np.sqrt(ta)     # partie supérieure de l'intervalle \n        a_mean     = theta_hat[a].dot(x_i)   # estimation actuelle de la mean\n        p[a]       = a_mean + a_upper_ci     # borne sup IC\n      \n      \n    norms[i]       = np.linalg.norm(theta_hat - theta,'fro') # convergence\n    \n    choix[i] = p.argmax()   #fonction de maxmisation\n    \n    # le resultat obtenu\n    \n    recomp[i] =((choix[i])==labels[i]) #la récompense\n   \n    # mettre à jour le vecteur d'input\n    A[int(choix[i])]      += np.outer(x_i,x_i)\n    A_inv[int(choix[i])]  = np.linalg.inv(A[int(choix[i])])\n    b[int(choix[i])]      += recomp[i] * x_i\n    \n\n\n\nregret=(np.ones(n) - recomp)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7cc8c261c5eade2097cd73535c3e4572de764f6"},"cell_type":"code","source":"plt.subplot(221)\nplt.plot(recomp.cumsum())\nplt.title(\"Recompense Cumulée \")\nplt.subplot(222)\nplt.plot(regret.cumsum(), color = \"red\")\nplt.title(\"Regret Cumulée \")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}