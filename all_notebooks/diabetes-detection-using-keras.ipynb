{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"../input/pima-indians-diabetes-database/diabetes.csv\"\ndf=pd.read_csv(url)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#no missing data\ndf.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#duplicate data should be removed to avoid overfitting\nprint(f\"Number of duplicates in the training data are {df.duplicated().sum()} of {len(df)}, ie {(100* df.duplicated().sum()/len(df)).round(2)} % of data duplicated\")\ndf.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the dataset is not unbalanced\npositive=df[df['Outcome']==1]\nnegative=df[df['Outcome']==0]\nprint(positive.shape)\nprint(negative.shape)\n#plotting the Outcome\nsns.distplot(df['Outcome'], bins=10);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bloodpressure, bmi, glucose, insulin, skinthickness\ndf.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = df.copy(deep = True)\ndf_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\ndf_copy['Glucose'].fillna(df_copy['Glucose'].mean(), inplace = True)\ndf_copy['BloodPressure'].fillna(df_copy['BloodPressure'].mean(), inplace = True)\ndf_copy['SkinThickness'].fillna(df_copy['SkinThickness'].median(), inplace = True)\ndf_copy['Insulin'].fillna(df_copy['Insulin'].median(), inplace = True)\ndf_copy['BMI'].fillna(df_copy['BMI'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the data looks better defined now\ndf_copy.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num_corr = df_copy.corr()['Outcome'][:-1]\ndf_num_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, len(df_copy.columns), 5):\n    sns.pairplot(data=df_copy,\n                x_vars=df_copy.columns[i:i+5],\n                y_vars=['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df_copy.iloc[:,:-1]\ny=df_copy['Outcome']\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX= sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = df.Outcome, random_state=0)\n\nmodels = []\nmodels.append(('KNN', KNeighborsClassifier(n_neighbors = 5)))\nmodels.append(('SVM', SVC(gamma='auto')))\nmodels.append(('GNB', GaussianNB()))\nmodels.append(('LR', LogisticRegression(solver='liblinear',random_state=0)))\nmodels.append(('decisiontree', tree.DecisionTreeClassifier()))\nmodels.append(('randomforest', RandomForestClassifier(max_depth=2, random_state=10, n_estimators=10)))\nmodels.append(('GB', GradientBoostingClassifier()))\n\nscores = []\nnames = []\n        \nfor name, model in models:\n    \n    score = cross_val_score(model, X, y, scoring='accuracy', cv=5).mean()\n    \n    names.append(name)\n    scores.append(score)\nkf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})\nprint(kf_cross_val)\n\naxis = sns.barplot(x = 'Name', y = 'Score', data = kf_cross_val)\naxis.set(xlabel='Classifier', ylabel='Accuracy')\nfor p in axis.patches:\n    height = p.get_height()\n    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha=\"center\") \n    \nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.01)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\nmodel = create_model()\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KerasClassifier(build_fn = create_model, verbose = 1)\nmodel.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.01)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, verbose = 1)\n\n# define the grid search parameters\nbatch_size = [10,15, 20]\nepochs = [10, 50, 100]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X, y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dropout\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model(learn_rate, dropout_rate):\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = learn_rate)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 10, verbose = 0)\n\n# define the grid search parameters\nlearn_rate = [0.001, 0.01, 0.1]\ndropout_rate = [0.0, 0.1, 0.2]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(learn_rate=learn_rate, dropout_rate=dropout_rate)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X, y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model(activation, init):\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer= init, activation= activation))\n    model.add(Dense(4, input_dim = 8, kernel_initializer= init, activation= activation))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 10, verbose = 0)\n\n# define the grid search parameters\nactivation = ['softmax', 'relu', 'tanh', 'linear']\ninit = ['uniform', 'normal', 'zero']\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(activation = activation, init = init)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X, y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nseed = 6\nnp.random.seed(seed)\nfrom keras.layers import Dropout\n# Start defining the model\ndef create_model(neuron1, neuron2):\n    # create model\n    model = Sequential()\n    model.add(Dense(neuron1, input_dim = 8, kernel_initializer= 'normal', activation= 'relu'))\n    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer= 'normal', activation= 'linear'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 10, verbose = 0)\n\n# define the grid search parameters\nneuron1 = [4, 8, 16]\nneuron2 = [2, 4, 8]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), refit = True, verbose = 10)\ngrid_results = grid.fit(X, y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = grid.predict(X)\nfrom sklearn.metrics import classification_report, accuracy_score\n\nprint(accuracy_score(y, y_pred))\nprint(classification_report(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}