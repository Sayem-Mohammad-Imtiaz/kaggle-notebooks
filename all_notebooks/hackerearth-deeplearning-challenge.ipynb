{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!/opt/conda/bin/python3.7 -m pip install --upgrade pip\n! pip install -q efficientnet\n!pip install -q -U tensorflow-addons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%rm -rf ./train_images\nshutil.copytree(\"../input/hackerearth-deep-learning-challenge-holidayseason/dataset/train\",\"./images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/hackerearth-deep-learning-challenge-holidayseason/dataset/train.csv\")\nclasses = list(train_df[\"Class\"].unique())\nclasses_dict = {}\nfor i,label in enumerate(classes):\n    classes_dict[label] = i\n    \ntrain_df.index = train_df[\"Image\"]\ntrain_df=train_df.drop([\"Image\"],axis=1)\ntrain_df.head()\n\nprint(classes_dict)\nprint(train_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"./images\"\ntrain_ls = os.listdir(train_path)\n\nif os.path.exists(\"./train\") != True:\n    os.mkdir(\"./train\")\n    for i in range(6):\n        os.mkdir(\"./train/\"+str(i))\n        \nfor name in train_ls:\n    path = os.path.join(train_path,name)\n    label = classes_dict[train_df.loc[name][\"Class\"]]\n    final_path = \"./train/\"+str(label)\n    shutil.move(path,final_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HEIGHT= 300\nWIDTH = 300\nBATCH_SIZE = 32\nNUM_IMAGES = len(train_ls)\nSPLIT = 0.85\nCLASSES = 6\n\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=True,\n        validation_split = 1-SPLIT,\n        rotation_range=25,\n        fill_mode=\"nearest\",\n        height_shift_range = 0.15,\n        width_shift_range = 0.15,\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    \"./train\",\n    target_size = (HEIGHT,WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode = \"categorical\",\n    shuffle = True,\n    subset = \"training\"\n)\n\n\nvalidation_generator = train_datagen.flow_from_directory(\n    \"./train\",\n    target_size = (HEIGHT,WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode = \"categorical\",\n    shuffle = True,\n    subset = \"validation\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    efficient_net = {\n        0 : efn.EfficientNetB0(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        1 : efn.EfficientNetB1(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        2 : efn.EfficientNetB2(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        3 : efn.EfficientNetB3(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        4 : efn.EfficientNetB4(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        5 : efn.EfficientNetB5(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        6 : efn.EfficientNetB6(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        7 : efn.EfficientNetB7(weights=\"noisy-student\",include_top=False ,input_shape=[HEIGHT,WIDTH, 3]),\n        8 : tf.keras.applications.Xception(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3]),\n        9 : tf.keras.applications.ResNet50(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3]),\n        10: tf.keras.applications.ResNet101(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3]),\n        11: tf.keras.applications.ResNet152(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3])\n    }\n\n    output = {}\n    inputs = tf.keras.Input(shape=(HEIGHT,WIDTH, 3))\n    \n    ls =   [5]   \n    \n    \n    for i in ls:\n        pretrained_model = efficient_net[i]\n        pretrained_model.trainable = False\n        x = pretrained_model(inputs)\n        x = tf.keras.layers.GlobalAveragePooling2D(name = \"average_\"+str(i))(x)\n        x = tf.keras.layers.Dense(512,activation=\"relu\")(x)\n        x = tf.keras.layers.Dropout(0.3)(x)\n        x = tf.keras.layers.Dense(256,activation=\"relu\")(x)\n        output[i] = tf.keras.layers.Dense(CLASSES,activation=\"softmax\", dtype='float32',name=\"dense_\"+str(i))(x)\n    \n    if len(ls)>1:\n        outputs = tf.keras.layers.average(list(output.values()))\n    else:\n        outputs = list(output.values())[0]\n        \n    model = tf.keras.Model(inputs, outputs)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_addons as tfa\n\ndef compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n        \n    metrics = [\n       tfa.metrics.F1Score(num_classes=CLASSES, average = \"weighted\",name=\"f1_score\")\n    ]\n   \n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_callbacks():\n    \n    cpk_path = './best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_f1_score',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_f1_score',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_f1_score',\n        mode='max',\n        patience=15, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 50\n\nwith tf.device('/device:GPU:0'):\n    model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(train_generator,\n                    epochs= EPOCHS,\n                    verbose=1,\n                    validation_data = validation_generator,\n                    callbacks= callbacks\n                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['f1_score']\nval_acc = history.history['val_f1_score']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(history.history['val_loss']))\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training F1 Score')\nplt.plot(epochs_range, val_acc, label='Validation F1 Score')\nplt.legend(loc='lower right')\nplt.title('Training and Validation F1 Score')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.load_model(\"./best_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"../input/hackerearth-deep-learning-challenge-holidayseason/dataset/test/\"\ntest_ls = os.listdir(test_path)\npredictions=[]\n\nlabel_dict = {\n    0:'Miscellaneous', 1:'Candle', 2:'Snowman', 3:'Airplane', 4:'Christmas_Tree', 5:'Jacket'\n}\n\nfor filename in test_ls:\n    img = tf.keras.preprocessing.image.load_img(\n      test_path+filename,target_size = (HEIGHT,WIDTH)\n    )\n    arr = tf.keras.preprocessing.image.img_to_array(img)\n    arr = tf.expand_dims(arr/255.,0)\n    predictions.append(label_dict[np.argmax(model.predict(arr)[0])])\n\ndf = pd.DataFrame(zip(test_ls,predictions),columns = [\"Image\",\"Class\"])\ndf.to_csv(\"./submission.csv\",index=False)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%rm -rf ./images\n%rm -rf ./train","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}