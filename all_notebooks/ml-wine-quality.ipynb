{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Import libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"import os\nimport time\nimport warnings\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import classification_report\n\nimport lightgbm as lgb\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Seeding random","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"np.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Declaring DataExplorer class","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class DataExplorer:\n    \"\"\"\n    Reading dataset\n    \"\"\"\n    def __init__(self, filedir, filename):\n        self.data = pd.read_csv(os.path.join(filedir, filename))\n        \n    def grouper_quality(self, row):\n        \"\"\"\n        Enlarging groups of target features\n        \"\"\"\n        quality = row['quality']\n\n        if quality < 5:\n            return 3\n\n        elif quality > 6:\n            return 1\n\n        else:\n            return 2\n        \n    def generalization(self):\n        \"\"\"\n        Greate enlarged groups of target features: third, second and first class wines\n        \"\"\"\n        data = self.data.copy()\n        data['gen_quality'] = self.data.apply(self.grouper_quality, axis=1)\n\n        return data.drop('quality', axis=1)\n    \n    def binomizator(self):\n        \"\"\"\n        Binominaizing target features\n        \"\"\"\n        data = self.data.copy()\n        data['bi_quality'] = self.data.quality.apply(lambda x: 1 if x >= 6 else 0)\n\n        return data.drop('quality', axis=1)\n\n    class Reporter():\n        \"\"\"\n        Collecting perfomance data and bulids report\n        \"\"\"\n        def __init__(self, data, target, features_dict, models, binomial=False):\n            \"\"\"\n            Instances for Reporter\n            \"\"\"\n\n            self.final_report = None\n            self.best_estimator = []\n            self.predictions = []\n            self.data = data\n            self.target = target\n            self.models = models\n            self.binomial = binomial\n            self.score = f1_score\n            self.scoring = 'f1_micro'\n            self.random_state = 42\n            self.features_dict = features_dict\n            self.folds = 5\n\n        def metrics_plot(self, model, model_title, features_valid, target_valid):\n            \"\"\"\n            Displays the PR curve and ROC curve\n            \"\"\"\n\n            probabilities_valid = model.predict_proba(features_valid)\n            precision, recall, thresholds = precision_recall_curve(target_valid, probabilities_valid[:, 1])\n            fpr, tpr, thresholds = roc_curve(target_valid, probabilities_valid[:, 1])\n\n            fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n            fig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n            sns.lineplot(recall, precision, drawstyle='steps-post', ax=ax[0])\n            ax[0].set_xlabel('Recall')\n            ax[0].set_ylabel('Precision')\n            ax[0].set_ylim([0.0, 1.05])\n            ax[0].set_xlim([0.0, 1.0])\n            ax[0].set_title('Precision-Recall Curve ' + model_title)\n\n            sns.lineplot(fpr, tpr, ax=ax[1])\n            ax[1].plot([0, 1], [0, 1], linestyle='--')\n            ax[1].set_xlim(0, 1)\n            ax[1].set_ylim(0, 1)\n            ax[1].set_xlabel('False Positive Rate')\n            ax[1].set_ylabel('True Positive Rate')\n            ax[1].set_title('ROC-curve ' + model_title)\n\n        def auc_roc(self, model, features_valid, target_valid):\n            \"\"\"\n            Calculating ROC-AUC\n            \"\"\"\n\n            probabilities_valid = model.predict_proba(features_valid)\n            probabilities_one_valid = probabilities_valid[:, 1]\n            auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n\n            return auc_roc\n\n        def grid_search(self, model, param_grid, x_features, y_features):\n            \"\"\"\n            GridSearchCV\n            \"\"\"\n            kfold = KFold(n_splits=self.folds, shuffle=True,\n                          random_state=self.random_state)\n            grid_model = GridSearchCV(model, param_grid=param_grid,\n                                      scoring=self.scoring, cv=kfold,\n                                      verbose=1, n_jobs=-1, )\n            grid_model.fit(x_features, y_features)\n            best_estimator = grid_model.best_estimator_\n            return best_estimator\n\n        def data_spliter(self, features):\n            \"\"\"\n            Splitting data into training and test in a ratio of 60:40\n            \"\"\"\n            x_train, x_test, y_train, y_test = train_test_split(self.data[features], \n                                                                self.data[self.target], \n                                                                train_size=0.6, \n                                                                stratify=self.data[self.target],\n                                                                random_state=self.random_state)\n\n            return x_train, y_train, x_test, y_test\n\n        def reporter(self):\n\n            started = time.time()\n            report = []\n            estimators = []\n            predictions = []\n            score_name = str(self.score).split(' ')[1]\n            models = self.models\n\n            for key in self.features_dict:\n\n                features = self.features_dict[key]\n\n                print('Features set - ', key)\n\n                x_train, y_train, x_test, y_test = self.data_spliter(features)\n                \n                x_train = np.log(x_train, where=x_train>0)\n                x_test = np.log(x_test, where=x_test>0)\n\n                scaler = StandardScaler()\n\n                x_train = scaler.fit_transform(x_train)\n                x_test = scaler.transform(x_test)\n\n                print('Dataset was splitted into training and test in a ratio of 60:40 and scaled using StandardScaler. \\n')\n                print('Shapes: \\n')\n                print('- train ', x_train.shape, y_train.shape)\n                print('- test ', x_test.shape, y_test.shape)\n                print('\\n')\n\n                print('Report: ')\n\n                for model in models:\n                    started_local = time.time()\n                    print('\\n', model[0], '\\n')\n                    grid_search = self.grid_search(model[1], model[2], x_train, y_train)\n                    print(grid_search)\n                    ended_local = time.time()\n                    predicted_test = np.ravel(grid_search.predict(x_test))\n                    test_score = self.score(y_test, predicted_test, average='micro')\n\n                    report.append((model[0], test_score, ended_local-started_local, key))\n                    estimators.append((model[0], grid_search))\n                    predictions.append((model[0], predicted_test))\n                    if self.binomial == True:\n                        self.metrics_plot(grid_search, model[0], x_test, y_test)\n                    print('\\n', 'Classification report for ' + model[0], '\\n\\n', classification_report(y_test, predicted_test))\n\n                print('--------------------------------------------------------------------')\n                print('--------------------------------------------------------------------')\n                print('--------------------------------------------------------------------')\n                print('--------------------------------------------------------------------')\n            self.final_report = pd.DataFrame(report, columns=['model', score_name + '_test', 'seconds_to_fit', 'features_key'])\n            self.best_estimator = pd.DataFrame(estimators, columns=['model', 'grid_params'])\n            self.predictions = pd.DataFrame(predictions, columns=['model', 'test_predictions'])\n            ended = time.time()\n            print('Cross-validation training and parameter search completed in {} sec.'.format(round(ended-started, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"explorer = DataExplorer('/kaggle/input/red-wine-quality-cortez-et-al-2009/', 'winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Defining features bunch","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"dict_of_features_combinations = {'all_features': ['fixed acidity', 'volatile acidity', 'citric acid', \n                                                   'residual sugar', 'chlorides', 'free sulfur dioxide', \n                                                   'total sulfur dioxide', 'density', 'pH', 'sulphates', \n                                                   'alcohol'],\n                                 \n                                 'most_important': ['volatile acidity', 'residual sugar', 'sulphates', 'alcohol']}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Preparing models and parameters for tuning","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"models_list = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### - LGBMClassifier","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"lg = lgb.LGBMClassifier(random_state=42, class_weight='balanced')\n\nparam_grid = {'boosting_type': ['gbdt'],\n              'num_leaves': [10, 20, 30],\n              'num_iterations': [600],\n              'learning_rate': [0.01, 0.0001],\n              'max_depth': [10, 30, 100]}\n\nmodels_list.append(('LGBMClassifier', lg, param_grid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Report for multiple classifications","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"explorer.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"multi_report = explorer.Reporter(explorer.data, 'quality', dict_of_features_combinations, models_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"multi_report.reporter()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"multi_report.final_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Report for enlarged groups classifications: three classes of wine (1 - best, 3 - worst)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_three_classed = explorer.generalization()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_three_classed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_report = explorer.Reporter(df_three_classed, 'gen_quality', dict_of_features_combinations, models_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_report.reporter()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_report.final_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Report for binomial classifications","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_binomial = explorer.binomizator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"bi_report = explorer.Reporter(df_binomial, 'bi_quality', dict_of_features_combinations, models_list, binomial=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"bi_report.reporter()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"bi_report.final_report","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}