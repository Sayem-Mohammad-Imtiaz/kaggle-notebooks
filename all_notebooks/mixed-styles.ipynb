{"cells":[{"metadata":{"_uuid":"2c838c7957b36ce334e934b595b44038b855105a","_cell_guid":"532314b3-a7e1-419d-ae0f-b169df7ce54c"},"cell_type":"markdown","source":"# Full Versions: [Variant 1](https://olgabelitskaya.github.io/DL_PP5_Additional.html) & [Variant 2](https://olgabelitskaya.github.io/DL_PP5_Additional_V2.html)\n# Versions in Google Colaboratory [Variant 1](https://colab.research.google.com/drive/1svW40BBscfSLD7Je99TyctBeRWIOYHKa) & [Variant 2](https://colab.research.google.com/drive/1IS_6BqJDLVbJJsuTuWTr3OfGP5uEu2eV)"},{"metadata":{"_uuid":"4705459319f12c766e841feeeb356a90d50b24ad","_cell_guid":"53e3e492-e13a-457a-8f4c-f1fda60c8e96"},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"_uuid":"e2b1be60d5577e3bb091ba0f18dfbda293c1548b","_cell_guid":"abc1ab55-c624-46ad-81b7-51325a6f55f5","trusted":true,"collapsed":true},"cell_type":"code","source":"import warnings; warnings.filterwarnings('ignore')\nimport cv2,numpy as np,tensorflow as tf,pylab as pl,keras as ks\nfrom tqdm import tqdm\nfpath='../input/image-examples-for-mixed-styles/'\nmw='../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nstyle_layers=['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c538aec062989f631258bef15e8956ed939cb35","_cell_guid":"5b42bb12-640b-498c-ad4f-2967f80f5383"},"cell_type":"markdown","source":"# Displaying Horizontal Images"},{"metadata":{"_uuid":"a60c55da09f884a994097d9da2aa2cb285ba73e8","_cell_guid":"38017881-acc2-40c6-8e34-c375b8b2d065","collapsed":true,"trusted":true},"cell_type":"code","source":"# Read from files and display images using OpenCV\ndef display_images(original,style,fpath=fpath):\n    original_img=cv2.imread(fpath+original)\n    style_img=cv2.imread(fpath+style)    \n    pl.figure(1,figsize=(12,4))\n    pl.subplot(121)\n    pl.title(\"Shape of the original image: %s\"%str(original_img.shape))\n    pl.imshow(cv2.cvtColor(original_img,cv2.COLOR_BGR2RGB))\n    pl.subplot(122)\n    pl.title(\"Shape of the style image: %s\"%str(style_img.shape))\n    pl.imshow(cv2.cvtColor(style_img,cv2.COLOR_BGR2RGB)); pl.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6746fc4de553ed9e6c99bc29ac8b4da51394979e","_cell_guid":"d69d7778-6436-4306-b4dc-03d4d974090f","trusted":true,"collapsed":true},"cell_type":"code","source":"display_images('picture03.png','pattern03.png')\ndisplay_images('picture02.png','pattern02.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a710095fe4a682c3444d21a7bfc3f2e0943f7a8f","_cell_guid":"636ea855-c430-401f-a890-2093e1a56196"},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_uuid":"bc36e951c321fd1bd99aeb3626d231f105c14242","_cell_guid":"81f00055-35a0-484b-af9a-877b39ef6b16","trusted":true,"collapsed":true},"cell_type":"code","source":"# Create image tensors and resize the biggest one; Pair 1\npicture01=cv2.imread(fpath+'picture03.png').astype('float32')\npattern01=cv2.imread(fpath+'pattern03.png').astype('float32')\npicture01=cv2.resize(picture01,(400,400)).astype('float32')\npattern01=cv2.resize(pattern01,(400,400)).astype('float32')\npicture01.shape,pattern01.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faea257a9d13fb7854b9e79eb51bfcc373946478","_cell_guid":"a40ec4da-4882-412d-97ee-b5e28568d2dd","trusted":true,"collapsed":true},"cell_type":"code","source":"# Create image tensors and resize the biggest one; Pair 2\npicture02=cv2.imread(fpath+'picture02.png').astype('float32')\npattern02=cv2.imread(fpath+'pattern02.png').astype('float32')\npicture02=cv2.resize(picture02,(630,520)).astype('float32')\npattern02=cv2.resize(pattern02,(630,520)).astype('float32')\npicture02.shape,pattern02.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d45aaf5a6716b052d8d460a880093dad8aa4e155","_cell_guid":"e97f1c84-ab23-41eb-916f-b52558b816a0","collapsed":true,"trusted":true},"cell_type":"code","source":"# Preprocess function for VGG16\ndef preprocess(img):\n    img=img.copy(); img=np.expand_dims(img,axis=0) \n    return ks.applications.vgg16.preprocess_input(img)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dc8e1315db159d8085fb5cdd5f2d550a68a0eee","_cell_guid":"7597525d-f2d9-435a-ada4-40034da0fba6","collapsed":true,"trusted":true},"cell_type":"code","source":"# Reverse of preprocessing\ndef deprocess(img):\n    img=img.copy()[0]                        \n    img[:,:,0]+=103.939; img[:,:,1]+=116.779; img[:,:,2]+=123.68             \n    img=img[:,:,::-1]              \n    img=np.clip(img,0,255)         \n    return img.astype('uint8') ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00ff880cbbaf27ff8b5099d8fd089690797ec0f0","_cell_guid":"6e2b9a8f-efbb-445a-8027-e241c60dbcc6","collapsed":true,"trusted":true},"cell_type":"code","source":"# Function for input tensors\ndef inputs(original_img,style_img):\n    original_input=tf.constant(preprocess(original_img))\n    style_input=tf.constant(preprocess(style_img))\n    generated_input=tf.placeholder(tf.float32,original_input.shape)\n    return original_input,style_input,generated_input","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c3311fdfb030ae70cad189403ad765019633f3d","_cell_guid":"c7d77e9d-2e68-4052-9a46-4d027c674073","trusted":true,"collapsed":true},"cell_type":"code","source":"# Create input tensors\noriginal_input,style_input,generated_input=inputs(picture01,pattern01)\ninput_tensor=tf.concat([original_input,style_input,generated_input],axis=0)\noriginal_input2,style_input2,generated_input2=inputs(picture02,pattern02)\ninput_tensor2=tf.concat([original_input2,style_input2,generated_input2],axis=0)\n[input_tensor.shape,input_tensor2.shape]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4fb1f14ec3b31f4ddb33491abbefdd46efdd696","_cell_guid":"1e141724-fdba-410f-8052-43480f518d83"},"cell_type":"markdown","source":"# VGG16 Usage"},{"metadata":{"_uuid":"ff7172e2e665dfed51216690403b977712d2b153","_cell_guid":"20893759-6da0-4737-86f5-28524b8319a4","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# Create the model using keras applications; Pair 1\nvgg16_model=ks.applications.vgg16.\\\nVGG16(weights=mw,input_tensor=input_tensor,include_top=False)\n# Create layer dictionaries\nvgg16_layer_dict={layer.name:layer for layer in vgg16_model.layers}\nvgg16_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Create the model using keras applications; Pair 2\nvgg16_model2=ks.applications.vgg16.\\\nVGG16(weights=mw,input_tensor=input_tensor2,include_top=False)\n# Create layer dictionaries\nvgg16_layer_dict2={layer.name:layer for layer in vgg16_model2.layers}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc99c3d9c1f2525683ea645de354f4ffec57f56b","_cell_guid":"14685ccd-94f5-4040-826b-179d7c47ce1e","collapsed":true,"trusted":true},"cell_type":"code","source":"def calculate_original_loss(layer_dict,original_layer_names):\n    loss=0\n    for name in original_layer_names:\n        layer=layer_dict[name]\n        original_features=layer.output[0,:,:,:]  \n        generated_features=layer.output[2,:,:,:] \n        loss+=ks.backend.sum(ks.backend.square(generated_features-original_features))\n    return loss/len(original_layer_names)\ndef gram_matrix(x):    \n    features=ks.backend.batch_flatten(ks.backend.permute_dimensions(x,(2,0,1))) \n    gram=ks.backend.dot(features,ks.backend.transpose(features))\n    return gram\ndef get_style_loss(style_features,generated_features,size):\n    S=gram_matrix(style_features)\n    G=gram_matrix(generated_features)\n    channels=3\n    return ks.backend.sum(ks.backend.square(S-G))/(4.*(channels**2)*(size**2))\ndef calculate_style_loss(layer_dict,style_layer_names,size):\n    loss=0\n    for name in style_layer_names:\n        layer=layer_dict[name]\n        style_features=layer.output[1,:,:,:] \n        generated_features=layer.output[2,:,:,:] \n        loss+=get_style_loss(style_features,generated_features,size) \n    return loss/len(style_layer_names)\ndef calculate_variation_loss(x):\n    row_diff=ks.backend.square(x[:,:-1,:-1,:]-x[:,1:,:-1,:])\n    col_diff=ks.backend.square(x[:,:-1,:-1,:]-x[:,:-1,1:,:])\n    return ks.backend.sum(ks.backend.pow(row_diff+col_diff,1.25))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aee14f36f384466915190bbaef6494b2fa44c4ca","_cell_guid":"da95617d-1d40-4202-92d8-0fa77dbcb36c","trusted":true,"collapsed":true},"cell_type":"code","source":"# Calculate all losses\noriginal_loss=calculate_original_loss(vgg16_layer_dict,['block5_conv2'])\nstyle_loss=calculate_style_loss(vgg16_layer_dict,style_layers, \n                                pattern01.shape[0]*pattern01.shape[1])\nvariation_loss=calculate_variation_loss(generated_input)\noriginal_loss2=calculate_original_loss(vgg16_layer_dict2,['block5_conv2'])\nstyle_loss2=calculate_style_loss(vgg16_layer_dict2,style_layers, \n                                 pattern02.shape[0]*pattern02.shape[1])\nvariation_loss2=calculate_variation_loss(generated_input2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e16a8ab47a6636e47a481b70e60ed64070eeecd0","_cell_guid":"92ff8409-0623-494f-85ff-6b2ce1400e36","trusted":true,"collapsed":true},"cell_type":"code","source":"### Pair 1 ###\n# Loss and gradients calculation\nloss=.5*original_loss+1.*style_loss+.1*variation_loss       \ngradients=ks.backend.gradients(loss,generated_input)[0]\ncalculate=ks.backend.function([generated_input],[loss,gradients])\n# Preprocess the image\ngenerated_data=preprocess(picture01)\n# Generate the new image \nfor i in tqdm(range(100)):\n    _,gradients_value=calculate([generated_data])\n    generated_data-=gradients_value*.001","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4625daac21ae41c3da5b17c06e47fbef7499b4a7","_cell_guid":"7f322624-a378-4561-82d9-1eba289318a6","trusted":true,"collapsed":true},"cell_type":"code","source":"### Pair 2 ###\n# Loss and gradients calculation\nloss2=.5*original_loss2+1.*style_loss2+.1*variation_loss2    \ngradients2=ks.backend.gradients(loss2,generated_input2)[0]\ncalculate2=ks.backend.function([generated_input2],[loss2,gradients2])\n# Preprocess the image\ngenerated_data2=preprocess(picture02)\n# Generate the new image \nfor i in tqdm(range(300)):\n    _,gradients_value2=calculate2([generated_data2])\n    generated_data2-=gradients_value2*.001","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generated Images"},{"metadata":{"_uuid":"a377ad0a41baa17bfab315943399d0d65f6fa58a","_cell_guid":"23ae6a70-f584-417f-9368-d176c1d0a49b","trusted":true,"collapsed":true},"cell_type":"code","source":"generated_image01=deprocess(generated_data)\ngenerated_image02=deprocess(generated_data2)\npl.figure(1,figsize=(8,16))\npl.subplot(211)\npl.title(\"Loss function: 0.5*original_loss+1.0*style_loss+0.1*variation_loss; 100 steps\")\npl.imshow(cv2.cvtColor(generated_image01,cv2.COLOR_BGR2RGB))\npl.subplot(212)\npl.title(\"Loss function: 0.5*original_loss+1.0*style_loss+0.1*variation_loss; 300 steps\")\npl.imshow(cv2.cvtColor(generated_image02,cv2.COLOR_BGR2RGB))\npl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One More Time\n# Displaying Vertical Images"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"display_images('picture01.png','pattern01.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def rr_img(image,angle,width,height):\n    [h,w]=image.shape[:2]; x,y=w//2,h//2\n    M=cv2.getRotationMatrix2D((x,y),-angle,1.)\n    cos,sin=np.abs(M[0,0]),np.abs(M[0,1])\n    nw,nh=int((h*sin)+(w*cos)),int((h*cos)+(w*sin))\n    M[0,2]+=(nw/2)-x; M[1,2]+=(nh/2)-y\n    img=cv2.warpAffine(image,M,(nw,nh))\n    return cv2.resize(img,(width,height)).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"picture01=cv2.imread(fpath+'picture01.png').astype('float32')\npattern01=cv2.imread(fpath+'pattern01.png').astype('float32')\npicture01=rr_img(picture01,90,600,400)\npattern01=rr_img(pattern01,90,600,400)\npicture01.shape,pattern01.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"original_input,style_input,generated_input=\\\ninputs(picture01,pattern01)\ninput_tensor=tf.concat([original_input,style_input,\n                        generated_input],axis=0)\ninput_tensor.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG16 Usage"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"vgg16_model=ks.applications.vgg16.\\\nVGG16(input_tensor=input_tensor,include_top=False)\nvgg16_layer_dict={layer.name:layer for layer in vgg16_model.layers}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"original_loss=calculate_original_loss(vgg16_layer_dict,['block5_conv2'])\nstyle_loss=calculate_style_loss(vgg16_layer_dict,style_layers, \n                                pattern01.shape[0]*pattern01.shape[1])\nvariation_loss=calculate_variation_loss(generated_input)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generated Images"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"loss=.5*original_loss+1.*style_loss+.1*variation_loss    \ngradients=ks.backend.gradients(loss,generated_input)[0]\ncalculate=ks.backend.function([generated_input],[loss,gradients])\ngenerated_data=preprocess(picture01) \nfor i in tqdm(range(30)):\n    _,gradients_value=calculate([generated_data])\n    generated_data-=gradients_value*.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"loss=.7*original_loss+1.*style_loss+.1*variation_loss    \ngradients=ks.backend.gradients(loss,generated_input)[0]\ncalculate=ks.backend.function([generated_input],[loss,gradients])\ngenerated_data2=preprocess(picture01) \nfor i in tqdm(range(300)):\n    _,gradients_value=calculate([generated_data2])\n    generated_data2-=gradients_value*.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"generated_image01=deprocess(generated_data)\ngenerated_image02=deprocess(generated_data2)\ngenerated_image01=rr_img(generated_image01,270,400,600)/255\ngenerated_image02=rr_img(generated_image02,270,400,600)/255\npl.figure(1,figsize=(8,16))\npl.subplot(211)\npl.title(\"Loss function: 0.5*original_loss+1.0*style_loss+0.1*variation_loss; 30 steps\")\npl.imshow(cv2.cvtColor(generated_image01,cv2.COLOR_BGR2RGB))\npl.subplot(212)\npl.title(\"Loss function: 0.7*original_loss+1.0*style_loss+0.1*variation_loss; 300 steps\")\npl.imshow(cv2.cvtColor(generated_image02,cv2.COLOR_BGR2RGB))\npl.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}