{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Libraries\nimport re\nimport nltk # natural language tool kit\nnltk.download(\"stopwords\")\nimport nltk\nnltk.download('punkt')\nimport nltk\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords\nimport nltk as nlp\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n#Machine Learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n#Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluation of Classification Algoritm**\n* **Logistic Regression -> ACC: 0.9820531227566404 **\n    * tuned hyperparameters: (best parameters):  {'C': 10.0, 'penalty': 'l2'} #l2 = Ridge\n    * accuracy:  0.9820531227566404\n\n\n* Naive Bayes -> ACC: 0.8791866028708134 \n    * average accuracy:  0.8687312379706806\n    * average std:  0.013148098012261957\n\n\n* Decision Tree (CART) -> ACC: 0.9706937799043063 \n    * average accuracy:  0.9633266204315982\n    * average std:  0.01429551797233446 \n\n\n* K-NN -> ACC: 0.9542354630294329\n    * tuned hyperparameter K:  {'n_neighbors': 2}\n    * tuned parameter (best score):  0.9542354630294329\n    * average accuracy:  0.9492226807067798\n    * average std:  0.014787458315299876\n\n\n* RandomForestClassifier -> ACC: 0.9778708133971292 \n    * average accuracy:  0.9748684249344347\n    * average std:  0.009858906987874947"},{"metadata":{},"cell_type":"markdown","source":"**IMPORT DATA**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")\ndata = pd.concat([data.Category,data.Message],axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CLEANING DATA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(axis = 0,inplace = True)\ndata.Category = [1 if each == \"ham\" else 0 for each in data.Category]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA SAMPLE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_description = data.Message[2]\ndescription = re.sub(\"[^a-zA-Z]\",\" \",first_description)\ndescription = description.lower() \n\ndescription","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**STOPWORDS/irrelavent words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"description = nltk.word_tokenize(description)\n\ndescription","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\ndescription","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LEMMATAZATION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lemma = nlp.WordNetLemmatizer()\ndescription = [ lemma.lemmatize(word) for word in description] \n\ndescription = \" \".join(description)\ndescription","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BAG OF WORDS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"description_list = []\nfor description in data.Message:\n    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n    description = description.lower()   \n    description = nltk.word_tokenize(description)\n    description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n    lemma = nlp.WordNetLemmatizer()\n    description = [ lemma.lemmatize(word) for word in description]\n    description = \" \".join(description)\n    description_list.append(description)\ndescription_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CountVectorizer **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer \nmax_features = 5000\ncount_vectorizer = CountVectorizer(max_features=max_features,stop_words = \"english\")\nsparce_matrix = count_vectorizer.fit_transform(description_list).toarray()  # x\nprint(\" Commonly Used {} words: {}\".format(max_features,count_vectorizer.get_feature_names()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TRAIN-TEST SPLIT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.iloc[:,0].values   # Ham - Spam classes\nx = sparce_matrix\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 42)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluation of Classification Algoritm**"},{"metadata":{},"cell_type":"markdown","source":"**KNN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\"n_neighbors\":np.arange(1,5)}\nknn= KNeighborsClassifier()\n\nknn_cv = GridSearchCV(knn, grid, cv = 5)  # GridSearchCV\nknn_cv.fit(x,y)\n\nprint(\"tuned hyperparameter K: \",knn_cv.best_params_)\nprint(\"tuned parameter (best score): \",knn_cv.best_score_)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=2)  # k = n_neighbors\n\naccuracies = cross_val_score(estimator = knn, X = x_train, y= y_train, cv = 10) #Cross Validation\nprint(\"average accuracy: \",np.mean(accuracies))\nprint(\"average std: \",np.std(accuracies))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ny_pred = knn_cv.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_pred)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\"C\":np.logspace(-3,3,7),\"penalty\":[\"l1\",\"l2\"]}  # l1 = lasso ve l2 = ridge\n\nlogreg = LogisticRegression()\nlogreg_cv = GridSearchCV(logreg,grid,cv = 5) #GridSearchCV\nlogreg_cv.fit(x,y)\n\nprint(\"tuned hyperparameters: (best parameters): \",logreg_cv.best_params_)\nprint(\"accuracy: \",logreg_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ny_pred = logreg_cv.predict(x_test)\ny_true = y_test\ncm = confusion_matrix(y_true,y_pred)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Naive Bayes & Decision Tree (CART) & RandomForestClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(('Naive Bayes', GaussianNB()))\nmodels.append(('Decision Tree (CART)',DecisionTreeClassifier())) \nmodels.append(('RandomForestClassifier',RandomForestClassifier(n_estimators = 100,random_state = 1)))\n\nfor name, model in models:\n    model = model.fit(x_train,y_train)\n    ACC = model.score(x_test,y_test)\n    accuracies = cross_val_score(estimator = model, X = x_train, y= y_train, cv = 10) #CrossFold Validation\n    print(\"{} -> ACC: {} \".format(name,ACC))\n    print(\"average accuracy: \",np.mean(accuracies))\n    print(\"average std: \",np.std(accuracies))\n    #Confusion Matrix\n    y_pred = model.predict(x_test)\n    y_true = y_test\n    cm = confusion_matrix(y_true,y_pred)\n    f, ax = plt.subplots(figsize =(5,5))\n    sns.heatmap(cm,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\n    plt.xlabel(\"y_pred\")\n    plt.ylabel(\"y_true\")\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}