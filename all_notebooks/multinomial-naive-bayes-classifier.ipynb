{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport nltk\nimport re\nimport csv\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom collections import Counter\nfrom sklearn.metrics import confusion_matrix,accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/mpst-movie-plot-synopses-with-tags/mpst_full_data.csv', sep=',')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imdb_id = data.imdb_id\nplot = data.plot_synopsis\n\nmovies = pd.DataFrame({'imdb_id': imdb_id, 'plot': plot})\nmovies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['imdb_id'] = data['imdb_id'].astype(str)\nmovies = pd.merge(movies, data[['imdb_id', 'title', 'tags', 'split']], on='imdb_id')\nmovies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genres_listas = []\n\nfor tag in movies.tags:\n    genres_listas.append(re.split(',', tag))\n\nmovies.tags = genres_listas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_genres = sum(genres_listas, [])\nfor i in range(0, len(all_genres)):\n    all_genres[i] = all_genres[i].strip()\nprint(len(set(all_genres)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_genres","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_genres = nltk.FreqDist(all_genres)\nall_genres_df = pd.DataFrame({'Genre': list(all_genres.keys()), 'Count': list(all_genres.values())})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\ng = all_genres_df.nlargest(columns='Count', n=50)\nplt.figure(figsize=(12,15))\nax = sns.barplot(data=g, x='Count', y='Genre')\nax.set(ylabel='Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for text cleaning \ndef clean_text(text):\n    # remove backslash-apostrophe \n    text = re.sub(\"\\'\", \"\", text) \n    # remove everything except alphabets \n    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n    # remove whitespaces \n    text = ' '.join(text.split()) \n    # convert text to lowercase \n    text = text.lower() \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\nmovies_new = copy.deepcopy(movies)\nmovies_new['clean_plot'] = movies['plot'].apply(lambda x: clean_text(x))\nmovies_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def freq_words(x, terms = 30):\n    all_words = ' '.join([text for text in x]) \n    all_words = all_words.split() \n    fdist = nltk.FreqDist(all_words) \n    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())}) \n  \n    # selecting top 20 most frequent words \n    d = words_df.nlargest(columns=\"count\", n = terms) \n  \n    # visualize words and frequencies\n    plt.figure(figsize=(12,15)) \n    ax = sns.barplot(data=d, x= \"count\", y = \"word\") \n    ax.set(ylabel = 'Word') \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print 100 most frequent words \nfreq_words(movies_new['clean_plot'], 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\n# function to remove stopwords\ndef remove_stopwords(text):\n    no_stopword_text = [w for w in text.split() if not w in stop_words]\n    return ' '.join(no_stopword_text)\n\nmovies_new['clean_plot'] = movies_new['clean_plot'].apply(lambda x: remove_stopwords(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_words(movies_new['clean_plot'], 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\nmlb.fit(movies_new[movies_new['split'] == 'train']['tags'])\ny = mlb.transform(movies_new[movies_new['split'] == 'train']['tags'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_new = pd.concat([movies_new, pd.DataFrame(y, columns=mlb.classes_)], axis=1)\nprint(len(movies_new.columns))\nmovies_new.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = []\ngenres = mlb.classes_\nsplit = []\nfor genre in genres:\n    counts.append((genre, movies_new[genre].sum()))\nmovies_new_stats = pd.DataFrame(counts, columns=['genres', 'plots'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(movies_new.columns))\ngenres = movies_new_stats.loc[movies_new_stats['plots'] > 100, 'genres'].tolist()\nmovies_new.drop(movies_new_stats.loc[movies_new_stats['plots'] < 100, 'genres'].tolist(), axis=1, inplace=True)\nlen(movies_new.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\nmlb.fit(movies_new[movies_new['split'] == 'train']['tags'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = movies_new[movies_new['split'] == 'train'].iloc[:, 6:len(movies_new.columns)+1]\ny.fillna(1, inplace=True)\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_tfidf = tfidf_vectorizer.fit_transform(movies_new[movies_new['split'] == 'train']['clean_plot'])\nxtrain_tfidf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest_tfidf = tfidf_vectorizer.fit_transform(movies_new[movies_new['split'] == 'test']['clean_plot'])\nxtest_tfidf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nt = []\n\nwhile i <= y.shape[1]-1:\n    s = []\n    clf.fit(xtrain_tfidf, y[:,i])\n    s.append(clf.predict(xtest_tfidf))\n    i += 1\n    t.append(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.array(t).reshape(np.array(t).shape[2], np.array(t).shape[0])\ny_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = movies_new[movies_new['split'] == 'test'].iloc[:, 6:len(movies_new.columns)+1]\ny_true.fillna(1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = np.array(y_true)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred.shape)\nprint(y_true.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sklearn.metrics.f1_score(y_true, y_pred, average='micro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sklearn.metrics.multilabel_confusion_matrix(y_true, y_pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}