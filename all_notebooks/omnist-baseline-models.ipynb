{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Purpose:\nInstantiate, train, and evaluate multiple classification models, establishing baseline performance metrics for each.\n## Implementation:\nMachine learning libraries used include scikit-learn, scikit-image, and Tensorflow's Keras API. Training and evaluation will occur with normalized arrays using the untuned, \"out-of-the-box\" classifiers seen below.\n* Multi-layer Perceptron\n* Convolutional Neural Network\n* Random Forest\n* K-Means\n* K-Nearest Neighbors\n* Support Vector Machine\n* Logistic Regression\n* AdaBoost\n* Stochastic Gradient Descent\n* Naive Bayes\n\n### Import Required Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport time as t\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom skimage import io, transform\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics\n\nimport tensorflow.keras as k\nfrom keras.losses import categorical_crossentropy\nfrom keras.utils import np_utils\n\nprint('Keras version {}'.format(k.__version__))\n\nTI = t.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Useful functions and shortcuts\ndef sp(int):\n    # Returns a blank string of length int\n    return ' ' * int\n\n\ndef timer(ti, tf, rnd = 2):\n    # Returns esapsed time in sec, min\n    dif = tf - ti\n    sc = round(dif, rnd)\n    print('{} sec'.format(sc))\n    return sc\n\n\ndef norm_pic(pic):\n    # Returns normalized array as type float32\n    return (pic - pic.mean()) / (pic.max() - pic.min()).astype('float32')\n\n\ndef batcher(num_pics):\n    # Returns dict of batch sizes for CNN input\n    lib = {'batch_size': []}\n    for i in range(10, num_pics):\n        batch_size = i + 1\n        num = num_pics % batch_size\n        if num == 0 and batch_size <= 150:\n            iters = int(num_pics / batch_size)\n            lib['batch_size'].append((batch_size, iters))\n    return lib\n\ndef reshaper(xtrain, xtest, ytrain, ytest):\n    xtr = np.asarray(xtrain).reshape(xtrain.shape[0], 28, 28, 1)\n    xtst = np.asarray(xtest).reshape(xtest.shape[0], 28, 28, 1)\n    ytr = np_utils.to_categorical(ytrain, 10)\n    ytst = np_utils.to_categorical(ytest, 10)\n    return (xtr, xtst, ytr, ytst)\n\n# Set random state for all classifiers\nrnd_st = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Prepare Overhead-MNIST"},{"metadata":{"trusted":true},"cell_type":"code","source":"# File path\npath = '../input/overheadmnist/overhead/'\npath_tr = path + 'training/'\n\n# Save files as dataframes\ntrain = pd.read_csv(path + 'train.csv')\nlabels = pd.read_csv(path + 'labels.csv')\ntr_labels = labels[labels['dataset'] == 'train'].drop('dataset', axis = 1)[['image', 'class', 'label']]\nts_labels = labels[labels['dataset'] == 'test'].drop('dataset', axis = 1)[['image', 'class', 'label']]\nclasses = pd.read_csv(path + 'classes.csv')\n\n# Create master DF to export \nmaster_tr = tr_labels.join(train.drop('label', axis = 1))\nmaster_ts = ts_labels.join(train.drop('label', axis = 1))\n\n# Save master DFs for future notebooks\nmaster_tr.to_csv('master_tr.csv')\nmaster_ts.to_csv('master_ts.csv')\n\n# Reference lists\nclss_lst = classes['class'].values\n\n# Store useful values\ntot_pics = len(train)\nnum_classes = len(classes)\nresults_dict = {}\n\n_ = timer(TI, t.time())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create training and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize arrays\nX = norm_pic(train.drop('label', axis = 1))\n\n# Create categorical labels\ny = train['label']\n\n# Split the trainig data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .2, \n                                                  stratify = y, random_state = rnd_st)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Model Creation & Training\n## Multi-Layer Perceptron (Neural Network)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\ny_dum = pd.get_dummies(y_train)\ny_val_dum = pd.get_dummies(y_val)\ny_dum.columns = clss_lst\ny_val_dum.columns = clss_lst\n\n# Instantiate the classifier\nmlp = MLPClassifier(random_state = rnd_st)\n\nst = t.time()\n# Fit the classifier to the training data\nmlp.fit(X_train, y_dum)\n\n# Makre predictions on evaluation data\nmlp_pred = mlp.predict_proba(X_val)\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions\ny_pred = mlp.predict(X_val)\n\n# Evaluate performance\nmlp_rpt = metrics.classification_report(y_val_dum, y_pred, output_dict = True,\n                                       target_names = clss_lst, zero_division = 1)\nacc = metrics.accuracy_score(y_val_dum, y_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_val_dum, y_pred)))\n\n# Save results\nmlp_results = pd.DataFrame(mlp_rpt).T\n\nresults_dict['Multi-Layer Perceptron'] = {'accuracy' : acc, \n                       'classification report' : mlp_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, mlp_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convolutional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape input files \nX_tr, X_vl, y_tr, y_vl = reshaper(X_train, X_val, y_train, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate classifier\ncnn = k.Sequential()\n\n# Add a layers & compile\ncnn.add(k.layers.Conv2D(filters = 32, kernel_size = (3, 3)))\ncnn.add(k.layers.Flatten())\ncnn.add(k.layers.Dense(100))\ncnn.add(k.layers.Dense(10, activation = 'softmax'))\n\ncnn.compile(loss = 'categorical_crossentropy', \n            metrics = ['accuracy', k.metrics.CategoricalAccuracy()])\n\n# Fit and evaluate\nst = t.time()\n\ncnn.fit(X_tr, y_tr)\n\n# Make predictions on evaluation data\ncnn_pred = np.round(cnn.predict(X_vl))\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\ncnn_rpt = metrics.classification_report(y_vl, cnn_pred, output_dict = True, \n                                       target_names = clss_lst, zero_division = 1)\nacc = metrics.accuracy_score(y_vl, cnn_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_vl, cnn_pred)))\n\n# Save results\ncnn_results = pd.DataFrame(cnn_rpt).T\n\nresults_dict['Convolutional Neural Network'] = {'accuracy' : acc, \n                       'classification report' : cnn_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, cnn_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Instantiate \nfst = RandomForestClassifier(random_state = rnd_st)\n\nst = t.time()\n# Fit\nfst.fit(X_train, y_tr)\n\n# Predict\nfst_pred = fst.predict(X_val)\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\nfst_rpt = metrics.classification_report(y_vl, fst_pred, output_dict = True, \n                                       target_names = clss_lst, zero_division = 1)\nacc = metrics.accuracy_score(y_vl, fst_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_vl, fst_pred)))\n\n# Save results\nfst_results = pd.DataFrame(fst_rpt).T\n\nresults_dict['Random Forest'] = {'accuracy' : acc, \n                       'classification report' : fst_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, fst_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkmn = KMeans(n_clusters = 10, random_state = rnd_st)\n\nst = t.time()\nkmn.fit(X_train, y_train)\n\nkmn_pred = np.asarray(pd.get_dummies(kmn.predict(X_val)))\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\nkmn_rpt = metrics.classification_report(y_vl, kmn_pred, output_dict = True, zero_division = 1)\nacc = metrics.accuracy_score(y_vl, kmn_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_vl, kmn_pred)))\n\n# Save results\nkmn_results = pd.DataFrame(kmn_rpt).T\n\nresults_dict['K-Means'] = {'accuracy' : acc, \n                       'classification report' : kmn_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, kmn_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Nearest Neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\n\nst = t.time()\nknn.fit(X_train, y_dum)\n\nknn_pred = knn.predict(X_val)\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\nknn_rpt = metrics.classification_report(y_vl, knn_pred, output_dict = True, zero_division = 1, \n                                       target_names = clss_lst)\nacc = metrics.accuracy_score(y_vl, knn_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_vl, knn_pred)))\n\n# Save results\nknn_results = pd.DataFrame(knn_rpt).T\n\nresults_dict['K-Nearest Neighbors'] = {'accuracy' : acc, \n                       'classification report' : knn_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, knn_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC()\n\nst = t.time()\nsvm.fit(X_train, y_train)\n\nsvm_pred = np.asarray(pd.get_dummies(svm.predict(X_val)))\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\nsvm_rpt = metrics.classification_report(y_vl, svm_pred, output_dict = True, zero_division = 1, \n                                       target_names = clss_lst)\nacc = metrics.accuracy_score(y_vl, svm_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_vl, svm_pred)))\n\n# Save results\nsvm_results = pd.DataFrame(svm_rpt).T\n\nresults_dict['Support Vector Machine'] = {'accuracy' : acc, \n                       'classification report' : svm_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, svm_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlgc = LogisticRegression()\n\nst = t.time()\nlgc.fit(X_train, y_train)\n\nlgc_pred = np.asarray(pd.get_dummies(lgc.predict(X_val)))\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\nlgc_rpt = metrics.classification_report(y_vl, lgc_pred, output_dict = True, zero_division = 1, \n                                       target_names = clss_lst)\nacc = metrics.accuracy_score(y_vl, lgc_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_vl, lgc_pred)))\n\n# Save results\nlgc_results = pd.DataFrame(lgc_rpt).T\n\nresults_dict['Logistic Regression'] = {'accuracy' : acc, \n                       'classification report' : lgc_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, lgc_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nadb = AdaBoostClassifier()\n\nadb.fit(X_train, y_train)\n\nst = t.time()\nadb_pred = np.asarray(pd.get_dummies(adb.predict(X_val)))\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\nadb_rpt = metrics.classification_report(y_vl, adb_pred, output_dict = True, \n                                        zero_division = 1, target_names = clss_lst)\nacc = metrics.accuracy_score(y_vl, adb_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_vl, adb_pred)))\n\n# Save results\nadb_results = pd.DataFrame(adb_rpt).T\n\nresults_dict['AdaBoost'] = {'accuracy' : acc, \n                       'classification report' : adb_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, adb_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stochastic Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\n\nst = t.time()\nsgd.fit(X_train, y_train)\n\nsgd_pred = sgd.predict(X_val)\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\nsgd_rpt = metrics.classification_report(y_val, sgd_pred, output_dict = True, zero_division = 1,\n                                        target_names = clss_lst)\nacc = metrics.accuracy_score(y_val, sgd_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_val, sgd_pred)))\n\n# Save results\nsgd_results = pd.DataFrame(sgd_rpt).T\n\nresults_dict['Stochastic Gradient Descent'] = {'accuracy' : acc, \n                       'classification report' : sgd_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, sgd_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\n\nst = t.time()\ngnb.fit(X_train, y_train)\n\ngnb_pred = gnb.predict(X_val)\n\n_ = timer(st, t.time())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance\ngnb_rpt = metrics.classification_report(y_val, gnb_pred, output_dict = True, zero_division = 1,\n                                        target_names = clss_lst)\nacc = metrics.accuracy_score(y_val, gnb_pred)\nconf = dict(zip(clss_lst, metrics.multilabel_confusion_matrix(y_val, gnb_pred)))\n\n# Save results\ngnb_results = pd.DataFrame(gnb_rpt).T\n\nresults_dict['Naive Bayes'] = {'accuracy' : acc, \n                       'classification report' : gnb_rpt, \n                       'confusion matrix' : conf}\n\nprint('accuracy: {}\\n\\n{}'.format(acc, gnb_results))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\nresultsDF = pd.DataFrame(results_dict)\nresultsDF.to_json('baselines.json')\n\n# Calculate total elapsed run time\nTF = t.time()\ntimer(TI, TF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy comparison\nresultsDF.T['accuracy']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary\nA Support Vector Machine model shows the best 'out-of-the-box' performance. Gaussian Naive Bayes and Multi-Layer Perceptron models achieve > 50% accuracy. All other models fall below this threshold, averaging 42%. The least accurate model is K-Means at 9.6%. Two models, MLP and LR, both failed to converge. \n\nFinal scores and confusion matrices are exported in json format as 'baselines.json'.\n## Next Steps\n* Complete EDA\n* Image Processing\n* Hyperparameter optimization"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}