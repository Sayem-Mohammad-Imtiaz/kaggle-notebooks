{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/real-time-advertisers-auction/Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()\n# No nans, it is great","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`integration_type_id` and `revenue_share_percent` - has one unique value, we should drop it\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['integration_type_id', 'revenue_share_percent']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's generate target value CPM\ndata['cpm'] = np.where(data.measurable_impressions > 0, data.total_revenue * 100 / data.measurable_impressions * 1000, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop target and useless cols\ndrop_cols += ['measurable_impressions', 'total_revenue']\ndata.drop(columns=drop_cols, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Continue Data exploring\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mark all data that have less than 255 unique values as categorical\nCAT_THRESHOLD = 255\ncat_features = set()\nfor col in data:\n    if data[col].nunique() <= CAT_THRESHOLD:\n        cat_features.add(col)\nprint(cat_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop date from cat values\ncat_features.remove('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform date to datetime and get some features\ndata['date'] = pd.to_datetime(data['date'])\ndata['day'] = data['date'].dt.day\ndata['month'] = data['date'].dt.month\ndata['dayofweek'] = data['date'].dt.dayofweek\ndata['dayofyear'] = data['date'].dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add some datetime features as categorical\ncat_features |= {'dayofweek', 'month', 'day'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom scipy import sparse\n\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cpm_threshold = data['cpm'].quantile(0.95)\ndata_raw = data.copy()\ndata = data.query('cpm < @cpm_threshold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_th = pd.to_datetime('2019-06-21')\ntrain = data.query('date <= @date_th')\ntest = data.query('date > @date_th')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train.pop('cpm')\ny_test = test.pop('cpm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe = OneHotEncoder(handle_unknown='ignore')\nX_cat_train = ohe.fit_transform(train[cat_features])\nX_cat_test = ohe.transform(test[cat_features], )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look on the rest features\nnp.setdiff1d(train.columns.values, list(cat_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_features = list(np.setdiff1d(train.columns.values, list(cat_features)))\nuseful_features.remove('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_int_train = train[useful_features]\nX_int_test = test[useful_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = sparse.hstack([X_cat_train, X_int_train])\nX_test = sparse.hstack([X_cat_test, X_int_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = XGBRegressor(\n#     predictor='gpu_predictor',\n    objective='reg:squarederror',\n#     cu\n    n_estimators=850, # best estimators num\n    verbosity=1,\n    reg_alpha=0.23,\n    reg_lambda=0.1,\n    n_jobs=6,\n    max_depth=9,\n    eta=0.25,\n    colsample_bytree=0.7\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calc train loss\ny_pred_train = xgb_model.predict(X_train)\nprint(f'Train MSE: {mean_squared_error(y_train, y_pred_train)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calc train loss\ny_pred_test = xgb_model.predict(X_test)\nprint(f'Test MSE: {mean_squared_error(y_test, y_pred_test)}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}