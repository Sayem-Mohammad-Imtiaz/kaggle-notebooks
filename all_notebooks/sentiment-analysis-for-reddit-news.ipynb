{"cells":[{"execution_count":null,"cell_type":"markdown","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"4402f0d25758a67d9d7d2430f8b2e6461f1a62f5","_cell_guid":"1fcf37ad-7ac5-4fa6-b3a8-e1fa4a2ff233"},"source":"I have analysed reddit news with more than 5000 upvotes.  Extracted top 50 proper nouns and analyzed the sentiment associated with the 50 proper nouns. Found the average of 50 and plotted against the nouns. Google, Mars and Canada have positive average sentiment with more 5000 upvote news headlines."},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"trusted":false,"_execution_state":"idle","_uuid":"6c747796c89f29153ed9fa08832ba4d62d600285","_cell_guid":"42d680bc-fe79-4d4d-8574-2f9161bbe69a"},"source":"from wordcloud import WordCloud,STOPWORDS\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import wordnet\nfrom nltk import word_tokenize\nfrom nltk.corpus import state_union\nfrom nltk.tag import pos_tag\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport collections, re\nimport string\nimport pylab as plt\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\ndf=pd.read_csv('../input/reddit_worldnews_start_to_2016-11-22.csv')\ndf1=df[df.up_votes>5000]\nprint(df1.head(5))"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"649efb35bbb93b072ebf78ac5071c325341e95f8","_cell_guid":"5314e8d7-f1ec-4767-95f1-e4a12add4513"},"source":"#stopwords removed and as sentence\n\nfiltered_words=df1['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n\nbagsofwords_1 = [ collections.Counter(re.findall(r'\\w+', txt)) for txt in filtered_words]\nsumbags = sum(bagsofwords_1, collections.Counter())\n\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"58a723990f6e2168712c14174f3c1ba8ff1938ee","_cell_guid":"3b614e82-7978-4c44-8c3d-c85c3167a564"},"source":"#to find the proper nouns in the filtered words\nA=pd.Series.to_string(filtered_words)\ntagged_sent = pos_tag(A.split())\npropernouns = [word for word,pos in tagged_sent if pos == 'NNP']\n\npropernouns_count=Counter(propernouns)"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"3c1448fbfd487e3ca5ba677081e6aef6f9db3556","_cell_guid":"762092d2-ea90-4b1f-bd6a-3806a39c3a89"},"source":"#wordcloud of most common 50 proper nouns\n\nmost_common_50 = propernouns_count.most_common(51)\nmost_common_50 = pd.DataFrame(most_common_50)\nmost_common_50 = most_common_50.drop(most_common_50.index[1])\nmost_common_50 = most_common_50.drop(most_common_50.index[38])\n\nmost_common_50.rename(columns={0:'text',1:'score'},inplace=True)\nwordcloud1 = WordCloud(background_color='white', width=3000, height=2500).generate(' '.join(most_common_50['text']))\n\nplt.figure(1,figsize=(8,8))\nplt.imshow(wordcloud1)\nplt.axis('off')\nplt.show()"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"d65246d67da0ac3d1933c44ff61356037bfeb5d1","_cell_guid":"591e385b-c0a9-436e-be66-01d460a29ffb"},"source":"sid=SentimentIntensityAnalyzer()\ndef senti_analysis(wordlist):\n    global local_vars\n    wordlist_1=[wordlist]\n    bag_of_sentences = [sentence for sentence in filtered_words if any(word in sentence for word in wordlist_1)]\n    ss=[]\n    senti_vals=[]    \n    for sentence in bag_of_sentences:   \n        ss.append(sid.polarity_scores(sentence))\n    senti_vals = [i['compound'] for i in ss]\n    senti_val =  sum(senti_vals)/len(senti_vals)\n    senti_val_positive = filter(lambda ss: ss['compound']>0,ss)\n    senti_val_negative = filter(lambda ss: ss['compound']<0,ss)\n    return senti_val\n\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"605427a9c46ae8121f9e8970a042b1e4def64ccf","_cell_guid":"40ab147d-10c8-414c-95d0-8b12c695b3f9"},"source":"most_common_50_1= []\nmost_common_50['text'] =most_common_50['text'].astype(str)\n\ni=0           \nfor word in most_common_50['text']:\n    most_common_50_1.append(senti_analysis(word))\n    i=i+1\n    \nmost_common_50['senti_val'] = pd.Series(most_common_50_1, index=most_common_50.index)\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"ccf78635f4c18fd37b80bbcca9e0abbba928ffe4","_cell_guid":"f95e0cd6-cbbb-4fba-ac71-592e5c49ecc2"},"source":"\nX = np.arange(0,len(most_common_50))\ny=most_common_50['senti_val']\n\nLABELS = most_common_50['text']\n\nax=plt.bar(X,y, align='center', width=0.5)\n#ax.autoscale(tight=True)\nplt.xticks(X, LABELS, rotation='vertical',fontsize=7)\nplt.show()\n"}],"nbformat":4,"metadata":{"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":0}