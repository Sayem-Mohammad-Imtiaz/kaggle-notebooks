{"cells":[{"metadata":{"papermill":{"duration":0.033703,"end_time":"2020-11-15T01:45:26.796024","exception":false,"start_time":"2020-11-15T01:45:26.762321","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 1. Import libraries<a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-11-15T01:45:26.871813Z","iopub.status.busy":"2020-11-15T01:45:26.870997Z","iopub.status.idle":"2020-11-15T01:45:27.994916Z","shell.execute_reply":"2020-11-15T01:45:27.995547Z"},"papermill":{"duration":1.165662,"end_time":"2020-11-15T01:45:27.995736","exception":false,"start_time":"2020-11-15T01:45:26.830074","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, ShuffleSplit, GridSearchCV\n\n# Modeling\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\n\n# Metrics\nfrom sklearn.metrics import r2_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.034366,"end_time":"2020-11-15T01:45:28.065585","exception":false,"start_time":"2020-11-15T01:45:28.031219","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 2. Download data<a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:28.141621Z","iopub.status.busy":"2020-11-15T01:45:28.140823Z","iopub.status.idle":"2020-11-15T01:45:28.149617Z","shell.execute_reply":"2020-11-15T01:45:28.148839Z"},"papermill":{"duration":0.049942,"end_time":"2020-11-15T01:45:28.149747","exception":false,"start_time":"2020-11-15T01:45:28.099805","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Download training data\ntrain = pd.read_csv('/kaggle/input/ammonium-prediction-in-river-water/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:28.307151Z","iopub.status.busy":"2020-11-15T01:45:28.303062Z","iopub.status.idle":"2020-11-15T01:45:28.320298Z","shell.execute_reply":"2020-11-15T01:45:28.319656Z"},"papermill":{"duration":0.067867,"end_time":"2020-11-15T01:45:28.320439","exception":false,"start_time":"2020-11-15T01:45:28.252572","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Display the first 5 rows of the training dataframe.\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:28.414751Z","iopub.status.busy":"2020-11-15T01:45:28.413804Z","iopub.status.idle":"2020-11-15T01:45:28.418103Z","shell.execute_reply":"2020-11-15T01:45:28.418852Z"},"papermill":{"duration":0.058454,"end_time":"2020-11-15T01:45:28.419015","exception":false,"start_time":"2020-11-15T01:45:28.360561","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Information for training data\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:28.497209Z","iopub.status.busy":"2020-11-15T01:45:28.496104Z","iopub.status.idle":"2020-11-15T01:45:28.502646Z","shell.execute_reply":"2020-11-15T01:45:28.501888Z"},"papermill":{"duration":0.047569,"end_time":"2020-11-15T01:45:28.502775","exception":false,"start_time":"2020-11-15T01:45:28.455206","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Download test data\ntest = pd.read_csv('../input/ammonium-prediction-in-river-water/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:28.666744Z","iopub.status.busy":"2020-11-15T01:45:28.665815Z","iopub.status.idle":"2020-11-15T01:45:28.669959Z","shell.execute_reply":"2020-11-15T01:45:28.669332Z"},"papermill":{"duration":0.05535,"end_time":"2020-11-15T01:45:28.670098","exception":false,"start_time":"2020-11-15T01:45:28.614748","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Display the 7 last rows of the training dataframe\ntest.tail()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:28.759252Z","iopub.status.busy":"2020-11-15T01:45:28.758472Z","iopub.status.idle":"2020-11-15T01:45:28.762504Z","shell.execute_reply":"2020-11-15T01:45:28.761922Z"},"papermill":{"duration":0.052347,"end_time":"2020-11-15T01:45:28.76263","exception":false,"start_time":"2020-11-15T01:45:28.710283","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.036681,"end_time":"2020-11-15T01:45:28.836398","exception":false,"start_time":"2020-11-15T01:45:28.799717","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 3. EDA & FE & Preprocessing data<a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### 3.1. Statistics & FE<a class=\"anchor\" id=\"3.1\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"papermill":{"duration":0.036429,"end_time":"2020-11-15T01:45:28.909704","exception":false,"start_time":"2020-11-15T01:45:28.873275","status":"completed"},"tags":[]},"cell_type":"markdown","source":"The analysis showed that many values are only available in stations 1 and 2, while others have much less data. I propose select only these two stations."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:28.993432Z","iopub.status.busy":"2020-11-15T01:45:28.992486Z","iopub.status.idle":"2020-11-15T01:45:29.025218Z","shell.execute_reply":"2020-11-15T01:45:29.024388Z"},"papermill":{"duration":0.078914,"end_time":"2020-11-15T01:45:29.025351","exception":false,"start_time":"2020-11-15T01:45:28.946437","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Select the stations with the most data in training dataset\ntrain = train.drop(['Id','3','4','5','6','7'], axis = 1)\ntrain = train.dropna().reset_index(drop=True)\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:29.184802Z","iopub.status.busy":"2020-11-15T01:45:29.183995Z","iopub.status.idle":"2020-11-15T01:45:29.204016Z","shell.execute_reply":"2020-11-15T01:45:29.203289Z"},"papermill":{"duration":0.06654,"end_time":"2020-11-15T01:45:29.204157","exception":false,"start_time":"2020-11-15T01:45:29.137617","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Display the statistics for training data\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EDA with Pandas Profiling\npp.ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:29.286768Z","iopub.status.busy":"2020-11-15T01:45:29.285761Z","iopub.status.idle":"2020-11-15T01:45:29.289226Z","shell.execute_reply":"2020-11-15T01:45:29.288491Z"},"papermill":{"duration":0.046731,"end_time":"2020-11-15T01:45:29.289359","exception":false,"start_time":"2020-11-15T01:45:29.242628","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Selecting a target featute and removing it from training dataset\ntarget = train.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:29.374989Z","iopub.status.busy":"2020-11-15T01:45:29.374164Z","iopub.status.idle":"2020-11-15T01:45:29.377439Z","shell.execute_reply":"2020-11-15T01:45:29.37672Z"},"papermill":{"duration":0.050089,"end_time":"2020-11-15T01:45:29.377563","exception":false,"start_time":"2020-11-15T01:45:29.327474","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Select the stations with the most data in test dataset\ntest = test.drop(['Id','3','4','5','6','7'], axis = 1)\ntest = test.dropna().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TASK:** Make EDA for the test dataset by Pandas Profiling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# EDA with Pandas Profiling\npp.ProfileReport(test)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:29.541739Z","iopub.status.busy":"2020-11-15T01:45:29.540909Z","iopub.status.idle":"2020-11-15T01:45:29.544265Z","shell.execute_reply":"2020-11-15T01:45:29.545309Z"},"papermill":{"duration":0.054285,"end_time":"2020-11-15T01:45:29.545519","exception":false,"start_time":"2020-11-15T01:45:29.491234","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Display basic information about the test data\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Data standartization<a class=\"anchor\" id=\"3.2\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standartization data\nscaler = StandardScaler()\ntrain = pd.DataFrame(scaler.fit_transform(train), columns = train.columns)\n\n# Display training data\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the statistics for training data\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TASK:** Standardize the test dataset with the same scaler and display it"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standartization data\ntest = pd.DataFrame(scaler.transform(test), columns = test.columns)\n# Display test\ndisplay(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TASK:** Display the statistics for test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the statistics for training data\ntest.describe()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.038092,"end_time":"2020-11-15T01:45:29.623279","exception":false,"start_time":"2020-11-15T01:45:29.585187","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**It is important to make sure** that all features in the training and test datasets:\n* do not have missing values (number of non-null values = number of entries of index) \n* all features have a numeric data type (int8, int16, int32, int64 or float16, float32, float64)."},{"metadata":{},"cell_type":"markdown","source":"**ADDITIONAL TASK:** Try use RobustScaler or MinMaxScaler instead of StandardScaler and to analyze what is the difference for accuracy of models will be below."},{"metadata":{"trusted":true},"cell_type":"code","source":"trainAdd = pd.read_csv('../input/ammonium-prediction-in-river-water/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standartization data\nrScaler = RobustScaler()\n\ntrainAdd = pd.DataFrame(rScaler.fit_transform(trainAdd), columns = trainAdd.columns)\n# Display training data\ntrainAdd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3. Training data splitting<a class=\"anchor\" id=\"3.3\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training data splitting to new training (part of the all training) and validation data\ntrain_all = train.copy()\ntarget_all = target.copy()\ntrain, valid, target_train, target_valid = train_test_split(train_all, target_all, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display information about new training data\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TASK:** Display information about validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display information about validation data\nvalid.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ADDITIONAL TASK:** Try use other values in the parameter test_size above: 0.1, 0.15, 0.3, 0.5 and to analyze what is the difference for accuracy of models will be below."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4. Cross-validation of training data<a class=\"anchor\" id=\"3.4\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross-validation of training data with shuffle\ncv_train =  KFold(n_splits=5, shuffle=False, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ADDITIONAL TASKS:** \n1. Set number of splitting = 5, 7, 10 and to compare of results.\n2. Try use another method for cross-validation of training data (without shuffle):\n\n        KFold(n_splits=5, shuffle=False, random_state=0)"},{"metadata":{"papermill":{"duration":0.038505,"end_time":"2020-11-15T01:45:29.700451","exception":false,"start_time":"2020-11-15T01:45:29.661946","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## 4. Modeling<a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creation the dataframe with the resulting score of all models\nresult = pd.DataFrame({'model' : ['Decision Tree Regressor', 'Random Forest Regressor', 'XGBoost Regressor'], \n                       'train_score': 0, 'valid_score': 0, 'y_train':  [[], [], []], 'y_val':  [[], [], []], 'y_test':  [[], [], []]})\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Для подальшого використання та оптимізації коду створено функцію, що універсалізує запуск моделей\n#Функція на виході дає результати розрахунку за певною моделлю для трейнової, валідаційної та тестової вибірок. \n\ndef get_model(train, valid, target_train, target_valid, model_name, name, param_grid, cv_train, result):\n    model = model_name\n    grid = GridSearchCV(model,\n                        param_grid,\n                        cv = cv_train,\n                        verbose=False)\n    grid.fit(train, target_train)\n    \n    # Prediction for training data\n    y_train = grid.predict(train)\n    print(grid.best_params_)\n    \n    # Accuracy of model\n    r2_score_acc = round(r2_score(target_train, y_train)*100,1)\n    print(f'Accuracy of {name} model training is {r2_score_acc}')\n    \n    result.loc[result['model'] == name, 'train_score'] = r2_score_acc\n    result.at[result.loc[result['model'] == name].index[0], 'y_train'] = y_train\n    \n    # Print rounded r2_score_acc to 2 decimal values after the text\n    y_val = grid.predict(valid)\n    r2_score_acc_valid = round(r2_score(target_valid, y_val)*100,1)\n    result.loc[result['model'] == name, 'valid_score'] = r2_score_acc_valid\n    result.at[result.loc[result['model'] == name].index[0], 'y_val'] = y_val\n    \n    print(f'Accuracy of {name} model prediction for valid dataset is {r2_score_acc_valid}')\n    \n    result.at[result.loc[result['model'] == name].index[0], 'y_test'] = grid.predict(test)\n    return result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.1. Decision Tree Regressor<a class=\"anchor\" id=\"4.1\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:29.850728Z","iopub.status.busy":"2020-11-15T01:45:29.849419Z","iopub.status.idle":"2020-11-15T01:45:29.860094Z","shell.execute_reply":"2020-11-15T01:45:29.859465Z"},"papermill":{"duration":0.121163,"end_time":"2020-11-15T01:45:29.860255","exception":false,"start_time":"2020-11-15T01:45:29.739092","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"decision_tree = DecisionTreeRegressor()\nparam_grid = {'min_samples_leaf': [i for i in range(5,10)], 'max_depth': [i for i in range(3,12)]}\nresult = get_model(train, valid, target_train, target_valid, decision_tree ,'Decision Tree Regressor', param_grid, cv_train, result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2. Random Forest Regressor<a class=\"anchor\" id=\"4.2\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor()\nparam_grid = {'n_estimators': [10, 100, 500], 'min_samples_leaf': [i for i in range(5,10)], \n              'max_features': ['auto'], 'max_depth': [i for i in range(4,6)], \n              'criterion': ['mse'], 'bootstrap': [False]}\nresult = get_model(train, valid, target_train, target_valid, rf ,'Random Forest Regressor', param_grid, cv_train, result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3. XGBoost Regressor<a class=\"anchor\" id=\"4.3\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ADDITIONAL TASK:** Add the XGBRegressor model (the same commands as in 4.1 and 4.2 adapted to the library xgb). Please see example in the notebooks: \n* [BOD prediction in river - 15 regression models](https://www.kaggle.com/vbmokin/bod-prediction-in-river-15-regression-models)\n* [XGBRegressor with GridSearchCV](https://www.kaggle.com/jayatou/xgbregressor-with-gridsearchcv)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost Regressor\nxgb = XGBRegressor(verbosity=0)\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['reg:linear'],\n              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n              'max_depth': [5, 6, 7],\n              'min_child_weight': [4],\n              'silent': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [0.7],\n              'n_estimators': [500]}\nresult = get_model(train, valid, target_train, target_valid, xgb ,'XGBoost Regressor', param_grid, cv_train, result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ADDITIONAL TASKS:** \n1. Add to dataframe result also calculated array: y_train, y_val.\n2. Creation the function with all commands and output information (in each section of this chapter 4) for all models:\n\n        result = get_model(train, valid, target_train, target_valid, model_name, param_grid, cv_train, result)"},{"metadata":{},"cell_type":"markdown","source":"## 5. Visualization<a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"**TASK:** Building plot for prediction for the valid data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building plot for prediction for the valid data \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TASK:** Building plot for prediction for the test data."},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:30.896636Z","iopub.status.busy":"2020-11-15T01:45:30.894538Z","iopub.status.idle":"2020-11-15T01:45:31.138038Z","shell.execute_reply":"2020-11-15T01:45:31.138898Z"},"papermill":{"duration":0.302709,"end_time":"2020-11-15T01:45:31.139095","exception":false,"start_time":"2020-11-15T01:45:30.836386","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Building plot for prediction for the test data \n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-15T01:45:30.366449Z","iopub.status.busy":"2020-11-15T01:45:30.365673Z","iopub.status.idle":"2020-11-15T01:45:30.687523Z","shell.execute_reply":"2020-11-15T01:45:30.688267Z"},"papermill":{"duration":0.370909,"end_time":"2020-11-15T01:45:30.688476","exception":false,"start_time":"2020-11-15T01:45:30.317567","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def plot_prediction(result, type_plot, target_train=[]):\n    if (type_plot == 'training'):\n        result_type = 'y_train'\n        result_title = 'Prediction for the training data'\n    if (type_plot == 'validation'):\n        result_type = 'y_val'\n        result_title = 'Prediction for the validation data'\n    if (type_plot == 'testing'):\n        result_type = 'y_test'\n        result_title = 'Prediction for the testing data'\n    x = np.arange(len(result.at[0, result_type]))\n    plt.figure(figsize=(16,10))\n    if (type_plot != 'testing'):\n        plt.scatter(x, target_train, label = \"Target data\", color = 'g')\n    plt.scatter(x, result.at[0, result_type], label = \"Decision Tree prediction\", color = 'b')\n    plt.scatter(x, result.at[1, result_type], label = \"Random Forest prediction\", color = 'y')\n    plt.scatter(x, result.at[2, result_type], label = \"XGB prediction\", color = '#17becf')\n    plt.plot(x, np.full(len(result.at[0, result_type]), 0.5), label = \"Maximum allowable value\", color = 'r')\n    plt.title(result_title)\n    plt.legend(loc='best')\n    plt.grid(True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_prediction(result, 'training', target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_prediction(result, 'validation', target_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_prediction(result, 'testing')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ADDITIONAL TASKS:** \n1. Add to dataframe result also calculated array: y_test.\n2. Add the line with XGBRegressor model prediction (train, valid, test take from the dataframe result).\n3. Creation the function with all commands and output information for all models (for type_plot = 'training', 'valid' or 'test'):\n\n        plot_prediction(result, type_plot='training')"},{"metadata":{},"cell_type":"markdown","source":"## 6. Select the best model <a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display results of modeling\nresult.sort_values(by=['valid_score', 'train_score'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select models with minimal overfitting\nresult_best = result[(result['train_score'] - result['valid_score']).abs() < 5]\nresult_best.sort_values(by=['valid_score', 'train_score'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the best model\nresult_best.nlargest(1, 'valid_score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find a name of the best model (with maximal valid score)\nbest_model_name = result_best.loc[result_best['valid_score'].idxmax(result_best['valid_score'].max()), 'model']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'The best model is \"{best_model_name}\"')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}