{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv',encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'] , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rename(columns={'v1':'label',\n                     'v2':'message'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_coding(row):\n    if row ==\"ham\":\n        return 0\n    return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'] = data['label'].apply(label_coding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\npunc=string.punctuation\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\nfrom nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer()\n\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_processing(row):\n    #converting to lowercase\n    _row=row.lower()\n    #Removing Punctuation\n    _row=\"\".join([x for x in _row if x not in punc])\n    #Removing stopwords\n    _row=\" \".join([word for word in str(_row).split() if word not in stop_words])\n    #Stemming\n    _row = \" \".join([stemmer.stem(word) for word in _row.split()])\n    #Lemmatization\n    _row = \" \".join([lemmatizer.lemmatize(word) for word in _row.split()])\n    #Split\n    _row = _row.split()\n    return _row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = data['message'].apply(pre_processing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX=data['text']\n\ny=data['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\nimport time\n# Skip-gram model (sg = 1)\nsize = 100\nwindow = 3\nmin_count = 1\nworkers = 3\nsg = 1\n\nOUTPUT_FOLDER=\"\"\n\nword2vec_model_file = OUTPUT_FOLDER + 'word2vec_' + str(size) + '.model'\nstart_time = time.time()\nstemmed_tokens = pd.Series(data['text']).values\n# Train the Word2Vec Model\nw2v_model = Word2Vec(stemmed_tokens, min_count = min_count, size = size, workers = workers, window = window, sg = sg)\nprint(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\nw2v_model.save(word2vec_model_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n# Load the model from the model file\nsg_w2v_model = Word2Vec.load(word2vec_model_file)\n\n# Unique ID of the word\nprint(\"Index of the word 'hi':\")\nprint(sg_w2v_model.wv.vocab[\"hi\"].index)\n\n# Total number of the words \nprint(len(sg_w2v_model.wv.vocab))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store the vectors for train data in following file\nword2vec_filename = OUTPUT_FOLDER + 'train_review_word2vec.csv'\nwith open(word2vec_filename, 'w+') as word2vec_file:\n    for index, row in enumerate(X.tolist()):\n        model_vector = (np.mean([sg_w2v_model[token] for token in row], axis=0)).tolist()\n        if index == 0:\n            header = \",\".join(str(ele) for ele in range(100))\n            word2vec_file.write(header)\n            word2vec_file.write(\"\\n\")\n        # Check if the line exists else it is vector of zeros\n        if type(model_vector) is list:  \n            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n        else:\n            line1 = \",\".join([str(0) for i in range(100)])\n        word2vec_file.write(line1)\n        word2vec_file.write('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_vectors=pd.read_csv('train_review_word2vec.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.33, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nmodel = XGBClassifier(max_depth=10,random_state=1,learning_rate=0.05,seed=1)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,accuracy_score\n\nprint(classification_report(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict probabilities\nprobs = model.predict_proba(X_test)\n\nprobs = probs[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate scores\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize scores\n\nprint(': ROC AUC=%.3f' % (auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate roc curves\nfpr, tpr, _ = roc_curve(y_test, probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\npyplot.plot(fpr, tpr, marker='.', label='ROC')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}