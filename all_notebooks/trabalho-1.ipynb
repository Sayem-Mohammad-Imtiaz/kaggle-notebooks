{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nfrom memory_profiler import memory_usage\nimport os\nfrom glob import glob\n\nimport IPython.display as ipd\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint \nfrom datetime import datetime \nfrom scipy.fftpack import fft,fftfreq\nimport numpy, scipy, matplotlib.pyplot as plt, sklearn, urllib, IPython.display as ipd\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Activation, Dense\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Divide a amostra em bases de treino, validação e teste\ndataset = pd.read_csv('../input/urbansound8k/UrbanSound8K.csv')\n\ndataset_size = len(dataset)\ntrain_size = int(dataset_size*0.7)\nvalid_size = int(dataset_size*0.15)\ntest_size = int(dataset_size*0.15)\n\nprint('train size: ' + str(train_size))\nprint('valid size: ' + str(valid_size))\nprint('test size: ' + str(test_size))\n\ntrain_data = dataset[0:train_size].copy().reset_index(drop=True)\nvalid_data = dataset[train_size:(train_size+valid_size)].copy().reset_index(drop=True)\ntest_data = dataset[(train_size+valid_size):(train_size+valid_size+test_size)].copy().reset_index(drop=True)\n\nprint(train_data.shape)\nprint(valid_data.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pegar apenas nome do arquivo\ntrain_data['slice_file_name'][0].split('.')[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#função utilizada para extrair as features\ndef extract_features(signal):\n    return [\n        librosa.feature.zero_crossing_rate(signal)[0, 0],\n        librosa.feature.spectral_centroid(signal)[0, 0],\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extrai features da amostra de treino\ntrain_features = []\nfulldatasetpath = '../input/urbansound8k/'\nfor _, row in tqdm(train_data.iterrows()):\n    filename = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    train_signals = librosa.load(filename) #faz a leitura do áudio\n\n    class_label = row[\"class\"] #salva qual a classe do audio\n\n    data = extract_features(train_signals[0]) #extrai as features\n    \n    train_features.append([data, class_label]) # salva dentro do test_features as features e a classe do audio, duas informacoes que sao necessarias para o treinamento","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extrai features da amostra de validação\nvalid_features = []\nfulldatasetpath = '../input/urbansound8k/'\nfor _, row in tqdm(valid_data.iterrows()):\n    filename = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    valid_signals = librosa.load(filename) #faz a leitura do áudio\n\n    class_label = row[\"class\"] #salva qual a classe do audio\n\n    data = extract_features(valid_signals[0]) #extrai as features\n    \n    valid_features.append([data, class_label]) # salva dentro do test_features as features e a classe do audio, duas informacoes que sao necessarias para o treinamento","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extrai features da amostra de test\ntest_features = []\nfulldatasetpath = '../input/urbansound8k/'\nfor _, row in tqdm(test_data.iterrows()):\n    filename = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    test_signals = librosa.load(filename) #faz a leitura do áudio\n\n    class_label = row[\"class\"] #salva qual a classe do audio\n\n    data = extract_features(test_signals[0]) #extrai as features\n    \n    test_features.append([data, class_label]) # salva dentro do test_features as features e a classe do audio, duas informacoes que sao necessarias para o treinamento","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizado para normalização\nscaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normaliza os dados de treino\nfeat_transf = []\nfeat_transf = scaler.fit_transform([f[0] for f in train_features])\n\ntrain_features_norm = []\nfor i in range(len(train_features)):\n    train_features_norm.append([feat_transf[i], train_features[i][1]])\ntrain_features_norm\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normaliza os dados de validação\nfeat_transf = []\nfeat_transf = scaler.fit_transform([f[0] for f in valid_features])\n\nvalid_features_norm = []\nfor i in range(len(valid_features)):\n    valid_features_norm.append([feat_transf[i], valid_features[i][1]])\nvalid_features_norm\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normaliza os dados de teste\nfeat_transf = []\nfeat_transf = scaler.fit_transform([f[0] for f in test_features])\n\n\ntest_features_norm = []\nfor i in range(len(test_features)):\n    test_features_norm.append([feat_transf[i], test_features[i][1]])\ntest_features_norm\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transformo os dados de treino em dataframe\ndf_train = pd.DataFrame({'v1':[],'v2':[],'classe':[]})\nfor i in range(len(train_features_norm)):\n    df_train = df_train.append({'v1': train_features_norm[i][0][0], 'v2': train_features_norm[i][0][1], 'classe': train_features_norm[i][1]}, ignore_index=True)\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transformo os dados de validação em data frame\ndf_valid = pd.DataFrame({'v1':[],'v2':[],'classe':[]})\nfor i in range(len(valid_features_norm)):\n    df_valid = df_valid.append({'v1': valid_features_norm[i][0][0], 'v2': valid_features_norm[i][0][1], 'classe': valid_features_norm[i][1]}, ignore_index=True)\ndf_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transformo os dados de teste em dataframe\ndf_test = pd.DataFrame({'v1':[],'v2':[],'classe':[]})\nfor i in range(len(test_features_norm)):\n    df_test = df_test.append({'v1': test_features_norm[i][0][0], 'v2': test_features_norm[i][0][1], 'classe': test_features_norm[i][1]}, ignore_index=True)\ndf_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.classe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# utilizo o label enconder em cada uma das três amostras\n\nle = LabelEncoder()\ntrain_classes_encoder_int = le.fit_transform(df_train.classe)\nvalid_classes_encoder_int = le.fit_transform(df_valid.classe)\ntest_classes_encoder_int = le.fit_transform(df_test.classe)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classes_encoder = keras.utils.to_categorical(train_classes_encoder_int)\nvalid_classes_encoder = keras.utils.to_categorical(valid_classes_encoder_int)\ntest_classes_encoder = keras.utils.to_categorical(test_classes_encoder_int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(train_classes_encoder[190])\n#(df_test.classe[190])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# modelo utilizado com as 10 categorias de resposta com função de ativação softmax e loo categorical crossentropy\ndef get_dense_model(num_features):\n    dnn_model = Sequential()\n    dnn_model.add(Dense(256, activation='relu', input_shape=(num_features,)))\n    dnn_model.add(Dropout(0.2))\n    dnn_model.add(Dense(256, activation='relu'))\n    dnn_model.add(Dropout(0.2))\n    dnn_model.add(Dense(256, activation='relu'))\n    dnn_model.add(Dropout(0.2))\n    dnn_model.add(Dense(10))\n    dnn_model.add(Activation('softmax'))\n\n    dnn_model.compile(loss='categorical_crossentropy', optimizer='adam',                 \n                      metrics=['accuracy'])\n    return dnn_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_dense_model(2)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = df_train[['v1','v2']]\ndata_valid = df_valid[['v1','v2']]\ndata_test = df_test[['v1','v2']]\n\n# train_classes_encoder\nlen(data_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_treino = keras.utils.to_categorical(train_classes_encoder, num_classes=10, dtype='float32')\ntrain_classes_encoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_treino = tf.keras.utils.to_categorical(y, num_classes=None, dtype='float32')\nbatch_size = 32\nSTEP_SIZE_TRAIN=len(data_train)//batch_size\nSTEP_SIZE_VALID=len(data_valid)//batch_size\nmodel.fit(x=data_train, y=train_classes_encoder, steps_per_epoch = STEP_SIZE_TRAIN, \n          validation_data=(data_valid,valid_classes_encoder), validation_steps = STEP_SIZE_VALID, epochs=20, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TEST=len(data_test)//batch_size\nmodel.evaluate(x=data_test, y=test_classes_encoder, steps=STEP_SIZE_TEST, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predito_teste = model.predict(x=data_test)\npredito_teste","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input/audio-1'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Parte de predição de exemplos**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pega os arquivos de exemplo\nexe1_train_signals = librosa.load('../input/audio-1/exemplo.wav')\nexe2_train_signals = librosa.load('../input/audio-2/exemplo2.wav')\nexe3_train_signals = librosa.load('../input/audio-3/exemplo3.wav')\n\n# Extrai as fitures deles\nexe1_data = extract_features(exe1_train_signals[0])\nexe2_data = extract_features(exe2_train_signals[0])\nexe3_data = extract_features(exe3_train_signals[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# estranho\nexe2_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_exe1_data = pd.DataFrame({'v1':[exe1_data[0]],'v2':[exe1_data[1]]})\ndf_exe2_data = pd.DataFrame({'v1':[exe2_data[0]],'v2':[exe2_data[1]]})\ndf_exe3_data = pd.DataFrame({'v1':[exe3_data[0]],'v2':[exe3_data[1]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Previsão exemplo 1\nmodel.predict(df_exe1_data)# Equivale a dog_bark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Previsão exemplo 2\nmodel.predict(df_exe2_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Previsão exemplo 3\nmodel.predict(df_exe3_data)# Equivale a dog_bark","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}