{"cells":[{"metadata":{},"cell_type":"markdown","source":"***Importing the required libraries***"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# for visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#for data preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n#for selecting the best feature effecting the target variable\nfrom sklearn.feature_selection import SelectKBest,chi2\n# for splitting the data into train and test dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVR\n# regression metrics\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Load the dataset***"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('../input/singapore-airbnb/listings.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Taking a look at the dataset ***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Checking the data types of all the features***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Dropping the unnecessary columns***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(['id','name','host_name','host_id','last_review'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_matrix=dataset.corr()\nsns.heatmap(correlation_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Here we can see that 'number_of_reviews' and 'reviews_per_month' are correlated with each other and hence one of them must be dropped in order to get better results from our model.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(['reviews_per_month'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Checking for missing values***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Checking for  univariate outliers using boxplot***"},{"metadata":{"trusted":true},"cell_type":"code","source":"names=['latitude','longitude','price','minimum_nights','number_of_reviews','calculated_host_listings_count','availability_365']\nplt.figure(figsize=(10,9))\nfor i in range(1,8):\n    \n    plt.subplot(2,4,i)\n    fig=dataset.boxplot(column=names[i-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Checking the distribution of each numerical feature to decide the method of detecting outliers for each of them ***"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nfor j in range(1,8):\n    plt.subplot(2,4,j)\n    sns.distplot(dataset[names[j-1]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***For all those who following a normal distribution they can use 'Z-Score' method for detecting outliers***"},{"metadata":{"trusted":true},"cell_type":"code","source":"#for latitude\nstd=np.std(dataset['latitude'])\nmean=np.mean(dataset['latitude'])\nmedian=np.median(dataset['latitude'])\noutliers=[]\nfor x in dataset['latitude']:\n    zscore=(x-mean)/std\n    if zscore>abs(3):\n        outliers.append(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(outliers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Removing the outliers by imputing them with median value***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_new=dataset.replace(outliers,median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nplt.subplot(1,2,1)\nfig=sns.distplot(dataset['latitude'])\nplt.title('before removing outliers')\nplt.subplot(1,2,2)\nfig2=sns.distplot(dataset_new['latitude'])\nplt.title('after removing outliers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for longitude\nstd=np.std(dataset['longitude'])\nmean=np.mean(dataset['longitude'])\nmedian=np.median(dataset['longitude'])\noutliers=[]\nfor x in dataset['longitude']:\n    zscore=(x-mean)/std\n    if -3<zscore>3:\n        outliers.append(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(outliers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for minimum_nights\nq1=dataset['minimum_nights'].quantile(0.25)\nq3=dataset['minimum_nights'].quantile(0.75)\noutlier=[]\niqr=q3-q1\nlower_bound=q1-(1.5*iqr)\nupper_bound=q3+(1.5*iqr)\nfor i in dataset['minimum_nights']:\n    if i<lower_bound or i>upper_bound:\n            outlier.append(i)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(outlier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.countplot(outlier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here we can see that after '365' there is a sudden increase in number of minimum nights which is not desirable as the hosts at air-bnb provide a maximum of one year stay in the form of rent to the visitors i.e of 365 days.\n* So all the values above 365 are considered as outliers. For eg : 1000 number of minimum nights is next to impossible.\n* Such values are supposed to get filtered out."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_new=dataset[dataset['minimum_nights']<=365]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nplt.subplot(1,2,1)\nsns.boxplot(dataset['minimum_nights'])\nplt.title('before removing outliers')\nplt.subplot(1,2,2)\nsns.boxplot(dataset_new['minimum_nights'])\nplt.title('after removing outliers')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Now the scale of values has been changed and after filtering out the outlier values we get a maximum of 365 number of nights***"},{"metadata":{"trusted":true},"cell_type":"code","source":"#for calculated_host_listings_count\nq1=dataset['calculated_host_listings_count'].quantile(0.25)\nq3=dataset['calculated_host_listings_count'].quantile(0.75)\noutlier=[]\niqr=q3-q1\nlower_bound=q1-(1.5*iqr)\nupper_bound=q3+(1.5*iqr)\nfor i in dataset['calculated_host_listings_count']:\n    if i<lower_bound or i>upper_bound:\n            outlier.append(i)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(outlier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(outlier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***These values of detected as outliers according to upper and lower bound rule are not outliers as values like '274','203','157' and '141' can be a count of host listings on air-bnb. So these values are left untouched.***"},{"metadata":{},"cell_type":"markdown","source":"***Now looking for the categorical features in the dataset ***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_new['room_type'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***As there are only three levels of categories in 'room_type' feature we can map them with certain values***"},{"metadata":{"trusted":true},"cell_type":"code","source":"mappings={'Entire home/apt':1,'Private room':2,'Shared room':3}\ndataset_new['room_type']=dataset_new['room_type'].map(mappings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_new['neighbourhood'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dataset_new['neighbourhood'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***As there are total 43 levels in 'neighbourhood' feature we can go for Binary Encoder so as to prevent dimensionality reduction by using one hot encoding***"},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\nbinary=ce.BinaryEncoder(cols=['neighbourhood'])\ndataset_new=binary.fit_transform(dataset_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_new.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Now splitting the dataset into dependent and independent features ***"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=dataset_new.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,13,14,15]].values\ny=dataset_new.iloc[:,12:13].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['neighbourhood_group'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***As there are 5 levels and the values are nominal type we can perform label encoding***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# In the ndarray of independent features 'neighbourhood_group' is at 0th position\nlabel=LabelEncoder()\nx[:,0]=label.fit_transform(x[:,0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***After converting all the features into numeric form we can check which indenpendent features are best effecting the target feature i.e. 'price'***"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_features=SelectKBest(score_func=chi2,k=5)\nfit=best_features.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(['neighbourhood_group', 'neighbourhood_0', 'neighbourhood_1',\n       'neighbourhood_2', 'neighbourhood_3', 'neighbourhood_4',\n       'neighbourhood_5', 'neighbourhood_6', 'latitude', 'longitude',\n       'room_type','minimum_nights', 'number_of_reviews',\n       'calculated_host_listings_count', 'availability_365'])\nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']\nresult=featureScores.nlargest(5,'Score')\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.barplot(x=result['Specs'],y=result['Score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Here we can see that 'calculated_host_listings_count' and 'minimum_nights' are the features that mostly affect our target variable (feature) i.e. 'price'***"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***As the features are not having linear relationship with each other we cant use linear regression model.Instead we can go for SVR.***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling the features is necessary to implement svr \nsc_x=StandardScaler()\nsc_y=StandardScaler()\nx=sc_x.fit_transform(x)\ny=sc_y.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Splitting into train and test data***"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Fitting the train data to the model and making out the predictions ***"},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor=SVR(kernel='rbf')\nregressor.fit(x_train,y_train)\npredictions=regressor.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict=pd.DataFrame(predictions)\nytest=pd.DataFrame(y_test)\nresultant=pd.concat([predict,ytest],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultant.columns=['Predicted_values','Actual_values']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultant.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae=mean_absolute_error(y_test,predictions)\nrmse=sqrt(mean_squared_error(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Usually mae ranges from 0 to infinity and lower the value better are the predictions.\n* So a value of 0.33 indicates that the model can give good predictions "},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***RMSE is always much higher than the mean absolute error(mae) as they are the squared values of error.***"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}