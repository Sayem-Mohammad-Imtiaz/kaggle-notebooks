{"cells":[{"metadata":{"_uuid":"5acc25ed3440ead516896dda2a13c9bd3c933f9c"},"cell_type":"markdown","source":"## 用决策树来分类贷款是否优良"},{"metadata":{"_uuid":"2d396134bd21c5eaf6fb37c24425fb64f4dcf86c"},"cell_type":"markdown","source":"[LendingClub](https://www.lendingclub.com/) 是一家贷款公司. 在本次作业中,我们需要手动实现决策树来预测一份贷款是否安全，并对比不同复杂度下决策树的表现  \n\n![alt text](./notebook_image/lc.jpg)"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"ff576785e84c2e72862103a0f680e9bd25cca3e1"},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn import metrics\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ba483e8f1e9956bac5cd98d36ab4f7e5212cdbe"},"cell_type":"markdown","source":"## 读取数据"},{"metadata":{"trusted":false,"_uuid":"46f71f53fc11294eb04e047c0d896270b3e2337a"},"cell_type":"code","source":"data = pd.read_csv(os.path.join(\"data\", \"loan_sub.csv\"), sep=',')\n#data = pd.read_csv(os.path.join(\"../input\", \"loan_sub.csv\"), sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ddd27974537dc372c8a3857ecfb54b3f3cee583"},"cell_type":"markdown","source":"## 打印可用特征"},{"metadata":{"trusted":false,"_uuid":"4a5620bf61040267c3f55d1ef0d1c554079581ce"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63761b72baea4ba2ad3abbd592efce05ee5e6f33"},"cell_type":"markdown","source":"## 预处理预测目标\n\n预测目标是一列'bad_loans'的数据。其中**1**表示的是不良贷款，**0**表示的是优质贷款。\n\n将预测目标处理成更符合直觉的标签，创建一列 `safe_loans`. 并且: \n\n* **+1** 表示优质贷款, \n* **-1** 表示不良贷款. "},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"8be6c1aadfa642ceef6e1ea580aafc6c555758b0"},"cell_type":"code","source":"# safe_loans =  1 => safe\n# safe_loans = -1 => risky\n#TODO\ndata['safe_loans'] = data['bad_loans'].apply(lambda x: +1 if x == 0 else -1)\ndata = data.drop('bad_loans', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91c64a497b4d98f0bb7622698b463d82a8e58904"},"cell_type":"markdown","source":"## 打印优质贷款与不良贷款的比例"},{"metadata":{"trusted":false,"_uuid":"2e1d8c4d555098944e1457b052fda4e3f032b4b8"},"cell_type":"code","source":"data['safe_loans'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a64a03c3a0ab725a1e156f7bd7d8ea798cb1bf3"},"cell_type":"markdown","source":"#### 这是一个不平衡数据， 好的贷款远比坏的贷款要多. "},{"metadata":{"_uuid":"6f5bfe0b2f873aa941a09b8a13291a936a22ab5a"},"cell_type":"markdown","source":"## 选取用于预测的特征"},{"metadata":{"trusted":false,"_uuid":"50923c2ef5e93bff5376f3252378f81c6b3b3579"},"cell_type":"code","source":"cols = ['grade', 'term','home_ownership', 'emp_length']\ntarget = 'safe_loans'\n\ndata = data[cols + [target]]#TODO\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"152b254be61699d44bce3975037651b6c057197d"},"cell_type":"markdown","source":"## 创建更为平衡的数据集  \n\n* 对占多数的标签进行下采样  \n* 注意有很多方法处理不平衡数据，下采样只是其中之一"},{"metadata":{"trusted":false,"_uuid":"7dc40e7628d5ac01e1bcc3a69be3582f6e3519ac"},"cell_type":"code","source":"data['safe_loans'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"2001350ccbfa29cb747c3a3f5e12c48c6f1f066e"},"cell_type":"code","source":"\n# use the percentage of bad and good loans to undersample the safe loans.\nbad_ones = data[data[target] == -1]# TODO\nsafe_ones = data[data[target] == 1]# TODO\npercentage = len(bad_ones) / float(len(safe_ones))#TODO\n\nrisky_loans = bad_ones\nsafe_loans = safe_ones.sample(frac=percentage, random_state=33)#TODO\n\n# combine two kinds of loans\ndata_set = pd.concat([risky_loans, safe_loans], axis=0)#TODO","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbb41631463ba9a83a42b83cf3e78c25f370f6e0"},"cell_type":"markdown","source":"Now, let's verify that the resulting percentage of safe and risky loans are each nearly 50%."},{"metadata":{"trusted":false,"_uuid":"a5e70938c64b33e8d09ee5e99e8bf29e37aaf016"},"cell_type":"code","source":"data_set[target].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24665a9f2bc9e3657bff05ccfc7b6c9e55480067"},"cell_type":"markdown","source":"## Preprocessing your features"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"944eb72042f53ffd41763ce56b71b8724c93bfb0"},"cell_type":"code","source":"def label_encode(data, columns=['pclass','name_title','embarked', 'sex']):\n    for col in columns:\n        data[col] = data[col].apply(lambda x: str(x))\n        new_cols = [col + '_' + i for i in data[col].unique()]\n        data = pd.concat([data, pd.get_dummies(data[col], prefix=col)[new_cols]], axis=1)\n        del data[col]\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"caed85b5cc743d1359956ba9ca38df913000112b"},"cell_type":"code","source":"#grade, home_ownership, target\ncols = ['grade', 'term','home_ownership', 'emp_length']\ndata_set = label_encode(data_set, columns=cols)#TODO\ndata_set.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c4d2fd4cb280330c365e7332ddf52c2a8fa5894"},"cell_type":"markdown","source":"## 将数据分成训练集和测试集"},{"metadata":{"_uuid":"6fbdcbb4f2872b68951f57741d2dc84f0c543b0d"},"cell_type":"markdown","source":"重要的事情说三遍!!  \n\n**把你的爪子从TEST DATA上拿开!!**   \n**把你的爪子从TEST DATA上拿开!!**  \n**把你的爪子从TEST DATA上拿开!!**  \n"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"f9c43b45e5acb622cc65f769e7bfe1a35c785a25"},"cell_type":"code","source":"train_data, test_data = train_test_split(data_set, test_size=0.2, random_state=33)#TODO\ntrainX, trainY = train_data[train_data.columns[1:]], pd.DataFrame(train_data[target])#TODO\ntestX, testY = test_data[test_data.columns[1:]], pd.DataFrame(test_data[target])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"1d59a86f1b5872260b771b82918540fc12ed8507"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2eaa6d3e51a4f4ad0ffedd1db8ebc7a123150d71"},"cell_type":"markdown","source":"## 建自己的决策树!  \n\n任务：  \n1 实现根据error来选择最佳划分特征的函数best_split()  \n2 实现根据entropy来选择最佳特征的函数best_split_entropy()  \n3 实现树节点的类TreeNode  \n4 实现模型的类MyDecisionTree  "},{"metadata":{"_uuid":"4b567b81d708bd810e3678430de96e7c151fc851"},"cell_type":"markdown","source":"#### 任务1(Optional)， 实现根据error来选择最佳划分特征的函数best_split()  \n约定树的左边对应target == 0， 树的右边对应target == 1"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"112cc32cbdc90092060c718efa6c39ee23b610aa"},"cell_type":"code","source":"def count_errors(labels_in_node):\n    \n    \"\"\"\n    Input: (Numpy Array/Pandas series)labels in node, eg: [-1,-1,1,-1,1]\n    Output: (Int) if we do the major class voting, how many errors we make?\n    \"\"\"\n    if len(labels_in_node) == 0:\n        return 0\n    \n    positive_ones = #TODO\n    negative_ones = #TODO\n    \n    return # TODO\n\n\ndef best_split(data, features, target):\n    \"\"\"\n    We want to select out the best feature such that it splits the data best based on your measurement(IG/accuracy)\n    Input: (Pandas DataFrame)data\n           (List of String) features  candidates we can choose feature from\n           (String) target  the target name we shoot for. eg: 'safe_loan' \n           \n    Output: (String) the best feature\n    \"\"\"\n    # return the best feature\n    best_feature = None\n    best_error = 2.0 \n    num_data_points = float(len(data))  \n\n    for feature in features:\n        \n        # 左分支对应当前特征为0的数据点\n        left_split = # TODO\n        \n        # 右分支对应当前特征为1的数据点\n        right_split = #TODO\n        \n        # 计算左边分支里犯了多少错\n        left_misses = #TODO            \n\n        # 计算右边分支里犯了多少错\n        right_misses = #TODO\n            \n        # 计算当前划分之后的分类犯错率\n        error = #TODO\n\n        # 更新应选特征和错误率，注意错误越低说明该特征越好\n        if error < best_error:\n            best_error = #TODO\n            best_feature = #TODO\n    return best_feature","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27965db44d0d6e8563d1220bca54f2593553e099"},"cell_type":"markdown","source":"#### 任务2， 实现根据entropy来选择最佳特征的函数best_split_entropy()  \n"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"031ea923b32683d8871f4362edf3efee7dc02eaa"},"cell_type":"code","source":"def entropy(labels_in_node):\n    # 二分类问题: 0 or 1\n    \"\"\"\n    input: labels_in_node should be an array of 0,1  eg [0,0,1,0,1,0..]\n    #####\n    output: the entropy of the array\n    \"\"\"\n    n = len(labels_in_node)\n    s1 = (labels_in_node==1).sum()\n    if s1 == 0 or s1 == n: # indicates the labels are the same~\n        return 0\n    \n    p1 = float(s1) / n\n    p0 = 1 - p1\n    return -p0 * np.log2(p0) - p1 * np.log2(p1)\n\n\ndef best_split_entropy(data, features, target):\n    \"\"\"\n    We want to select out the best feature such that it splits the data best based on your measurement(IG/accuracy)\n    Input: (Pandas DataFrame)data\n           (List of String) features  candidates we can choose feature from\n           (String) target  the target name we shoot for. eg: 'safe_loan' \n           \n    Output: (String) the best feature\n    \"\"\"    \n    best_feature = None\n    best_info_gain = float('-inf') \n    num_data_points = float(len(data))\n    # 计算划分之前数据集的整体熵值\n    entropy_original = entropy(data[target])#TODO\n\n    for feature in features:\n        \n        # 左分支对应当前特征为0的数据点\n        left_split = #TODO\n        \n        # 右分支对应当前特征为1的数据点\n        right_split = #TODO \n        \n        # 计算左边分支的熵值\n        left_entropy = #TODO           \n\n        # 计算右边分支的熵值\n        right_entropy = #TODO\n            \n        # 计算左边分支与右分支熵值的加权和（数据集划分后的熵值）\n        entropy_split = #TODO\n        \n        # 计算划分前与划分后的熵值差得到信息增益\n        info_gain = #TODO\n\n        # 更新最佳特征和对应的信息增益的值\n        if info_gain > best_info_gain:\n            best_info_gain = info_gain\n            best_feature = feature\n    return best_feature\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75fe62b46303f1ceb10d2e5d447bcdfc6d01b278"},"cell_type":"markdown","source":"#### 任务3，实现树节点的类TreeNode，每个树节点应该包含如下信息:  \n\n   3.1 is_leaf: True/False  表示当前节点是否为叶子节点  \n   \n   3.2 prediction: 当前节点做全民公投的预测结果\n   \n   3.3 left: 左子树  \n   \n   3.4 right: 右子树 \n   \n   3.5 split_feature: 当前节点用来划分数据时所采用的特征"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0d6423391338b7d0ba121dd116e56ab168265f4b"},"cell_type":"code","source":"class TreeNode:\n    def __init__(self, is_leaf, prediction, split_feature):\n    # TODO\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"588986c1a79de57a28eaea1c89d3411ad55d33a4"},"cell_type":"markdown","source":"#### 任务4，实现模型的类MyDecisionTree， 实现如下主要函数  \n  \n  \n   4.1 fit(): 模型在训练集上的学习  \n   \n   4.2 predict(): 模型在数据集上的预测\n   \n   4.3 score(): 模型在测试集上的得分   \n   \n   \n   \n   \n   为了实现4.1 - 4.3的方法， 需要实现如下辅助函数  \n   4.4 create_tree(): 创建一棵树  \n   \n   4.5 create_leaf(): 创建叶子节点  \n   \n   4.6 predict_single_data(): 模型预测单个数据  \n   \n   4.7 count_leaves(): 统计模型的叶子数"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"8e9639de6ae0506719d306aa5ee412969d5424f3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"7116dd71d9f9a8712edf580ad4fa7b30aa6fab30"},"cell_type":"code","source":"from sklearn.base import BaseEstimator\nfrom sklearn.metrics import accuracy_score\nclass MyDecisionTree(BaseEstimator):\n    \n    def __init__(self, max_depth, min_error):\n        self.max_depth = max_depth\n        self.min_error = min_error\n    \n    def fit(self, X, Y, data_weights = None):\n\n        \n        \n        data_set = pd.concat([X, Y], axis=1)\n        features = #TODO\n        target = Y.columns[0]\n        self.root_node = self.create_tree(data_set, features, \n                               target, current_depth = 0, max_depth = self.max_depth, min_error=self.min_error)\n    \n    def create_tree(self, data, features, target, current_depth = 0, max_depth = 10, min_error=0):\n        \"\"\"\n        Input\n            data: (pandas data frame) the input data\n            features: (pandas series/dataframe/numpy array) available features\n            target: (pandas series/dataframe/numpy array)  the target to predict\n            current_depth: (Int)  current depth of the tree\n            max_depth: (Int)  the maximum depth of the tree\n            min_error: (Float) the minimum error reduction  \n            \n        Output:\n            (TreeNode)  root        \n        \"\"\"\n        #探索三种不同的终止划分数据集的条件  \n  \n        #termination 1, 当错误率降到min_error以下, 终止划分并返回叶子节点  \n        #termination 2, 当特征都用完了, 终止划分并返回叶子节点  \n        #termination 3, 当树的深度等于最大max_depth时, 终止划分并返回叶子节点\n\n        \n    \n        # 拷贝可用特征\n        remaining_features = #TODO\n\n        target_values = # TODO\n\n        \n        \n        #################\n        #  第一部分： 递归出口！\n        #################\n        # termination 1   bonus task\n        #if count_errors(target_values) <= min_error:\n        #    print(\"Termination 1 reached.\")     \n        #    return # TODO\n\n        # termination 2\n        if len(remaining_features) == 0:\n            print(\"Termination 2 reached.\")    \n            return #TODO    \n\n        # termination 3\n        if current_depth >= max_depth: \n            print(\"Termination 3 reached.\")\n            return self.create_leaf(target_values)\n\n\n        \n        \n        #################\n        #  第二部分： 如果继续划分，划分数据集！\n        #################\n        \n        # 选出最佳当前划分特征\n        #split_feature = # TODO   #根据正确率划分   bonus task\n        split_feature = # TODO  # 根据信息增益来划分\n\n        # 选出最佳特征后，该特征为0的数据分到左边，该特征为1的数据分到右边\n        left_split = # TODO\n        right_split = # TODO\n\n        # 剔除已经用过的特征\n        remaining_features = # TODO\n        print(\"Split on feature %s. (%s, %s)\" % (split_feature, str(len(left_split)), str(len(right_split))))\n\n        # 如果当前数据全部划分到了一边，直接创建叶子节点返回即可\n        if len(left_split) == len(data):\n            print(\"Perfect split!\")\n            return self.create_leaf(left_split[target])\n        if len(right_split) == len(data):\n            print(\"Perfect split!\")\n            return self.create_leaf(right_split[target])\n\n        # 递归上面的步骤\n        left_tree = # TODO     \n        right_tree = # TODO\n        \n        \n        #################\n        #  第三部分： 左右递归完之后，把当前结果返回！\n        #################\n        \n        #生成当前的树节点\n        result_node = TreeNode(False, None, split_feature)\n        result_node.left = left_tree\n        result_node.right = right_tree\n        return result_node    \n    \n    \n    \n    def create_leaf(self, target_values):\n        \"\"\"\n        Input\n        target_values: (pd frame/numpy array)  eg: [1,1,-1,1,-1,-1,1]\n        ####\n        Output:\n        leaf :  class TreeNode(is_leaf, prediction, split_feature)   \n        \"\"\"\n        # 用于创建叶子的函数\n\n        # 初始化一个树节点\n        leaf = # TODO\n\n        # 统计当前数据集里标签为+1和-1的个数，较大的那个即为当前节点的预测结果\n        num_positive_ones = #TODO\n        num_negative_ones = #TODO\n\n        if num_positive_ones > num_negative_ones:\n            leaf.prediction = 1\n        else:\n            leaf.prediction = -1\n\n        # 返回叶子        \n        return leaf     \n    \n    \n        \n    def predict(self, X):\n        \n        \"\"\"\n        Input:  (Pandas DataFrame/Numpy array, size: m * n) a matrix and each row indicates a data point\n        Output: (Pandas DataFrame/Numpy array, size: m * 1) array of the predicted result\n        \n        Tips: each row is predicted by the function predict_single_data()\n        \"\"\"\n        prediction = X.apply(lambda row: self.predict_single_data(self.root_node, row), axis=1)\n        return prediction\n    \n    \n    \n    def predict_single_data(self, tree, x, annotate = False):   \n        # 如果已经是叶子节点直接返回叶子节点的预测结果\n        \"\"\"\n        Input:  (TreeNode)  tree\n                (Pandas DataFrame) x  it's a single array or one row from a pandas dataframe (one data point)\n                (Bool)  annotate  if intermediate result is displayed\n        Output:  (Int)  -1 or 1 in our case\n        \"\"\"\n        \n        \n        if tree.is_leaf:\n            if annotate: \n                print(\"leaf node, predicting %s\" % tree.prediction)\n            return # TODO \n        else:\n            # 查询x对应当前节点特征的值\n            split_feature_value = x[tree.split_feature]# TODO\n\n            if annotate: \n                print(\"Split on %s = %s\" % (tree.split_feature, split_feature_value))\n            if split_feature_value == 0:\n                #如果x在该特征上的值为0，交给左子树来预测\n                return self.predict_single_data()# TODO\n            else:\n                #如果x在该特征上的值为1，交给右子树来预测\n                return self.predict_single_data()# TODO \n    \n    \n    \n        \n    def score(self, testX, testY):\n        target = testY.columns[0]\n        result = self.predict(testX)\n        return accuracy_score(testY[target], result)\n\n\n    def count_leaves(self):\n        return self.count_leaves_helper(self.root_node)\n    \n    def count_leaves_helper(self, tree):\n        # TODO\n    \n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"79152374b6d26c54094e42a9dc6e375af373a298"},"cell_type":"code","source":"m = MyDecisionTree(max_depth = 10, min_error = 1e-15)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"8167f0b30320e60862d3cf43d7e68b2f58afdd3d"},"cell_type":"code","source":"#m.fit(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"cd6c4bfbb089e95739d4dc3b89a61a50871ad03d"},"cell_type":"code","source":"#m.score(testX, testY)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"dad8776b65f56f6b51bb04f44454ecaf9c77f877"},"cell_type":"markdown","source":"### 决策树复杂度的探讨"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6f0a5f6635a64e62208169f77f6be60e1c4b7100"},"cell_type":"code","source":"#m.count_leaves()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f37c8bf5a94057de4527ac05ef6c44f8a772d25"},"cell_type":"markdown","source":"#### 探索不同树深度对决策树的影响  \n\n1 max_depth = 3  \n2 max_depth = 7  \n3 max_depth = 15\n"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0aea693742d0bb841beeb0dc5090d79a6cd0d60d"},"cell_type":"code","source":"model_1 = MyDecisionTree(max_depth=3, min_error = 1e-15)# TODO\nmodel_2 = MyDecisionTree(max_depth=7, min_error = 1e-15)# TODO\nmodel_3 = MyDecisionTree(max_depth=15, min_error = 1e-15)# TODO\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"d471e474c31b21309742f255a1a8b5a632d99bc4"},"cell_type":"code","source":"#model_1.fit(trainX, trainY)\n#model_2.fit(trainX, trainY)\n#model_3.fit(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c644f3eb230bc22b0b3c2917ef50c2af6b436649"},"cell_type":"code","source":"#print(\"model_1 training accuracy :\", model_1.score(trainX, trainY))\n#print(\"model_2 training accuracy :\", model_2.score(trainX, trainY))\n#print(\"model_3 training accuracy :\", model_3.score(trainX, trainY))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"5722b74f073d225d6eecade6701111fbe0799250"},"cell_type":"code","source":"#print(\"model_1 testing accuracy :\", model_1.score(testX, testY))\n#print(\"model_2 testing accuracy :\", model_2.score(testX, testY))\n#print(\"model_3 testing accuracy :\", model_3.score(testX, testY))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"253fd37bebb48b9481ed9b9c46d439c3f2098d6e"},"cell_type":"code","source":"#print(\"model_1 complexity is: \", model_1.count_leaves())\n#print(\"model_2 complexity is: \", model_2.count_leaves())\n#print(\"model_3 complexity is: \", model_3.count_leaves())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"942cb153551ee2838ed915993b3e41acbb52362d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"nbformat":4,"nbformat_minor":1}