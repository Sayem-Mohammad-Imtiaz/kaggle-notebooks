{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Thank you for visting my code. If there is anything missing or wrong, please feel free to inform me. Also like my page on fb: https://www.facebook.com/codemakerz\n\n\n#### Stay tuned for the more updates in the same notebook."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"../input\"))\n# LIKE US ON FB: https://www.facebook.com/codemakerz\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# load data\ndf = pd.read_csv(\"../input/googleplaystore.csv\", encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top n Columns using head()"},{"metadata":{"trusted":true},"cell_type":"code","source":"# So we got our dataset\ndf.head() \n# Here in our dataset we can see Result = 0, 1 that mean 1 mean selected celebrity has cancer and 0 means no cancer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can also mention the number of rows\ndf.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# so before visualization lets do some EDA. Exploratory data analysis.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find Out How Many Missing Values are There?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets find is there any missing values?\ndf.isnull().sum() # We can see in Rating we have 1474 missing values & 1 value in Type, 1 in content rating and others also","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get All the Column Names"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see the all columns names\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get All Column Datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the datatype of all the columns \ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get Column wise Record Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"# total number of records in dataset\ndf.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Describe() - Descriptive Statistic for Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary statistics. It will show you the summary statistic for all the numerical values\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Info Function to Get General Column Information"},{"metadata":{"trusted":true},"cell_type":"code","source":"# info is also used to see some important statistics for dataset.\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selection & Indexing"},{"metadata":{},"cell_type":"markdown","source":"#### Select Single Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will show you top 5 Name columns. As head return top 5\ndf.App.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can also do above same thing with array type\ndf[[\"App\"]].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Select Multiple Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# show multiple columns\ndf[[\"App\", \"Rating\"]].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Select Last 5 Records for Selected Columns (Use it same as head())"},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can also watch below 5 using tail\ndf[[\"App\", \"Rating\"]].tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## General Statistic - Mean, Median, Standard Deviation, Variance and Percentiles."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic statistics\nprint(\"Mean Age: \", df.Rating.mean())\nprint(\"Median Age: \", df.Rating.median())\nprint(\"Variance Age: \", df.Rating.var())\nprint(\"Standard Deviation Age: \", df.Rating.std())\nprint(\"25th Percentile of Age: \", df.Rating.quantile(.25))\nprint(\"50th Percentile of Age: \", df.Rating.quantile(.5))\nprint(\"75th Percentile of Age: \", df.Rating.quantile(.75))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Location Base Indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# position based indexing\n# We use iloc for this. Here we mention [row, cols] like this.\n# : as row means all the rows & 1:4 as columns means 1st index(2nd columns aqs index start from 0), 3rd column and 4th column. 4th index will not included/\ndf.iloc[:, 1:4].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# name based indexing\n# in below example we are using all the rows(:) and only Name and Age column.\n# you can use any indexing method but i usually prefer iloc. As i am more comfortable with indices.\ndf.loc[:,[\"App\", \"Rating\"]].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get Different Value Counts for Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets find out different type of Type column\ndf.Type.value_counts()\n# we can see the number of free and paid apps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Univariate distribution for Ratings using histogram. It will show the total number or app according to the ratings.\n# Total number of app acccording to  the ratings\nplt.figure(figsize= (15, 10));\n#plt.hist(x=df.Rating, color='c');\ndf.Rating.plot(kind=\"hist\", bins=30, color='c')\nplt.title(\"Univariate: Rating Histogram\");\nplt.xlabel(\"Rating\");\nplt.ylabel(\"Total Counts\");\nplt.xlim(right=6)\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets see how many categories are there and total number of apps grouped by category\ndf.Category.value_counts()\n# So it clearly show the count of apps for a particular category. value_counts() is very handly function for this.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# but really saying this data is not convincing... we can make it more appealing by plotting it.\n# lets plot it.\nplt.figure(figsize=(15,10))\ndf.Category.value_counts().plot(kind=\"bar\", rot=0, title=\"Pclass Vs Count\", color='c', );\nplt.xticks(rotation='vertical');\nplt.title(\"Category Vs App Count\")\nplt.xlabel(\"Category Name\")\nplt.ylabel(\"Count\")\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So now from above example we can see that mostly apps belongs to the family, games , tool category.\n# and beauty categroy app is least in number.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets plot the average rating of eah category.\ndf.groupby([\"Category\"]).Rating.mean()\n# We can see 1.9 category has a rating of 19.0.. which is not possible as our rating is out of 5.\n# So definitly it may be some data issue. Now what to do?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"Category\"] == '1.9'] # We can see Rating has a value of 19.0, which is not possible.\n# So we have two choices:\n# 1. Either we remove this row\n# 2. Correct this value.\n# i will not prefer removing row as it is the only row related to the category 1.9.\n# lets replace this value with average rating.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inplace will save your change to the original dataframe\ndf[\"Rating\"].replace(19.0, df.Rating.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now lets check again\ndf[df[\"Category\"] == '1.9'] # So we have finally replaced it to the average value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby([\"Category\"]).Rating.mean() # So we can see now average values are correct for all categries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\ndf.groupby([\"Category\"]).Rating.mean().plot(kind=\"bar\", rot=0, title=\"Pclass Vs Count\");\nplt.xticks(rotation='vertical');\nplt.xlabel(\"Category Name\")\nplt.ylabel(\"Avg. Rating\")\nplt.title(\"Category Vs Avg. Rating\")\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# so now we can see the average rating. As per our data average rating is almost same for all so bars are almost equal.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby([\"Category\", \"Installs\"]).Rating.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets find out how many apps are paid or free.\ndf.Type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10));\ndf.Type.value_counts().plot(kind=\"bar\");\nplt.xlabel(\"License Type\");\nplt.ylabel(\"Counts\")\nplt.title(\"License Type Vs Counts\")\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So from our above diagrame we can see we have huge number of free apps.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets try to find out the content rating.. that mean how many adult apps are there or how many non-adult apps.\ndf.columns # it will select content rating column\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Content Rating'].value_counts() # you can see we have 6 categories in content rating.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10), dpi=100, );\ndf[\"Content Rating\"].value_counts().plot(kind=\"bar\");\nplt.title(\"Content Vs Total Count\");\nplt.xlabel(\"Content Type\");\nplt.ylabel(\"Count\");\nplt.ylim(bottom=-10);\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actually you can see last two bars are almost hidden because the value is very less.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now lets see apps grouped by os version \ndf[\"Android Ver\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"Android Ver\"] == '1.0 and up'] # we can verify the above data by using this command. You can\n# simply replace the value of OS and get the number.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10));\nplt.xlabel(\"Anroid Version\");\nplt.ylabel(\"Total Apps\");\nplt.title(\"Android Version Vs Total Conts\");\ndf[\"Android Ver\"].value_counts().plot(kind=\"bar\");\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Android Ver\"].value_counts(normalize=True) # You can get the percentage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Genres\"].value_counts() # here can find all the genres.. Try its plot yourself","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets plot top 10 genres\nplt.figure(figsize=(15, 10));\ndf[\"Genres\"].value_counts().head(10).plot(kind=\"bar\");\n#df.groupby([\"Genres\"])..head(10).plot(kind=\"bar\");\nplt.title(\"Top 10 Genres\");\nplt.xlabel(\"Genres\");\nplt.ylabel(\"Count\");\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you can verify using below statement.\n# So found the genre wise installs\ndf[df[\"Genres\"] == 'Video Players & Editors;Music & Video']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to change the dtype of review but there is one column whih contains 3.0M\ndf.Reviews.replace(\"3.0M\", '3000000', inplace=True)\ndf[df.Reviews == \"3.0M\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Reviews = df.Reviews.astype(\"float\") # lets change the datatype of Ratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_new = df.groupby([\"Genres\", \"Category\"], as_index=False).sum()[[\"Genres\", \"Category\", \"Reviews\"]].sort_values(by=\"Reviews\", ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Below diagram shows the ;top 10 famous genres as per there review counts\nplt.figure(figsize=(15, 10));\nplt.title(\"Top 10 Most Reviewed Genres\");\nplt.xlabel(\"Genres\");\nplt.ylabel(\"Count\");\ndf_new.groupby(\"Genres\").Reviews.sum().sort_values(ascending=False).plot(kind='bar');\nplt.plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pandas Crosstabs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets find out category wise application type, how many free and paid apps are there in a category.\npd.crosstab(df[\"Category\"], df[\"Type\"]).apply(lambda r: r/r.sum(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AS we can see there is one app with type 0, which is obviously not the proper type. Lets fetch that row.\nindexNames = df[df[\"Type\"]== '0'].index # find the index\n# So we can see its pricing is also not there(everything) and installs section is free. So in this case this data seems to be improper.\n# as it doesnt have any exceptional infomrmation so we can remove this.\n# Delete these row indexes from dataFrame\ndf.drop(indexNames , inplace=True) # delete the row","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Crosstab Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df[\"Category\"], df[\"Type\"]).plot(kind=\"bar\",figsize=(15, 10));\nplt.plot();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handle missing values\ndf.isnull().sum() # we can see 4 columns have missing values. Lets start with Type","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Handle Missing Values"},{"metadata":{},"cell_type":"markdown","source":"#### Handle Missing Values in Type Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.Type.isnull()] # lets fetch first","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we can clearly see, its price is 0 that mean it is from free type. So we can replace it.\ndf.Type.fillna(\"Free\", inplace=True) # replaced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.Type.isnull()]  # No null values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handle Missing Values in \"Android Ver\" Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# now lets handle android version column missing values\ndf[df['Android Ver'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see we have android ver for both of the records. Lets see a crosstab for android ver and current ver\npd.crosstab(df[(df['Current Ver'] == '4.4')]['Current Ver'], df[(df['Current Ver'] == '4.4')][\"Android Ver\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df[(df['Current Ver'] == '4.4')]['Current Ver'], df['Android Ver']).plot(kind='bar', figsize=(15, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see there is last updated column, we canuse it to extact year and then we can find out which Andriod Version was popular at that time.\n# Seems like a good finding.\n# Lets create one function to extract year from the Last Updated.\ndef get_year(date):\n    year = date.split(',')[1]\n    year = year.strip()\n    return year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Last Updated\"].map(lambda x: get_year(x)) # we get the year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets create a new column for year\ndf[\"Year\"] = df[\"Last Updated\"].map(lambda x: get_year(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now lets plot crosstab for year and android ver\npd.crosstab(df[df[\"Year\"] == '2018'].Year, df[\"Android Ver\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df[df[\"Year\"] == '2018'].Year, df[\"Android Ver\"]).plot(kind='bar', figsize=(15, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# so we can see in year 2018 mostly app were using android version 4.1 and up. So this seems a fair analysis. Let replace with this value.\nmost_frequent_andoid = df['Android Ver'].value_counts().idxmax()\ndf[\"Android Ver\"].fillna(most_frequent_andoid, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check again for null values in android version\ndf[df[\"Android Ver\"].isnull()] # So no records... its done.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check again for null values in whole data frame\ndf.isnull().sum() # so we can see rating has a big number of missing values. Lets deal with it.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows  = 15  # it will display always 15 rows.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handle Missing Values in Rating Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets fetch all the missing value rows for Rating\ndf[df[\"Rating\"].isnull()] # there are total 1474 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #Lets get the median review according to genre and category\ndf.groupby([\"Genres\", \"Category\"]).Rating.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby([\"Genres\", \"Category\"]).Rating.median().plot(kind=\"bar\", figsize=(30, 10));\n# so we can see Ratings for all the genres and category are simillar. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets find out the median rating of total df\ndf.Rating.median() # in this case our median is also simillar to category and genres wise grouped data. so lets replace with this data only.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_rating = df.Rating.median()\ndf.Rating.fillna(median_rating, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.Rating.isnull()] # so finally we replaced all the missing values. Lets check it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() # so finally we got rid of missing values.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thank you for visting my code. If there is anything missing or wrong, please feel free to inform me. Also like my page on fb: https://www.facebook.com/codemakerz"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}