{"cells":[{"metadata":{"_uuid":"621816a669ad59231772cb28449f0a33f39b1fec"},"cell_type":"markdown","source":"# **SDG 2: No Hunger - Bees**\n\n#### **Reference:** https://www.nrdc.org/sites/default/files/bees.pdf\n\n* **Bees are** one of a myriad of other animals, including birds, bats, beetles, and butterflies, called **pollinators**. Pollinators transfer pollen and seeds from one flower to another, fertilizing the plant to it can grow and produce food. **Cross-pollination helps at least 30 percent of the world’s crops and 90 percent of our wild plants to thrive**. Without bees to spread seeds, many plants—including food crops—would die off.\n* BUT **Bee populations are shrinking** -  In the United States alone, more than 25 percent of the managed honey bee population has disappeared since 1990.\n\n### **Problem**: Could we help track the health of our bees by allowing farmers, beekeepers, anyone to accuratly asses the health of bees using their mobile phone. Can we build model to help accuratly classify bees as health or unhealthy?\n"},{"metadata":{"_uuid":"71684d5a434e1e0702d017772d859fa8efa46658"},"cell_type":"markdown","source":"### **Solution**: Using KERAS lets build a Convolutional Neural Network (CNN) to classify the bees. We'll use test accuracy as our metric."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#####################################\n# Libraries\n#####################################\n# Common libs\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\nimport sys\nimport os\nimport random\n\n# Image processing\nimport imageio\nimport skimage.io\nimport skimage.transform\n\n# Charts\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# ML\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPool2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\n\n\n#####################################\n# Settings\n#####################################\n\n# Set random seed to make results reproducable\nnp.random.seed(42)\ntensorflow.set_random_seed(42)\n\n# Global variables\nimg_folder='../input/bee_imgs/bee_imgs/'\n\n# plotting\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"608c1225539edf4dab52d143adb9176c7abff648"},"cell_type":"markdown","source":"# 1. Read in the Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"### READ IN BEE DATA AND FORMAT SOME COLUMNS\nbee_data = pd.read_csv(\"../input/bee_data.csv\", \n            parse_dates={'datetime': ['date', 'time']}, \n            dtype={'subspecies':'category', 'health':'category','caste':'category'})\n\nbee_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"308b3929f57d167ae4c2bf162a72541c03073430"},"cell_type":"markdown","source":"# 2. EDA\n## 2.1 Distribution of the classifications in the dataset"},{"metadata":{"trusted":true,"_uuid":"ca12a961e1cf023eb78c3103e5af4c13b1dae3a5"},"cell_type":"code","source":"f, ax = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n\nbee_data.subspecies.value_counts().plot(kind='bar',ax=ax[0, 0])\nax[0,0].set_ylabel('Count')\nax[0,0].set_title('Subspecies')\n\nbee_data.location.value_counts().plot(kind='bar', ax=ax[0, 1])\nax[0,1].set_title('Location')\nax[0,1].set_ylabel('Count')\n\nbee_data.caste.value_counts().plot(kind='bar', ax=ax[1, 0])\nax[1,0].set_title('Caste')\nax[1,0].set_ylabel('Count')\n\nbee_data.health.value_counts().plot(kind='bar', ax=ax[1,1])\nax[1,1].set_title('Health')\nax[1,1].set_ylabel('Count')\n\nf.subplots_adjust(hspace=0.7)\nf.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cfcacd7c9fd3d73ae7ff83d8edbb6eddb25515b"},"cell_type":"markdown","source":"## 2.2 Any missing Data?"},{"metadata":{"trusted":true,"_uuid":"8cccf64ed84fa1942940af3e8db5657020f1edd7"},"cell_type":"code","source":"### RECORDS WE HAVE IN THE CSV FILE\nprint(\"Number of records in CSV: {}\".format(bee_data.shape[0]))\n\n### RECORDS WITH EXISTING PHOTOS AVAILABLE\nimg_exists = bee_data['file'].apply(lambda f: os.path.exists(img_folder + f))\nbee_data = bee_data[img_exists]\nprint(\"Number of records with a photo available: {}\".format(bee_data.shape[0]))\n\n### PLOT MATRIX TO SEE IF HAVE ANY NaN RECORDS\nmsno.matrix(bee_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6023b49d649290ee974ff1ddb2ecc7a6c6c68123"},"cell_type":"markdown","source":"* No NaN - Thanks Jenny Yang and https://www.kaggle.com/jenny18/honey-bee-annotated-images for the clean dataset\n## 2.3 Look at photos of healthy bees and sick bees\n"},{"metadata":{"trusted":true,"_uuid":"5bce8ef6cf9622d288761a347b70c79435d11ba4"},"cell_type":"code","source":"### FUNCTION FOR PLOTTING IMAGES\n\ndef plot_image_grid(data, W, H, title=\"ADD A PLOT TITLE\"):\n    \n    #### VIEW IMAGES IN A GRID\n    W_grid = W\n    L_grid = H\n\n    fig, axes = plt.subplots(L_grid, W_grid, figsize = (17,10))\n\n    axes = axes.ravel() #flatten the 5x2 matrix into 10 array\n\n    for i in np.arange(0, W_grid * L_grid): # create evenly spaces variable\n\n        # select a random number\n        index = random.choice(data.index)\n\n        # read and display an image with the selected index\n        axes[i].imshow(skimage.io.imread(img_folder + data['file'][index]))\n        axes[i].set_title(data['health'][index], fontsize = 8)\n        axes[i].axis('off')\n\n    plt.suptitle(title)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c818555f245e42571129a07453e741da235a9f75"},"cell_type":"markdown","source":"### Healthy"},{"metadata":{"trusted":true,"_uuid":"f3b42e80acff467d5e91a01054c700f1c31362a2"},"cell_type":"code","source":"healthy = bee_data[bee_data['health'] == 'healthy']\n\nplot_image_grid(data = healthy, W=5, H=2, title=\"HEALTHY BEES\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00039450523f0e1d89ce8184bbe53c50350a5564"},"cell_type":"markdown","source":"### Sick"},{"metadata":{"trusted":true,"_uuid":"0e2e1d10b108cc7f089a9c390b4bfdd62c1b4d0f"},"cell_type":"code","source":"### first lets get the categories of \"unhealthy\"\nailments = bee_data['health'].cat.categories\nailments = [a for a in ailments if a != 'healthy']\n\nprint('Non healthy bees fall into these categories: ')\nprint(ailments)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa53188a89628b62b80f54817bf7e7bef0fc47a6"},"cell_type":"code","source":"### NOW LETS SAMPLE ACROSS EACH CATEGORY AND PLOT EXAMPLE IMAGES\nnon_healthy = pd.DataFrame()\nfor sickness in ailments:\n    non_healthy = non_healthy.append(bee_data[bee_data['health'] == sickness].sample(2))\nplot_image_grid(data = non_healthy, W=5, H=2, title=\"SICK BEES\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"969beef769dbfe9f7b58a169cc59df883806654b"},"cell_type":"markdown","source":"### 2.4 Image Shapes"},{"metadata":{"trusted":true,"_uuid":"eb34e5ba134be4d2448e51d5d641d3f19d00a024"},"cell_type":"code","source":"image_properties = pd.DataFrame()\n\nfor file in bee_data['file']:  \n    h,w,c = np.array(skimage.io.imread(img_folder + file)).shape\n    image_properties = image_properties.append([[h,w,c]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1736c915e146850a20976d77bb48b4b105a66715"},"cell_type":"code","source":"image_properties.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fc318d88fb22c2f3faf5f1ebacfda497ca88e41"},"cell_type":"markdown","source":"* Images have different sizes and so we'll have to deal with this when we load them in\n* We'll also need to make sure to normalize and perform som data augmentation\n"},{"metadata":{"_uuid":"7c1119f797abbfc39aa7b46be1d4f5081000f0d3"},"cell_type":"markdown","source":"## 3. Image (Data) Processing "},{"metadata":{"trusted":true,"_uuid":"1962921903314c1efba2aa8fc47450c5c20d6238"},"cell_type":"markdown","source":"#### Next Steps\n*  Load images\n*  Resize\n*  Normalize\n*  Transform\n* OHE the classes\n*  Train, dev, test split\n* Balance Train set\n\nFirst we can build some helper functions to do this"},{"metadata":{"trusted":true,"_uuid":"c2f18cac89eb181174064e903961927a6da8dcf9"},"cell_type":"code","source":"### SET THESE HERE SO EASY TO CHANGE LATER IF WE WANT TO\nimage_height = 100\nimage_width = 100\nimage_channels = 3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17359b27913d8b950af27ac0a43a7a8c811fd14a"},"cell_type":"markdown","source":" ### **3.1 Train, Dev, Test Split**"},{"metadata":{"trusted":true,"_uuid":"c7b8eb75c688d629b3f9b05df43fcce8e39f9615"},"cell_type":"code","source":"def split_and_balance(dataset, balance_col):\n    \"\"\"\n    1. Split into our different data sets\n    2. Balance the training set for balance_col\n    \"\"\"\n    ### 70% data for train\n    data_train, data_dev = train_test_split(dataset, test_size=0.3, random_state=42)\n    ### 15% each for validation and testing\n    data_dev, data_test = train_test_split(data_dev, test_size=0.5, random_state=42)\n    \n    print (\"number of training examples = \" + str(data_train.shape[0]))\n    print (\"number of dev examples = \" + str(data_dev.shape[0]))\n    print (\"number of test examples = \" + str(data_test.shape[0]))\n    \n    \n    #### BALANCING - LETS NOT DO THIS ON FIRST RUN\n    #### ADD IT IN AS EXCERSIZE TO IMPROVE MODEL LATE\n    \n    #### ALSO WOULD BE GREAT TO PLOT THE BALANE BEFORE AND AFTER\n    \n    return data_train, data_dev, data_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59e1c256ed0b6389ef8d371e76082fa869bb021a"},"cell_type":"markdown","source":" ### **3.2 Get images OHE the Y values**"},{"metadata":{"trusted":true,"_uuid":"26208fb600e7c173bb47089a66f2c18c8f6c7e10"},"cell_type":"code","source":"### LOADING IMAGES\ndef load_images(file):\n    \"\"\"\n    Given a file name it will load the images in the correct size.\n    \"\"\"\n    image = skimage.io.imread(img_folder + file)\n    image = skimage.transform.resize(image, (image_width, image_height), mode='reflect')\n    return image[:,:,:image_channels]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1be27a97ffde5d62f1901e94be84f63da97b0e5"},"cell_type":"code","source":"def data_prep(data_train, data_dev, data_test, target_col, normalize=True):\n    \"\"\"\n    1. Loads images into the train, dev, test sets\n    2. OHE the target col for train, dev and test sets\n    3. Normalize images\n    \"\"\"\n    num_cat = data_train[target_col].cat.categories\n    \n    ### TRAINING DATA\n    X_train = np.stack(data_train['file'].apply(load_images))\n    y_train = pd.get_dummies(data_train[target_col], drop_first=False)\n    \n    ### DEV DATA\n    X_dev = np.stack(data_dev['file'].apply(load_images))\n    y_dev = pd.get_dummies(data_dev[target_col], drop_first=False)\n    \n    ### TEST DATA\n    X_test = np.stack(data_test['file'].apply(load_images))\n    y_test = pd.get_dummies(data_test[target_col], drop_first=False)\n    \n    ### NORMALIZE THE FEATURES (ASSUME 255)\n    if normalize:\n        X_train = X_train / 255\n        X_dev = X_dev / 255\n        X_test = X_test / 255\n        \n    #### NOT DOING GENERATOR TO TRANSFORM  / AUGMENT THE DATA\n    #### ADD THIS IN LATER ITERATION\n    \n    print (\"number of training examples = \" + str(X_train.shape[0]))\n    print (\"number of dev examples = \" + str(X_dev.shape[0]))\n    print (\"number of test examples = \" + str(X_test.shape[0]))\n    \n    print (\"\\nnumber of clategories for classifier = \" + str(num_cat.shape[0]))\n    print(num_cat)\n    \n    print (\"\\nX_train shape: \" + str(X_train.shape))\n    print (\"Y_train shape: \" + str(y_train.shape))\n    \n    print (\"\\nX_dev shape: \" + str(X_dev.shape))\n    print (\"\\nY_dev shape: \" + str(y_dev.shape))\n    \n    print (\"\\nX_test shape: \" + str(X_test.shape))\n    print (\"\\nY_test shape: \" + str(y_test.shape))\n    \n    return X_train, X_dev, X_test, y_train, y_dev, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87d07bde63289c812caa695122a45a6331ecf47f"},"cell_type":"markdown","source":" ### **3.3 Putting it all together**    \n"},{"metadata":{"trusted":true,"_uuid":"d1cca27d51b14243218632d772c932ea5e241e51"},"cell_type":"code","source":"data_train, data_dev, data_test = split_and_balance(bee_data, 'health')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54415935f3d2e8f0206b7fa4483100cb958b0c60"},"cell_type":"code","source":"data_train.dtypes\ndata_train['health'].cat.categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0555270332a2ac1d02bb9d2ebe7c7dd93283100c"},"cell_type":"code","source":"X_train, X_dev, X_test, y_train, y_dev, y_test = data_prep(data_train, data_dev, data_test, 'health', normalize=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fed67ba8cb69b2e2c9e5c6821d377fd3e4663ffe"},"cell_type":"markdown","source":"# 4. MODELLING"},{"metadata":{"trusted":true,"_uuid":"a7e72ce39feedd6612a641a277a8981df17846c1"},"cell_type":"code","source":"def BeesModel():\n\n    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n    model1=Sequential()\n    model1.add(Conv2D(6, kernel_size=3, input_shape=(image_width, image_height, 3), activation='relu', padding='same'))\n    model1.add(MaxPool2D(2))\n    model1.add(Conv2D(12, kernel_size=3, activation='relu', padding='same'))\n    model1.add(Flatten())\n    model1.add(Dense(y_train.columns.size, activation='softmax'))\n\n    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n\n    return model1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7309a21dc200f5d43752674889d8312413c10db4"},"cell_type":"code","source":"### INIITATE THE MODEL\nbeesModel = BeesModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0f52f011dafd2ba6c8d0ece6307f031eec38466"},"cell_type":"code","source":"### COMPILE THE MODEL\nbeesModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0ab786f2f3243f9474c2ceb7414c4460e558e3c","scrolled":true},"cell_type":"code","source":"### TRAIN THE MODEL\nrun_history_1 = beesModel.fit(x = X_train, y = y_train, validation_data=(X_dev, y_dev), epochs = 10,batch_size = 8, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ea3ffe9169c441c016cc2000d872cddda0a6b40"},"cell_type":"code","source":"# list all data in history\nprint(run_history_1.history.keys())\n\n# summarize history for accuracy\nplt.plot(run_history_1.history['acc'])\nplt.plot(run_history_1.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(run_history_1.history['loss'])\nplt.plot(run_history_1.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"609350adb134d1ebca02216cdfe910f12501a05f"},"cell_type":"code","source":"### function for plotting scores\n\ndef how_did_it_do(ml_model, X_dev, y_dev, use_model_dot_score=True, cf_matrix=True):\n    ## predict from dev set\n    y_pred = ml_model.predict(X_dev)\n    y_pred = np.argmax(y_pred, axis=1)\n    y_dev = np.argmax(y_dev.values, axis=1)\n    print(\"performance on X_dev:\")\n    \n    if use_model_dot_score:\n        # Accuracy\n        print(\"\\nAccuracy:\")\n        acc = round(ml_model.score(X_dev, y_dev), 3)\n        print(acc)\n    else:\n        print(\"\\nAccuracy score:\")\n        acc = round(accuracy_score(y_dev, y_pred), 3)\n        print(acc)    \n\n    # of predicted +ve, how many correct\n    print(\"Precision score:\")\n    prec = round(precision_score(y_dev, y_pred, average='macro'), 3)\n    print(prec)\n\n\n    # of all actual +ve how many did we get\n    print(\"Recall score:\")\n    rec = round(recall_score(y_dev, y_pred, average='macro'), 3)\n    print(rec)\n\n    # f1 combines\n    print(\"Global F1 score:\")\n    f1 = round(f1_score(y_dev, y_pred, average='macro'), 3)\n    print(f1)\n    \n    ### plot confusion matrix if needed\n    if cf_matrix:\n        cm = confusion_matrix(y_dev, y_pred.round())\n        df_cm = pd.DataFrame(cm, index = (0,1,2,3,4,5), columns=(0,1,2,3,4,5))\n        plt.figure(figsize = (10,7))\n        sns.set(font_scale=1.4)\n        sns.heatmap(df_cm, annot = True, fmt='g')\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n        plt.show()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d99a79205ea77f7ccc2150754187b9ed5046a1f"},"cell_type":"code","source":"how_did_it_do(beesModel, X_test, y_test, use_model_dot_score=False, cf_matrix=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73f74ab3dc19ccf582691049e983a726ae84439f"},"cell_type":"code","source":"data_dev['health'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8573e96f4e5a11984b76cc9f621204132cd8585"},"cell_type":"code","source":"data_dev['health'].cat.categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c4c18b5c804e660524261a0d1280be8374439bb"},"cell_type":"code","source":"y_pred = beesModel.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)\ntarget_names=y_test.columns\ny_test = np.argmax(y_test.values, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be78b64e35e0433d670296dce5cb52abf11528e1"},"cell_type":"code","source":"print(metrics.classification_report(y_test, y_pred, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65575502284a076857ab0f3bfa6165bcc0c002be"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7acacd9debfb059376451d44ff35d78095fd40b2"},"cell_type":"code","source":"\n\n\n#### VIEW IMAGES IN A GRID\nW_grid = 5\nL_grid = 2\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (17,10))\n\naxes = axes.ravel() #flatten the 5x2 matrix into 10 array\n\nfor i in np.arange(0, W_grid * L_grid): # create evenly spaces variable\n\n    # select a random number\n    #index = random.choice(data.index)\n\n    # read and display an image with the selected index\n    axes[i].imshow(X_test[i])\n    title = str(np.argmax(y_test.values, axis=1)[i]) + \" :\" + str(y_pred[i])\n    axes[i].set_title(title , fontsize = 8)\n    axes[i].axis('off')\n\nplt.suptitle(\"EXAMPLES FROM TEST SET\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a1579d6e8d73252fc45ee5a03ad9189a55a138a"},"cell_type":"code","source":"X_test[0:5].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"537770c5b15e785a165766f6868ff473d235b63e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}