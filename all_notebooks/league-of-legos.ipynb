{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n#Let's first examine the correlation in our dataset\n\nsns.heatmap(df.corr(),cmap=sns.diverging_palette(20, 220, n=200))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Next, let's see how correlated each of these are correlated with whether Blue team wins:\nplt.figure(figsize=(14,10))\nsns.barplot(y=df.corr()['blueWins'],x=df.columns)\nplt.xticks(rotation=70)\n\n#It's clear some of these are very correlated.  Let's examine these more closely, removing all the cases where correlation <0.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's just add a few intuitive features\n#Having a high number of kills can offset a high number of deaths.  This will give us a relative difference between kills and deaths\n#\ndf['blueKD']=df['blueKills']-df['blueDeaths']\n\n#redKD is redundant. A blueKD of 5 would imply a redKD of -5\n#df['redKD']=df['redKills']-df['redDeaths']\n\n\n\n\n\n#Let's also remove redKills and redDeaths.  These are redundant, since a blue kill corresponds to a red death\ndf=df.drop(['redKills'],axis=1)\ndf=df.drop(['redDeaths'], axis=1)\n\n#The differentials for red Team are also redundant, since it is the difference between (one is blue-red, other is red-blue)\ndf=df.drop(['redGoldDiff'],axis=1)\ndf=df.drop(['redExperienceDiff'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's go ahead and drop those features which are not very correlated\n\ndf.corr()['blueWins']\ncols=df.columns\nfor i,j in enumerate(df.corr()['blueWins']):\n    print (j)\n    if abs(j) < 0.25:\n        df=df.drop([cols[i]], axis=1)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I would like to make a barplot to examine the correlation. Some of these values need to be discretized. Let's look at redTotalGold:\n\nsns.distplot(df['redTotalGold'])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will discretize into bins using qcut\n\ndef truncgraph(values):\n    trunc=pd.qcut(values, 8)\n    return trunc\n\n\n#now, let's try to graph with a barplot\n\n\nsns.barplot(y=df['blueWins'],x=truncgraph(df['redTotalGold']))\nplt.xticks(rotation=70)\n    \n\n'''Clearly, if red team has very little gold after the first 10 minutes, they are very likely to lose. Conversely, if they get a lot of\ngold, they are very likely to win. Let's see this for the remaining features.\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here, we can examine those effects. Here, both the distributions are plotted and the barplots of each factor corresponding to the winrate\n#For instance, huge gold differences are great predictors, but typically the difference in gold is centered about zero.\n\nlen_plots=len(df.columns)\n\nplt.figure()\n#fig,axs=plt.subplots(17,2)\nplt.figure(figsize=(20,100))\nfor i,j in enumerate(df.columns):\n    #If there is a strong correlation:\n    if abs(df[j]).mean() > 10:\n        \n        \n        plt.subplot(len_plots,2,(2*i)+1)\n        sns.distplot((df[j]))\n        \n        \n        plt.subplot(len_plots,2,(2*i)+2)\n        sns.barplot(truncgraph(df[j]),y=df['blueWins'])\n        plt.xticks(rotation=10)\n        \n    else:\n        plt.subplot(len_plots,2,(2*i)+1)\n        sns.distplot((df[j]))\n        plt.subplot(len_plots,2,(2*i)+2)\n        sns.barplot(x=df[j],y=df['blueWins'])\n        plt.xticks(rotation=10)\n        #plt.show()\n              \n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\n#Now, let's see if we can predict who is going to win the game based off the first 10 minutes of gameplay.\n\n#Split into X and y\nX=df.drop(['blueWins'], axis=1)\ny=df['blueWins']\n\n#do a 80:20 train:test split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=13)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Scale the X values\nscaler=StandardScaler().fit(X_train)\nX_train_scaled=scaler.transform(X_train)\nX_test_scaled=scaler.transform(X_test)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n\n#I am going to use XGBoost for the learner. I am going to perform a 3-fold cross validation on the training set\n#to determine an decent set of hyperparameters\n\n#I have gone ahead and skipped the hyperparameter tuning part to make the notebook run faster, which has already been performed\n#Feel free to uncomment it \n\ndef hyperParameterTuning(X_train, y_train):\n    param_tuning = {\n        'reg_lambda': np.linspace(.01,2,10),\n        \n        'max_depth': [2,3,4],\n        'min_child_weight': [1,3,5],\n        'eta': [ 0.05 ],\n        'subsample': [ 0.8,1],\n        'colsample_bytree': [0.8,1],\n        'n_estimators' : [200],\n   \n    }\n\n    xgb_model = XGBClassifier()\n\n    gsearch = GridSearchCV(estimator = xgb_model,\n                           param_grid = param_tuning,                        \n                           scoring = 'accuracy', \n                           cv = 3,\n                           n_jobs = 1,\n                           verbose = 4)\n\n    gsearch.fit(X_train,y_train)\n\n    return gsearch#.best_params_,gsearch.best_estimator\n\n#model=hyperParameterTuning(X_train_scaled,y_train).best_estimator_\n#print (model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, eta=0.05, gamma=0,\n              gpu_id=-1, importance_type='gain', interaction_constraints='',\n              learning_rate=0.0500000007, max_delta_step=0, max_depth=2,\n              min_child_weight=5,  \n              n_estimators=200, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=0.01, scale_pos_weight=1, subsample=0.8,\n              tree_method='exact', validate_parameters=1, verbosity=None)\n\nmodel.fit(X_train_scaled,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here's the best estimator\n\n\n\nfrom sklearn.metrics import plot_confusion_matrix\nconfusion_matrix=plot_confusion_matrix(model,X_test_scaled,y_test, normalize='true')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like our accuracy is about ~71%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see our explanatory factors on what would lead to a victory or loss\nplt.figure(figsize=(14,10))\nsns.barplot(y=model.feature_importances_, x=X_train.columns)\nplt.xticks(rotation=80)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on our model, the biggest factor in predicting who will win after 10 minutes is the gold differential, followed by the experience differential.\n\nThis makes sense, as most of the other features tie into these.  When you get kills, you get gold and experience.\n\nUltimately, our model is able to predict with about 71% accuracy who will win the game after 10 minutes of game time.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}