{"cells":[{"metadata":{"_uuid":"5e558b93251decdca05f090a772372d9b8de2897"},"cell_type":"raw","source":"https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/version/2"},{"metadata":{"trusted":true,"_uuid":"061cd1ea6ea83193c14043f04bf36ab2aeeef2ad"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\nimport statsmodels.api as sm\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9e7d6c69f01179d78bb80e2a8bd51aa4d360cce"},"cell_type":"code","source":"bc = pd.read_csv('../input/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c3317fda7e675d851a37f383a4e78f48419b40a"},"cell_type":"code","source":"bc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b53b1ecce6e37cc606b88024fda0ee9d36b51014"},"cell_type":"code","source":"bc.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"2c73175f965c2b2f5286b1cbdc6d9fd398297053"},"cell_type":"code","source":"bc.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7a690349d3a00a2644dd3935cb027ad7854a532"},"cell_type":"raw","source":"Data Dictionary\n\n1) ID number \n2) Diagnosis (M = malignant, B = benign) \n3-32) \n\nTen real-valued features are computed for each cell nucleus: \n\na) radius (mean of distances from center to points on the perimeter) \nb) texture (standard deviation of gray-scale values) \nc) perimeter \nd) area \ne) smoothness (local variation in radius lengths) \nf) compactness (perimeter^2 / area - 1.0) \ng) concavity (severity of concave portions of the contour) \nh) concave points (number of concave portions of the contour) \ni) symmetry \nj) fractal dimension (\"coastline approximation\" - 1)"},{"metadata":{"trusted":true,"_uuid":"74575433570fc46d2c7da2f1a82723905210096e"},"cell_type":"code","source":"dum = pd.get_dummies(bc.diagnosis)\nbc = pd.concat([bc, dum], axis = 1)\nbc = bc.drop('diagnosis', axis = 1)\nbc = bc.drop('B', axis = 1)\nbc = bc.drop('Unnamed: 32', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aef16b7c8887184946a032846f6555b9b310f59a"},"cell_type":"code","source":"bc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"413ffeadf8fe1f1b79b603d21e5e2715f7a72d38"},"cell_type":"code","source":"bc.drop(['id'], axis = 1).hist(figsize = (14,14))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53ffadb990e2f06220a93bae32d70cfe68f8213d"},"cell_type":"code","source":"plt.figure(figsize = (12,10))\nsns.heatmap(bc.corr())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb4c1effbce8841e4a4672f358312aca487fc9d9"},"cell_type":"raw","source":"In the data set the concavity is a bulge (a rounded swelling or protuberance that distorts a flat surface - synonyms:\tswelling, bump, lump, protuberance) in the cell."},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"cc16e18d94b501ffb50cf3b8df6cabaab9040da1"},"cell_type":"code","source":"def num_densityplot():\n    for n in range(1, 31):\n        plt.subplot(9, 4, n)\n        bc.iloc[:, n].plot.kde()\n        plt.xlabel(bc.iloc[:, n].name)\n        \nplt.figure(figsize = (25, 60))\nnum_densityplot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca4835ea7c87a02af51cada90acfc23a4a096149"},"cell_type":"raw","source":"These plots are showing the distribtution of the data over a continuous interval."},{"metadata":{"trusted":true,"_uuid":"4b1518a900eccd1177565f04a8b373e0ccf5f81d"},"cell_type":"code","source":"bc2 = bc[['radius_mean','perimeter_mean','area_mean','concavity_mean',\n         'concave points_mean','radius_worst','perimeter_worst','area_worst',\n         'concave points_worst']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7faed9a46c88e176b2d903129e41a479f0f0ca01"},"cell_type":"code","source":"a = pd.plotting.scatter_matrix(bc2, figsize = (15, 10))\nplt.xticks(rotation = 45)\nplt.yticks(rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1e2a0117b9225ec4a7a064b4e7ccc59adebecd2"},"cell_type":"code","source":"sns.pairplot(bc, x_vars = bc2.columns[0: 4], y_vars = ['M'], kind = 'reg')\nplt.yticks([0.0, 1.0],['Benign', 'Malignant'])\nsns.pairplot(bc, x_vars = bc2.columns[4: ], y_vars = ['M'], kind = 'reg')\nplt.yticks([0.0, 1.0],['Benign', 'Malignant'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c01be1974b4bc53ef1ec4b789c8548f0d23cfba"},"cell_type":"raw","source":"We can observe that there is a direct correlation between the x variable and the tumor's malignancy.  The higher the x variable the greater diagnois of malignancy. "},{"metadata":{"trusted":true,"_uuid":"48ef63761cda49a81c776934fe0923285d5bafa5"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom xgboost import XGBClassifier\n\nfrom yellowbrick.classifier import ConfusionMatrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"040c20b534c250800b2ba3531d4802107ed3bfaa"},"cell_type":"code","source":"X = bc.drop(['id','M'], axis = 1).values\ny = bc.M","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fee82cd1f901e5da2a7d70c919128b56bca2dde5"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e7234973cac33e775d5be67a7754131f6830bc2"},"cell_type":"code","source":"def model_fit(x):\n    x.fit(X_train, y_train)\n    y_pred = x.predict(X_test)\n    model_fit.accuracy = accuracy_score(y_test, y_pred)\n    print('Accuracy Score',accuracy_score(y_test, y_pred))\n    print(classification_report(y_test, y_pred))\n    model_cm = ConfusionMatrix(\n    x, classes = ['Malignat', 'Benign'],\n    label_encoder = {1 : 'Malignat', 0 : 'Benign'})\n    model_cm.fit(X_train, y_train)\n    model_cm.score(X_test, y_test)\n    \n    model_cm.poof() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c456b25e0b407ef72c4639173d0f0ee0ecab55"},"cell_type":"code","source":"list = []\nfor i in range(1,10): \n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    \n    list.append(accuracy_score(y_test, y_pred))\n   \nfor n in range(0, len(list)):\n    if list[n] == max(list):\n        i = n+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a5531753acdb65d3765200f33f5b2d872645485"},"cell_type":"code","source":"model_fit(KNeighborsClassifier(n_neighbors = i))\nKNN = model_fit.accuracy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f17a3c7bc19d64b7dc0d8f3034311bc58a119cd8"},"cell_type":"raw","source":"We were able to see that 4, 5, and 7 was a better value giving us the highest score after using a loop using a range 1 to 10.  We will go with 7, choosing the odd number because it is advisable to take odd values for binary classification to avoid the ties (two class labels achieving the same score)."},{"metadata":{"_uuid":"f167f787b783f937708aa59e1688be1810a66763"},"cell_type":"raw","source":"We are now going to use the Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"32ecf85de8590a04fc33ca8e3b7481a0558f2d32"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66325d3cae1afc80c96d099381b4f45871763ce4"},"cell_type":"code","source":"model_fit(LogisticRegression())\nLogistic = model_fit.accuracy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4edb6d6e001a999a0a32a527cd64b7a8e030fdd"},"cell_type":"raw","source":"We will now be using the naive bayes model"},{"metadata":{"trusted":true,"_uuid":"140b4f7552af39173cfc46560be51753749a96c8"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2c1c311a095b07e6820785bf4e2edfe91461cf4"},"cell_type":"code","source":"model_fit(GaussianNB())\nGaussian = model_fit.accuracy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cb51364b128a5a4334429c7c2b0de2956fc2674"},"cell_type":"raw","source":"We will now make a new model - decsion tree"},{"metadata":{"trusted":true,"_uuid":"7bb402ab5d601d4b11fee1c5121252faf8618d94"},"cell_type":"code","source":"from sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d9736a5d1b07e4ec9eb214b3d06a190db66345f"},"cell_type":"code","source":"model_fit(tree.DecisionTreeClassifier())\nTree = model_fit.accuracy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56d413fb04ab547222319621ef7e3de2c76c6d03"},"cell_type":"raw","source":"We will now make a new model called random forest"},{"metadata":{"trusted":true,"_uuid":"4d8170e40d1236dec358e6412d0464d89e3fcff8"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"822ae95037402284b792ee8e55f072b1d21a4d08"},"cell_type":"code","source":"model_fit(RandomForestClassifier(n_estimators = 100, max_depth =10, random_state = 1))\nRandomForest = model_fit.accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"739f20f539c6450704ed9e38530badc3358a9156"},"cell_type":"code","source":"list=[]\nival = range(1, 100)\njval = range(1,100)\nfor i,j in zip(ival, jval): \n    clfr = RandomForestClassifier(n_estimators = i, max_depth = j, random_state = 1)\n    clfr.fit(X_train, y_train)\n    y_pred = clfr.predict(X_test)\n    \n    list.append((accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fb621b65717ce1c135d1c0a9dab21bf90daf686"},"cell_type":"code","source":"list = pd.DataFrame(list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d943a480448ec2b8e5bd8051533734109981cc2c"},"cell_type":"code","source":"list[list == list.max()].dropna().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4200db3a81790c4b8de2448aa67b8ed71617ef09"},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0bf30ef9ccaaab05d7d1ea63a485185cd680538"},"cell_type":"code","source":"model_fit(XGBClassifier())\nXGBClf = model_fit.accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"293274fa4864d0416a39ae0ed657007a35fd15e3"},"cell_type":"code","source":"scores_list_1 = ['KNN','Logistic','Gaussian','Tree','RandomForest','XGBClassifier']\nscores_1 = [KNN, Logistic, Gaussian, Tree, RandomForest, XGBClf]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"302fad2c4544dd7b666d93e45e3ad8aeb06ad03c"},"cell_type":"code","source":"score_df_classification = pd.DataFrame([scores_list_1, scores_1]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa2cbea51d4fae6f033ca4e97c8275a9375e6d38"},"cell_type":"code","source":"score_df_classification.index = score_df_classification[0]\ndel score_df_classification[0]\nscore_df_classification","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0125deaa7bf8f328f5f0d6beb78a743113489225"},"cell_type":"raw","source":"It appears that XGBClassifier is the best choice at 95.614%.  Using this model, we are able to predict a diagnsis of malignancy."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}