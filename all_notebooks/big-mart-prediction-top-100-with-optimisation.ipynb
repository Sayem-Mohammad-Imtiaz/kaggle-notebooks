{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#/kaggle/input/big-mart-sales-prediction/Submission.csv\n#/kaggle/input/big-mart-sales-prediction/Train.csv\n#/kaggle/input/big-mart-sales-prediction/Test.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Problem Statement\nThe data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and predict the sales of each product at a particular outlet.\n\nUsing this model, BigMart will try to understand the properties of products and outlets which play a key role in increasing sales.\n"},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/big-mart-sales-prediction/Train.csv')\ndf1=pd.read_csv('/kaggle/input/big-mart-sales-prediction/Test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outlet_Size'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outlet_Location_Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outlet_Size'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statistics import mode\ndf['Item_Weight'].fillna(df['Item_Weight'].mean(),inplace=True)\ndf['Outlet_Size'].fillna(mode(df['Outlet_Size']),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() #format are right","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Item_Fat_Content'].replace({'LF':'Low Fat','reg':'Regular','low fat':\"Low Fat\"},inplace=True) #check for outliers \n# and remove them","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Item_Fat_Content'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['Item_Weight'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Item_Visibility',y='Item_Visibility',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Item_Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['Item_MRP'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outlet_Identifier'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outlet_Establishment_Year'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outlet_Location_Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outlet_Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Item_Weight'].fillna(df1['Item_Weight'].mean(),inplace=True)\ndf1['Outlet_Size'].fillna(mode(df1['Outlet_Size']),inplace=True)\ndf1['Item_Fat_Content'].replace({'LF':'Low Fat','reg':'Regular','low fat':\"Low Fat\"},inplace=True) #check for outliers \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Item visibility and item sales outlet is left skewed is left skewed, we can use standard scalar for normalization\n\n2. as we can see in the plot they are not seperated by linear regression we can try decision tree, random forest or boosting technique to split the and predict data(using information gain or gini index) or SVR\n\n3. We can see that low sales has comparatively low visibility\n\n4. High MRP has comparatively low sales"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Item_Fat_Content',y='Item_Outlet_Sales',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean are almost the same for low fat and regular but regular has little more sales than lowfat"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,7))\nsns.barplot(x='Item_Type',y='Item_Outlet_Sales',data=df)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" soft drinks, baking goods, and health and hygene has comparatively low sales \n\nMeans of different item type are varying we can use it in our prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df[['Outlet_Establishment_Year','Outlet_Size','Outlet_Location_Type','Outlet_Type']].columns:\n    chart = sns.barplot(x=df[i], y=df['Item_Outlet_Sales'])\n    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outlet_Establishment_Year, Outlet_Size, Outlet_Location_Type and Outlet_Type has a good varying values \n1. Grocery store has a really low sales\n2. Teir has comparatively low sales \n3. 1998 we can see has low sales\n4. small size has comparatively low sales\n\nwe can look into it as to why is they have low sales and try to increase their saless"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is high correlation between mrp and sales we can clearly say that high mrp has low sales\n\nthere is very less correlation between outlet year and weight"},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[:,1:-1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=pd.get_dummies(df.iloc[:,1:-1])\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=pd.get_dummies(df1.iloc[:,1:])\ny_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\ny_train = sc.fit_transform(y_train)\n#X_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=df.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nX_sm  = sm.add_constant(X_train)\nmodel = sm.OLS(X_test,X_sm)\nmodel.fit().summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.model_selection import cross_val_score\n\nlm = LinearRegression()\nlm.fit(X_train, X_test)\n\nnp.mean(cross_val_score(lm,X_train,X_test, scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lasso regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = []\nerror = []\n\nfor i in range(1,200):\n    alpha.append(i/1)\n    lml = Lasso(alpha=(i/1))\n    error.append(np.mean(cross_val_score(lml,X_train,X_test, scoring = 'neg_mean_absolute_error', cv= 3)))\n    \nplt.plot(alpha,error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"err = tuple(zip(alpha,error))\ndf_err = pd.DataFrame(err, columns = ['alpha','error'])\ndf_err[df_err.error == max(df_err.error)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_l = Lasso(alpha=32.0)\nlm_l.fit(X_train,X_test)\nnp.mean(cross_val_score(lm_l,X_train,X_test, scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision tree, Random forest and boosting technique"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nRegressor = DecisionTreeRegressor(random_state = 0)\nRegressor.fit(X_train, X_test)\nnp.mean(cross_val_score(Regressor,X_train,X_test, scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(bootstrap=True, max_features=0.9,\n                           min_samples_leaf=18, min_samples_split=20, n_estimators=400,criterion='mse',max_depth=10.2,\n                           max_samples=5665)\nrf.fit(X_train, X_test)\nnp.mean(cross_val_score(rf,X_train,X_test,scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nmodel = XGBRegressor()\nmodel.fit(X_train, X_test)\nnp.mean(cross_val_score(model,X_train,X_test,scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\nclassifier = AdaBoostRegressor(\n    n_estimators=500\n)\nclassifier.fit(X_train, X_test)\nnp.mean(cross_val_score(classifier,X_train,X_test,scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nlr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1,1.01]\n\nfor learning_rate in lr_list:\n    gb_clf = GradientBoostingRegressor(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n    gb_clf.fit(X_train, X_test)\n\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf = GradientBoostingRegressor(n_estimators=200, learning_rate=1.01, max_features=2, max_depth=2, random_state=0)\ngb_clf.fit(X_train, X_test)\nnp.mean(cross_val_score(gb_clf,X_train,X_test,scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nextra1=sklearn.ensemble.ExtraTreesRegressor(bootstrap=True, max_features=0.8,\n                    min_samples_leaf=18, min_samples_split=6, n_estimators=100)\nextra1.fit(X_train,X_test)\nnp.mean(cross_val_score(extra1,X_train,X_test,scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As the accuracy of ExtraTreesRegressor fit the best we will use ExtraTreesRegressor "},{"metadata":{},"cell_type":"markdown","source":"### Used random searchcv and gridsearchcv for optimisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nextra=sklearn.ensemble.ExtraTreesRegressor(bootstrap=True, max_features=0.9,\n                    min_samples_leaf=18, min_samples_split=20, n_estimators=400,criterion='mse',max_depth=10.2,\n                                           max_samples=5665)\nextra.fit(X_train,X_test)\nnp.mean(cross_val_score(extra,X_train,X_test,scoring = 'neg_mean_absolute_error', cv= 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-756.0596882610718\n#-755.66193353781\n#-755.105940462904\ne=extra.predict(y_train)\ndf1['Item_Outlet_Sales']=e\ndf1[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']].to_csv('samplesub2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}