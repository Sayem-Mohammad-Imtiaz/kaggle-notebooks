{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Future Forecast With LSTM"},{"metadata":{},"cell_type":"markdown","source":"## Before Begin"},{"metadata":{},"cell_type":"markdown","source":"I took a job to predict the client's future effectiveness in real life. In my research, I came to the point that the best way to do this is LSTM. I wanted to make a beginner kernal patch about this. I hope my help will help other people. Let's start."},{"metadata":{},"cell_type":"markdown","source":"## Resources"},{"metadata":{},"cell_type":"markdown","source":"It is the first time that I am doing a project on future repairs and I have examined many resources. I leave three links for your review below.\n\n- [How to Use the TimeseriesGenerator for Time Series Forecasting in Keras](https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/)\n- [A Quick Example of Time-Series Prediction Using Long Short-Term Memory (LSTM) Networks](https://medium.com/swlh/a-quick-example-of-time-series-forecasting-using-long-short-term-memory-lstm-networks-ddc10dc1467d)\n- [Time Series Forecasting — ARIMA, LSTM, Prophet with Python](https://medium.com/@cdabakoglu/time-series-forecasting-arima-lstm-prophet-with-python-e73a750a9887)"},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom pandas.tseries.offsets import DateOffset\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loading And Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Let's load the data and observe the first five lines."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/air-passengers/AirPassengers.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We convert the `Month` variable to date type."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Month\"] = pd.to_datetime(data[\"Month\"])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We assign the month variable as index. We edit variable and index names."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.set_index(\"Month\", inplace=True)\ndata.columns = [\"passengers\"]\ndata.index.name = \"date\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can look at the summary of the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()\nprint(f\"Dataset shape: {data.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train And Test Split"},{"metadata":{},"cell_type":"markdown","source":"We reserve the last twelve months in the data for testing. We will train our model with the rest of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = data[:len(data)-12]\ntest_data = data[len(data)-12:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Scaling"},{"metadata":{},"cell_type":"markdown","source":"We scale the data between 0 and 1 for our LSTM model. We need to scale the data for all deep learning models."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(train_data)\ntrain = scaler.transform(train_data)\ntest = scaler.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Model"},{"metadata":{},"cell_type":"markdown","source":"We turn the data into a time series to train the LSTM model."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_input = 12\nn_features = 1\ngenerator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model consists of a 200-node LSTM layer, a 0.15 Dropout layer and a one-node Dense layer as the output layer. We use Adam as the optimizer and mean squares error as the loss method."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))\nmodel.add(Dropout(0.15))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit_generator(generator,epochs=90, verbose= 0)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After training our model, we prediction our test set and store it in an empty array."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_list = []\nbatch = train[-n_input:].reshape((1, n_input, n_features))\nfor i in range(n_input):   \n    pred_list.append(model.predict(batch)[0]) \n    batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We turn our predictions into a data frame and combine it with our original data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_predict = pd.DataFrame(scaler.inverse_transform(pred_list),index=data[-n_input:].index, columns=['Prediction'])\ndf_test = pd.concat([data,df_predict], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have only prediction for the past twelve months. Let's view the last thirteen observations of the new data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.tail(13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the results and observe the difference between the values ​​predicted by our model and the real values."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 5))\nplt.plot(df_test.index, df_test['passengers'])\nplt.plot(df_test.index, df_test['Prediction'], color='r')\nplt.legend(loc='best', fontsize='xx-large')\nplt.xticks(fontsize=18, color= \"white\")\nplt.yticks(fontsize=16, color= \"white\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we predict twelve from the last twelve months of the training set."},{"metadata":{},"cell_type":"markdown","source":"## Future Forecast"},{"metadata":{},"cell_type":"markdown","source":"Now, let's do the same things to predict the future. We will complete twelve months after the deadline in the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data\nscaler.fit(train)\ntrain = scaler.transform(train)\nn_input = 12\nn_features = 1\ngenerator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\nmodel.fit_generator(generator,epochs=90, verbose= 0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_list = []  \nbatch = train[-n_input:].reshape((1, n_input, n_features))\nfor i in range(n_input):\n    pred_list.append(model.predict(batch)[0])      \n    batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We add the next twelve months to the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"add_dates = [data.index[-1] + DateOffset(months=x) for x in range(0,13) ]\nfuture_dates = pd.DataFrame(index=add_dates[1:],columns=data.columns)\nfuture_dates.head(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_predict = pd.DataFrame(scaler.inverse_transform(pred_list),\n                          index=future_dates[-n_input:].index, columns=['Prediction'])\n\ndf_proj = pd.concat([data,df_predict], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 5))\nplt.plot(df_proj.index, df_proj['passengers'])\nplt.plot(df_proj.index, df_proj['Prediction'], color='r')\nplt.legend(loc='best', fontsize='xx-large')\nplt.xticks(fontsize=18, color = \"white\")\nplt.yticks(fontsize=16, color = \"white\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lost chart of our latest model."},{"metadata":{"trusted":true},"cell_type":"code","source":"losses_lstm = model.history.history['loss']\nplt.figure(figsize=(12,4))\nplt.xlabel(\"Epochs\", color = \"white\")\nplt.ylabel(\"Loss\", color = \"white\")\nplt.xticks(  color = \"white\")\nplt.yticks(  color = \"white\")\nplt.plot(range(len(losses_lstm)),losses_lstm);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"- My first LSTM study.\n- I was inspired by the articles I linked above.\n- This kernel was written for the first time to help people who will start working with LSTM.\n- Please share your contributions and criticisms in the comments.\n\nGood work to everyone. Best regards.\n\n**Note:** Sorry for my English."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}