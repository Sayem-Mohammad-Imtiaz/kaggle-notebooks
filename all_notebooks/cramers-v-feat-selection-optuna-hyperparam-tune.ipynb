{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn import tree\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating 5 Stratified K Fold cross validation sets","metadata":{}},{"cell_type":"code","source":"TRAINING_PATH='../input/mushroom-classification/mushrooms.csv'\n\ndf=pd.read_csv(TRAINING_PATH)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAINING_FOLDS_PATH='./'\n\nimport pandas as pd\n\ndf_train=pd.read_csv(TRAINING_PATH)\ndf_train.head()\n\ndf_train['class'].value_counts()\n\ndf_train['kfolds']=-1\ndf_train=df_train.sample(frac=1).reset_index(drop=True)\ndf_train.head()\n\nfrom sklearn import model_selection\n\nstrat_kf=model_selection.StratifiedKFold(n_splits=5)\n\nfor fold,(trn_,val_) in enumerate(strat_kf.split(X=df_train,y=df_train['class'])):\n  df_train.loc[val_,'kfolds']=fold\ndf_train.head()\n\ndf_train.to_csv(TRAINING_FOLDS_PATH+'train_folds.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# File Paths","metadata":{}},{"cell_type":"code","source":"TRAINING_PATH='./train_folds.csv'\nMODEL_PATH='./'\nSUBMISSION_FILES_PATH='./Submissions/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data ExplorationÂ¶\n1. Null Values\n2. Number of unique values","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(TRAINING_PATH)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of null values in each column\ndf.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total number of unique values in each column\ndf.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(['Unnamed: 0'],axis=1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for class imbalance \ndf['class'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for any numerical data. If present, it has to be scaled etc.\n\ncolumns = df.columns\nnumerical_columns = df._get_numeric_data().columns\nnumerical_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection : Removing some categorical features based on Cramer's V\n\n*References :*\n1. https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n2. https://www.kaggle.com/chrisbss1/cramer-s-v-correlation-matrix","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy.stats as ss\nimport seaborn as sns\n\n\ndef cramers_v(confusion_matrix):\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum()\n    phi2 = chi2 / n\n    r, k = confusion_matrix.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n    rcorr = r - ((r-1)**2)/(n-1)\n    kcorr = k - ((k-1)**2)/(n-1)\n    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows= []\n\nfor var1 in df:\n  col = []\n  for var2 in df :\n    confusion_matrix = pd.crosstab(df[var1], df[var2])\n     # Cramer's V test\n    col.append(round(cramers_v(confusion_matrix.values),2)) # Keeping of the rounded value of the Cramer's V  \n  rows.append(col)\n  \ncramers_results = np.array(rows)\ndf_corr = pd.DataFrame(cramers_results, columns = df.columns, index =df.columns)\n\n\n\ndf_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since veil-type has NaN values in the correlation matrix\ndf_corr = df_corr.drop(['veil-type'],axis=0)\ndf_corr = df_corr.drop(['veil-type'],axis=1)\n\n# Since kfolds is not required for correlation\ndf_corr = df_corr.drop(['kfolds'],axis=0)\ndf_corr = df_corr.drop(['kfolds'],axis=1)\ndf_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(30,15))\nsns.heatmap(df_corr, annot=True, cmap=plt.cm.CMRmap_r)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### High correlation between 2 features indicate some sort of duplication or that 1 feature can be represented in the form of other. So we only need 1 of those 2 features and we can remove 1. We can set a threshold (here, 0.7); above which if 2 features have correlation, we can drop 1.","metadata":{}},{"cell_type":"code","source":"# with the following function we can select highly correlated features\n# it will remove the first feature that is correlated with anything other feature\n\ndef correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = correlation(df_corr, 0.7)\nprint(f\"No of features which can be removed : {len(set(corr_features))}\")\nprint(f\"Removable features : {corr_features}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(list(corr_features), axis=1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One hot encode categorical features","metadata":{}},{"cell_type":"code","source":"columns_to_one_hot_encode = list(df.columns)\ncolumns_to_one_hot_encode.remove('class')\ncolumns_to_one_hot_encode.remove('kfolds')\ncolumns_to_one_hot_encode ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One hot encode the categorical columns - All except the target column \"class\" and the \"kfolds\" column\n\ndf=pd.get_dummies(data=df,columns=columns_to_one_hot_encode)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['class'] = df['class'].replace({'e':0,'p':1})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Move the class and kfolds column to the end","metadata":{}},{"cell_type":"code","source":"# Move the target and kfolds column to the last\n\ndf=df[[column for column in df if column not in['class','kfolds']]+['class','kfolds']]\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(fold,df,models,target_name, save_model, print_details=False):\n  \n  # print(df.head())\n  # Training and validation sets\n  df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n  df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n  # x and y of training dataset\n  x_train=df_train.drop(target_name,axis=1).values\n  y_train=df_train[target_name].values\n\n  # x and y of validation dataset\n  x_valid=df_valid.drop(target_name,axis=1).values\n  y_valid=df_valid[target_name].values\n\n  # accuracy => will store accuracies of the models  (same for confusion_matrices)\n  accuracy=[]\n  confusion_matrices=[]\n  classification_report=[]\n\n  for model_name,model_constructor in list(models.items()):\n    clf=model_constructor\n    clf.fit(x_train,y_train)\n\n    # preds_train, preds_valid => predictions when training and validation x are fed into the trained model\n    preds_train=clf.predict(x_train)\n    preds_valid=clf.predict(x_valid)\n\n    acc_train=metrics.accuracy_score(y_train,preds_train)\n    acc_valid=metrics.accuracy_score(y_valid,preds_valid)\n\n    f1_train = metrics.f1_score(y_train,preds_train)\n    f1_valid = metrics.f1_score(y_valid,preds_valid)\n\n    conf_matrix=metrics.confusion_matrix(y_valid,preds_valid)\n    class_report=metrics.classification_report(y_valid,preds_valid)\n\n    accuracy.append(acc_valid)\n    confusion_matrices.append(conf_matrix)\n    classification_report.append(class_report)\n\n    if(print_details==True):\n      print(f'Model => {model_name} => Fold = {fold} => Training Accuracy = {acc_train} => Validation Accuracy = {acc_valid}')\n\n    if(save_model==True):\n      joblib.dump(clf, f\"{MODEL_PATH}{model_name}_F1_{f1_valid}_ACC_{acc_valid}_FOLD_{fold}.bin\")\n\n  if(print_details==True):\n    print('\\n--------------------------------------------------------------------------------------------\\n')\n    \n  return accuracy,confusion_matrices,classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning for different models using Optuna\nModels :\n\n1. XGB Classifier\n2. SVM Classifier\n3. Random Forest Classifier\n4. Decision Tree Classifier","metadata":{}},{"cell_type":"markdown","source":"### 1. Random Forest","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom functools import partial\n\ndef optimize_rfc(trial,df,total_folds,target_name):\n    criterion = trial.suggest_categorical(\"criterion\", ['gini','entropy'])\n    n_estimators = trial.suggest_int('n_estimators', 100, 1500)\n    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n    max_features = trial.suggest_uniform(\"max_features\", 0.01, 1.0)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 100)\n    \n    model = RandomForestClassifier(\n        n_estimators = n_estimators, \n        max_depth = max_depth, \n        max_features = max_features, \n        min_samples_leaf = min_samples_leaf,\n        min_samples_split = min_samples_split,\n        criterion = criterion\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_rfc = partial(optimize_rfc, df = df, total_folds = 5,target_name = 'class')\nstudy_rfc = optuna.create_study(direction = 'maximize')\nstudy_rfc.optimize(optimization_function_rfc, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_best_params = study_rfc.best_trial.params\nrfc_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"def optimize_xgb(trial,df,total_folds,target_name):\n    \n    learning_rate = trial.suggest_uniform(\"learning_rate\", 0.01, 1.0)\n    gamma = trial.suggest_uniform(\"gamma\", 0.05, 1.0)\n    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 10)\n    subsample = trial.suggest_uniform(\"subsample\", 0.5, 1.0)\n    colsample_bytree = trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0)\n    reg_lambda = trial.suggest_uniform(\"reg_lambda\", 0.01, 1.0)\n    reg_alpha = trial.suggest_uniform(\"reg_alpha\", 0.01, 1.0)\n    \n    model = XGBClassifier(\n        learning_rate = learning_rate,\n        gamma = gamma,\n        max_depth = max_depth,\n        min_child_weight = min_child_weight,\n        subsample = subsample,\n        colsample_bytree = colsample_bytree,\n        reg_lambda = reg_lambda,\n        reg_alpha = reg_alpha\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_xgb = partial(optimize_xgb, df = df, total_folds = 5,target_name = 'class')\nstudy_xgb = optuna.create_study(direction = 'maximize')\nstudy_xgb.optimize(optimization_function_xgb, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_best_params = study_xgb.best_trial.params\nxgb_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. SVM Classifier","metadata":{}},{"cell_type":"code","source":"def optimize_svc(trial,df,total_folds,target_name):\n    \n    C = trial.suggest_uniform(\"C\", 0.001, 1000)\n    gamma = trial.suggest_categorical(\"gamma\", ['auto'])\n    class_weight = trial.suggest_categorical(\"class_weight\", ['balanced'])\n    \n    model = SVC(\n        C = C,\n        gamma = gamma,\n        class_weight = class_weight\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_svc = partial(optimize_svc, df = df, total_folds = 5,target_name = 'class')\nstudy_svc = optuna.create_study(direction = 'maximize')\nstudy_svc.optimize(optimization_function_svc, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_best_params = study_svc.best_trial.params\nsvc_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"def optimize_dt(trial,df,total_folds,target_name):\n    criterion = trial.suggest_categorical(\"criterion\", ['gini','entropy'])\n    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n    max_features = trial.suggest_uniform(\"max_features\", 0.01, 1.0)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 100)\n    \n    model = DecisionTreeClassifier(\n        max_depth = max_depth, \n        max_features = max_features, \n        min_samples_leaf = min_samples_leaf,\n        min_samples_split = min_samples_split,\n        criterion = criterion\n    )\n    \n    accuracies = []\n    \n    for fold in range(total_folds):\n        \n        df_train=df[df['kfolds']!=fold].reset_index(drop=True)\n        df_valid=df[df['kfolds']==fold].reset_index(drop=True)\n\n\n        # x and y of training dataset\n        x_train=df_train.drop(target_name,axis=1).values\n        y_train=df_train[target_name].values\n\n        # x and y of validation dataset\n        x_valid=df_valid.drop(target_name,axis=1).values\n        y_valid=df_valid[target_name].values\n        \n        model.fit(x_train, y_train)\n        preds= model.predict(x_valid)\n        \n        fold_acc = metrics.accuracy_score(y_valid, preds)\n        accuracies.append(fold_acc)\n        \n    return np.mean(accuracies)\n\noptimization_function_dt = partial(optimize_dt, df = df, total_folds = 5,target_name = 'class')\nstudy_dt = optuna.create_study(direction = 'maximize')\nstudy_dt.optimize(optimization_function_dt, n_trials=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_best_params = study_dt.best_trial.params\ndt_best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit and Predict the models","metadata":{}},{"cell_type":"code","source":"XGB_model=XGBClassifier(**xgb_best_params)\nSVM_model=SVC(**svc_best_params)\nRFC_model=RandomForestClassifier(**rfc_best_params)\nDT_model=DecisionTreeClassifier(**dt_best_params)\nmodels={\n    'XGB Classifier' : XGB_model,\n    'SVM Classifier' : SVM_model,\n    'Random Forest Classifier' : RFC_model,\n    'Decision Tree Classifier' : DT_model\n    }\n\naccuracies,confusion_matrices,classification_reports=[],[],[]\nfor f in range(5):\n  accuracy,confusion_matrix,classification_report=run(f,df,models=models,target_name='class', save_model= True, print_details=True)\n  accuracies.append(accuracy)\n  confusion_matrices.append(confusion_matrix)\n  classification_reports.append(classification_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Heatmap of the Confusion Matrix","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(fold_num, models, title):\n    \n    classifier_num = list(models.keys()).index(title)\n    \n    cf_matrix = confusion_matrices[fold_num][classifier_num]\n    group_names = ['True Neg','False Pos','False Neg','True Pos']\n    group_counts = [\"{0:0.0f}\".format(value) for value in\n                    cf_matrix.flatten()]\n    group_percentages = [\"{0:.2%}\".format(value) for value in\n                         cf_matrix.flatten()/np.sum(cf_matrix)]\n    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n              zip(group_names,group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n\n    plt.figure(figsize=(10,6))\n    plt.title(title, fontsize=20)\n    sns.heatmap(cf_matrix, annot=labels, fmt='', annot_kws={\"fontsize\" : 20})\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(fold_num = 0, models = models, title = \"XGB Classifier\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(fold_num = 0, models = models, title = \"SVM Classifier\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(fold_num = 0, models = models, title = \"Random Forest Classifier\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(fold_num = 0, models = models, title = \"Decision Tree Classifier\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion : Since the dataset was already cleaned and it was an easy dataset so all the 4 models ie. XGBoost, Decision Tree, Random Forest and SVM gave 100% accuracies on both train and test data","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}