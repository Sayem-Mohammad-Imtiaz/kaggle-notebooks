{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Data Analysis\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-darkgrid')\nimport seaborn as sns\n\n#Data Preprocessing and Feature Engineering\nfrom nltk import PorterStemmer\nfrom textblob import TextBlob\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image\nimport plotly.express as pex\n\nimport urllib\nimport requests","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = pd.read_csv('/kaggle/input/covid19-tweets/covid19_tweets.csv')\ntweets.columns = tweets.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\nprint('Tweets data shape: ', tweets.shape)\ntweets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_pattern(text, pattern):\n    r = re.findall(pattern, text)\n    for i in r:\n        text = re.sub(i, \"\", text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets['text'] = np.vectorize(remove_pattern)(tweets['text'], \"@[\\w]*\")\ntweets['text'] = np.vectorize(remove_pattern)(tweets['text'], \"#[\\w]*\")\ntweets['text'] = np.vectorize(remove_pattern)(tweets['text'], '[0-9]')\ntweets['text'] = tweets['text'].str.replace(\"[^a-zA-Z#]\", \" \")\ntweets['text'] = tweets['text'].apply(lambda x: ' '.join([i for i in x.split() if len(i) > 3]))\ntweets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet = tweets['text'].apply(lambda x: x.split())\ntweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = PorterStemmer()\ntweet = tweet.apply(lambda x: [ps.stem(i) for i in x])\ntweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(tweet)):\n    tweet[i] = ' '.join(tweet[i])\ntweets['text'] = tweet\ntweets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Wordclouds by Countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"India = ' '.join(text for text in tweets['text'][tweets['user_location'] == 'India'])\nChina = ' '.join(text for text in tweets['text'][tweets['user_location'] == 'China'])\nUSA = ' '.join(text for text in tweets['text'][tweets['user_location'] == 'USA'])\nSA = ' '.join(text for text in tweets['text'][tweets['user_location'] == 'South Africa'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combining the image with the dataset\nMask = np.array(Image.open(requests.get('http://clipart-library.com/image_gallery2/Twitter-PNG-Image.png', stream = True).raw))\n\n# We use the ImageColorGenerator library from Wordcloud \n# Here we take the color of the image and impose it over our wordcloud\nimage_colors = ImageColorGenerator(Mask)\n\n# Now we use the WordCloud function from the wordcloud library \nwc = WordCloud(background_color = 'black', height = 1500, width = 4000, mask = Mask).generate(India)\n\n# Size of the image generated \nplt.figure(figsize = (10, 20))\n\n# Here we recolor the words from the dataset to the image's color\n# recolor just recolors the default colors to the image's blue color\n# interpolation is used to smooth the image generated \nplt.imshow(wc.recolor(color_func = image_colors), interpolation = \"hamming\")\n\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Mask = np.array(Image.open(requests.get('http://clipart-library.com/image_gallery2/Twitter-PNG-Image.png', stream = True).raw))\nimage_colors = ImageColorGenerator(Mask)\nwc = WordCloud(background_color = 'black', height = 1500, width = 4000, mask = Mask).generate(China)\nplt.figure(figsize = (10, 20))\nplt.imshow(wc.recolor(color_func = image_colors), interpolation = \"hamming\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Mask = np.array(Image.open(requests.get('http://clipart-library.com/image_gallery2/Twitter-PNG-Image.png', stream = True).raw))\nimage_colors = ImageColorGenerator(Mask)\nwc = WordCloud(background_color = 'black', height = 1500, width = 4000, mask = Mask).generate(USA)\nplt.figure(figsize = (10, 20))\nplt.imshow(wc.recolor(color_func = image_colors), interpolation = \"hamming\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Mask = np.array(Image.open(requests.get('http://clipart-library.com/new_gallery/18-189677_instagram-logo-twitter-logo-bird-twitter-logo-2017.png', stream = True).raw))\nimage_colors = ImageColorGenerator(Mask)\nwc = WordCloud(background_color = 'black', height = 1500, width = 4000, mask = Mask).generate(SA)\nplt.figure(figsize = (10, 20))\nplt.imshow(wc.recolor(color_func = image_colors), interpolation = \"hamming\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting more features"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_f = tweets.copy()\n\ntweets['date'] = pd.to_datetime(tweets['date'])\n\ntweets['year'] = tweets['date'].dt.year\ntweets['month'] = tweets['date'].dt.month\ntweets['day'] = tweets['date'].dt.day\ntweets['dayofweek'] = tweets['date'].dt.dayofweek\ntweets['hour'] = tweets['date'].dt.hour\ntweets['minute'] = tweets['date'].dt.minute\ntweets['dayofyear'] = tweets['date'].dt.dayofyear\ntweets['date_only'] = tweets['date'].dt.date\ntweets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 5))\ntweets_daily = tweets.groupby([\"dayofweek\"])[\"text\"].count().reset_index()\ntweets_daily.columns = ['dayofweek', 'tweet_count']\nsns.lineplot(x = 'dayofweek', y = 'tweet_count', hue = None, data = tweets_daily)\nplt.title('Tweets count by day of the week (Monday-Sunday)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 5))\ntweets_yearly = tweets.groupby([\"dayofyear\"])[\"text\"].count().reset_index()\ntweets_yearly.columns = ['dayofyear', 'tweet_count']\nsns.lineplot(x = 'dayofyear', y = 'tweet_count', hue = None, data = tweets_yearly)\nplt.title('Tweets count by day of year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweetMax = tweets.groupby(tweets.user_name)[[\"user_location\"]].count().reset_index()\ntweetMax.columns= ['user_name','count']\ntweetMax = tweetMax.sort_values(by = \"count\" , ascending = False)\ntweetMax= tweetMax.head(10)\ntweetMax\n\n\nfig = pex.bar(tweetMax, x = 'user_name', y='count', title = 'User Standings')\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}