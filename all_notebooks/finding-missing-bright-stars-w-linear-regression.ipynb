{"cells":[{"metadata":{"_uuid":"81a5f9857a93ade364c59297d14918788c435827"},"cell_type":"markdown","source":"## Executive Summary\n\nThis analysis aids PASSNYS's mission to \"identify talented underserved students within New York City’s underperforming school districts in order to increase the diversity of students taking the Specialized High School Admissions Test.\" It explores 3 different data sets: (1) District 5 (Central Harlem) SHSAT enrollment, (2) PASSNYC's School Explorer data and (3) NY School Demographics and Accountability Snapshot. I hypothesize that an effective use of resources is to target and aid high-performing and talented students in the more diverse school of central Harlem who are not taking the SHSAT. To this end, this work presents a classifier used to find schools schools where the number of students who received excellent scores on their New York state standardized tests exceeds the number of students who even took the SHSAT. Furthermore, a regression model was built to not only identify which schools have excellent but underserved students, but also to quantify the overlooked potential."},{"metadata":{"_uuid":"f6c65e9004bf45201a200b1c82ac266c45369928"},"cell_type":"markdown","source":"## Problem Statement\n\nPASSNYC's mission is to \"identify talented underserved students within New York City’s underperforming school districts in order to increase the diversity of students taking the Specialized High School Admissions Test.\" Ultimately, this goal aims to increase the diversity of specialized high school placements. To this end, PASSNYC and its partners provide outreach services including test prep and tutoring, after school programs and activities, resources for parents and community groups.\n\nThe challenge is to assess the needs of students by using publicly available data to quantify the challenges they face in taking the SHSAT. The solution should match schools and the needs of students to PASSNYC services."},{"metadata":{"_uuid":"de789e46aeb81d24583714d542af2ec0e929df17"},"cell_type":"markdown","source":"## Dataset Exploration"},{"metadata":{"_uuid":"81de2a59eac77ec6eb8944d2681d38451d14f430"},"cell_type":"markdown","source":"### District 5 (Central Harlem) SHSAT (Specialized High School Test Admissions Test)\n\nThe District 5 (Central Harlem) SHSAT (Specialized High School Test) data, from the NYC Dept. of Education, gives high level information about SHSAT involvement for that district. Information includes number of students registered for the test, number of students who took the test and the total number of students enrolled in that grade level for 2013-2016.\n\nThis report looks presents some initial observations to note any major trends. The first observation of this data is to view the test taking trends as a function of time. The number of classes observed increases from 33 to 35 from 2013 to 2014, stays constant from 2014 to 2015 and increases from 35 to 37 from 2015 to 2016. The mean of percent students taking the test ranges from 11.70% to 11.92%. The standard deviation ranges from 10.79% to 12.54%. Overall, there is no strong trend in either direction with time.\n\nThe second observation of this dataset views the test taking trends as a function of grade level. There does seem to be a significant difference in percentage of students taking the test between grade levels. The mean $\\pm$ std dev. of percent of students taking the test in the eight grade is 18.39% $\\pm$ 10.36% and 1.64% $\\pm$ 2.84% in the ninth grade. The maximum percentage of students taking the test in the eight grade was 45.92% and only 13.15% in the ninth grade. This observation makes sense when considering the admissions process into the specialized high schools. Most admission offers into NYC's specialized high schools is for 9th graders (8th grade test takers). There are very few openings for 10 graders, thus fewer students would seek those openings. Consequently, the remainder of this analysis focuses on 8th grade test takers since they are both more abundant and more likely to gain admission."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"#Import the District 5 SHSAT dataset\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #plotting\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier #random forest classifier\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score #classifier performance\nfrom sklearn.metrics import recall_score #classifier performance\n\n#Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\n#Explore the dataset for the test registration and testers\nprint(\"Looking at the first few rows of the dataset: \")\ntest_df = pd.read_csv(\"../input/data-science-for-good/D5 SHSAT Registrations and Testers.csv\")\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"#Let's take a look at some basic high level points about the testing data we have\n\nnum_schools = test_df['DBN'].unique().size\nnum_test_groups = test_df['DBN'].count()\nyears_taken = np.sort(test_df['Year of SHST'].unique())\ngrade_levels = np.sort(test_df['Grade level'].unique())\n\nprint(\"Number of unique test groups (i.e. school/class/year combos): \", num_test_groups)\nprint(\"Number of schools for which there is data: \", num_schools)\nprint(\"Years for the test data: \", years_taken)\nprint(\"Grade levels for the test data: \", grade_levels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbf1b727cea434101ef98aaaf00cd1f4e5aed86f","trusted":false},"cell_type":"code","source":"#Looking at the overall trend in time among schools\npercent_taken_dict = {}\npercent_taken_stats_dict = {}\ndf_by_year_dict = {}\n\n#Add two columns: percentage of students who took the test and percentage of students who signed up for the test \npercent_taken = pd.DataFrame({'Percent Class Test Taken': test_df['Number of students who took the SHSAT']/test_df['Enrollment on 10/31']*100})\npercent_signed = pd.DataFrame({'Percent Class Registered for Test': test_df['Number of students who registered for the SHSAT']/test_df['Enrollment on 10/31']*100})\nschool_test_df = test_df.merge(percent_taken, left_index=True, right_index=True).merge(percent_signed, left_index=True, right_index=True)\n\nfor year in years_taken:\n    year_df = school_test_df.loc[lambda school_test_df: school_test_df['Year of SHST'] == year, :]\n    df_by_year_dict[year] = year_df\n    percent_taken_dict[year] = year_df['Number of students who took the SHSAT'].sum()/year_df['Enrollment on 10/31'].sum()\n    \n    percent_taken_stats_dict[year] = year_df['Percent Class Test Taken'].describe()\n    \nprint(pd.DataFrame(percent_taken_stats_dict))\n\n#In general, there are apparent trends in the percentage of students taking the test by year. The number of classes observed increases from 33 to 35 from 2013 to 2014,\n#stays constant from 2014 to 2015 and increases from 35 to 37 from 2015 to 2016. The mean of percent students taking the test ranges from 11.70%\n#to 11.92%. The standard deviation ranges from 10.79% to 12.54%. Overall, there is no strong trend in either direction with time.\n\n#Showing a basic boxplot of the percent taken by year\nschool_test_df.boxplot(column='Percent Class Test Taken', by='Year of SHST', figsize=[14,8])\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b1bc05a2fa722dc4c0a3b24c502d2d79b3dac1d","trusted":false},"cell_type":"code","source":"#Looking at the trends between grade levels (i.e. is there a big difference in enrollment from grade 8 to grade 9?)\npercent_taken_stats_by_grade = {}\n\nfor grade in grade_levels:\n    grade_df = school_test_df.loc[lambda school_test_df: school_test_df['Grade level'] == grade, :]\n    \n    percent_taken_stats_by_grade[grade] = grade_df['Percent Class Test Taken'].describe()\n    \nprint(pd.DataFrame(percent_taken_stats_by_grade))\n\n#There does seem to be a significant difference in percentage of students taking the test between grade levels. The mean/std dev. of percent of students taking the test in the eight grade\n#is 18.39%/10.36% and 1.64%/2.84% in the ninth grade. The maximum percentage of studenst taking the test in the eight grade was 45.92% and only 13.15% in the ninth grade.\n\n#Showing a basic boxplot of the percent taken by grade\nschool_test_df.boxplot(column='Percent Class Test Taken', by='Grade level', figsize=[14,8])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0370470e7d6a54a760960caf9d8968ec1a592442"},"cell_type":"markdown","source":"### PASSNYC 2016 School Explorer\n\nThe 2016 School Explorer dataset offers a wealth of information for school located in New York City. For each school the dataset includes basic identifying information (e.g. address, district, grade levels), high-level financial details, student population demographics, school performance ratings and New York state standardized test scores.\n\nThe initial analysis of this dataset focused on the percent of the class taking the test. It makes sense that if a student doesn't take the test, then the probability of admission falls to zero. Consequently, by raising the number of students taking the SHSAT, you may also raise the probability of admissions in this targeted school district. A look at the correlation coefficients between meaningful variables in the School Explorer dataset at the percent of the class taking the test might provide some insight into factors relating to the probability of test taking. First teh correlation between these factors and all the points from the District 5 SHSAT data was observed. As was predicted, the grade level showed the largest correlation (-0.70) to the percentage of student test takers. Given that information the previous correlation analysis was repeated for only data from 8th grade test takers. In doing so, the outliers are being removed and the correlation coefficients increased substantially, allowing a better look at the interactions between the variables. The conclusion of this segment of the analysis is as follows: some of the most important single factors in determining the percentage of the class include economic need index, student racial demographics, and the 2016 8th grade standardized test results."},{"metadata":{"_uuid":"a5f6878e0a2530a0127f94b715af867804db2c87","trusted":false},"cell_type":"code","source":"#Loading teh included NYC school data and transforming it to better fit our analysis\ntotal_school_df = pd.read_csv(\"../input/data-science-for-good/2016 School Explorer.csv\")\n\n#Prepare a much smaller table that only included the school for which we have testing data\n#The \"DBN\" field in the test file is the same key as the \"Location Code\" in the School Explorer file\n\n#Get a list of all school info location codes\nall_location_codes = total_school_df['Location Code'].values\n#keep track of the indices where the schools in the total_school_df are\nmerger_index = []\n\n#for each unique dbn code in the test_df\nfor dbn in school_test_df['DBN'].unique():\n    #if it matches the location code in the total_school_df\n    for i,loc_code in enumerate(all_location_codes):\n        if loc_code == dbn:\n            #record index\n            merger_index.append(i)\n\n#Create a smaller df with only schools of interest\nschool_df_unformatted = total_school_df.iloc[merger_index, :]\n\n#Remove all columns not relevant to analysis\nremoved_columns = ['Adjusted Grade', 'New?', 'Other Location Code in LCGMS', 'School Name', 'SED Code']\nfor col in list(school_df_unformatted):\n    if 'Grade 3' in col or 'Grade 4' in col or 'Grade 5' in col:\n        removed_columns.append(col)\n        \nschool_df_unformatted = school_df_unformatted.drop(columns = removed_columns)\n\n#Normalize ELA/Math test scores by class size (find % of students who scored 4s)\ngrades = ['Grade 6 ', 'Grade 7 ', 'Grade 8 ']\nto_norm_cols_suffix = ['4s - All Students', '4s - American Indian or Alaska Native', '4s - Black or African American', '4s - Hispanic or Latino', '4s - Asian or Pacific Islander', '4s - White', '4s - Multiracial', '4s - Limited English Proficient', '4s - Economically Disadvantaged']\nfor grade in grades:\n    for subject in ['ELA ', 'Math ']:\n        total_col = grade + subject + '- All Students Tested'\n        denom = school_df_unformatted[total_col]\n        for suff in to_norm_cols_suffix:\n            norm_col = grade + subject + suff;\n            new_col = norm_col + ' - Normalized'\n            school_df_unformatted[new_col]=school_df_unformatted[norm_col].divide(denom)\n            school_df_unformatted[new_col].fillna(value=0, inplace=True)\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb23f27063a855b21e543b426751beeefe1cb45b","trusted":false},"cell_type":"code","source":"#Merge the school df and the test results df, clean up the dataset and look at correlation coefficients between\n#all fields and the percent class test taken\ntest_and_school_df_unformatted = school_test_df.merge(school_df_unformatted, left_on='DBN', right_on='Location Code')\n\n#Need to clean the '%' out of certain columns or they are read as strings\npercent_columns = ['Percent ELL', 'Percent Asian', 'Percent Black', 'Percent Hispanic', 'Percent Black / Hispanic', 'Percent White', 'Student Attendance Rate', 'Percent of Students Chronically Absent', 'Rigorous Instruction %', 'Collaborative Teachers %', 'Supportive Environment %', 'Effective School Leadership %', 'Strong Family-Community Ties %', 'Trust %']\n\nfor col in percent_columns:\n    for i,row in test_and_school_df_unformatted.iterrows():\n        val_string = row.loc[col]\n        val_num = float(val_string.replace(\"%\", \"\"))\n        test_and_school_df_unformatted.at[i, col] = val_num\n    \n\n#test_and_school_df1 = test_and_school_df_unformatted.convert_objects(convert_numeric=True)\ntest_and_school_df1 = test_and_school_df_unformatted.infer_objects()\n\n\n#Look for correlations between percent test taken and hand-selected features\ncorr_coeffs = test_and_school_df1.corr()['Percent Class Test Taken']\ncorr_rows_removed = ['Enrollment on 10/31', 'Number of students who took the SHSAT', 'District', 'Zip', 'Grade 8 ELA - All Students Tested', 'Grade 8 Math - All Students Tested', 'Percent Class Test Taken', 'Number of students who registered for the SHSAT', 'Longitude', 'Latitude']\n\nfor row_label, val in corr_coeffs.iteritems():\n    if 'Grade 6' in row_label or 'Grade 7' in row_label or '- Normalized' in row_label:\n        corr_rows_removed.append(row_label)\n        \n\n#Drop values that are non-sensical in a correlatin analysis and all N/A values as well\ncorr_coeffs = pd.DataFrame(corr_coeffs.drop(corr_rows_removed).dropna(how='all').sort_values())\n\ncorr_coeffs.style.bar(align='zero', color=['#5fba7d'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1658e74fc1957dd829e1479fd955e1f8848256a4","trusted":false},"cell_type":"code","source":"#Grade level has the second largest correlation coefficient. However, it's unclear if including data\n#about grade 9 classes is useful. There are far fewer slots for grade 10 entry into the specialized high schools,\n#thus I think students udnerstand the odds and are less willing to take the test. Further, many who would\n#have been inclined to take the test have probably done so. I'm shaping the data to look at 8th grade test takers\n#only to see if the trends become more obvious.\n\n#create a new df for just 8th grade test results\ntest_and_school_df_8thgrade = test_and_school_df1.copy()\nremoved_rows = []\nfor i,row in test_and_school_df1.iterrows():\n    if row['Grade level'] == 9:\n        removed_rows.append(i)\ntest_and_school_df_8thgrade = test_and_school_df_8thgrade.drop(index=removed_rows)\n\n#find correlation coefficients\ncorr_coeffs_8thgrade = test_and_school_df_8thgrade.corr()['Percent Class Test Taken']\ncorr_rows_removed = ['Enrollment on 10/31', 'Number of students who took the SHSAT', 'District', 'Zip', 'Grade 6 ELA - All Students Tested', 'Grade 6 Math - All Students Tested', 'Grade 7 ELA - All Students Tested', 'Grade 7 Math - All Students Tested', 'Grade 8 ELA - All Students Tested', 'Grade 8 Math - All Students Tested', 'Percent Class Test Taken', 'Number of students who registered for the SHSAT']\n\nfor row_label, val in corr_coeffs_8thgrade.iteritems():\n    if 'Grade 6' in row_label or 'Grade 7' in row_label or '- Normalized' in row_label:\n        corr_rows_removed.append(row_label)\n\n\n#Drop values that are non-sensical in a correlatin analysis and all N/A values as well\ncorr_coeffs_8thgrade = pd.DataFrame(corr_coeffs_8thgrade.drop(corr_rows_removed).dropna(how='all').sort_values())\n\ncorr_coeffs_8thgrade.style.bar(align='zero', color=['#5fba7d'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28445391abc87a0f2a98ad7ef2d443e77411651c","trusted":false},"cell_type":"code","source":"#Let's break the data up into a couple categories and look at the covariance matrices, can we reduce the features there?\n#Start with test scores of just 8th graders\n\ntest_and_school_df_8thgrade_test_scores = pd.DataFrame()\n\n#Normalize ELA/Math test scores by class size (find % of students who scored 4s)\ngrades = ['Grade 6 ', 'Grade 7 ', 'Grade 8 ']\n#grades = ['Grade 7 ']\ntest_cols_suffix = ['4s - All Students', '4s - American Indian or Alaska Native', '4s - Black or African American', '4s - Hispanic or Latino', '4s - Asian or Pacific Islander', '4s - White', '4s - Multiracial', '4s - Limited English Proficient', '4s - Economically Disadvantaged']\nfor grade in grades:\n    for subject in ['ELA ']:\n        for suff in to_norm_cols_suffix:\n            norm_col = grade + subject + suff;\n            test_and_school_df_8thgrade_test_scores[norm_col]=test_and_school_df_8thgrade[norm_col]\n            \n#Add average scores\ntest_and_school_df_8thgrade_test_scores['Average ELA Proficiency'] = test_and_school_df_8thgrade['Average ELA Proficiency']\n\nstate_test_scores_coeffs = test_and_school_df_8thgrade_test_scores.corr()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"116a1db426816d25ca37724e7be3fd21cb330c5f"},"cell_type":"markdown","source":"### NY School Demographics and Accountability Snapshot\n\nThe NY School Demographics and Accountability Snapshot dataset is a dataset that provides various statistics about NY schools. I looked at this dataset in the hopes that the percent of free or reduced lunches information might provide more insight into the economic obstacles faced by students. However, too much of the data was null to be useful here."},{"metadata":{"_uuid":"8176032a2ff54c858dbfe4b92b620bfba6e7c193","trusted":false},"cell_type":"code","source":"#Expand the dataset to include NY School Demographics and Accountability Snapshot, redcued and free lunch stats\n\n#Read in the file\nschool_demo_all_df = pd.read_csv(\"../input/ny-school-demographics-and-accountability-snapshot/2006-2012-school-demographics-and-accountability-snapshot.csv\")\n#Reduce the df to only the relevant schools for the most recent year available (2012)\nschool_demo_reduced_df = school_demo_all_df.loc[lambda school_demo_all_df: school_demo_all_df['schoolyear'] == 20112012]\n\n#Merge the free and reduced lunch columns form the school demographics snapshot file\ntest_and_school_df_8thgrade_plusdemo = test_and_school_df_8thgrade.merge(school_demo_reduced_df.loc[:, ['DBN','fl_percent','frl_percent']], left_on='DBN', right_on='DBN', how='left')\n#Merge the fl_percent and frl_percent columns, one of the other is filled and we will treat them as both here\n\nfinding_nulls_series = np.bitwise_and(test_and_school_df_8thgrade_plusdemo.loc[:,['frl_percent']].isnull(), test_and_school_df_8thgrade_plusdemo.loc[:,['fl_percent']].isnull())\n\nnum_empty_entries = finding_nulls_series.sum()\n\nprint('Of 78 test entries, ', num_empty_entries[0], 'did not have data on free and reduced lunch data reported')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e7042bba65910d3b09d16bbc15a592cfca20167"},"cell_type":"markdown","source":"## Model - Finding the Forgotten Bright Stars"},{"metadata":{"_uuid":"4cde5af5ad0ae6c1ce4d74089ba9720d4b3d2cdb"},"cell_type":"markdown","source":"### Identification of high potential students not taking the SHSAT\n\nOur initial data exploration gave several different insights into test taking probability trends, but one that stuck out was that 8th graders who performed better on standardized tests were more likely to take the SHSAT. There is a certain common sense to that. Generally higher performing test takers are likely more confident when approaching the SHSAT. The best goal is therefore to improve education for all students thereby increasing their standardized test scores and probability of entrance into a specialized high school.\n\nAnother (smaller scale) interesting approach is prompted by PASSNYC's goals: to \"discover diamonds in the rough\". Are there high performing students with a high likelihood of gaining entrance into a specialized high school who aren't even taking the test? Is there a way to predict where they go to school and allocate the appropriate resources there?\n\nTo this end, I looked at the number of students who received a \"4\" (the highest mark) on their standardized test in either ELA (English and Language Arts) and Math and compared it to the number of students taking the SHSAT. If more students received an excellent mark on their standardized tests than took the SHSAT, then those are potentially promising students who have slipped through the cracks. Below, the figure plots the comparison. The line with slope=1 indicates a minimum goal that at least the number of students achieving a \"4\" on their standardized test should have taken the SHSAT. Therefore, points below the line are schools where there is likely more high performing students who should have taken the test, but did not. For the points below the line, a larger vertical distance between the line and the point indicates a larger number of missed students."},{"metadata":{"_uuid":"fb1495dd513a632f782418fc1cd1391c9538192b","trusted":false},"cell_type":"code","source":"#Plotting to show the students who do well on standardized tests but don't take the SHSAT\n\nplt.figure(1, figsize=(15, 7))\nplt.subplot(121)\nplt.scatter(test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016,'Grade 8 Math 4s - All Students'], test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016, 'Number of students who took the SHSAT'])\nplt.plot([0, 10, 20, 30, 40, 50], [0, 10, 20, 30, 40, 50], 'r')\nplt.xlabel('Number of students who scored a 4 on the Math Standardized Test')\nplt.ylabel('Number of students who took the SHSAT')\n\nplt.subplot(122)\nplt.scatter(test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016,'Grade 8 ELA 4s - All Students'], test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016, 'Number of students who took the SHSAT'])\nplt.plot([0, 10, 20, 30, 40, 50], [0, 10, 20, 30, 40, 50], 'r')\nplt.xlabel('Number of students who scored a 4 on the ELA Standardized Test')\nplt.ylabel('Number of students who took the SHSAT')\nplt.suptitle('Finding High Potential Students Not Taking the SHSAT')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f4143b4da462451fdb33956d325a26af8416963d"},"cell_type":"code","source":"#Plotting a Histogram of high performing students missed\n\n\nplt.hist(test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016,'Grade 8 Math 4s - All Students'].subtract(test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016, 'Number of students who took the SHSAT']))\nplt.ylabel('Number of schools')\nplt.xlabel('Number of students who scored a 4 on the Math Standardized Test who didn\\'t take the SHSAT')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86bb81f3d5dae7865e959e13f8df6e37c07a0e34"},"cell_type":"markdown","source":"### Random Forest Classifier to find schools with overlooked high performing students\n\nI built a classifier to help find the missing high performers. A school is classified a \"high potential overlooked\" if the number of SHSAT test takers in 2016 was less than the number of 4's received on either the ELA or Math section of the New York state standardized test. For this dataset in 2016, there were 21 schools with an 8th graders taking the SHSAT. Of those 21 schools, 4 of them meet the \"high potential overlooked\" classification.\n\nIn the end, I settled with a random forest classifier. Other classifiers considered included support vector machines (which tended to have very poor recall) and naiive Bayes (which had poor precision and recall). Many different feature combinations were also considered. Initially, I tried, as much as possible, to use features outside of test scores. Examples of those features included a school's economic need index, performance ratings and student demographics. The reason for avoiding inclusion of standardized test results was that test results are not reported until the following school year. According to the NY Department of Education website, for example, knowledge of 2016 standardized test results wouldn't be known until 2017 (after taking the 2016 SHSAT). Therefore, is wouldn't help PASSNYC in predicting where the overlooked high performers are. However, those results resulted in such a significantly better performing classifier, that I used it in the end. The justification for continuing with this feature was the hope that the standardized test performance trends are consistent in time. Further datasets will be explored later to confirm/deny this hypothesis\n\nThe final random forest classifier was a simple model including only two features: 'Grade 8 ELA 4s - All Students' and 'Grade 8 Math 4s - All Students'. The mean accuracy over 100 trials of randomized training/set data splits and random classifier seeds is 0.86. Precision and recall are omitted from this analysis. The data is so sparse that there are frequently no true positives in the test data, thus yielding low values that are not truly indicative of the classifier's performance."},{"metadata":{"_uuid":"97e1994ffc3116d62de5e35e8f8a14fddc954677","trusted":false},"cell_type":"code","source":"#Building a classifier that finds high potential, but overlooked students\n\n#Make a new column in the dataframe of high potential but overlooked students\ntest_and_school_df_8thgrade['High Potential Overlooked Classification'] = pd.Series(False, index = test_and_school_df_8thgrade.index)\ntest_and_school_df_8thgrade['High Potential Overlooked Classification'].mask((test_and_school_df_8thgrade['Number of students who took the SHSAT']<test_and_school_df_8thgrade['Grade 8 Math 4s - All Students']) | (test_and_school_df_8thgrade['Number of students who took the SHSAT']<test_and_school_df_8thgrade['Grade 8 ELA 4s - All Students']),other=True, inplace=True)\n\n#Make a list of columns to include in the features\n#train_cols = ['Economic Need Index', 'Grade 8 ELA 4s - All Students', 'Grade 8 Math 4s - All Students']\ntrain_cols = ['Grade 8 ELA 4s - All Students', 'Grade 8 Math 4s - All Students']\n#train_cols = ['Strong Family-Community Ties %', 'Percent of Students Chronically Absent', 'Percent Asian']\n#train_cols = ['Percent Black / Hispanic', 'Supportive Environment %', 'Collaborative Teachers %', 'Student Attendance Rate', 'Economic Need Index']\n#train_cols = ['Percent Black / Hispanic', 'Supportive Environment %', 'Collaborative Teachers %', 'Strong Family-Community Ties %']\n\n#Use only the data form 2016\nx_all = test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016,train_cols]\ny_all = test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016, 'High Potential Overlooked Classification']\n\n#Iterate through the random forest kernels and different test sets\nnum_trials = 100\nscore = np.zeros(num_trials)\n\nfor i in range(num_trials):\n    #Split the data into testing and training data\n    x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.25, random_state=i)\n    #Build a random forest classifier to find overlooked students\n    model2 = RandomForestClassifier(n_estimators=10, random_state=i)\n    #Fit the model to the training data\n    model2.fit(x_train, y_train)\n    #Use developed model to predict the classifications of the test data\n    y_test_model = model2.predict(x_test)\n    #Find the score\n    score[i] = model2.score(x_test, y_test)\n\n#Print results\nmean_score = np.mean(score)\nprint(\"The average score of the classifier over\", num_trials, \"trials is: {:.2}\".format(mean_score))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e99ddfbe7370e7aed26cdb88aba7ff38827d732"},"cell_type":"markdown","source":"### Linear regression to quantify the number of high performing students at each school not taking the SHSAT\n\nI also developed a linear regression model to help quantify the number of high performing students at the schools not taking the SHSAT. The number of \"high potential students overlooked\" is defined as the difference between the number of SHSAT test takers in 2016 and the number of 4's received on the Math section of the New York state standardized test. The math tests were used because they had the higher number of instances where the school was classified as high potential overlooked.\n\nA quick observation of the correlation coefficients between the number of high potential overlooked students and the other variables showed that the number of students performing exemplary on the New York state standardized tests was the most highly correlated single variable. Some trial and error was performed with other variables, but the number of students scoring a 4 on the state standardized test did yield the best fit model.\n\nThe final linear regression model uses the following equation to estimate the number of high potential overlooked students:\n\n$y = -11.33 + 0.75x$\n\nwhere x is number of students who scored a '4' on the New York state standardized math test.  The accuracy score of the regression model is $R^{2} = 0.61$. The figure below presents a scatter plot of the actual values and the regression model's fit. The model's mean error is 0 students and the standard deviation is 6.7 students. It presents a pretty good fit.\n\nIn conclusion, the simple regression model was the best solution explored in this analysis to locate and quantify where high-performing students who aren't fully exercising their potential by taking the specialized high school admissions test. This model could help PASSNYC best provide resources to Harlem students in need. Currently this model can only observe the test results for 2016. A data set that included more years of data about the observed schools for which we have several years of SHSAT data would likely greatly improve this model and open up opportunities for more advanced modeling."},{"metadata":{"_uuid":"a0589ed252297853043a901cff264e070a577336","trusted":false},"cell_type":"code","source":"#Running a lienar regression on students lost (rather than a classifer)\ntest_and_school_df_8thgrade_2016only = test_and_school_df_8thgrade.loc[test_and_school_df_8thgrade['Year of SHST'] == 2016, :].copy()\n\ntest_and_school_df_8thgrade_2016only['Num Students Overlooked'] = test_and_school_df_8thgrade_2016only.loc[:,'Grade 8 Math 4s - All Students'].sub(test_and_school_df_8thgrade_2016only.loc[:,'Number of students who took the SHSAT'])\n\n# #find correlation coefficients\n# corr_coeffs_8thgrade_2016 = test_and_school_df_8thgrade_2016only.corr()['Num Students Overlooked']\n# corr_rows_removed = ['District', 'Zip', 'Num Students Overlooked', 'Latitude', 'Longitude']\n\n# for row_label, val in corr_coeffs_8thgrade_2016.iteritems():\n#     if 'Grade 6' in row_label or 'Grade 7' in row_label or 'Normalized' in row_label:\n#         corr_rows_removed.append(row_label)\n\n# #Drop values that are non-sensical in a correlatin analysis and all N/A values as well\n# corr_coeffs_8thgrade_2016 = pd.DataFrame(corr_coeffs_8thgrade_2016.drop(corr_rows_removed).dropna(how='all').sort_values())\n\n# corr_coeffs_8thgrade_2016.style.bar(align='zero', color=['#5fba7d'])\n\n\n#Remove rows for which there was no state testing data\ntest_and_school_df_8thgrade_2016only = test_and_school_df_8thgrade_2016only.loc[lambda df: df['Grade 8 Math - All Students Tested'] != 0]\n\n#Define the training columns\ntrain_cols = ['Grade 8 Math 4s - All Students']\n#train_cols = ['Grade 8 ELA 4s - All Students', 'Grade 8 Math 4s - All Students']\n#train_cols = ['Percent Black / Hispanic', 'Supportive Environment %', 'Collaborative Teachers %', 'Student Attendance Rate', 'Economic Need Index']\nx_train = test_and_school_df_8thgrade_2016only.loc[:,train_cols]\ny_train = test_and_school_df_8thgrade_2016only.loc[:,'Num Students Overlooked']\n\n\n\n#Build the linear regression model\nmodel = linear_model.LinearRegression()\n#Fit the model\nmodel.fit(x_train, y_train)\n#Print the score\nmodel_score = model.score(x_train, y_train)\n#Declare the model's values as a seperate variable\ny_model = model.predict(x_train)\n\n\n#Show the relationship between number of students recieving a 4 on teh math section of the standardized test\n#and the number of overlooked students\n#Plot the data we are trying to fit vs. the model's output\nplt.scatter(x_train, y_train, c='b', label='2016 Harlem School Data')\nx_model_plot = np.array([0, 5, 10, 15, 20, 25, 30, 45, 50])\ny_model_plot = np.add(model.intercept_, np.multiply(model.coef_[0], x_model_plot))\nplt.plot(x_model_plot, y_model_plot, 'g', label='Linear Regression Model')\nplt.ylabel('Number of High Potential Overlooked Students')\nplt.xlabel('Number of students who scored a 4 on the Math Standardized Test')\nplt.legend()\nplt.text(35, 12, \"y = {:.2f} + {:.2}x\".format(model.intercept_, model.coef_[0]))\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22e6d036fd1d9b83e6b7de7340df43e477c2d6ea","trusted":false},"cell_type":"code","source":"#Show some statistics about the final model (i.e., parameters, performance)\nerror = y_model - y_train\nprint(\"The regression model's score is: {:.2}\".format(model_score))\nprint(\"The model's mean error is: {:.2}\".format(np.mean(error)))\nprint(\"The model's std. dev. of error is: {:.2}\".format(np.std(error)))\n\nprint(\"The model's y-intercept is {:.2f} and slope is {:.2}\".format(model.intercept_, model.coef_[0]))\n\n\nplt.hist(error)\nplt.title('Distribution of error of the students overlooked linear regression model')\nplt.xlabel('Number of Students Overlooked Error')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fb270f9ef18d3a5c0cd4794d5cdb3d62903adc61"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}