{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93b0df69-32f2-1ba4-02c0-df64fd930ac5"},"outputs":[],"source":"from pandas import read_csv\ndata = read_csv(\"../input/mushrooms.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f95f431-eacd-b5c7-c972-684bf281a976"},"outputs":[],"source":"target = \"class\"\ncategorical_features = data.drop(\"class\",1).columns \n\nfrom pandas import get_dummies,concat\nonehot_encoded_categorical_data = get_dummies(data[categorical_features])\n\nX = onehot_encoded_categorical_data\ny = data[target]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33045278-76ce-8c2b-672d-09112baeec39"},"outputs":[],"source":"def get_results(model, X, y):\n\n    import warnings\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        from sklearn.model_selection import cross_val_score\n        compute = cross_val_score(model, X, y)\n        mean = compute.mean()\n        std = compute.std()\n        return mean, std\n\ndef display_classifier_results(X,y):\n\n    models = []\n\n    from sklearn.neighbors import KNeighborsClassifier\n    models = [KNeighborsClassifier()]\n    \n    from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n    models += [GaussianNB(), MultinomialNB(), BernoulliNB()]\n\n    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier#, VotingClassifier\n    models += [RandomForestClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), ExtraTreesClassifier()]\n\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n    models += [LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis()]\n\n    from sklearn.svm import SVC, LinearSVC\n    models += [SVC(),LinearSVC()]\n\n    from sklearn.linear_model import SGDClassifier\n    models += [SGDClassifier()]\n\n    from sklearn.neighbors.nearest_centroid import NearestCentroid\n    models += [NearestCentroid()]\n\n    from sklearn.neural_network import MLPClassifier\n    models += [MLPClassifier(hidden_layer_sizes=(len(X.columns), 2))]\n    \n    from xgboost import XGBClassifier\n    models += [XGBClassifier()]\n\n    output = {}\n\n    for m in models:\n        try:\n            model_name = type(m).__name__\n            from time import time\n            start = time()\n            scores = get_results(m,X,y)\n            finish = time() - start\n            time_finished = \"%d minutes%2d seconds\" % (int(finish / 60), finish % 60) \n            row = {\"Average Score\" : scores[0], \"Standard Deviation\" : scores[1], \"Processing Time\": time_finished}\n            output[model_name] = row\n        except:\n            pass\n\n    from pandas import DataFrame\n    from IPython.display import display\n\n    display(DataFrame(data=output).T.round(2).sort_values(\"Average Score\", ascending=False))\n\ndisplay_classifier_results(X,y)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}