{"nbformat_minor":1,"cells":[{"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"metadata":{"_cell_guid":"88b68eaf-770e-4cd3-99ea-763d757c5d7c","_uuid":"798244ea518abd781555f263c6bd3408dd0a18e6"},"cell_type":"code"},{"execution_count":null,"source":"from sklearn.preprocessing import LabelEncoder\ndftest=pd.read_csv('../input/Test.csv')\ndftrain=pd.read_csv('../input/Train.csv')\ndftrain['source']='TRAIN'\ndftest['source']='TEST'","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"c4eaf344-6c8c-40fe-a7f1-3dfabcf70d4a","_uuid":"35966ca5fd1068c60cdfc5a9a3e17ac82e18be25"},"cell_type":"code"},{"execution_count":null,"source":"data=pd.concat([dftrain,dftest],ignore_index=True)\nprint(data.apply(lambda x:sum(x.isnull())))\nprint(data.apply(lambda x:len(x.unique())))\ncategorical_columns = [x for x in data.dtypes.index if data.dtypes[x]=='object']\nprint(len(categorical_columns))\ncategorical_columns=[x for x in categorical_columns if x not in ['Item_Identifier','Outlet_Identifier','source']]","outputs":[],"metadata":{"_cell_guid":"e7e22201-6df4-46e1-8132-b34f4c0d03b5","_uuid":"9ad15a95465b8fee6555934285a5bbcafbe8f065"},"cell_type":"code"},{"execution_count":null,"source":"for x in categorical_columns:\n    print(\"\\n frequency of %s\"%x)\n    print(data[x].value_counts())\ndata['Item_Weight'].interpolate(inplace=True)\ndata['Outlet_Size'].fillna(\"Medium\",inplace=True)  # first find mode of Outlet_size using data['Outlet_Size'].mode() and then fillna\n#grouped=data.groupby([\"Outlet_Type\",\"Outlet_Size\"],as_index=False)\ndata['Item_Visibility'].interpolate(inplace=True)\nmeanofitemvis=data['Item_Visibility'].mean()\ndata=data.replace({'Item_Visibility': {0: meanofitemvis}})","outputs":[],"metadata":{"_cell_guid":"8eafa875-62eb-4744-b416-edbaf379a723","_uuid":"4c86701e4686925988102612695353a2ab4e48a3"},"cell_type":"code"},{"execution_count":null,"source":"data['Item_Type_Combined'] = data['Item_Identifier'].apply(lambda x: x[0:2])\ndata['Item_Type_Combined']=data['Item_Type_Combined'].map({'FD':'Food','NC':'Non-Consumable','DR':'Drinks'})","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"bc447ecf-dbbf-4da5-a11b-f8d06d9c3d6e","_uuid":"0e727ab1646bc2715ef20370d8ad883839e76f5e"},"cell_type":"code"},{"execution_count":null,"source":"pivot=pd.pivot_table(data,index=['Outlet_Establishment_Year'])\npivot2=pd.pivot_table(data,index=['Item_Identifier'],values=['Item_Weight','Item_Visibility'],aggfunc=np.sum)\ngrouped=data.groupby(\"Item_Visibility\")\nprint(grouped)       \ns=data['Item_Identifier'][data.Item_Fat_Content=='Low Fat'].value_counts()\nfor x in range(0,len(s)):\n    if s[x]==s.max():\n        print(x,s[x])\ns.reset_index()","outputs":[],"metadata":{"_cell_guid":"38135e8d-1aab-4686-9827-948c15de5d98","_uuid":"bd48afaee0961c240a5557fecbdb1f25e75003a1"},"cell_type":"code"},{"execution_count":null,"source":"df=data['Item_Identifier'][data.Item_Fat_Content=='Low Fat'].value_counts()\ndf = df.to_frame().reset_index()\ndf[\"Item_Identifier\"][df.Item_Identifier >= s.max()]\ndf.columns = [\"Item_Id\", \"Item_Count\"]   #RENAME COLUMNS\ndf[\"Item_Id\"][df.Item_Count >= s.max()] \ndf[\"New\"]=df[\"Item_Id\"].apply(lambda x:x[0:2])\nt=df[\"Item_Id\"][df.Item_Count >= s.max()]\n##  print(t[0][0:2])   #FIRST TWO CHARACTERS OF SERIES t\nle = LabelEncoder()\ndata['Outlet'] = le.fit_transform(data['Outlet_Identifier'])\nvar_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']\nle = LabelEncoder()\nfor i in var_mod:\n    data[i] = le.fit_transform(data[i])","outputs":[],"metadata":{"_cell_guid":"9751d137-728e-4c9b-be26-8c170fe39e0c","_uuid":"b3e21f29e14564cff980134a0e68ccf08aeab215"},"cell_type":"code"},{"execution_count":null,"source":"data = pd.get_dummies(data, columns=['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Outlet_Type','Item_Type_Combined','Outlet'])\ntrain = data.loc[data['source']==\"TRAIN\"]   \ntest = data.loc[data['source']==\"TEST\"]\ntest.drop(['Item_Outlet_Sales','source'],axis=1,inplace=True)\ntrain.drop(['source'],axis=1,inplace=True)\ntrain.to_csv(\"train_modified.csv\",index=False)\ntest.to_csv(\"test_modified.csv\",index=False)\nmean_sales = train['Item_Outlet_Sales'].mean()","outputs":[],"metadata":{"_cell_guid":"a64340b6-cb02-4577-bd31-dd386d266781","_uuid":"9451cf573ed4b2e3a19bdd0a700ce62647e45c13"},"cell_type":"code"}],"metadata":{"language_info":{"mimetype":"text/x-python","version":"3.6.4","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat":4}