{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nimport glob\nimport matplotlib.pyplot as plt\nimport json\nimport math\nimport cv2\nimport os\n#shutil.rmtree('/kaggle/working/augmented')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.mkdir('augmented')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('/kaggle/working/augmented/benign')\nos.mkdir('/kaggle/working/augmented/malignant')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getListOfFiles(dirName):\n    # create a list of file and sub directories \n    # names in the given directory \n    listOfFile = os.listdir(dirName)\n    allFiles = list()\n    # Iterate over all the entries\n    for entry in listOfFile:\n        # Create full path\n        fullPath = os.path.join(dirName, entry)\n        # If entry is a directory then get the list of files in this directory \n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n                \n    return allFiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport math\nimport os\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom keras import backend as K\nimport gc\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json\nimport itertools\n\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Dataset_loader(DIR, RESIZE, sigmaX=10):\n    IMG = []\n    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n        PATH = os.path.join(DIR,IMAGE_NAME)\n        _, ftype = os.path.splitext(PATH)\n        if ftype == \".png\":\n            img = read(PATH)\n           \n            img = cv2.resize(img, (RESIZE,RESIZE))\n           \n            IMG.append(np.array(img))\n    return IMG\n\ndef processing2(img_path):\n    img = cv2.imread(img_path)\n    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (224,224))\n    image = cv2.medianBlur(image, 5)\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n    image[:, :, 2] = cv2.equalizeHist(image[:, :, 2])\n    image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n    cv2.imwrite(img_path,image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files_benign=getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign')\nfor f in files_benign:\n    if f.endswith('.png'):\n        shutil.copy(f,'augmented/benign')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files_malignant=getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant')\nfor f in files_malignant:\n    if f.endswith('.png'):\n        shutil.copy(f,'augmented/malignant')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"benign_train = np.array(Dataset_loader('augmented/benign',224))\nmalign_train = np.array(Dataset_loader('augmented/malignant',224))\nbenign_test = np.array(Dataset_loader('augmented/benign',224))\nmalign_test = np.array(Dataset_loader('augmented/malignant',224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Skin Cancer: Malignant vs. Benign\n# Create labels\nbenign_train_label = np.zeros(len(benign_train))\nmalign_train_label = np.ones(len(malign_train))\nbenign_test_label = np.zeros(len(benign_test))\nmalign_test_label = np.ones(len(malign_test))\n\n# Merge data \nX_train = np.concatenate((benign_train, malign_train), axis = 0)\nY_train = np.concatenate((benign_train_label, malign_train_label), axis = 0)\nX_test = np.concatenate((benign_test, malign_test), axis = 0)\nY_test = np.concatenate((benign_test_label, malign_test_label), axis = 0)\n\n# Shuffle train data\ns = np.arange(X_train.shape[0])\nnp.random.shuffle(s)\nX_train = X_train[s]\nY_train = Y_train[s]\n\n# Shuffle test data\ns = np.arange(X_test.shape[0])\nnp.random.shuffle(s)\nX_test = X_test[s]\nY_test = Y_test[s]\n\n# To categorical\nY_train = to_categorical(Y_train, num_classes= 2)\nY_test = to_categorical(Y_test, num_classes= 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(\n    X_train, Y_train, \n    test_size=0.2, \n    random_state=11\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # Display first 15 images of moles, and how they are classified\nw=60\nh=40\nfig=plt.figure(figsize=(15, 15))\ncolumns = 4\nrows = 3\n\nfor i in range(1, columns*rows +1):\n    ax = fig.add_subplot(rows, columns, i)\n    if np.argmax(Y_train[i]) == 0:\n        ax.title.set_text('Benign')\n    else:\n        ax.title.set_text('Malignant')\n    plt.imshow(x_train[i], interpolation='nearest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 8\n\n# Using original generator\ntrain_generator = ImageDataGenerator(\n        zoom_range=2,  # set range for random zoom\n        rotation_range = 90,\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(backbone, lr=1e-4):\n    model = Sequential()\n    model.add(backbone)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(2, activation='softmax'))\n    \n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=lr),\n        metrics=['accuracy']\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session()\ngc.collect()\n\nresnet = DenseNet201(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\n\n\n \n\n\nmodel = build_model(resnet ,lr = 1e-4)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Learning Rate Reducer\nlearn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,\n                                  verbose=1,factor=0.2, min_lr=1e-7)\n\n# Checkpoint\nfilepath=\"weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    train_generator.flow(x_train, y_train, batch_size=BATCH_SIZE),\n    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n    epochs=5,\n    validation_data=(x_val, y_val),\n    callbacks=[learn_control, checkpoint]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(str(history.history), f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['accuracy', 'val_accuracy']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df[['lr']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_val_pred = model.predict(x_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(np.argmax(y_val, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=55)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\ncm = confusion_matrix(np.argmax(Y_test, axis=1),np.argmax(Y_pred, axis=1))\n\ncm_plot_label =['benign', 'malignant']\nplot_confusion_matrix(cm, cm_plot_label, title ='Confusion Metrix for Breast Cancer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nclassification_report( np.argmax(Y_test, axis=1),np.argmax(Y_pred, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(Y_test)):\n    if(np.argmax(Y_test[i])==np.argmax(Y_pred[i])):\n        prop_class.append(i)\n    if(len(prop_class)==8):\n        break\n\ni=0\nfor i in range(len(Y_test)):\n    if(not np.argmax(Y_test[i])==np.argmax(Y_pred[i])):\n        mis_class.append(i)\n    if(len(mis_class)==8):\n        break\n\n# # Display first 8 images of benign\nw=60\nh=40\nfig=plt.figure(figsize=(18, 10))\ncolumns = 4\nrows = 2\n\ndef Transfername(namecode):\n    if namecode==0:\n        return \"Benign\"\n    else:\n        return \"Malignant\"\n    \nfor i in range(len(prop_class)):\n    ax = fig.add_subplot(rows, columns, i+1)\n    ax.set_title(\"Predicted result:\"+ Transfername(np.argmax(Y_pred[prop_class[i]]))\n                       +\"\\n\"+\"Actual result: \"+ Transfername(np.argmax(Y_test[prop_class[i]])))\n    plt.imshow(X_test[prop_class[i]], interpolation='nearest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}