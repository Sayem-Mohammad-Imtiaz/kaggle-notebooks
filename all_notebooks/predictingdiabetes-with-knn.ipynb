{"cells":[{"metadata":{"_uuid":"6f26eb78b366364f38fe16a49e5c0c512f5915ee"},"cell_type":"markdown","source":"Importing important dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings    #warnings to ignore any kind of warnings that we may recieve.\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc965bb48ebe7ebb92b5386183af5d8f4e257b0f"},"cell_type":"code","source":"def display_all(df):\n    '''\n    input: dataframe\n    description: it takes a dataframe and allows use to show a mentioned no. of rows and columns in the screen\n    '''\n    with pd.option_context(\"display.max_rows\",10,\"display.max_columns\",9):  #you might want to change these numbers.\n        display(df)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/diabetes.csv')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56a1f75340bc2d05162698a96ead60aa9782328b","trusted":true},"cell_type":"code","source":"display_all(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e40a814b38fc8823a6905280687598fd197077a7"},"cell_type":"markdown","source":"Making a function for showing us a well defind table regarding the no. of missing values in each rows of the dataframe"},{"metadata":{"trusted":true,"_uuid":"8e5a47500f9cf82bc5e1e11643bf0eccd7688b59"},"cell_type":"code","source":"def missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        \n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5c784efd9e26eb4b1bfbeab43505cbd06c39839"},"cell_type":"markdown","source":"**Checking Missing values**"},{"metadata":{"trusted":true,"_uuid":"7e958ea37d136017dacee891be2413776945d05f"},"cell_type":"code","source":"missing_values_table(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b931ba2d999c027f5045005ae739ffd2c53cc13"},"cell_type":"markdown","source":"We found that no missing values are there in our dataset. But one thing we forgot to analyse that few features that are mentioned in the dataset like **BMI**  ,**Insulin** ,**BloodPressure**,**SkinThickness**,**Glucose** cannot have a value of zero. So there is a strong possibility that the rows in which these features are termed as zero is due to unavailability of data and hence can be termed as missing values "},{"metadata":{"trusted":true,"_uuid":"53ee66f6a05e97176c9b693e6ebb36a34638a4e8"},"cell_type":"code","source":"features_with_missing_values=['BMI','SkinThickness','BloodPressure','Insulin','Glucose']\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ceb41db9aebb85e6f25e7357061c4a578deda70d"},"cell_type":"markdown","source":"**It is worth mentioning that why we used median and not mean to replace the value of 0 in these mentioned columns?**\nIt is due to the fact that there can be some outliers (more spread out data points) that may have a strong effect on mean and mean can be more biased towards these outliers. So a good thing is to use median since median is not affected by outliers. To study more on this topic : [https://medium.com/@pswaldia1/statistics-for-data-science-why-it-is-important-e30c60c5018d](http://)"},{"metadata":{"trusted":true,"_uuid":"c3151a3dbd154fedcbff96463970a319f91c446e"},"cell_type":"code","source":"for i in features_with_missing_values:\n    df[i]=df[i].replace(0,np.median(df[i].values))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09a8f1588fe4e12106018635a5704679609d0422"},"cell_type":"markdown","source":"**Making target column different from the dataset**"},{"metadata":{"trusted":true,"_uuid":"9c7ddd2ce29575b1c8492448c310a4574fab3abe"},"cell_type":"code","source":"target=df['Outcome'].values\ndf.drop(['Outcome'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aadb3a04aad26579e071429d1d18797f21e61380"},"cell_type":"markdown","source":"**Now we need to standardise the dataset because data is not well spread and is varied in magnitude that may make training harder**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"bb8273beb5acc34ce5fe04d1d2b01af72d3e66aa"},"cell_type":"code","source":"#from sklearn importing standard scalar that will convert the provided dataframe into standardised one.\nfrom sklearn.preprocessing import StandardScaler                                              \nsta=StandardScaler()\ninput=sta.fit_transform(df)    #will give numpy array as output","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0fbf50add109e0a6acc092d881a6423c68eea6e"},"cell_type":"markdown","source":"**Splitting the dataset into train and test set**"},{"metadata":{"trusted":true,"_uuid":"bb63b1b2d8ae68dcc93b3bec3c4dc4ca17e439b3"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(input,target,test_size=0.1,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"368156108d4f7e869b818af0222802a1fee82fa2"},"cell_type":"markdown","source":"**Using Knearest classifier**"},{"metadata":{"trusted":true,"_uuid":"accd0b00621904cd86a8b30b987569642a647a7d"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1aab9a0ee197b68e843e0f34bd07b40d9718d1da"},"cell_type":"code","source":"knn=KNeighborsClassifier(n_neighbors=7)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a16081d032da6b599c6baa837cd823da8e5fc91e"},"cell_type":"markdown","source":"**Training model on train set**"},{"metadata":{"trusted":true,"_uuid":"bbe0a888e58d1e06b2ee8dc6a0686816e9a50ab1"},"cell_type":"code","source":"knn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea374e49a1ce52b997f6e382f231d725c613832b"},"cell_type":"markdown","source":"**Checking accuracy on test set**"},{"metadata":{"trusted":true,"_uuid":"57c1832f2240a0770203f56db2bb0f4f17969f6c"},"cell_type":"code","source":"knn.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bf176f50165020094165a03227e5f70c99af4fc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}