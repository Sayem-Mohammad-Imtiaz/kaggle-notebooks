{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Summary\n\nWe face the problem of predicting tweets sentiment. \nWe have coded the text as Bag of Words and applied an SVM model. We have built a pipeline to check different hyperparameters using cross-validation. At the end, we have obtained a good model which achieve an AUC of **0.92** ","metadata":{}},{"cell_type":"markdown","source":"## Data loading and cleaning","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom nltk.tokenize import TweetTokenizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, accuracy_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score","metadata":{"_uuid":"db376733d0954ea531a81ee31675624c5968706f","_cell_guid":"d5db572f-3b58-42a5-979a-464769d52524","execution":{"iopub.status.busy":"2021-06-19T10:22:49.33389Z","iopub.execute_input":"2021-06-19T10:22:49.334496Z","iopub.status.idle":"2021-06-19T10:22:49.358759Z","shell.execute_reply.started":"2021-06-19T10:22:49.334448Z","shell.execute_reply":"2021-06-19T10:22:49.357767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/twitter-airline-sentiment/Tweets.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:49.360872Z","iopub.execute_input":"2021-06-19T10:22:49.361275Z","iopub.status.idle":"2021-06-19T10:22:49.466394Z","shell.execute_reply.started":"2021-06-19T10:22:49.361238Z","shell.execute_reply":"2021-06-19T10:22:49.46525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We take only the tweets we are very confident with. We use the BeautifulSoup library to process html encoding present in some tweets because scrapping.","metadata":{}},{"cell_type":"code","source":"data_clean = data.copy()\ndata_clean = data_clean[data_clean['airline_sentiment_confidence'] > 0.65]\ndata_clean['sentiment'] = data_clean['airline_sentiment'].\\\n    apply(lambda x: 1 if x=='negative' else 0)\n\ndata_clean['text_clean'] = data_clean['text'].apply(lambda x: BeautifulSoup(x, \"lxml\").text)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:49.46785Z","iopub.execute_input":"2021-06-19T10:22:49.468415Z","iopub.status.idle":"2021-06-19T10:22:51.971939Z","shell.execute_reply.started":"2021-06-19T10:22:49.468377Z","shell.execute_reply":"2021-06-19T10:22:51.971178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to distinguish two cases: tweets with negative sentiment and tweets with non-negative sentiment","metadata":{}},{"cell_type":"code","source":"data_clean['sentiment'] = data_clean['airline_sentiment'].apply(lambda x: 1 if x=='negative' else 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:51.973176Z","iopub.execute_input":"2021-06-19T10:22:51.973505Z","iopub.status.idle":"2021-06-19T10:22:51.986653Z","shell.execute_reply.started":"2021-06-19T10:22:51.973471Z","shell.execute_reply":"2021-06-19T10:22:51.985858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_clean = data_clean.loc[:, ['text_clean', 'sentiment']]","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:51.989985Z","iopub.execute_input":"2021-06-19T10:22:51.990685Z","iopub.status.idle":"2021-06-19T10:22:52.004735Z","shell.execute_reply.started":"2021-06-19T10:22:51.990644Z","shell.execute_reply":"2021-06-19T10:22:52.003709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_clean.head()","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-06-19T10:22:52.008297Z","iopub.execute_input":"2021-06-19T10:22:52.00854Z","iopub.status.idle":"2021-06-19T10:22:52.023591Z","shell.execute_reply.started":"2021-06-19T10:22:52.008518Z","shell.execute_reply":"2021-06-19T10:22:52.022423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine Learning Model","metadata":{}},{"cell_type":"markdown","source":"We split the data into training and testing set:","metadata":{}},{"cell_type":"code","source":"train, test = train_test_split(data_clean, test_size=0.2, random_state=1)\nX_train = train['text_clean'].values\nX_test = test['text_clean'].values\ny_train = train['sentiment']\ny_test = test['sentiment']","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:52.025308Z","iopub.execute_input":"2021-06-19T10:22:52.02567Z","iopub.status.idle":"2021-06-19T10:22:52.034516Z","shell.execute_reply.started":"2021-06-19T10:22:52.025635Z","shell.execute_reply":"2021-06-19T10:22:52.033617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(text): \n    tknzr = TweetTokenizer()\n    return tknzr.tokenize(text)\n\ndef stem(doc):\n    return (stemmer.stem(w) for w in analyzer(doc))\n\nen_stopwords = set(stopwords.words(\"english\")) \n\nvectorizer = CountVectorizer(\n    analyzer = 'word',\n    tokenizer = tokenize,\n    lowercase = True,\n    ngram_range=(1, 1),\n    stop_words = en_stopwords)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:52.035956Z","iopub.execute_input":"2021-06-19T10:22:52.036382Z","iopub.status.idle":"2021-06-19T10:22:52.048166Z","shell.execute_reply.started":"2021-06-19T10:22:52.036345Z","shell.execute_reply":"2021-06-19T10:22:52.047435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to use cross validation and grid search to find good hyperparameters for our SVM model. We need to build a pipeline to don't get features from the validation folds when building each training model.","metadata":{}},{"cell_type":"code","source":"kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:52.049552Z","iopub.execute_input":"2021-06-19T10:22:52.050108Z","iopub.status.idle":"2021-06-19T10:22:52.055869Z","shell.execute_reply.started":"2021-06-19T10:22:52.050069Z","shell.execute_reply":"2021-06-19T10:22:52.055149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(1)\n\npipeline_svm = make_pipeline(vectorizer, \n                            SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\n\ngrid_svm = GridSearchCV(pipeline_svm,\n                    param_grid = {'svc__C': [0.01, 0.1, 1]}, \n                    cv = kfolds,\n                    scoring=\"roc_auc\",\n                    verbose=1,   \n                    n_jobs=-1) \n\ngrid_svm.fit(X_train, y_train)\ngrid_svm.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:22:52.057334Z","iopub.execute_input":"2021-06-19T10:22:52.057945Z","iopub.status.idle":"2021-06-19T10:30:23.259676Z","shell.execute_reply.started":"2021-06-19T10:22:52.057895Z","shell.execute_reply":"2021-06-19T10:30:23.25879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_svm.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:23.261404Z","iopub.execute_input":"2021-06-19T10:30:23.261754Z","iopub.status.idle":"2021-06-19T10:30:23.271428Z","shell.execute_reply.started":"2021-06-19T10:30:23.261715Z","shell.execute_reply":"2021-06-19T10:30:23.270428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_svm.best_score_","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:23.272823Z","iopub.execute_input":"2021-06-19T10:30:23.273363Z","iopub.status.idle":"2021-06-19T10:30:23.283132Z","shell.execute_reply.started":"2021-06-19T10:30:23.273324Z","shell.execute_reply":"2021-06-19T10:30:23.28221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def report_results(model, X, y):\n    pred_proba = model.predict_proba(X)[:, 1]\n    pred = model.predict(X)        \n\n    auc = roc_auc_score(y, pred_proba)\n    acc = accuracy_score(y, pred)\n    f1 = f1_score(y, pred)\n    prec = precision_score(y, pred)\n    rec = recall_score(y, pred)\n    result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:23.285488Z","iopub.execute_input":"2021-06-19T10:30:23.285773Z","iopub.status.idle":"2021-06-19T10:30:23.293794Z","shell.execute_reply.started":"2021-06-19T10:30:23.285746Z","shell.execute_reply":"2021-06-19T10:30:23.29298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see how the model (with the best hyperparameters) works on the test data:","metadata":{}},{"cell_type":"code","source":"report_results(grid_svm.best_estimator_, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:23.295043Z","iopub.execute_input":"2021-06-19T10:30:23.295451Z","iopub.status.idle":"2021-06-19T10:30:27.545719Z","shell.execute_reply.started":"2021-06-19T10:30:23.295412Z","shell.execute_reply":"2021-06-19T10:30:27.544975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_roc_curve(model, X, y):\n    pred_proba = model.predict_proba(X)[:, 1]\n    fpr, tpr, _ = roc_curve(y, pred_proba)\n    return fpr, tpr","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:27.547045Z","iopub.execute_input":"2021-06-19T10:30:27.547361Z","iopub.status.idle":"2021-06-19T10:30:27.553734Z","shell.execute_reply.started":"2021-06-19T10:30:27.547326Z","shell.execute_reply":"2021-06-19T10:30:27.552865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_svm = get_roc_curve(grid_svm.best_estimator_, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:27.555014Z","iopub.execute_input":"2021-06-19T10:30:27.555337Z","iopub.status.idle":"2021-06-19T10:30:29.723076Z","shell.execute_reply.started":"2021-06-19T10:30:27.555301Z","shell.execute_reply":"2021-06-19T10:30:29.721425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr = roc_svm\nplt.figure(figsize=(14,8))\nplt.plot(fpr, tpr, color=\"red\")\nplt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Roc curve')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:29.728698Z","iopub.execute_input":"2021-06-19T10:30:29.729275Z","iopub.status.idle":"2021-06-19T10:30:30.17711Z","shell.execute_reply.started":"2021-06-19T10:30:29.729219Z","shell.execute_reply":"2021-06-19T10:30:30.176044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see if our model has some bias or variance problem ploting its learning curve:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, test_scores = \\\n    learning_curve(grid_svm.best_estimator_, X_train, y_train, cv=5, n_jobs=-1, \n                   scoring=\"roc_auc\", train_sizes=np.linspace(.1, 1.0, 10), random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:30:30.178164Z","iopub.execute_input":"2021-06-19T10:30:30.178493Z","iopub.status.idle":"2021-06-19T10:39:52.240184Z","shell.execute_reply.started":"2021-06-19T10:30:30.178455Z","shell.execute_reply":"2021-06-19T10:39:52.23927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_learning_curve(X, y, train_sizes, train_scores, test_scores, title='', ylim=None, figsize=(14,8)):\n\n    plt.figure(figsize=figsize)\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"lower right\")\n    return plt","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:39:52.241477Z","iopub.execute_input":"2021-06-19T10:39:52.241814Z","iopub.status.idle":"2021-06-19T10:39:52.252733Z","shell.execute_reply.started":"2021-06-19T10:39:52.241769Z","shell.execute_reply":"2021-06-19T10:39:52.249888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_learning_curve(X_train, y_train, train_sizes, \n                    train_scores, test_scores, ylim=(0.7, 1.01), figsize=(14,6))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:39:52.254044Z","iopub.execute_input":"2021-06-19T10:39:52.254434Z","iopub.status.idle":"2021-06-19T10:39:52.490722Z","shell.execute_reply.started":"2021-06-19T10:39:52.254396Z","shell.execute_reply":"2021-06-19T10:39:52.489845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like there isn't a big bias or variance problem, but it is clear that our model would work better with more data:. if we can get more labeled data the model performance will increase.","metadata":{}},{"cell_type":"markdown","source":"## Examples\n\nWe are going to apply the obtained machine learning model to some example text. If the output is **1** it means that the text has a negative sentiment associated:","metadata":{}},{"cell_type":"code","source":"grid_svm.predict([\"flying with @united is always a great experience\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:39:52.491995Z","iopub.execute_input":"2021-06-19T10:39:52.492454Z","iopub.status.idle":"2021-06-19T10:39:52.502853Z","shell.execute_reply.started":"2021-06-19T10:39:52.492418Z","shell.execute_reply":"2021-06-19T10:39:52.502152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_svm.predict([\"flying with @united is always a great experience. If you don't lose your luggage\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:39:52.504721Z","iopub.execute_input":"2021-06-19T10:39:52.505132Z","iopub.status.idle":"2021-06-19T10:39:52.513993Z","shell.execute_reply.started":"2021-06-19T10:39:52.505099Z","shell.execute_reply":"2021-06-19T10:39:52.51288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_svm.predict([\"I love @united. Sorry, just kidding!\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:39:52.515391Z","iopub.execute_input":"2021-06-19T10:39:52.515848Z","iopub.status.idle":"2021-06-19T10:39:52.525896Z","shell.execute_reply.started":"2021-06-19T10:39:52.515812Z","shell.execute_reply":"2021-06-19T10:39:52.525029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_svm.predict([\"@united very bad experience!\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:39:52.527652Z","iopub.execute_input":"2021-06-19T10:39:52.528089Z","iopub.status.idle":"2021-06-19T10:39:52.536806Z","shell.execute_reply.started":"2021-06-19T10:39:52.528053Z","shell.execute_reply":"2021-06-19T10:39:52.535785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_svm.predict([\"@united very bad experience!\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T10:51:36.574299Z","iopub.execute_input":"2021-06-19T10:51:36.574609Z","iopub.status.idle":"2021-06-19T10:51:36.583558Z","shell.execute_reply.started":"2021-06-19T10:51:36.574581Z","shell.execute_reply":"2021-06-19T10:51:36.58251Z"},"trusted":true},"execution_count":null,"outputs":[]}]}