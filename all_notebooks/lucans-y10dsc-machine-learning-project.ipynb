{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using Machine Learning Methods Inorder To Predict The Amount Of Installations Of Games On The Google Play Store.","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nHello kaggle community, or probably just Mr. Nolan in this case,\n\nin this workbook we will be looking at using certain machine learning models inorder to make predictions on our android-games data set, which contains data such as: the amounts of a certain game sold on the store, the ratings a game has received, its growth over a certain period of time , the amounts of good ratings it has received etc...\n\n\n***Our Variables***\n\nmachine learning methods are used by data scientists to predict certain outcomes through use of already given information.\nin data science, the values used to make predictions are referred to as \"X\" values aswell as independent variables or features, while the value that is to be predicted is the \"y\" value or dependant variable.\n\nIn our case our \"X\" Values are;\n* Average Rating of the game out of 5 stars\n* Price of the game in Australian dollars\n* 5 star ratings\n* Growth 60 days\n\nAnd our \"y\" value is:\n* amount of installataions of game (millions)\n\n\n**Issues Within The Data Set**\n\nout of our four features, the most impactfull on our \"y\" value will be the price of the game, due to the fact that in any situation, the game becoming costly will decrease its appeal to android users.\nthis price factor may provide small outliers in our installation values, as they will have slightly less downloads and will lower the download prediction by fractions of a million in turn raising our Mean absolute error by a small amount.\n\n**Discussion Of Machine Learning Model Usage**\n\ninorder to effectivley compare and contrast different machine learning methods, we will be implementing mulitivariant linear regression, aswell as a random forest.\n\n**Multivariant Linear Regression**\n\nLinear Regression is a machine learning method that implements a line of best fit inorder to attempt to replicate the relationships between out \"X\" and \"y\" variables.\nThe term \"multivariant\" means that multiple variables are used inorder to predict the \"y\" value, providing a more accurate prediction.\n\n**Random Forest Regressors**\n\nA Random forest is a machine learning method comprised of multiple decison tree regressors, hence the term \"forest\".\na desicion tree regressor is a machine learning method where the dataset is broken down into smaller and smaller subsets of data untill a conclusion is drawn, the term regression implies that the tree is dealing with numerical values, and not string values such as \"hot\" or \"cold\".\nIn a random forest multiple desicion trees are constructed from bootstrapped data sets that have been reconstructed from random and possibly overlapping values derived from the original data set.\neach induvidual bootstrapped set is then used inorder to create a regression tree, and after a large amount of trees have been constructed, the most prominent prediction is taken from all of them, leaving us with a final result.\n\n**Least MAE Method?**\n \nI believe that the Multivariant Linear Regression will be the most effective machine learning method, as what we are attempting to predict is a single numerical value, along with features that are also all numerical discreet data.\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# importing nescesary libraries and accesing files\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # data visualisation\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import linear_model # importing our linear regression\nfrom sklearn.model_selection import train_test_split # our tool to split the data inorder to perform a validation\nfrom sklearn.metrics import mean_absolute_error # mae calculations\nfrom sklearn.ensemble import RandomForestRegressor # importing our random forest\n\n# loading from kaggle\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T06:38:38.273005Z","iopub.execute_input":"2021-06-29T06:38:38.273353Z","iopub.status.idle":"2021-06-29T06:38:38.285796Z","shell.execute_reply.started":"2021-06-29T06:38:38.273323Z","shell.execute_reply":"2021-06-29T06:38:38.285051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring Our Data\n\n**Why Was This Data Chosen**\n\nThe main reasoning behind the choice of this paticular data set is that it contains only numerical values apart from the name of the game its self and its catagory, meaning it will be easy to work efficiently and make more concise predictions with the data\n\n**Recap of Variables**\n\nOur Features:\n\n* The average Android Users rating of the game, out of 5 stars\n* The price of the game in Australian dollars\n* The amount of 5 star ratings that the certain game posseses\n* The %Growth of the game over a 60 day time period\n\nWhat we Wish to Predict:\n* amount of installations that a game posseses, measured in millions","metadata":{}},{"cell_type":"code","source":"# Getting CSV file for data\ntrain_file_path = '../input/ggldataset/android-games.csv'\n\n# Create a new Pandas DataFrame with our training data\ngoogle_train_data = pd.read_csv(train_file_path)\n\n# Taking a squiz at our data prior to cleaning\ngoogle_train_data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T06:38:38.287025Z","iopub.execute_input":"2021-06-29T06:38:38.287601Z","iopub.status.idle":"2021-06-29T06:38:38.445337Z","shell.execute_reply.started":"2021-06-29T06:38:38.287566Z","shell.execute_reply":"2021-06-29T06:38:38.444867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning Our Data\n\n**Why Do We Prepare Our Data?**\n\nin machine learning it is important to have a ready and functional data set, inorder to implement machine learning methods effectivley.\n\n**Our Preparations**\n\nWith this data I have chosen to drop the entire row of missing values instead of just creating an average value, as the causes for the missing values may be dependant of the outliers in said rows","metadata":{}},{"cell_type":"code","source":"# Selecting a number of independent variables (\"X\" values) we will use to predict our dependent variable (\"y\" value)\n# Note: the \"y\" value is kept in the data set inorder to be seperated out later, this is done for easief data preperation\nselected_columns = ['average rating', 'price', 'growth (60 days)', '5 star ratings','installs']\n\n# Create our new training set containing only the features we want\nprepared_data = google_train_data[selected_columns]\n\n# Drop rows (axis=0) that contain missing values\nprepared_data = prepared_data.dropna(axis=1)\n\n# Converting all values to intiger values, inorder to deny the possibility of issues with the data set later\nprepared_data = prepared_data.astype(int)\n\n# Taking a look at our cleaned data\nprepared_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T06:38:38.448479Z","iopub.execute_input":"2021-06-29T06:38:38.44869Z","iopub.status.idle":"2021-06-29T06:38:38.481705Z","shell.execute_reply.started":"2021-06-29T06:38:38.448669Z","shell.execute_reply":"2021-06-29T06:38:38.480798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Header of cleaned data\nprepared_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T06:38:38.483021Z","iopub.execute_input":"2021-06-29T06:38:38.483279Z","iopub.status.idle":"2021-06-29T06:38:38.494024Z","shell.execute_reply.started":"2021-06-29T06:38:38.483252Z","shell.execute_reply":"2021-06-29T06:38:38.493038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting and Fitting Our Data\n\n**Multivariant Linear Regression VS Random Forest Regressor**\n\n**Multivariant Linear Regression**\n\nLinear Regression is a machine learning method that implements a line of best fit inorder to attempt to replicate the relationships between out \"X\" and \"y\" variables.\nThe term \"multivariant\" means that multiple variables are used inorder to predict the \"y\" value, providing a more accurate prediction.\n\n**Random forest Regressors**\n\nA Random forest is a machine learning method comprised of multiple decison tree regressors, hence the term \"forest\".\na desicion tree regressor is a machine learning method where the dataset is broken down into smaller and smaller subsets of data untill a conclusion is drawn, the term regression implies that the tree is dealing with numerical values, and not string values such as \"hot\" or \"cold\".\nIn a random forest multiple desicion trees are constructed from bootstrapped data sets that have been reconstructed from random and possibly overlapping values derived from the original data set.\neach induvidual bootstrapped set is then used inorder to create a regression tree, and after a large amount of trees have been constructed, the most prominent prediction is taken from all of them, leaving us with a final result.\n\n**Why Do We Split Our Data Set?**\n\nIn data science we use a train test split method, meaning splitting our whole data set in to two sets, one for training (the training set) our model, and another for comparing our predictions to (the testing set).","metadata":{}},{"cell_type":"code","source":"# Separate out the prediction target\ny = prepared_data.installs\n\n# Dropping the \"y\" value from the original dataframe and keeping the rest of the data as our \"X\" values\nX = prepared_data.drop('installs', axis=1)\n\n# Spliting data into training data and validation data, for the \"X\" and the \"y\"\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n\n# Defining forest\nforest_model = RandomForestRegressor(random_state=1)\n\n# Fitting forest\nforest_model.fit(train_X, train_y)\n\n# Getting predictions via random forest\nforest_prediction = forest_model.predict(val_X)\n\n# Looking at our MAE for our random forest\nfmae = mean_absolute_error(val_y, forest_prediction)\n\n# -------------------------------------------------------------------------------------------------------------- #\n\n# Defining regressor\ninstalls_predictor = linear_model.LinearRegression()\n\n# Fasciting regressor\ninstalls_predictor.fit(train_X, train_y)\n\n# Get predicted installations via linear regression\nlinear_predictions = installs_predictor.predict(val_X)\n\n# Getting at our MAE for our Linear Regression\nlmae = mean_absolute_error(val_y, linear_predictions)\n\n# Printing Our Predictions\nprint(f\"\"\"                        linear regression predictions \n      {linear_predictions}\n                  Random forest predictions\n      {forest_prediction}\n      \"\"\")\n\n# Printing our MAE\nprint(f\"\"\"       linear regression MAE\n       {lmae}\n       random forest regressor MAE\n       {fmae}\"\"\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T06:38:38.495069Z","iopub.execute_input":"2021-06-29T06:38:38.495298Z","iopub.status.idle":"2021-06-29T06:38:38.774891Z","shell.execute_reply.started":"2021-06-29T06:38:38.495267Z","shell.execute_reply":"2021-06-29T06:38:38.774194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"# Performance of Our Models\n\n**What Have we Observed?**\n\nAfter running bot our models simeltaniousley, we can see that the MAE of the random forest model is lower than that of the linear ragression model.\nthis difference in accuracy could be due to the fact that the forest utilises multiple bootstrapped datasets inorder to make predictions, while the linear regression only takes our singular set of regular training data.","metadata":{}},{"cell_type":"markdown","source":"# Tuning Our Hyper Parameters\n\n**What are Hyperparameters?**\n\nIn data science, the hyperparameters of a model ar the parts that can be altered after the fact, making for a better MAE.\nThe hyperparameters of our models are as follows:\n\n**Linear Regressor Tuning**\n\nin a linear regression model, when tuning our hyper paramaters we can consider adding or removing some of the features that we use inorder make predictions, for example the 30 day growth could be implemented as a 5th variable, or used as a replacement for the 60 day growth.\n\n**Random Forest Regressor Tuning**\n\nWith a Random Forest there are also hyperparameters that are available for us to tune and alter.\nWe can look at the amount of leaf nodes in the trees, and change them according to the best prediction.\n    ","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n\n**Summary**\n\nIn this investigation we have looked at the effectivness of different machine learning methods on predicting the amount of installations of games on the google play store.\nwe have implemented both Multivariant Linear Regression and Random Forest Regression methods to predict our data.\n\n**What Did We Find**\n\nAfter performing both methods of machine learning, I have found that, disproving my hypothesis, random forests are a more effective method for prediction with our data set.\nWe have also found that the installation amount was affected the most by the prices of the games, which made the overal spread of the data nearer to the lower end of the spectrum.\n\n\n\n\n","metadata":{}}]}