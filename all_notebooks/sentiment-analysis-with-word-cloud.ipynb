{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:27:19.604134Z","start_time":"2020-04-20T15:27:19.598119Z"},"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Data Gathering"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:35:34.367878Z","start_time":"2020-04-20T14:35:33.921118Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:25:26.266972Z","start_time":"2020-04-20T14:25:26.252013Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:25:39.088679Z","start_time":"2020-04-20T14:25:39.081732Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"df.label.unique()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:25:47.286488Z","start_time":"2020-04-20T14:25:47.274522Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"df.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:26:05.688087Z","start_time":"2020-04-20T14:26:05.596784Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"df.label.value_counts().plot(kind='pie', figsize=(20,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- '0' refers to negative feedback, '1' refers to positive feedback"},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:13:36.395171Z","start_time":"2020-04-20T15:13:36.389187Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"def text_prepare(text):\n    wordnet = WordNetLemmatizer()\n    STOPWORDS = set(stopwords.words('english'))\n    text = text.lower()\n    tokens = nltk.word_tokenize(text)\n    tokens = [i for i in tokens if len(i)>2]\n    tokens = [i for i in tokens if i.isalpha()]\n    tokens = [i for i in tokens if i not in STOPWORDS]\n    tokens = [wordnet.lemmatize(i) for i in tokens]\n    return tokens","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:36:53.663063Z","start_time":"2020-04-20T14:35:39.540733Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"df['text'] = df['text'].apply(lambda x: text_prepare(x))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:37:35.95496Z","start_time":"2020-04-20T14:37:35.949973Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"## A dictionary to count the frequency of words\nfreq_count = {}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:38:59.582351Z","start_time":"2020-04-20T14:38:58.552013Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"for line in df['text']:\n    for word in line:\n        if word not in freq_count:\n            freq_count[word] = 1\n        else:\n            freq_count[word] += 1\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:42:08.635344Z","start_time":"2020-04-20T14:42:08.570926Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"freq_count_sorted = {k: v for k, v in sorted(freq_count.items(), key=lambda item: item[1], reverse=True)}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:44:50.299321Z","start_time":"2020-04-20T14:44:50.295333Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"SET_LIMIT = 5000","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:52:49.594483Z","start_time":"2020-04-20T14:52:49.584509Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"word_index_map = {v:k for k,v in enumerate(list(freq_count_sorted.keys())[:SET_LIMIT])}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:52:51.901015Z","start_time":"2020-04-20T14:52:51.896028Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"def text_vector(text, label):\n    x = np.zeros(len(word_index_map)+1)\n    for word in text:\n        if word in word_index_map:\n            index = word_index_map[word]\n            x[index] += 1\n        \n    x = x/x.sum()\n    x[-1] = label\n    return x ","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:53:43.993082Z","start_time":"2020-04-20T14:53:43.985096Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"data = np.zeros((len(df), len(word_index_map)+1))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:55:55.188238Z","start_time":"2020-04-20T14:55:50.68369Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"idx = 0\nindex = 0\nfor idx in range(len(df)):\n    tokens = df.iloc[idx,0]\n    label = df.iloc[idx,1]\n    data[index,:] = text_vector(tokens, label)\n    index += 1","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:56:02.322792Z","start_time":"2020-04-20T14:56:02.314816Z"},"heading_collapsed":true},"cell_type":"markdown","source":"## Data Modelling"},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:57:04.077533Z","start_time":"2020-04-20T14:57:04.071001Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"X = data[:,:-1]\ny = data[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:57:50.395796Z","start_time":"2020-04-20T14:57:43.018943Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T14:58:05.147989Z","start_time":"2020-04-20T14:58:04.887537Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"model.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring Test data"},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:13:13.007567Z","start_time":"2020-04-20T15:13:12.929777Z"},"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format/Test.csv')\ntest_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:13:50.620503Z","start_time":"2020-04-20T15:13:39.874758Z"},"trusted":true},"cell_type":"code","source":"test_data['text'] = test_data['text'].apply(lambda x: text_prepare(x))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:14:44.34013Z","start_time":"2020-04-20T15:14:44.334146Z"},"trusted":true},"cell_type":"code","source":"data2 = np.zeros((len(test_data), len(word_index_map)+1))","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:16:58.542777Z","start_time":"2020-04-20T15:16:57.956528Z"},"trusted":true},"cell_type":"code","source":"idx = 0\nindex = 0\nfor idx in range(len(test_data)):\n    tokens = test_data.iloc[idx,0]\n    label = test_data.iloc[idx,1]\n    data2[index,:] = text_vector(tokens, label)\n    index += 1","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:17:03.076407Z","start_time":"2020-04-20T15:17:03.072418Z"},"trusted":true},"cell_type":"code","source":"X_test = data2[:,:-1]\ny_test = data2[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:18:23.918406Z","start_time":"2020-04-20T15:18:23.878996Z"},"trusted":true},"cell_type":"code","source":"model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:18:08.032192Z","start_time":"2020-04-20T15:18:07.973367Z"},"trusted":true},"cell_type":"code","source":"model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion"},{"metadata":{},"cell_type":"markdown","source":"- The model score is good enough\n- Positive and Negative Impact words are listed below"},{"metadata":{},"cell_type":"markdown","source":"### Words Having *Positive* Impact"},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:40:42.020378Z","start_time":"2020-04-20T15:40:42.009409Z"},"trusted":true},"cell_type":"code","source":"threshold = 0.8\npositive_score = {}\nfor word,index in word_index_map.items():\n    weight = model.coef_[0][index]\n    if weight > threshold:\n        positive_score[word] = weight","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:40:00.092961Z","start_time":"2020-04-20T15:40:00.077005Z"},"trusted":true},"cell_type":"code","source":"positive_score = {k: v for k, v in sorted(positive_score.items(), key=lambda item: item[1], reverse=True)}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:40:30.803213Z","start_time":"2020-04-20T15:40:29.464298Z"},"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width = 1000, height = 500).generate(\" \".join(list(positive_score.keys())))\nplt.figure(figsize = (20, 20), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Words Having *Negative* Impact"},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:41:13.42109Z","start_time":"2020-04-20T15:41:13.409155Z"},"trusted":true},"cell_type":"code","source":"threshold = 1\nnegative_score = {}\nfor word,index in word_index_map.items():\n    weight = model.coef_[0][index]\n    if weight < -threshold:\n        negative_score[word] = weight","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:41:58.023507Z","start_time":"2020-04-20T15:41:58.002765Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"negative_score = {k: v for k, v in sorted(negative_score.items(), key=lambda item: item[1], reverse=False)}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-04-20T15:41:59.943995Z","start_time":"2020-04-20T15:41:58.507212Z"},"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width = 1000, height = 500).generate(\" \".join(list(negative_score.keys())))\nplt.figure(figsize = (20, 20), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Thank you. Please share your feedback to make it better. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}