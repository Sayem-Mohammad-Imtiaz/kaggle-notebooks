{"metadata":{"kernelspec":{"display_name":"tensor","language":"python","name":"tensor"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport nltk\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\nps = PorterStemmer()\nwordnet = WordNetLemmatizer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"message_df = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\")\nmessage_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"message_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the redundent looking collumns (for this project)\nto_drop = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\nmessage_df = message_df.drop(message_df[to_drop], axis=1)\n# Renaming the columns because I feel fancy today \nmessage_df.rename(columns = {\"v1\":\"label\", \"v2\":\"message\"}, inplace = True)\nmessage_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"message_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"message_df[\"message\"][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"message_df[\"label\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x= message_df[\"label\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"message_df[message_df[\"label\"] == \"spam\"].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Preprocessing ","metadata":{}},{"cell_type":"code","source":"sentences = message_df[\"message\"]\nsentences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text_stemming(sentences):\n    '''\n    Removing Stop Words, Punctuation, Numbers and Performing Stemming\n    '''\n    corpus = []\n    for i in range(len(sentences)):\n        review = re.sub(\"[^a-zA-Z]\",\" \", sentences[i])\n        review = review.lower()\n        words = review.split()\n        words = [ps.stem(word) for word in words if not word in set(stopwords.words(\"english\"))]\n        new_sentence = \" \".join(words)\n        corpus.append(new_sentence)\n        \n    return corpus\n\ndef preprocess_text_lemma(sentences):\n    '''\n    Removing Stop Words, Punctuation, Numbers and Performing lemmatization\n    '''\n    corpus = []\n    for i in range(len(sentences)):\n        review = re.sub(\"[^a-zA-Z]\",\" \", sentences[i])\n        review = review.lower()\n        words = review.split()\n        words = [wordnet.lemmatize(word) for word in words if not word in set(stopwords.words(\"english\"))]\n        new_sentence = \" \".join(words)\n        corpus.append(new_sentence)\n        \n    return corpus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# cleaned_corpus = preprocess_text_stemming(sentences)\ncleaned_corpus = preprocess_text_lemma(sentences)\nprint(len(cleaned_corpus))\ncleaned_corpus[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = nltk.word_tokenize(\" \".join(cleaned_corpus))\nprint(\"Total unique Words: \",len(set(words)))\nwords[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total Words: \", len(words))\nprint(\"Total unique Words: \",len(set(words)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BOW","metadata":{}},{"cell_type":"code","source":"cv = CountVectorizer(max_features = 2500) # considering only the top 2500 features only\nX = cv.fit_transform(cleaned_corpus).toarray()\nX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = pd.get_dummies(message_df[\"label\"])\ny = y.iloc[:,1].values # Considering only one value, since from its we can predict the next","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state = 41)\n\nprint(\"Shape of X_train: \", X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \", y_train.shape)\nprint(\"Shape of y_test: \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"model = MultinomialNB().fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}