{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers.experimental import preprocessing\n#from cnnArchitectures.Xception import get_xception_model\nfrom sklearn.model_selection import StratifiedKFold\nimport os\nimport datetime\n\n%matplotlib inline\n%reload_ext tensorboard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data paths\n# E.g. D:\\DATASETS\\ALL_2\\training\\fold_0\\all\ndataset_path = os.path.abspath('../input/leukemia-classification/C-NMC_Leukemia')\ntrain_data_path = dataset_path + '/training_data'\ntrain_data_paths = [\n    dataset_path + '/training_data/fold_0/',\n    dataset_path + '/training_data/fold_1/',\n    dataset_path + '/training_data/fold_2/'\n]\ntest_data_path = os.path.abspath('../input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data')\nimage_format = \".bmp\"\n\ndata_paths = list(map(os.path.abspath, train_data_paths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pathes_labels(path=None):\n    # Create list of picture pathes and labels\n    if path == None:\n        dir_iter = os.walk(train_data_path) # If we want all training data\n    else:\n        dir_iter = os.walk(path)\n    image_pathes = []\n    labels = []\n    for dir in dir_iter:\n        if \"all\" in dir[0]:\n            for img_name in dir[2]:\n                image_pathes.append(dir[0] + \"/\" + img_name)\n                labels.append(0)\n        elif \"hem\" in dir[0]:\n            for img_name in dir[2]:\n                image_pathes.append(dir[0] + \"/\" + img_name)\n                labels.append(1)\n    image_pathes, labels = np.array(image_pathes), np.array(labels)\n    return [image_pathes, labels]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment(image):\n    max_gamma_delta = 0.1\n    seed = 3746\n    image = tf.image.random_brightness(image, max_delta=max_gamma_delta, seed=None)\n    image = tf.image.random_flip_up_down(image, seed=None)\n    image = tf.image.random_flip_left_right(image, seed=None)\n    #image = tf.image.random_saturation()\n    return image\naug_model = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(image):\n    result = tf.image.resize(image, (256, 256))\n    result = tf.image.per_image_standardization(result)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(path):\n    image = tf.io.decode_bmp(tf.io.read_file(path), channels=3)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ds(filenames, labels, batch_size, pref_buf_size):\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    label_ds, image_pathes = tf.data.Dataset.from_tensor_slices(labels), tf.data.Dataset.from_tensor_slices(filenames)\n    images_ds = image_pathes.map(load_image, AUTOTUNE).map(preprocess, AUTOTUNE)\n    ds = tf.data.Dataset.zip((images_ds, label_ds)).batch(batch_size).prefetch(pref_buf_size)\n    return ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Return pair of (X_train, y_train), (X_test, y_test)\ndef get_stratified_datasets(X, Y):\n    # Create Stratified object\n    skf = StratifiedKFold(n_splits=4, shuffle=True)\n    skf.get_n_splits(X, Y)\n    for train_index, test_index in skf.split(X, Y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = Y[train_index], Y[test_index]\n        p = np.random.permutation(len(X_train))\n        X_train, y_train = X_train[p], y_train[p]\n        yield [[X_train, y_train], [X_test, y_test]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up dataset parameters\nBATCH_SIZE = 16\nIMAGE_SIZE = (256, 256)\nSEED = 322\nPREFETCH_BUFFER_SIZE = 400\nSHUFFLE_BUFFER_SIZE = 1000\nCACHE_DIR = \"caches/ds_cache\"\nds_params = dict(\n    labels=\"inferred\",\n    label_mode=\"categorical\",\n    class_names=[\"all\", \"hem\"],\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    image_size=IMAGE_SIZE,\n    seed=SEED\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, callbacks=None):\n    #../input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data_labels.csv\n    test_dir = dataset_path + \"/validation_data\"\n    test_data_csv = pd.read_csv(\n        test_dir + \"/C-NMC_test_prelim_phase_data_labels.csv\"\n    )\n    #print(test_data_csv.head())\n    #labels = np.array(test_data_csv[\"labels\"].to_list())\n    #inverted_labels = test_data_csv[[\"new_names\", \"labels\"]].sort_values(\"new_names\")[\"labels\"].to_list()\n    #labels = np.array([1 - label for label in inverted_labels])\n    test_data_dir = test_dir + \"/C-NMC_test_prelim_phase_data\"\n    dir_list = list(os.walk(test_data_dir))[0]\n    filenames = sorted([test_data_dir + \"/\" + name for name in dir_list[2]])\n    get_label_by_name = lambda x: test_data_csv.loc[test_data_csv['new_names'] == x][\"labels\"].to_list()[0]\n    labels = [1 - get_label_by_name(name) for name in dir_list[2]]\n    #print(filenames)\n    #print(test_data_csv[[\"new_names\", \"labels\"]])\n    test_ds = get_ds(filenames, labels, BATCH_SIZE, PREFETCH_BUFFER_SIZE)\n\n    if callbacks == None:\n        model.evaluate(test_ds)\n    else:\n        model.evaluate(test_ds, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cnn_model_1(input_shape):\n\n    kernel_initializer = 'lecun_uniform'\n    bias_initializer = 'lecun_uniform'\n    kernel_regularizer = None\n    activation = \"selu\"\n\n    model = tf.keras.Sequential()\n    model.add(Conv2D(32, (3, 3), input_shape=input_shape, \n                     data_format=\"channels_last\", kernel_initializer=kernel_initializer, \n                     bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer\n                    ))\n    model.add(Activation(activation))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3), data_format=\"channels_last\", kernel_initializer=kernel_initializer, \n                     bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer\n                    ))\n    model.add(Activation(activation))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n\n    model.add(Conv2D(128, (3, 3), data_format=\"channels_last\", kernel_initializer=kernel_initializer, \n                     bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer\n                    ))\n    model.add(Activation(activation))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n\n    model.add(Conv2D(256, (3, 3), data_format=\"channels_last\", kernel_initializer=kernel_initializer, \n                     bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer\n                    ))\n    model.add(Activation(activation))\n    model.add(Dropout(0.6))\n\n    # adding fully connected layers\n    model.add(Flatten())\n    model.add(Dense(512, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n    model.add(Activation(activation))\n    model.add(Dropout(0.8))\n    model.add(Dense(256, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n    model.add(Activation(activation))\n    model.add(Dropout(0.8))\n    model.add(Dense(128, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n    model.add(Activation(activation))\n    model.add(Dropout(0.7))\n    model.add(Dense(64, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_cnn_model_1(IMAGE_SIZE + (3,))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam_opt = tf.keras.optimizers.Adam(learning_rate=0.0001, amsgrad=True)\nmetrics = [\"accuracy\", tf.keras.metrics.Precision(name=\"precision\")]\nmodel.compile(\n    optimizer=adam_opt,\n    loss=tf.keras.losses.BinaryCrossentropy(),\n    metrics=metrics\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ERAS = 50\nEPOCHS = 1\n#update_freq = 250","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_checkpoint_callback1 = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"./prec_checkpoints/\",\n    save_weights_only=True,\n    monitor='val_precision',\n    mode='max',\n    save_best_only=True)\nmodel_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"./\",\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)\n#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq = update_freq,\n#                                                     profile_batch = '500,520')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, labels = get_pathes_labels()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor era in range(ERAS):\n    print(\"Era \", era)\n    data_gen = get_stratified_datasets(images, labels)\n    while True:\n        try:\n            train_data, valid_data = next(data_gen)\n            train_ds = get_ds(*train_data, BATCH_SIZE, PREFETCH_BUFFER_SIZE)\n            train_ds = train_ds.map(lambda x,y: [augment(x), y], tf.data.experimental.AUTOTUNE)\n            valid_ds = get_ds(*valid_data, BATCH_SIZE, PREFETCH_BUFFER_SIZE)\n            model.fit(\n                train_ds, validation_data=valid_ds, epochs=EPOCHS, \n                batch_size=BATCH_SIZE, callbacks=[model_checkpoint_callback1])\n        except StopIteration:\n            break\n    print(\"Model test\")\n    test_model(model, [model_checkpoint_callback1, model_checkpoint_callback2])\n    model.save_weights(\"./w.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_model(model, [model_checkpoint_callback1, model_checkpoint_callback2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"./w.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}