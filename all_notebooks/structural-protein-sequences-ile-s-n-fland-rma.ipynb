{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import cm\nsns.set_style('ticks')\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision_hesapla(class_id,TP, FP, TN, FN):\n    sonuc=0\n    \n    for i in range(0,len(class_id)):\n        if TP[i]==0 or FP[i]==0:\n            TP[i]=0.00000000001\n            FP[i]=0.00000000001\n        sonuc+=(TP[i]/(TP[i]+FP[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\n\ndef recall_hesapla(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=(TP[i]/(TP[i]+FN[i]))\n       \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef accuracy_hesapla(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=((TP[i]+TN[i])/(TP[i]+FP[i]+TN[i]+FN[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef specificity_hesapla(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=(TN[i]/(FP[i]+TN[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef NPV_hesapla(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=(TN[i]/(TN[i]+FN[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef perf_measure(y_actual, y_pred):\n    class_id = set(y_actual).union(set(y_pred))\n    TP = []\n    FP = []\n    TN = []\n    FN = []\n\n    for index ,_id in enumerate(class_id):\n        TP.append(0)\n        FP.append(0)\n        TN.append(0)\n        FN.append(0)\n        for i in range(len(y_pred)):\n            if y_actual[i] == y_pred[i] == _id:\n                TP[index] += 1\n            if y_pred[i] == _id and y_actual[i] != y_pred[i]:\n                FP[index] += 1\n            if y_actual[i] == y_pred[i] != _id:\n                TN[index] += 1\n            if y_pred[i] != _id and y_actual[i] != y_pred[i]:\n                FN[index] += 1\n\n\n    return class_id,TP, FP, TN, FN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def yenimetot(y_test,y_score):\n    from sklearn.preprocessing import label_binarize\n    from sklearn.metrics import roc_curve, auc\n    y_test = label_binarize(y_test, classes=[0,1,2])\n    y_score = label_binarize(y_score, classes=[0,1,2])\n    n_classes = 3\n    fpr = dict()\n    tpr = dict()\n    thr = dict()\n    roc_auc = dict()\n    for i in range(n_classes):\n        fpr[i], tpr[i], thr[i] = roc_curve(y_test[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n    return roc_auc[2],fpr[2],tpr[2],thr[2]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_dup = pd.read_csv('../input/pdb_data_no_dups.csv')\ndf_seq = pd.read_csv('../input/pdb_data_seq.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merge = df_dup.merge(df_seq,how='inner',on='structureId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_dup.classification.unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merge.rename({'macromoleculeType_x':'macromoleculeType','residueCount_y':'residueCount'},axis=1,inplace=True)\ndf_merge.drop(['macromoleculeType_y','residueCount_x'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_isnull = pd.DataFrame(round((df_merge.isnull().sum().sort_values(ascending=False)/df_merge.shape[0])*100,1)).reset_index()\ndf_isnull.columns = ['Columns', '% of Missing Data']\ndf_isnull.style.format({'% of Missing Data': lambda x:'{:.1%}'.format(abs(x))})\ncm = sns.light_palette(\"skyblue\", as_cmap=True)\ndf_isnull = df_isnull.style.background_gradient(cmap=cm)\ndf_isnull","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pub_year = df_merge.dropna(subset=['publicationYear']) #dropping the missing values from the publicationYear only\n#graph\nx1= df_pub_year.publicationYear.value_counts().sort_index().index\ny1 = df_pub_year.publicationYear.value_counts().sort_index().values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ph_scale (ph):\n    if ph < 7 :\n        ph = 'Acidic'\n    elif ph > 7:\n        ph = 'Bacis'\n    else:\n        ph = 'Neutral'\n    return ph\nprint('The pH Scale are group into 3 Categories: BASIC if [ pH > 7 ], ACIDIC if [ pH < 7 ] and NEUTRAL if pH [ is equal to 7 ]')\n\n#Transform the dataset\ndf_ph = df_merge.dropna(subset=['phValue']) # dropping missing values in the phValue column only\ndf_ph['pH_scale'] = df_ph['phValue'].apply(ph_scale)\n#Graph\nlabels= df_ph['pH_scale'].value_counts().index\nvalues = df_ph['pH_scale'].value_counts().values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The result of this cell Show the Top 10 most used crystallization method\ndf_cry_meth = df_merge.dropna(subset=['crystallizationMethod']) # this will drop all missing values in\n#the crystallizationMethod column\n\ncry_me = pd.DataFrame(df_cry_meth.crystallizationMethod.value_counts(ascending=False).head(10)).reset_index()\ncry_me.columns = ['Crystallization Method','Values']\n\nf,ax = plt.subplots(figsize=(10,8))\ncry_me.plot(kind = 'barh',ax=ax,color='gray',legend=None,width= 0.8)\n# get_width pulls left or right; get_y pushes up or down\nfor i in ax.patches:\n    ax.text(i.get_width()+.1, i.get_y()+.40, \\\n            str(round((i.get_width()), 2)), fontsize=12, color='black',alpha=0.8)  \n#Set ylabel\nax.set_yticklabels(cry_me['Crystallization Method'])\n# invert for largest on top \nax.invert_yaxis()\nkwargs= {'length':3, 'width':1, 'colors':'black','labelsize':'large'}\nax.tick_params(**kwargs)\nx_axis = ax.axes.get_xaxis().set_visible(False)\nax.set_title ('Top 10 Crystallization Method',color='black',fontsize=16)\nsns.despine(bottom=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"popular_exp_tech = df_merge.experimentalTechnique.value_counts()[:3] # Extract the 3 top used Exp Tech \npopular_exp_tech_df = pd.DataFrame(popular_exp_tech).reset_index()\npopular_exp_tech_df.columns=['Experimental Technique','values']\n# ADDING A ROW FOR THE ORTHER EXPERIMENTAL TECHNIQUE USED. PLEASE PUT IN MIND THAT TO ORTHER TECHNIQUES \n#IS JUST A GROUP OF THE REST OF THECNIQUES USED\npopular_exp_tech_df.loc[3]  = ['OTHER TECHNIQUE', 449]\nprint ('The X-RAY DIFFRACTION is by far the most used Experimental Technique during the Study of the Protein Sequences')\n\nlabels = popular_exp_tech_df['Experimental Technique']\nvalues = popular_exp_tech_df['values']\na = 'Exp Tech'\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('There are more than 10 macro molecules used in this dataset but PROTEIN is widely used than the others')\n\nex = df_merge.macromoleculeType.value_counts()\na = 'Macro Mol Type'\ncolors = ['SlateGray','Orange','Green','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue',\n        'DodgerBlue','DodgerBlue','DodgerBlue','DodgerBlue']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification distribution\nclasific =df_merge.classification.value_counts(ascending=False)\ndf_class = pd.DataFrame(round(((clasific/df_merge.shape[0])*100),2).head(10)).reset_index()\ndf_class.columns = ['Classification', 'percent_value']\nprint('There are {} Unique Classification Types and the top 10 Classification type accounts for more than 50% of the classification in the dataset'.format(df_merge.classification.nunique()))\nf,ax = plt.subplots(figsize=(10,8))\n\ndf_class.plot(kind = 'barh',ax=ax,color='slategray',legend=None,width= 0.8)\n# get_width pulls left or right; get_y pushes up or down\nfor i in ax.patches:\n    ax.text(i.get_width()+.1, i.get_y()+.40, \\\n            str(round((i.get_width()), 2))+'%', fontsize=12, color='black',alpha=0.8)  \n#Set ylabel\nax.set_yticklabels(df_class['Classification'])\n# invert for largest on top \nax.invert_yaxis()\nkwargs= {'length':3, 'width':1, 'colors':'black','labelsize':'large'}\nax.tick_params(**kwargs)\nx_axis = ax.axes.get_xaxis().set_visible(False)\nax.set_title ('Top 10 Classification Types',color='black',fontsize=16)\nsns.despine(bottom=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class.Classification.values.tolist()[1:4]\n# Reduce the df_merge to df_protein which is compose of macromolecule type [Protein and Protein#RNA]\nmacrotype = ['Protein','Protein#RNA']\ndf_protein = df_merge[(df_merge['experimentalTechnique'] =='X-RAY DIFFRACTION') & \n                      (df_merge['macromoleculeType'].isin(macrotype))&\n                     (df_merge['classification'].isin(df_class.Classification.values.tolist()[1:4]))]\n\ndf_protein.reset_index(drop=True,inplace=True)\ncolumns = ['crystallizationMethod' ,'pdbxDetails', 'publicationYear','phValue','crystallizationTempK']\n#Dropping columns with missing value above 15%\ndf_protein.drop(columns=columns,inplace=True)\n# Classification Type that will be used from now on\nf,ax= plt.subplots(figsize=(10,5))\nsns.countplot('classification',data=df_protein, ax=ax)\nax.set_title('Classification Types Selected',fontsize=14,color='black')\nax.tick_params(length =3,labelsize=11,color='black')\nax.set_xlabel('Classification',color='black',fontsize=13)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import norm, skew, kurtosis\ndef stat_kde_plot(input1,input2,input3):\n    f, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,5))\n    sns.kdeplot(df_protein[input1],ax = ax1,color ='blue',shade=True,\n                label=(\"Skewness : %.2f\"%(df_protein[input1].skew()),\n                       \"Kurtosis: %.2f\"%(df_protein[input1].kurtosis())))\n    sns.kdeplot(df_protein[input2], ax = ax2,color='r',shade=True,\n                label=(\"Skewness : %.2f\"%(df_protein[input2].skew()),\n                       \"Kurtosis: %.2f\"%(df_protein[input2].kurtosis())))\n    sns.kdeplot(df_protein[input3], ax = ax3,color='gray',shade=True,\n                label=(\"Skewness : %.2f\"%(df_protein[input3].skew()),\n                       \"Kurtosis: %.2f\"%(df_protein[input3].kurtosis())))\n    axes = [ax1,ax2,ax3]\n    input = [input1,input2,input3]\n    for j in range(len(axes)):\n        axes[j].set_xlabel(input[j],color='black',fontsize=12)\n        axes[j].set_title(input[j] + ' Kdeplot',fontsize=14)\n        axes[j].axvline(df_protein[input[j]].mean() , color ='g',linestyle = '--')\n        axes[j].legend(loc ='upper right',fontsize=12,ncol=2)\n    sns.despine()\n    return plt.show()\n\nstat_kde_plot('resolution','residueCount','structureMolecularWeight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['resolution','residueCount','structureMolecularWeight']:\n    df_protein[i] = df_protein[i].map(lambda i: np.log(i) if i > 0 else 0)\nstat_kde_plot('resolution','residueCount','structureMolecularWeight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop all null values from this columns\ndef stat_plot (input):\n    (mu, sigma) = norm.fit(df_protein[input])\n    f, (ax1, ax2)= plt.subplots(1,2,figsize=(15,5))\n    # Apply the log transformation on the column\n    sns.distplot(df_protein[input],ax = ax1,fit=norm,color ='blue',hist=False)\n    ax1.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\n    ax1.set_ylabel('Frequency')\n    ax1.set_title(input +' Distribution',color='black',fontsize=14)\n    #Get also the QQ-plot\n    res = stats.probplot(df_protein[input], plot=ax2)\n    sns.despine()\n    return plt.show()\nstat_plot('structureMolecularWeight')\nstat_plot('residueCount')\nstat_plot('resolution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def box_plot(input):\n    g = sns.factorplot(x=\"classification\", y = input,data = df_protein, kind=\"box\",size =4,\n                  aspect=2)\n    plt.title(input, fontsize=14,color='black')\n    return plt.show()\n\nbox_plot('residueCount')\nbox_plot('resolution')\nbox_plot('structureMolecularWeight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#class_dict = {'RIBOSOME':1,'HYDROLASE':2,'TRANSFERASE':3} \nclass_dict = {'HYDROLASE':1,'TRANSFERASE':2,'OXIDOREDUCTASE':3}\ndf_protein['class'] = df_protein.classification.map(class_dict)\n#Reduce the dataset to only numerical column and clssification column\ncolumns = ['resolution','structureMolecularWeight','densityMatthews','densityPercentSol',\n           'residueCount','class']\ndf_ml = df_protein[columns]\ndf_ml.dropna(inplace=True)\ndf_ml.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nf, ax = plt.subplots(figsize=(18,7))\nsns.heatmap(df_ml.corr(),cmap= colormap,annot=True,ax=ax,annot_kws ={'fontsize':12})\nkwargs= {'length':3, 'width':1, 'colors':'black','labelsize':13}\nax.tick_params(**kwargs)\nax.tick_params(**kwargs,axis='x')\nplt.title ('Pearson Correlation Matrix', color = 'black',fontsize=18)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nX = df_ml.drop('class',axis = 1)\ny = df_ml['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=y.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n\n# Standardizing the dataset\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,precision_score,recall_score,f1_score,roc_auc_score,accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_liste=[]\nauc_scor=[]\nprecision_scor=[]\nrecall_scor=[]\nf1_scor=[]\nLR_plus=[]\nLR_eksi=[]\nodd_scor=[]\nNPV_scor=[]\nyouden_scor=[]\nspecificity_scor=[]\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=11\nknn = KNeighborsClassifier(n_neighbors = k)\nknn.fit(x_train,y_train)\ny_head=knn.predict(x_test)\nprint(\"KNN Algoritması başarım sonucu: \",knn.score(x_test,y_test))\n\nfrom sklearn.metrics import confusion_matrix\ncmknn = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmknn,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.title(\"KNN Algoritması Karmaşıklık Matrisi\")\nplt.show()\nknnauc,knn_fpr,knn_tpr,knn_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(knnauc)\n#knn_fpr,knn_tpr,knn_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\n\nLR_plus.append((recall_hesapla(classid,tn,fp,fn,tp)/(1-specificity_hesapla(classid,tn,fp,fn,tp))))\nLR_eksi.append(((1-recall_hesapla(classid,tn,fp,fn,tp))/specificity_hesapla(classid,tn,fp,fn,tp)))\nodd_scor.append(((recall_hesapla(classid,tn,fp,fn,tp)/(1-specificity_hesapla(classid,tn,fp,fn,tp))))/(((1-recall_hesapla(classid,tn,fp,fn,tp))/specificity_hesapla(classid,tn,fp,fn,tp))))\nyouden_scor.append((recall_hesapla(classid,tn,fp,fn,tp)+specificity_hesapla(classid,tn,fp,fn,tp)-1))\nprint(\"KNN algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier()\ndtc.fit(x_train,y_train)\ny_head=dtc.predict(x_test)\nprint(\"Karar Ağaçları Algoritması için başarım sonucu: \",dtc.score(x_test,y_test))\ndtcauc,dtc_fpr,dtc_tpr,dtc_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(dtcauc)\n#dtc_fpr,dtc_tpr,dtc_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\n\nprint(\"DTC algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmdtc = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmdtc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Tahminde edilen değer\")\nplt.ylabel(\"Gerçek Değer\")\nplt.title(\"Karar Ağaçları Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(n_estimators=225,random_state=1)\nrfc.fit(x_train,y_train)\ny_head=rfc.predict(x_test)\nprint(\"Rastgele Orman Algoritması başarım sonucu: \",rfc.score(x_test,y_test))\nrfcauc,rfc_fpr,rfc_tpr,rfc_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(rfcauc)\n#rfc_fpr,rfc_tpr,rfc_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"Rastgele Orman algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmrfc = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmrfc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.title(\"Rastgele Orman Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train,y_train)\ny_head=nb.predict(x_test)\nprint(\"Naive Bayes Algoritması başarım sonucu: \",nb.score(x_test,y_test))\n\nnbauc,nb_fpr,nb_tpr,nb_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(nbauc)\n#nb_fpr,nb_tpr,nb_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"Naive Bayes algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmnb = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmnb,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"Gerçek Değer\")\nplt.title(\"Naive Bayes Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(x_train,y_train)\ny_head=lr.predict(x_test)\nprint(\"Logistic Regresyon Algoritması başarım sonucu: \",lr.score(x_test,y_test))\n\nlrcauc,lrc_fpr,lrc_tpr,lrc_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(lrcauc)\n#lrc_fpr,lrc_tpr,lrc_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"Lojistik Regresyon algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmlr = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmlr,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"Gerçek Değer\")\nplt.title(\"Lojistik Regresyon Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc=SVC(random_state=1)\nsvc.fit(x_train,y_train)\ny_head=svc.predict(x_test)\nprint(\"Destek Vektör Makineleri Algoritması başarım sonucu: \",svc.score(x_test,y_test))\n\nsvcauc,svc_fpr,svc_tpr,svc_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(svcauc)\n#svc_fpr,svc_tpr,svc_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"Destek Vektör Makineleri algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmsvc = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmsvc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"Gerçek Değer\")\nplt.title(\"Destek Vektör Makineleri Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gfc=GradientBoostingClassifier(n_estimators= 1000, max_leaf_nodes= 4, max_depth=None,random_state= 2,min_samples_split= 5)\ngfc.fit(x_train,y_train)\ny_head=gfc.predict(x_test)\nprint(\"Gradient Boosting Classifier Algoritması başarım sonucu: \",gfc.score(x_test,y_test))\ngfcauc,gfc_fpr,gfc_tpr,gfc_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(gfcauc)\n#gfc_fpr,gfc_tpr,gfc_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"Gradient Boosting Classifier algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmgfc = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmgfc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"Gerçek Değer\")\nplt.title(\"Gradient Boosting Classifier Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc=AdaBoostClassifier(n_estimators=100, random_state=0)\nabc.fit(x_train,y_train)\ny_head=abc.predict(x_test)\nprint(\"AdaBoosting Classifier Algoritması başarım sonucu: \",abc.score(x_test,y_test))\n\nabcauc,abc_fpr,abc_tpr,abc_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(abcauc)\n#abc_fpr,abc_tpr,abc_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"AdaBoosting Classifier algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmabc = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmabc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"Gerçek Değer\")\nplt.title(\"AdaBoosting Classifier Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ysa=MLPClassifier(alpha=1, max_iter=1000)\nysa.fit(x_train,y_train)\ny_head=ysa.predict(x_test)\nprint(\"Yapay Sinir Ağları Algoritması başarım sonucu: \",ysa.score(x_test,y_test))\n\nysaauc,ysa_fpr,ysa_tpr,ysa_trr=yenimetot(y_test,y_head)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_head)\nauc_scor.append(ysaauc)\n#ysa_fpr,ysa_tpr,ysa_trr=roc_curve(y_test,y_head)\nscore_liste.append(accuracy_hesapla(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_hesapla(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_hesapla(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_head,average='macro'))\nNPV_scor.append(NPV_hesapla(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_hesapla(classid,tn,fp,fn,tp))\nTPR=recall_hesapla(classid,tn,fp,fn,tp)\nTNR=specificity_hesapla(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"AdaBoosting Classifier algoritması için sınıflandırma raporu: \\n\",classification_report(y_test,y_head))\n\ncmysa = confusion_matrix(y_test,y_head)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmysa,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Tahmin Edilen\")\nplt.ylabel(\"Gerçek Değer\")\nplt.title(\"AdaBoosting Classifier Algoritması Karmaşıklık Matrisi\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo_liste=[\"KNN\",\"Decision Tree\",\"Random Forest\",\"Naive Bayes\",\"Linear Regression\",\"Support Vector Machine\",\"Gradient Boosting Classifier\",\"AdaBoosting Classifier\",\"Neural Network\"]\nscore={\"algo_list\":algo_liste,\"score_liste\":score_liste,\"precision\":precision_scor,\"recall\":recall_scor,\"f1_score\":f1_scor,\"AUC\":auc_scor,\"LR+\":LR_plus,\"LR-\":LR_eksi,\"ODD\":odd_scor,\"YOUDEN\":youden_scor,\"Specificity\":specificity_scor}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(score)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax1 = plt.subplots(figsize =(15,15))\nsns.pointplot(x=df['algo_list'], y=df['score_liste'],data=df,color='lime',alpha=0.8,label=\"score_liste\")\nsns.pointplot(x=df['algo_list'], y=df['precision'],data=df,color='red',alpha=0.8,label=\"precision\")\nsns.pointplot(x=df['algo_list'], y=df['recall'],data=df,color='black',alpha=0.8,label=\"recall\")\nsns.pointplot(x=df['algo_list'], y=df['f1_score'],data=df,color='blue',alpha=0.8,label=\"f1_score\")\nsns.pointplot(x=df['algo_list'], y=df['AUC'],data=df,color='yellow',alpha=0.8,label=\"AUC\")\n\nsns.pointplot(x=df['algo_list'], y=df['LR-'],data=df,color='orange',alpha=0.8,label=\"YOUDEN\")\n\nsns.pointplot(x=df['algo_list'], y=df['YOUDEN'],data=df,color='brown',alpha=0.8,label=\"LR-\")\nsns.pointplot(x=df['algo_list'], y=df['Specificity'],data=df,color='purple',alpha=0.8,label=\"Specificity\")\nplt.xlabel('Algoritma ismi',fontsize = 15,color='blue')\nplt.ylabel('Score',fontsize = 15,color='blue')\nplt.xticks(rotation= 45)\nplt.title('HCC Survival Dataset ile Sınıflandırma',fontsize = 20,color='blue')\nplt.grid()\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr,rfc_fpr,rfc_tpr,nb_fpr,nb_tpr,gbc_fpr,gbc_tpr,abc_fpr,abc_tpr,ysa_fpr,ysa_tpr):\n    plt.figure(figsize=(16,8))\n    plt.title('ROC Curve \\n Top 9 Classifiers', fontsize=18)\n    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: %0.2f'% lrcauc)\n    plt.plot(knear_fpr, knear_tpr, label='KNears Neighbors Classifier Score: %0.2f'% knnauc)\n    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: %0.2f'% svcauc)\n    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: %0.2f'% dtcauc)\n    plt.plot(rfc_fpr, rfc_tpr, label='Random Forest Classifier Score: %0.2f'% rfcauc)\n    plt.plot(nb_fpr, nb_tpr, label='Naive Bayes Classifier Score: %0.2f'% nbauc)\n    plt.plot(gbc_fpr, gbc_tpr, label='Gradient Boosting Classifier Score: %0.2f'% gfcauc)\n    plt.plot(abc_fpr, abc_tpr, label='AdaBoosting Classifier Score: %0.2f'% abcauc)\n    plt.plot(ysa_fpr, ysa_tpr, label='Neural Network Score: %0.2f'% ysaauc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.01, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n                )\n    plt.legend()\n    \ngraph_roc_curve_multiple(lrc_fpr, lrc_tpr, knn_fpr, knn_tpr, svc_fpr, svc_tpr, dtc_fpr, dtc_tpr,rfc_fpr,rfc_tpr,nb_fpr,nb_tpr,gfc_fpr,gfc_tpr,abc_fpr,abc_tpr,ysa_fpr,ysa_tpr)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}