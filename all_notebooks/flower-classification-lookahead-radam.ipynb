{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nimport time\nimport math\nimport tqdm as tqdm\nimport os\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Folders"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/oxford-102-flower-pytorch/flower_data/flower_data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/oxford-102-flower-pytorch/flower_data/flower_data'\ntrain_dir = data_dir + '/train'\nvalid_dir = data_dir + '/valid'\ntest_dir = data_dir + '/test'\nname_json = data_dir + '/cat_to_name.json'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pil_loader(path):\n    with open(path, 'rb') as f:\n        img = Image.open(f)\n        return img.convert('RGB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, path, transform=None):\n        self.path = path\n        self.files = []\n        for (dirpath, _, filenames) in os.walk(self.path):\n            for f in filenames:\n                if f.endswith('.jpg'):\n                    p = {}\n                    p['img_path'] = dirpath + '/' + f\n                    self.files.append(p)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img_path = self.files[idx]['img_path']\n        img_name = img_path.split('/')[-1]\n        image = pil_loader(img_path)\n        if self.transform:\n            image = self.transform(image)\n        return image, 0, img_name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label mapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\nwith open(name_json, 'r') as f:\n    cat_to_name = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_to_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cat_name(index):\n    return cat_to_name[idx_to_class[index]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalize = transforms.Normalize(mean=mean, std=std)\ndata_transforms = transforms.Compose([\n                    transforms.Pad(4, padding_mode='reflect'),\n                    transforms.RandomRotation(10),\n                    transforms.RandomResizedCrop(224),\n                    transforms.RandomHorizontalFlip(),\n                    transforms.ToTensor(),\n                    normalize\n                ])\ntest_transforms = transforms.Compose([\n                    #transforms.Pad(4, padding_mode='reflect'),\n                    transforms.RandomResizedCrop(224),\n                    transforms.ToTensor(),\n                    normalize\n                ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datasets = datasets.ImageFolder(train_dir, data_transforms)\nval_datasets = datasets.ImageFolder(valid_dir, test_transforms)\ntest_datasets = TestDataset(test_dir, test_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(train_datasets, batch_size=bs, shuffle=True)\nvalidloader = torch.utils.data.DataLoader(val_datasets, batch_size=bs, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_datasets, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_to_class = {val:key for key, val in val_datasets.class_to_idx.items()}\nidx_to_class","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_img(preds=None, is_pred=False):        \n    fig = plt.figure(figsize=(8,8))\n    columns = 4\n    rows = 5\n\n    for i in range(1, columns*rows +1):\n        fig.add_subplot(rows, columns, i)\n        \n        if is_pred:\n            img_xy = np.random.randint(len(test_datasets));\n            img = test_datasets[img_xy][0].numpy()           \n        else:\n            img_xy = np.random.randint(len(train_datasets));\n            img = train_datasets[img_xy][0].numpy()\n            \n        img = img.transpose((1, 2, 0))\n        img = std * img + mean\n        \n        if is_pred:\n            plt.title(get_cat_name(preds[img_xy]) + \"/\" + get_cat_name(test_datasets[img_xy][1]))\n        else:\n            plt.title(str(get_cat_name(train_datasets[img_xy][1])))\n        plt.axis('off')\n        img = np.clip(img, 0, 1)\n        plt.imshow(img, interpolation='nearest')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(output, target, is_test=False):\n    global total\n    global correct\n    batch_size = target.size(0)\n    total += batch_size    \n    _, pred = output.max(dim=1)\n    if is_test:\n        preds.extend(pred)\n    correct += torch.sum(pred == target.data)\n    return  (correct.float()/total) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reset():\n    global total, correct\n    global train_loss, test_loss, best_acc\n    global trn_losses, trn_accs, val_losses, val_accs\n    total, correct = 0, 0\n    train_loss, test_loss, best_acc = 0.0, 0.0, 0.0\n    trn_losses, trn_accs, val_losses, val_accs = [], [], [], []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AvgStats(object):\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.losses =[]\n        self.precs =[]\n        self.its = []\n        \n    def append(self, loss, prec, it):\n        self.losses.append(loss)\n        self.precs.append(prec)\n        self.its.append(it)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_checkpoint(model, is_best, filename='./checkpoint.pth.tar'):\n    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n    if is_best:\n        torch.save(model.state_dict(), filename)  # save checkpoint\n    else:\n        print (\"=> Validation Accuracy did not improve\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_checkpoint(model, filename = './checkpoint.pth.tar'):\n    sd = torch.load(filename, map_location=lambda storage, loc: storage)\n    names = set(model.state_dict().keys())\n    for n in list(sd.keys()): \n        if n not in names and n+'_raw' in names:\n            if n+'_raw' not in sd: sd[n+'_raw'] = sd[n]\n            del sd[n]\n    model.load_state_dict(sd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cyclic Learning Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CLR(object):\n    \"\"\"\n    The method is described in paper : https://arxiv.org/abs/1506.01186 to find out optimum \n    learning rate. The learning rate is increased from lower value to higher per iteration \n    for some iterations till loss starts exploding.The learning rate one power lower than \n    the one where loss is minimum is chosen as optimum learning rate for training.\n\n    Args:\n        optim   Optimizer used in training.\n\n        bn      Total number of iterations used for this test run.\n                The learning rate increasing factor is calculated based on this \n                iteration number.\n\n        base_lr The lower boundary for learning rate which will be used as\n                initial learning rate during test run. It is adviced to start from\n                small learning rate value like 1e-4.\n                Default value is 1e-5\n\n        max_lr  The upper boundary for learning rate. This value defines amplitude\n                for learning rate increase(max_lr-base_lr). max_lr value may not be \n                reached in test run as loss may explode before reaching max_lr.\n                It is adviced to use higher value like 10, 100.\n                Default value is 100.\n\n    \"\"\"\n    def __init__(self, optim, bn, base_lr=1e-7, max_lr=100):\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.optim = optim\n        self.bn = bn - 1\n        ratio = self.max_lr/self.base_lr\n        self.mult = ratio ** (1/self.bn)\n        self.best_loss = 1e9\n        self.iteration = 0\n        self.lrs = []\n        self.losses = []\n        \n    def calc_lr(self, loss):\n        self.iteration +=1\n        if math.isnan(loss) or loss > 4 * self.best_loss:\n            return -1\n        if loss < self.best_loss and self.iteration > 1:\n            self.best_loss = loss\n            \n        mult = self.mult ** self.iteration\n        lr = self.base_lr * mult\n        \n        self.lrs.append(lr)\n        self.losses.append(loss)\n        \n        return lr\n        \n    def plot(self, start=10, end=-5):\n        plt.xlabel(\"Learning Rate\")\n        plt.ylabel(\"Losses\")\n        plt.plot(self.lrs[start:end], self.losses[start:end])\n        plt.xscale('log')\n        \n        \n    def plot_lr(self):\n        plt.xlabel(\"Iterations\")\n        plt.ylabel(\"Learning Rate\")\n        plt.plot(self.lrs)\n        plt.yscale('log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lookahead"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.optim import Optimizer\nfrom collections import defaultdict\n\n\nclass Lookahead(Optimizer):\n    r'''Implements Lookahead optimizer.\n\n    It's been proposed in paper: Lookahead Optimizer: k steps forward, 1 step back\n    (https://arxiv.org/pdf/1907.08610.pdf)\n\n    Args:\n        optimizer: The optimizer object used in inner loop for fast weight updates.\n        alpha:     The learning rate for slow weight update.\n                   Default: 0.5\n        k:         Number of iterations of fast weights updates before updating slow\n                   weights.\n                   Default: 5\n\n    Example:\n        > optim = Lookahead(optimizer)\n        > optim = Lookahead(optimizer, alpha=0.6, k=10)\n    '''\n    def __init__(self, optimizer, alpha=0.5, k=5):\n        assert(0.0 <= alpha <= 1.0)\n        assert(k >= 1)\n        self.optimizer = optimizer\n        self.alpha = alpha\n        self.k = k\n        self.param_groups = self.optimizer.param_groups\n        self.state = defaultdict(dict)\n        for group in self.param_groups:\n            group['k_counter'] = 0\n        self.slow_weights = [[param.clone().detach() for param in group['params']] for group in self.param_groups]\n    \n    def step(self, closure=None):\n        loss = self.optimizer.step(closure)\n        for group, slow_Weight in zip(self.param_groups, self.slow_weights):\n            group['k_counter'] += 1\n            if group['k_counter'] == self.k:\n                for param, weight in zip(group['params'], slow_Weight):\n                    weight.data.add_(self.alpha, (param.data - weight.data))\n                    param.data.copy_(weight.data)\n                group['k_counter'] = 0\n\n        return loss\n\n    def state_dict(self):\n        fast_dict = self.optimizer.state_dict()\n        fast_state = fast_dict['state']\n        param_groups = fast_dict['param_groups']\n        slow_state = {(id(k) if isinstance(k, torch.Tensor) else k): v\n                        for k, v in self.state.items()}\n        return {\n            'fast_state': fast_state,\n            'param_groups': param_groups,\n            'slow_state': slow_state\n        }\n\n    def load_state_dict(self, state_dict):\n        fast_dict = {\n            'state': state_dict['fast_state'],\n            'param_groups': state_dict['param_groups']\n        }\n        slow_dict = {\n            'state': state_dict['slow_state'],\n            'param_groups': state_dict['param_groups']\n        }\n        super(Lookahead, self).load_state_dict(slow_dict)\n        self.optimizer.load_state_dict(fast_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initialize Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss = 0.0\ntest_loss = 0.0\nbest_acc = 0.0\ntrn_losses = []\ntrn_accs = []\nval_losses = []\nval_accs = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = 0\ncorrect = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LR Find"},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_lr(optimizer, lr):\n    for g in optimizer.param_groups:\n        g['lr'] = lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lr_find(clr, model, optimizer=None):\n    t = tqdm.tqdm(trainloader, leave=False, total=len(trainloader))\n    running_loss = 0.\n    avg_beta = 0.98\n    model.train()\n    for i, (input, target) in enumerate(t):\n        input, target = input.to(device), target.to(device)\n        var_ip, var_tg = Variable(input), Variable(target)\n        output = model(var_ip)\n        loss = criterion(output, var_tg)\n    \n        running_loss = avg_beta * running_loss + (1-avg_beta) *loss.item()\n        smoothed_loss = running_loss / (1 - avg_beta**(i+1))\n        t.set_postfix(loss=smoothed_loss)\n    \n        lr = clr.calc_lr(smoothed_loss)\n        if lr == -1 :\n            break\n        update_lr(optimizer, lr)   \n    \n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(epoch=0, model=None, optimizer=None):\n    model.train()\n    global best_acc\n    global trn_accs, trn_losses\n    is_improving = True\n    counter = 0\n    running_loss = 0.\n    avg_beta = 0.98\n    for i, (input, target) in enumerate(trainloader):\n        bt_start = time.time()\n        input, target = input.to(device), target.to(device)\n        var_ip, var_tg = Variable(input), Variable(target)\n                                    \n        output = model(var_ip)\n        loss = criterion(output, var_tg)\n            \n        running_loss = avg_beta * running_loss + (1-avg_beta) *loss.item()\n        smoothed_loss = running_loss / (1 - avg_beta**(i+1))\n        \n        trn_losses.append(smoothed_loss)\n            \n        # measure accuracy and record loss\n        prec = accuracy(output.data, target)\n        trn_accs.append(prec)\n\n        train_stats.append(smoothed_loss, prec, time.time()-bt_start)\n        if prec > best_acc :\n            best_acc = prec\n            save_checkpoint(model, True)\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model=None):\n    with torch.no_grad():\n        model.eval()\n        global val_accs, val_losses\n        running_loss = 0.\n        avg_beta = 0.98\n        for i, (input, target) in enumerate(validloader):\n            bt_start = time.time()\n            input, target = input.to(device), target.to(device)\n            var_ip, var_tg = Variable(input), Variable(target)\n            output = model(var_ip)\n            loss = criterion(output, var_tg)\n        \n            running_loss = avg_beta * running_loss + (1-avg_beta) *loss.item()\n            smoothed_loss = running_loss / (1 - avg_beta**(i+1))\n\n            # measure accuracy and record loss\n            prec = accuracy(output.data, target, is_test=True)\n            test_stats.append(loss.item(), prec, time.time()-bt_start)\n        \n            val_losses.append(smoothed_loss)\n            val_accs.append(prec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(model=None, sched=None, optimizer=None):\n    print(\"Epoch\\tTrn_loss\\tVal_loss\\tTrn_acc\\t\\tVal_acc\")\n    for j in range(epoch):\n        train(epoch=j, model=model, optimizer=optimizer)\n        test(model)\n        if sched:\n            sched.step(j)\n        print(\"{}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\"\n              .format(j+1, trn_losses[-1], val_losses[-1], trn_accs[-1], val_accs[-1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model and Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fc = nn.Linear(in_features=model.fc.in_features, out_features=102)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.require_grad = False\n    \nfor param in model.fc.parameters():\n    param.require_grad = True\n    \nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_checkpoint(model, True, 'before_start_resnet50.pth.tar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)\noptimizer = Lookahead(optim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clr = CLR(optim, len(trainloader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_find(clr, model, optim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clr.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_checkpoint(model, 'before_start_resnet50.pth.tar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nepoch = 30\ntrain_stats = AvgStats()\ntest_stats = AvgStats()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)\noptimizer = Lookahead(optim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(model=model, optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_checkpoint(model, True, 'before_unfreeze_resnet50.pth.tar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel(\"Iterations\")\nplt.ylabel(\"Accuracy\")\nplt.plot(train_stats.precs, 'r', label='Train')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.plot(train_stats.losses, 'r', label='Train')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel(\"Iterations\")\nplt.ylabel(\"Accuracy\")\nplt.plot(test_stats.precs, 'b', label='Valid')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.plot(test_stats.losses, 'b', label='Valid')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\ntrain_stats = AvgStats()\ntest_stats = AvgStats()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.require_grad = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optim = torch.optim.SGD(model.parameters(), lr=1e-6, momentum=0.9, weight_decay=1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clr = CLR(optim, len(trainloader), base_lr=1e-9, max_lr=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_find(clr, model, optim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clr.plot(start=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_checkpoint(model, 'before_unfreeze_resnet50.pth.tar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\ntrain_stats = AvgStats()\ntest_stats = AvgStats()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optim = torch.optim.SGD(model.parameters(), lr=1e-9, momentum=0.9, weight_decay=1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(model=model, optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_checkpoint(model, True, 'after_unfreeze_resnet50.pth.tar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.plot(train_stats.losses, 'r', label='Train')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.plot(test_stats.losses, 'b', label='Valid')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef predict(img, model):\n    model.eval()\n    with torch.no_grad():\n        input = Variable(img)\n        input = input.to(device)\n        output = model(input)\n        _, pred = output.max(dim=1)\n        return pred[0].item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = dict()\nfor i, (input, _, path) in enumerate(testloader):\n    predicted = predict(input, model)\n    result[path[0]] = idx_to_class[predicted]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf dict.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_file = open('dict.csv', 'w')\nwriter = csv.writer(csv_file)\nwriter.writerow(['file_name','id'])\nfor key, value in result.items():\n    writer.writerow([key, value])\ncsv_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}