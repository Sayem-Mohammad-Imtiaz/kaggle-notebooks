{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# <a id='7.5'>Breast Cancer Detection</a>"},{"metadata":{},"cell_type":"markdown","source":"##  <a id='0'>0. Loading Libraries</a>"},{"metadata":{"trusted":true,"_uuid":"bbf404e4824ea60fd69de5d6117edec5f61480b8"},"cell_type":"code","source":"#importing libraries\n#main ones\nimport pandas as pd\nimport numpy as np\n\n#classifiers and metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\n#for plotting\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n%matplotlib inline\nimport itertools\nfrom itertools import chain\n\n\n#extra\nimport warnings\nimport time\n\n#for neural links\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n> ## <a id='1'>1. Loading Data</a>"},{"metadata":{"trusted":true,"_uuid":"6da5e989161e2ae3a8b3349881fec598b17f78c1"},"cell_type":"code","source":"#readin data\ndata = pd.read_csv('../input/data.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking a look at data\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <a id='1.1'>1.1 Refining Data</a>"},{"metadata":{"trusted":true,"_uuid":"625b46ed9cde8f870f2e524eef2c964b09521390"},"cell_type":"code","source":"#dropping extra columns\n\ndata = data.drop(['Unnamed: 32','id'],axis = 1)\n\ndata.diagnosis.replace(to_replace = dict(M = 1, B = 0), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7da89c8be02c5d4656e0c406e3c494b24ce48c50"},"cell_type":"code","source":"#looking at data and labels\n\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc1c0f7f6e8a3bac177dd78aa50fa0e37ac535db"},"cell_type":"code","source":"# making it 2 datasets\n\nM = data[(data['diagnosis'] != 0)]\nB = data[(data['diagnosis'] == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how the initial distribution is\n\ntrace = go.Pie(labels = ['benign','malignant'], values = data['diagnosis'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['gray', 'red'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of diagnosis variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dividing in three parts\n\nfeatures_mean= list(data.columns[0:11])\nfeatures_se= list(data.columns[11:20])\nfeatures_worst=list(data.columns[21:31])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation\ncorrelation = data.corr()\nmatrix_cols = correlation.columns.tolist()\ncorr_array  = np.array(correlation)\n\n#Plotting\ntrace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   xgap = 2,\n                   ygap = 2,\n                   colorscale='Reds',\n                   colorbar   = dict() ,\n                  )\nlayout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                     ),\n                        yaxis   = dict(tickfont = dict(size = 12)),\n                        xaxis   = dict(tickfont = dict(size = 12)),\n                       )\n                  )\nfig = go.Figure(data = [trace],layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"795455398b0a632d31cc35df2ad6302d4dff1f4c"},"cell_type":"code","source":"y = np.array(data.diagnosis.tolist())\ndata = data.drop('diagnosis', 1)\nX = np.array(data.as_matrix())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"472146c22b27a8b6488f37a3540d7c7a032120af"},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca7ac96b655e461d1435d8e2610a1035a27b211e"},"cell_type":"code","source":"random_state = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.12, random_state = random_state)\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <a id='1.2'>1.2 Metrics and Plots</a>"},{"metadata":{"trusted":true,"_uuid":"80b76823aa878dabe5bd58d41d4b4ea4187c00c1"},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion matrix\"',\n                          cmap = plt.cm.RdGy) :\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] > thresh else 'black')\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n# Show metrics \ndef show_metrics():\n    tp = cm[1,1]\n    fn = cm[1,0]\n    fp = cm[0,1]\n    tn = cm[0,0]\n    print('Accuracy  =     {:.3f}'.format((tp+tn)*100/(tp+tn+fp+fn)))\n    print('Precision =     {:.3f}'.format(tp*100/(tp+fp)))\n    print('Recall    =     {:.3f}'.format(tp*100/(tp+fn)))\n    print('F1_score  =     {:.3f}'.format(2*(((tp/(tp+fp))*(tp/(tp+fn))*100)/\n                                                 ((tp/(tp+fp))+(tp/(tp+fn))))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5167ea79d4fee3776082fce10fc8c85795f8115a"},"cell_type":"code","source":"def cross_val_metrics(model) :\n    scores = ['accuracy', 'precision', 'recall']\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <a id='2'>2. Logistic Regression</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgr_clf_start_time = time.time()\n\nlgr_clf=LogisticRegression(random_state = random_state)\nlgr_clf.fit(X_train, y_train)\n\nprint(\"--- %s seconds ---\" % (time.time() - lgr_clf_start_time))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred =lgr_clf.predict(X_test)\ny_score = lgr_clf.decision_function(X_test)\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Logistic Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\n\ncross_log = cross_val_metrics(lgr_clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='2.1'>2.1 Tuning Parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_clf = LogisticRegression(random_state = random_state)\nparam_grid = {\n            'penalty' : ['l2','l1'],  \n            'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n            }\n\nCV_log_clf = GridSearchCV(estimator = log_clf, param_grid = param_grid , scoring = 'accuracy', verbose = 1, n_jobs = -1)\nCV_log_clf.fit(X_train, y_train)\n\nbest_parameters = CV_log_clf.best_params_\nprint('The best parameters for using this model is', best_parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CV_log_clf = LogisticRegression(C = best_parameters['C'], \n                                penalty = best_parameters['penalty'], \n                                random_state = random_state)\n\nCV_log_clf.fit(X_train, y_train)\ny_pred = CV_log_clf.predict(X_test)\ny_score = CV_log_clf.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned Logistic Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(CV_log_clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <a id='3'>3. Decision Tree</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_start_time = time.time()\n\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train, y_train)\n\nprint(\"--- %s seconds ---\" % (time.time() - dtree_start_time))\n\ny_pred = dtree.predict(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title=' Decision Tree Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(dtree)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  <a id='3.1'>3.1 Tuning Parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Classification_model_gridsearchCV(model,param_grid,X_data,y_data):\n    clf = GridSearchCV(model,param_grid,cv=10,scoring=\"accuracy\")\n  \n    clf.fit(X_train,y_train)\n    print(\"The best parameter found on development set is :\")\n    print(clf.best_params_)\n    print(\"the bset estimator is \")\n    print(clf.best_estimator_)\n    print(\"The best score is \")\n    print(clf.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n              'min_samples_split': [2,3,4,5,6,7,8,9,10], \n              'min_samples_leaf':[2,3,4,5,6,7,8,9,10] }\n\ndtree= DecisionTreeClassifier()\nClassification_model_gridsearchCV(dtree,param_grid,X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=5, min_samples_split=3,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\ndtree.fit(X_train, y_train)\n\ny_pred = dtree.predict(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned Logistic Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(dtree)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <a id='4'>4. SVM</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_start_time = time.time()\n\nclf_svm=svm.SVC()\nclf_svm.fit(X_train, y_train)\n\nprint(\"--- %s seconds ---\" % (time.time() - svm_start_time))\n\ny_pred = clf_svm.predict(X_test)\ny_score = clf_svm.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='SVM Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(clf_svm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  <a id='4.1'>3.1 Tuning Parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm=svm.SVC(kernel='linear', C=1000000) \nclf_svm.fit(X_train, y_train)\ny_pred = clf_svm.predict(X_test)\ny_score = clf_svm.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned SVM Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(clf_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm=svm.SVC(kernel='linear', C=0.1) \nclf_svm.fit(X_train, y_train)\ny_pred = clf_svm.predict(X_test)\ny_score = clf_svm.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned SVM Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(clf_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm=svm.SVC(kernel='rbf', C=1000000) \nclf_svm.fit(X_train, y_train)\ny_pred = clf_svm.predict(X_test)\ny_score = clf_svm.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned SVM Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(clf_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm=svm.SVC(kernel='rbf', C=0.1) \nclf_svm.fit(X_train, y_train)\ny_pred = clf_svm.predict(X_test)\ny_score = clf_svm.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned SVM Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(clf_svm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <a id='5'>5. KNN</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_start_time = time.time()\n\nclf_knn = KNeighborsClassifier(n_neighbors=1)\nclf_knn.fit(X_train, y_train)\n\nprint(\"--- %s seconds ---\" % (time.time() - knn_start_time))\n\n\ny_pred =clf_knn.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='KNN Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\n\ncross_log = cross_val_metrics(clf_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  <a id='5.1'>5.1 Tuning Parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn = KNeighborsClassifier(n_neighbors=10)\nclf_knn.fit(X_train, y_train)\ny_pred =clf_knn.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned KNN Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\n\ncross_log = cross_val_metrics(clf_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn = KNeighborsClassifier(n_neighbors=50)\nclf_knn.fit(X_train, y_train)\ny_pred =clf_knn.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Tuned KNN Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\n\ncross_log = cross_val_metrics(clf_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Overfitting!!!!**"},{"metadata":{},"cell_type":"markdown","source":"##  <a id='6'>6. GaussianNB</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"GNB_clf_start_time = time.time()\n\nGNB_clf = GaussianNB()\nGNB_clf.fit(X_train, y_train)\n\nprint(\"--- %s seconds ---\" % (time.time() - GNB_clf_start_time))\n\ny_pred = GNB_clf.predict(X_test)\n#y_score = GNB_clf.decision_function(X_test)\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='GaussianNB Confusion matrix')\nplt.savefig('6')\nplt.show()\n\nshow_metrics()\ncross_log = cross_val_metrics(GNB_clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <a id='7'>7. Neural Network</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras import metrics\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\n\nnetwork_start_time = time.time()\n\nnetwork = Sequential()\nnetwork.add(Dense (60, activation='relu' , input_shape=(30,)))\nnetwork.add(Dense (60, activation='relu'))\nnetwork.add(Dense (1, activation='sigmoid'))\n            \nnetwork.compile(optimizer='sgd',\n             loss='binary_crossentropy',\n             metrics=['accuracy',])\n            \nhistory = network.fit(X_train, y_train, epochs = 10, batch_size=4, validation_data=(X_test, y_test))\n\n\nprint(\"--- %s seconds ---\" % (time.time() - network_start_time))\n\nnetwork.evaluate(X_test, y_test)\n\n\nloss = history.history['loss']\nval_loss = history.history ['val_loss']\n\nepochs = range(1, 11)\n\nplt.plot(epochs, loss, 'bo', label= 'training loss')\nplt.plot(epochs, val_loss, 'b', label= 'Validation loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Different optimizers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"network2_start_time = time.time()\n\nnetwork2 = Sequential()\nnetwork2.add(Dense (60, activation='relu' , input_shape=(30,)))\nnetwork2.add(Dense (60, activation='relu'))\nnetwork2.add(Dense (1, activation='sigmoid'))\n            \nnetwork2.compile(optimizer='rmsprop',\n             loss='binary_crossentropy',\n             metrics=['accuracy',])\n            \nhistory2 = network2.fit(X_train, y_train, epochs = 10, batch_size=4, validation_data=(X_test, y_test))\n\n\nprint(\"--- %s seconds ---\" % (time.time() - network2_start_time))\n\nnetwork2.evaluate(X_test, y_test)\n\nloss = history2.history['loss']\nval_loss = history2.history ['val_loss']\n\nepochs = range(1, 11)\n\nplt.plot(epochs, loss, 'bo', label= 'training loss')\nplt.plot(epochs, val_loss, 'b', label= 'Validation loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network3_start_time = time.time()\n\nnetwork3 = Sequential()\nnetwork3.add(Dense (60, activation='relu' , input_shape=(30,)))\nnetwork3.add(Dense (60, activation='relu'))\nnetwork3.add(Dense (1, activation='sigmoid'))\n            \nnetwork3.compile(optimizer='adam',\n             loss='binary_crossentropy',\n             metrics=['accuracy',])\n            \nhistory3 = network3.fit(X_train, y_train, epochs = 10, batch_size=4, validation_data=(X_test, y_test))\n\n\nprint(\"--- %s seconds ---\" % (time.time() - network3_start_time))\n\nnetwork3.evaluate(X_test, y_test)\n\nloss = history3.history['loss']\nval_loss = history3.history ['val_loss']\n\nepochs = range(1, 11)\n\nplt.plot(epochs, loss, 'bo', label= 'training loss')\nplt.plot(epochs, val_loss, 'b', label= 'Validation loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network4_start_time = time.time()\n\nnetwork4 = Sequential()\nnetwork4.add(Dense (60, activation='relu' , input_shape=(30,)))\nnetwork4.add(Dense (60, activation='relu'))\nnetwork4.add(Dense (1, activation='sigmoid'))\n            \nnetwork4.compile(optimizer='adamax',\n             loss='binary_crossentropy',\n             metrics=['accuracy',])\n            \nhistory4 = network4.fit(X_train, y_train, epochs = 10, batch_size=4, validation_data=(X_test, y_test))\n\n\nprint(\"--- %s seconds ---\" % (time.time() - network4_start_time))\n\nnetwork4.evaluate(X_test, y_test)\n\nloss = history4.history['loss']\nval_loss = history4.history ['val_loss']\n\nepochs = range(1, 11)\n\nplt.plot(epochs, loss, 'bo', label= 'training loss')\nplt.plot(epochs, val_loss, 'b', label= 'Validation loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de6ad8bba144fad0f695b83e204f4594fce7e216"},"cell_type":"markdown","source":"## <a id='8'>8. Results and Comparing</a>"},{"metadata":{"trusted":true,"_uuid":"5003dd3cfeb323cdb1d563bd751b9b33554769a0"},"cell_type":"code","source":"models_metrics = {'logistic regression': [0.97891, 0.98106, 0.96224], \n                 'tuned logistic regression': [0.98242, 0.99036, 0.96235],\n                 'decision tree' : [0.92445,0.87080,0.91528],\n                 'tuned decision tree' : [0.91566,0.93318,0.91561],\n                 'svm' : [0.97544,0.97173,0.96235],\n                 'tuned svm' : [0.97541,0.98548,0.94817],\n                  'knn' : [0.95075,0.93891,0.92901],\n                 'tuned knn' : [0.96494,0.98986,0.91528],\n                  'gaussiannb' : [0.92808,0.91233,0.89657]\n                }\ndf = pd.DataFrame(data = models_metrics)\ndf.rename(index={0:'Accuracy',1:'Precision', 2: 'Recall'}, \n                 inplace=True)\nax = df.plot(kind='bar', figsize = (15,10), ylim = (0.86, 1), \n        color = ['#c6e2ff', '#7c96b3', '#fa85af', '#ccb1bd', '#a2b970', '#9bae88', '#d2ccda', '#9690a8' , '#f08080'],\n        rot = 0, title ='Models performance (cross val mean)',\n        edgecolor = 'grey', alpha = 0.5)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01, p.get_height() * 1.0005))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_metrics = {'logistic regression': [0.0044], \n                 'decision tree' : [0.0270],\n                 'svm' : [0.0078],\n                  'knn' : [0.0017],\n                  'gaussiannb' : [0.0017]\n                }\ndf = pd.DataFrame(data = models_metrics)\ndf.rename(index={0:'time'}, \n                 inplace=True)\nax = df.plot(kind='bar', figsize = (15,10), ylim = (0.0015, 0.028), \n        color = ['#c6e2ff', '#fa85af', '#a2b970','#d2ccda', '#f08080'],\n        rot = 0, title ='Models performance (cross val mean)',\n        edgecolor = 'grey', alpha = 0.5)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01, p.get_height() * 1.0005))\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}