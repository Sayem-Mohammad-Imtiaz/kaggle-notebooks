{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Helper Functions","metadata":{"id":"s6tGTqOyVNU3"}},{"cell_type":"markdown","source":"Helper functions for Automating Selection and Making it Easier as explained near the end of the notebook.","metadata":{"id":"o02dxAS0iC_u"}},{"cell_type":"code","source":"def evaluate_model_fn(classifier, X_train, y_train, X_test, y_test):\n    \n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    ac = accuracy_score(y_test, y_pred)\n\n    return ac","metadata":{"id":"njcl22Qehwwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def choose_best_model_fn(X_train, y_train, X_test, y_test):\n    \"\"\"Get the best model based on its accuracy where the models'\n    hyperparameters were tuned after feature selection that is based on the\n    initial Exploratory Data Analysis (EDA).\n    \"\"\"\n\n    model_accuracy_dict = defaultdict(int)\n\n    # Logistic Regression\n    lr = LogisticRegression(random_state=0)\n    model_accuracy_dict['Logistic Regression'] = evaluate_model_fn(lr, X_train,\n                                                    y_train, X_test, y_test)\n    \n    # Support Vector Machine\n    svc = SVC(kernel='linear', random_state=0)\n    model_accuracy_dict['Support Vector Machine'] = evaluate_model_fn(svc,\n                                        X_train, y_train, X_test, y_test)\n    \n    # KNN\n    knn = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=2)\n    model_accuracy_dict['KNN'] = evaluate_model_fn(knn, X_train, y_train,\n                                                   X_test, y_test)\n    \n    # Kernel SVM\n    svm = SVC(kernel = 'rbf', random_state = 0)\n    model_accuracy_dict['Kernel SVM'] = evaluate_model_fn(svm, X_train, y_train,\n                                                          X_test, y_test)\n    \n    # Naive Bayes\n    nv = GaussianNB()\n    model_accuracy_dict['Naive Bayes'] = evaluate_model_fn(nv, X_train, y_train,\n                                                           X_test, y_test)\n    \n    # Decision Tree (DT)\n    dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n    model_accuracy_dict['DT'] = evaluate_model_fn(dt, X_train, y_train, X_test,\n                                                  y_test)\n    \n    # Random Forest (RF)\n    rf = grid_search.best_estimator_\n    model_accuracy_dict['RF'] = evaluate_model_fn(rf, X_train, y_train,\n                                                  X_test, y_test)\n\n    # get the key of the classifier with the maximum accuracy\n    best_classifier = max(model_accuracy_dict.items(),\n                          key=operator.itemgetter(1))[0]\n    best_classifier_accuracy = model_accuracy_dict[best_classifier]\n\n    # return model_accuracy_dict\n    print(f'Best classifier is {best_classifier} with accuracy '\n          f'{best_classifier_accuracy :.3f}.')\n    ","metadata":{"id":"z9uZZw6ShtWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def columns_predictive_power_fn(csv_file_path):\n    \"\"\"Obtain the accuracy of each column on using it independently on all\n    models.\"\"\"\n    # read the csv file\n    dataframe = pd.read_csv(csv_file_path)\n    # get labels\n    y = dataframe.iloc[:, -1].values\n    # remove the label column from the dataframe\n    dataframe.drop(['label'], axis=1, inplace=True)\n    # loop over all dataframe columns\n    for col in dataframe.columns:\n        # select the current column as the only feature\n        X = dataframe[col]\n        # split data into training and testing set\n        X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                test_size=0.25, random_state=0)\n        # reshape X_train and X_test for using then in feature scaling\n        X_train = np.array(X_train).reshape(-1, 1)\n        X_test = np.array(X_test).reshape(-1, 1)\n        # feature scaling\n        sc = StandardScaler()\n        # get scaling factors based on the training set\n        X_train = sc.fit_transform(X_train)\n        # apply the same training set scaling facotrs to the testing set\n        X_test = sc.transform(X_test)\n        print(f\"Using {col} column\")\n        choose_best_model_fn(X_train, y_train, X_test, y_test)\n        print(\"\")","metadata":{"id":"CXEfd97yhCz3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Import Libraries & Load Data","metadata":{"id":"zOsNwNbB7zQx"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# for evaluating models\nfrom sklearn.metrics import confusion_matrix, accuracy_score,\\\nclassification_report\n\nimport operator\nfrom collections import defaultdict\n\nimport scipy.stats as stats\nimport copy\nimport warnings\n\nwarnings.filterwarnings('ignore')\n# graphics in retina format\n%config InlineBackend.figure_format = 'retina'","metadata":{"id":"_1NQDK6V63-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/voicegender/voice.csv')\ndf.head()","metadata":{"id":"gT4k1pKF7x-k","outputId":"ab292304-6cfa-4823-9b33-06e30109094a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Detect Missing Data","metadata":{"id":"YhwWzLon8N4O"}},{"cell_type":"code","source":"print(f\"Data Shape: {df.shape}\")","metadata":{"id":"6GT5NSu28BOX","outputId":"97898f49-97f8-4d55-8225-103dfbc271f3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"nsg4oRvR8i9d","outputId":"f867ce45-51f5-4d86-8a52-82f87d61b63e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for more assertion check for nans\ndf.isna().apply(pd.value_counts)","metadata":{"id":"ggAcQiOo8tKS","outputId":"eb042c6b-944b-412e-af99-8b59e1a2574e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unique labels\ndf['label'].unique()","metadata":{"id":"4W4DRROb-Y-j","outputId":"8a1fbe5b-16db-4bcb-81fd-cdd41e2ec04d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results\n\n* No missing data.\n* 20 columns contain float numbers.\n* 1 column contain category `['male', 'female']`.\n\n**Objective:** Build a classifier that accurately predicts if the voice is a male's or female's voice given all the input features.","metadata":{"id":"ufgouRvV8vPh"}},{"cell_type":"markdown","source":"# 3. Exploratory Data Analysis (EDA) and Data Preprocessing","metadata":{"id":"MgWXRAb8-1fr"}},{"cell_type":"code","source":"# number of unique values per column\ndf.nunique()","metadata":{"id":"St7uTOk99xSf","outputId":"5910ab5d-71bf-4648-db63-a02cbe6b1600"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Remove Columns with very low Predictive power","metadata":{"id":"2daArGTb_wJI"}},{"cell_type":"markdown","source":"We could observe from the above number of unique values per column, that features that have **3166** unique values are nearly **100%** unique since number of examples are **3168**. Therefore I will remove all these columns from the dataframe since they nearly won't have any predictive power in deducing the label (Male or Female).","metadata":{"id":"_dJ-9MH9-_Jy"}},{"cell_type":"code","source":"np.sum(df.nunique() == 3166)","metadata":{"id":"KqPCkz2cAU38","outputId":"9608dc71-5d0a-4a64-a646-0bca31d9656a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore I will remove 8 columns.","metadata":{"id":"t_JLwMw3s9Rm"}},{"cell_type":"code","source":"df.nunique() == 3166","metadata":{"id":"ZImJtqEClIVx","outputId":"eb13666b-ff2e-4818-ad58-1147e2adf100"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop low predictive power columns\ndf.drop(labels=['meanfreq', 'sd', 'skew', 'kurt', 'sp.ent', 'sfm', 'centroid',\n                'meanfun', 'median'], axis=1, inplace=True)\ndf.head()","metadata":{"id":"TFmqx0YetYiQ","outputId":"6276d7af-d373-4f5c-9b17-3fc62f3c040c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"New Data Shape: {df.shape}\")","metadata":{"id":"t2zqZ6PstaMD","outputId":"a3522900-26a1-451e-d4a8-821798804eb8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now things seems much easier for classifiers since noise should be reduced.","metadata":{"id":"9e2R84K9taaz"}},{"cell_type":"markdown","source":"## 3.2 Remove Columns with very low Predictive power","metadata":{"id":"7V3mZBOqVQ2e"}},{"cell_type":"markdown","source":"Now I will visualize if the left features have any considerable difference betweeen males and females by plotting continuous probability density curves.","metadata":{"id":"21xqUnCHVXp0"}},{"cell_type":"code","source":"plt.subplots(3, 4, figsize=(15, 15))\n\nfor i in range(1, 12):\n    plt.subplot(3, 4, i)\n    sns.kdeplot(df.loc[df['label'] == 'male', df.columns[i-1]], color='blue',\n                label='Male')\n    sns.kdeplot(df.loc[df['label'] == 'female', df.columns[i-1]],\n                color='green', label='Female')","metadata":{"id":"fbfFCYMRV6Au","outputId":"0e92cee8-0d55-47e2-b029-d4a7a2f0e5f0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some features seem to have big overlap between males, and females. Therefore I will drop those features from the dataframe.","metadata":{"id":"57kLiYBuYr4h"}},{"cell_type":"code","source":"df.drop(labels=['Q75', 'minfun', 'maxfun', 'modindx'], axis=1, inplace=True)\ndf.head()","metadata":{"id":"QGGWFW9yY3TC","outputId":"2d863ca8-f024-4a5f-b25c-eed10434817c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Split data into training and testing set","metadata":{"id":"_U3yY-ZxZq8n"}},{"cell_type":"code","source":"X = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values","metadata":{"id":"AfDuIXyAZ4cQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# use the random state for having reproducible results\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n                                                    random_state=0)","metadata":{"id":"bfFEQOizZ7Fs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Feature Scaling","metadata":{"id":"ACWB6MuVaBgZ"}},{"cell_type":"code","source":"# value ranges before feature scaling\ndf.describe()","metadata":{"id":"KwyzcY20aFgf","outputId":"20d586ba-bffc-4e7c-86b6-ebd530490e28"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It would be better for the models to put values on the same scale by appling feature scaling to avoid the dominance of some features over others due to their higher scale although they could have less predictive power as a feature.","metadata":{"id":"pA7LDNVbaKls"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"id":"_fTANcFAaf6N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Modeling (Trying different classifiers)","metadata":{"id":"0PM9KWcvErWw"}},{"cell_type":"markdown","source":"I will do this to understand more the different linear and non-linear classifiers.","metadata":{"id":"nLGipUNOcwjP"}},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"id":"F3HWGKuxcpAu","outputId":"532d2b9f-1c33-4566-d187-3a23e2b1723a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Evaluation:** I will only use accuracy as my evaluation metric since precision, recall and F1-score are more useful in case of having unequal labels as far as I know, and the number of males and females in the dataset are exactly the same. Moreover, I think voice detection is not as critical as medical domains where precision and recall will be more important.","metadata":{"id":"c9k21St7E1l0"}},{"cell_type":"markdown","source":"## 1. Linear Classifiers","metadata":{"id":"mcFKgcqdKYFC"}},{"cell_type":"markdown","source":"### 1.1 Logistic Regression","metadata":{"id":"DeCj_nWsKVth"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(random_state=0)\nevaluate_model_fn(lr, X_train, y_train, X_test, y_test)","metadata":{"id":"IBdBizZ2Ed_5","outputId":"dc68ee08-c898-485f-fc4b-15d089765388"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Support Vector Machine","metadata":{"id":"v71hLO-EKeGQ"}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc = SVC(kernel='linear', random_state=0)\nevaluate_model_fn(svc, X_train, y_train, X_test, y_test)","metadata":{"id":"qEk3b2iII_kY","outputId":"96bde627-b096-440a-9455-04290fe0ee0c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Non-linear Classifiers","metadata":{"id":"5UFgzbEQK_mP"}},{"cell_type":"markdown","source":"### 2.1 K-Nearest Neighbors (K-NN)","metadata":{"id":"-utAWJldLDIL"}},{"cell_type":"markdown","source":"If K is too small it will be sensitive to noise, and if it is too high it may include majority points from other classes.\n\n> Therefore a rule of thumb is to choose $K < \\sqrt(n)$ where n is the number of training examples.\n\n> Also choose K to be an odd number to avoid ties.","metadata":{"id":"02G0pB3vdUBw"}},{"cell_type":"code","source":"np.sqrt(df.shape[0])","metadata":{"id":"2Fmvw1zqdjOI","outputId":"8e9dc319-5787-47f9-da4a-3e526246a026"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def knn_optimize_fn(k, X_train, y_train, X_test, y_test):\n    \"\"\"Get the best number of nearest neighbors in KNN.\"\"\"\n    accuracies = []\n    K = range(1, k)\n    for i in K:\n        # we will set metric='minkowski' with p=2 for choosing the euclidean\n        # distance as written in the sklearn documentation \n        knn = KNeighborsClassifier(n_neighbors=i, metric='minkowski', p=2)\n        accuracies.append(evaluate_model_fn(knn, X_train, y_train, X_test,\n                                            y_test))\n        \n    plt.plot(K, accuracies, linestyle='dashed', marker='o',\n             markerfacecolor='red')\n    plt.xlabel('K')\n    plt.ylabel('Accuracy')\n    plt.show()\n    print(f\"Best K = {K[accuracies.index(max(accuracies))]}\")\n","metadata":{"id":"6rNT4YYMd81_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_optimize_fn(25, X_train, y_train, X_test, y_test)","metadata":{"id":"zYa_64DvK4G3","outputId":"b5f013bc-e5b4-47d7-f3ef-ad44e2614523"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will set metric='minkowski' with p=2 for choosing the euclidean distance as\n# written in the sklearn documentation \nknn = KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=2)\nevaluate_model_fn(knn, X_train, y_train, X_test, y_test)","metadata":{"id":"TQc4lyyifscc","outputId":"2f0bbebd-decb-4308-f28e-b6b6b99391b3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Kernel Support Vector Machine (SVM)","metadata":{"id":"AJk7HZbuLiN3"}},{"cell_type":"code","source":"def svm_optimize_fn(X_train, y_train, X_test, y_test):\n    \"\"\"Get the best SVM kernel.\"\"\"\n    accuracies = []\n    kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n    for kernel in kernels:\n        # we will set metric='minkowski' with p=2 for choosing the euclidean\n        # distance as written in the sklearn documentation \n        svm = SVC(kernel = kernel, random_state = 0)\n        accuracies.append(evaluate_model_fn(svm, X_train, y_train, X_test,\n                                            y_test))\n        \n    plt.plot(kernels, accuracies, linestyle='dashed', marker='o',\n             markerfacecolor='red')\n    plt.xlabel('Kernel')\n    plt.ylabel('Accuracy')\n    plt.show()\n    print(f\"Best Kernel = {kernels[accuracies.index(max(accuracies))]}\")\n","metadata":{"id":"RNgURZ1bgy6U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm_optimize_fn(X_train, y_train, X_test, y_test)","metadata":{"id":"Qh2HrCwphuxu","outputId":"c19daf90-2d8d-4cb7-c725-ecda09bcfc8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = SVC(kernel = 'rbf', random_state = 0)\nevaluate_model_fn(knn, X_train, y_train, X_test, y_test)","metadata":{"id":"ptGqZb8ILdMW","outputId":"0fe856f2-d0b0-4866-9538-d9b59e95e305"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Naive Bayes","metadata":{"id":"eVqyX9kOMMWp"}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnv = GaussianNB()\nevaluate_model_fn(nv, X_train, y_train, X_test, y_test)","metadata":{"id":"A9MH5LObL0BV","outputId":"8ba750e4-6e34-4023-93d8-9b97a2d3fc2c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4 Decision Tree (DT)","metadata":{"id":"i4CZR8iuOR1p"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# using entropy criterion\ndt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nevaluate_model_fn(dt, X_train, y_train, X_test, y_test)","metadata":{"id":"Nqw79pJJOPIz","outputId":"60751fca-25f7-4ca0-cd92-0361963bda48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# using gini criterion\ndt = DecisionTreeClassifier(criterion = 'gini', random_state = 0)\nevaluate_model_fn(dt, X_train, y_train, X_test, y_test)","metadata":{"id":"vluctywSiqdu","outputId":"4987acdc-4bb4-4136-d0d1-895085fe2e26"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore **entropy** is a better criterion in this case.","metadata":{"id":"0ZSsxadCivGz"}},{"cell_type":"markdown","source":"### 2.5 Random Forest (RD)","metadata":{"id":"cJq0c7tnO613"}},{"cell_type":"markdown","source":"I was guided in here by this blog post [Hyperparameter Tuning the Random Forest in Python](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74).","metadata":{"id":"aZZhVjNqq8i5"}},{"cell_type":"markdown","source":"#### 2.5.1 Random Hyperparameter Grid","metadata":{"id":"HuWD81wHqbWQ"}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom pprint import pprint\n\n# number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n# number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 150, num = 15)]\n# minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# method of selecting samples for training each tree\nbootstrap = [True, False]\n# create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\npprint(random_grid)               ","metadata":{"id":"bdYFndzHqfgv","outputId":"50b7228b-8b86-49b1-8c8d-d7299f104740"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.5.2 Random Search Training","metadata":{"id":"zSNeBOotrh1q"}},{"cell_type":"markdown","source":"Use the random grid to search for best hyperparameters.","metadata":{"id":"I7Da7bXzruB3"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# create the base model to tune\nrf = RandomForestClassifier()\n# random search of parameters using 5 fold cross validation, \n# search across 200 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf,\n                               param_distributions = random_grid,\n                               n_iter = 200, cv = 5, verbose=2, random_state=0,\n                               n_jobs = -1)\n# fit the random search model\nrf_random.fit(X_train, y_train)\n\npprint(rf_random.best_params_)","metadata":{"id":"JAy-k6P6rmdH","outputId":"1c375643-56bc-4f21-cf54-340e14ae6cd4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From these results, we should be able to narrow the range of values for each hyperparameter.\n\nNow we could narrow the range of values for each hyperparameter using the **Random Search** results.","metadata":{"id":"t7NDQTWeslHj"}},{"cell_type":"markdown","source":"#### 2.5.3 Grid Search with Cross Validation","metadata":{"id":"7CllDwZps_Ab"}},{"cell_type":"markdown","source":"Using Random Search results we could do **GridSearchCV** which evaluates all the combinations that we define instead of random sampling. We should make another grid based on the best values we obtained by random search for using Grid Search.","metadata":{"id":"zrLzRYVDtBUz"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# create the parameter grid based on the random search results\nparam_grid = {\n    'bootstrap': [False],\n    'max_depth': [140, 150, 160, 170],\n    'max_features': ['sqrt'],\n    'min_samples_leaf': [1, 2, 3],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [1900, 2000, 2100]\n}\n\n# create a based model\nrf = RandomForestClassifier()\n# instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 5, n_jobs = -1, verbose = 2)\n\n# fit the grid search to the data\ngrid_search.fit(X_train, y_train)\n\npprint(grid_search.best_params_)","metadata":{"id":"humSMDb4tm1g","outputId":"d412ff59-378f-4f14-b71a-ff0ab1a12152"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.5.4 Implement the RF Algorithm using the best obtained hyperparameters","metadata":{"id":"TS4bqgIPuJY5"}},{"cell_type":"markdown","source":"The result of `rf = grid_search.best_estimator_` I obtained was\n```\nRandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=140, max_features='sqrt',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=10,\n                       min_weight_fraction_leaf=0.0, n_estimators=1900,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)\n```","metadata":{"id":"-mzvHOYSZPVM"}},{"cell_type":"code","source":"rf = grid_search.best_estimator_\nevaluate_model_fn(rf, X_train, y_train, X_test, y_test)","metadata":{"id":"bjiXYV_2O1F9","outputId":"2b9db1b7-15dd-4ab7-db05-d9859e067a0b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So unitl now **Random Forest** final obtained model using grid search has obtained the highest accuracy on the test set with `accuracy = 0.9479495268138801`.","metadata":{"id":"X87L521Bb1Kf"}},{"cell_type":"markdown","source":"# 5. Optimization (Feature Selection)","metadata":{"id":"LxF015gkvTOC"}},{"cell_type":"markdown","source":"Now that we have nearly obtained the best models given the features we have now, why not see if these features were the best or not by reselecting features based on their performance on these newly obtained models.\n\nSo now instead of feature engineering then modeling, I will somehow inverse the process. Therefore, based on having some models, I will:\n1. Get the predictive power of each feature independently by using it alone across all models and see which feature will give the highest accuracy with the best model.\n2. Based on their predictive power, I will select features that obtained certain accuracies.\n3. Using these features, I will get the best model which resulted in the highest accuracy.\n4. Then I will return back to step 2 by decreasing the accuracy threshold a little bit, and therefore adding more features to the model, and moving until step 3 to get the model with highest accuracy.\n5. Repeat the above process and see which model has overall obtained the highest accuracy and choose this model as your final model.","metadata":{"id":"ly3OWxhHvYRV"}},{"cell_type":"markdown","source":"## 5.1 Get Each Feature Predictive Power","metadata":{"id":"6myInLvFth5D"}},{"cell_type":"markdown","source":"We could check the predictive power on using them only by using the `columns_predictive_power_fn` function defined above in the helpers functions.","metadata":{"id":"vGxlUawXx5Jr"}},{"cell_type":"code","source":"columns_predictive_power_fn('../input/voicegender/voice.csv')","metadata":{"id":"8Pqof8Rmx7sd","outputId":"4d4defd9-4cec-4d3d-923b-74e8a4f7d0cb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def choose_best_model_given_df_fn(dataframe):\n    \"\"\"Extract features and labels, split data into training and testing sets,\n    perforem feature scaling and finally fit the best model.\"\"\"\n    print(f'New Data Shape: {dataframe.shape}')\n\n    X = dataframe.iloc[:, :-1].values\n    y = dataframe.iloc[:, -1].values\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n                                                        random_state=0)\n    sc = StandardScaler()\n    X_train = sc.fit_transform(X_train)\n    X_test = sc.transform(X_test)\n    choose_best_model_fn(X_train, y_train, X_test, y_test)","metadata":{"id":"wbilZRJf1x-1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Using Features with Accuracy above 90%","metadata":{"id":"sz20yXysnCfU"}},{"cell_type":"code","source":"df = pd.read_csv('../input/voicegender/voice.csv')\ndf = df[['IQR', 'meanfun', 'label']]\nchoose_best_model_given_df_fn(df)","metadata":{"id":"W_tvh7AOrPkP","outputId":"abed1cce-ec68-47f6-e89a-423be1829466"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Using Features with Accuracy above 80%","metadata":{"id":"H0So-8WSnhBj"}},{"cell_type":"code","source":"df = pd.read_csv('../input/voicegender/voice.csv')\ndf = df[['IQR', 'meanfun', 'sd', 'Q25', 'label']]\nchoose_best_model_given_df_fn(df)","metadata":{"id":"UbGYDgi3noTD","outputId":"7abd3c77-9070-4c07-93df-5a0b48f594fc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4 Using Features with Accuracy above 70%","metadata":{"id":"evLL3R-6oILp"}},{"cell_type":"code","source":"df = pd.read_csv('../input/voicegender/voice.csv')\ndf = df[['IQR', 'meanfun', 'sd', 'Q25', 'sp.ent', 'sfm', 'mode', 'label']]\nchoose_best_model_given_df_fn(df)","metadata":{"id":"QcewXZb3oLHH","outputId":"52287286-eff1-4f5c-e5d3-dbb4dc1dbbb8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.5 Using Features with Accuracy above 60%","metadata":{"id":"QGk7G7NFobnW"}},{"cell_type":"code","source":"df = pd.read_csv('../input/voicegender/voice.csv')\ndf = df[['IQR', 'meanfun', 'sd', 'Q25', 'sp.ent', 'sfm', 'mode', 'meanfreq',\n         'median', 'skew', 'centroid', 'meandom', 'mindom', 'maxdom', 'dfrange',\n         'label']]\nchoose_best_model_given_df_fn(df)","metadata":{"id":"27gxDSecod9M","outputId":"d5eddccd-830c-4960-dca4-1b0e6f5199a7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.5 Using all features","metadata":{"id":"IHIrBVp621l7"}},{"cell_type":"code","source":"df = pd.read_csv('../input/voicegender/voice.csv')\nchoose_best_model_given_df_fn(df)","metadata":{"id":"-0DksncE3CIm","outputId":"6aa59218-7bd1-4854-9a23-26fbb5cf7f73"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Conclusion\n\nBy using the final optimization technique we obtained models with higher accuracies than using the features obtained from the first Exploratory Data Analysis (EDA) which got us an accuracy of 0.94 by using **Random Search** then **Grid Search** in **Random Forest**. Now, after optimization the best models are:\n1. Using all features: **RBF Kernel SVM** with accuracy 0.985.\n2. Using these features: `['IQR', 'meanfun', 'sd', 'Q25', 'sp.ent', 'sfm', 'mode', 'label']` **RBF Kernel SVM** with accuracy 0.985.\n\nSo I would prefer to go with the second option to avoid including unnecessary features which will need more computations since both obtained the same accuracy to the third decimal place but the second option has less features with higher predictive power if when they were acting in the models independently.","metadata":{"id":"thegTCGNyqD8"}},{"cell_type":"code","source":"","metadata":{"id":"Eu5APFk2enxN"},"execution_count":null,"outputs":[]}]}