{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fn = '/kaggle/input/real-time-advertisers-auction/Dataset.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Description"},{"metadata":{},"cell_type":"markdown","source":"The dataset provided to you has data for several websites owned by the same company and they are asking for your help for what should be their approach to set reserve prices and what is the range for reserve prices they should be setting for July. The data is only of the actual revenue generation and not at bid level. The dataset has the following columns:\n\n    Date\n    site_id : each id denotes a different website\n    adtypeid : each id denotes a different ad_type. These can be display ads , video ads, text ads etc\n    geo_id : each id denotes a different country. our maximum traffic is from english speaking countries\n    devicecategoryid : each id denoted a different device_category like desktop , mobile, tablet\n    advertiser_id: each id denotes a different bidder in the auction\n    order_id : can be ignored\n    lineitemtype_id : can be ignored\n    osid : each id denotes a different operating system for mobile device category only (android , ios etc) . for all other device categories, osid will correspond to not_mobile\n    integrationtypeid : it describes how the demand partner is setup within a publisher's ecosystem - can be adserver (running through the publisher adserver) or hardcoded\n    monetizationchannelid : it describes the mode through which demand partner integrates with a particular publisher - it can be header bidding (running via prebid.js), dynamic allocation, exchange bidding, direct etc\n    adunitid - each id denotes a different ad unit (one page can have more than one ad units)\n    total_impressions - measurement column measuring the impressions for the particular set of dimensions\n    total_revenue - measurement column measuring the revenue for the particular set of dimensions\n    viewable_impressions - Number of impressions on the site that were viewable out of all measurable impressions. A display ad is counted as viewable if at least 50% of its area was displayed on screen for at least one second\n    measurable_impressions - Impressions that were measurable by Active View out of the total number of eligible impressions. This value should generally be close to 100%. For example, an impression that is rendering in a cross-domain iframe may not be measurable.\n    Revenuesharepercent - not every advertiser gives all the revenue to the publisher. They charge a certain share for the services they provide. This captures the fraction of revenue that will actually reach the publishers pocket.\n"},{"metadata":{},"cell_type":"markdown","source":"#### DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(fn)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CPM"},{"metadata":{"trusted":true},"cell_type":"code","source":"def weird_division(n, d):\n    return n / d if d else 0\ndata['CPM'] = data.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)\n\nlabel = 'CPM'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### FEATURES"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [x for x in data.columns if x not in [label,'date','CPM', 'total_revenue', 'measurable_impressions', 'viewable_impressions', 'revenue_share_percent', 'total_impressions']]\nfeatures","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SPLIT and CLEAR"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as DT\ntextEnd = \"2019-06-22 00:00:00\"\ndateEnd = DT.datetime.strptime(textEnd, '%Y-%m-%d  %H:%M:%S').date()\n# text = \"2019-06-30 00:00:00\"\ndates = [DT.datetime.strptime(x, '%Y-%m-%d  %H:%M:%S').date() for x in data['date'].values]\ndates = np.array(dates)\n\ntrain_idx = dates<dateEnd\ntest_idx = dates>=dateEnd\ntrain = data[train_idx]\ntest = data[test_idx]\n\nmax_train_cpm = train['CPM'].quantile(.95)\nprint(f\"Train: value 95 quantile = {max_train_cpm}\");\ntrain_idx = (dates<dateEnd)&(data['CPM']<=max_train_cpm)\n\nmax_test_cpm = test['CPM'].quantile(.95)\nprint(f\"Test: value 95 quantile = {max_test_cpm}\");\ntest_idx = (dates>=dateEnd)&(data['CPM']>=0)&(data['CPM']<=max_test_cpm)\ntrain = data[train_idx]\ntest = data[test_idx]\nprint(f\"negative CPM data={(data['CPM']<0).sum()}\")\n\nprint(f\"size(train)={train.shape}, size(test)={test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### FIT-PREDICT simple LGBMRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators=500\nmax_depth=9\n\nX_train, X_test, y_train, y_test = train_test_split(train[features],train[label], test_size=0.3)\nmodel = LGBMRegressor(n_estimators=n_estimators,max_depth=max_depth)\nmodel.fit(X_train,y_train)\npred = model.predict(X_test)\nval_score = mean_squared_error(y_test,pred)\npred = model.predict(test[features])\ntest_score = mean_squared_error(test[label],pred)\nprint(f\"Score: val = {val_score}, test = {test_score}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMRegressor(n_estimators=n_estimators,max_depth=max_depth)\nmodel.fit(train[features],train[label])\npred = model.predict(test[features])\ntest_score = mean_squared_error(test[label],pred)\nprint(f\"Score: test = {test_score}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}