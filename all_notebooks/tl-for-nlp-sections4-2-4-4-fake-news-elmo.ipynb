{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preliminaries\nFirst install a critical dependency for our code","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install keras==2.2.4 # critical dependency, ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Write requirements to file, anytime you run it, in case you have to go back and recover dependencies.\n\nLatest known such requirements are hosted for each notebook in the companion github repo, and can be pulled down and installed here if needed. Companion github repo is located at https://github.com/azunre/transfer-learning-for-nlp","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze > kaggle_image_requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read and Preprocess Fake News Dataset\nFirst let's list the available data files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read in the \"true\" and \"fake\" data\n\nIn quotes, because that has the potential to simply replicate the biases of the labeler, so should be carefully evaluated","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Read the data into pandas DataFrames\nDataTrue = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")\nDataFake = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")\n\nprint(\"Data labeled as True:\")\nprint(DataTrue.head())\nprint(\"\\n\\n\\nData labeled as Fake:\")\nprint(DataFake.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assemble the two different kinds of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Nsamp =1000 # number of samples to generate in each class - 'true', 'fake'\nDataTrue = DataTrue.sample(Nsamp)\nDataFake = DataFake.sample(Nsamp)\nraw_data = pd.concat([DataTrue,DataFake], axis=0).values\n\n# combine title, body text and topics into one string per document\nraw_data = [sample[0].lower() + sample[1].lower() + sample[3].lower() for sample in raw_data]\n\nprint(\"Length of combined data is:\")\nprint(len(raw_data))\nprint(\"Data represented as numpy array (first 5 samples) is:\")\nprint(raw_data[:5])\n\n# corresponding labels\nCategories = ['True','False']\nheader = ([1]*Nsamp)\nheader.extend(([0]*Nsamp))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shuffle data, split into train and test sets...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for shuffling data\ndef unison_shuffle(a, b):\n    p = np.random.permutation(len(b))\n    data = np.asarray(a)[p]\n    header = np.asarray(b)[p]\n    return data, header\n\nraw_data, header = unison_shuffle(raw_data, header)\n\n# split into independent 70% training and 30% testing sets\nidx = int(0.7*raw_data.shape[0])\n\n# 70% of data for training\ntrain_x = raw_data[:idx]\ntrain_y = header[:idx]\n# remaining 30% for testing\ntest_x = raw_data[idx:]\ntest_y = header[idx:]\n\nprint(\"train_x/train_y list details, to make sure it is of the right form:\")\nprint(len(train_x))\n#print(train_x)\nprint(train_y[:5])\nprint(train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build, Train and Evaluate ELMo Model\n\nFirst import required neural network libraries\n\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom keras import backend as K\nimport keras.layers as layers\nfrom keras.models import Model, load_model\nfrom keras.engine import Layer\n\n# Initialize tensorflow/keras session\nsess = tf.Session()\nK.set_session(sess)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a custom tf hub ELMO embedding layer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class ElmoEmbeddingLayer(Layer):\n    def __init__(self, **kwargs):\n        self.dimensions = 1024 # initialize output dimension of ELMo embedding\n        self.trainable=True\n        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape): # function for building ELMo embedding\n        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n                               name=\"{}_module\".format(self.name)) # download pretrained ELMo model\n        \n        # extract trainable parameters, which are only a small subset of the total - this is a constraint of\n        # the tf hub module as shared by the authors - see https://tfhub.dev/google/elmo/2\n        # the trainable parameters are 4 scalar weights on the sum of the outputs of ELMo layers \n        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n        super(ElmoEmbeddingLayer, self).build(input_shape)\n\n    def call(self, x, mask=None): # specify function for calling embedding\n        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n                      as_dict=True,\n                      signature='default',\n                      )['default']\n        return result\n\n    def compute_output_shape(self, input_shape): # specify output shape\n        return (input_shape[0], self.dimensions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now use the custom TF hub ELMo embedding layer within a higher-level function to define the overall model. More specifically, we put a dense trainable layer of output dimension 256 on top of the ELMo embedding.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to build overall model\ndef build_model():\n    input_text = layers.Input(shape=(1,), dtype=\"string\")\n    embedding = ElmoEmbeddingLayer()(input_text)\n    dense = layers.Dense(256, activation='relu')(embedding)\n    pred = layers.Dense(1, activation='sigmoid')(dense)    \n    model = Model(inputs=[input_text], outputs=pred)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build and fit\n\nmodel = build_model()\nhistory = model.fit(train_x, \n          train_y,\n          validation_data=(test_x, test_y),\n          epochs=10,\n          batch_size=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save trained model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('ELMoModel.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize Convergence","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf_history = pd.DataFrame(history.history)\n\nfig,ax = plt.subplots()\nplt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\nplt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('ELMo Fake News Classification Training')\nplt.legend(loc='best')\nplt.grid()\nplt.show()\n# Save figures\nfig.savefig('ELMoConvergence.eps', format='eps')\nfig.savefig('ELMoConvergence.pdf', format='pdf')\nfig.savefig('ELMoConvergence.png', format='png')\nfig.savefig('ELMoConvergence.svg', format='svg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make figures downloadable to local system in interactive mode","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\ndef create_download_link(title = \"Download file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(filename='ELMoConvergence.svg')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}