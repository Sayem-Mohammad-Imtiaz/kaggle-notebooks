{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Lets read the data\ndata = pd.read_csv(\"/kaggle/input/credit-card-customers/BankChurners.csv\", index_col = 0)\ndata_train, data_test = train_test_split(data, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets take a quick look at the data\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets get an overview of income distributions\nincome = data_train.groupby(\"Income_Category\").Income_Category.agg([\"count\"])\n\nfig = plt.figure()\nplt.title(\"Number of customers in income categories\")\nplt.grid(which = \"both\", color = \"lightgray\", linestyle = \"--\")\nplt.bar(x = income.index, height = income[\"count\"])\nplt.xticks(rotation = 45)\nplt.xlabel(\"Income category\")\nplt.ylabel(\"Number of customers\")\n\nincome","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_income = data_train.groupby([\"Income_Category\", \"Gender\"]).Income_Category.agg([\"count\"])\ngender_income.unstack().plot(kind = \"bar\")\nplt.title(\"Income distribution based on income and gender\")\nplt.xticks(rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"education_income = data_train.groupby([\"Income_Category\", \"Education_Level\"]).Income_Category.agg([\"count\"])\neducation_income.unstack().plot(kind = \"bar\")\nplt.title(\"Income distribution based on education and gender\")\nplt.xticks(rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = data_train.shape[1] - 10\ncategories = {a: b for a, b in zip(range(n), data_train.columns)}\nfor i in range(2, n):\n    data_train.groupby([categories[i], categories[0]]).Attrition_Flag.agg([\"count\"]).unstack().plot(kind = \"bar\")\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total relationship count and Contacts count over 12 months looks like indicators. However, it is hard to see which attributes to use since the value of Atrrited and Existing custumor is less informative than their relation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(2, n):\n    base = data_train.groupby([categories[i]]).Attrition_Flag.agg([\"count\"])\n    temp_data = data_train.groupby([categories[i], categories[0]]).Attrition_Flag.agg([\"count\"])/base\n    temp_data.unstack().plot(kind = \"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After normalizing and eyeballing it appears age might provide some information, education, income and card category is mildly indicative, month on book might be a good indicator. Total relationship count and months inactive appear strong indicators.\n\nLet's create a pipeline and start transforming the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom pandas.api.types import CategoricalDtype\n\n# make a custom function for the pipeline\nclass ToCat(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y = None):\n        return self\n    \n    def transform(self, X, y = None):\n        df = X.copy()\n        cat_cols = [0, 2, 3, 4, 5, 7]\n        income_cats = CategoricalDtype(categories=[\"Unknown\", \"Less than $40K\", \"$40K - $60K\", \"$60K - $80K\", \"$80K - $120K\", \"$120K +\"], ordered=True)\n        df.loc[:, categories[6]] = df.iloc[:, 6].astype(income_cats)\n        df.iloc[:, 6] = df.iloc[:, 6].fillna(\"Unknown\")\n        for i in cat_cols:\n            df.iloc[:, [i]] = df.iloc[:, [i]].astype(\"category\")\n        return df\n    \nclass CatToCodes(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y = None):\n        return self\n    \n    def transform(self, X, y = None):\n        df = X.copy()\n        df[\"Income_Unknown\"] = (df[\"Income_Category\"] == \"Unknown\").astype(int)\n        df[\"Income_Cat\"] = df.Income_Category.cat.codes\n        df.drop(columns = [\"Income_Category\"], inplace = True)\n        cat_cols = df.select_dtypes(['category']).columns\n        for col in cat_cols:\n            df = pd.concat([df, pd.get_dummies(df[col], prefix = col)], axis = 1)\n            df.drop(columns = [col], inplace = True)\n        df.drop(columns = [\"Attrition_Flag_Attrited Customer\"], inplace = True)\n        return df\n    \nclass DropColumns(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y = None):\n        return self\n    \n    def transform(self, X, y = None):\n        return X.iloc[:, list(range(X.shape[1] - 2))]\n\npipe = Pipeline(steps = [\n    ('drop_cols', DropColumns()),\n    ('make_cat', ToCat()),\n    ('cat_to_codes', CatToCodes()),\n    ])\n\npipe.fit(data_train)\ndata_train = pipe.transform(data_train)\ndata_test  = pipe.transform(data_test)\n\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that everything is changed to numbers we should inspect the data to check how it is related. We start with a correlation plot which checks for linear dependencies. "},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mat = data_train.corr()\n\nsns.heatmap(corr_mat)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the correlation matrix it appears the non-categorical features has the greatest linear relation with the attrition feature. Now let's check if all variables are approximately normally distributed. We also see that Credit_Limit and Avg_Open_To_Buy is almost perfectly correlated.\n\nBut first let's also list the most correlated variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mat[\"Attrition_Flag_Existing Customer\"].abs().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears Total_Trans_Ct, Total_Ct_Chng_Q4_Q1, Total_Revolving_Bal and Contacts_Count_12_mon is the features which has the greatest correlation with the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context('seaborn-darkgrid'):\n    fig = plt.figure(figsize = (12, 12))\n    ax = pd.plotting.radviz(data_train, 'Attrition_Flag_Existing Customer', alpha = 0.25)\n    L = ax.legend(loc = \"upper right\")\n    L.get_texts()[0].set_text(\"Attrited Customer\")\n    L.get_texts()[1].set_text(\"Existing Customer\")\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear from the radviz plot that the classes are not well seperated."},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-darkgrid\"):\n    fig = plt.figure()\n    axes = pd.plotting.scatter_matrix(data_train.iloc[:, 0:13], alpha = 0.1, figsize = (18, 18), diagonal = 'hist')\n    for ax in axes.flatten():\n        ax.xaxis.label.set_rotation(90)\n        ax.yaxis.label.set_rotation(0)\n        ax.yaxis.label.set_ha('right')\n    plt.tight_layout()\n    plt.gcf().subplots_adjust(wspace = 0, hspace = 0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, Credit_Limit and Avg_Open_To_Buy seems to capture virtually the same information. They are perfectly linearly correlated and it may be prudent to drop one of them. Customer_Age and Months_on_book are also well correlated. So, it may be wise to drop Custumer_Age. Additionally, not all features are normally distributed. Some features are from a power distribution. So, it is important that we rescale these. Finally, there are some artifacts with exceptional amount of people with 36 or so Months_on_book and some other features. Let's do a rescaling and check again.\n\nBut, first let's seperate the training target from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate features from target and dropping Customer age and avg open to buy\n\ntarget_train = data_train[\"Attrition_Flag_Existing Customer\"]\ndata_train = data_train.drop(columns = [\"Attrition_Flag_Existing Customer\"])\ntarget_test = data_test[\"Attrition_Flag_Existing Customer\"]\ndata_test = data_test.drop(columns = [\"Attrition_Flag_Existing Customer\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's rescale and see if we get better distributions. Let's also try and do some feature eliminations. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import PowerTransformer\nss = StandardScaler()\nmms = MinMaxScaler(feature_range = (0, 1))\npt = PowerTransformer(method = \"box-cox\")\n\npipe_scale = Pipeline(steps = [('s', mms), ('ss', ss)])\npipe_scale.fit(data_train, target_train)\ndata_train_t = pipe_scale.transform(data_train)\ndata_test_t = pipe_scale.transform(data_test)\n\ndata_train_t = pd.DataFrame(data_train_t, columns = data_train.columns, index = data_train.index)\ndata_test_t = pd.DataFrame(data_test_t, columns = data_test.columns, index = data_test.index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_t.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context(\"seaborn-darkgrid\"):\n    fig = plt.figure()\n    axes = pd.plotting.scatter_matrix(data_train_t.iloc[:, 0:13], alpha = 0.1, figsize = (18, 18), diagonal = 'hist')\n    for ax in axes.flatten():\n        ax.xaxis.label.set_rotation(90)\n        ax.yaxis.label.set_rotation(0)\n        ax.yaxis.label.set_ha('right')\n    plt.tight_layout()\n    plt.gcf().subplots_adjust(wspace = 0, hspace = 0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is better than before, but not all power distributions have been scaled to normal distributions. Let's now reinspect the cluster plot generated by the radviz function."},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context('seaborn-darkgrid'):\n    fig = plt.figure(figsize = (12, 12))\n    temp = data_train_t.copy()\n    temp[\"Attrition_Flag\"] = target_train\n    ax = pd.plotting.radviz(temp, 'Attrition_Flag', alpha = 0.25)\n    L = ax.legend(loc = \"upper right\")\n    L.get_texts()[0].set_text(\"Attrited Customer\")\n    L.get_texts()[1].set_text(\"Existing Customer\")\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data seem a bit more centered but no obvious change is visible. Still, with the scaling and so on we will test with a logistic regression and see if we can gain a good accuracy with the dataset as it currently is."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import SVC\n\nestimator = SVC(kernel = \"linear\")\n\nmin_features_to_select = 1  # Minimum number of features to consider\nrfecv = RFECV(estimator=estimator, step=1, cv=StratifiedKFold(2),\n              scoring='accuracy',\n              min_features_to_select=min_features_to_select)\nrfecv.fit(data_train_t, target_train)\n\nselected_train = data_train_t.iloc[:, rfecv.ranking_ == 1]\nselected_test = data_test_t.iloc[:, rfecv.ranking_ == 1]\n\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)\n\n# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(min_features_to_select,\n               len(rfecv.grid_scores_) + min_features_to_select),\n         rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Start with a simple Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n\nclf_t = LogisticRegression().fit(data_train_t, target_train)\nscores = cross_val_score(clf_t, data_train_t, target_train, cv = 5)\nprint(\"Mean score: \", np.mean(scores), \" Std: \", np.std(scores))\n\nclf_t = LogisticRegression().fit(selected_train, target_train)\nscores = cross_val_score(clf_t, selected_train, target_train, cv = 5)\nprint(\"Mean score: \", np.mean(scores), \" Std: \", np.std(scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With these transformed feateres, we get about 91% accuracy using logistic regression. Now let's reduce the features further with PCA analysis and keep the tranformed features with greatest variation."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(0.95)\n\npca.fit(selected_train)\nselected_train = pca.transform(selected_train)\nselected_test = pca.transform(selected_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\n\nparameters = {'kernel':('linear', 'rbf', 'poly'), 'C':np.logspace(0,1,11)}\nsvc = svm.SVC()\ngnb = GaussianNB()\nrfc = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_t = GridSearchCV(svc, parameters)\nclf_t.fit(data_train_t, target_train)\nclf_t.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_selected = GridSearchCV(svc, parameters)\nclf_selected.fit(selected_train, target_train)\nclf_selected.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb.fit(data_train_t, target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_parameters = {\n                'max_depth': range(1, 10),\n                'min_samples_leaf': range(1, 10),\n                }\nclf_rf = GridSearchCV(rfc, rf_parameters)\nclf_rf.fit(data_train_t, target_train)\nclf_rf.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_t = cross_val_score(clf_t, data_train_t, target_train, cv = 5)\nprint(\"Mean score: \", np.mean(scores_t), \" Std: \", np.std(scores_t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_selected = cross_val_score(clf_selected, selected_train, target_train, cv = 5)\nprint(\"Mean score: \", np.mean(scores_selected), \" Std: \", np.std(scores_selected))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_gnb = cross_val_score(gnb, data_train_t, target_train, cv = 5)\nprint(\"Naive Bayes Mean score: \", np.mean(scores_gnb), \" Std: \", np.std(scores_gnb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_rnc = cross_val_score(clf_rf, data_train_t, target_train, cv = 5)\nprint(\"Random Forest Mean score: \", np.mean(scores_rnc), \" Std: \", np.std(scores_rnc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The random forest appear to give the best results at 94%. Let's wrap it up with testing against the test sets and perform an ANOVA test to verify that the best performer is indeed the best performer."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_scores_t = cross_val_score(clf_t, data_test_t, target_test, cv = 10)\ntest_scores_selected = cross_val_score(clf_selected, selected_test, target_test, cv = 10)\ntest_scores_rnc = cross_val_score(clf_rf, data_test_t, target_test, cv = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now we will perform an ANOVA test with the null hypothesis $H_0$: all test scores are the same, $H_a$: at least one test score is different to the rest."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.stats.multicomp\n\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.anova import anova_lm\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nsns.kdeplot(test_scores_t, shade = True)\nsns.kdeplot(test_scores_selected, shade = True)\nsns.kdeplot(test_scores_rnc, shade = True)\nplt.legend([\"SVM\", \"SVM reduced features\", \"Random Forest\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distributions are approximately normally distributed, and the Random forest classifier perfermed the best."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}