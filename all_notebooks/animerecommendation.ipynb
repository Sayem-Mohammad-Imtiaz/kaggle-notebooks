{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"animeSet = pd.read_csv('/kaggle/input/anime-recommendations-database/anime.csv', usecols=[0, 1, 2], index_col='anime_id')\nanimeSet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We only need Anime Table to lookup the name and genre of the recommended anime Id's \n**We don't need it for recommendation process**\n\nLet's create a method where we pass anime_id and get name and title.","metadata":{}},{"cell_type":"code","source":"def getAnimeDetails(anime_id):\n    name = animeSet.at[anime_id, 'name']\n    genre = animeSet.at[anime_id, 'genre']\n    return anime_id, name, genre","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getAnimeDetails(32281)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's Read ratings data and clean that\n","metadata":{}},{"cell_type":"code","source":"ratings = pd.read_csv('/kaggle/input/anime-recommendations-database/rating.csv')\nratings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('users are', len(ratings['user_id'].value_counts()))\nprint('animes are', len(ratings['anime_id'].value_counts()))\nprint('so the matrix is ', len(ratings['user_id'].value_counts()), 'X', len(ratings['anime_id'].value_counts()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# It's better to drop users who have seen fewer than 5 Movies\n# Drop movies watched by fewwer than 5 users\n**This will reduce the size of the sparse matrix**","metadata":{}},{"cell_type":"code","source":"animeIdSeries = ratings['anime_id'].value_counts()\nuserIdSeries = ratings['user_id'].value_counts()\n# Remove inactive animies\nratings = ratings[ratings['anime_id'].isin(animeIdSeries[animeIdSeries > 10].index)]\n# Remove inactive Users\nratings = ratings[ratings['user_id'].isin(userIdSeries[userIdSeries > 10].index)]\n# Remove animies those are not in anime dataset\nratings = ratings[ratings['anime_id'].isin(animeSet.index)]\n\nprint('final users are', len(ratings['user_id'].value_counts()))\nprint('final animes are', len(ratings['anime_id'].value_counts()))\nprint('so the matrix is ', len(ratings['user_id'].value_counts()), 'X', len(ratings['anime_id'].value_counts()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we have the good and less sparse table\n# Now we can go ahead with creating the pivot table","metadata":{}},{"cell_type":"code","source":"# Replace -1 with NaN because -1 will be considered for distance\ndef replacewithNAN(value):\n    if value == -1:\n        return np.NaN\n    return value\n\nratings['rating'] = ratings['rating'].apply(replacewithNAN)\nratings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct the pivot table now\nratingsPivot = pd.pivot_table(ratings, values='rating', index='user_id', columns='anime_id')\nratingsPivot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hamming Distance that omits NaN's for better comparisions\ndef hammingDist(user1, user2):\n    matches = 0\n    nans = 0\n    for i in range(len(user1)):\n        if np.isnan(user1[i]):\n            nans += 1\n            continue\n        if np.isnan(user2[i]):\n            nans += 1\n            continue\n        if user1[i] == user2[i]:\n            matches += 1\n    res = matches / (len(user1) - nans)\n    return 1-res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the hamming distance between two users\nfrom scipy.spatial import distance\ndef distanceFn(user1, user2):\n    try:\n        user1Ratings= ratingsPivot.transpose()[user1]\n        user2Ratings= ratingsPivot.transpose()[user2]\n        dist = distance.hamming(user1Ratings, user2Ratings)\n    except:\n        dist = np.NaN\n    return dist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find all the users and get the distance for each User\ndef KNearestNeighbors(activeUser, k=10):\n    allUsers = pd.DataFrame(ratingsPivot.index)\n    allUsers = allUsers[allUsers.user_id != activeUser]\n    allUsers['distance'] = allUsers['user_id'].apply(lambda user: distanceFn(activeUser, user))\n    topUsers = allUsers.sort_values(['distance'], ascending=[True])[:k]\n    return topUsers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getBestSuggestions(activeuser, topUsers, animeCount=10):\n    #     Get the nearest neighbours\n    neighbourRatings = ratingsPivot[ratingsPivot.index.isin(topUsers['user_id'])]\n    #     Get the average rating for all animes from the neighbors\n    avgRatings = neighbourRatings.apply(np.nanmean).dropna()\n    # Get all animes which dosn't have nan \n    animesWatched = ratingsPivot.transpose()[activeuser].dropna().index\n    #     Delete animes you already watched to stop redundancies\n    avgRatings = avgRatings[~avgRatings.index.isin(animesWatched)]\n    #     Sort and get top 10 Animies\n    topanime_ids = avgRatings.sort_values(ascending=False).index[:10]\n    #     Return a dataframe to the user with top 10 recommendations\n    recommendedAnimes = pd.DataFrame(columns = ['anime_id', 'name', 'genre'])\n    for anime in topanime_ids:\n        res = getAnimeDetails(anime)\n        recommendedAnimes = recommendedAnimes.append({'anime_id' : res[0], 'name' : res[1], 'genre' : res[2]}, \n                    ignore_index = True)\n    return recommendedAnimes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def directorMethod(activeUser):\n    topUsers = KNearestNeighbors(activeUser)\n    return getBestSuggestions(activeUser, topUsers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activeUser = 73515\nsuggestions = directorMethod(activeUser)\nsuggestions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here is the Flow\n1. Get the ratings dataset\n2. If that's huge and spares drop that gives less information\n3. Then construct the pivot table\n4. Then calculate the distance b/w all users and pick the most nearest people\n5. Then compute the averages for each anime with respect to all users\n6. Then pick the top 5 or 10 with highest average\n7. That's it now user the lookup table to get the names and genre of the shows","metadata":{}},{"cell_type":"markdown","source":"**                                     The END           **","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}