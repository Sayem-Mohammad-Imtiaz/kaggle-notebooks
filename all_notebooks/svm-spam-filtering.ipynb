{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **CAT -3 PREDICTIVE ANALYSIS**\n","metadata":{}},{"cell_type":"markdown","source":"#  Implement Support Vector Machine to build a spam classifier\n","metadata":{"_uuid":"25f02ffdb0d53b9663f351fa0c0f415d2bce15b1","_cell_guid":"f169d7cf-818b-4815-a5be-76265e99d139"}},{"cell_type":"markdown","source":"##  Import required libraries","metadata":{"_uuid":"e27ea858875f6d5698fcfb196b32160c8d761697","_cell_guid":"ba30922b-183b-4f2e-ac19-35ebc9dd865a"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\nfrom IPython.display import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline  ","metadata":{"_uuid":"5eb96b9e55cca9f7dbc74128cd5933856b39aa51","_cell_guid":"77dbf249-4662-4faf-ae30-654f5f76f5b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the Dataset","metadata":{"_uuid":"2a11f84b23cf786579a3beb1074c6e7375456b77","_cell_guid":"ab7471a7-9fda-4dc9-ba8b-6d4f0c1b92e1"}},{"cell_type":"code","source":"data = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv', encoding='latin-1')\ndata.head(n=10)","metadata":{"_uuid":"3a9038c1ea6026f8ae89cf052aa71c89bcb940dd","_cell_guid":"e8604809-62b9-47bd-84fa-92063d8ae5b3","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Describe the Data Set","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution spam/non-spam plots","metadata":{"_uuid":"d71ec916875461c07bdb1f9d53d9b0a7210de035","_cell_guid":"2ed76eea-004a-42a0-a1c9-c45c092bbb4b"}},{"cell_type":"code","source":"count_Class=pd.value_counts(data[\"v1\"], sort= True)\ncount_Class.plot(kind= 'bar', color= [\"blue\", \"orange\"])\nplt.title('Bar chart')\nplt.show()","metadata":{"_uuid":"99a4b831313c23573b7972c65637d01dd497c6fe","_cell_guid":"74f9cf41-4793-4be5-a46e-bdb93067e973","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_Class.plot(kind = 'pie', shadow=True,explode=(0,0.1), autopct='%1.1f%%')\nplt.title('Pie chart')\nplt.ylabel('')\nplt.show()","metadata":{"_uuid":"f233eab105cb93e90ce37f9361616a5be6645751","_cell_guid":"5596df63-7be7-4625-b952-c5508917a630","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Analytics","metadata":{"_uuid":"9ec51be1879d2987eef26632bc411a3577b42ae8","_cell_guid":"ff53e1a6-a37b-4a31-9b41-c959296156de"}},{"cell_type":"markdown","source":"We want to find the frequencies of words in the spam and non-spam messages. The words of the messages will be model features.<p>\nWe use the function Counter.","metadata":{"_uuid":"b3c395e8534efc8a402df3b6ac1b699b48fa09f3","_cell_guid":"ba58d2e5-63a4-4443-ab05-7810decb5eb7"}},{"cell_type":"code","source":"count1 = Counter(\" \".join(data[data['v1']=='ham'][\"v2\"]).split()).most_common(20)\ndf1 = pd.DataFrame.from_dict(count1)\ndf1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\ncount2 = Counter(\" \".join(data[data['v1']=='spam'][\"v2\"]).split()).most_common(20)\ndf2 = pd.DataFrame.from_dict(count2)\ndf2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})","metadata":{"_uuid":"03677f8369b4bb3450ffe8a9cd3de9c0b01e681d","_cell_guid":"8c750858-87e9-498c-86f5-4df7310f9e63","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.plot.bar(legend = False)\ny_pos = np.arange(len(df1[\"words in non-spam\"]))\nplt.xticks(y_pos, df1[\"words in non-spam\"])\nplt.title('More frequent words in non-spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()","metadata":{"_uuid":"d18e09f35264ea374ffce57eae07c9335439a2ef","_cell_guid":"b8850226-0043-4a37-9e65-a8409efe7026","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.plot.bar(legend = False, color = 'orange')\ny_pos = np.arange(len(df2[\"words in spam\"]))\nplt.xticks(y_pos, df2[\"words in spam\"])\nplt.title('More frequent words in spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()","metadata":{"_uuid":"bf9b59581db68038824724344fe937e65f5f8661","_cell_guid":"9637faec-7114-4365-aceb-a2d74787a205","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can see that the majority of frequent words in both classes are stop words such as 'to', 'a', 'or' and so on.\n\n#### With stop words we refer to the most common words in a language, there is no single, universal list of stop words.","metadata":{"_uuid":"c971edae5a8be1bfd0719e777ba92322ad897abe","_cell_guid":"40db40e9-aeb2-487f-9ab7-d6debf26d611"}},{"cell_type":"markdown","source":"## **Predictive Analysis**","metadata":{"_uuid":"1f0489faa50638217e4754ff0a8f26e5298752df","_cell_guid":"448eda90-2493-46f0-a588-8e6e73b7e2d3"}},{"cell_type":"markdown","source":"#### **Our goal is to predict if a new sms is spam or non-spam. We assume that is much worse misclassify non-spam than misclassify an spam. (We want to have minimum number of false positives)**\n\n\n#### This model should get lowest possible number of spam message in our inbox(False Negative) and lowest number of non spam message in the spam folder(False Positive).\n\n#### First we transform the variable spam/non-spam into binary variable(assigning binary values 0 to non spam mails and 1 to spam mails), then we split our data set in training set and test set. ","metadata":{"_uuid":"da31f2e8dd19f4ff0a6c1f6dbf29b34a2c28391a","_cell_guid":"e19c8da3-73b0-4ed8-ac08-04e45a4309da"}},{"cell_type":"code","source":"data[\"v1\"]=data[\"v1\"].map({'spam':1,'ham':0})\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['v1'], test_size=0.33, random_state=42)\nprint([np.shape(X_train), np.shape(X_test)])","metadata":{"_uuid":"ab65abc5fe63168bfea503db8e58e5ab03383a22","_cell_guid":"e5e2bee3-cdad-4ee6-9c59-f3a536195ed7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Support Vector Machine**","metadata":{"_uuid":"63efdf82c6e3aeabf14cc906cec456ba6f6a6ac0","_cell_guid":"edfcb798-4f74-4552-8bea-2617804eea56"}},{"cell_type":"markdown","source":"#### We are going to apply the same reasoning applying the support vector machine model with the gaussian kernel.\n\n#### We train different models changing the regularization parameter C.\n\n#### We evaluate the accuracy, recall and precision of the model with the test set.","metadata":{"_uuid":"2d549025a14408ce4cd2df88f02c3468e75b9c45","_cell_guid":"2fc3af32-8b41-402b-b934-7e594eb4c972"}},{"cell_type":"code","source":"list_C = np.arange(500, 2000, 100) #100000\nscore_train = np.zeros(len(list_C))\nscore_test = np.zeros(len(list_C))\nrecall_test = np.zeros(len(list_C))\nprecision_test= np.zeros(len(list_C))\ncount = 0\nfor C in list_C:\n    svc = svm.SVC(C=C)\n    svc.fit(X_train, y_train)\n    score_train[count] = svc.score(X_train, y_train)\n    score_test[count]= svc.score(X_test, y_test)\n    recall_test[count] = metrics.recall_score(y_test, svc.predict(X_test))\n    precision_test[count] = metrics.precision_score(y_test, svc.predict(X_test))\n    count = count + 1 ","metadata":{"_uuid":"1101b49ede4dccec53089e86f3db2969abea67ee","_cell_guid":"f82fc85a-e883-42d1-abbc-c3b3342247dc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now let's look at our learning model and its metrics","metadata":{"_uuid":"4e1c88cc318233afe97fa9e298562c1e6025de1d","_cell_guid":"820fad12-6a0e-4ec6-b16a-e9734d69bf64"}},{"cell_type":"code","source":"matrix = np.matrix(np.c_[list_C, score_train, score_test, recall_test, precision_test])\nmodels = pd.DataFrame(data = matrix, columns = \n             ['C', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\nmodels.head(n=10)","metadata":{"_uuid":"ec36f5defc3f1477cca07c5280818ee4282995d9","_cell_guid":"4da69237-fe8c-40ac-a72a-d33dc7863859","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking for model with highest precision","metadata":{"_uuid":"17a895a4c6a415493afae69ebeff7d172f09b014","_cell_guid":"7d5e554d-e0d8-44b0-9fca-480063caf529"}},{"cell_type":"code","source":"best_index = models['Test Precision'].idxmax()\nmodels.iloc[best_index, :]","metadata":{"_uuid":"45c5f185a965f1b92889e56ce5f12c7acacffdf6","_cell_guid":"d0380748-44f5-4e41-af56-d25230c44479","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we see if there are more than 1 model available with the highest precision(99.5%)","metadata":{"_uuid":"a428ab899dc27a65d3ec696ead5a049663c16524","_cell_guid":"166cb5ab-09da-49f4-bbb7-4e43bebd5c8e"}},{"cell_type":"code","source":"models[models['Test Precision']>=0.995].head(n=20)","metadata":{"_uuid":"fe2f070186300fed89e91380437f036e5feabe1d","_cell_guid":"89a59c66-8814-49d0-8f0e-f3b8acee666b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Between these models with the highest possible precision, we are going to selct which has more test accuracy.","metadata":{"_uuid":"790cff4e431937d762bbe8db39911bf0d87dc53d","_cell_guid":"08cb6d81-fb1d-4e11-95a6-7922d19d082b"}},{"cell_type":"code","source":"best_index = models[models['Test Precision']>=0.995]['Test Accuracy'].idxmax()\nsvc = svm.SVC(C=list_C[best_index])\nsvc.fit(X_train, y_train)\nmodels.iloc[best_index, :]","metadata":{"_uuid":"d7d6eb9f249d10c19d4b9332c794476973dcf33f","_cell_guid":"49e4103a-3be1-4feb-bec4-d8baa5255a0b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Confusion matrix with support vector machine classifier.**","metadata":{"_uuid":"dd004721e1b6171488e1acf4c2a14235fc7f9700","_cell_guid":"d41fbc97-15f5-4963-9d5f-1452b2efe7ab"}},{"cell_type":"code","source":"m_confusion_test = metrics.confusion_matrix(y_test, svc.predict(X_test))\npd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n            index = ['Actual 0', 'Actual 1'])","metadata":{"_uuid":"77005bd9a0fd6de323ada9206468c0598fa9c476","_cell_guid":"bf03b698-42e2-407f-a3da-dcc4acc36221","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We misclassify 37 spam as non-spam messages and we misclassify 1 non-spam message.","metadata":{"_uuid":"5190739594c1136056c12e2539889e38a9827641","_cell_guid":"44c24499-7357-41f3-af6f-2d05f2b988b4"}},{"cell_type":"markdown","source":"### **Accuracy**","metadata":{}},{"cell_type":"code","source":"svc.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we are getting accuracy of 97.93%","metadata":{}}]}