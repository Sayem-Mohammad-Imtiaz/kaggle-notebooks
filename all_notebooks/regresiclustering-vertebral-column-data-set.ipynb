{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport operator\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# import warnings\nimport warnings\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")\nfrom subprocess import check_output\nfrom IPython.display import Markdown as md\nfrom prettytable import PrettyTable\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom numpy import sqrt\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/vertebralcolumndataset/column_2C.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to see features and target variable\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Well know question is is there any NaN value and length of this data so lets look at info\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\npd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal='hist',\n                                       alpha=0.5,\n                                       s = 200,\n                                       marker = '*',\n                                       edgecolor= \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"class\", data=data)\ndata.loc[:,'class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ******REGRESSION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create data1 that includes pelvic_incidence that is feature and sacral_slope that is target variable\ndata1 = data[data['class'] =='Abnormal']\nx = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(data1.loc[:,'sacral_slope']).reshape(-1,1)\n# Scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x=x,y=y)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LinearRegression\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\npredict_space = np.linspace(min(x), max(x)).reshape(-1,1)\n# Fit\nreg.fit(x,y)\n# Predict\npredicted = reg.predict(predict_space)\n# # R^2 \n# print('R^2 score: ',reg.score(x, y))\ndegree = 1\n\nx = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(data1.loc[:,'sacral_slope']).reshape(-1,1)\npolynomial_features= PolynomialFeatures(degree=degree)\nx_poly = polynomial_features.fit_transform(x)\n\nmodel = LinearRegression()\nmodel.fit(x_poly, y)\ny_poly_pred = model.predict(x_poly)\n\nrmse = sqrt(mean_squared_error(y,y_poly_pred))\nr2 = r2_score(y,y_poly_pred)\n\n\n# tabel parameter\ntabel_parameter = PrettyTable(['parameter', 'nilai'])\ntabel_parameter.add_row(['Polynomial\\nDegree', degree])\ntabel_parameter.add_row(['RMSE','{:.10}'.format(rmse)])\ntabel_parameter.add_row(['R^2', '{:.10}'.format(r2)])\n\n# Plot regression line and scatter\nplt.plot(predict_space, predicted, color='black', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.title('Biomechanical features of orthopedic patients\\n')\nplt.xlabel('pelvic_incidence')\nplt.ylabel('sacral_slope')\nplt.show()\nprint(tabel_parameter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_equation(model):\n    for coef in model.coef_:\n        pass\n    streq = \"$y = \" +str(model.intercept_[0])\n    for i,c in enumerate(coef):\n        j = len(coef)-i-1\n        if abs(c) > c:\n            sign = \"-\"\n        else:\n            sign = \"+\"\n        if i > 1:\n            streq += sign +str(abs(c)) + \" \\cdot x^{\"+str(i)+\"}\"\n        elif i == 1:\n            streq += sign +str(abs(c)) + \" \\cdot x\"\n\n    streq =   streq + \"$\"\n    return md(streq)\ndisplay_equation(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Polynomial Regression (Degree = 10)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Polynomial\ndegree = 10\n\nx = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\ny = np.array(data1.loc[:,'sacral_slope']).reshape(-1,1)\npolynomial_features= PolynomialFeatures(degree=degree)\nx_poly = polynomial_features.fit_transform(x)\n\nmodel = LinearRegression()\nmodel.fit(x_poly, y)\ny_poly_pred = model.predict(x_poly)\n\nrmse = sqrt(mean_squared_error(y,y_poly_pred))\nr2 = r2_score(y,y_poly_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tabel parameter\ntabel_parameter = PrettyTable(['parameter', 'nilai'])\ntabel_parameter.add_row(['Polynomial\\nDegree', degree])\ntabel_parameter.add_row(['RMSE','{:.10}'.format(rmse)])\ntabel_parameter.add_row(['R^2', '{:.10}'.format(r2)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x, y, s=10)\nsort_axis = operator.itemgetter(0)\nsorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\nx, y_poly_pred = zip(*sorted_zip)\nplt.title('Biomechanical features of orthopedic patients\\n')\nplt.xlabel('\\npelvic_incidence')\nplt.ylabel('sacral_slope')\n\nplt.plot(x, y_poly_pred, color='m')\nplt.show()\nprint(tabel_parameter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_equation(model):\n    for coef in model.coef_:\n        pass\n    streq = \"$y = \" +str(model.intercept_[0])\n    for i,c in enumerate(coef):\n        j = len(coef)-i-1\n        if abs(c) > c:\n            sign = \"-\"\n        else:\n            sign = \"+\"\n        if i > 1:\n            streq += sign +str(abs(c)) + \" \\cdot x^{\"+str(i)+\"}\"\n        elif i == 1:\n            streq += sign +str(abs(c)) + \" \\cdot x\"\n\n    streq =   streq + \"$\"\n    return md(streq)\ndisplay_equation(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KMEANS CLUSTERING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data\ndata = pd.read_csv('../input/vertebralcolumndataset/column_2C.csv')\n# get_dummies\ndf = pd.get_dummies(data)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop one of the feature\ndf.drop(\"class_Normal\",axis = 1, inplace = True) \ndf.head(10)\n# instead of two steps we can make it with one step pd.get_dummies(data,drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df\n\ny = df['class_Abnormal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nX['class_Abnormal'] = le.fit_transform(X['class_Abnormal'])\n\ny = le.transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nms = MinMaxScaler()\n\nX = ms.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(X, columns=[cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\n\nfrom yellowbrick.cluster import KElbowVisualizer\n\n# Generate synthetic dataset with 3 random clusters\nX, y = make_blobs(n_samples=310, n_features=10, centers=3, random_state=0)\n\n# Instantiate the clustering model and visualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(model, k=(1,11))\n\nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see there is no labels in data\nplt.scatter(data['pelvic_radius'],data['degree_spondylolisthesis'])\nplt.xlabel('pelvic_radius')\nplt.ylabel('degree_spondylolisthesis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K = 2\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=2,random_state=0)\n\nkmeans.fit(X)\n\nlabels = kmeans.labels_\n\n# check how many of the samples were correctly labeled\n\ncorrect_labels = sum(y == labels)\n\nprint(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, y.size))\n\nprint('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# k = 2 (sembarang)\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=2, random_state=0) \n\nkmeans.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.inertia_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K = 3\nkmeans = KMeans(n_clusters=3, random_state=0)\n\nkmeans.fit(X)\n\n# check how many of the samples were correctly labeled\nlabels = kmeans.labels_\n\ncorrect_labels = sum(y == labels)\nprint(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, y.size))\nprint('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#k = 3 (OPTIMAL)\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=3, random_state=0) \n\nkmeans.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.inertia_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#k = 2\nfrom sklearn.datasets.samples_generator import make_blobs\nX, y_true = make_blobs(n_samples=300, centers=2,cluster_std=0.60, shuffle=True, random_state=0)\nplt.scatter(X[:, 0], X[:, 1], edgecolor='blue', s=50);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkm = KMeans(\n    n_clusters=2, init='random',\n    n_init=10, max_iter=300, \n    tol=1e-04, random_state=0\n)\ny_km = km.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the 2 clusters\nplt.scatter(\n    X[y_km == 0, 0], X[y_km == 0, 1],\n    s=50, c='lightgreen',\n    marker='s', edgecolor='black',\n    label='cluster 1'\n)\n\nplt.scatter(\n    X[y_km == 1, 0], X[y_km == 1, 1],\n    s=50, c='orange',\n    marker='o', edgecolor='black',\n    label='cluster 2'\n)\n\n# plot the centroids\nplt.scatter(\n    km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n    s=250, marker='*',\n    c='red', edgecolor='black',\n    label='centroids'\n)\nplt.legend(scatterpoints=1)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K = 3\nfrom sklearn.datasets.samples_generator import make_blobs\nX, y_true = make_blobs(n_samples=300, centers=3,cluster_std=0.60, shuffle=True, random_state=0)\nplt.scatter(X[:, 0], X[:, 1], edgecolor='blue', s=50);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkm = KMeans(\n    n_clusters=3, init='random',\n    n_init=10, max_iter=300, \n    tol=1e-04, random_state=0\n)\ny_km = km.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the 3 clusters\nplt.scatter(\n    X[y_km == 0, 0], X[y_km == 0, 1],\n    s=50, c='lightgreen',\n    marker='s', edgecolor='black',\n    label='cluster 1'\n)\n\nplt.scatter(\n    X[y_km == 1, 0], X[y_km == 1, 1],\n    s=50, c='orange',\n    marker='o', edgecolor='black',\n    label='cluster 2'\n)\n\nplt.scatter(\n    X[y_km == 2, 0], X[y_km == 2, 1],\n    s=50, c='lightblue',\n    marker='v', edgecolor='black',\n    label='cluster 3'\n)\n\n\n# plot the centroids\nplt.scatter(\n    km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n    s=250, marker='*',\n    c='red', edgecolor='black',\n    label='centroids'\n)\nplt.legend(scatterpoints=1)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Silhouette Plot of KMeans"},{"metadata":{"trusted":true},"cell_type":"code","source":"#K = 2 (sembarang) \nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom sklearn.cluster import KMeans\nmodel = SilhouetteVisualizer(KMeans(n_clusters=2))\nmodel.fit(X)\nmodel.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K= 3 (OPTIMAL)\nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom sklearn.cluster import KMeans\nmodel = SilhouetteVisualizer(KMeans(n_clusters=3))\nmodel.fit(X)\nmodel.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import silhouette_samples, silhouette_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 2\n# Initialize the clusterer with n_clusters value and a random generator\n# seed of 10 for reproducibility.\nclusterer = KMeans(n_clusters=n_clusters, random_state=10)\ncluster_labels = clusterer.fit_predict(X)\n# clusters\nsilhouette_avg = silhouette_score(X, cluster_labels)\nprint(\"For n_clusters =\", n_clusters,\n      \"The average silhouette_score is :\", silhouette_avg)\n# Compute the silhouette scores for each sample\nsample_silhouette_values = silhouette_samples(X, cluster_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 3\n# Initialize the clusterer with n_clusters value and a random generator\n# seed of 10 for reproducibility.\nclusterer = KMeans(n_clusters=n_clusters, random_state=10)\ncluster_labels = clusterer.fit_predict(X)\n# clusters\nsilhouette_avg = silhouette_score(X, cluster_labels)\nprint(\"For n_clusters =\", n_clusters,\n      \"The average silhouette_score is :\", silhouette_avg)\n# Compute the silhouette scores for each sample\nsample_silhouette_values = silhouette_samples(X, cluster_labels)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}