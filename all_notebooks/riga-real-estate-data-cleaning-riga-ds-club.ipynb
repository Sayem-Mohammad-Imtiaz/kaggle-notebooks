{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Riga](https://cdn.getyourguide.com/img/tour_img-1814782-148.jpg)\n# Introduction\n[Riga](https://en.wikipedia.org/wiki/Riga) is a lovely city near the Baltic Sea, the capital of Latvia. \n\n\nThis kernel is written by Riga Data Science Club - an international community of data scientists based in Riga and Slack 😃\nWe will be happy to accept people from all over the world to join our friendly chat. It is totally free. Please sign up here: [http://rigadsclub.com/join-us/](http://rigadsclub.com/join-us/)\n\nYours,\nRiga DS Club"},{"metadata":{},"cell_type":"markdown","source":"# Data exploration\nFirst, let's load our dataset and get familiar with it by printing out several rows:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/riga-real-estate-dataset/riga_re.csv')\n# Printing top 5 rows\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking total amount of rows in given dataset\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the **op_type** column. This abbreviation stands for \"operation type\". Values of this column might have huge impact on our further work, since sale price is much different from the rent price for any object."},{"metadata":{},"cell_type":"markdown","source":"Let's check if there are any other operation types in this column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing out unique values of a column\ndf.op_type.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping by operation type and getting statistics within groups\ndf_by_op_type = df.groupby('op_type')\ndf_by_op_type.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you see, there are also other values like \"Buying\", \"Renting\", \"Change\" and \"Other\". Before continuing, let's do the following:\n1. Drop entries with operations \"Change\", \"Other\" as irrelevant to our goal - price prediction\n2. Drop entries with operations \"Buying\" and \"Renting\" as they are presented with very few samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt = df[~df['op_type'].isin(['Change', 'Other', 'Buying', 'Renting'])]\nlen(df_filt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we could pay attention to **district** column. Let's explore unique districts first:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.district.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's inspect unique values of other columns as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['floor', 'total_floors']:\n    print(col, \":\", sorted(df_filt[col].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Floor values look fine."},{"metadata":{"trusted":true},"cell_type":"code","source":" for col in ['house_seria', 'house_type', 'condition']:\n    print(col, \":\", df_filt[col].unique())\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One not coming from the eastern europe might be confused by the **house_seria** values, but believe us - they are fine. Despite Riga being the city with the highest concentration of [Art Nouveau architecture](https://en.wikipedia.org/wiki/Art_Nouveau_architecture_in_Riga) anywhere in the world, there are also many standardized apartment blocks constructed in the [Soviet period](https://en.wikipedia.org/wiki/Urban_planning_in_communist_countries), so **602**, **119**, **103.**, **467.**, **104.** are just weird names of construction projects. We will treat them as ordinary categorical values.\n"},{"metadata":{},"cell_type":"markdown","source":"Now let's check how our items look on the map:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nviz=df_filt.plot(kind='scatter', x='lon', y='lat', alpha=0.4, figsize=(10,10))\nviz.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The latitude of Rīga, Latvia is 56.946285, and the longitude is 24.105078. While some of the values seem to be within a correct range, there are broken values, that make plot look terribly zoomed out. Let's check how many samples have wrong coordinates. Previous plot allows us to assume all broken values deviate too much from real Riga coordinates, so we can use rough comparison to filter them out."},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong = df_filt[(df_filt['lat'] < 55)|(df_filt['lat'] > 58)|(df_filt['lon'] < 24)|(df_filt['lon'] > 25)]\nlen(wrong)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not so many to worry about, let's just drop them and see how plot looks without broken values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt = df_filt[~((df_filt['lat'] < 55)|(df_filt['lat'] > 58)|(df_filt['lon'] < 24)|(df_filt['lon']>25))]\nviz=df_filt.plot(kind='scatter', x='lon', y='lat', alpha=0.4, figsize=(10,10))\nviz.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Much better! All items are now concentrated within a single location matching Riga coordinates. Let's see them overlaying actual Riga map:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\n# Define helper function to plot over Riga map\ndef plot_on_riga_map(data_frame): \n    riga_map = folium.Map(\n        location=[56.946285, 24.105078],\n        tiles='cartodbpositron',\n        zoom_start=12,\n    )\n    data_frame.apply(lambda row:folium.Marker(location=[row[\"lat\"], row[\"lon\"]]).add_to(riga_map), axis=1)\n    return riga_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_on_riga_map(df_filt[~df_filt['lon'].isna()].head(500))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling missing values\n"},{"metadata":{},"cell_type":"markdown","source":"Let's define a helper function to get missing values for a dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing(df):\n    df_missing = pd.DataFrame(df.isna().sum().sort_values(ascending = False), columns = ['missing_count'])\n    df_missing['missing_share'] = df_missing.missing_count / len(df)\n    return df_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing(df_filt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing geo coordinates\nWe see most missing values come from geo coordinate columns - **lon** and **lat**. Let's fix them using geocoding utility."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look at some samples with missing coordinates\ndf_filt.loc[df_filt['lon'].isna()].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To find missing geo coordinates we could potentially use **street** column which in fact is address of the building, however it seems to contain some abbreviations that might not be understood by geocoding utility. Let's check."},{"metadata":{"trusted":true},"cell_type":"code","source":"from geopandas.tools import geocode\ndef geocode_safely(address):\n    try: \n        return geocode(address, provider=\"nominatim\").geometry.iloc[0]\n    except: \n        return 'Not found'\n   \n\nprint(\"1.\", geocode_safely('Viestura pr. 47'))\nprint(\"2.\", geocode_safely('Viestura prospekts 47'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The assumption was correct. Abbreviation of the street is not found by geocoder, while full value is processed correctly. We might need to find a way to deal with this."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect all street names of samples without geo coordinates to find abbreviation patterns\ndf_filt.loc[df_filt['lon'].isna(), 'street'].tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fixing all different kinds of street name abbreviations seems to be a feature engineering task. Let us know if you wish to write a separate LSTM model to handle this 😃"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Constructing dictionary mappings from abbreviations to full values\nabbrs = {\n  \"Asteres\": \"Aisteres iela\",\n  \"M. Kuldīgas\": \"Mazā Kuldīgas iela\",\n  \"M. Nometņu\": \"Mazā Nometņu iela\",\n  \"Pulkv. Brieža\": \"Pulkveža brieža iela\",\n  \"J. Vācieša\": \"Jukuma Vācieša iela\",\n  \"J. Daliņa\": \"Jāņa Daliņa iela\",\n  \"pr.\": \"prospekts\",\n  \"l.\": \"līnija\",\n  \"š.\" : \"šoseja\",\n  \"d.\": \"dambis\",\n  \"g.\": \"gatve\",\n  \"lauk.\": \"laukums\",\n  \"bulv.\": \"bulvāris\",\n  \"krastm.\": \"krastmala\",\n  \"šķ līnija\": \"šķērslīnija\",\n  \"šķ. līnija\": \"šķērslīnija\",\n  \"M.\": \"mazais\",  \n  \"432k1\": \"432-k-1\",\n  \"252k5\": \"252-k-5\"\n}\n# Defining helper method to unabbreviate address\ndef unabbreviate(address):\n    # 1. Replace abbreviations\n    for abbr, full in abbrs.items():\n        address = address.replace(abbr, full)\n     \n    streetTypes = list(abbrs.values())\n    # 2. If address does not contain word \"street\" (\"iela\" in Latvian) and none of manually abbreviated values\n    # -> add \"iela\" as a second word in address\n    if (\"iela\" not in address) & (not any(s in address for s in streetTypes)):\n        words = address.split(\" \")\n        words.insert(1,\"iela\")\n        address = \" \".join(words)\n    # 3. Finally, append \"Rīga\" at the end of address if not present\n    if \"Rīga\" not in address:\n        address += \", Rīga\"\n    return address\n    \ndf_filt.loc[df_filt['lon'].isna(), 'street'] = df_filt.loc[df_filt['lon'].isna()].street.apply(unabbreviate)\ndf_filt.loc[df_filt['lon'].isna(), 'street'].tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks good. Let's move to geocoding."},{"metadata":{"trusted":true},"cell_type":"code","source":"from geopandas.tools import geocode\nfrom geopy.extra.rate_limiter import RateLimiter\n\n# Delay between geocode calls to prevent it from failures\ngeocode = RateLimiter(geocode, min_delay_seconds=1)\n\ndef get_lat_lon(address):\n    try:\n        point = geocode(address, provider='nominatim').geometry.iloc[0]\n        return pd.Series({'lat': point.y, 'lon': point.x})\n    except:\n        return pd.Series({'lat': None, 'lon': None})\n\n# Running this will take roughly 3 minutes due to artificial delay between geocode calls\ndf_filt.loc[df_filt['lon'].isna(), ['lat','lon']] = df_filt.loc[df_filt['lon'].isna()].street.apply(get_lat_lon)\nlen(df_filt.loc[df_filt['lon'].isna()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All right. We have fixed most geo coordinates - just 1 address hasn't been geolocated. Let's review it manually:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt['lon'].isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check this address on the [Google Maps](https://www.google.com/maps/place/Lauvu+iela+22,+Ber%C4%A3i,+Garkalnes+novads,+LV-1024/@56.9855,24.3108859,14z/data=!4m5!3m4!1s0x46eecc767c49e4f1:0x2ac3e039274560b6!8m2!3d56.995796!4d24.3074993). It turns out it is located in Berģi, out of Riga borders, so our \"Rīga\" postfix in fact made geolocation fail for this particular item. Taking into account the property is located out of Riga, we will drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt = df_filt[df_filt.street != 'Lauvu iela 22, Rīga']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's verify all geo coordinates are corrected and review remaining missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing(df_filt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing districts\nLet's take a look at the entries with missing district value:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt['district'].isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One can find out missing district names by looking at rows with the same street:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt.street.str.startswith('Ogļu')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! There are multiple properties listed at the same address - Ogļu 32. Let's impute missing value:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt.street == 'Ogļu 32', 'district'] = 'Ķīpsala'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try doing the same for **Pupuku iela 9**:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt.street.str.startswith('Pupuku')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No luck this time - this is the only property on the **Pupuku** street in our dataset. We might use alternative approach to seach nearest points within some range using **lat** **lon** column values, but it would be overkill for a single row. Let's impute district manually by finding **Pupuku iela 9** on [Google Maps](https://www.google.com/maps/place/Pupu%C4%B7u+iela+9,+Zemgales+priek%C5%A1pils%C4%93ta,+R%C4%ABga,+LV-1076/@56.9051591,24.1411307,17z/data=!3m1!4b1!4m5!3m4!1s0x46eed191e0607163:0xb7e8552585e17c39!8m2!3d56.9051591!4d24.1433194):"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt.street == 'Pupuku iela 9', 'district'] = 'Valdlauči'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once again, let's review what else is missing:"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing(df_filt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Invalid or missing Rooms\nJust **one** row without **rooms** value. This might be easy! ..not so fast, before doing this, let's check unique room values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.rooms.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" It turns out this column is categorical due to the presence of value \"Citi\". This is bad, as room count by nature is numerical and might be important input for correct price prediction in our model. So what does this \"Citi\" really mean for **rooms**? \"Citi\" translates from Latvian as \"Other\". In our context this word might describe some special architectural solutions, where room count can't be clearly defined. "},{"metadata":{},"cell_type":"markdown","source":"For the sake of data integrity let's treat \"Citi\" the same way as missing value:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt['rooms'] == 'Citi', 'rooms'] = None\ndf_filt.loc[df_filt['rooms'].isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 15 rows to fix instead of 1. In order to do this correctly, we could take advantage of other samples with the similar area. Let's build a helper functions to approximate room count. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter out only valid rows with rooms\ndf_with_rooms = df_filt.loc[~df_filt['rooms'].isna()]\n# Calculate average dataset room area\naverage_room_area = (df_with_rooms['area']/df_with_rooms['rooms'].astype('int64')).mean()\naverage_room_area","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n# Very rough room count estimation using average dataset room area\ndef estimate_room_count_rough(area):\n    return np.ceil(area / average_room_area)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delicate estimation: finding out room count that occurs most among dataset samples of similar area\n# If no samples found of a similar area, fallback to rough estimation\ndef estimate_room_count(area, delta = 10):\n    # Defining lower and upper bounds to find similar area\n    area_lo = area - delta\n    area_up = area + delta\n    try:\n        df_similar_by_area = df_with_rooms[(df_with_rooms['area'] > area_lo) & (df_with_rooms['area'] < area_up)]\n        room_values = df_similar_by_area[\"rooms\"].values.flatten()\n        return pd.value_counts(room_values).idxmax()\n    except:\n        return estimate_room_count_rough(area)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputing helper, that sets most probable rooms value\ndef impute_most_probable_room_value(index):\n    df_filt.loc[index, 'rooms'] = estimate_room_count(df_filt.loc[index].area)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are ready!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fix missing rooms by imputing most probable room values\ndf_filt.loc[df_filt['rooms'].isna()].apply(lambda row: impute_most_probable_room_value(row.name), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.loc[df_filt['rooms'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change column type\ndf_filt.rooms= df_filt.rooms.astype('int64')\n\n# Verify\ndf_filt.rooms.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Room column now is numeric and contains no missing values. "},{"metadata":{},"cell_type":"markdown","source":"Final check:"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing(df_filt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are done! Now it's time to save corrected dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_filt.to_csv('riga.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}