{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Ouverture du dataframe TITANIC\ndf = pd.read_csv('../input/titanic/train_and_test2.csv')\npd.set_option('display.max_columns', None)\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rapide analyse des différentes varialbes et de la target (2urvived ici, ) : remarque tout de suite que toutes les variables zero sont inutiles et devront être retiré\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analyses des différentes variables, tous des float ou des int ==> variables déjà encodé et sont propice à l'utilitsation d'un algorythme de machine learning\ndf.dtypes.value_counts().plot.pie()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyse des valeurs manquantes : très peu de valeur manquante, un dropna pour retirer les valeurs manquantes est une bonne idéee vu qu'il y en a peu\nplt.figure(figsize=(20,10))\nsns.heatmap(df.isna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#supprime les variables inutiles\ndf = df.drop(df.columns[5:12], axis = 1)\ndf = df.drop(df.columns[6:13], axis = 1)\ndf = df.drop(['zero.14','zero.15','zero.16','zero.17','zero.18','Passengerid'], axis = 1)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualisation de la target : 75% morts et 25% survivant environ ==> problème de manque de donnée pour le train set. En effet celui possède 50% survivant et 50% morts. \nplt.hist(df['2urvived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Création du dataframe train et visualisation (df_viz)\ndf_alive = df[df['2urvived']==1].copy()\ndf_dead = df[df['2urvived']==0][:len(df_alive)].copy()\ndf_viz = pd.concat([df_alive,df_dead])\n\npd.set_option('display.max_rows', None, 'display.max_columns', None)\ndf_viz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#étude des répartitions de variables selon la target dans le dataframe train. Le sex, la classe, le coût semble avoir un bon impact avec un peu l'age en plus\nfor col in df.columns:\n    plt.figure()\n    plt.hist([df_alive[col],df_dead[col]], label=['alive','dead'])\n    plt.title(col)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#même analyse mais cette fois ci dans le dataframe entier. On arrive aux même conclusion ==> Dataframe train est une bonne représentation de la réalité\nfor coll in df.columns:\n    g = sns.FacetGrid(df,col='2urvived')\n    g.map(plt.hist, coll, bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# matrice de correlation  montre de bonne correlation entre la target avec le sex (40%) la classe (-24%) le cou^t (17%) toutefois les correlations sont mauvaises avec le reste.\n# Une idée est donc de tenter d'ameliorer la correlation pour ameliorer le modèle\nf, ax2 = plt.subplots(1, 1, figsize=(20,10))\nsub_sample_corr = df.corr()\nsns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2,annot = True)\nax2.set_title('matrice correlation', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definition de la fonction évaluation avec une matrice de confusion, les scores ainsi que la courbe d'apprentissage.\ndf_alive = df[df['2urvived']==1].copy()\ndf_dead = df[df['2urvived']==0][:len(df_alive)].copy()\ndf_viz = pd.concat([df_alive,df_dead])\npd.set_option('display.max_rows', None, 'display.max_columns', None)\n\n\ndf_viz=df_viz.dropna()\ndf_viz=df_viz.reset_index().drop(['index'],1)\ny= df_viz['2urvived']\nX = df_viz.drop(['2urvived'],axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=0)\nclf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n\ndef evaluation(model):\n    model.fit(X_train,y_train)\n    ypred=model.predict(X_test)\n    print(confusion_matrix(y_test,ypred))\n    print(classification_report(y_test,ypred))\n    N, train_score, val_score = learning_curve(model,X_train, y_train, cv=4,scoring= 'f1',train_sizes=np.linspace(0.1,1,10))\n    plt.figure(figsize=(10,5))\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, val_score.mean(axis=1), label='train score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Premier model test simple, résultat satisfaisant cepandant il y a un gros gap entre nos deux courbes dans le graphique des courbes d'apprentissage\nmodel = DecisionTreeClassifier(random_state=0)\nevaluation(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Répartition du poids des variables par de l'algorythme utilisé\npd.DataFrame(model.feature_importances_, index= X_train.columns).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Etape Pre-processing : Objectif : catégorisé l'âge pour regrouper plus de donnée\nfor i in range(len(df_viz)): \n    if df_viz['Age'][i]<= 5:\n        df_viz['Age'][i]= 0\n    if df_viz['Age'][i]> 5 and df_viz['Age'][i]<= 10:\n        df_viz['Age'][i]= 1\n    if df_viz['Age'][i]> 10 and df_viz['Age'][i]<= 15:\n        df_viz['Age'][i]= 2\n    if df_viz['Age'][i]> 15 and df_viz['Age'][i]<= 20:\n        df_viz['Age'][i]= 3\n    if df_viz['Age'][i]> 20 and df_viz['Age'][i]<= 25:\n        df_viz['Age'][i]= 4\n    if df_viz['Age'][i]> 25 and df_viz['Age'][i]<= 27:\n        df_viz['Age'][i]= 5\n    if df_viz['Age'][i]> 27 and df_viz['Age'][i]<= 28:\n        df_viz['Age'][i]= 6\n    if df_viz['Age'][i]> 28 and df_viz['Age'][i]<= 35:\n        df_viz['Age'][i]= 7\n    if df_viz['Age'][i]> 35 and df_viz['Age'][i]<= 45:\n        df_viz['Age'][i]= 8\n    if df_viz['Age'][i]> 45 and df_viz['Age'][i]<= 55:\n        df_viz['Age'][i]= 9\n    if df_viz['Age'][i]> 55 and df_viz['Age'][i]<= 65:\n        df_viz['Age'][i]= 10\n    if df_viz['Age'][i]> 65 :\n        df_viz['Age'][i]= 11\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test avec l'âge modifié, résultat : meilleur résultat, on garde cette opération\ny= df_viz['2urvived']\nX = df_viz.drop(['2urvived'],axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=0)\nclf = KNeighborsClassifier(n_neighbors=5, weights='distance')\nevaluation(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## on fait de même mais pour le coût :\n#for i in range(len(df_viz)): \n #   if df_viz['Fare'][i]<= 10:\n #       df_viz['Fare'][i]= 0\n #   if df_viz['Fare'][i]> 10 and df_viz['Fare'][i]<= 20:\n#        df_viz['Fare'][i]= 1\n#    if df_viz['Fare'][i]> 20 and df_viz['Fare'][i]<= 30:\n#        df_viz['Fare'][i]= 2\n#    if df_viz['Fare'][i]> 30 and df_viz['Fare'][i]<= 50:\n#        df_viz['Fare'][i]= 3\n#    if df_viz['Fare'][i]> 50 and df_viz['Fare'][i]<= 70:\n#        df_viz['Fare'][i]= 4\n#    if df_viz['Fare'][i]> 70 and df_viz['Fare'][i]<= 100:\n#        df_viz['Fare'][i]= 5\n#    if df_viz['Fare'][i]> 100 and df_viz['Fare'][i]<= 150:\n#        df_viz['Fare'][i]= 6\n#    if df_viz['Fare'][i]> 150 and df_viz['Fare'][i]<= 200:\n#        df_viz['Fare'][i]= 7\n#    if df_viz['Fare'][i]> 200 and df_viz['Fare'][i]<= 250:\n#        df_viz['Fare'][i]= 8\n#    if df_viz['Fare'][i]> 250 and df_viz['Fare'][i]<= 350:\n#        df_viz['Fare'][i]= 9\n#    if df_viz['Fare'][i]> 350 and df_viz['Fare'][i]<= 450:\n#        df_viz['Fare'][i]= 10\n#    if df_viz['Fare'][i]> 450 :\n# #       df_viz['Fare'][i]= 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#résultat : catégoriser le coût nous fait obtenir de moins bon résultat. On supprime cette idée\n#y= df_viz['2urvived']\n##X = df_viz.drop(['2urvived'],axis=1)\n###X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n####model = make_pipeline(SelectKBest(f_classif, k=6), DecisionTreeClassifier(random_state=0))\n#####evaluation(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test plein d'algorythme différent pour choisir le meilleur\n#Résultat : RandomForest possède les meilleurs résultat mais AdaBoostClassifier possède la meilleur courbe d'apprentissage (gap très léger).\n# Les deux modèles seront donc étudier et nous allons en retenir le meilleur.\npreprocessor = make_pipeline(SelectKBest(f_classif, k=6))\nRandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\nDecisionTree = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=0))\nAdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\nSVM = make_pipeline(preprocessor,StandardScaler(), SVC(random_state=0))\nKNN = make_pipeline(preprocessor, StandardScaler(),  KNeighborsClassifier())\n\nDictionaireModel = {\n    'RandomForest':RandomForest, 'DecisionTree':DecisionTree, 'AdaBoost':AdaBoost, 'SVM':SVM,'KNN':KNN\n}\nListeModel = [RandomForest,DecisionTree,AdaBoost,SVM,KNN]\n\nfor nom,model in DictionaireModel.items():\n    print(nom)\n    evaluation(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0, n_estimators =110, criterion=\"gini\",max_leaf_nodes =40))\nevaluation(RandomForest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0,n_estimators =110,algorithm=\"SAMME.R\"))\nevaluation(AdaBoost)\n\n# Comparaison des deux modèle :\n# La courbe d'apprentissage de l'adaboost est meilleur que celle du randomForest\n# Les résultat du randomForest sont bien supérieur à ceux de l'adaboost. Il convient donc de choisir le randomForest\n\n# Résultat : score = 81%, précision mort = 73%, précision survivant = 93%, recall mort = 94%, recall survivant = 70% ==> score f1 mort = 82% et score f1 survivant =80%","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}