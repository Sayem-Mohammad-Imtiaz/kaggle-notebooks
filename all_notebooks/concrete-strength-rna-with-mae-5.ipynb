{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Concrete Strength Prediction\n\nDownloaded from https://www.kaggle.com/prathamtripathi/regression-with-neural-networking\n\nGoal: Predict the concrete strength of multiple types of concrete with neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error as mae\n\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Wrangling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/regression-with-neural-networking/concrete_data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data set has no null data."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\nheatmap = sns.heatmap(df.corr(), vmin=-1,vmax=1, annot=True, cmap='viridis')\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that Strength, our target, is deeply correlated to Cement (type), Superplasticizer and Age.\n\nAnyway, Neural Networks are capable to take all components at once and weight them properly so we are not taking any PCA or similar.\n\nIn the other hand, in order to make work easier for the neural netwrok we need to normalize all variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0,1))\nTarget = df.Strength\nPredictors = df.drop(columns=['Strength'])\npred_norm = pd.DataFrame(scaler.fit_transform(Predictors), columns=df.columns.values.tolist()[0:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_norm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr, X_ts, Y_tr, Y_ts = train_test_split(pred_norm, Target, test_size=0.1, shuffle=True, random_state=42)\nX_val, X_ts, Y_val, Y_ts = train_test_split(X_ts, Y_ts, test_size=0.5, shuffle=True,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network Regression model"},{"metadata":{},"cell_type":"markdown","source":"## Architecture : Bottleneck RNA"},{"metadata":{"trusted":true},"cell_type":"code","source":"NNR = models.Sequential()\n\nNNR.add(layers.Dense(300, activation='relu', input_shape = (pred_norm.shape[1],)))\nNNR.add(layers.Dense(150, activation = 'relu'))\nNNR.add(layers.Dense(50, activation = 'relu'))\nNNR.add(layers.Dense(150, activation = 'relu'))\nNNR.add(layers.Dense(300, activation = 'relu'))\nNNR.add(layers.Dense(1))\n\nNNR.compile(loss='mae',\n           optimizer='adam',\n           metrics = 'mae')\nNNR.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"es = EarlyStopping(monitor = 'val_loss', mode='min',patience=5, verbose=1)\n\nhNNR= NNR.fit(X_tr,Y_tr,\n             epochs=100,\n             validation_data=(X_val,Y_val),\n             callbacks=[es])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nwith plt.style.context('fivethirtyeight'):\n\n    sns.lineplot(x=np.arange(0,len(hNNR.history['mae'])),y=hNNR.history['mae'])\n    sns.lineplot(x=np.arange(0,len(hNNR.history['mae'])),y=hNNR.history['val_mae'])\n\n    plt.legend(['Train','Validation'], loc='upper right')\n    plt.xlabel('epochs')\n    plt.ylabel('MAE')\n    plt.title('Evaluation\\nMean Absolute Error: {:.3f}'.format(hNNR.history['mae'][-1]))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = NNR.predict(X_ts)\n\nY_pred = np.array(Y_pred.reshape(Y_pred.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAE = mae(Y_ts,Y_pred)\n\nplt.figure(figsize=(12,8))\nwith plt.style.context('fivethirtyeight'):\n\n    plt.plot(sorted(Y_ts), label='Actual')\n    plt.plot(sorted(Y_pred), label='Predicted')\n    plt.fill_between(x=np.arange(0,len(Y_pred)),y1=sorted(Y_pred)+MAE,y2=sorted(Y_pred)-MAE, \n                     alpha=0.1, color='r', label='MAE')\n\n    plt.title('Testing prediction\\nMean Absolute Error = {:.3f}'.format(MAE))\n    plt.ylabel('Concrete Strength')\n    plt.xlabel('Item')\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you like it, don't forget to give a like.\nIf you would change or don't undertstand anything in this notebook please comment it, I will give an answer.\n\nI am just trying to build my first bottleneck RNA architecture, comment if you would use other.\n\nThanks for reading!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}