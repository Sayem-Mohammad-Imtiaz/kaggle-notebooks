{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outline\n\n1. Import libraries\n2. Read the dataframe\n3. Preprocess (missing data, categorical encoding, detecting outliers)\n4. Choose features to be clustered\n5. Simulate cluster number using dendrogram and kmeans\n6. Fit and predict cluster numbers in the dataframe\n7. Interpret the findings"},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries\nOther than numpy and pandas (have been imported on the first cell)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.cluster import AgglomerativeClustering","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read the Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_orig = pd.read_csv('/kaggle/input/clustering-data-id-gender-income-spending/ClusteringHSS.csv')\n\ndf = df_orig.copy()\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n1. Encode categorical variable\n2. Handle missing data\n3. Detect outlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.Gender_Code.value_counts(), df.Region.value_counts(), sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1\n\ndf['Gender_Code'] = df['Gender_Code'].replace({\"Female\":1,\"Male\":0})\ndf['Region']= df['Region'].replace({\"Urban\":1, \"Rural\":0})\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 fill missing data\n\ndf = df.fillna(df.mean().round(0))\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3 detect outlier\n\npd.DataFrame.boxplot(df.iloc[:,[3,4]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Choosing Features to be Clustered\n\nPerhaps we can just focus on Income and Spending as we can agree that Customer ID and Gender perhaps give less value to our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.iloc[:,2:]\nx = df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simulate Cluster Number\n1. Using Hierarchical Clustering\n2. Using KMeans"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1\n\nplt.figure(figsize=(30,10))\ndendrogram(linkage(x, method='ward'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2\n\nwscc = []\nfor i in range(1,11):\n    kmeans = KMeans(i)\n    kmeans.fit(x)\n    wscc.append(kmeans.inertia_)\n\nplt.figure(figsize=(20,10))\nplt.plot(range(1,11), wscc)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perhaps the most optimum number of clusters based on Hierarchical Clustering and KMeans is **Three Clusters**."},{"metadata":{"trusted":true},"cell_type":"code","source":"hc = AgglomerativeClustering(3)\ncluster = hc.fit_predict(x)\ndf['Cluster'] = cluster\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cluster'] = df['Cluster'].apply(lambda x: x+1)\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in df:\n    grid = sns.FacetGrid(df, col='Cluster')\n    grid.map(plt.hist, c)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}