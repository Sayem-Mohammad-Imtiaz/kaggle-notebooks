{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Car Prizes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Setting up the notebook, loading necessary libraries, defining some useful methods:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# To reduce output size while working with vscode\n%config InlineBackend.figure_format = 'png'\n\n%matplotlib inline\n\n# Display all columns\npd.options.display.max_columns = None\n\nFIGURES_PATH = \"plots/\"\n\ndef save_fig(name, extension=\"png\", resolution=300):\n    os.makedirs(FIGURES_PATH, exist_ok=True)\n    path = os.path.join(FIGURES_PATH, name + \".\" + extension)\n    # print(\"Saving figure\", name)\n    plt.tight_layout()\n    plt.savefig(path, format=extension, dpi=resolution)\n\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading data form CSV files:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"AUDI_DATASET_PATH = \"../input/used-car-dataset-ford-and-mercedes/audi.csv\"\n\naudi_orig = pd.read_csv(AUDI_DATASET_PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Audi\nPredicting Audi prices.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Having a look at data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Firstly, create a copy of the original dataframe:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"audi = audi_orig.copy()\naudi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audi.describe()","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"audi.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values, everything looks ok for now.\n\nGet the names of numerical and categorical columns:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_attribs = audi_orig.select_dtypes(\"number\").columns.to_numpy()\ncat_attribs = audi_orig.select_dtypes(\"object\").columns.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Draw histograms to better know the data.","execution_count":null},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"audi.hist(figsize=(15, 10), bins=30)\nsave_fig(\"audi_numerical_hist\")\nfor cat in cat_attribs:\n    plt.subplots(figsize=(10, 4))\n    sns.countplot(cat, data=audi, order=audi[cat].value_counts().index)\n    save_fig(f\"audi_{cat}_hist\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting into test and train data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\naudi_train, audi_test = train_test_split(audi_orig, random_state=42, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"print(\"Train:\\t\", audi_train.shape)\nprint(\"Test:\\t\", audi_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discovering data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Draw some plots about the correlation of attributes:","execution_count":null},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\n\nattribs = num_attribs\n\nscatter_matrix(audi[attribs], figsize=(12, 10))\nsave_fig(\"audi_scatter_matrix\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate Pearson correlation coefficient:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = audi[num_attribs].corr()\ncorr[\"price\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try to divide each attribute by another. Maybe some interesting correlations will appear.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"audi_corr = audi_train.copy()\n\ncolumns_search = num_attribs[num_attribs != \"price\"]\nfor i in columns_search:\n    for j in columns_search:\n        if i != j:\n            i_num = audi[columns_search].columns.get_loc(i)\n            j_num = audi[columns_search].columns.get_loc(j)\n            audi_corr[(i_num, j_num)] = audi_corr[i] / audi_corr[j]\n\ncorrelations = audi_corr.corr()[\"price\"]\ncorrelations = correlations[~correlations.index.isin(num_attribs)].abs().sort_values()\ncorrelations","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a method which add new attributes to the dataframe. It will be used later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def divided_attributes(X, min_corr=0.7):\n    new_attribs = []\n    for i, j in correlations[correlations >= min_corr].index:\n        new_attribs.append((X[:, i] / X[:, j]).reshape((-1, 1)))\n    new_attribs = np.concatenate(new_attribs, axis=1)\n    return np.concatenate((X, new_attribs), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import PolynomialFeatures, FunctionTransformer, StandardScaler, OneHotEncoder, Normalizer\nfrom sklearn.compose import ColumnTransformer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split into X and y:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = audi_train.drop(\"price\", axis=1)\nX_test = audi_test.drop(\"price\", axis=1)\ny_train = audi_train[[\"price\"]].to_numpy()\ny_test = audi_test[[\"price\"]].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_attribs = X_train.select_dtypes(\"number\").columns\ncat_attribs = X_train.select_dtypes(\"object\").columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define pipelines for data transformations:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"additional_attribs\", FunctionTransformer(divided_attributes, kw_args={\"min_corr\":0.65})),\n    (\"polynomial_attribs\", PolynomialFeatures(degree=2)),\n    (\"scaler\", StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n])\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", cat_pipeline, cat_attribs),\n])\n\nlabel_pipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform the data:","execution_count":null},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"X_train = full_pipeline.fit_transform(X_train, y_train)\nX_test = full_pipeline.transform(X_test)\n\ny_train = label_pipeline.fit_transform(y_train)\n\ny_test = label_pipeline.transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\n\ndef train_evaluate(model, X_train, y_train, X_test, y_test, cv=10):\n    model.fit(X_train, y_train)\n    scores = cross_val_score(model, X_test, y_test, cv=cv, scoring=\"neg_mean_absolute_error\")\n    print(\"Model:\\t\", model)\n    print(\"Mean MAE:\\t\", -scores.mean())\n    print(\"StD MAE:\\t\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Regression","execution_count":null},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.tree import DecisionTreeRegressor\n\ntrain_evaluate(DecisionTreeRegressor(), X_train, y_train, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"\"\"\"\n%%time\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {\"max_depth\": [12, 15, 17, 20],\n     \"splitter\": [\"random\", \"best\"],\n     \"random_state\": [42],\n     \"min_samples_split\": [3, 4, 5, 6]}\n]\n\ntree = DecisionTreeRegressor()\ngrid_search = GridSearchCV(tree, param_grid, cv=10, scoring=\"neg_mean_absolute_error\", verbose=1)\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best params:\\t\", grid_search.best_params_)\nprint(\"Best MAE:\\t\", -grid_search.best_score_)\nbest_tree = grid_search.best_estimator_\n\"\"\"\nbest_tree = DecisionTreeRegressor(max_depth=12, min_samples_split=3, splitter=\"random\", random_state=42)\ntrain_evaluate(best_tree, X_train, y_train, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regression","execution_count":null},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.ensemble import RandomForestRegressor\n\ntrain_evaluate(RandomForestRegressor(n_jobs=16), X_train, y_train.ravel(), X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"\"\"\"\n%%time\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {\"n_estimators\": [200],\n     \"random_state\": [42],\n     \"warm_start\": [True, False],\n     \"oob_score\": [True, False],\n     \"bootstrap\": [True, False],\n     \"min_samples_split\": [7, 8]}\n]\n\nforest = RandomForestRegressor()\ngrid_search = GridSearchCV(forest, param_grid, cv=10, scoring=\"neg_mean_absolute_error\", verbose=1, n_jobs=16)\ngrid_search.fit(X_train, y_train.ravel())\n\nprint(\"Best params:\\t\", grid_search.best_params_)\nprint(\"Best MAE:\\t\", -grid_search.best_score_)\nbest_forest = grid_search.best_estimator_\n\"\"\"\nbest_forest = RandomForestRegressor(bootstrap=True, min_samples_split=7, n_estimators=200, \n                                    oob_score=True, random_state=42, warm_start=True, n_jobs=16)\ntrain_evaluate(best_forest, X_train, y_train.ravel(), X_train, y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = best_forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_absolute_error\n \nfinal_r2 = r2_score(y_test, predictions)\nfinal_mae = mean_absolute_error(y_test, predictions)\n\nprint(\"Final R²:\\t\", final_r2)\nprint(\"Final MAE:\\t\", final_mae)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}