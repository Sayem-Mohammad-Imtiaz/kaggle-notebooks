{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi there and welcome to this kernel. This kernel focuses on implementation of Long-Short Term Memory Networks which come under Recurrent Neural Networks. If you're new to RNN and LSTM we request to visit:-\n\nRNN -> https://en.wikipedia.org/wiki/Recurrent_neural_network\n\nLSTM -> https://en.wikipedia.org/wiki/Long_short-term_memory\n\nFor now let's begin with loading necessary libraries which will help carrying out our tasks."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas.plotting import autocorrelation_plot as acp\nimport matplotlib.pyplot as plt\nimport plotly_express as px\n%matplotlib inline\nfrom sklearn.preprocessing import MinMaxScaler\nimport sklearn.metrics as mt\nimport math\nimport keras\nfrom keras.layers import Dense,LSTM,Dropout\nfrom keras.models import Sequential\ndf = pd.read_csv(\"../input/portland-oregon-average-monthly-.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\nOur first step is to clean the data in order to correct the data types of column(s) and removing irrelevent items from the dataframe. We can also rename the column(s) name(s) to ease their accessibility. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['Month','Avg Ridership']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While investigating we found that Average Ridership is object, instead of integer, which should be. So let's try change it, but first let's if there's any object item/element itself within the column."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Avg Ridership'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When uniquely identifying the Average Ridership column we can clearly see ' n=114' is object which needs to be removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Avg Ridership'] = df['Avg Ridership'].replace(' n=114',np.nan)\ndf = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We replace ' n=114' with NaN and simple drop it from the dataframe. Just to make sure it's correctly replaced it we uniquely identify the column again "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf['Avg Ridership'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Avg Ridership'] = pd.to_numeric(df['Avg Ridership'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now we can easily change the data type of the column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Time Series"},{"metadata":{"trusted":true},"cell_type":"code","source":"px.line(df,x='Month',y='Avg Ridership').show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graph Description:** Above is Time Series. Plotly (which is used over here) is a data visualization library build to be used for making interactive chart. Feel free to hover over the line and see the instances."},{"metadata":{},"cell_type":"markdown","source":"# LSTM forecasting\nLet's begin with the forecasting process,which involve the following preprocessing steps:-\n\n1) Setting 'Month' Column as index as it's a time series dataset\n\n2) Scaling the Average Ridership column with MinMaxScaler\n\n3) Splitting the entire dataset into Train and Test, in which Training will be used for LSTM model learning and Testing would be used to test the performance of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.set_index('Month')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = MinMaxScaler(feature_range=(0,1))\nDF = s.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train Test splitted in to 66:34 ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(len(DF) * 0.66)\ntest_size = len(DF) - train_size\ntrain, test = DF[0:train_size,:], DF[train_size:len(DF),:]\nprint(f'Training Size = {len(train)}, Testing Size = {len(test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(S, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(S)-look_back-1):\n        a = S[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(S[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look Back is the number of previous time steps to use as input variables to predict the next time period"},{"metadata":{"trusted":true},"cell_type":"code","source":"look_back = 1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Model Formation and Learning\nThe model is setup with 128 cells with look_back as 1, Dropout 0.2, with lastly with 1 single node since we're dealing with regression problem. The loss is measured through Mean Squared Error (MSE) with 'Adam' as optimizer. Validation is also performed considering the testing dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(128, input_shape=(1, look_back)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nhistory = model.fit(trainX, trainY, epochs=100, batch_size=2,validation_data=(testX,testY), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graph Description:** Training and Testing Loss as depicted by the above diagram"},{"metadata":{},"cell_type":"markdown","source":"# Measuring Model's Performance\nFor measuring model's performance, Mean Squared Error (MSE) and Root Mean Square Error (RMSE) were taken as performance measuring measures."},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPredict = model.predict([trainX])\ntestPredict = model.predict([testX])\n#Changing prediction to it's original units\ntrainPredict = s.inverse_transform(trainPredict)\ntrainY = s.inverse_transform([trainY])\ntestPredict = s.inverse_transform(testPredict)\ntestY = s.inverse_transform([testY])\n\ntrainScore = math.sqrt(mt.mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score = %.2f MSE' % mt.mean_squared_error(trainY[0],trainPredict[:,0]))\nprint('Train Score =  %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mt.mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score = %.2f MSE' % mt.mean_squared_error(testY[0],testPredict[:,0]))\nprint('Test Score = %.2f RMSE' % (testScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPredictPlot = np.empty_like(DF)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(DF)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(DF)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(s.inverse_transform(DF))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graph Description:** The Blue color represent the original series, orange represents the series generated on training dataset, and at lastly green represents the series generated on testing dataset."},{"metadata":{},"cell_type":"markdown","source":"We hope you liked this kernel and helped you understand the concept of LSTM and it's application in Time Series Forecasting."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}