{"cells":[{"metadata":{},"cell_type":"markdown","source":"# RESTAURANT RECOMMENDER SYSTEM\n\nThis data set consists of restaurants of Hyderabad/India collected from Zomato.\n\nMy aim is to create a content based recommender system in which;\n* I will write a restaurant name,\n* Recommender system will look at the reviews of other restaurants\n* System will recommend us other restaurants with similar reviews and sort them from the highest rated.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_names = pd.read_csv('../input/zomato-restaurants-hyderabad/Restaurant names and Metadata.csv')\ndata_reviews = pd.read_csv('../input/zomato-restaurants-hyderabad/Restaurant reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the data types and NaN values\ndata_names.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting the unique values\ndata_names.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the data types and NaN values\ndata_reviews.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Counting the unique values\ndata_reviews.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merging Two Data Sets\n\nI will merge these two data sets.\n\nAfter the merging I will have a data set with individual customer reviews and ratings for the restaurants.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming the restaurant name column with the same value as in the other data set:\ndata_reviews = data_reviews.rename(columns={'Restaurant': 'Name'})\n\n# Merging the two data sets:\ndf = pd.merge(data_reviews, data_names, how='left', on='Name')\n\n# Dropping the columns which I am not going to use:\ndf.drop(['Reviewer', 'Time', 'Pictures', 'Links', 'Collections'], axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Cost and Rating Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing cost and rating columns data types:\ndf['Cost'] = df['Cost'].str.replace(',', '').astype(int)\ndf['Rating'] = df['Rating'].str.replace('Like', '1').astype(float)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Nu of data inputs:', len(df))\nprint('\\nNu of NaN values for each column:\\n')\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rating column is important for recommender system. So I am not going to drop those 38 NaN values.\n\nLet's examine data with NaN rating value.  \n\nI will fill those NaN values with each restaurants' mean rating value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Examine missing Rating values:\ndf['Name'][df['Rating'].isnull() == True].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there are only two restaurants with total of 38 NaN rating values.\n\nLet's see individual restaurant's average rating value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean of Rating for American Wild Wings: ', df['Rating'][df['Name'] == 'American Wild Wings'].mean())\nprint('Mean of Rating for Arena Eleven: ', df['Rating'][df['Name'] == 'Arena Eleven'].mean())\nprint('Overall Mean of Ratings: ', df['Rating'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that mean value for missing rating value should be 4 (3,9 and 4,1 for each restaurant). \n\nLet's fill those restaurants missing rating values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Rating'].fillna(4, inplace=True)\n\n# Changing NaN reviews by '-'\ndf['Review'] = df['Review'].fillna('-')\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Separating Metadata (Reviews and Followers)\n\nI will separate review and follower numbers into different columns in order to use it later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling missing values:\ndf['Metadata'].fillna('0 Review , 0 Follower', inplace=True)\n\n# Standardizing strings\ndf['Metadata'] = df['Metadata'].str.replace('Reviews', 'Review')\ndf['Metadata'] = df['Metadata'].str.replace('Followers', 'Follower')\n\ndf['Metadata'][df['Metadata'].str.endswith('w')] = df['Metadata'][df['Metadata'].str.endswith('w')] + ' , - Follower'\n\n# Splitting into two columns\ndf[['Reviews', 'Followers']] = df['Metadata'].str.split(' , ', expand=True)\n\n# Erasing wording from the columns\ndf['Reviews'] = df['Reviews'].str.replace('Review', '')\ndf['Reviews'] = df['Reviews'].str.replace('Posts', '')\ndf['Reviews'] = df['Reviews'].str.replace('Post', '')\n\ndf['Followers'] = df['Followers'].str.replace('Follower', '')\ndf['Followers'] = df['Followers'].str.replace('-', '0')\n\n# Changing str values to integers\ndf[['Reviews', 'Followers']] = df[['Reviews', 'Followers']].astype(int)\n\n# Dropping the initial column\ndf.drop(['Metadata'], axis=1, inplace=True)\n\n# Sorting restaurants with their names and costs\ndf = df.sort_values(['Name', 'Cost'], ascending=False).reset_index()\ndf.drop('index', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating New Features (Mean of Ratings, Reviews, and Followers)\n\nRating, Review, and Followers columns represents individual customers' inputs.\n\nI am going to find the means of these values and assign them for the restaurants.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"restaurants = list(df['Name'].unique())\ndf['Mean Rating'] = 0\ndf['Mean Reviews'] = 0\ndf['Mean Followers'] = 0\n\nfor i in range(len(restaurants)):\n    df['Mean Rating'][df['Name'] == restaurants[i]] = df['Rating'][df['Name'] == restaurants[i]].mean()\n    df['Mean Reviews'][df['Name'] == restaurants[i]] = df['Reviews'][df['Name'] == restaurants[i]].mean()\n    df['Mean Followers'][df['Name'] == restaurants[i]] = df['Followers'][df['Name'] == restaurants[i]].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling\n\nI will scale the features between 1-5.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range = (1,5))\n\ndf[['Mean Rating', 'Mean Reviews', 'Mean Followers']] = scaler.fit_transform(df[['Mean Rating', 'Mean Reviews', 'Mean Followers']]).round(2)\n\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Preprocessig and Cleaning\n\nWe will be using 'Review' and 'Cuisines' feature'in order to create a recommender system.\n\nSo we need to prepare and clean the text in those columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5 examples of these columns before text processing:\ndf[['Review', 'Cuisines']].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define symbols to be replaced by space\nreplace_space = re.compile('[/(){}\\[\\]\\|@,;]')\n# Define symbols to be removed\nremove_symbols = re.compile('[^0-9a-z #+_]')\n# Define stopwords\nstopwords = set(stopwords.words('english'))\n\ndef text_preprocessing(text):\n    # Lowercase all the letters\n    text = text.lower()\n    \n    # Replace these symbols with space\n    text = replace_space.sub(' ', text)\n    \n    # Remove these symbols\n    text = remove_symbols.sub('', text)\n    \n    # Remove stopwords\n    text = ' '.join(word for word in text.split() if word not in stopwords)\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Review'] = df['Review'].apply(text_preprocessing)\ndf['Cuisines'] = df['Cuisines'].apply(text_preprocessing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns after processed:\ndf[['Review','Cuisines']].sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA - Analysing Restaurants and Popularities","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# RESTAURANT NAMES:\nrestaurant_names = list(df['Name'].unique())\nrestaurant_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_rating = df.drop_duplicates(subset='Name')\ndf_rating = df_rating.sort_values(by='Mean Rating', ascending=False).head(10)\n\nplt.figure(figsize=(7,5))\nsns.barplot(data=df_rating, x='Mean Rating', y='Name', palette='RdBu')\nplt.title('Top Rated 10 Restaurants');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews = df.drop_duplicates(subset='Name')\ndf_reviews = df_reviews.sort_values(by='Mean Reviews', ascending=False).head(10)\n\nplt.figure(figsize=(7,5))\nsns.barplot(data=df_reviews, x='Mean Reviews', y='Name', palette='RdBu')\nplt.title('Top Reviewed 10 Restaurants');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_followers = df.drop_duplicates(subset='Name')\ndf_followers = df_followers.sort_values(by='Mean Followers', ascending=False).head(10)\n\nplt.figure(figsize=(7,5))\nsns.barplot(data=df_followers, x='Mean Followers', y='Name', palette='RdBu')\nplt.title('Most Followed Top 10 Restaurants');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA - Word Frequency Distribution:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_words(column, top_nu_of_words, nu_of_word):\n    \n    vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')\n    \n    bag_of_words = vec.fit_transform(column)\n    \n    sum_words = bag_of_words.sum(axis=0)\n    \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    \n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    \n    return words_freq[:top_nu_of_words]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 20 two word frequencies for Cuisines\nlist1 = get_top_words(df['Cuisines'], 20, (2,2))\n\ndf_words1 = pd.DataFrame(list1, columns=['Word', 'Count'])\n\nplt.figure(figsize=(7,6))\nsns.barplot(data=df_words1, x='Count', y='Word')\nplt.title('Word Couple Frequency for Cuisines');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 20 two word frequencies for Reviews\nlist2 = get_top_words(df['Review'], 20, (2,2))\n\ndf_words2 = pd.DataFrame(list2, columns=['Word', 'Count'])\n\nplt.figure(figsize=(7,6))\nsns.barplot(data=df_words2, x='Count', y='Word')\nplt.title('Word Couple Frequency for Reviews');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONTENT BASE RECOMMENDER SYSTEM\n\n## TF-IDF Matrix (Term Frequency — Inverse Document Frequency Matrix)\n\nTF-IDF method is used to quantify words and compute weights for them. \n\nIn other words, representing each word (or couples of words etc.) with a number in order to use mathematics in our recommender system.\n\nCosine similarity is a metric used to determine how similar the documents are irrespective of their size.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing data set index by restaurant name\ndf.set_index('Name', inplace=True)\n\n# Saving indexes in a series\nindices = pd.Series(df.index)\n\n# Creating tf-idf matrix\ntfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\ntfidf_matrix = tfidf.fit_transform(df['Review'])\n\n# Calculating cosine similarities\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the Recommender System:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def recommend(name, cosine_similarities = cosine_similarities):\n    \n    # Create a list to put top 10 restaurants\n    recommend_restaurant = []\n    \n    # Find the index of the hotel entered\n    idx = indices[indices == name].index[0]\n    \n    # Find the restaurants with a similar cosine-sim value and order them from bigges number\n    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)\n    \n    # Extract top 30 restaurant indexes with a similar cosine-sim value\n    top30_indexes = list(score_series.iloc[0:31].index)\n    \n    # Names of the top 30 restaurants\n    for each in top30_indexes:\n        recommend_restaurant.append(list(df.index)[each])\n    \n    # Creating the new data set to show similar restaurants\n    df_new = pd.DataFrame(columns=['Cuisines', 'Mean Rating', 'Cost', 'Timings'])\n    \n    # Create the top 30 similar restaurants with some of their columns\n    for each in recommend_restaurant:\n        df_new = df_new.append(pd.DataFrame(df[['Cuisines','Mean Rating', 'Cost', 'Timings']][df.index == each].sample()))\n    \n    # Drop the same named restaurants and sort only the top 10 by the highest rating\n    df_new = df_new.drop_duplicates(subset=['Cuisines','Mean Rating', 'Cost'], keep=False)\n    df_new = df_new.sort_values(by='Mean Rating', ascending=False).head(10)\n    \n    print('TOP %s RESTAURANTS LIKE %s WITH SIMILAR REVIEWS: ' % (str(len(df_new)), name))\n    \n    return df_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing the Recommender System\n\n## 1. Example:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# HERE IS A RANDOM RESTAURANT. LET'S SEE THE DETAILS ABOUT THIS RESTAURANT:\ndf[df.index == 'Hyderabadi Daawat'].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LET'S SEE WHAT ARE WE GOING TO BE RECOMMENDED:\nrecommend('Hyderabadi Daawat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Example:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# HERE IS A BAKERY. LET'S SEE THE DETAILS ABOUT THIS RESTAURANT:\ndf[df.index == 'Labonel'].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LET'S SEE WHAT ARE WE GOING TO BE RECOMMENDED:\nrecommend('Labonel')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Example:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# HERE IS A MEDITERRANEAN / NORT INDIAN / KEBAB / BBQ RESTAURANT. LET'S SEE THE DETAILS ABOUT THIS RESTAURANT:\ndf[df.index == 'Barbeque Nation'].sample(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LET'S SEE WHAT ARE WE GOING TO BE RECOMMENDED:\nrecommend('Barbeque Nation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks for your attention and please upvote if you appreciate my work.\n\nMelih","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}