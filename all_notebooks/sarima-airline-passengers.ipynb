{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p align=\"center\">\n<img style=\"width:90%;\" src=\"https://cdn.pixabay\n.com/photo/2016/04/30/08/35/aircraft-1362586_960_720.jpg\">\n</p>\n\n[Image source](https://pixabay.com/photos/aircraft-sunset-silhouette-clouds-1362586/)\n","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"text-align: center; color:#01872A; font-size: 80px;\nbackground:#daf2e1; border-radius: 20px;\n\">Airline passengers with SARIMA</h1>\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\n\">Contents</h2>\n\n## 1.\t[EDA](#step1)\n## 2.\t[Test harness](#step2)\n## 3.\t[Choosing SARIMA parameters](#step3)\n## 4.\t[SARIMA](#step4)\n## 5.\t[SARIMA grid search](#step5)\n## 6.\t[Check residuals](#step6)\n## 7.\t[Test scoring](#step7)\n## 8.   [Summary](step8#)\n","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.gofplots import qqplot\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom itertools import product\nfrom tqdm import tqdm_notebook\nfrom matplotlib import cm\nfrom statsmodels.api import qqline\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure Matplotlib and seaborn\nplt.style.use('seaborn-muted')\nsns.set_palette(\"muted\")\nplt.rcParams['figure.figsize'] = (16,5);\nplt.rcParams['figure.facecolor'] = '#daf2e1'\nplt.rcParams['axes.facecolor'] = '#daf2e1'\nplt.rcParams['axes.grid'] = True\nplt.rcParams['lines.linewidth'] = 5\nplt.rcParams['figure.titlesize'] = 30\nplt.rcParams['axes.titlesize'] = 25\nplt.rcParams['image.cmap']=cm.tab10\nplt.rcParams['font.family'] = 'serif'\nplt.rcParams['xtick.labelsize']=14\nplt.rcParams['ytick.labelsize']=14\ncmap = cm.tab10\nblue = cmap.colors[0]\norange = cmap.colors[1]\ngreen = cmap.colors[2]","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series = pd.read_csv('../input/international-airline-passengers/international-airline-passengers.csv',\n                     index_col=0, parse_dates=True,\n                     squeeze=True, names=['Month', 'Passengers'],\n                     header=0,\n                     )\nseries = series[:-1].astype('int')\nseries.index = pd.to_datetime(series.index)\n\n# Create a pivot table for data\ndf = pd.DataFrame()\ndf['Month'] = series.index.month\ndf['Year'] = series.index.year\ndf['Date'] = series.index\ndf['Passengers'] = series.values\ndf_pivot = pd.pivot_table(df, values='Passengers', columns='Year',\n                          index='Month')","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"step1\">\n</div>\n\n<h2 style=\"padding: 10px;\n background:#daf2e1;\n  border-radius: 20px;\n text-align: center; color:#01872A;\n font-size: 40px;\">\nStep 1. EDA.</h2>","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 15))\nlayout = (5, 2)\nline_ax = plt.subplot2grid(layout, (0, 0))\nhist_ax = plt.subplot2grid(layout, (0, 1))\nseries.plot(ax=line_ax, label='Passengers', color=blue)\ndf[df['Month'].isin([7, 8])].plot(x='Date', y='Passengers', kind='scatter',\n                                  ax=line_ax, color=orange, s=200,\n                                  label='July and August peak', zorder=2)\ndf[df['Month'].isin([11])].plot(x='Date', y='Passengers', kind='scatter',\n                                  ax=line_ax, color=green, s=200,\n                                  label='November lows', zorder=2)\nline_ax.set_title('Airline passengers')\nline_ax.legend(fontsize=15)\nseries.plot(kind='hist', ax=hist_ax, zorder=10, color=blue)\nseries.plot(kind='kde', ax=hist_ax, secondary_y=True, color=orange)\nhist_ax.text(0.65, 0.42, 'Distribution is\\nnot normal',\n             transform = hist_ax.transAxes, size=20, fontweight='bold')\nhist_ax.right_ax.grid(False)\nhist_ax.grid(True, zorder=0)\nhist_ax.set_title('Histogram and KDE');\n\naxes = [plt.subplot2grid(layout, (1, 0)), plt.subplot2grid(layout, (2, 0)),\n        plt.subplot2grid(layout, (3, 0))]\n\nyears = ['1958', '1959', '1960']\ndf_pivot.loc[:, years[0]:years[-1]].plot(kind='line', subplots=True,\n                                    grid=True, color=blue,\n                                    legend=False,\n                                    title=years,\n                                    ax=axes)\ndf_pivot.loc[6:9, years[0]:years[-1]].plot(kind='line', subplots=True,\n                                      grid=True,  color=orange,\n                                      ax=axes, legend=False,\n                                      title=years)\nfor i in range(len(years)):\n    axes[i].text(0.15, 0.8, 'Summer peak', transform=axes[i].transAxes,\n                    size=20, fontweight='bold')\n# Boxplot\nboxplot_ax = plt.subplot2grid(layout, (1, 1), rowspan=3)\nsns.boxplot(x='Year', y='Passengers', linewidth=2, data=df,\n            color=blue, ax=boxplot_ax)\nboxplot_ax.text(0.15, 0.6, 'Increasing trend', transform=boxplot_ax.transAxes,\n                size=20, fontweight='bold')\nboxplot_ax.set_title('Boxplot for years')\nplt.suptitle('EDA')\nplt.tight_layout();","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 30px;\nfont-style: italic; background:#daf2e1; border-radius: 20px;\n\">Step 1 results:</h2>\n\n### 1. **Increasing trend** over years.\n### 2. **Seasonality** - with peak at summer (July and August) and very low periods - November (February).\n### 3. **Distribution is not normal** - Power Transform of data can help to improve prediction results.\n","metadata":{}},{"cell_type":"markdown","source":"<div id=\"step2\">\n</div>\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nStep 2. Test harness: Train-test split, scoring function, baseline.</h2>\n","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">Will use RMSE as a metric to punish for highly inaccurate predictions.</h3>\n$\n\\ \\huge RMSE = \\sqrt{\\frac{1}{n}\\sum\\limits_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n$","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def score_model(y_test, predictions):\n    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n    rmse = rmse.round(3)\n    return rmse","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def manual_split(series, train_size=0.6, validation_size=0.2):\n    train_size = int(len(series) * train_size)\n    validation_size = int(len(series) * validation_size)\n    train = series.iloc[:train_size]\n    validation = series.iloc[train_size:(train_size + validation_size)]\n    test = series.iloc[(train_size + validation_size):]\n    return train, validation, test","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">As a baseline will use the persistence model. Persistence model predicts the value in t+1 period to be the same as value in t period.</h3>\n$\n\\ \\huge value_{(t)} = observation_{(t-1)}\n$","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def plot_split(train, validation, test):\n    fig, ax = plt.subplots(figsize=(16, 5))\n    ax.plot(train, label='Train')\n    ax.plot(validation, label='Validation')\n    ax.plot(test, label='Test')\n    ax.axvline(max(train.index), color='black')\n    ax.axvline(max(validation.index), color='black')\n    ax.set_title('Train-test split');\n\n    ax.text(0.45, 0.1, f'Train size: {len(train)}',\n            transform = ax.transAxes, size=14, fontweight='bold')\n    ax.text(0.59, 0.1, f'Validation size: {len(validation)}',\n            transform = ax.transAxes, size=14, fontweight='bold')\n    ax.text(0.78, 0.1, f'Test size: {len(test)}',\n        transform = ax.transAxes, size=14, fontweight='bold')\n    ax.legend(prop={'size': 20});\n\ntrain, validation, test = manual_split(series)\ndataset = pd.concat([train, validation])\nplot_split(train, validation, test)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def persistence_predictions(train, test):\n    predictions = test.shift(1)\n    predictions[0] = train[-1]\n    return predictions\n\ndef plot_predictions(values, predictions, title='', ax=None):\n    score = score_model(values, predictions)\n    if ax is None:\n        fig, ax = plt.subplots()\n    ax.plot(values, label='Actual values')\n    ax.plot(predictions, label='Predictions')\n    ax.text(0.5, 1.2, f'{title}', ha=\"center\", va=\"center\",\n            transform = ax.transAxes, size=30)\n    ax.set_title(f'Score: {score}', color=orange)\n    ax.legend(prop={'size': 20})\n    plt.tight_layout();\n\nbaseline_val_preds = persistence_predictions(train, validation)\nplot_predictions(validation, baseline_val_preds, title='Persistence model '\n                                                   'predictions (baseline)')\nbaseline_val_score = score_model(validation, baseline_val_preds)\nbaseline_test_preds = persistence_predictions(dataset, test)\nbaseline_test_score = score_model(test, baseline_test_preds)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with scores\nscore_df = pd.DataFrame(columns=['ModelName', 'Source', 'Order',\n                                 'SeasonalOrder',\n                                 'ValidationScore', 'TestScore'])","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_scores(score_df, modelname, source, order=None, seasonal_order=None,\n                  validation_score=None, test_score=None):\n    if modelname not in score_df['ModelName'].values:\n        model_dict = dict()\n        model_dict['ModelName'] = modelname\n        model_dict['Source'] = source\n        model_dict['Order'] = order\n        model_dict['SeasonalOrder'] = seasonal_order\n        model_dict['ValidationScore'] = validation_score\n        model_dict['TestScore'] = test_score\n        score_df = score_df.append(model_dict, ignore_index=True)\n    return score_df\n\nscore_df = update_scores(score_df, 'Persistence', 'Baseline', order=None,\n                         seasonal_order=None,\n                         validation_score=baseline_val_score,\n                         test_score=baseline_test_score)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 30px;\nbackground:#daf2e1; border-radius: 20px;\n\">Step 2 results:</h2>\n\n### 1. **Split data** into the train, validation and test sets.\n### 2.  **Established a baseline** to check future predictions against. Baseline validation score: 38.477.\n### 3. **RMSE** will be used as a scoring metric.","metadata":{}},{"cell_type":"markdown","source":"<div id=\"step3\">\n</div>\n\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nStep 3. Choosing starting SARIMA parameters</h2>\n","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">Check if the data is stationary with Dickey-Fuller test.</h3>","metadata":{}},{"cell_type":"code","source":"def adfuller_test_results(X):\n    result = adfuller(X)\n    print(f'ADF statistic:{result[0]:.3f}')\n    print(f'p-value: {result[1]:.5f}')\n    print(f'Used lags: {result[2]}')\n    print(f'Used observations: {result[3]}')\n    print('Critical values:')\n    for key, value in result[4].items():\n        print(f'{key}: {value:.3f}')\n    print(f'Maximized information criteria: {result[5]:.3f}')\n\ndef tsplot(y, lags=None, figsize=(16, 7), title='Time series analysis',\n           important_acf=None, important_pacf=None):\n    fig = plt.figure(figsize=figsize)\n    layout = (2, 2)\n    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n    acf_ax = plt.subplot2grid(layout, (1, 0))\n    pacf_ax = plt.subplot2grid(layout, (1, 1))\n\n    y.plot(ax=ts_ax)\n    p_value = adfuller(y)[1]\n    fig.suptitle(title)\n    ts_ax.set_title(f' Dickey-Fuller: p={p_value:.5f}',\n                    color=orange)\n    plot_acf(y, lags=lags, ax=acf_ax,\n             zero=False)\n    plot_pacf(y, lags=lags, ax=pacf_ax,\n              zero=False)\n    if important_acf:\n        plot_acf(y, lags=important_acf, ax=acf_ax,\n                  vlines_kwargs={\"colors\": orange},\n                  zero=False, alpha=None)\n        acf_ax.text(0.01, 0.05, f'Important lags: {important_acf}',\n                    transform = acf_ax.transAxes, size=13, fontweight='bold',\n                    color=orange)\n    if important_pacf:\n        plot_pacf(y, lags=important_pacf, ax=pacf_ax,\n                  vlines_kwargs={\"colors\": orange},\n                  zero=False, alpha=None)\n        pacf_ax.text(0.01, 0.05, f'Important lags: {important_pacf}',\n            transform = pacf_ax.transAxes, size=13, fontweight='bold',\n            color=orange)\n    plt.tight_layout();\n\ntsplot(dataset, lags=36, important_acf=12, important_pacf=1)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cor_lags(series, n_lags=3):\n    values = pd.DataFrame(series.values)\n    dataframe = \\\n        pd.concat([values.shift(i) for i in reversed(range(1, n_lags + 1))]\n                  + [values],axis=1)\n    dataframe.columns = \\\n        ['t-' + str(i) for i in reversed(range(1, n_lags + 1))] + ['t']\n    results = dataframe.corr()\n    fig, ax = plt.subplots(figsize=(16, 7))\n    sns.heatmap(results, annot=True, ax=ax, cmap=\"YlGnBu\", cbar=False)\n    fig.suptitle('Lag correlation')\n    ax.set_title('12 month correlation', color=orange)\ncor_lags(series, n_lags=14)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">The data is not stationary, need to remove seasonality.</h3>\n\n$\n\\ \\huge value_{(t)} = observation_{(t)} - observation_{(t-12)}\n$","metadata":{}},{"cell_type":"code","source":"dataset_deseason = dataset.diff(12)[12:]\ntsplot(dataset_deseason, lags=36, title='Deseasoned time series',\n       important_acf=4, important_pacf=1)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">There are still lots of important lags in autocorrelation plot.\nNeed to calculate difference.</h3>\n$\n\\ \\huge value_{(t)} = observation_{(t)} - observation_{(t-1)}\n$","metadata":{}},{"cell_type":"code","source":"dataset_diff = dataset_deseason.diff(1)[1:]\ntsplot(dataset_diff, lags=36, title='Differenced time series',\n       important_acf=1, important_pacf=1)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 30px;\nfont-style: italic; background:#daf2e1; border-radius: 20px;\n\">Step 3 results:</h2>\n\n### 1. **Meaningful lags**: on ACF: 1 or 3, on PACF: 1\n### 2. Used **differencing** and **removed seasonality**.\n### 3. No seasonal meaningful lags left on ACF and PACF plots.\n### 4. The first model to try: **SARIMA(1, 1, 1,) (0, 1, 0, 12)**","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"<div id=\"step4\">\n</div>\n\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nStep 4. SARIMA.</h2>\n","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def sarimax_predictions(train, test, order, seasonal_order):\n    predictions = pd.Series()\n    history = [x for x in train]\n    for i in range(len(test)):\n        model = SARIMAX(history, order=order, seasonal_order=seasonal_order)\n        model_fit = model.fit(disp=0)\n        yhat = model_fit.forecast()[0]\n        predictions[test.index[i]] = yhat\n        obs = test[i]\n        history.append(obs)\n    return predictions","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order = (1, 1, 1)\nseasonal_order = (0, 1, 0, 12)\nvalidation_predictions = sarimax_predictions(train, validation, order=order,\n                                      seasonal_order=seasonal_order)\nvalidation_score = score_model(validation, validation_predictions)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">Fitting the model with previously selected parameters.</h3>\n","metadata":{}},{"cell_type":"code","source":"plot_predictions(validation, validation_predictions,\n                 title=f'SARIMA {order} {seasonal_order}')\nscore_df = update_scores(score_df, f'SARIMA {order} {seasonal_order}',\n                         'Hand selected', order=order,\n                         seasonal_order=seasonal_order, validation_score=validation_score)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 30px;\nfont-style: italic; background:#daf2e1; border-radius: 20px;\n\">Step 4 results:</h2>\n\n### 1. Manually selected model shows **decent score** and **follows data patterns**.","metadata":{}},{"cell_type":"markdown","source":"<div id=\"step5\">\n</div>\n\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nStep 5.\tSARIMA grid search.</h2>\n","metadata":{}},{"cell_type":"code","source":"# setting initial values and some bounds for them\nps = range(0, 5)\nd = 1\nqs = range(0, 5)\nPs = range(0, 2)\nD = 1\nQs = range(0, 2)\ns = 12\n# creating list with all the possible combinations of parameters\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\n","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">Use grid search to find model with best hyperparameters.</h3>\n\n[Source](https://mlcourse.ai/articles/topic9-part1-time-series/)","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def optimizeSARIMA(parameters_list, d, D, s):\n    \"\"\"\n        Return dataframe with parameters and corresponding AIC\n\n        parameters_list - list with (p, q, P, Q) tuples\n        d - integration order in ARIMA model\n        D - seasonal integration order\n        s - length of season\n    \"\"\"\n    results = []\n    best_aic = float(\"inf\")\n    for param in tqdm_notebook(parameters_list):\n        # we need try-except because on some combinations model fails to converge\n        try:\n            model=SARIMAX(dataset, order=(param[0], d, param[1]),\n                          seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)\n        except:\n            continue\n        aic = model.aic\n        # saving best model, AIC and parameters\n        if aic < best_aic:\n            best_model = model\n            best_aic = aic\n            best_param = param\n        results.append([param, model.aic])\n\n    result_table = pd.DataFrame(results)\n    result_table.columns = ['parameters', 'aic']\n    # sorting in ascending order, the lower AIC is - the better\n    result_table = \\\n        result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)\n\n    return result_table","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_table = optimizeSARIMA(parameters_list, d, D, s)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">Using two best models from grid search</h3>\n","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 1, figsize=(16, 8))\nn_models = 2\n\nfor i in range(n_models):\n    ax = axes.ravel()[i]\n    model_params = result_table.iloc[i]['parameters']\n    best_order = (model_params[0], d, model_params[1])\n    best_seasonal_order = (model_params[2], D, model_params[3], s)\n    validation_predictions = \\\n        sarimax_predictions(train, validation, order=best_order,\n                            seasonal_order=best_seasonal_order)\n    grid_search_score = score_model(validation, validation_predictions)\n    plot_predictions(validation, validation_predictions,\n                     title=f'SARIMA {best_order} {best_seasonal_order}',\n                     ax=ax)\n    score_df = update_scores(score_df, f'SARIMA {best_order} '\n                                       f'{best_seasonal_order}',\n                             'OptimizeArima', order=best_order,\n                             seasonal_order=best_seasonal_order,\n                             validation_score=grid_search_score)\nplt.tight_layout()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 30px;\nfont-style: italic; background:#daf2e1; border-radius: 20px;\n\">Step 5 results:</h2>\n\n### 1. Model **SARIMA (4, 1,3) (0, 1, 0, 12)** slightly outperforms model SARIMA (1, 1, 1) (0, 1, 0, 12) on the validation set.\n### 2. Added 2 best models from grid search for final evaluation.\n","metadata":{}},{"cell_type":"markdown","source":"<div id=\"step6\">\n</div>\n\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nStep 6.\tCheck residuals.</h2>\n","metadata":{}},{"cell_type":"code","source":"def analyze_residuals(residuals, lags=20, model_name=None):\n    # Ideal residuals should be like white noise:\n    # 1. Stationary (Fuller test p value < 0.05)\n    # 2. Mean about 0.\n    # 3. Gaussian distribution.\n    # 4. Low variance (shows how good the model is).\n\n    fig = plt.figure(figsize=(16, 10))\n    layout = (3, 2)\n    resid_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n    hist_ax = plt.subplot2grid(layout, (1, 0))\n    qq_ax = plt.subplot2grid(layout, (1, 1))\n    acf_ax = plt.subplot2grid(layout, (2, 0))\n    pacf_ax = plt.subplot2grid(layout, (2, 1))\n    fig.suptitle(model_name, size=25)\n    # Plot residual errors to look for patterns\n    residuals.plot(ax=resid_ax)\n    resid_ax.set_title(f'Mean = {residuals.mean():.3f}', loc='left',\n                       color=orange)\n    resid_ax.set_title(f'Variance: {residuals.var():.3f}', loc='center',\n                       color=orange)\n    resid_ax.set_title(f'Dickey-Fuller: {adfuller(residuals)[1]:.3f}',\n                       loc='right', color=orange)\n    # Residual errors histogram and density plot\n    residuals.hist(ax=hist_ax)\n    residuals.plot(kind='kde', ax=hist_ax, secondary_y=True)\n    hist_ax.set_title('Histogram and KDE')\n\n    # Residuals QQ plot\n    # Check the distributions with QQ-Plots. If the dots are not on the\n    # diagonal line, the distribution is not normal.\n    qqplot(residuals, ax=qq_ax, fit=True, color=blue)\n    qqline(ax=qq_ax, line='45', color=orange)\n    qq_ax.set_title('QQ plot')\n\n    # Residuals autocorrelation plot\n    plot_acf(residuals, zero=False, lags=lags, ax=acf_ax)\n    acf_ax.set_title('Autocorrelation plot')\n\n    # Partial autocorrelation\n    plot_pacf(residuals, zero=False, lags=lags, ax=pacf_ax)\n    pacf_ax.set_title('Partial autocorrelation plot')\n\n    plt.tight_layout()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_df.sort_values('ValidationScore', inplace=True)\nbest_model = \\\n    score_df.iloc[0]\nvalidation_predictions = \\\n        sarimax_predictions(train, validation, order=best_model['Order'],\n                  seasonal_order=best_model['SeasonalOrder'])\nanalyze_residuals(pd.Series(validation - validation_predictions), lags=13,\n                  model_name=best_model['ModelName'])","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 30px;\nfont-style: italic; background:#daf2e1; border-radius: 20px;\n\">Step 6 results:</h2>\n\n### 1. The residuals of best model are **not stationary**.\n### 2. Distribution of residuals is **not normal**.\n### 3. There is still room for **model improvement**.","metadata":{}},{"cell_type":"markdown","source":"<div id=\"step7\">\n</div>\n\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nStep 7. Test scoring.</h2>\n","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(16, 8))\nn_models = 4\n\nfor i in range(n_models):\n    ax = axes.ravel()[i]\n    model_params = score_df.iloc[i]\n    if model_params['ModelName'] == 'Persistence':\n        test_predictions = persistence_predictions(dataset, test)\n        title = model_params['ModelName']\n    else:\n        best_order = model_params['Order']\n        best_seasonal_order =  model_params['SeasonalOrder']\n        test_predictions = \\\n            sarimax_predictions(dataset, test, order=best_order,\n                                seasonal_order=best_seasonal_order)\n        title = f'SARIMA {best_order} {best_seasonal_order}'\n    test_score = score_model(test, test_predictions)\n    score_df['TestScore'].iloc[i] = test_score\n    plot_predictions(test, test_predictions,\n                     title=title,\n                     ax=ax)\n    ax.tick_params(axis='both', which='major', labelsize=10)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def autolabel(rects, ax, decimals=2):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        value = round(height, decimals)\n        ax.annotate('{}'.format(value),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  size=14,# 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\nfig, ax = plt.subplots(figsize=(16, 6))\nscore_df.sort_values(['TestScore'], inplace=True)\nrects = ax.bar(x=score_df['ModelName'], height=score_df['ValidationScore'],\n               color=orange, zorder=2, label='Validation score', width=-0.4,\n               align='edge')\nautolabel(rects, ax, decimals=2)\nrects = ax.bar(x=score_df['ModelName'], height=score_df['TestScore'],\n               color=blue, zorder=2, label='Test score', width=0.4,\n               align='edge')\nautolabel(rects, ax, decimals=2)\nax.legend(fontsize=14)\nax.set_title('Models')\nax.text(0.05, 0.45, 'Model with best\\nresults',\n             transform = ax.transAxes, size=15, fontweight='bold')\nax.text(0.30, 0.45, 'Much simpler model\\nwith decent score',\n             transform = ax.transAxes, size=15, fontweight='bold')\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.tight_layout();","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 30px;\nfont-style: italic; background:#daf2e1; border-radius: 20px;\n\">Step 7 results:</h2>\n\n### 1. Model **SARIMA(4, 1, 3) (0, 1, 0, 12) is the best model** based on test and validation scores.\n### 2. Another options is to use a much simplier model **SARIMA(1, 1, 1) (0, 1, 0, 12) with decent score** compared to the leader.","metadata":{}},{"cell_type":"markdown","source":"<div id=\"step8\">\n</div>\n\n<h2 style=\"padding: 10px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nStep 8. Summary.</h2>\n\n### 1. Selected two final models: **SARIMA(1, 1, 1) (0, 1, 0, 12) and SARIMA(4, 1, 3) (0, 1, 0, 12)**.\n### 2. Selected models **show predictive power** compared to baseline.\n### 3. There is still space for model improvements as **residuals of models are not white noise**.","metadata":{}},{"cell_type":"markdown","source":"<h3 style=\"padding: 10px; text-align: left; color:#01872A; font-size: 20px;\n\">Further analysis.</h3>\n\n### 1. Use **power transfom** data to improve results.\n### 2. Use **regression models** and feature engineering for alternative analysis.","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"padding: 30px; text-align: center; color:#01872A; font-size: 40px;\nbackground:#daf2e1; border-radius: 20px;\">\nThank you for reading. Any feedback is highly appreciated. </h2>\n","metadata":{}}]}