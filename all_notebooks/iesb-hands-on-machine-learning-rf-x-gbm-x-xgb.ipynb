{"cells":[{"metadata":{"_uuid":"424b0d5ec3fc1b101dfbc6da8127e362a71a1398"},"cell_type":"markdown","source":"# Random Forest x GBM x XGBoost\n\nOs três métodos usam `árvore de decisão` como base e são chamados de `métodos ensemble`, que se caracterizam como métodos que procuram usar modelos mais simples/fracos de forma conjunta para melhorar o desempenho.\n\n## Random Forest\nPara obter melhor acurárica, o algoritimo de RF vai criar diversas `árvores de decisão` (parâmetro `n_estimators`) e chegar ao resultado final com base no resultado de cada árvore criada. A idéia básica é separar o conjunto de dados diversas vezes e para cada sub-conjunto treinar um novo regressor/classificador.  Os diferentes regressores/classificadores irão produzir resultados diferentes, e o resultado final será determinado com base nessas regressões/classificações.\n\n## Gradient Boosting\nGBM é um método de `boosting`, construído em cima de regressores/classificadores fracos. A idéia é adicionar um regressor/classificador de cada vez, então o próximo regressor/classificador é treinado para melhorar o resultado atingido até o momento ('soma de resultados'). Ao contrário do RF, que treina cada regressor/classificador de forma independente, no GBM eles são treinados em conjunto, um ligado ao outro.\n\n## XGBoost\nXGB é uma implementação específica do GBM, dita melhor e mais rápida que a implementação padrão do scikit-learn. Tanto o GBM quanto o XGB precisam de maior trabalho de interpretação dos dados e `tunning` do modelo."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importando as bibliotecas\nimport numpy as np\nimport pandas as pd\n\n# Verificando os arquivos\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Carregando os dados\ndf = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"853095a9b232b1061747decb6da30394841fd009"},"cell_type":"code","source":"# Verificando os tipos e os valores nulos\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d2eef949f1363b8bf1361520b2182334c915728"},"cell_type":"code","source":"# Transformar texto em número\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        df[col] = df[col].astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cfa949450228855bb823f2d92ca370bcbf58592"},"cell_type":"code","source":"# Dividindo o DataFrame\nfrom sklearn.model_selection import train_test_split\n\n# Treino e teste\ntrain, test = train_test_split(df, test_size=0.15, random_state=42)\n\n# Veificando o tanho dos DataFrames\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbf93c25394f447d4c793a74b4da149a68e036e1"},"cell_type":"code","source":"# Selecionado as features\nfeats = [c for c in df.columns if c not in ['Churn']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59064643318fc8f63ab6f9529257554a42fee315"},"cell_type":"code","source":"# Trabalhando com RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier(n_estimators=200, min_samples_split=5, max_depth=4, random_state=42)\nrf.fit(train[feats], train['Churn'])\naccuracy_score(test['Churn'], rf.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baecccd6fb9af646ceb894d88dd867d8e2d57761"},"cell_type":"code","source":"# Trabalhando com GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(train[feats], train['Churn'])\naccuracy_score(test['Churn'], gbm.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88421958801359c1bf5db0f8c29c177a32896c1c"},"cell_type":"code","source":"# Trabalhando com XGBoost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(n_estimators=200, learning_rate=0.09, random_state=42)\nxgb.fit(train[feats], train['Churn'])\naccuracy_score(test['Churn'], xgb.predict(test[feats]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7930fe978fa8d04344a1ac0c72f6427fc0085e23"},"cell_type":"code","source":"# Feature Importance com RF\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"444f9ece2b74d446c0c71d20720248e2cc1a0857"},"cell_type":"code","source":"# Feature Importance com GBM\npd.Series(gbm.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdb23712faedfd8d24ff8f4f5d9e35310727b861"},"cell_type":"code","source":"# Feature Importance com XGB\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f2e4afcefd79b3097daaebc77a92bb2656c675a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}