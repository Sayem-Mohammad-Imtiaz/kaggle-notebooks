{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's parse data.**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/carla-driver-behaviour-dataset/full_data_carla.csv\",index_col=0)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are 7 columns in dataset. A column named \"class\" is label, others are features (6 column named accelX,accelY,accelZ,gyroX,gyroY,gyroZ)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As you see, max and min value of features are 99 and -99 respectively. That's cause of data filtered while preparing dataset on Carla Simulator.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are no NULL values which is pretty good. We do not need to clean or fill missing values.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['class'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are 7 different classes & these are class names. The names of classes are in Turkish which can be look weird most of you :)**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**My name is mehdi. Also you can extract my driver patterns too :))**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Let's split data into features and labels. The labels are in string format which is not good to predict. We convert it to integer.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop([\"class\"],axis=1)\ny = data[\"class\"].values\nfrom sklearn.preprocessing import LabelEncoder\ny = LabelEncoder().fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, we have to split data into train and test to analyze our model.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, shuffle=True)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In this section, we train and test multiple classical machine learning approaches with well-known hyperparameters. I just want to try the dataset into these classical models.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(X_train,y_train)\nnn = MLPClassifier(solver='lbfgs')\nnn.fit(X_train,y_train)\nnb = GaussianNB()\nnb.fit(X_train,y_train)\nknn = KNeighborsClassifier(n_neighbors = 3) #n_neighbors = k\nknn.fit(X_train,y_train)\nsvm = SVC(random_state = 1)\nsvm.fit(X_train,y_train)\nprint(\"SVM accuracy is :\",svm.score(X_test,y_test))\nprint(\"k={} nn score={}\".format(3,knn.score(X_test,y_test)))\nprint('Naive Bayes Accuracy= :', nb.score(X_test,y_test))\nprint('MLP Accuracy= ',nn.score(X_test,y_test))\nprint('SGD Accuracy=: ', sgd.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The best fitting model look KNN algorithm. Even this algorithm without tuned fitted bad accuracy.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nimport numpy as np\naccuracy = cross_val_score(estimator = knn, X = X_train, y =y_train, cv = 8)\nprint(\"avg acc: \",np.mean(accuracy))\nprint(\"acg std: \",np.std(accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Althought accuracy is pretty bad, standart deviation is pretty good.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}