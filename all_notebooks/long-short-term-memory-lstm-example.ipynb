{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font color='red'>\n## Long Short Term Memory (LSTM) Example\n<font color='green'>\n- First of all, Welcome to LSTM Example Kernel.\n- In this kernel, I want to show you something about LSTM\n- LSTM is used in time-varying data sets.\n\n<font color='red'>\n**Content:**\n<font color='black'>\n1. [Imports](#1)\n    1. [Import Data](#2)\n2. [Preprocessing Data](#3)\n    1. [Normalize Data](#4)\n    2. [Test - Train Split](#5)\n    3. [Prepare Data](#6)\n3. [Create Model](#7)\n    1. [Visualize Losses](#16)\n4. [Prediction](#8)\n5. [Visualize](#9)\n6. [Conclusion](#10)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n<font color='red'>\n### Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # Linear algebra.\nimport pandas as pd # Data processing.\nimport matplotlib.pyplot as plt # Visualize\nimport math\nfrom keras.models import Sequential # Create Model\nfrom keras.layers import Dense # Neurons\nfrom keras.layers import LSTM # Long Short Term Memory\nfrom sklearn.preprocessing import MinMaxScaler # Normalize\nfrom sklearn.metrics import mean_squared_error # Loss Function\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n<font color='blue'>\n**Import Data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/Tesla.csv - Tesla.csv.csv\") # Import data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.iloc[:,1].values # We use \"Open\" column.\nplt.plot(df)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Open\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n<font color='red'>\n### Preprocessing Data"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n<font color='blue'>\n#### Normalize Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.reshape(-1,1)\n\nscaler = MinMaxScaler(feature_range = (0,1)) # Normalize data\ndf = scaler.fit_transform(df)\nnp.max(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n<font color='blue'>\n**Train - Test Split**\n<font color='black'>\n- We will split the data into 75% train and 25% test."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test - Train Split\ntrain_size = int(len(df) * 0.75) # % 75 Train\ntest_size = len(df) - train_size # % 25 Test\nprint(\"Train Size :\",train_size,\"Test Size :\",test_size)\n\ntrain = df[0:train_size,:]\ntest = df[train_size:len(df),:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n<font color='blue'>\n**Prepare Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_stemp = 10\n\ndatax = []\ndatay = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    datax.append(a)\n    datay.append(train[i + time_stemp, 0])\ntrainx = np.array(datax)\ntrainy = np.array(datay)\n\n\ndatax = []\ndatay = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    datax.append(a)\n    datay.append(test[i + time_stemp, 0])\ntestx = np.array(datax)\ntesty = np.array(datay)\n\ntrainx = np.reshape(trainx, (trainx.shape[0], 1, trainx.shape[1])) # For Keras\ntestx = np.reshape(testx, (testx.shape[0], 1,testx.shape[1])) # For Keras\nprint(trainx.shape)\ntestx.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n<font color='red'>\n### Create Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 200\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape = (1, time_stemp)))\nmodel.add(Dense(1)) # Output Layer\nmodel.compile(loss = \"mean_squared_error\", optimizer = \"adam\")\nhistory = model.fit(trainx,trainy, epochs = epochs, batch_size = 50, verbose=0)\n# As you can see, Loss is very little","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"16\"></a> <br>\n<font color='blue'>\n**Visualize Losses**"},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = np.arange(0, epochs, 10)\nlosses = []\nfor i in epoch:\n    if i % 10 == 0:\n        losses.append(history.history[\"loss\"][i])\n        \ndata = {\"epoch\":epoch,\"loss\":losses}\ndata = pd.DataFrame(data) # Create dataframe for visualize with plotly\n\n# Visualize\nimport plotly.express as px\n\nfig = px.line(data,x=\"epoch\",y=\"loss\",width = 1200, height = 500)\nfig.show()\n# I choose plotly for visualize because it's interactive","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\n<font color='red'>\n### Prediction"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"train_predict = model.predict(trainx)\ntest_predict = model.predict(testx)\n\ntrain_predict = scaler.inverse_transform(train_predict)\ntest_predict = scaler.inverse_transform(test_predict)\ntrainy = scaler.inverse_transform([trainy])\ntesty = scaler.inverse_transform([testy])\n\ntrain_score = math.sqrt(mean_squared_error(trainy[0], train_predict[:,0])) # mean_squared_error -> Loss Function\nprint(\"Train Score : %2.f RMSE\" % (train_score))\ntest_score = math.sqrt(mean_squared_error(testy[0], test_predict[:,0]))\nprint(\"Test Score : %2.f RMSE\" % (test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a> <br>\n<font color='red'>\n### Visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"# empty_like -> Return a new array with the same shape and type as a given array.\ntrain_predict_plot = np.empty_like(df)\ntrain_predict_plot[:,:] = np.nan\ntrain_predict_plot[time_stemp:len(train_predict)+time_stemp, :] = train_predict\n\ntest_predict_plot = np.empty_like(df)\ntest_predict_plot[:, :] = np.nan\ntest_predict_plot[len(train_predict)+(time_stemp*2)+1:len(df)-1, :] = test_predict\n\nplt.plot(scaler.inverse_transform(df),color = \"red\",label = \"Real\")\nplt.plot(train_predict_plot,label = \"Train Predict\",color = \"yellow\",alpha = 0.7)\nplt.plot(test_predict_plot,label = \"Test Predict\",color = \"green\", alpha = 0.7)\nplt.legend()\nplt.xlabel(\"Time\")\nplt.ylabel(\"Open Value\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a> <br>\n<font color='red'>\n### Conclusion\n<font color='black'>\n- As you can see, Our model is very successful.\n- If you encounter an error or would like to make a suggestion, please do not forget to comment\n- If you don't understand something, please don't forget to ask."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}