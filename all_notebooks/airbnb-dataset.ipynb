{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Importing the dataset\ndf = pd.read_csv('/kaggle/input/berlin-airbnb-data/listings_summary.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's drop the columns that are not necessary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's drop  the unnesessary columns, it can vary and may sometime impact our \n# accuracy also, so be cautious while ddoing so\ndf.drop(['listing_url', 'scrape_id', 'last_scraped', 'experiences_offered', 'neighborhood_overview',\n        'transit', 'access', 'interaction', 'house_rules',\n       'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url',\n       'host_about', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location',\n       'host_acceptance_rate', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count',\n       'host_total_listings_count', 'host_verifications',\n       'host_has_profile_pic', 'host_identity_verified', 'street',\n       'neighbourhood', 'neighbourhood_cleansed', 'host_is_superhost',\n       'city', 'state', 'zipcode', 'market', 'weekly_price', 'monthly_price', \n       'smart_location', 'country_code', 'country','calendar_updated', 'has_availability',\n       'availability_30', 'availability_60', 'availability_90', 'instant_bookable',\n       'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'is_location_exact',\n       'first_review', 'last_review', 'requires_license','maximum_nights',\n       'license', 'jurisdiction_names', 'require_guest_profile_picture', 'require_guest_phone_verification',\n       'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n       'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value',\n       'calculated_host_listings_count', 'reviews_per_month', 'is_business_travel_ready', 'minimum_nights'],\n        axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking whether there is any repeated or duplicate values\ndf.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above output indicates that there is no duplicate values in our dataset after deleting the unnecessary columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the missing values \ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting 'id' as an index\ndf = df.set_index('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since above we found that there are many missing values in some columns\n# so dropping the columns with extremely high missing values\ndf.drop(['space', 'notes', 'square_feet', 'host_response_time', 'host_response_rate'],\n       axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Still we can see that there is many missing values in some columns so now\n# we will fill some of these missing values of columns\n# So lets replace the NaNs in bathrooms and bedrooms with 1 \ndf.bathrooms.fillna(1, inplace = True)\ndf.bedrooms.fillna(1, inplace = True)\n\n# we can replace the NaNa in beds by neighbour column 'accomodate'\n#df.beds.fillna(df['accomodates'], inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['beds'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can replace the NaNa in beds by neighbour column 'accomodate'\ndf.beds.fillna(df['accommodates'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Communities deployment \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (10,5))\nsns.countplot(y = df['neighbourhood_group_cleansed'], order = df.neighbourhood_group_cleansed.value_counts().index)\nplt.xlabel(\"Quantity of listings\", fontsize = 'medium')\nplt.ylabel('')\nplt.title(\"Communities deployment\", fontsize = 'large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['neighbourhood_group_cleansed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.neighbourhood_group_cleansed.value_counts().index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Property type deployment - TOP-10 types\nplt.figure(figsize = (15,5))\nsns.countplot(df['property_type'], order = df.property_type.value_counts().iloc[:10].index)\nplt.xlabel(\"\")\nplt.ylabel(\"Quantity of listings\", fontsize = 'large')\nplt.title(\"Property type\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Room type deployment\nplt.figure(figsize = (5,5))\nsns.countplot(df['room_type'], order = df.room_type.value_counts(normalize = True).index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**'price' and other money related columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaning (replace '$') and formatig price-related columns\ndf.price = df.price.str.replace('$', '').str.replace(',', '').astype(float)\n#df.security_deposit = df.security_deposit.str.replace('$', '').str.replace(',', '').astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.security_deposit = df.security_deposit.str.replace('$', '').str.replace(',', '').astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.cleaning_fee = df.cleaning_fee.str.replace('$', '').str.replace(',', '').astype(float)\ndf.extra_people = df.extra_people.str.replace('$', '').str.replace(',', '').astype(float)\n\n# NaNs in security_deposit and cleaning_fee seem to be 0\n#df.security_deposit.filna(0, inplace = True)\n#df.cleaning_fee.fillna(0, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we already have seen that there is NaNs in security_deposit and cleaning_fee\n# so lets fill them\ndf.security_deposit.fillna(0, inplace = True)\ndf.cleaning_fee.fillna(0, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['security_deposit'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cleaning_fee'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so we can see that there is no NaNs in cleaning_fee and security deposit now"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking suspiciously low prices\nprint(df[(['price', 'name'])][df.price<10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping rows with price < 8$\ndf = df.drop(df[df.price<8].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now cheecking the price greater than $8 but less than 10\nprint(df[(['price', 'name'])][df.price<10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking suspiciously high prices \ndf['price'].plot(kind = 'box', xlim = (0,600),vert = False, figsize = (16,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since high price are not  affordable for everyone so dropping the extremely \n# high price\n\ndf = df.drop(df[df.price > 380].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[(['price', 'name'])][(df.price<80) & (df.price>20)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extracting and Working out data re room size**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract number that may contain info re square of rooms from 'description' \n#columns (contains, 's/m/S/M')\ndf['room_size'] = df['description'].str.extract(\"(\\d{2,3}\\s[smSM])\", expand = True)\ndf['room_size'] = df['room_size'].str.replace(\"\\D\", \"\").astype(float)\nrv = len(df) - df['room_size'].isna().sum()\nprint('Real values in \"room_size\" column:   ', rv)\nprint('Real values in \"room_size\" column (%):   ', round(rv/len(df)*100, 1), '%')\n\n\n# (C) This cell of code was taken from the original research, done by Britta Bettendorf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract numbers that may contain info re square of rooms from 'name' columns\n# (contains 's/m/S/M')\n\ndf['room_size_name'] = df['name'].str.extract(\"(\\d{2,3}\\s[smSM])\", expand = True)\ndf['room_size_name'] = df['room_size_name'].str.replace(\"\\D\", \"\").astype(float)\n\nrv = len(df) - df['room_size_name'].isna().sum()\nprint('Real values in \"room_size_name\" column:    ', rv)\nprint('Real values in \"room_size_name\" column(%):    ', round(rv/len(df)*100, 1), '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.room_size.fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Updatig column 'room_size' with values extracted from column 'name'\ndf.loc[df['room_size'] == 0, 'room_size'] = df['room_size_name']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We don't needit any more\ndf.drop(['room_size_name'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking suspiciously low sizes\nprint(df[(['room_size', 'name'])][(df.room_size < 10)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping rows with  suspiciously low sizes\ndf = df.drop(df[df.room_size < 10].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking suspiciously high sizes\ndf['room_size'].plot(kind = 'box', vert = False, figsize = (16,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[(['room_size', 'name'])][df.room_size > 250])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping values of suspiciously high sizes\ndf.loc[df['room_size'] > 250, 'room_size'] = ''\ndf.room_size.replace(to_replace = '', value = np.nan, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Wehave NaN's in our column, 2/3 of all values\ndf.room_size.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New df for further regression\ndf_temp = df[['neighbourhood_group_cleansed', 'accommodates', 'bathrooms', 'bedrooms',\n             'beds', 'price', 'security_deposit', 'cleaning_fee', 'guests_included',\n             'extra_people', 'room_size']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_temp.shape)\ndf_temp.head(10).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking care of categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\ncategorical_cols = ['neighbourhood_group_cleansed']\ndf_temp[categorical_cols] = df_temp[categorical_cols].apply(lambda col: labelencoder_X.fit_transform(col.astype(str)))\ndf_temp.head(10).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['neighbourhood_group_cleansed'].unique().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Arranging datasets by existence of 'room_size' value\n\ntrain_set = df_temp[df_temp['room_size'].notnull()]\ntest_set = df_temp[df_temp['room_size'].isnull()]\n\n# Arranging X-taining and X-testing datasets\nX_train = train_set.drop('room_size', axis = 1)\nX_test = test_set.drop('room_size', axis = 1)\n\n# Arranging y-training datasets \ny_train = train_set['room_size']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Regression Model\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 300, random_state = 123)\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Introduction of predicted data to the main dataset 'df'\ny_pred = pd.DataFrame(y_pred)\ny_pred.columns = ['room_size']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_id = pd.DataFrame(X_test.index)\ntemp_id.columns = ['temp_id']\n\ny_pred = pd.concat([y_pred, temp_id], axis = 1)\ny_pred.set_index(['temp_id'], inplace = True)\n\ndf_pred = pd.concat([X_test, y_pred], axis = 1)\ndf_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = pd.DataFrame()\ndf_temp = pd.concat([df_pred, train_set], axis = 0)\nprint(df_temp.shape)\ndf_temp.head().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp.head(10).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking again suspiciously low sizes\nprint(df_temp[(['room_size'])][(df_temp.room_size<10)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking suspiciously high sizes\ndf_temp['room_size'].plot(kind = 'box', vert = False, figsize = (16,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_temp.shape)\ndf_temp.head().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['property_type', 'amenities', 'cancellation_policy']]\nprint(df.shape)\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, df_temp], axis = 1)\nprint(df.shape)\ndf.head(3).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking whether there is a null value or not in df\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Amenities score introduction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's explore amenities\npd.set_option('display.max_colwidth', -1)\ndf.amenities.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's introduce new column with score of amenities\ndf['amen_score'] = df['amenities'].str.count(',') + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We don't need it any more\ndf.drop(['amenities'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['amen_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Every columns is now non empty*"},{"metadata":{},"cell_type":"markdown","source":"**Gradient Boosting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A separate copy for TF\ndf_tf = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking care of categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\ncategorical_cols = ['property_type', 'cancellation_policy']\ndf[categorical_cols] = df[categorical_cols].apply(lambda col: labelencoder_X.fit_transform(col.astype(str)))\ndf.head(10).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating DV and IV sets\nX = df.drop('price', axis = 1)\ny = df['price']\n\n# Splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient Boosting Regression\nfrom sklearn.ensemble import GradientBoostingRegressor\nregressor = GradientBoostingRegressor(n_estimators = 100, max_depth = 3, min_samples_split = 2,\n                                      learning_rate = 0.1)\nregressor.fit(X_train, y_train)\n\n# Predicting the test set results\ny_pred = regressor.predict(X_test)\n\n# Finding the mean_sqaured error (MSE)\nfrom sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred)\n\n# Finding the r2 score or the variance (R2)\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, y_pred)\n\n# Applying k-fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = regressor, X = X_test, y = y_test, cv = 10)\n\n# Printing metrics \nprint(\"RMSE Error:\", round(np.sqrt(mse), 2))\nprint(\"R2 Score:\", round(r2, 4))\nprint(\"Mean Accuracy:\", round(accuracies.mean(), 2))\nprint(\"Std Deviation:\", round(accuracies.std(), 4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tensor Flow DNN_Regressor**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating DV and IV sets\nX_tf = df_tf.drop('price', axis = 1)\ny_tf = df_tf['price']\n\n# Splitting the datasets into the Training set and Test set\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_tf, y_tf, test_size = 0.25,\n                                                   random_state = 123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature columns\nproperty_type = tf.feature_column.categorical_column_with_hash_bucket('property_type', hash_bucket_size=50)\ncancellation_policy = tf.feature_column.categorical_column_with_hash_bucket('cancellation_policy', hash_bucket_size=10)\nneighbourhood_group_cleansed = tf.feature_column.numeric_column('neighbourhood_group_cleansed')\naccommodates = tf.feature_column.numeric_column('accommodates')\nbathrooms = tf.feature_column.numeric_column('bathrooms')\nbedrooms = tf.feature_column.numeric_column('bedrooms')\nbeds = tf.feature_column.numeric_column('beds')\nsecurity_deposit = tf.feature_column.numeric_column('security_deposit')\ncleaning_fee = tf.feature_column.numeric_column('cleaning_fee')\nguests_included = tf.feature_column.numeric_column('guests_included')\nroom_size = tf.feature_column.numeric_column('room_size')\namen_score = tf.feature_column.numeric_column('amen_score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_property_type = tf.feature_column.embedding_column(property_type, dimension = 33)\nemb_cancellation_policy = tf.feature_column.embedding_column(cancellation_policy, dimension = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_cols = [emb_property_type, emb_cancellation_policy, neighbourhood_group_cleansed, accommodates, bathrooms,\n            bedrooms, beds, security_deposit, cleaning_fee, guests_included, room_size, amen_score]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input function\nfrom tensorflow_core.estimator import inputs\ninput_func =  tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=1000,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating and training model\nmodel = tf.estimator.DNNRegressor(hidden_units = [12,12,12], feature_columns = feat_cols)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.train(input_fn = input_func, steps = 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(x = X_test, batch_size = 10, num_epochs = 1, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = list(model.predict(pred_input_func))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\nfor i in predictions:\n    y_pred.append(i['predictions'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ntf_mse = mean_squared_error(y_test, y_pred)\nprint(\"MSE Error:\", round(tf_mse, 2))\nprint(\"RMSE Error:\", round(np.sqrt(tf_mse), 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}