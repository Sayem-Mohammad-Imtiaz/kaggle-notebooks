{"cells":[{"metadata":{"_uuid":"616d69e03dde03cac092c52cdd8acfc6b9a724f5"},"cell_type":"markdown","source":"# Spam Detection using NLP and Random Forest"},{"metadata":{"_uuid":"f20d7a4210db9fd3d380530e1203e900a890e1d0"},"cell_type":"markdown","source":"This Project focusses on the following areas : \n\n1. Data Cleaning Pipeline : \n    - Removing Punctuation\n    - Tokenizing\n    - Removing Stop Words\n2. Applying NLYKs - TF-IDF on the Cleaned Dataset\n3. Feature Engineering\n    - Length of Text Messages\n    - Percent of punctuation used in each corpus\n    - Number finding in each corpus\n    - Web links in each corpus\n4. Understanding the Features\n5. Making a new Dataframe having all the required features for prediction\n   and have the TF-IDF data\n6. Splitting the Dataset into Test and Train to build and apply the model\n7. Building model on Train set using Random Forest\n8. Understanding the relative importance of features used\n9. Applying the model on Test set\n10. Tweaking hyperparameters using Grid Search\n"},{"metadata":{"_uuid":"fc431070703980252d0a32ea5644499393ba9455"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"cd327cd9bf990a579c9099e611229b079010fef9"},"cell_type":"markdown","source":"# Importing NLP's nltk library\n# Downloading Stopwords to remove from the dataset later"},{"metadata":{"trusted":true,"_uuid":"1f872844f178d90776dc1b06d25cd6b819222199","collapsed":true},"cell_type":"code","source":"import nltk\n#nltk.download()\nfrom nltk.corpus import stopwords\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a92807065a048fe30fd95e1334737fb80369eb2a"},"cell_type":"markdown","source":"# 1. Data Cleaning Pipeline"},{"metadata":{"trusted":true,"_uuid":"16d8bc1dab8e7f5ead5e4cd1022ae2c0ab1c4bf2"},"cell_type":"code","source":"import pandas as pd\nadd = \"../input/spam.csv\"\ndata = pd.read_csv(add, encoding='latin-1')\ndata.head(5)\ndata = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\npd.set_option('display.max_colwidth', 0)\ndata.columns = ['label','text']\n\ndata.head(5)\n\n#print(data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55bc0b3ed1a783e78b6e27e65f83baefa70b44b4"},"cell_type":"markdown","source":"### Applying the Data Cleaning Pipeline  - followed by TF_IDF"},{"metadata":{"_uuid":"336a2d0c899af7cbb1f61fa8f00d307a1e6dfce8"},"cell_type":"markdown","source":"The stopwords can be in many languages, for this particular dataset we'll use the English Language words"},{"metadata":{"trusted":true,"_uuid":"166db5f4e36f08ad2b0236563c6fe08de6865df8","collapsed":true},"cell_type":"code","source":"import string\nimport re\nstopword = nltk.corpus.stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ad22b9d0e26538460ebc12cc0eef567c8d76963"},"cell_type":"markdown","source":"We'll apply Stemming so as to remove any redundancy among words, i.e words which have the same root eg. running and run etc would be converted into run using stemming. \n\nNOTE :  For the same task,another technique named lemmatizing can also be used, which also considers the grammatical sense of the word in the context in which it has been used.\n\nAs we're using stemming here, we'll use the portstemmer as below"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0bab7634a0532fdfa59bce32d5ae6b330963c542"},"cell_type":"code","source":"ps = nltk.PorterStemmer()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"583e3b92262e08f916a8afcbc2ae32222d766677"},"cell_type":"markdown","source":"We'll Remove  all the Punctuation, StopWords from the dataset and finally apply stemming on the resulting dataset to make clean, tidy and ready for processing"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"255fd8dc0053ee0ef790a77f04c2b5fc86a5da74"},"cell_type":"code","source":"def clean_text(text):\n    remove_punct = \"\".join([word.lower() for word in text if word not in string.punctuation])\n    tokens = re.split('\\W+',remove_punct)\n    noStop = ([ps.stem(word) for word in tokens if word not in stopword])\n    return noStop","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20ef18f401c9d7f381cfee0f3383938b1012e5e0"},"cell_type":"markdown","source":"# 2. Applying NLYKs - TF-IDF on the Cleaned Dataset"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"070c3b548a27b873fe8c364da4a6db6d0f42f455"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_Vector = TfidfVectorizer(analyzer= clean_text)\nXtfidf_Vector = tfidf_Vector.fit_transform(data['text'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f78a047a7e5fafbfb735dfce618d9d504910b013"},"cell_type":"markdown","source":"# 3. Feature Engineering"},{"metadata":{"_uuid":"d6722f30156b1b2fecbebaf8af0d8c67cda8c205"},"cell_type":"markdown","source":"#### Feature for Length of Text messages & Punctuation Percentage"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8add47c4599039aa78a0ce8429e7503ae4b7e4e6"},"cell_type":"code","source":"import string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"040e081dd63db2c820e6d08e3dfe0c88e2c8e6d7"},"cell_type":"code","source":"def punct_percent(text):\n    count = sum([1 for char in text if char in string.punctuation])\n    return round(count/ (len(text) - text.count(\" \")),3)*100\ndata['punct_%'] = data['text'].apply(lambda x: punct_percent(x))\ndata['length'] = data['text'].apply(lambda x: len(x) - x.count(\" \"))\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"344bbfa071713ac4cfd43bb5ae9460581bdcd2c6"},"cell_type":"code","source":"pd.set_option('display.max_colwidth', 0)\n\nprint(data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb0fcc1434ced20c223a5cf78185fa10637d303f"},"cell_type":"markdown","source":"#### Features for Rows having numbers with number.length > =5"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"10721eb5754efbc9afd189b13f92edcf433e862d"},"cell_type":"code","source":"import re\n\n#def find_num(text):\n#    return re.findall('\\d{7,}',text)\n\ndata['number'] = pd.DataFrame(data['text'].apply(lambda x: len(re.findall('\\d{5,}',x))))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"83ae1917f61063c71d3c43f9b4baea1db8e2efc2"},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efd8c48f11471618e1de6bed0326b47eaec2ff35"},"cell_type":"markdown","source":"#### Feature for Currency"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1a399ae7fae1c629b3bd5d96e9fb4e54feff9e11"},"cell_type":"code","source":"\n#def get_currency_symbol(text):\n#    pattern = r'(\\D*)\\d*\\.?\\d*(\\D*)'\n#    result = re.match(pattern,text).group()\n#    return result\n#data['currency']= pd.DataFrame(data['text'].apply(lambda x: len(get_currency_symbol(x))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"45b8dfd92243dba8ae14388d565a10af1e18d0ad"},"cell_type":"code","source":"#print(data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b1b6bb1e0655d08acb5f61cf8b464f0cd31c1a0"},"cell_type":"markdown","source":"#### Feature for web address"},{"metadata":{"trusted":true,"_uuid":"06eb68b7f390596596ee3fc360287bd2858276fb"},"cell_type":"code","source":"def web_address(t):\n    if(len(re.findall('www|http|https|.co',t)) > 0):\n        return 1\n    else:\n        return 0\n    \ndata['url'] = pd.DataFrame(data['text'].apply(lambda x: web_address(x)))\nprint(data.head(5))   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80b1502b4bb1d0b16649dbd68c02da72f4f3b8e7"},"cell_type":"markdown","source":"# 4. Understand the Feartures"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4113c1f65f225efc480bd3087a65117dac27f65a"},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"7d5c72d65175b4fb721bc524c93ca0b7b2731027"},"cell_type":"code","source":"bins = np.linspace(0,200,40)\npyplot.hist(data[data['label'] == 'spam']['length'],bins,alpha = 0.5,normed = True,label = 'spam')\npyplot.hist(data[data['label'] == 'ham']['length'],bins,alpha = 0.5,normed = True, label = 'ham')\npyplot.legend(loc = 'upper right')\npyplot.figure(figsize = (1000,400), dpi = 1000)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c236b2a5d9318869882facfc50f4f89e8c42fe4a"},"cell_type":"code","source":"bins = np.linspace(0,50,40)\npyplot.hist(data[data['label'] == 'spam']['punct_%'], bins, alpha = 0.5,normed = True, label = 'spam')\npyplot.hist(data[data['label'] == 'ham']['punct_%'], bins, alpha = 0.5,normed = True, label = 'ham')\npyplot.legend(loc = 'upper right')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c92e17d7d0e6aca92628c683091f53c2785c06da"},"cell_type":"code","source":"bins = np.linspace(0,5,10)\npyplot.hist(data[data['label'] == 'spam']['number'], bins,alpha = 0.5, label = 'spam')\npyplot.hist(data[data['label'] == 'ham']['number'], bins, alpha = 0.5, label = 'ham')\npyplot.legend(loc = 'upper right')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"f592e8c2d590d84b6a0c48558f406904bd843615"},"cell_type":"code","source":"bins = np.linspace(0,5,100)\npyplot.hist(data[data['label'] == 'spam']['url'], bins,alpha = 0.5, label = 'spam')\npyplot.hist(data[data['label'] == 'ham']['url'], bins, alpha = 0.5, label = 'ham')\npyplot.legend(loc = 'upper right')\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a080f0925caf19757c44cea4d9a44d9160db4cb"},"cell_type":"markdown","source":"#### Drawing pyplot for Datawith url as feature for data"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"2c2305022cba3d81067bb7d8fdb3e14afbef875e"},"cell_type":"code","source":"data['url'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"128da792fa472fcf70986b3df63d078a645879d7"},"cell_type":"markdown","source":"####  0 values : 78.4%\n#### 1 valyes  : 21.6%"},{"metadata":{"_uuid":"103b3b978b6ff08ddf5fb7996e3ddb026981e76a"},"cell_type":"markdown","source":"# 5. Making new Dataframe with all features for prediction and TF-IDF data"},{"metadata":{"trusted":true,"_uuid":"d7aee67d490c32b1eec0fda706d0379ec5b49696"},"cell_type":"code","source":"Xfeatures_data = pd.concat([data['length'],data['punct_%'],data['number'],data['url'], pd.DataFrame(Xtfidf_Vector.toarray())], axis = 1)\nXfeatures_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11c1c661c7a2c888c2d7c97fd5bef08532443607"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nprint(dir(RandomForestClassifier))\nprint(RandomForestClassifier())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6b5de98fdc4f5be6bdbb7126d361e3277edb7e6"},"cell_type":"markdown","source":"# 6. Splitting the Dataset into Test and Train to build and apply the model\n"},{"metadata":{"scrolled":true,"trusted":true,"collapsed":true,"_uuid":"e71b3357a67bbd356c81c578594a8db192c9047e"},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(Xfeatures_data, data['label'], test_size = 0.2)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"babcf255e4f4f58eee418686249c7dbf227331d5"},"cell_type":"markdown","source":"# 7. Building the model on Train Data\n# 8. Understanding the relative importance of features added"},{"metadata":{"trusted":true,"_uuid":"5c7de127ec43742ad21da0a28668d929ec1ca566"},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators= 50, max_depth= 20, n_jobs = -1)\nrf_model = rf.fit(X_train,y_train)\nsorted(zip(rf.feature_importances_,X_train.columns), reverse= True)[0:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1eefb44a64fb5f3048166c6b29a869a4a5db9316"},"cell_type":"markdown","source":"This shows that our original assumption about < numbers, length, url > in a row being good predictors of ham/spam class was correct"},{"metadata":{"_uuid":"5f78a1b0ba154662e20e7e0ec89a6945fe994169"},"cell_type":"markdown","source":"# 9. Applying the model on Test set"},{"metadata":{"trusted":true,"_uuid":"13c64c078700f909c71d304acdf49eb8b8f49d7e"},"cell_type":"code","source":"y_pred = rf_model.predict(X_test)\nprecision,recall,fscore,support = score(y_test,y_pred,pos_label = 'spam', average = 'binary')\nprint('Precision: {}/ Recall: {}/ Accuracy: {}'.format(round(precision,3), round(recall,3), (y_pred == y_test).sum()/len(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a726e934ded2990b3594095d7100ab9a04689e13"},"cell_type":"markdown","source":"# 10. Tweaking hyperparameters using Grid Search"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57e94135d5a1a34931526a413635315f5ff9c32d"},"cell_type":"code","source":"def train_rf(n_est, depth):\n    rf = RandomForestClassifier(n_estimators= n_est, max_depth= depth, n_jobs = -1)\n    rf_model = rf.fit(X_train,y_train)\n    y_pred = rf_model.predict(X_test)\n    precision,recall,fscore,support = score(y_test,y_pred,pos_label= 'spam',average= 'binary')\n    print('Est: {}/ Depth: {}/ Precision: {}/ Recall: {}/ Accuracy : {}'.format(n_est,depth, round(precision,3), round(recall,3), (y_pred == y_test).sum()/len(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"4b931c39ab080266c041382ac44c7fece91fa1f2"},"cell_type":"code","source":"for n_est in [10,30,50,70]:\n    for depth in [20,40,60,80, None]:\n        train_rf(n_est,depth)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"948de179d9fe8861d3684b77e68caa71ad713ec8"},"cell_type":"markdown","source":"# Conclusion :\n\n\n\nSo our best results are :  Est: 70/ Depth: None/ Precision: 1.0/ Recall: 0.908/ Accuracy : 0.9883303411131059"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a99be3c2db8d7c152ca74b1eab1ed26bb9e19432"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}