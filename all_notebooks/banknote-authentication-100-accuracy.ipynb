{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BANKNOTE AUTHENTICATION\nProblem to solve : To Predict whether the note is genuine or not"},{"metadata":{},"cell_type":"markdown","source":"### Libraries to import"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf  \nfrom tensorflow import keras  \nfrom tensorflow.keras import Sequential \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading data from csv file using pandas read_csv function"},{"metadata":{"trusted":false},"cell_type":"code","source":"#get the train and test data from the below link respectively\nbank_note_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/training_set_label.csv\" )\ntest_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/testing_set_label.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"bank_note_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Assigning input and Output variables to X and y respectively"},{"metadata":{"trusted":false},"cell_type":"code","source":"X = bank_note_data.drop('Class', axis=1) #Input variables\n# axis=1 indicates that a column will be dropped\ny = bank_note_data['Class']  # Target variable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardizing all the numerical column values in both training and testing data"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX=pd.DataFrame(scaler.fit_transform(X),columns=X.columns)\ntest_data=pd.DataFrame(scaler.fit_transform(test_data),columns=test_data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Spliting the data into 80/20 ratio for training and testing"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building the sequential model with one input, hidden and output layer"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Building the model\nmodel = Sequential()\nmodel.add(Dense(8, activation='relu', input_shape=(X_train.shape[1],)))   \nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compling the model with binary_crossentrophy loss and adam optimizer"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Compiling the model\nfrom tensorflow.keras.optimizers import Adam\nmodel.compile(loss='binary_crossentropy', optimizer= 'adam' , metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting the model with the validation data of 20%  for 200 epocs and batch size of 10 "},{"metadata":{"trusted":false},"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluated the model and got the accuracy of 100% in validation data"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### plotting the accuracy and loss curves for training and validation data"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using the above model to predict the unseen data"},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions=model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_kg_hide-output":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_kg_hide-output":true},"cell_type":"code","source":"x = np.round(predictions)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"res = pd.DataFrame(x) \nres.index = test_data.index \nres.columns = [\"prediction\"]\nres.to_csv(\"Banknote_submitted.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Achieved 100% accuracy in test data set as well"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}