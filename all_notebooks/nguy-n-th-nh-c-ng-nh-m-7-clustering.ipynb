{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COVID-19 Literature Clustering","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nImage(url='https://raw.githubusercontent.com/MaksimEkin/COVID19-Literature-Clustering/master/cover/bokeh_plot.png', width=800, height=800)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:48:33.470849Z","iopub.execute_input":"2021-06-26T21:48:33.471206Z","iopub.status.idle":"2021-06-26T21:48:33.485757Z","shell.execute_reply.started":"2021-06-26T21:48:33.471133Z","shell.execute_reply":"2021-06-26T21:48:33.484965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport json\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:48:35.923303Z","iopub.execute_input":"2021-06-26T21:48:35.923644Z","iopub.status.idle":"2021-06-26T21:48:35.927983Z","shell.execute_reply.started":"2021-06-26T21:48:35.923615Z","shell.execute_reply":"2021-06-26T21:48:35.927034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_path = '/kaggle/input/CORD-19-research-challenge/'\nmetadata_path = f'{root_path}/metadata.csv'\nmeta_df = pd.read_csv(metadata_path, dtype={\n    'pubmed_id': str,\n    'Microsoft Academic Paper ID': str, \n    'doi': str\n})\nmeta_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:48:36.605397Z","iopub.execute_input":"2021-06-26T21:48:36.605714Z","iopub.status.idle":"2021-06-26T21:48:54.094Z","shell.execute_reply.started":"2021-06-26T21:48:36.605684Z","shell.execute_reply":"2021-06-26T21:48:54.093218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:48:54.095418Z","iopub.execute_input":"2021-06-26T21:48:54.095764Z","iopub.status.idle":"2021-06-26T21:48:54.883631Z","shell.execute_reply.started":"2021-06-26T21:48:54.095711Z","shell.execute_reply":"2021-06-26T21:48:54.882804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lấy path tất cả các file json trong thư mục document_parses","metadata":{}},{"cell_type":"code","source":"all_json = ! ls $root_path/document_parses/pdf_json\nlen(all_json)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:48:54.885316Z","iopub.execute_input":"2021-06-26T21:48:54.885859Z","iopub.status.idle":"2021-06-26T21:48:58.827694Z","shell.execute_reply.started":"2021-06-26T21:48:54.885816Z","shell.execute_reply":"2021-06-26T21:48:58.826851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nall_json = [root_path + \"document_parses/pdf_json/\" + s for s in all_json]\nall_json[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:48:58.829295Z","iopub.execute_input":"2021-06-26T21:48:58.829661Z","iopub.status.idle":"2021-06-26T21:48:58.897456Z","shell.execute_reply.started":"2021-06-26T21:48:58.829622Z","shell.execute_reply":"2021-06-26T21:48:58.896395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(all_json)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:48:58.89899Z","iopub.execute_input":"2021-06-26T21:48:58.899357Z","iopub.status.idle":"2021-06-26T21:48:58.90517Z","shell.execute_reply.started":"2021-06-26T21:48:58.899318Z","shell.execute_reply":"2021-06-26T21:48:58.904207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            self.paper_id = content['paper_id']\n            self.abstract = []\n            self.body_text = []\n            # Abstract\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.abstract = '\\n'.join(self.abstract)\n            self.body_text = '\\n'.join(self.body_text)\n    def __repr__(self):\n        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\nfirst_row = FileReader(all_json[0])\nprint(first_row)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:49:17.514204Z","iopub.execute_input":"2021-06-26T21:49:17.514517Z","iopub.status.idle":"2021-06-26T21:49:17.533658Z","shell.execute_reply.started":"2021-06-26T21:49:17.514487Z","shell.execute_reply":"2021-06-26T21:49:17.5328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef clean_json(all_json):\n    all_json_clean = list()\n    for idx, entry in tqdm(enumerate(all_json), total=len(all_json)):\n\n        try:\n            content = FileReader(entry)\n        except Exception as e:\n            continue  # invalid paper format, skip\n\n        if len(content.body_text) == 0:\n            continue\n\n        all_json_clean.append(all_json[idx])\n    return all_json_clean\n\n    \nall_json = clean_json(all_json)\nlen(all_json)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T21:50:57.181337Z","iopub.execute_input":"2021-06-26T21:50:57.183142Z","iopub.status.idle":"2021-06-26T22:15:48.022773Z","shell.execute_reply.started":"2021-06-26T21:50:57.182447Z","shell.execute_reply":"2021-06-26T22:15:48.021029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nrandom.seed(42)\n\nall_json = random.sample(all_json, 50000)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:16:04.896836Z","iopub.execute_input":"2021-06-26T22:16:04.89716Z","iopub.status.idle":"2021-06-26T22:16:04.914929Z","shell.execute_reply.started":"2021-06-26T22:16:04.89713Z","shell.execute_reply":"2021-06-26T22:16:04.914069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_breaks(content, length):\n    data = \"\"\n    words = content.split(' ')\n    total_chars = 0\n\n    # add break every length characters\n    for i in range(len(words)):\n        total_chars += len(words[i])\n        if total_chars > length:\n            data = data + \"<br>\" + words[i]\n            total_chars = 0\n        else:\n            data = data + \" \" + words[i]\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:16:24.143121Z","iopub.execute_input":"2021-06-26T22:16:24.143436Z","iopub.status.idle":"2021-06-26T22:16:24.148874Z","shell.execute_reply.started":"2021-06-26T22:16:24.143406Z","shell.execute_reply":"2021-06-26T22:16:24.147784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndict_ = {'paper_id': [], 'doi':[], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\nfor idx, entry in tqdm(enumerate(all_json), total = len(all_json)):\n    \n    try:\n        content = FileReader(entry)\n    except Exception as e:\n        continue  # invalid paper format, skip\n    \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    # no metadata, skip this paper\n    if len(meta_data) == 0:\n        continue\n    if len(content.body_text) == 0:\n        continue\n    dict_['abstract'].append(content.abstract)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['body_text'].append(content.body_text)\n    \n    # also create a column for the summary of abstract to be used in a plot\n    if len(content.abstract) == 0: \n        # no abstract provided\n        dict_['abstract_summary'].append(\"Not provided.\")\n    elif len(content.abstract.split(' ')) > 100:\n        # abstract provided is too long for plot, take first 300 words append with ...\n        info = content.abstract.split(' ')[:100]\n        summary = get_breaks(' '.join(info), 40)\n        dict_['abstract_summary'].append(summary + \"...\")\n    else:\n        # abstract is short enough\n        summary = get_breaks(content.abstract, 40)\n        dict_['abstract_summary'].append(summary)\n        \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    \n    try:\n        # if more than one author\n        authors = meta_data['authors'].values[0].split(';')\n        if len(authors) > 2:\n            # more than 2 authors, may be problem when plotting, so take first 2 append with ...\n            dict_['authors'].append(get_breaks('. '.join(authors), 40))\n        else:\n            # authors will fit in plot\n            dict_['authors'].append(\". \".join(authors))\n    except Exception as e:\n        # if only one author - or Null valie\n        dict_['authors'].append(meta_data['authors'].values[0])\n    \n    # add the title information, add breaks when needed\n    try:\n        title = get_breaks(meta_data['title'].values[0], 40)\n        dict_['title'].append(title)\n    # if title was not provided\n    except Exception as e:\n        dict_['title'].append(meta_data['title'].values[0])\n    \n    # add the journal information\n    dict_['journal'].append(meta_data['journal'].values[0])\n    \n    # add doi\n    dict_['doi'].append(meta_data['doi'].values[0])\n    \ndf_covid = pd.DataFrame(dict_, columns=['paper_id', 'doi', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\ndf_covid.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:16:36.624129Z","iopub.execute_input":"2021-06-26T22:16:36.624442Z","iopub.status.idle":"2021-06-26T22:30:04.963331Z","shell.execute_reply.started":"2021-06-26T22:16:36.624412Z","shell.execute_reply":"2021-06-26T22:30:04.962479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_covid.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:30:04.964862Z","iopub.execute_input":"2021-06-26T22:30:04.965221Z","iopub.status.idle":"2021-06-26T22:30:04.982756Z","shell.execute_reply.started":"2021-06-26T22:30:04.965185Z","shell.execute_reply":"2021-06-26T22:30:04.981813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_covid.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing","metadata":{}},{"cell_type":"code","source":"df = df_covid\ndf.dropna(inplace=True)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:31:34.624339Z","iopub.execute_input":"2021-06-26T22:31:34.624646Z","iopub.status.idle":"2021-06-26T22:31:34.684095Z","shell.execute_reply.started":"2021-06-26T22:31:34.624616Z","shell.execute_reply":"2021-06-26T22:31:34.68327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install langdetect\n","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:32:15.343631Z","iopub.execute_input":"2021-06-26T22:32:15.343993Z","iopub.status.idle":"2021-06-26T22:32:25.070646Z","shell.execute_reply.started":"2021-06-26T22:32:15.343955Z","shell.execute_reply":"2021-06-26T22:32:25.069601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom langdetect import detect\nfrom langdetect import DetectorFactory\n\n# set seed\nDetectorFactory.seed = 0\n\n# hold label - language\nlanguages = []\n\n# go through each text\nfor ii in tqdm(range(0,len(df))):\n    # split by space into list, take the first x intex, join with space\n    text = df.iloc[ii]['body_text'].split(\" \")\n    \n    lang = \"en\"\n    try:\n        if len(text) > 50:\n            lang = detect(\" \".join(text[:50]))\n        elif len(text) > 0:\n            lang = detect(\" \".join(text[:len(text)]))\n    # ught... beginning of the document was not in a good format\n    except Exception as e:\n        all_words = set(text)\n        try:\n            lang = detect(\" \".join(all_words))\n        # what!! :( let's see if we can find any text in abstract...\n        except Exception as e:\n            \n            try:\n                # let's try to label it through the abstract then\n                lang = detect(df.iloc[ii]['abstract_summary'])\n            except Exception as e:\n                lang = \"unknown\"\n                pass\n    \n    # get the language    \n    languages.append(lang)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:32:25.072535Z","iopub.execute_input":"2021-06-26T22:32:25.07292Z","iopub.status.idle":"2021-06-26T22:33:16.047412Z","shell.execute_reply.started":"2021-06-26T22:32:25.072874Z","shell.execute_reply":"2021-06-26T22:33:16.046493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\n\nlanguages_dict = {}\nfor lang in set(languages):\n    languages_dict[lang] = languages.count(lang)\n    \nprint(\"Total: {}\\n\".format(len(languages)))\npprint(languages_dict)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:33:16.049116Z","iopub.execute_input":"2021-06-26T22:33:16.049516Z","iopub.status.idle":"2021-06-26T22:33:16.061118Z","shell.execute_reply.started":"2021-06-26T22:33:16.049452Z","shell.execute_reply":"2021-06-26T22:33:16.060159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['language'] = languages\ndf = df[df['language'] == 'en'] \ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:34:05.777901Z","iopub.execute_input":"2021-06-26T22:34:05.778272Z","iopub.status.idle":"2021-06-26T22:34:05.815767Z","shell.execute_reply.started":"2021-06-26T22:34:05.77824Z","shell.execute_reply":"2021-06-26T22:34:05.814719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz ","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:35:21.309386Z","iopub.execute_input":"2021-06-26T22:35:21.309713Z","iopub.status.idle":"2021-06-26T22:36:39.923668Z","shell.execute_reply.started":"2021-06-26T22:35:21.309682Z","shell.execute_reply":"2021-06-26T22:36:39.922747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nimport en_core_sci_lg","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:36:39.92709Z","iopub.execute_input":"2021-06-26T22:36:39.927366Z","iopub.status.idle":"2021-06-26T22:36:42.614583Z","shell.execute_reply.started":"2021-06-26T22:36:39.927335Z","shell.execute_reply":"2021-06-26T22:36:42.613673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\n\npunctuations = string.punctuation\nstopwords = list(STOP_WORDS)\nstopwords[:10]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:36:42.616235Z","iopub.execute_input":"2021-06-26T22:36:42.616763Z","iopub.status.idle":"2021-06-26T22:36:42.623457Z","shell.execute_reply.started":"2021-06-26T22:36:42.616704Z","shell.execute_reply":"2021-06-26T22:36:42.622537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_stop_words = [\n    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', \n    'al.', 'Elsevier', 'PMC', 'CZI'\n]\n\nfor w in custom_stop_words:\n    if w not in stopwords:\n        stopwords.append(w)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:36:59.453342Z","iopub.execute_input":"2021-06-26T22:36:59.453668Z","iopub.status.idle":"2021-06-26T22:36:59.461273Z","shell.execute_reply.started":"2021-06-26T22:36:59.453637Z","shell.execute_reply":"2021-06-26T22:36:59.460436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Parser\nparser = en_core_sci_lg.load(disable=[\"tagger\", \"ner\"])\nparser.max_length = 7000000\n\n\ndef spacy_tokenizer(sentence):\n    mytokens = parser(sentence)\n    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n    mytokens = \" \".join([i for i in mytokens])\n    return mytokens","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:51:50.555495Z","iopub.execute_input":"2021-06-26T22:51:50.555859Z","iopub.status.idle":"2021-06-26T22:51:56.520868Z","shell.execute_reply.started":"2021-06-26T22:51:50.555823Z","shell.execute_reply":"2021-06-26T22:51:56.520004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\ndf[\"processed_text\"] = df[\"body_text\"].progress_apply(spacy_tokenizer)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-26T22:51:58.63763Z","iopub.execute_input":"2021-06-26T22:51:58.638031Z","iopub.status.idle":"2021-06-26T23:26:55.890352Z","shell.execute_reply.started":"2021-06-26T22:51:58.637997Z","shell.execute_reply":"2021-06-26T23:26:55.889258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vectorization","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ndef vectorize(text, maxx_features):\n    \n    vectorizer = TfidfVectorizer(max_features=maxx_features)\n    X = vectorizer.fit_transform(text)\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:26:56.10451Z","iopub.execute_input":"2021-06-26T23:26:56.104852Z","iopub.status.idle":"2021-06-26T23:26:56.109283Z","shell.execute_reply.started":"2021-06-26T23:26:56.104819Z","shell.execute_reply":"2021-06-26T23:26:56.108167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = df['processed_text'].values\nmax_features = 2**12\n\nX = vectorize(text, max_features)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:27:12.149668Z","iopub.execute_input":"2021-06-26T23:27:12.150079Z","iopub.status.idle":"2021-06-26T23:27:27.939745Z","shell.execute_reply.started":"2021-06-26T23:27:12.150038Z","shell.execute_reply":"2021-06-26T23:27:27.938889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PCA & Clustering","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=0.95, random_state=42)\nX_reduced= pca.fit_transform(X.toarray())\nX_reduced.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:27:41.965213Z","iopub.execute_input":"2021-06-26T23:27:41.96554Z","iopub.status.idle":"2021-06-26T23:28:50.946828Z","shell.execute_reply.started":"2021-06-26T23:27:41.965507Z","shell.execute_reply":"2021-06-26T23:28:50.946003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans\nfrom sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:29:03.796958Z","iopub.execute_input":"2021-06-26T23:29:03.797268Z","iopub.status.idle":"2021-06-26T23:29:03.869764Z","shell.execute_reply.started":"2021-06-26T23:29:03.797239Z","shell.execute_reply":"2021-06-26T23:29:03.868996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom scipy.spatial.distance import cdist\n\n# run kmeans with many different k\ndistortions = []\nK = range(2, 30)\nfor k in K:\n    k_means = KMeans(n_clusters=k, random_state=42).fit(X_reduced)\n    k_means.fit(X_reduced)\n    distortions.append(sum(np.min(cdist(X_reduced, k_means.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n    #print('Found distortion for {} clusters'.format(k))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:29:06.733704Z","iopub.execute_input":"2021-06-26T23:29:06.734053Z","iopub.status.idle":"2021-06-26T23:56:18.541577Z","shell.execute_reply.started":"2021-06-26T23:29:06.734021Z","shell.execute_reply":"2021-06-26T23:56:18.540606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_line = [K[0], K[-1]]\nY_line = [distortions[0], distortions[-1]]\n\n# Plot the elbow\nplt.plot(K, distortions, 'b-')\nplt.plot(X_line, Y_line, 'r')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:56:18.542965Z","iopub.execute_input":"2021-06-26T23:56:18.543288Z","iopub.status.idle":"2021-06-26T23:56:18.711129Z","shell.execute_reply.started":"2021-06-26T23:56:18.543253Z","shell.execute_reply":"2021-06-26T23:56:18.710163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-> Lựa conhj k=20","metadata":{}},{"cell_type":"code","source":"k = 20\nkmeans = KMeans(n_clusters=k, random_state=42)\ny_pred = kmeans.fit_predict(X_reduced)\ndf['y'] = y_pred","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:56:38.960532Z","iopub.execute_input":"2021-06-26T23:56:38.960897Z","iopub.status.idle":"2021-06-26T23:57:13.661677Z","shell.execute_reply.started":"2021-06-26T23:56:38.960854Z","shell.execute_reply":"2021-06-26T23:57:13.660777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n\ntsne = TSNE(verbose=1, perplexity=50)  # Changed perplexity from 100 to 50 per FAQ\nX_embedded = tsne.fit_transform(X.toarray())","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:57:13.663143Z","iopub.execute_input":"2021-06-26T23:57:13.663665Z","iopub.status.idle":"2021-06-26T23:58:45.347345Z","shell.execute_reply.started":"2021-06-26T23:57:13.663623Z","shell.execute_reply":"2021-06-26T23:58:45.346475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\n# sns settings\nsns.set(rc={'figure.figsize':(15,15)})\n\n# colors\npalette = sns.color_palette(\"bright\", 1)\n\n# plot\nsns.scatterplot(X_embedded[:,0], X_embedded[:,1], palette=palette)\nplt.title('t-SNE with no Labels')\nplt.savefig(\"t-sne_covid19.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T23:59:50.900997Z","iopub.execute_input":"2021-06-26T23:59:50.901343Z","iopub.status.idle":"2021-06-26T23:59:51.434437Z","shell.execute_reply.started":"2021-06-26T23:59:50.901312Z","shell.execute_reply":"2021-06-26T23:59:51.433648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# sns settings\nsns.set(rc={'figure.figsize':(13,9)})\n\n# colors\npalette = sns.hls_palette(20, l=.4, s=.9)\n\n# plot\nsns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\nplt.title('t-SNE with Kmeans Labels')\nplt.savefig(\"improved_cluster_tsne.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T00:00:01.698429Z","iopub.execute_input":"2021-06-27T00:00:01.698773Z","iopub.status.idle":"2021-06-27T00:00:04.160504Z","shell.execute_reply.started":"2021-06-27T00:00:01.698723Z","shell.execute_reply":"2021-06-27T00:00:04.159637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-27T00:01:15.162207Z","iopub.execute_input":"2021-06-27T00:01:15.162529Z","iopub.status.idle":"2021-06-27T00:01:15.167523Z","shell.execute_reply.started":"2021-06-27T00:01:15.162498Z","shell.execute_reply":"2021-06-27T00:01:15.166481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}