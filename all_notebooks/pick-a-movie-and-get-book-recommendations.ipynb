{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pick a movie, and get some book recommendations\n### In this notebook we will work on a content based recommendation system. we use two different datasets, one for movies([the movies dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset)), the other one for books ([top2k book descriptions](https://www.kaggle.com/yehyachali/top2k-books-with-descriptions)).\n### I used Goodreads API to download descriptions for 2000 most rated books.(soon I will update the dataset with 10K descriptions)\n![](https://media.giphy.com/media/cw80NAWi858lO/giphy.gif)\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies = pd.read_csv(\"../input/the-movies-dataset/movies_metadata.csv\")\nprint(movies.columns)\nmovies.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies['genres'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"as you can see the genres in Movies dataset are in a dictionary format however the type is string. I will use literal_eval function to get the dictionary, then all we need is to select names of the genres.","metadata":{}},{"cell_type":"code","source":"movies['genres'] = movies['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll add genres and sub-genres or keywords to our soup. we already have genres, now we need to get the keywords.","metadata":{}},{"cell_type":"code","source":"keywords = pd.read_csv('../input/the-movies-dataset/keywords.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keywords.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_ids(x):\n    try:\n        return int(x)\n    except:\n        return np.nan\n\nmovies['id'] = movies['id'].apply(clean_ids)\nmovies = movies[movies['id'].notnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Joining movies and keywords dataframes","metadata":{}},{"cell_type":"code","source":"movies['id'] = movies['id'].astype('int')\nkeywords['id'] = keywords['id'].astype('int')\n\nmovies = movies.merge(keywords, on='id')\n\nmovies.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies[\"keywords\"][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"same as the genres, we need to convert them from string to dictionary.","metadata":{}},{"cell_type":"code","source":"movies[\"keywords\"] = movies[\"keywords\"].apply(literal_eval)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"generate_list function will help you to select as many keywords you need.","metadata":{}},{"cell_type":"code","source":"def generate_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        if len(names) > 10:\n            names = names[:10]\n        return names\n    return []\n\nmovies['keywords'] = movies['keywords'].apply(generate_list)\nmovies['genres'] = movies['genres'].apply(lambda x: x[:10])\n\nmovies[['title', 'keywords', 'genres']].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have to change them back to string tokens so that we can add them all to our soup.","metadata":{}},{"cell_type":"code","source":"def sanitize(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(' ','')) for i in x]\n    else:\n        if isinstance(x, str):\n            return str.lower(x.replace(' ', ''))\n        else:\n            return ''\n\nfor feature in ['genres', 'keywords']:\n    movies[feature] = movies[feature].apply(sanitize)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our soup for movies includes the name of the movie, genres, overview, and the keywords(or sub-genres)","metadata":{}},{"cell_type":"code","source":"\ndef movie_soup(x):\n    return  x[\"title\"] + \" \" + \" \".join(x['genres']) + \" \"+x['overview']+\" \"+\" \".join(x['keywords'])\n\nmovies['overview'] = movies['overview'].fillna('')\nmovies['title'] = movies['title'].fillna('')\nmovies['soup'] = movies.apply(movie_soup, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies.loc[movies['title']==\"The Matrix\",'soup'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books = pd.read_csv(\"../input/top2k-books-with-descriptions/top2k_book_descriptions.csv\", index_col=0)\nprint(books.columns)\nbooks.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books['tag_name'][1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"converting tag_name from string to list.<br>\nand we can't have our soup ready without description and tag_names, at least we must have one.","metadata":{}},{"cell_type":"code","source":"books['tag_name'] = books['tag_name'].apply(lambda x: literal_eval(x) if literal_eval(x) else np.nan)\nbooks = books[books['description'].notnull() | books['tag_name'].notnull()]\nbooks = books.fillna('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our soup for books includes the title, description, tag names(or book shelves) and author(s)","metadata":{}},{"cell_type":"code","source":"def book_soup(x):\n    soup = x[\"original_title\"]+\" \"+x[\"description\"]+\" \"+\" \".join(x['tag_name'])+\" \"+x[\"authors\"]\n    return soup","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books[\"soup\"] = books.apply(book_soup, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is ready, we have our soups!<br>\nnow all we have to do is to vectorize the data. And because our soup includes genres and tag names, I think it is better if we use Count vectorizer.<br>\nthis is how it works\n![](https://www.educative.io/api/edpresso/shot/5197621598617600/image/6596233398321152)","metadata":{}},{"cell_type":"code","source":"\nsoups = pd.concat([movies['soup'],books['soup']],ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ncount = CountVectorizer(stop_words = \"english\")\ncount.fit(soups)\n\nmovies_matrix = count.transform(movies['soup'])\nbooks_matrix = count.transform(books['soup'])\n\nbooks_matrix.shape, movies_matrix.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the most important part of this recommendation system is to find the similarities between these vectors.<br> \nI am going to use Cosine_similarity formula.\n![](https://miro.medium.com/max/875/1*r5ULMbx7ju3_Y4TU1PJIyQ.png)\nBy applying the definition of similarity, this will be in fact equal to 1 if the two vectors are identical, and it will be 0 if the two are orthogonal. In other words, the similarity is a number bounded between 0 and 1 that tells us how much the two vectors are similar.","metadata":{}},{"cell_type":"code","source":"cosine_sim = cosine_similarity(movies_matrix, books_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"to make the search easier, I change the index to the title column, that way I will get the index of the movie I am searching for.","metadata":{}},{"cell_type":"code","source":"movies = movies.reset_index()\nindices = pd.Series(movies.index, index=movies['title'].apply(lambda x: x.lower() if x is not np.nan else \"\")).drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ahh.. finally we have our Content based Recommendation system<br>\nit will select the first 10 books that are most similar to the movie you search for","metadata":{}},{"cell_type":"code","source":"def content_recommender(title):\n    idx = indices[title.lower()]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse=True)\n    \n    sim_scores = sim_scores[:10]\n\n    book_indices = [i[0] for i in sim_scores]\n\n    return books.iloc[book_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n!pip3 install -q ipywidgets\n!jupyter nbextension enable --py --sys-prefix widgetsnbextension\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>these are the top book recommendations for the movie <b>I, Robot</b></h2>","metadata":{}},{"cell_type":"code","source":"import ipywidgets\nfrom IPython.display import HTML\ndef showhtml(recommendations):\n    html = ' '.join([f\"\"\"\n     <div class=\"flip-card\">\n      <div class=\"flip-card-inner\">\n        <div class=\"flip-card-front\">\n          <img src=\"{recommendations.iloc[i]['image_url']}\" alt=\"Avatar\" style=\"width:300px;height:300px;\">\n        </div>\n        <div class=\"flip-card-back\">\n          <h4>{recommendations.iloc[i]['title']}</h4>\n          <p>by {recommendations.iloc[i]['authors']}</p>\n        </div>\n      </div>\n    </div> \"\"\" for i in range(10)])\n    html = \"<div class='grid'>\"+html+\"</div>\"\n    html +=\"\"\"<style>\n    .flip-card {\n      background-color: transparent;\n      width: 200px;\n      height: 300px;\n      border: 1px solid #f1f1f1;\n    }\n\n    .flip-card-inner {\n      position: relative;\n      width: 100%;\n      height: 100%;\n      text-align: center;\n      transition: transform 0.8s;\n      transform-style: preserve-3d;\n    }\n\n    .flip-card:hover .flip-card-inner {\n      transform: rotateY(180deg);\n    }\n\n    .flip-card-front, .flip-card-back {\n      position: absolute;\n      width: 100%;\n      height: 100%;\n      -webkit-backface-visibility: hidden; /* Safari */\n      backface-visibility: hidden;\n    }\n\n    .flip-card-front {\n      background-color: #bbb;\n      color: black;\n    }\n\n    .flip-card-back {\n    padding:10px;\n      background-color: dodgerblue;\n      color: white;\n      transform: rotateY(180deg);\n    }\n    .grid {\n        display: grid;\n        grid-template-columns: 30% 30% 30%;\n        grid-template-rows: 25% 25% 25%;\n        grid-gap: 5%;\n    }\n    </style>\"\"\"\n    return html\n\n\ndef show_books(movie_name='I, robot'):\n    recommendations = content_recommender(movie_name)\n#     for i in range(10):\n#         disPic(recommendations[\"image_url\"].iloc[i])\n#         print(recommendations[\"original_title\"].iloc[i])\n#         print(recommendations[\"description\"].iloc[i])\n    display(HTML(showhtml(recommendations)))\ndisplay(ipywidgets.interact(show_books))\n\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}