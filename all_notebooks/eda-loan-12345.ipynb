{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Import neccesary libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport os\nimport re\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score,roc_auc_score, roc_curve, auc, precision_score\n%matplotlib inline\nmatplotlib.rcParams.update({'font.size': 20})\nfrom sklearn.decomposition import PCA\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTETomek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read Data\ntrain = pd.read_csv('../input/train.csv', infer_datetime_format=True)\ntest = pd.read_csv('../input/test.csv', infer_datetime_format=True)\n# des = pd.read_excel('./Data Dictionary.xlsx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check train test \nprint(train.shape)\nprint(test.shape)\n\n#Drop duplicates\n# test.drop_duplicates()\n# No duplicates in data\n# print(test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loan_default.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop null values as this data is too sparse with 0 as most values\n# train.dropna(inplace=True)\n# test.dropna(inplace=True)\nprint(train.shape)\nprint(test.shape)\n# print(train.isnull().sum().sum())\n\n# print(test.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"def credit_risk(df):\n    d1=[]\n    d2=[]\n    for i in df:\n        p = i.split(\"-\")\n        if len(p) == 1:\n            d1.append(p[0])\n            d2.append('unknown')\n        else:\n            d1.append(p[1])\n            d2.append(p[0])\n\n    return d1,d2\n\ndef calc_number_of_ids(row):\n#     print(type(row), row.size)\n    return sum(row[['Aadhar_flag', 'PAN_flag', 'VoterID_flag', 'Driving_flag',\n       'Passport_flag']])\n\ndef check_pri_installment(row):\n    if row['PRIMARY.INSTAL.AMT']<=1:\n        return 0\n    else:\n        return row['PRIMARY.INSTAL.AMT']\n    \ndef plot_2d_space(X, y, label='Classes'):   \n    colors = ['#1F77B4', '#FF7F0E']\n    markers = ['o', 's']\n    for l, c, m in zip(np.unique(y), colors, markers):\n        plt.scatter(\n            X[y==l, 0],\n            X[y==l, 1],\n            c=c, label=l, marker=m\n        )\n    plt.title(label)\n    plt.legend(loc='upper right')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"risk_map = {'No Bureau History Available':-1, \n              'Not Scored: No Activity seen on the customer (Inactive)':-1,\n              'Not Scored: Sufficient History Not Available':-1,\n              'Not Scored: No Updates available in last 36 months':-1,\n              'Not Scored: Only a Guarantor':-1,\n              'Not Scored: More than 50 active Accounts found':-1,\n              'Not Scored: Not Enough Info available on the customer':-1,\n              'Very Low Risk':4,\n              'Low Risk':3,\n              'Medium Risk':2, \n              'High Risk':1,\n              'Very High Risk':0}\n\nsub_risk = {'unknown':-1, 'I':5, 'L':2, 'A':13, 'D':10, 'M':1, 'B':12, 'C':11, 'E':9, 'H':6, 'F':8, 'K':3,\n       'G':7, 'J':4}\nemployment_map = {'Self employed':0, 'Salaried':1,np.nan:-1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_engineering(df):\n    print('feature engineering started')\n    df['DisbursalDate'] = pd.to_datetime(df['DisbursalDate'], format = \"%d-%m-%y\",infer_datetime_format=True)\n    df['Date.of.Birth'] = pd.to_datetime(df['Date.of.Birth'], format = \"%d-%m-%y\",infer_datetime_format=True)\n    now = pd.Timestamp('now')\n    df['Age'] = (now - df['Date.of.Birth']).astype('<m8[Y]').astype(int)\n    age_mean = int(df[df['Age']>0]['Age'].mean())\n    df.loc[:,'age'] = df['Age'].apply(lambda x: x if x>0 else age_mean)\n    df['disbursal_months_passed'] = ((now - df['DisbursalDate'])/np.timedelta64(1,'M')).astype(int)\n    df['average_act_age_in_months'] = df['AVERAGE.ACCT.AGE'].apply(lambda x : int(re.findall(r'\\d+',x)[0])*12 + int(re.findall(r'\\d+',x)[1]))\n    df['credit_history_length_in_months'] = df['CREDIT.HISTORY.LENGTH'].apply(lambda x : int(re.findall(r'\\d+',x)[0])*12 + int(re.findall(r'\\d+',x)[1]))\n    df['number_of_0'] = (df == 0).astype(int).sum(axis=1)\n    \n    df.loc[:,'credit_risk'],df.loc[:,'credit_risk_grade']  = credit_risk(df[\"PERFORM_CNS.SCORE.DESCRIPTION\"])\n    \n    df.loc[:, 'loan_to_asset_ratio'] = df['disbursed_amount'] /df['asset_cost']\n    df.loc[:,'no_of_accts'] = df['PRI.NO.OF.ACCTS'] + df['SEC.NO.OF.ACCTS']\n\n    df.loc[:,'pri_inactive_accts'] = df['PRI.NO.OF.ACCTS'] - df['PRI.ACTIVE.ACCTS']\n    df.loc[:,'sec_inactive_accts'] = df['SEC.NO.OF.ACCTS'] - df['SEC.ACTIVE.ACCTS']\n    df.loc[:,'tot_inactive_accts'] = df['pri_inactive_accts'] + df['sec_inactive_accts']\n    df.loc[:,'tot_overdue_accts'] = df['PRI.OVERDUE.ACCTS'] + df['SEC.OVERDUE.ACCTS']\n    df.loc[:,'tot_current_balance'] = df['PRI.CURRENT.BALANCE'] + df['SEC.CURRENT.BALANCE']\n    df.loc[:,'tot_sanctioned_amount'] = df['PRI.SANCTIONED.AMOUNT'] + df['SEC.SANCTIONED.AMOUNT']\n    df.loc[:,'tot_disbursed_amount'] = df['PRI.DISBURSED.AMOUNT'] + df['SEC.DISBURSED.AMOUNT']\n    df.loc[:,'tot_installment'] = df['PRIMARY.INSTAL.AMT'] + df['SEC.INSTAL.AMT']\n    df.loc[:,'bal_disburse_ratio'] = np.round((1+df['tot_disbursed_amount'])/(1+df['tot_current_balance']),2)\n    df.loc[:,'pri_tenure'] = (df['PRI.DISBURSED.AMOUNT']/( df['PRIMARY.INSTAL.AMT']+1)).astype(int)\n    df.loc[:,'sec_tenure'] = (df['SEC.DISBURSED.AMOUNT']/(df['SEC.INSTAL.AMT']+1)).astype(int)\n#     df.loc[:,'tenure_to_age_ratio'] =  np.round((df['pri_tenure']/12)/df['age'],2)\n    df.loc[:,'disburse_to_sactioned_ratio'] =  np.round((df['tot_disbursed_amount']+1)/(1+df['tot_sanctioned_amount']),2)\n    df.loc[:,'active_to_inactive_act_ratio'] =  np.round((df['no_of_accts']+1)/(1+df['tot_inactive_accts']),2)\n    print('done')\n#     df.loc[:,'']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_data(df):\n    print('labeling started')\n    df.loc[:,'credit_risk_label'] = df['credit_risk'].apply(lambda x: risk_map[x])\n    df.loc[:,'sub_risk_label'] = df['credit_risk_grade'].apply(lambda x: sub_risk[x])\n    df.loc[:,'employment_label'] = df['Employment.Type'].apply(lambda x: employment_map[x])\n    print('labeling done')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_correction(df):\n    print('invalid data handling started')\n    #Many customers have invalid date of birth, so immute invalid data with mean age\n    df.loc[:,'PRI.CURRENT.BALANCE'] = df['PRI.CURRENT.BALANCE'].apply(lambda x: 0 if x<0 else x)\n    df.loc[:,'SEC.CURRENT.BALANCE'] = df['SEC.CURRENT.BALANCE'].apply(lambda x: 0 if x<0 else x)\n    \n    #loan that do not have current pricipal outstanding should have 0 primary installment\n    df.loc[:,'new_pri_installment']= df.apply(lambda x : check_pri_installment(x),axis=1)\n    print('done')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(df):\n    df = data_correction(df)\n    df = features_engineering(df)\n    df = label_data(df)\n\n    return df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare training and test data\ntrain_data = prepare_data(train)\ntrain_data = train_data[train_data['number_of_0']<=25]\ntest_data = prepare_data(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data['number_of_0']>=20]['number_of_0'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_drop = ['UniqueID', 'ltv', 'branch_id',\n       'supplier_id', 'manufacturer_id', 'Current_pincode_ID', 'Date.of.Birth',\n       'Employment.Type', 'DisbursalDate', 'State_ID', 'Employee_code_ID',\n       'MobileNo_Avl_Flag', 'PRIMARY.INSTAL.AMT',\n       'PERFORM_CNS.SCORE.DESCRIPTION',\n       'AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH', \n       'loan_default', 'Age',  'credit_risk', 'credit_risk_grade',\n       ]\nfeatures = ['disbursed_amount', 'asset_cost',\n            'Aadhar_flag', 'PAN_flag',\n       'PERFORM_CNS.SCORE',\n             'PRI.ACTIVE.ACCTS',\n       'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT',\n       'PRI.DISBURSED.AMOUNT',  'SEC.ACTIVE.ACCTS',\n       'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE', 'SEC.SANCTIONED.AMOUNT',\n       'SEC.DISBURSED.AMOUNT',  'SEC.INSTAL.AMT',\n       'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',\n            'NO.OF_INQUIRIES','disbursal_months_passed',\n       'average_act_age_in_months', 'credit_history_length_in_months',\n       'number_of_0','loan_to_asset_ratio', 'no_of_accts', 'pri_inactive_accts',\n       'sec_inactive_accts', 'tot_inactive_accts', 'tot_overdue_accts',\n       'tot_current_balance', 'tot_sanctioned_amount', 'tot_disbursed_amount',\n       'tot_installment', 'bal_disburse_ratio', 'pri_tenure', 'sec_tenure',\n       'credit_risk_label',\n       'employment_label', 'age', 'new_pri_installment'\n           ]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import  RobustScaler\n# std_scaler = StandardScaler()\n# RobustScaler is less prone to outliers.\nrob_scaler = RobustScaler()\n\nscaled_training = train_data.copy()\nscaled_testing = test_data.copy()\n\n\nscaled_training[features] = rob_scaler.fit_transform(scaled_training[features])\nscaled_testing[features] = rob_scaler.fit_transform(scaled_testing[features])\n\ny = scaled_training.loan_default\nX = scaled_training[features]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting up testing and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27,stratify=y)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape,y_test.shape)\nsm = SMOTE(random_state=2)\nX_train, y_train = sm.fit_sample(X_train, y_train.ravel())\nprint(X_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Prepare data for modeling\n# Separate input features and target\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_2d_space(X, y, 'Imbalanced dataset (2 PCA components)')\n#Fitting the PCA algorithm with our Data\npca = PCA(n_components=7).fit(X)\nX = pca.fit_transform(X)\nX = pd.DataFrame(X, columns = ['p1','p2','p3','p4','p5','p6','p7'])\ntest_df = pd.DataFrame(pca.fit_transform(scaled_testing[features]), columns = ['p1','p2','p3','p4','p5','p6','p7'])\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure(figsize=(15,5))\nplt.plot(np.cumsum(pca.explained_variance_ratio_), 'r-')\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\nplt.title('L& T Loan Dataset Explained Variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # setting up testing and training sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test['number_of_0'].value_counts()\n# Drop row having more than 50 % data as 0\n# train_data = train[train['number_of_0']<=20]\n# test_data = test[test['number_of_0']<=20]\n# train_data = train.copy()\n# test_data = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2 , figsize=(20, 7), sharex=True)\n# sns.despine(left=True)\nsns.distplot(train['asset_cost'],kde = False, color=\"b\", ax=axes[0])\nsns.distplot(test['asset_cost'],kde = False, color=\"r\", ax=axes[1])\n\n\n# plt.pyplot.setp(axes, yticks=[])\n# plt.pyplot.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2 , figsize=(20, 7), sharex=True)\n# sns.despine(left=True)\nsns.distplot(train['ltv'],kde = False, color=\"b\", ax=axes[0])\nsns.distplot(test['ltv'],kde = False, color=\"r\", ax=axes[1])\n# train['ltv'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,1,figsize=(4.5, 5))\nsns.countplot(train['Aadhar_flag'],  palette=\"Set3\").set_title('Aadhar count')\nfig, ax =plt.subplots(1,2,figsize=(10, 5))\n# fig, ax =plt.subplots(2,2,figsize=(10, 10))\n# sns.countplot(train['Aadhar_flag'], ax=ax[0,0],  palette=\"Set3\")\n# sns.countplot(test['Aadhar_flag'], ax=ax[0,1],  palette=\"Set3\")\nsns.countplot(train[train['Aadhar_flag']==1]['loan_default'], ax=ax[0], palette=\"Set3\").set_title('Aadhar=1')\nsns.countplot(train[train['Aadhar_flag']==0]['loan_default'], ax=ax[1],  palette=\"Set3\").set_title('Aadhar=0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,1,figsize=(4.5, 5))\nsns.countplot(train['PAN_flag'],  palette=\"Set3\").set_title('PAN count')\nfig, ax =plt.subplots(1,2,figsize=(10, 5))\n# sns.countplot(test['PAN_flag'], ax=ax[0,1] ,palette=\"Set3\")\n# sns.countplot(train[train['PAN_flag']==1]['loan_default'], ax=ax[0,0],palette=\"Set3\").set_title(\"LaLaLa\")\n# sns.countplot(train[train['PAN_flag']==0]['loan_default'], ax=ax[0,1],palette=\"Set3\")\nsns.countplot(train[train['PAN_flag']==1]['loan_default'], ax=ax[0],palette=\"Set3\").set_title(\"PAN=1\")\nsns.countplot(train[train['PAN_flag']==0]['loan_default'], ax=ax[1],palette=\"Set3\").set_title(\"PAN=0\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,1,figsize=(4.5, 5))\nsns.countplot(train['VoterID_flag'],  palette=\"Set3\").set_title('VoterID count')\nfig, ax =plt.subplots(1,2,figsize=(10, 5))\n# sns.countplot(test['PAN_flag'], ax=ax[0,1] ,palette=\"Set3\")\n# sns.countplot(train[train['PAN_flag']==1]['loan_default'], ax=ax[0,0],palette=\"Set3\").set_title(\"LaLaLa\")\n# sns.countplot(train[train['PAN_flag']==0]['loan_default'], ax=ax[0,1],palette=\"Set3\")\nsns.countplot(train[train['VoterID_flag']==1]['loan_default'], ax=ax[0],palette=\"Set3\").set_title(\"VoterID=1\")\nsns.countplot(train[train['VoterID_flag']==0]['loan_default'], ax=ax[1],palette=\"Set3\").set_title(\"VoterID=0\")\n#######\n# fig, ax =plt.subplots(2,2,figsize=(10, 10))\n# sns.countplot(train['VoterID_flag'], ax=ax[0,0])\n# sns.countplot(test['VoterID_flag'], ax=ax[0,1])\n# sns.countplot(train[train['VoterID_flag']==1]['loan_default'], ax=ax[1,0])\n# sns.countplot(train[train['VoterID_flag']==0]['loan_default'], ax=ax[1,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(2,2,figsize=(10, 10))\nsns.countplot(train['Driving_flag'], ax=ax[0,0])\nsns.countplot(test['Driving_flag'], ax=ax[0,1])\nsns.countplot(train[train['Driving_flag']==1]['loan_default'], ax=ax[1,0])\nsns.countplot(train[train['Driving_flag']==0]['loan_default'], ax=ax[1,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(2,2,figsize=(10, 10))\nsns.countplot(train['Passport_flag'], ax=ax[0,0])\nsns.countplot(test['Passport_flag'], ax=ax[0,1])\nsns.countplot(train[train['Passport_flag']==1]['loan_default'], ax=ax[1,0])\nsns.countplot(train[train['Passport_flag']==0]['loan_default'], ax=ax[1,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model):\n    # Checking accuracy\n    model = model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    print('accuracy_score',accuracy_score(y_test, pred))\n    print('precision_score',precision_score(y_test, pred))\n    print('recall_score',recall_score(y_test, pred))\n    print('f1_score',f1_score(y_test, pred))\n    print('roc_auc_score',roc_auc_score(y_test, pred))\n    # confusion matrix\n    print('confusion_matrix')\n    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modeling the data as is\n# Train model\n# xgb = XGBClassifier()\n\n# xgb = train_model(xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from xgboost import plot_importance\n# from matplotlib import pyplot\n# # plot feature importance\n# plot_importance(xgb)\n# pyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nrfc = RandomForestClassifier()\nrfc = train_model(rfc)\n# predict on test set\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt_clf = DecisionTreeClassifier(random_state=0)\ndt_clf = train_model(dt_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxgb_clf=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\nxgb_clf = train_model(xgb_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\ndef train_using_svm(param_set):\n#     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n    best_accuracy = 0\n    best_hyperparam = {}\n    svcs = {}\n    for param in param_set:\n        print(\"#################\")\n        svcs[str(param)] = SVC(kernel = param[\"kernel\"], C = param[\"C\"], degree = param[\"degree\"], gamma = \"scale\")\n        svcs[str(param)] = train_model(svcs[str(param)])\n        print(\"###################\")\n#     print(\"best parameter\",best_hyperparam)\n#     return best_accuracy\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_set = [\n#     {'kernel': 'rbf', 'C': 1, 'degree': 1},\n              {'kernel': 'rbf', 'C': 3, 'degree': 1},\n#               {'kernel': 'rbf', 'C': 5, 'degree': 1},\n#               {'kernel': 'rbf', 'C': 10, 'degree': 1},\n#               {'kernel': 'rbf', 'C': 50, 'degree': 1},\n\n              {'kernel': 'linear', 'C': 1, 'degree': 1},\n              {'kernel': 'linear', 'C': 3, 'degree': 1},\n#               {'kernel': 'linear', 'C': 5, 'degree': 1},\n#               {'kernel': 'linear', 'C': 10, 'degree': 1},\n#               {'kernel': 'linear', 'C': 50, 'degree': 1},\n\n              {'kernel': 'poly', 'C': 1, 'degree': 1},\n              {'kernel': 'poly', 'C': 1, 'degree': 2},\n#               {'kernel': 'poly', 'C': 1, 'degree': 4},\n              {'kernel': 'poly', 'C': 3, 'degree': 1},\n              {'kernel': 'poly', 'C': 3, 'degree': 2},\n#               {'kernel': 'poly', 'C': 3, 'degree': 4},\n#               {'kernel': 'poly', 'C': 5, 'degree': 1},\n#               {'kernel': 'poly', 'C': 5, 'degree': 2},\n#               {'kernel': 'poly', 'C': 5, 'degree': 4}\n            ]\ntrain_using_svm(param_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train = lgb.Dataset(X_train, label=y_train)\nparams = {}\n\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'binary'\nparams['metric'] = 'binary_logloss'\nparams['sub_feature'] = 0.5\nparams['num_leaves'] = 10\nparams['min_data'] = 50\nparams['max_depth'] = 10\nclf = lgb.train(params, d_train, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=clf.predict(X_test)\nfor i in range(len(pred)):\n    if pred[i]>=.4:       # setting threshold to .5\n        pred[i]=1\n    else:  \n        pred[i]=0\nprint('accuracy_score',accuracy_score(y_test, pred))\nprint('recall_score',recall_score(y_test, pred))\nprint('f1_score',f1_score(y_test, pred))\nprint('roc_auc_score',roc_auc_score(y_test, pred))\n# confusion matrix\nprint('confusion_matrix')\nprint(pd.DataFrame(confusion_matrix(y_test, pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# f = ['p1','p2','p3','p4','p5']\n# fi = xgb.feature_importances_\n# rfi = rfc.feature_importances_\n# xgbfi = pd.DataFrame({'features':f,'xgb_importance':fi, 'rf_importance':rfi})\n# xgbfi.sort_values(by=['rf_importance'],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_parameters = gd_sr.best_params_  \n# print(best_parameters)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_result = gd_sr.best_score_  \n# print(best_result)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_id = scaled_testing.UniqueID\ny_pred_rf = rfc.predict(scaled_testing[features])\nsubmission1 = pd.DataFrame({'UniqueID': unique_id,'loan_default': y_pred_rf})\nsubmission1.head()\n\n# unique_id = testing.UniqueID\n# y_pred_rf = xgb.predict(testing.drop(to_drop_test, axis=1))\n# submission2 = pd.DataFrame({'UniqueID': unique_id,'loan_default': y_pred_rf})\n# submission2.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'submission_rf.csv'\n\nsubmission1.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)\n\n# filename1 = 'submission_xgb.csv'\n\n# submission2.to_csv(filename1,index=False)\n\n# print('Saved file: ' + filename1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}