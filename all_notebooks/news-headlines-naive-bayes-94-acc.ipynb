{"cells":[{"metadata":{"_cell_guid":"e45fa26c-5b46-d737-6486-2b7f4de1c915"},"cell_type":"markdown","source":"The UCI ML News Aggregator Dataset contains headlines and categories for over 400k news articles. Let's see if we can accurately classify the news category based just on the headline.\n\nWe'll use a [Multinomial Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) model to classify the headlines. Multinomial Naive Bayes models are provided in Python by the [scikit-learn library](http://scikit-learn.org/stable/modules/naive_bayes.html)."},{"metadata":{"_cell_guid":"a12bb00d-8b76-ef20-38fd-8777b9c10cba","trusted":true},"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nimport string\n\n\n# grab the data\nnews = pd.read_csv(\"../input/uci-news-aggregator.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0db96719-79c5-b270-a349-ed9723f8b838","trusted":true},"cell_type":"code","source":"news.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0e2df6cf-eee7-0e5c-9000-bf624af694fa","trusted":true},"cell_type":"code","source":"def normalize_text(s):\n    \n\n    s = s.lower()\n    \n    s = re.sub('(https?:\\/\\/)(\\s)?(www\\.)?(\\s?)(\\w+\\.)*([\\w\\-\\s]+\\/)*([\\w-]+)\\/?',' ',s)\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W\\s',' ',s)\n    s = re.sub(\"[0-9]+\", \" \",s)\n    s = re.sub(r\"\\b[a-z]\\b\", \" \", s)\n    \n    for ch in string.punctuation:                                                                                                     \n        s = s.replace(ch, \" \")\n    s = re.sub('\\s+',' ',s)\n    \n        \n    s = s.strip()\n    \n    #print(s)\n    \n    \n    return s\n\nnews['TITLE'] = [normalize_text(s) for s in news['TITLE']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = [len(s) for s in news['TITLE']]\nprint(np.min(lens), np.mean(lens), np.max(lens))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pull the data into vectors\nencoder = LabelEncoder()\n\nx = news['TITLE']\ny = encoder.fit_transform(news['CATEGORY'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data splitting"},{"metadata":{"_cell_guid":"20de11e1-fddb-288f-de82-8a9cc15d9338","trusted":true},"cell_type":"code","source":"# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, stratify=y_train, random_state=42)\n\n# take a look at the shape of each of these\nprint(\"trainining size:\", x_train.shape[0])\nprint(\"validation size:\", x_val.shape[0])\nprint(\"testing size:\", x_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model construction and validation"},{"metadata":{"_cell_guid":"971e7969-766c-e75b-4ae8-b09ce26b33df","trusted":true},"cell_type":"code","source":"vectorizer = Pipeline([\n    ('count', CountVectorizer(min_df=3, binary=False, ngram_range=(1,3), stop_words='english')),\n    ('tfid', TfidfTransformer())]).fit(x_train)\n\n\nx_train_vec = vectorizer.transform(x_train)\nx_val_vec = vectorizer.transform(x_val)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = MultinomialNB(alpha=0.1)\nnb.fit(x_train_vec, y_train)\nprint('validation accuracy:', np.sum(nb.predict(x_val_vec)==y_val)/len(y_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final test"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_vec = vectorizer.transform(x_test)\nprint('test accuracy:', np.sum(nb.predict(x_test_vec)==y_test)/len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}