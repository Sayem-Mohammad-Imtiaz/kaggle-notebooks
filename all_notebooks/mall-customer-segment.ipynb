{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualsion\nimport seaborn as sns # data visualsion\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Impot the dataset\ndf = pd.read_csv('../input/Mall_Customers.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets a quick look of our dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the statistical inference of the dataset\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check if any missing value in our dataset\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count Plot of Gender\nplt.figure(1 , figsize = (10 , 5))\nsns.countplot(x = 'Gender' , data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look the distribution of the Annual Income\nsns.set(style = 'whitegrid')\nsns.distplot(df['Annual Income (k$)'], color = 'blue')\nplt.title('Distribution of Annual Income', fontsize = 20)\nplt.xlabel('Range of Annual Income')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that most of Mall Customers have Annual Income around 50k-75k doller."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now look the distribution of Age\nsns.set(style = 'whitegrid')\nsns.distplot(df['Age'], color = 'red')\nplt.title('Distribution of Age', fontsize = 20)\nplt.xlabel('Range of Age')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice that most of regular customers have age around 30-40 i.e middle age. On the other hand elder and youngstres are not regular customers.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now look the distribution of Spending Score\nsns.set(style = 'whitegrid')\nsns.distplot(df['Spending Score (1-100)'], color = 'green')\nplt.title('Spending Score (1-100)', fontsize = 20)\nplt.xlabel('Range of Spending Score (1-100)')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now look the correlation by ploting heatmap\ncorr = df.corr()\ncolormap = sns.diverging_palette(220, 10, as_cmap = True)\nplt.figure(figsize = (8,6))\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            annot=True,fmt='.2f',linewidths=0.30,\n            cmap = colormap, linecolor='white')\nplt.title('Correlation of df Features', y = 1.05, size=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly we see the features are not well correlated with each other"},{"metadata":{"trusted":true},"cell_type":"code","source":"#now look the pariplot of the dataset\nsns.pairplot(df)\nplt.title('Pairplot for the Data', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look the Age vs Annual Income\nplt.scatter(x = 'Age' , y = 'Annual Income (k$)' , data = df) \nplt.xlabel('Age')\nplt.ylabel('Annual Income (k$)')\nplt.title('Age vs Annual Income w.r.t Gender')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now look Age Vs Spending Score\nplt.scatter(x = 'Age' , y = 'Spending Score (1-100)' , data = df) \nplt.xlabel('Age')\nplt.ylabel('Spending Score (1-100)')\nplt.title('Age vs Spending Score (1-100)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we can conclued that customers have age around 30-40 have more speding score than others.\nSo they are most valueable customer of the Mall."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look the Annual Income vs Spending Score\nplt.scatter(x = 'Annual Income (k$)' , y = 'Spending Score (1-100)' , data = df) \nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.title('Age vs Annual Income w.r.t Gender')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we can conclude that customers have 75k-100k have more spending score than others.\nAnd also we can say that they are most valueable customer of mall without any mechine learning model."},{"metadata":{},"cell_type":"markdown","source":"Now we build our mechine learning model and lets check our predicting is correct or not.\n"},{"metadata":{},"cell_type":"markdown","source":"We first apply cluster solution between Annual income and Speding score"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets take our matrice of features for ml model\nx = df.iloc[:, [3, 4]].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At first we build K-means clustering model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using the Elbow Method to find Optimal Number of Cluster\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    Kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    Kmeans.fit(x)\n    wcss.append(Kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of Cluster')\nplt.ylabel('WCSS')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we note that our optimal number of culster is 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Appling K-Means to the Mall Dataset\nKmeans = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init =10, random_state = 0)\ny_Kmeans = Kmeans.fit_predict(x)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualsing the Cluster\nplt.scatter(x[y_Kmeans == 0, 0], x[y_Kmeans == 0, 1], s = 50, c = 'red', label = 'Careful Customers group')\nplt.scatter(x[y_Kmeans == 1, 0], x[y_Kmeans == 1, 1], s = 50, c = 'blue', label = 'Standard Customers group')\nplt.scatter(x[y_Kmeans == 2, 0], x[y_Kmeans == 2, 1], s = 50, c = 'green', label = 'Target Customers group')\nplt.scatter(x[y_Kmeans == 3, 0], x[y_Kmeans == 3, 1], s = 50, c = 'cyan', label = 'Careless Customers group')\nplt.scatter(x[y_Kmeans == 4, 0], x[y_Kmeans == 4, 1], s = 50, c = 'magenta', label = 'Sensible Customers group')\nplt.scatter(Kmeans.cluster_centers_[:, 0], Kmeans.cluster_centers_[:, 1], s = 100, c = 'Yellow', label = 'Centroid')\nplt.title('Cluster of the Clients')\nplt.xlabel('Annual Income(K$)')\nplt.ylabel('Spending Scores(1-100)')\nplt.legend()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Form above graph we can see our previous prediction is also right. Mall has customers whoes income around 75k-100k they are most valueable customer."},{"metadata":{},"cell_type":"markdown","source":"Now we apply Hierarchical Clustering to the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using the Dendrogram to find optimal number of cluster\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(x, method = 'ward'))\nplt.title('Dendogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean Distance')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From Dendogram we can see our optimal number cluster is 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting Hierarchical Clustering to the Dataset\nfrom sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualising the Cluster\nplt.scatter(x[y_hc == 0, 0], x[y_hc == 0, 1], s = 50, c = 'red', label = 'Careful Customers group')\nplt.scatter(x[y_hc == 1, 0], x[y_hc == 1, 1], s = 50, c = 'blue', label = 'Standard Customers group')\nplt.scatter(x[y_hc == 2, 0], x[y_hc == 2, 1], s = 50, c = 'green', label = 'Target Customers group')\nplt.scatter(x[y_hc == 3, 0], x[y_hc == 3, 1], s = 50, c = 'cyan', label = 'Careless Customers group')\nplt.scatter(x[y_hc == 4, 0], x[y_hc == 4, 1], s = 50, c = 'magenta', label = 'Sensible Customers group')\nplt.title('Cluster of Customers')\nplt.xlabel('Ananul Income(k$)')\nplt.ylabel('Spending Score(1-100)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we also get the same result"},{"metadata":{},"cell_type":"markdown","source":"Now we apply the same thing between Age and Spending Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets take our matrices of features\nX = df.iloc[:, [2,4]].values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using the Elbow Method to find Optimal Number of Cluster\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    Kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    Kmeans.fit(X)\n    wcss.append(Kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of Cluster')\nplt.ylabel('WCSS')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we can see our optimal number of cluser is 4."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Appling K-Means to the Mall Dataset\nKmeans = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 300, n_init =10, random_state = 0)\ny_Kmeans = Kmeans.fit_predict(X)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualsing the Cluster\nplt.scatter(X[y_Kmeans == 0, 0], X[y_Kmeans == 0, 1], s = 100, c = 'red', label = 'Customers should be paid more attention')\nplt.scatter(X[y_Kmeans == 1, 0], X[y_Kmeans == 1, 1], s = 100, c = 'blue', label = 'Premium Customers group')\nplt.scatter(X[y_Kmeans == 2, 0], X[y_Kmeans == 2, 1], s = 100, c = 'green', label = 'Customers have Potential ')\nplt.scatter(X[y_Kmeans == 3, 0], X[y_Kmeans == 3, 1], s = 100, c = 'cyan', label = 'Customers should be treated carefully')\nplt.scatter(Kmeans.cluster_centers_[:, 0], Kmeans.cluster_centers_[:, 1], s = 100, c = 'Yellow', label = 'Centroid')\nplt.title('Cluster of the Clients')\nplt.xlabel('Age')\nplt.ylabel('Spending Scores(1-100)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we note middle age customers are most valuable for Mall, which is also previously preidcted."},{"metadata":{},"cell_type":"markdown","source":"Now we apply Hierarchical Clustering to the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using the Dendrogram to find optimal number of cluster\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.title('Dendogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean Distance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we can see our optimal number of cluster is 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting Hierarchical Clustering to the Dataset\nfrom sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 4, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualising the Cluster\nplt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = 'Customers should be treated carefully')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = 'Customers have Potential')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Customers should be paid more attention')\nplt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Premium Customers group')\nplt.title('Cluster of Customers')\nplt.xlabel('Age')\nplt.ylabel('Spending Score(1-100)')\nplt.legend(loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we get diffierent segments of age group of customers. From this graph we can see most valuable age group of customers of Mall."},{"metadata":{},"cell_type":"markdown","source":"We use both k-means and Hierarchical Clustering fro this problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}