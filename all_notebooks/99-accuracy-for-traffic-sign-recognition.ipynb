{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this tutorial we use the GTSRB - German Traffic Sign Recognition Benchmark (https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign) dataset to train a Convolutional Neural Network perform single-image, multi-class classification.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport tensorflow as tf\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Loading the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_path = '/kaggle/input/gtsrb-german-traffic-sign/'\nprint(os.listdir(base_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(os.path.join(base_path, 'Train')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 'Train' folder contains 43 folders each representing a different class of image. We will create an array with respective data and labels for training and validation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in the image data and labels\ndata = []\nlabels = []\nnumber_of_classes = 43\n\nfor i in range(number_of_classes):\n    path = os.path.join(base_path, 'Train', str(i))\n    images = os.listdir(path)\n    \n    for item in images:\n        try:\n            image = Image.open(path + '/' + item)\n            image = image.resize((30,30))\n            image = np.array(image)\n            data.append(image)\n            labels.append(i)\n        except:\n            print('Error loading the image file')\ndata = np.array(data)\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Shape of the data {data.shape}')\nprint(f'Shape of the labels {labels.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Splitting the data into training and validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into training and validation data \nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n\n# normalize the input data\nX_train = X_train/255.\nX_test = X_test/255.\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encoding the labels for the training and validation labels\ny_train = to_categorical(y_train, number_of_classes)\ny_test = to_categorical(y_test, number_of_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Model building and training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNN model defination\nmodel = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=X_train.shape[1:]),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPool2D(2,2),\n    Dropout(0.3),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPool2D(2,2),\n    Dropout(0.3),\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPool2D(2,2),\n    Dropout(0.3),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.3),\n    Dense(number_of_classes, activation='softmax')\n])\n\n# Compiling the model\nmetrics = ['accuracy',\n           tf.keras.metrics.Precision(name='precision'),\n           tf.keras.metrics.Recall(name='recall')\n          ]\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running the model\nepochs = 30\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Visualizing model performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 2, figsize=(10, 10))\naxs = axs.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss', 'precision', 'recall']):\n    axs[i].plot(history.history[met])\n    axs[i].plot(history.history['val_' + met])\n    axs[i].set_title(f'Model {met}')\n    axs[i].set_xlabel('epochs')\n    axs[i].set_ylabel(met)\n    axs[i].legend(['training', 'validation'])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the accuracy for our model is around 99%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5. Model prediction and evaluation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next we will see how well the model does on unseen test data. Our dataset contains a Test.csv file, we will use it to evaluate our model. The data is in the form of a .csv file so we can use pandas to read in the data and then extract the images and the corresponding labels. We will then perform necessary data preparation like resizing and converting into numpy array.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read in the Test.csv file \ntest_data = pd.read_csv(os.path.join(base_path, 'Test.csv'))\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract the 'ClassId' and image 'Path'\nimage_file_path = test_data['Path'].values\nprint(image_file_path[:5])\n\ntest_labels = test_data['ClassId'].values\nprint(test_labels[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in the image data and normalize it\ndata=[]\n\nfor img in image_file_path:\n    image = Image.open(base_path + '/' + img)\n    image = image.resize((30,30))\n    data.append(np.array(image))\nX_test = np.array(data)\nX_test = X_test/255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making prediction\nprediction = model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nprint(accuracy_score(test_labels, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(test_labels, prediction))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}