{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Objectif\n\nSimplement de mettre en oeuvre les connaissances acquises avec la specialisation Deep Learning sur Coursera.  \n\nOn va tenter de determiner a partir de la reponse a la question 2, quelle etait la reponse a la question 1 choisie. \n\n## imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# imports dans l'ordre d'utilisation \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, LSTM, Activation\nfrom keras.layers.embeddings import Embedding\nfrom tensorflow import keras\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparation des donnees La transition Ecologique\n\n## chargement des donnees"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"nRowsRead = None # specify 'None' if want to read whole file\ndf = pd.read_csv('../input/granddebat/LA_TRANSITION_ECOLOGIQUE.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'LA_TRANSITION_ECOLOGIQUE.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selection des colonnes \ncorrespondant aux questions 1 & 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"q1q2_tmp = df.loc[:,['id', \"QUXVlc3Rpb246MTYw - Quel est aujourd'hui pour vous le problème concret le plus important dans le domaine de l'environnement ?\", 'QUXVlc3Rpb246MTYx - Que faudrait-il faire selon vous pour apporter des réponses à ce problème ?']]\nq1q2_tmp.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1q2 = q1q2_tmp.rename(columns={\"QUXVlc3Rpb246MTYw - Quel est aujourd'hui pour vous le problème concret le plus important dans le domaine de l'environnement ?\": \"Q1\", 'QUXVlc3Rpb246MTYx - Que faudrait-il faire selon vous pour apporter des réponses à ce problème ?': \"Q2\"})\nq1q2.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selection des lignes\n* Conservation des lignes avec une des 4 reponses cochables sur Q1\n* Conservation des lignes avec des reponses sur Q2"},{"metadata":{"trusted":true},"cell_type":"code","source":"q1q2['Q1'].value_counts().head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1q2[q1q2['Q1']=='Les dérèglements climatiques (crue, sécheresse)']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1q2_lignes_1 = q1q2[q1q2['Q1'].isin(['Les dérèglements climatiques (crue, sécheresse)', 'La biodiversité et la disparition de certaines espèces', \"La pollution de l'air\", \"L'érosion du littoral\"])]\nq1q2_lignes_1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1q2_lignes_2 = q1q2_lignes_1[pd.notna(q1q2_lignes_1['Q1']) & pd.notna(q1q2_lignes_1['Q2'])]\nq1q2_lignes_2.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encodage de la variable predite\n\nAssociation d'un chiffre a chaque reponse"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit(q1q2_lignes_2['Q1'])\nle.classes_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"application a la colonne Q1 => creation d'une colonne Q1E pour colonne Q1 Encodee "},{"metadata":{"trusted":true},"cell_type":"code","source":"q1q2_lignes_2.loc[:,'Q1E'] = le.transform(q1q2_lignes_2['Q1']).tolist()\nq1q2_lignes_2.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La variable predite doit aussi etre onehot encoded/reshapee en (m,c) avec m le nombre de lignes dans q1q2_lignes_2 et c le nombre de categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: reshape(-1, 1) permet ca, -1 indiquant de conserver le nombre de ligne, cf doc de reshape\n# y = q1q2_lignes_2['Q1E'].values.reshape(-1,1)\n# ici on fait un one hot encoding\ny = to_categorical(q1q2_lignes_2['Q1E'].values)\ny, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = q1q2_lignes_2['Q2']\nX, X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scission en jeux de donnees de test et train"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 333)\nX_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Choix de la métrique\n\ncf https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/  \nemojify notebook of week 2 of course 5 Sequence Models  \nhttps://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics  \n\nL'entropie croisée est la metrique de base."},{"metadata":{},"cell_type":"markdown","source":"# Word embedding\n\nComment representer les mots utilises dans le formulaire de La Transition Ecologique.\nLa methode utilisee ici sera d'entrainer une couche d'Embedding de Keras.  \n\nLe texte des reponses doit etre prepare en amont cf https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n\nDans un premier temps, pas de pretraitement du genre suppression de mots ou utilisation d'un dictionnaire. "},{"metadata":{},"cell_type":"markdown","source":"## Pretraitement pour le word embedding\n* tokenization\n* conversion en sequence\n* padding pour que toutes les sequences aient la meme taille"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_words = 1001\nmax_len = 1000\n# http://faroit.com/keras-docs/1.2.2/preprocessing/text/\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\n# https://keras.io/preprocessing/sequence/\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A quoi ressemble les sequences_matrix ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modele\n\nModification du modele emojify_V2 du notebook semaine 2 du cours 5 Sequence Models\nmelangee avec le notebook Simple LSTM for text classification\n\n## Construction du graphe du modele"},{"metadata":{"trusted":true},"cell_type":"code","source":"def modelgraph_transition_eco():\n    \"\"\"\n    Function creating the Emojify-v2 (nope the transition eco) model's graph.\n    \n    Arguments:\n    input_shape -- shape of the input, usually (max_len,)\n\n    Returns:\n    model -- a model instance in Keras\n    \"\"\"\n    \n    ### START CODE HERE ###\n    # Define sequences_matrix as the input of the graph, it should be of shape [max_len]\n    inputs = Input(name='inputs',shape=[max_len])\n    \n    # Embedding layer to be learned\n    embedding_layer = Embedding(max_words,50,input_length=max_len)(inputs)\n    \n    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n    # Be careful, the returned output should be a batch of sequences.\n    X = LSTM(units = 128, return_sequences = True)(embedding_layer)\n    # Add dropout with a probability of 0.5\n    X = Dropout(rate=0.5)(X)\n    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n    X = LSTM(units = 128)(X)\n    # Add dropout with a probability of 0.5\n    X = Dropout(rate=0.5)(X)\n    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n    X = Dense(4)(X)\n    # Add a softmax activation\n    X = Activation(activation=\"softmax\")(X)\n    \n    # Create Model instance which converts sentence_indices into X.\n    model = Model(inputs=inputs, outputs=X)\n    \n    ### END CODE HERE ###\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Appel de la fonction pour creation du modele"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = modelgraph_transition_eco()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definition de la metrique et compilation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Entrainement du modele\n\nModifier les valeurs d'epochs et batch_size permet d'obtenir de meilleurs resultats\nPar exemple, epoch=1 et batch_size=1024 donne de moins bons resultats que epoch=5 et batch_size=256"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(sequences_matrix, y_train, epochs = 1, batch_size = 1024, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sauvegarde du modele\n\nRessource : https://www.tensorflow.org/guide/keras/save_and_serialize"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/modele_lstm_classif_gdte.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test consistant a recreer le modele a partir du fichier modele_lstm_classif_gdte"},{"metadata":{"trusted":true},"cell_type":"code","source":"modele_lstm_classif_gdte = keras.models.load_model('/kaggle/working/modele_lstm_classif_gdte.h5')\nmodele_lstm_classif_gdte","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Application aux donnees de test"},{"metadata":{"trusted":true},"cell_type":"code","source":"sequences_test = tok.texts_to_sequences(X_test)\nsequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len)\nsequences_matrix_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = modele_lstm_classif_gdte.evaluate(sequences_matrix_test, y_test)\nprint()\nprint(\"Test accuracy = \", acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualisation des resultats\n\nFaisons par exemple une matrice des resultats obtenus pour le test\navec en ligne les vrais réponses et en colonne les réponses prédites...  "},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = modele_lstm_classif_gdte.predict(sequences_matrix_test)\npred_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transformation de pred_test et y_test afin d'avoir des array de shape (nb_cas_test,), de valeurs parmi [0,1,2,3] qui correspondent aux reponses de Q1"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(np.argmax(y_test, axis=1), np.argmax(pred_test, axis=1), rownames=['Actual'], colnames=['Predicted'], margins=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bizarrement, il n'y a aucune prediction 0 (l'erosion du littoral...), qui est tres certainement la reponse minoritaire a Q1 (parmi les cases cochees), voir d'autres notebooks pour s'en assurer."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}