{"cells":[{"metadata":{},"cell_type":"markdown","source":"# First import of required lybraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport nltk\nimport string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's read the data from csv file"},{"metadata":{"trusted":false},"cell_type":"code","source":"data= pd.read_csv('../input/sms-spam-collection-dataset/spam.csv',delimiter=',',encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.head() #First five row","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the preview of data shows there are three useless columns, we need to delete these columns and Rename the columns v1 and v2 to 'Labels' and 'Message'"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\ndata = data.rename(columns={'v1':'Labels','v2':'Message'}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's calculate the percentage of ham and spam messages"},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(data.Labels)\nplt.title('No. of ham and spam messages')\nprint('{:0.2f}% of the ham massages'.format(100*(data.Labels.value_counts()[0])/len(data)))\nprint('{:0.2f}% of the spam massages'.format(100*(data.Labels.value_counts()[1])/len(data)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"86% of data consists of ham message"},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.set_option('display.max_colwidth',2000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['message_len']=data['Message'].apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.loc[data['message_len'].max()][1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now define our text precessing function,comman preprocessing includes removing punctuation and stopwords (i.e. \"and\" \"or\" these words are not giving useful meaning). Also the characters are changed to lower case "},{"metadata":{"trusted":false},"cell_type":"code","source":"data['Text'] = data['Message'].map(lambda word :''.join([w for w in word if not w in string.punctuation]))\ndata['Text'] = data['Text'].map(lambda text : word_tokenize(text.lower()))\nstopword = set(stopwords.words('english'))\ndata['Text'] = data['Text'].map(lambda token : [w for w in token if not w in stopword])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After all that stems each word.Stemming is the process of reducing inflected words to their word stem, base or root form generally a written word form. Here, i am using 'SnowballStemmer'(this means that it replaces a word with the root of that word, for example \"tasted\" or \"tasting\" would become \"taste\")."},{"metadata":{"trusted":false},"cell_type":"code","source":"from nltk.stem import SnowballStemmer\nstemmer = SnowballStemmer(\"english\")\ndata['Text'] = data['Text'].map(lambda text : [stemmer.stem(w)for w in text])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['Text'] = data['Text'].map(lambda text : ' '.join(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets convert our clean text into a representation that a machine learning model can understand. I'll use the Tfifd for this"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nx = data['Text']\ny = data['Labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tfidf = TfidfVectorizer()\ntfidf_dtm = tfidf.fit_transform(x)\ntfidf_data=pd.DataFrame(tfidf_dtm.toarray())\ntfidf_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's split our features into train and test test"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(tfidf_data,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import machine model and make functions to fit our classifiers and make predictions"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nnb = MultinomialNB(alpha=0.2)\nnb.fit(x_train,y_train)\npred = nb.predict(x_test)\naccuracy_score(pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\naccuracy_score(pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"Naive bayes gives the best result."},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}