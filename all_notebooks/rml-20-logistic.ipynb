{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import data\n\ntrain = pd.read_csv('/kaggle/input/glass/glass.csv')\nprint(train.shape)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the data\n# Use seaborn to conduct heatmap to identify missing data\nsns.heatmap(train.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Feature Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation between variables of the dataset\n\ncorr = train.corr()\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(corr,cmap='Blues', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(train.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(train.columns)\nax.set_yticklabels(train.columns)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Binary Logistic Regression: The target variable has only two possible outcomes such as Window or Non Window\ntrain['Type'] = train['Type'].apply({1:0, 2:0, 3:0, 5:1, 6:1, 7:1}.get)\n\ncount_non_window = len(train[train['Type']==1])\ncount_window = len(train[train['Type']==0])\npct_of_non_window = count_non_window/(count_non_window+count_window)\nprint(\"percentage of non window glass is\", pct_of_non_window*100)\npct_of_window = count_window/(count_non_window+count_window)\nprint(\"percentage of window glass\", pct_of_window*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('Type').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.scatter(train['Na'].to_numpy(),train['Type'].to_numpy(),marker=\"s\", label='Na')\nax1.scatter(train['Al'].to_numpy(),train['Type'].to_numpy(),marker=\"s\", label='Al')\n#ax1.scatter(train['Si'].to_numpy(),train['Type'].to_numpy(),marker=\"s\", label='si')\nax1.scatter(train['Ba'].to_numpy(),train['Type'].to_numpy(),marker=\"s\", label='Ba')\nplt.title(\"Glass Type\")\nplt.xlabel('Elements Chosen')\nplt.ylabel('1:Non-Window, 0:Window)')\nplt.legend(loc='center right');\nax.figure.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Experimented with the scatter plot to understand the Features , taking these features as these training dataset is close.\nfeatures = ['Na', 'Al', 'Ba']\n\nX = train[features]\ny = train['Type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import module to split dataset\nfrom sklearn.model_selection import train_test_split\n# Split data set into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data available for Training\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the Model class\nfrom sklearn.linear_model import LogisticRegression\n\n# instantiate the model \nlogistic = LogisticRegression(solver='lbfgs')\n\n# Fit the logistic regression model.\nlogistic.fit(X_train,y_train)\n\n# Get predictions \ny_predict = logistic.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">MODEL Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the metrics class\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_predict)\ncnf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples = len(y_test)\nprint('Accuracy:  %.2f' % ((cnf_matrix[0][0] + cnf_matrix[1][1]) / n_samples))\nprint('Precision: %.2f' % (cnf_matrix[1][1] / (cnf_matrix[0][1] + cnf_matrix[1][1])))\nprint('Recall:    %.2f' % (cnf_matrix[1][1] / (cnf_matrix[1][0] + cnf_matrix[1][1])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(cnf_matrix,annot=True,cbar=False,cmap='Blues')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.title('Confusion Matrix')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logistic.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logistic.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}