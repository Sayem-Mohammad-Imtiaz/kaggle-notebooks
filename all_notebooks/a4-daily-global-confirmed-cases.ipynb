{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Analysis and Prediction of Daily Global Confirmed Cases"},{"metadata":{},"cell_type":"markdown","source":"By  \nZahra Jalia (20858708)  \nAnnanya Panda (20861832)  \nGroup Name:- A-Z  \nGroup No:- 48"},{"metadata":{},"cell_type":"markdown","source":"Thanks to Mehdi Afshari for providing the latest data."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport requests\nimport pandas as pd\nimport io\n\nBASE_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'\nCONFIRMED = 'time_series_covid19_confirmed_global.csv'\nDEATH = 'time_series_covid19_deaths_global.csv'\nRECOVERED = 'time_series_covid19_recovered_global.csv'\nCONFIRMED_US = 'time_series_covid19_confirmed_US.csv'\nDEATH_US = 'time_series_covid19_deaths_US.csv'\n\ndef get_covid_data(subset = 'CONFIRMED'):\n    \"\"\"This function returns the latest available data subset of COVID-19. \n        The returned value is in pandas DataFrame type.\n    Args:\n        subset (:obj:`str`, optional): Any value out of 5 subsets of 'CONFIRMED',\n        'DEATH', 'RECOVERED', 'CONFIRMED_US' and 'DEATH_US' is a valid input. If the value\n        is not chosen or typed wrongly, CONFIRMED subet will be returned.\n    \"\"\"    \n    switcher =  {\n                'CONFIRMED'     : BASE_URL + CONFIRMED,\n                'DEATH'         : BASE_URL + DEATH,\n                'RECOVERED'     : BASE_URL + RECOVERED,\n                'CONFIRMED_US'  : BASE_URL + CONFIRMED_US,\n                'DEATH_US'      : BASE_URL + DEATH_US,\n                \n                }\n\n    CSV_URL = switcher.get(subset, BASE_URL + CONFIRMED)\n\n    with requests.Session() as s:\n        download        = s.get(CSV_URL)\n        decoded_content = download.content.decode('utf-8')\n        data            = pd.read_csv(io.StringIO(decoded_content))\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deaths=get_covid_data(subset = 'DEATH') # global deaths\nconfirmed_cases=get_covid_data(subset = 'CONFIRMED')# confirmed cases","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA EXPLORATION AND PLOTTING**"},{"metadata":{},"cell_type":"markdown","source":"Growth of cases in Brazil, Canada, Germany, US, Spain, Italy from 1/22/20"},{"metadata":{"trusted":true},"cell_type":"code","source":"countries=['Brazil', 'Canada', 'Germany','US','Spain','Italy']\ny=confirmed_cases.loc[confirmed_cases['Country/Region']=='Italy'].iloc[0,4:]\ns = pd.DataFrame({'Italy':y})\nfor c in countries:    \n    s[c] = confirmed_cases.loc[confirmed_cases['Country/Region']==c].iloc[0,4:]\n    plt.plot(range(y.shape[0]),s[c],label=c)#    print(s[c])\nplt.title('Total Number of Confirmed Cases from 1/22/20')\nplt.xlabel('Day')\nplt.ylabel('Number of Cases')\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates=confirmed_cases.columns.values.tolist()\ndates=dates[4:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"World wide growth of cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_list=confirmed_cases['Country/Region'].unique()\nconfirmed = pd.DataFrame({'Italy':y})\ndict={}\na=[]\nb=[]\n\nfor c in country_list:\n    a.append(c)\n    confirmed=( confirmed_cases.loc[confirmed_cases['Country/Region']==c].iloc[:,4:].sum(axis=0))\n    b.append(confirmed[y.shape[0]-1])  \n    dict[c]=confirmed[y.shape[0]-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nf = plt.figure(figsize=(90,40))\nf.add_subplot(111)\n\nbarWidth=1\nplt.axes(axisbelow=True)\n#langs = ['C', 'C++', 'Java', 'Python', 'PHP']\n#students = [23,17,35,29,12]\nplt.bar(a,b,linewidth=17.0)\n\nplt.xlabel(\"Countries \",fontsize=45)\nplt.ylabel(\"Number of cases \",fontsize=45)\nplt.title(\"Confirmed cases of all countries around the world\",fontsize=60)\nplt.grid(alpha=0.3)\nplt.tick_params(size=5,labelsize = 30,rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Growth of cases in Canada"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 8))\ncanada = confirmed_cases.loc[confirmed_cases['Country/Region']=='Canada'].iloc[:,4:].sum(axis=0)\ncanada.tail()\ncanada.plot(label='Canada')\nplt.legend()\nplt.title(\"Number of confirmed cases in Canada\")\nplt.xlabel(\"Dates \",fontsize=15)\nplt.ylabel(\"Number of deaths \",fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Moving Average"},{"metadata":{"trusted":true},"cell_type":"code","source":"CAN = confirmed_cases[confirmed_cases['Country/Region']=='Canada']\n\nCAN = pd.DataFrame(CAN.iloc[0,4:-2])\n\ndef plot_moving_average(series, window, plot_intervals=False, scale=1.96):\n\n    rolling_mean = series.rolling(window=window).mean()\n    \n    plt.figure(figsize=(20,8))\n    plt.title('Moving average\\n window size = {}'.format(window))\n    plt.plot(rolling_mean, 'g', label='Rolling mean trend')\n    \n    #Plot confidence intervals for smoothed values\n    if plot_intervals:\n        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n        deviation = np.std(series[window:] - rolling_mean[window:])\n        lower_bound = rolling_mean - (mae + scale * deviation)\n        upper_bound = rolling_mean + (mae + scale * deviation)\n        plt.plot(upper_bound, 'r--', label='Upper bound / Lower bound')\n        plt.plot(lower_bound, 'r--')\n        \n            \n    plt.plot(series[window:], label='Actual values')\n    plt.legend(loc='best')\n    plt.xticks(rotation=90)\n    plt.grid(True)\n\n#Smooth by the previous 5 days (by week)\nplot_moving_average(CAN, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_moving_average(CAN, 30, plot_intervals=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=[]\nfor i in dates:\n  c= confirmed_cases.iloc[:,4:].sum(axis=0)\n  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANALYSIS AND TRAINING OF DATA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndf = pd.DataFrame(columns=['ds','y'])\ndf\ndf['ds'] = pd.to_datetime(dates)\nfor  j in range(0,len(c)):\n  df['y'][j]=pd.to_numeric(c[j])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport datetime\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression, BayesianRidge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array([i for i in range(len(dates))]).reshape(-1, 1)\nY = np.array(c).reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Future forcasting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"days_in_future = 15 #next 2 weeks\nfuture_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forcast[:-15]\nstart = '1/22/2020'\nstart_date = datetime.datetime.strptime(start, '%m/%d/%Y')\nfuture_forcast_dates = []\nfor i in range(len(future_forcast)):\n    future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime('%m/%d/%Y'))\n    \nX_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(X, Y, test_size=0.10, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model for predicting confirmed cases\n\n1. Support vector machines"},{"metadata":{"trusted":true},"cell_type":"code","source":"# svm_confirmed = svm_search.best_estimator_\nsvm_confirmed = SVR(C=1,degree=5,kernel='poly',epsilon=0.01)\nsvm_confirmed.fit(X_train_confirmed, y_train_confirmed)\nsvm_pred = svm_confirmed.predict(future_forcast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check against testing data\nsvm_test_pred = svm_confirmed.predict(X_test_confirmed)\nplt.plot(y_test_confirmed)\nplt.plot(svm_test_pred)\nplt.legend(['Test Data', 'SVM Predictions'])\nprint('MAE:', mean_absolute_error(svm_test_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(svm_test_pred, y_test_confirmed))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transforming our data for polynomial regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npoly = PolynomialFeatures(degree=3)\npoly_X_train_confirmed = poly.fit_transform(X_train_confirmed)\npoly_X_test_confirmed = poly.fit_transform(X_test_confirmed)\npoly_future_forcast = poly.fit_transform(future_forcast)\n\nbayesian_poly = PolynomialFeatures(degree=4)\nbayesian_poly_X_train_confirmed = bayesian_poly.fit_transform(X_train_confirmed)\nbayesian_poly_X_test_confirmed = bayesian_poly.fit_transform(X_test_confirmed)\nbayesian_poly_future_forcast = bayesian_poly.fit_transform(future_forcast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_model = LinearRegression(normalize=True, fit_intercept=True)\nlinear_model.fit(poly_X_train_confirmed, y_train_confirmed)\ntest_linear_pred = linear_model.predict(poly_X_test_confirmed)\nlinear_pred = linear_model.predict(poly_future_forcast)\nprint('MAE:', mean_absolute_error(test_linear_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(test_linear_pred, y_test_confirmed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(linear_model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(y_test_confirmed)\nplt.plot(test_linear_pred)\nplt.legend(['Test Data', 'Polynomial Regression Predictions'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Bayesian ridge polynomial regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"# bayesian ridge polynomial regression\ntol = [1e-4, 1e-3, 1e-2]\nalpha_1 = [1e-7, 1e-6, 1e-5, 1e-4]\nalpha_2 = [1e-7, 1e-6, 1e-5, 1e-4]\nlambda_1 = [1e-7, 1e-6, 1e-5, 1e-4]\nlambda_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n\nbayesian_grid = {'tol': tol, 'alpha_1': alpha_1, 'alpha_2' : alpha_2, 'lambda_1': lambda_1, 'lambda_2' : lambda_2}\n\nbayesian = BayesianRidge(fit_intercept=False, normalize=True)\nbayesian_search = RandomizedSearchCV(bayesian, bayesian_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=40, verbose=1)\nbayesian_search.fit(bayesian_poly_X_train_confirmed, y_train_confirmed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bayesian_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bayesian_confirmed = bayesian_search.best_estimator_\ntest_bayesian_pred = bayesian_confirmed.predict(bayesian_poly_X_test_confirmed)\nbayesian_pred = bayesian_confirmed.predict(bayesian_poly_future_forcast)\nprint('MAE:', mean_absolute_error(test_bayesian_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(test_bayesian_pred, y_test_confirmed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(y_test_confirmed)\nplt.plot(test_bayesian_pred)\nplt.legend(['Test Data', 'Bayesian Ridge Polynomial Predictions'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predictions **"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_predictions(x, y, pred, algo_name, color):\n    plt.figure(figsize=(7, 5))\n    plt.plot(x, y)\n    plt.plot(future_forcast, pred, linestyle='dashed', color=color)\n    plt.title('Growth of Confirmed Cases Over Time', size=15)\n    plt.xlabel('Days Since 1/22/2020', size=15)\n    plt.ylabel('Number of Cases', size=15)\n    plt.legend(['Confirmed Cases', algo_name], prop={'size': 15})\n    plt.xticks(size=10)\n    plt.yticks(size=10)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction via SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(adjusted_dates, c, svm_pred, 'SVM Predictions', 'purple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction via Polynomial Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(adjusted_dates, c, linear_pred, 'Polynomial Regression Predictions', 'orange')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction via Bayesian Ridge Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(adjusted_dates, c, bayesian_pred, 'Bayesian Ridge Regression Predictions', 'green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Future predictions using SVM "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'SVM Prediction of Confirmed Cases Worldwide': np.round(svm_pred[-10:])})\nsvm_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Future predictions using polynomial regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# \nlinear_pred = linear_pred.reshape(1,-1)[0]\nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'Polynomial Prediction of Confirmed Cases Worldwide': np.round(linear_pred[-10:])})\nsvm_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Future predictions using Bayesian Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  \nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'Bayesian Ridge Prediction of Confirmed Cases Worldwide': np.round(bayesian_pred[-10:])})\nsvm_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Using prophet for automate future forecasting and predictions**"},{"metadata":{},"cell_type":"markdown","source":"***Prophet***  \nWe use Prophet, a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well. It is also an open source software released by Facebook’s Core Data Science team. It is available for download on CRAN and PyPI.\n\n"},{"metadata":{},"cell_type":"markdown","source":"***Why Prophet?***  \nProphet is easy to customize and use, and to produce accurate forecasts which can be explained intuitively with supporting evidence such as forecast seasonality components. It allows the analyst to explain in an intuitive and convinving manner to higher management as to why the forecasts are as such, and the plausible underlying factors that contribute to its result. Furthermore, it is also open-source! :)\n\n"},{"metadata":{},"cell_type":"markdown","source":"***References***\n1. https://facebook.github.io/prophet/\n2. https://facebook.github.io/prophet/docs/\n3. https://github.com/facebook/prophet\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Forecasting Confirmed Cases Worldwide with Prophet (Baseline)  \nWe perform a week's ahead forecast with Prophet, with 95% prediction intervals. Here, no tweaking of seasonality-related parameters and additional regressors are performed.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"m = Prophet(interval_width=0.95)\nm.fit(df)\nfuture = m.make_future_dataframe(periods=7)\nfuture_confirmed = future.copy() # for non-baseline predictions later on\nfuture.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_forecast_plot = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_components = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analysis using RNN via PyTorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pandas.plotting import register_matplotlib_converters\nfrom torch import nn, optim\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 14, 10\nregister_matplotlib_converters()\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=[]\nworld_cases = []\nY=[]\nfor i in dates:\n  c= confirmed_cases.iloc[:,4:].sum(axis=0)\ndaily_cases=c.copy()\ndaily_cases.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 15))\nplt.plot(daily_cases)\nplt.title(\"Cumulative daily cases\");\nplt.tick_params(size=15,labelsize = 15,rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases = daily_cases.diff().fillna(daily_cases[0]).astype(np.int64)\ndaily_cases.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 15))\nplt.plot(daily_cases)\nplt.title(\"Daily cases\");\nplt.tick_params(size=15,labelsize = 15,rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Testing on available data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_size = 14\n\ntrain_data = daily_cases[:-test_data_size]\ntest_data = daily_cases[-test_data_size:]\n\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(train_data, axis=1))\n\ntrain_data = scaler.transform(np.expand_dims(train_data, axis=1))\n\ntest_data = scaler.transform(np.expand_dims(test_data, axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Currently, we have a big sequence of daily cases. We’ll convert it into smaller ones"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_sequences(data, seq_length):\n    xs = []\n    ys = []\n\n    for i in range(len(data)-seq_length-1):\n        x = data[i:(i+seq_length)]\n        y = data[i+seq_length]\n        xs.append(x)\n        ys.append(y)\n\n    return np.array(xs), np.array(ys)\nseq_length = 5\nX_train, y_train = create_sequences(train_data, seq_length)\nX_test, y_test = create_sequences(test_data, seq_length)\n\nX_train = torch.from_numpy(X_train).float()\ny_train = torch.from_numpy(y_train).float()\n\nX_test = torch.from_numpy(X_test).float()\ny_test = torch.from_numpy(y_test).float()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CoronaVirusPredictor(nn.Module):\n\n  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n    super(CoronaVirusPredictor, self).__init__()\n\n    self.n_hidden = n_hidden\n    self.seq_len = seq_len\n    self.n_layers = n_layers\n\n    self.lstm = nn.LSTM(\n      input_size=n_features,\n      hidden_size=n_hidden,\n      num_layers=n_layers,\n      dropout=0.5\n    )\n    self.rnn = nn.RNN( input_size=n_features, hidden_size=n_hidden,  num_layers=n_layers, batch_first=True, nonlinearity='relu')\n \n\n    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n\n  def reset_hidden_state(self):\n    self.hidden = (\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n    )\n\n  def forward(self, sequences):\n    \n    lstm_out, self.hidden = self.lstm(\n      sequences.view(len(sequences), self.seq_len, -1),\n      self.hidden\n    )\n    last_time_step = \\\n      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n    y_pred = self.linear(last_time_step)\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(\n  model,\n  train_data,\n  train_labels,\n  test_data=None,\n  test_labels=None\n):\n  loss_fn = torch.nn.MSELoss(reduction='sum')\n\n  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n  num_epochs = 100\n\n  train_hist = np.zeros(num_epochs)\n  test_hist = np.zeros(num_epochs)\n\n  for t in range(num_epochs):\n    model.reset_hidden_state()\n\n    y_pred = model(X_train)\n\n    loss = loss_fn(y_pred.float(), y_train)\n\n    if test_data is not None:\n      with torch.no_grad():\n        y_test_pred = model(X_test)\n        test_loss = loss_fn(y_test_pred.float(), y_test)\n      test_hist[t] = test_loss.item()\n\n      if t % 10 == 0:\n        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n    elif t % 10 == 0:\n      print(f'Epoch {t} train loss: {loss.item()}')\n\n    train_hist[t] = loss.item()\n\n    optimiser.zero_grad()\n\n    loss.backward()\n\n    optimiser.step()\n\n  return model.eval(), train_hist, test_hist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CoronaVirusPredictor(\n  n_features=1,\n  n_hidden=32,\n  seq_len=seq_length,\n  n_layers=2\n)\nmodel, train_hist, test_hist = train_model(\n  model,\n  X_train,\n  y_train,\n  X_test,\n  y_test\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use all data for training to predict future cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(daily_cases, axis=1))\n\nall_data = scaler.transform(np.expand_dims(daily_cases, axis=1))\n\nall_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all, y_all = create_sequences(all_data, seq_length)\n\nX_all = torch.from_numpy(X_all).float()\ny_all = torch.from_numpy(y_all).float()\n\nmodel = CoronaVirusPredictor(\n  n_features=1,\n  n_hidden=512,\n  seq_len=seq_length,\n  n_layers=2\n)\nmodel, train_hist, _ = train_model(model, X_all, y_all)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting future cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"DAYS_TO_PREDICT = 12\n\nwith torch.no_grad():\n  test_seq = X_all[:1]\n  preds = []\n  for _ in range(DAYS_TO_PREDICT):\n    y_test_pred = model(test_seq)\n    pred = torch.flatten(y_test_pred).item()\n    preds.append(pred)\n    new_seq = test_seq.numpy().flatten()\n    new_seq = np.append(new_seq, [pred])\n    new_seq = new_seq[1:]\n    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_cases = scaler.inverse_transform(\n  np.expand_dims(preds, axis=0)\n).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases.index[-1]\npredicted_index = pd.date_range(\n  start=daily_cases.index[-1],\n  periods=DAYS_TO_PREDICT + 1,\n  closed='right'\n)\n\npredicted_cases = pd.Series(\n  data=predicted_cases,\n  index=predicted_index\n)\n\nplt.plot(predicted_cases, label='Predicted Daily Cases')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_cases","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}