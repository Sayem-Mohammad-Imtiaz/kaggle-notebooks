{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"base_dir = \"../input/mobile-price-classification/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Library Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader as DL\nfrom torch.nn.utils import weight_norm as WN\nimport torch.nn.functional as F\n\nfrom time import time\nimport random as r\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.impute import SimpleImputer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def breaker():\n    print(\"\\n\" + 30*\"-\" + \"\\n\")\n\ndef head(x, no_of_ele=5):\n    breaker()\n    print(x[:no_of_ele])\n    breaker()\n    \ndef getCol(x):\n    return [col for col in x.columns]\n\ndef getObj(x):\n    s = (x.dtypes == \"object\")\n    return list(s[s].index)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Handling"},{"metadata":{},"cell_type":"markdown","source":"**Input**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_Set = pd.read_csv(base_dir + \"train.csv\")\nts_Set = pd.read_csv(base_dir + \"test.csv\")\n\nbreaker()\nprint(\"Training Set Shape :\", repr(tr_Set.shape))\nbreaker()\n\nfor name in getCol(tr_Set):\n    print(name)\nbreaker()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"breaker()\nprint(\"Test Set Shape :\", repr(ts_Set.shape))\nbreaker()\n\nfor name in getCol(ts_Set):\n    print(name)\nbreaker()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Processing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tr_Set.iloc[:, :-1].copy().values\ny = tr_Set.iloc[:, -1].copy().values\n\nX_test = ts_Set.iloc[:, 1:].copy().values\n\nX = X.astype(float)\nX_test = X_test.astype(float)\n\ny = y.astype(int)\n\nsc_X = StandardScaler()\n#X = sc_X.fit_transform(X)\n#X_test = sc_X.transform(X)\n\nnum_features = X.shape[1]\nnum_classes  = len(set(y))\n\ndel tr_Set, ts_Set, ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dataset Template**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DS(Dataset):\n    def __init__(this, X=None, y=None, mode=\"train\"):\n        this.mode = mode\n        this.X = X\n        if mode == \"train\":\n            this.y = y\n    \n    def __len__(this):\n        return this.X.shape[0]\n    \n    def __getitem__(this, idx):\n        if this.mode == \"train\":\n            return torch.FloatTensor(this.X[idx]), torch.LongTensor(this.y[idx])\n        else:\n            return torch.FloatTensor(this.X[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ANN"},{"metadata":{},"cell_type":"markdown","source":"**Config**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CFG():\n    tr_batch_size = 64\n    ts_batch_size = 64\n    va_batch_size = 64\n    \n    epochs = 50\n    n_folds = 5\n    \n    IL = num_features\n    HL_1 = [128]\n    HL_2 = [128, 64]\n    OL = num_classes\n    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ncfg = CFG()\n\nts_data_setup = DS(X_test, None, \"test\")\nts_data       = DL(ts_data_setup, batch_size=cfg.ts_batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Setup**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(this, IL=None, HL=None, OL=None):\n        super(MLP, this).__init__()\n        \n        this.HL = HL\n        \n        this.DP1 = nn.Dropout(p=0.2)\n        this.DP2 = nn.Dropout(p=0.5)\n        \n        if len(HL) == 1:\n            this.BN1 = nn.BatchNorm1d(IL)\n            this.FC1 = WN(nn.Linear(IL, HL[0]))\n            \n            this.BN2 = nn.BatchNorm1d(HL[0])\n            this.FC2 = WN(nn.Linear(HL[0], OL))\n            \n        elif len(HL) == 2:\n            this.BN1 = nn.BatchNorm1d(IL)\n            this.FC1 = WN(nn.Linear(IL, HL[0]))\n            \n            this.BN2 = nn.BatchNorm1d(HL[0])\n            this.FC2 = WN(nn.Linear(HL[0], HL[1]))\n            \n            this.BN3 = nn.BatchNorm1d(HL[1])\n            this.FC3 = WN(nn.Linear(HL[1], OL))\n            \n        else:\n            raise NotImplementedError(\"Only supports Networks of depth 2 and 3\")\n            \n    def getOptimizer(this, A_or_S=True, lr=1e-3, wd=0):\n        if A_or_S:\n            return optim.Adam(this.parameters(), lr=lr, weight_decay=wd)\n        else:\n            return optim.SGD(this.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n    \n    def forward(this, x):\n        if len(this.HL) == 1:\n            x = this.BN1(x)\n            #x = this.DP1(x)\n            x = F.relu(this.FC1(x))\n            x = this.BN2(x)\n            #x = this.DP2(x)\n            x = F.log_softmax(this.FC2(x), dim=1)\n            return x\n        else:\n            x = this.BN1(x)\n            #x = this.DP1(x)\n            x = F.relu(this.FC1(x))\n            x = this.BN2(x)\n            #x = this.DP2(x)\n            x = F.relu(this.FC2(x))\n            x = this.BN3(x)\n            #x = this.DP2(x)\n            x = F.log_softmax(this.FC3(x), dim=1)\n            return x        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANN Helpers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(X=None, y=None, n_folds=None, HL_Used=None):\n    breaker()\n    print(\"Training ...\")\n    breaker()\n    \n    LP = []\n    names = []\n    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n    fold = 0\n    \n    start_time = time()\n    for tr_idx, va_idx in StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0).split(X, y):\n        print(\"Processing Fold {fold}\".format(fold=fold+1))\n        \n        X_train, X_valid, y_train, y_valid = X[tr_idx], X[va_idx], y[tr_idx], y[va_idx]\n        \n        tr_data_setup = DS(X_train, y_train.reshape(-1,1))\n        va_data_setup = DS(X_valid, y_valid.reshape(-1,1))\n        \n        DLS = {\"train\" : DL(tr_data_setup, batch_size=cfg.tr_batch_size, shuffle=True, generator=torch.manual_seed(0)),\n               \"valid\" : DL(va_data_setup, batch_size=cfg.va_batch_size, shuffle=False)\n              }\n        \n        torch.manual_seed(0)\n        model = MLP(cfg.IL, HL_Used, cfg.OL)\n        model.to(cfg.device)\n        \n        optimizer = model.getOptimizer()\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, eps=1e-6, verbose=True)\n        \n        for e in range(cfg.epochs):\n            epochLoss = {\"train\" : 0, \"valid\" : 0}\n            for phase in [\"train\", \"valid\"]:\n                if phase == \"train\":\n                    model.train()\n                else:\n                    model.eval()\n                lossPerPass = 0\n                \n                for feat, label in DLS[phase]:\n                    feat, label = feat.to(cfg.device), label.to(cfg.device).view(-1)\n                    \n                    optimizer.zero_grad()\n                    with torch.set_grad_enabled(phase == \"train\"):\n                        output = model(feat)\n                        loss   = nn.NLLLoss()(output, label)\n                        if phase == \"train\":\n                            loss.backward()\n                            optimizer.step()\n                    lossPerPass += (loss.item() / label.shape[0])\n                epochLoss[phase] = lossPerPass\n            LP.append(epochLoss)\n            scheduler.step(epochLoss[\"valid\"])\n            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n                bestLoss = epochLoss\n                name = \"./Model_{ids}_Fold_{fold}.pt\".format(ids=len(HL_Used), fold=fold)\n                names.append(name)\n                torch.save(model.state_dict(), name)\n        fold += 1\n    \n    breaker()\n    print(\"Time Taken to Train {f} folds for {e} epochs : {:.2f} minutes\".format((time() - start_time)/60, f=n_folds, e=cfg.epochs))\n    breaker()\n    print(\"Best Loss :\", repr(bestLoss))\n    breaker()\n\n    return LP, names, model\n\ndef eval_fn(model=None, names=None, dataloader=None, num_obs_test=None):\n    y_pred = np.zeros((num_obs_test, 1))\n    \n    for name in names:\n        Preds = torch.zeros(cfg.ts_batch_size, 1).to(cfg.device)\n        \n        model.load_state_dict(torch.load(name))\n        model.eval()\n        \n        for X in dataloader:\n            X = X.to(cfg.device)\n            with torch.no_grad():\n                logProb = model(X)\n            Prob = torch.exp(logProb)\n            Pred = torch.argmax(Prob, dim=1)\n            Preds = torch.cat((Preds, Pred.view(-1,1)), dim=0)\n        Preds = Preds[cfg.ts_batch_size:].cpu().numpy()\n        y_pred = np.add(y_pred, Preds)\n    y_pred = np.divide(y_pred, len(names))\n    return y_pred.astype(int)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_tr_data_setup = DS(X, None, \"test\")\nfull_tr_data = DL(full_tr_data_setup, batch_size=cfg.ts_batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Configuration 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"LP_1, Names_1, Network_1 = train_fn(X=X, y=y, n_folds=cfg.n_folds, HL_Used=cfg.HL_1)\n\ny_pred = eval_fn(Network_1, set(Names_1), full_tr_data, full_tr_data_setup.__len__())\n\nprint(\"Configuration 1 Accuracy : {:.4f} %\".format(accuracy_score(y, y_pred) * 100))\nbreaker()\n\nLPV = []\nLPT = []\nfor i in range(len(LP_1)):\n  LPT.append(LP_1[i][\"train\"])\n  LPV.append(LP_1[i][\"valid\"])\n\nxAxis = [i+1 for i in range(cfg.epochs)]\nplt.figure(figsize=(15, 30))\nfor fold in range(cfg.n_folds):\n    plt.subplot(cfg.n_folds, 1, fold+1)\n    plt.plot(xAxis, LPT[fold*cfg.epochs:(fold+1)*cfg.epochs], \"b\", label=\"Training Loss\")\n    plt.plot(xAxis, LPV[fold*cfg.epochs:(fold+1)*cfg.epochs], \"r--\", label=\"Validation Loss\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Fold {fold}\".format(fold=fold+1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Configuration 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"LP_2, Names_2, Network_2 = train_fn(X=X, y=y, n_folds=cfg.n_folds, HL_Used=cfg.HL_2)\n\ny_pred = eval_fn(Network_2, set(Names_2), full_tr_data, full_tr_data_setup.__len__())\n\nprint(\"Configuration 2 Accuracy : {:.4f} %\".format(accuracy_score(y, y_pred) * 100))\nbreaker()\n\nLPV = []\nLPT = []\nfor i in range(len(LP_2)):\n  LPT.append(LP_2[i][\"train\"])\n  LPV.append(LP_2[i][\"valid\"])\n\nxAxis = [i+1 for i in range(cfg.epochs)]\nplt.figure(figsize=(15, 30))\nfor fold in range(cfg.n_folds):\n    plt.subplot(cfg.n_folds, 1, fold+1)\n    plt.plot(xAxis, LPT[fold*cfg.epochs:(fold+1)*cfg.epochs], \"b\", label=\"Training Loss\")\n    plt.plot(xAxis, LPV[fold*cfg.epochs:(fold+1)*cfg.epochs], \"r--\", label=\"Validation Loss\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Fold {fold}\".format(fold=fold+1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred = eval_fn(Network_Name, Model_Names, ts_data, ts_data_setup.__len__())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}