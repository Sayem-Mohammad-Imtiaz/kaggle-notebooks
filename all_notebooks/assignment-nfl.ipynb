{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/nfl-scores-and-betting-data/spreadspoke_scores.csv\")\nteams = pd.read_csv(\"../input/nfl-scores-and-betting-data/nfl_teams.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.replace(r'^\\s*$', np.nan, regex=True)\ndata = data[(data.score_home.isnull() == False)&(data.team_favorite_id.isnull() == False)&(data.over_under_line.isnull() == False)&(data.schedule_season >= 1980)]\ndata.reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[(data.schedule_week == '18'), 'schedule_week'] = '17'\ndata.loc[(data.schedule_week == 'Wildcard') | (data.schedule_week == 'WildCard'), 'schedule_week'] = '18'\ndata.loc[(data.schedule_week == 'Division'), 'schedule_week'] = '19'\ndata.loc[(data.schedule_week == 'Conference'), 'schedule_week'] = '20'\ndata.loc[(data.schedule_week == 'Superbowl') | (data.schedule_week == 'SuperBowl'), 'schedule_week'] = '21'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['team_home'] = data.team_home.map(teams.set_index('team_name')['team_id'].to_dict())\ndata['team_away'] = data.team_away.map(teams.set_index('team_name')['team_id'].to_dict())\ndata['over_under_line'] = data.over_under_line.astype(float)\ndata['schedule_week'] = data.schedule_week.astype(int)\ndata[\"team_favorite_away\"] = (data[\"team_favorite_id\"] == data[\"team_away\"]).astype(int)\ndata[\"team_favorite_home\"] = (data[\"team_favorite_id\"] == data[\"team_home\"]).astype(int)\ndata[\"schedule_playoff\"] = data[\"schedule_playoff\"].astype(int)\ndata[\"stadium_neutral\"] = data[\"stadium_neutral\"].astype(int)\ndata.schedule_season = data.schedule_season-2000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"result\"] = (data[\"score_home\"]>=data[\"score_away\"]).astype(int)\ndata = data.drop([\"score_away\",\"score_home\",\"team_favorite_id\",\"schedule_date\",\"stadium_neutral\",\"weather_detail\"],axis = 1)\ndata = data.fillna(0)\ndata[\"stadium\"]=pd.factorize(data.stadium)[0]\ndata[\"team_away\"]=pd.factorize(data.team_away)[0]\ndata[\"team_home\"]=pd.factorize(data.team_home)[0]\ndata['weather_humidity'] = pd.to_numeric(data['weather_humidity'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#using top 10 features from previous part\n#data = data.drop([\"weather_temperature\",\"weather_wind_mph\",\"weather_humidity\",\"team_favorite_away\",\"team_favorite_home\"],1)\nlabels = np.array(data['result'])\ntrain_data= data.drop('result', axis = 1)\nfeature_list = list(train_data.columns)\ntrain_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import LeaveOneOut\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import cross_val_score\nmodel = DecisionTreeClassifier()\nmodel.fit(train_features,train_labels)\npredictions = model.predict(test_features)\nerrors = np.sum(abs(predictions - test_labels))/len(predictions)\nprint('Accuracy ',1 - errors)\n\n#Cross validation\nmodel = DecisionTreeClassifier()\nscores = cross_val_score(model,train_data,labels, cv=5)\nprint('Cross-Validation Accuracy Scores', scores)\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores),np.std(scores)))\n\n\n#Bagging \npipeline = make_pipeline(StandardScaler(),DecisionTreeClassifier())\nbgclassifier = BaggingClassifier(base_estimator=pipeline, n_estimators=100,max_features=10, max_samples=100, random_state=1, n_jobs=5)\nbgclassifier.fit(train_data,labels)\nprint()\nprint(\"Bagging\")\nprint('Model training Score: %.3f' %bgclassifier.score(train_data,labels))\n\n#LOOCV \ncv = LeaveOneOut()\nmodel = DecisionTreeClassifier()\nscores = cross_val_score(model,train_data,labels, cv=cv)\nprint()\nprint(\"LOOCV\")\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores),np.std(scores)))\n\n#Colleccting data while changing the training set from 10% to 90%\ntree_stats = {}  #dict from %train data to accuracy\nfor i in range(1,10):\n    train_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.10*i)\n    model = DecisionTreeClassifier()\n    model.fit(train_features,train_labels)\n    predictions = model.predict(test_features)\n    Accuracy = 1 - np.sum(abs(predictions - test_labels))/len(predictions)\n    tree_stats[100 - 10*i]  = Accuracy\nprint()\nplt.title(\"Decision Tree, % training set vs Test Set Accuracy\")\nplt.ylim(0.5,0.6)\nplt.bar(tree_stats.keys(),tree_stats.values(),width = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#logistic regression\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(train_features,train_labels)\npredictions = model.predict(test_features)\nerrors = np.sum(abs(predictions - test_labels))/len(predictions)\nprint('Accuracy ',1 - errors)\n\n#Cross validation\nmodel = LogisticRegression()\nscores = cross_val_score(model,train_data,labels, cv=5)\nprint('Cross-Validation Accuracy Scores', scores)\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores),np.std(scores)))\n\n#LOOCV \ncv = LeaveOneOut()\nmodel = LogisticRegression()\nscores = cross_val_score(model,train_data,labels, cv=cv)\nprint()\nprint(\"LOOCV\")\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores),np.std(scores)))\n\n#Bagging \npipeline = make_pipeline(StandardScaler(),LogisticRegression())\nbgclassifier = BaggingClassifier(base_estimator=pipeline, n_estimators=100,max_features=10, max_samples=100, random_state=1, n_jobs=5)\nbgclassifier.fit(train_data,labels)\nprint()\nprint(\"Bagging\")\nprint('Model training Score: %.3f' %bgclassifier.score(train_data,labels))\n\nlogreg_stats = {}  #dict from %train data to accuracy\nfor i in range(1,10):\n    train_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.10*i)\n    model = LogisticRegression()\n    model.fit(train_features,train_labels)\n    predictions = model.predict(test_features)\n    Accuracy = 1 - np.sum(abs(predictions - test_labels))/len(predictions)\n    logreg_stats[100 - 10*i]  = Accuracy\nprint()\nplt.title(\"Logistic Regression, % training set vs Test Set Accuracy\")\nplt.ylim(0.6,0.7)\nplt.bar(logreg_stats.keys(),logreg_stats.values(),width = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Guassian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(train_features,train_labels)\npredictions = model.predict(test_features)\nerrors = np.sum(abs(predictions - test_labels))/len(predictions)\nprint('Accuracy ',1 - errors)\n\n#Cross validation\nmodel = GaussianNB()\nscores = cross_val_score(model,train_data,labels, cv=5)\nprint('Cross-Validation Accuracy Scores', scores)\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores),np.std(scores)))\n\n#LOOCV \ncv = LeaveOneOut()\nmodel = GaussianNB()\nscores = cross_val_score(model,train_data,labels, cv=cv)\nprint()\nprint(\"LOOCV\")\nprint('Accuracy: %.3f (%.3f)' % (np.mean(scores),np.std(scores)))\n\n#Bagging \npipeline = make_pipeline(StandardScaler(),GaussianNB())\nbgclassifier = BaggingClassifier(base_estimator=pipeline, n_estimators=100,max_features=10, max_samples=100, random_state=1, n_jobs=5)\nbgclassifier.fit(train_data,labels)\nprint()\nprint(\"Bagging\")\nprint('Model training Score: %.3f' %bgclassifier.score(train_data,labels))\n\nnb_stats = {}  #dict from %train data to accuracy\nfor i in range(1,10):\n    train_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.10*i)\n    model = LogisticRegression()\n    model.fit(train_features,train_labels)\n    predictions = model.predict(test_features)\n    Accuracy = 1 - np.sum(abs(predictions - test_labels))/len(predictions)\n    nb_stats[100 - 10*i]  = Accuracy\nprint()\nprint(\"Guassian NB, Training set % mapped to test accuracy\")\nplt.ylim(0.6,0.7)\nplt.bar(nb_stats.keys(),nb_stats.values(),width = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = {}\nRMSE = {}\n\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = BaggingClassifier(base_estimator = DecisionTreeClassifier())\ntrain_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.15)\nmodel.fit(train_features,train_labels)\npredictions = model.predict(test_features)\nprint(\"Bagging Classifier\")\nprint('Mean Absolute Error:', metrics.mean_absolute_error(test_labels,predictions)) \nprint('Mean Squared Error:', metrics.mean_squared_error(test_labels,predictions)) \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_labels,predictions)))\nprint()\nacc[\"BaggingClassifier\"] = 1 - metrics.mean_absolute_error(test_labels,predictions)\nRMSE[\"BaggingClassifier\"] = np.sqrt(metrics.mean_squared_error(test_labels,predictions))\n\nfrom sklearn.ensemble import RandomForestClassifier\nmodel =RandomForestClassifier(n_estimators=150)\ntrain_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.15)\nmodel.fit(train_features,train_labels)\npredictions = model.predict(test_features)\nprint(\"Random Forest Classifier\")\nprint('Mean Absolute Error:', metrics.mean_absolute_error(test_labels,predictions)) \nprint('Mean Squared Error:', metrics.mean_squared_error(test_labels,predictions)) \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_labels,predictions)))\nprint()\nacc[\"RandomForestClassifier\"] = 1 - metrics.mean_absolute_error(test_labels,predictions)\nRMSE[\"RandomForestClassifier\"] = np.sqrt(metrics.mean_squared_error(test_labels,predictions))\n\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nmodel = GradientBoostingClassifier()\ntrain_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.15)\nmodel.fit(train_features,train_labels)\npredictions = model.predict(test_features)\nprint(\"Gradient Boosting Classifier\")\nprint('Mean Absolute Error:', metrics.mean_absolute_error(test_labels,predictions)) \nprint('Mean Squared Error:', metrics.mean_squared_error(test_labels,predictions)) \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_labels,predictions)))\nprint()\nacc[\"GradientBoostingClassifier\"] = 1 - metrics.mean_absolute_error(test_labels,predictions)\nRMSE[\"GradientBoostingClassifier\"] = np.sqrt(metrics.mean_squared_error(test_labels,predictions))\n\n\nfrom xgboost import XGBClassifier\nmodel = XGBClassifier()\ntrain_features, test_features, train_labels, test_labels = train_test_split(train_data, labels, test_size = 0.15)\nmodel.fit(train_features,train_labels)\npredictions = model.predict(test_features)\nprint(\"XGBClassifier\")\nprint('Mean Absolute Error:', metrics.mean_absolute_error(test_labels,predictions)) \nprint('Mean Squared Error:', metrics.mean_squared_error(test_labels,predictions)) \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_labels,predictions)))\nprint()\nacc[\"XGBClassifier\"] = 1 - metrics.mean_absolute_error(test_labels,predictions)\nRMSE[\"XGBClassifier\"] = np.sqrt(metrics.mean_squared_error(test_labels,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RMSE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Accuracy of different models\")\nplt.ylim(0.3,0.7)\nplt.xticks(rotation=90) \nplt.bar(acc.keys(),acc.values())\nplt.show()\n\nplt.title(\"RMSE of different models\")\nplt.ylim(0.3,0.7)\nplt.xticks(rotation=90) \nplt.bar(RMSE.keys(),acc.values())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}