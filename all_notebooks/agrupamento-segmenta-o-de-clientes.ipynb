{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Agrupamento - Segmentação de Clientes\n\nEste notebook realiza uma análise de Agrupamento de Dados sobre o dataset [Mall Customer Segmentation Data](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python). Um conjunto de dados que reúne características de 200 clientes que frequentam um shopping mall. Neste estudo veremos algumas visualizações de dados sobre os clientes, bem como o uso de agrupamento de dados para segmentação dos clientes, explorando os algoritmos k-Means e DBSCAN - e comparando seus resultados.   \n\n> Conteúdo voltado para iniciantes na área de Aprendizado de Máquina e Ciência de Dados!\n\n<a id=\"top\"></a>\n\n## Conteúdo\n\n> **Nota**. Alguns códigos foram ocultados a fim de facilitar a leitura e dar destaque para os conteúdos mais importantes.\n\nO notebook está organizado como segue:\n\n- [Dados](#loading) - Carregamento dos dados.\n- [Visualização](#visual) - Análise exploratória dos dados.\n- [Agrupamento](#clustering) - Aplicação de algoritmos de Aprendizado de Máquina.\n    - [k-Means](#kmeans) - Segmentação com k-Means.\n    - [DBSCAN](#dbscan) - Segmentação com DBSCAN.\n    - [Dados Sintéticos](#new_data) - Exploração sobre Dados Sintéticos."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"loading\"></a>\n\n---\n\n# Dados\n\n- Carregamento dos dados.\n\n[Voltar para o Topo](#top)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# processamento de dados, algebra linear\nimport numpy as np \nimport pandas as pd\n\n# visualização de dados\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# impime os arquivos\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"visual\"></a>\n\n---\n\n# Visualização dos Dados\n\n- Carregamento dos dados.\n\n[Voltar para o Topo](#top)"},{"metadata":{},"cell_type":"markdown","source":"## Estatística Descritiva\n\nNesta seção vemos dois métodos do `pandas.DataFrame` para visualizar características dos dados, tais como: (1) `.info()`, presença de valores nulos e os tipos dos dados; e (2) `.describe()`, amplitude, média, desvio padrão e quartiles."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizações\n\nVamos visualizar a relação dos atributos \"receita anual\" x \"score de gasto\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Será que o comportamento muda com o sexo?\n\nVamos pintar as bolinhas de acordo com o sexo do cliente."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\", hue=\"Gender\", style=\"Gender\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Será que o comportamento muda com a idade?\n\nVamos pintar as bolinhas de acordo com a idade do cliente."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\", hue=\"Age\", palette='crest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"clustering\"></a>\n\n---\n\n# Agrupamento de Dados\n\nNesta seção exploramos:\n\n- Seleção dos dados de interesse.\n- k-Means\n- DBSCAN\n- Dados Sintéticos _(extra)_\n\n[Voltar para o Topo](#top)"},{"metadata":{},"cell_type":"markdown","source":"## Seleção dos Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# removendo as colunas id, gênero e idade\nX = df.drop(['CustomerID', 'Gender', 'Age'], axis = 1)\nX.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Abaixo tem _(ocultado)_ um código para normalizar os valores por coluna.\n\n> O k-Means utiliza uma função de similaridade para computar a distância entre os pontos.   \n> As funções de similaridade se benificiam de dados normalizados.   \n\n> Para este estudo de caso, este procedimento não muda o resultado final.   "},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# normalizando os valores por coluna\nfrom sklearn import preprocessing\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nX = min_max_scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"kmeans\"></a>\n\n## k-Means\n\nO algoritmo `KMeans` agrupa os dados tentando separar amostras em $k$ grupos de variância igual, minimizando a distância intercluster e maximizando a distância intracluster. Este algoritmo necessita saber o número de grupos, _i.e.,_ valor de $k$.    \n\nNeste estudo, buscamos identificar 5 grupos de clientes do shopping, ou seja, utilizaremos o $k = 5$ para particionar os dados."},{"metadata":{"trusted":true},"cell_type":"code","source":"# aprendizado de máquina\nfrom sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KMeans(n_clusters = 5)\nmodel.fit(X)\ndf['Group'] = model.predict(X)\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizando os Grupos"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\", hue='Group', style='Group', palette='tab10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Características dos Grupos"},{"metadata":{"trusted":true},"cell_type":"code","source":"val = df.drop(['CustomerID', 'Gender', 'Age'], axis = 1).groupby('Group').describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# removendo alguns atributos\nannual_income  = val['Annual Income (k$)'].drop(['std','min','25%','50%','75%','max'], axis = 1)\nspending_score = val['Spending Score (1-100)'].drop(['count','std','25%','50%','75%'], axis = 1)\nval = annual_income.merge(spending_score, left_on='Group', right_on='Group')\nval.columns = ['Count', 'Income Mean', 'Score Mean', 'Score Min', 'Score Max']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"val","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação - Silhouette\n\n[Silhouette](https://en.wikipedia.org/wiki/Silhouette_(clustering)) é uma métrica de interpretação e validação de algoritmos de agrupamento de dados, avaliando a consistência dentro dos grupos. Esta técnica avalia a distância intracluster (*i.e.,* a distância entre os elementos dentro do mesmo grupo) em relação a distância intercluster (*i.e.,* a distância entre elementos de grupos distintos). Neste caso, quanto maior (mais próximo de 1) a silhouette melhor a divisão dos grupos, e o contrário (mais próximo de 1) pior a divisão dos elementos nos grupos - baseando-se nas distâncias (premissa da métrica)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# importa a métrica\nfrom sklearn.metrics import silhouette_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"silhouette_score(X, df['Group'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão k-Means**   \n\nk-Means conseguiu particionar os dados em 5 grupos bem visiveis.   \nNota-se que suas características podem ser descritas como segue:\n\n> **Nota**. Os números dos grupos são aleatórios a cada vez que roda o algoritmo.   \n> Por isso, abaixo são informado os grupos como letras e não números.\n\n- Grupo A - Recebe pouco dinheiro, e tem score baixo.\n- Grupo B - Recebe muito dinheiro, e tem score alto. _(interessante)_\n- Grupo C - Recebe muito dinheiro, e tem score baixo.\n- Grupo D - Recebe pouco dinheiro, e tem score alto.\n- Grupo E - Recebe médio dinheiro, e tem score médio.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"dbscan\"></a>\n\n## DBSCAN\n\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise). Encontra amostras de núcleo de alta densidade e expande os clusters a partir delas. Bom para dados que contêm clusters de densidade semelhante. Existem dois parâmetros para o algoritmo, `min_samples` (número minímo de elementos para formar um grupo) e `eps` (raio de distância dos elementos), que definem o que queremos dizer quando dizemos denso.   \n\n> Neste algoritmo, ele identificará o número ideal de grupos. Contudo, devemos informar outros parâmetros que também são difíceis de serem definidos.\n> Logo, a escolha do algoritmos de Aprendizado de Máquina, depende do seu domínio sobre os dados e definição do problema.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import DBSCAN","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parâmetros, $eps=0.1$ e $min\\_samples=3$"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Group'] = DBSCAN(eps=0.1, min_samples=3).fit(X).labels_\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\", hue='Group', style='Group', palette='tab10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mudando um pouquinho o valor do $eps$ os resultados são totalmente diferentes.   \nParâmetros, $eps=0.09$ e $min\\_samples=3$"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Group'] = DBSCAN(eps=0.09, min_samples=3).fit(X).labels_\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\", hue='Group', style='Group', palette='tab10')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação - Silhouette"},{"metadata":{"trusted":true},"cell_type":"code","source":"silhouette_score(X, df['Group'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão DBSCAN**   \n\nNeste dados a densidade aparenta ser mais difícil de se trabalhar do que a partição do k-Means.   \nNota-se que a definisão do `eps` dificultou a partição dos dados.   \n\nMas quando que o DBSCAN se destaca ao k-Means? depende dos dados...   \nNa próxima seção, veremos um conjunto de dados sintético e o resultado de ambos os modelos.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"new_data\"></a>\n\n## Dados Sintéticos\n\nVamos simular uma nova distribuição de dados, apenas para visualizar a vantagem do DBSCAN sobre o k-Means."},{"metadata":{"trusted":true},"cell_type":"code","source":"# produzir dados sintéticos\nfrom sklearn.datasets import make_blobs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Realiza a geração de um dataset sintético _(código ocultado)._"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"X, Y = make_blobs(n_samples=1500, random_state=170)\ntransformation = [[0.60834549, -0.43667341], [-0.40887718, 0.85253229]]\nX_aniso = np.dot(X, transformation)\nX, Y = X_aniso[:, 0], X_aniso[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(X, Y)\nplt.title(\"Dados Sintéticos\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DBSCAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = DBSCAN(eps=0.4, min_samples=3).fit(X_aniso).labels_\nplt.scatter(X, Y, c=pred)\nplt.title(\"Dados Sintéticos - DBSCAN\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### k-Means\n\nVamos ver o desenpenho do k-Means sobre o conjunto de dados sintético?"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = KMeans(n_clusters = 3).fit(X_aniso).predict(X_aniso)\nplt.scatter(X, Y, c=pred)\nplt.title(\"Dados Sintéticos - k-Means\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-----\n\n**Conclusão**   \n\nConhecer o comportamento dos dados é essencial, afim de escolher o melhor algoritmo de agrupamento.   \n\n> 1. Nos dados dos consumidores do Shopping, o algoritmo k-Means apresentou bons resultados.   \n> 2. Contudo nos dados sintéticos, o algoritmo DBSCAN se destacou pela habilidade de agrupar regiões densas.   \n\n[Voltar para o Topo](#top)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}