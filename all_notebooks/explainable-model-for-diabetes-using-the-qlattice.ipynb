{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Explainable models Use a Community QLattice to find explainable models for diabetes\n\nThe QLattice is a supervised machine learning tool for symbolic regression developed by [Abzu](https://www.abzu.ai) . It is inspired by Richard Feynman's path integral formulation. That's why the python module to use it is called *Feyn*, and the *Q* in QLattice is for Quantum.\n\nAbzu provides free QLattices for non-commercial use to anyone. These free community QLattices gets allocated for us automatically if we use Feyn without an active subscription, as we will do in this notebook. Read more about how it works here: https://docs.abzu.ai/docs/guides/getting_started/community.html\n\nThe feyn Python module is not installed on Kaggle by default so we have to pip install it first. \n\n__Note__: the pip install will fail unless you enable *Internet* in the *settings* to the right --->","metadata":{}},{"cell_type":"code","source":"!pip install feyn","metadata":{"execution":{"iopub.status.busy":"2021-06-22T13:54:02.231865Z","iopub.execute_input":"2021-06-22T13:54:02.232324Z","iopub.status.idle":"2021-06-22T13:54:08.945799Z","shell.execute_reply.started":"2021-06-22T13:54:02.232266Z","shell.execute_reply":"2021-06-22T13:54:08.944593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Python imports\nIn this notebook we will use only three python modules: the `feyn` module to access the QLattice, and the `pandas` module to access the data, and sklearn to split the data in test/train sets","metadata":{}},{"cell_type":"code","source":"import feyn\nimport pandas as pd\nimport sklearn.model_selection","metadata":{"execution":{"iopub.status.busy":"2021-06-22T13:54:08.948359Z","iopub.execute_input":"2021-06-22T13:54:08.948683Z","iopub.status.idle":"2021-06-22T13:54:08.954475Z","shell.execute_reply.started":"2021-06-22T13:54:08.94865Z","shell.execute_reply":"2021-06-22T13:54:08.953006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data\nRead in the data and have a quick look at it:","metadata":{}},{"cell_type":"code","source":"data = '/kaggle/input/predict-diabetes-based-on-diagnostic-measures/diabetes.csv'\ndf = pd.read_csv(data)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-22T13:54:08.956142Z","iopub.execute_input":"2021-06-22T13:54:08.956519Z","iopub.status.idle":"2021-06-22T13:54:09.005108Z","shell.execute_reply.started":"2021-06-22T13:54:08.956477Z","shell.execute_reply":"2021-06-22T13:54:09.003695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adjust data types\nThe \"gender\" and \"diabetes\" features are really boolean, but represented as text. Let's start by fixing that.\nWe will also remove the patient_number column as it will overfit","metadata":{}},{"cell_type":"code","source":"df[\"gender\"]=(df[\"gender\"]==\"male\").astype(int)\ndf[\"diabetes\"]=(df[\"diabetes\"]==\"Diabetes\").astype(int)\ndf.drop([\"patient_number\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T13:54:09.006535Z","iopub.execute_input":"2021-06-22T13:54:09.006823Z","iopub.status.idle":"2021-06-22T13:54:09.018188Z","shell.execute_reply.started":"2021-06-22T13:54:09.006795Z","shell.execute_reply":"2021-06-22T13:54:09.01691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is also a problem with the three real-valued columns: \"chol_hdl_ratio\", \"bmi\" and \"waist_hip_ratio\". They use comma as a decimal seperator, European-style, which the csv parser in pandas did not know about. Lets fix that too:","metadata":{}},{"cell_type":"code","source":"df[\"bmi\"] = df[\"bmi\"].str.replace(\",\",\".\").astype(float)\ndf[\"waist_hip_ratio\"] = df[\"waist_hip_ratio\"].str.replace(\",\",\".\").astype(float)\ndf[\"chol_hdl_ratio\"] = df[\"chol_hdl_ratio\"].str.replace(\",\",\".\").astype(float)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T13:54:09.021358Z","iopub.execute_input":"2021-06-22T13:54:09.021683Z","iopub.status.idle":"2021-06-22T13:54:09.03566Z","shell.execute_reply.started":"2021-06-22T13:54:09.021631Z","shell.execute_reply":"2021-06-22T13:54:09.034418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target balance\nLet's have a quick look at the balance of target variable","metadata":{}},{"cell_type":"code","source":"df.diabetes.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T13:54:09.037878Z","iopub.execute_input":"2021-06-22T13:54:09.038426Z","iopub.status.idle":"2021-06-22T13:54:09.059954Z","shell.execute_reply.started":"2021-06-22T13:54:09.038333Z","shell.execute_reply":"2021-06-22T13:54:09.058426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are skewed towards \"No diabetes\". \n\n# Splitting\nLet's split the data for train/test. We will stratify by diabetes and take 2/3 for training. This will leave 20 diabetic patients in the test set, so we are at the quite low end.","metadata":{}},{"cell_type":"code","source":"train, test = sklearn.model_selection.train_test_split(df,stratify=df[\"diabetes\"], train_size=.66, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:02:24.527443Z","iopub.execute_input":"2021-06-22T14:02:24.527787Z","iopub.status.idle":"2021-06-22T14:02:24.53588Z","shell.execute_reply.started":"2021-06-22T14:02:24.527759Z","shell.execute_reply":"2021-06-22T14:02:24.534641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.diabetes.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:02:24.955835Z","iopub.execute_input":"2021-06-22T14:02:24.956426Z","iopub.status.idle":"2021-06-22T14:02:24.963459Z","shell.execute_reply.started":"2021-06-22T14:02:24.956386Z","shell.execute_reply":"2021-06-22T14:02:24.962736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Allocate a QLattice\nThe actual QLattice is a quantum simulator that runs on Abzu's hardware, but we can allocate one to use for our analysis with a single line of code. Hopefully the following line will get us one.","metadata":{}},{"cell_type":"code","source":"ql = feyn.connect_qlattice()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T13:54:09.07757Z","iopub.execute_input":"2021-06-22T13:54:09.078019Z","iopub.status.idle":"2021-06-22T13:54:10.437113Z","shell.execute_reply.started":"2021-06-22T13:54:09.077975Z","shell.execute_reply":"2021-06-22T13:54:10.436257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resetting and reproducability\nThe QLattice has the potential to store learnings between sessions to enable transfer of learning and federated learning. This is not possible with Community QLattices, since a new one gets allocated whenever we run the notebook, so it is not strictly necessary to call the reset function on our new QLattice. \n\nBut the reset function also allows us to provide a random seed, which will ensure that we get the same results every time we run this notebook","metadata":{}},{"cell_type":"code","source":"ql.reset(random_seed=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:07:42.517648Z","iopub.execute_input":"2021-06-22T14:07:42.518104Z","iopub.status.idle":"2021-06-22T14:07:43.335181Z","shell.execute_reply.started":"2021-06-22T14:07:42.518064Z","shell.execute_reply":"2021-06-22T14:07:43.334022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Search for the best model\n\nWe are now ready to instruct the QLattice to search for the best mathematical model to explain the data. Here we use the high-level convenience function that does everything with sensible defaults: https://docs.abzu.ai/docs/guides/essentials/auto_run.html.\n\nFor more detailed control, we could use the primitives: https://docs.abzu.ai/docs/guides/primitives/using_primitives.html\n\nNOTE: This will take a minute to complete. It involves work done on the QLattice machine remotely as well as in the local notebook. The part that runs locally is slowing things down because of the limited CPU resources on Kaggle. Running the same on my machine locally only takes 10 seconds!","metadata":{}},{"cell_type":"code","source":"models = ql.auto_run(train, output_name=\"diabetes\", kind=\"classification\", criterion=\"aic\")","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:07:44.15524Z","iopub.execute_input":"2021-06-22T14:07:44.155762Z","iopub.status.idle":"2021-06-22T14:08:57.096962Z","shell.execute_reply.started":"2021-06-22T14:07:44.155727Z","shell.execute_reply":"2021-06-22T14:08:57.096039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A quite simple model\nWe have ended up with a model that uses only two features, age and glucose. That is quite minimal, and impressive if it works well. \n\n# Evaluate the performance of the model\nLets look at the ROC curves of the model on the training and the test data","metadata":{}},{"cell_type":"code","source":"models[0].plot_roc_curve(train, label=\"Training data\")\nmodels[0].plot_roc_curve(test, label=\"Test data\")","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:25:40.528566Z","iopub.execute_input":"2021-06-22T14:25:40.529027Z","iopub.status.idle":"2021-06-22T14:25:40.68961Z","shell.execute_reply.started":"2021-06-22T14:25:40.528993Z","shell.execute_reply":"2021-06-22T14:25:40.68873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seems good\nWith only two features we get an AUC of .94 on the test data. This is pretty much exactly thee same as the performance on the training data, indicating that the model generalises very well. This is consistent with other findings, such as for example this research paper:\n[Symbolic regression outperforms other models for small data sets](https://arxiv.org/abs/2103.15147)\n\nLet's have a look at the actual mathematical expression found:","metadata":{}},{"cell_type":"code","source":"models[0].sympify(2)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:29:03.08886Z","iopub.execute_input":"2021-06-22T14:29:03.089272Z","iopub.status.idle":"2021-06-22T14:29:03.118239Z","shell.execute_reply.started":"2021-06-22T14:29:03.089237Z","shell.execute_reply":"2021-06-22T14:29:03.116685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparison\nFinally, let's compare it to the usual model methods, random forest, gradient boosting and logistic regression","metadata":{}},{"cell_type":"code","source":"rf = feyn.reference.RandomForestClassifier(train, output_name=\"diabetes\")\ngb = feyn.reference.GradientBoostingClassifier(train, output_name=\"diabetes\")\nlr = feyn.reference.LogisticRegressionClassifier(train, output_name=\"diabetes\", max_iter=10000)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:09:05.036932Z","iopub.execute_input":"2021-06-22T14:09:05.037316Z","iopub.status.idle":"2021-06-22T14:09:05.657002Z","shell.execute_reply.started":"2021-06-22T14:09:05.037285Z","shell.execute_reply":"2021-06-22T14:09:05.655623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.plot_roc_curve(test, label=\"Random Forest\")\ngb.plot_roc_curve(test, label=\"Gradient Boosting\")\nlr.plot_roc_curve(test, label=\"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2021-06-22T14:30:41.596114Z","iopub.execute_input":"2021-06-22T14:30:41.596615Z","iopub.status.idle":"2021-06-22T14:30:41.802489Z","shell.execute_reply.started":"2021-06-22T14:30:41.596579Z","shell.execute_reply":"2021-06-22T14:30:41.801047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pretty consistent\nAll the four models curiously perform about equally well. The unique property of the QLattice is really that it is able to explain the data with the use of only two features in a fairly straightforward mathematical equation.\n\n# Conclusion\nUsing the QLattice for symbolic regression, we were able to find a model that predicts diabetes in this dataset with the same accuracy as the usual black-box machine learning techniques.\n\nA simple result such as this one will have much more clinical credibility than a black-box model, and will also help medical researchers understand what actually drives diabetes.\n\nNote though, that the findings are quite limited by the small size of the data set.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}