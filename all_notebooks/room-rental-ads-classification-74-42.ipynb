{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nimport missingno as miss\n\nfrom collections import Counter\n\nfrom nltk.corpus import stopwords #removes and, in, the, a ... etc\n\nimport plotly.express as px\n\nimport matplotlib.pyplot as plt\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"FILEPATH = '/kaggle/input/newyork-room-rentalads/room-rental-ads.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(FILEPATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visual on Null"},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.heatmap(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.dendrogram(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.bar(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the number of missing data points per column\nmissing_values_count = df.isnull().sum()\n\n# missing points in the first 10 \nmissing_values_count[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_space(pre_content, total_space_count = 30):\n\n    current_space_count = total_space_count - len(pre_content)\n    \n    return pre_content + (\" \" * current_space_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_missing_percentage(current_df):\n    \n    total_cells = np.product(current_df.shape)\n    total_missing = missing_values_count.sum()\n    \n    total_space_count = 20\n\n    print(get_space(\"Total cells\", total_space_count)+\": {}\".format(total_cells))\n    print(get_space(\"Total missing cells\", total_space_count)+\": {}\".format(total_missing))\n\n    missing_percentage = (total_missing / total_cells)\n\n    print(get_space(\"Missing Percentage\", total_space_count)+\": {:.2%}\".format(missing_percentage))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_missing_percentage(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning Process"},{"metadata":{},"cell_type":"markdown","source":"Check for null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 20 null entries in the Dataset. Let's drop them we don't want them at the moment."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's rename the column `Vague/Not` to `Low_Quality`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns = {'Vague/Not' : 'Low_Quality'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's change the data type of `Low_Quality` column from float to int"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Low_Quality'] = df['Low_Quality'].astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['new_col'] = range(1, len(df) + 1)\ndf = df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visual Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_donut_plot(col):\n    \n    cur_df = df\n    \n#     rating_data = cur_df.groupby(col)[['Complaint ID']].count().head(10)\n    rating_data = cur_df.groupby(col)[['index']].count().head(10)\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data[['index']], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    \n    cols = []\n    for index, row in rating_data.iterrows():\n        cols.append(index)\n    plt.legend(cols)\n    \n    plt.title('Donut Plot - ' + str(col) + '', loc='center')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_donut_plot('Low_Quality')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean the data\ndef clean_text_simple(text):\n    text = text.lower()\n    text = re.sub(r'[^(a-zA-Z)\\s]','', text)\n    text = text.strip()\n    text = re.sub(\"\\n\", \"\", text)\n\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Description'] = df['Description'].apply(clean_text_simple)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Named Entity Recognition"},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\n\nnlp = spacy.load('en_core_web_sm') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we will remove noise in the string. \n# Sample noise: httpsyoutube, httpswwwyoutube, (string less than 3 characters)\ndef is_noise(content):\n    \n    if('httpsyoutube' in content or 'httpswwwyoutube' in content):\n        return True\n    \n    if(len(content) < 3):\n        return True\n    \n    return False\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_NER(sentence):\n  \n    doc = nlp(sentence) \n    \n    ner_set = set()\n    \n    for ent in doc.ents: \n        # print(ent.text, ent.start_char, ent.end_char, ent.label_) \n        # print(ent.text)\n        \n        current_ner = str(ent.text)\n        \n        if(not is_noise(current_ner)):\n            ner_set.add(current_ner)\n    \n    return list(ner_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NER'] = df['Description'].apply(get_NER)\ndf['NER_count'] = df['NER'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = df[['NER', 'NER_count']][0:50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def highlight_max_custom(s, color = 'lightblue'):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: '+color if v else '' for v in is_max]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.style.apply(highlight_max_custom, color = '#CFFE96',  axis = 0, subset=['NER_count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords1 = stopwords.words('english')\n\nwords_collection = Counter([item for sublist in df['NER'] for item in sublist if not item in stopwords1])\nfreq_word_df = pd.DataFrame(words_collection.most_common(30))\nfreq_word_df.columns = ['frequently_used_word','count']\n\n\nfreq_word_df.style.background_gradient(cmap='OrRd', low=0, high=0, axis=0, subset=None)\n\n# Possible color map values\n# 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds', 'YlOrBr', \n# 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu','GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we need to keep the pie chart clean, we are using only top 15 rows\nfreq_word_df_small = freq_word_df[0:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(freq_word_df_small, values='count', names='frequently_used_word', title='Rental ads - Frequently Used NER')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n\n* `manhattan` NER is used most in the rental ads.\n* `brooklyn` NER comes as a second most word."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define how much percent data you wanna split\nsplit_count = int(0.23 * len(df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffles dataframe\ndf = df.sample(frac=1).reset_index(drop=True)\n\n# Training Sets\ntrain = df[split_count:]\ntrainX = train['Description']\ntrainY = train['Low_Quality'].values\n\n# Test Sets\ntest = df[:split_count]\ntestX = test['Description']\ntestY = test['Low_Quality'].values\n\nprint(f\"Training Data Shape: {testX.shape}\\nTest Data Shape: {testX.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Load the vectorizer, fit on training set, transform on test set\nvectorizer = TfidfVectorizer()\ntrainX = vectorizer.fit_transform(trainX)\ntestX = vectorizer.transform(testX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's introduce various models to the maximum accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier()\ndt_model = dt_model.fit(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier().fit(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n\nknn_model = knn.fit(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlor = LogisticRegression(solver = \"liblinear\")\nlor_model = lor.fit(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\n#     svm_model,\n    dt_model,\n    rf_model,\n    knn_model,\n    lor_model\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_accuracy = 0\nbest_model = None\n\nfor model in models:\n    \n    model_name = model.__class__.__name__\n    \n    predY = model.predict(testX)\n    accuracy = accuracy_score(testY, predY)\n    \n    print(\"-\" * 43)\n    print(model_name + \": \" )\n    \n    if(accuracy > best_model_accuracy):\n        best_model_accuracy = accuracy\n        best_model = model_name\n    \n    print(\"Accuracy: {:.2%}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best Model : {}\".format(best_model))\nprint(\"Best Model Accuracy : {:.2%}\".format(best_model_accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To Do:**\n\n* Need to clean up the code with more feature engineering, etc.\n* Need to add more documentation\n* Need to come up with more visualization"},{"metadata":{},"cell_type":"markdown","source":"**Final Notes:**\n\nI am adding things still. You can come back and check for more information.\n\nAlso, if you **like my notebook**, <font style=\"color:blue;size:14px;\">please upvote it</font> as it will motivate me to come up with better approach in the upcoming notebooks.\n"},{"metadata":{},"cell_type":"markdown","source":"<table style=\"font-family: 'Trebuchet MS', Arial, Helvetica, sans-serif;border-collapse: collapse;width: 100%;\">\n  <tr>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Notebook</th>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Tags</th>\n  </tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/sof-questions-eda-and-visual\">SOF Questions - EDA and Visual</a> </td>\n    <td style=\"text-align: left\">Data Visual, Plotly</td>\n  </tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/netflix-visualization-plotly-plots-treemap\">Netflix - Visualization, Plotly, Plots, and Treemap</a> </td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, Data Cleaning, Plotly</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/prediction-with-various-algorithms\">Prediction with various Algorithms</a> </td>\n    <td style=\"text-align: left\">Random Forest, Logistic Regression</td>\n  </tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/eda-and-visualization\">EDA and Visualization</a> </td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Cleaning, Data Visual</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/job-analysis-eda-visual\">Job Analysis - EDA and Visual</a> </td>\n    <td style=\"text-align: left\">Data Visual, EDA, Plotly</td>\n  </tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/estonia-disaster-visualization\">Estonia Disaster - Visualization</a> </td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, EDA, Data Cleaning</td>\n  </tr>\n    \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/pandas-dundas-challenge-100\" >Pandas 100+ exercises collection</a></td>\n    <td style=\"text-align: left\">Pandas, Data Manipulation</td>\n  </tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/prediction-with-various-algorithms\">Credit Card Fraud - Prediction with various algorithms</a></td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Various ML Algorithms</td>\n  </tr>  \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/linear-equations-real-time\">Linear Equations - Real Time</a> </td>\n    <td style=\"text-align: left\">Linear Equation</td>\n  </tr>  \n</table>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}