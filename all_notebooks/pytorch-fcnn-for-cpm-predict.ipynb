{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary\n!pip install mlencoders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport tqdm\nimport warnings\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom mlencoders.target_encoder import TargetEncoder\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchsummary import summary\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Загрузка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv('/kaggle/input/real-time-advertisers-auction/Dataset.csv', sep=',', verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Целевая переменная "},{"metadata":{"trusted":true},"cell_type":"code","source":"def weird_division(n, d):\n    if d:\n        return n / d\n    else:\n        return 0\n\nraw_data['CPM'] = raw_data.apply(lambda x: weird_division(((x['total_revenue'] * 100)), x['measurable_impressions']) * 1000, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Удаление ненужных признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_for_drop(df, cols):\n    n = []\n    f = []\n    for col in cols:\n        if len(df[col].unique()) < 2: \n            n.append(len(df[col].unique()))\n            f.append(col)\n    return dict(zip(f, n))\n\nfeatures_for_drop(raw_data, raw_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_data = raw_data.drop(['revenue_share_percent', 'integration_type_id', 'total_revenue', 'measurable_impressions'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Деление выборки на тренировочную и тестовую"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = clean_data[clean_data['date'].between('2019-06-01 00:00:00', '2019-06-21 00:00:00')]\nX_test = clean_data[clean_data['date'].between('2019-06-22 00:00:00', '2019-06-30 00:00:00')]\n\nX_train_95_per = X_train['CPM'].quantile(0.95)\nX_test_95_per = X_test['CPM'].quantile(0.95)\n\nX_test = X_test[(X_test['CPM'] >= 0) & (X_test['CPM'] < X_test_95_per)]\n\nX_valid = X_train.sample(frac=0.1, random_state=1234, replace=False)\nX_train = X_train.loc[list(set(X_train.index) - set(X_valid.index)), :]\n\nX_train = X_train[X_train['CPM'] < X_train_95_per]\nX_valid = X_valid[X_valid['CPM'] < X_train_95_per]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Кодирование категориальных признаков "},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = TargetEncoder(cols=['site_id',\n                          'ad_type_id',\n                          'geo_id',\n                          'device_category_id',\n                          'advertiser_id',\n                          'order_id',\n                          'line_item_type_id',\n                          'os_id',\n                          'monetization_channel_id',\n                          'ad_unit_id',\n                          'total_impressions',\n                          'viewable_impressions',\n                         ],\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_enc = enc.fit_transform(X_train, X_train['CPM'])\nX_valid_enc = enc.transform(X_valid)\nX_test_enc = enc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_enc.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = X_train_enc['CPM'].values\nX_train = X_train_enc.drop(['CPM', 'date'], axis=1).values\n\ny_val = X_valid_enc['CPM'].values\nX_val = X_valid_enc.drop(['CPM', 'date'], axis=1).values\n\ny_test = X_test_enc['CPM'].values\nX_test = X_test_enc.drop(['CPM', 'date'], axis=1).values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Масштабирование признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\n\nX_train_sc = scaler.fit_transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Создание нейросетевой модели (полносвязная сеть)"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cpu')\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RegressionDataset(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n    \ntrain_dataset = RegressionDataset(torch.from_numpy(X_train_sc).float(), torch.from_numpy(y_train).float())\nval_dataset = RegressionDataset(torch.from_numpy(X_val_sc).float(), torch.from_numpy(y_val).float())\ntest_dataset = RegressionDataset(torch.from_numpy(X_test_sc).float(), torch.from_numpy(y_test).float())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 30\nBATCH_SIZE = 1024\nLEARNING_RATE = 0.001\n\nNUM_FEATURES = X_train_sc.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultipleRegression(nn.Module):\n    def __init__(self, num_features):\n        super(MultipleRegression, self).__init__()\n        \n        self.layer_1 = nn.Linear(num_features, 30)\n        self.bn1 = nn.BatchNorm1d(num_features=30)\n        self.layer_2 = nn.Linear(30, 15)\n        self.bn2 = nn.BatchNorm1d(num_features=15)\n        self.layer_3 = nn.Linear(15, 10)\n        self.bn3 = nn.BatchNorm1d(num_features=10)\n        self.layer_out = nn.Linear(10, 1)       \n        self.relu = nn.ReLU()\n    \n    def forward(self, inputs):\n        x = self.relu(self.bn1(self.layer_1(inputs)))\n        x = self.relu(self.bn2(self.layer_2(x)))\n        x = self.relu(self.bn3(self.layer_3(x)))\n        x = self.layer_out(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MultipleRegression(NUM_FEATURES)\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(model=model, input_size=(NUM_FEATURES, ), device='cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_stats = {'train': [], \"val\": [], }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Start training\")\n\nfor e in tqdm.tqdm_notebook(range(1, EPOCHS+1)):\n    \n    # TRAINING\n    train_epoch_loss = 0\n    model.train()\n    for X_train_batch, y_train_batch in train_loader:\n        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n        optimizer.zero_grad()\n        y_train_pred = model(X_train_batch)\n        train_loss = criterion(y_train_pred, y_train_batch.unsqueeze(1))\n        train_loss.backward()\n        optimizer.step()\n        train_epoch_loss += train_loss.item()\n              \n    # VALIDATION    \n    with torch.no_grad():\n        val_epoch_loss = 0\n        model.eval()\n        for X_val_batch, y_val_batch in val_loader:\n            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n            y_val_pred = model(X_val_batch)            \n            val_loss = criterion(y_val_pred, y_val_batch.unsqueeze(1))\n            val_epoch_loss += val_loss.item()\n            \n    loss_stats['train'].append(train_epoch_loss / len(train_loader))\n    loss_stats['val'].append(val_epoch_loss / len(val_loader))                              \n    \n    print(f'Epoch {e+0:03}: | Train MSE: {train_epoch_loss / len(train_loader):.5f} | Val MSE: {val_epoch_loss / len(val_loader):.5f}')\n    \nprint(\"Finish training\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Оценка качества модели на тестовой выборке"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_list = []\n\nwith torch.no_grad():\n    model.eval()\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        y_pred_list.append(y_test_pred.cpu().numpy())\n        \ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MSE on test data = {}'.format(mean_squared_error(y_test, y_pred_list)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}