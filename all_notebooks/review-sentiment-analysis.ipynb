{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re # for regex\n# NLTK\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\n# BOW\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\nfrom sklearn.metrics import accuracy_score\n# pkl\nimport pickle\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\nprint(data.shape)\ndata.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### No null values. Label encode sentiment to 1(positive) and 0(negative)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sentiment.replace('positive',1,inplace=True)\ndata.sentiment.replace('negative',0,inplace=True)\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.review[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## STEPS TO CLEAN THE REVIEWS :\n1. Remove HTML tags\n2. Remove special characters\n3. Convert everything to lowercase\n4. Remove stopwords\n5. Stemming","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Remove HTML tags\nRegex rule : '<.*?>'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(text):\n    cleaned = re.compile(r'<.*?>')\n    return re.sub(cleaned,'',text)\n\ndata.review = data.review.apply(clean)\ndata.review[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Remove special characters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_special(text):\n    rem = ''\n    for i in text:\n        if i.isalnum():\n            rem = rem + i\n        else:\n            rem = rem + ' '\n    return rem\n\ndata.review = data.review.apply(is_special)\ndata.review[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Convert everything to lowercase","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_lower(text):\n    return text.lower()\n\ndata.review = data.review.apply(to_lower)\ndata.review[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Remove stopwords","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def rem_stopwords(text):\n    stop_words = set(stopwords.words('english'))\n    words = word_tokenize(text)\n    return [w for w in words if w not in stop_words]\n\ndata.review = data.review.apply(rem_stopwords)\ndata.review[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Stem the words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def stem_txt(text):\n    ss = SnowballStemmer('english')\n    return \" \".join([ss.stem(w) for w in text])\n\ndata.review = data.review.apply(stem_txt)\ndata.review[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CREATING THE MODEL","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Creating Bag Of Words (BOW)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(data.iloc[:,0].values)\ny = np.array(data.sentiment.values)\ncv = CountVectorizer(max_features = 1000)\nX = cv.fit_transform(data.review).toarray()\nprint(\"X.shape = \",X.shape)\nprint(\"y.shape = \",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Train test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx,testx,trainy,testy = train_test_split(X,y,test_size=0.2,random_state=9)\nprint(\"Train shapes : X = {}, y = {}\".format(trainx.shape,trainy.shape))\nprint(\"Test shapes : X = {}, y = {}\".format(testx.shape,testy.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Defining the models and Training them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb,mnb,bnb = GaussianNB(),MultinomialNB(alpha=1.0,fit_prior=True),BernoulliNB(alpha=1.0,fit_prior=True)\ngnb.fit(trainx,trainy)\nmnb.fit(trainx,trainy)\nbnb.fit(trainx,trainy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Prediction and accuracy metrics to choose best model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ypg = gnb.predict(testx)\nypm = mnb.predict(testx)\nypb = bnb.predict(testx)\n\nprint(\"Gaussian = \",accuracy_score(testy,ypg))\nprint(\"Multinomial = \",accuracy_score(testy,ypm))\nprint(\"Bernoulli = \",accuracy_score(testy,ypb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(bnb,open('model1.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rev =  \"\"\"Terrible. Complete trash. Brainless tripe. Insulting to anyone who isn't an 8 year old fan boy. Im actually pretty disgusted that this movie is making the money it is - what does it say about the people who brainlessly hand over the hard earned cash to be 'entertained' in this fashion and then come here to leave a positive 8.8 review?? Oh yes, they are morons. Its the only sensible conclusion to draw. How anyone can rate this movie amongst the pantheon of great titles is beyond me.\n\nSo trying to find something constructive to say about this title is hard...I enjoyed Iron Man? Tony Stark is an inspirational character in his own movies but here he is a pale shadow of that...About the only 'hook' this movie had into me was wondering when and if Iron Man would knock Captain America out...Oh how I wished he had :( What were these other characters anyways? Useless, bickering idiots who really couldn't organise happy times in a brewery. The film was a chaotic mish mash of action elements and failed 'set pieces'...\n\nI found the villain to be quite amusing.\n\nAnd now I give up. This movie is not robbing any more of my time but I felt I ought to contribute to restoring the obvious fake rating and reviews this movie has been getting on IMDb.\"\"\"\nf1 = clean(rev)\nf2 = is_special(f1)\nf3 = to_lower(f2)\nf4 = rem_stopwords(f3)\nf5 = stem_txt(f4)\n\nbow,words = [],word_tokenize(f5)\nfor word in words:\n    bow.append(words.count(word))\n#np.array(bow).reshape(1,3000)\n#bow.shape\nword_dict = cv.vocabulary_\npickle.dump(word_dict,open('bow.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = []\nfor i in word_dict:\n    inp.append(f5.count(i[0]))\ny_pred = bnb.predict(np.array(inp).reshape(1,1000))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}