{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"602c63c3-ecf8-9ada-eab4-4c50a6451974"},"source":"## Summary\n\nThere are several \"classic\" models which fit well with this dataset and achieve a great accuracy. We are going to use a neural network to experiment its potential to transform raw input data into useful features to difference the two possible classes. We have implemented a neural network with Keras and obtained the values of the hidden layer for each input. We have used t-SNE to project this data in a two dimension plot where we can see the points of each class are grouped."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6ab3261-af03-285e-7e4c-b62f7f78f378"},"outputs":[],"source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport math"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"39b6c1c8-7444-02a5-b63c-0f0ca8dfe0a4"},"outputs":[],"source":"data = pd.read_csv(\"../input/mushrooms.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f7688e2-2730-689d-d440-215b2fe63a92"},"outputs":[],"source":"data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93ca8a70-fb7d-56ba-39b9-82585fbea984"},"outputs":[],"source":"data.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8d81d6d-af33-fa11-c2f5-388f35311b77"},"outputs":[],"source":"data['stalk-root'].value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"1cfe9ea2-ae8e-10a1-101d-0aa134f6042c"},"source":"More than 30% of the values of **stalk-root** are missing values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f209adc7-1f41-0592-5deb-0b07e00b45c5"},"outputs":[],"source":"100*len(data.loc[data['stalk-root']=='?']) / sum(data['stalk-root'].value_counts())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e195102-07aa-28c6-a22c-8b0f761c1322"},"outputs":[],"source":"data = data.drop('stalk-root', 1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"22cce55f-ac5d-d571-7f70-c062e94ddb05"},"source":"We prepare the data to be used in the neural network model:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e798914-a2c8-3402-9ec6-3fda51432103"},"outputs":[],"source":"Y = pd.get_dummies(data.iloc[:,0],  drop_first=False)\nX = pd.DataFrame()\nfor each in data.iloc[:,1:].columns:\n    dummies = pd.get_dummies(data[each], prefix=each, drop_first=False)\n    X = pd.concat([X, dummies], axis=1)\n    "},{"cell_type":"markdown","metadata":{"_cell_guid":"a933f169-7172-5fce-3f85-41a27a8d0b2b"},"source":"We build the neural network with Keras:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22c2729a-7f4e-bf8b-a2d0-c83eeebaf4b9"},"outputs":[],"source":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import cross_val_score\nfrom keras import backend as K\n\nseed = 123456 \n\ndef create_model():\n    model = Sequential()\n    model.add(Dense(20, input_dim=X.shape[1], kernel_initializer='uniform', activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(2, activation='softmax'))\n    sgd = SGD(lr=0.01, momentum=0.7, decay=0, nesterov=False)\n    model.compile(loss='binary_crossentropy' , optimizer='sgd', metrics=['accuracy'])\n    return model"},{"cell_type":"markdown","metadata":{"_cell_guid":"68765185-183a-2e30-e237-af7d4d722f78"},"source":"We train the model and get the associated training graphs:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e93a707a-6532-785b-c861-9806dde8b085"},"outputs":[],"source":"model = create_model()\nhistory = model.fit(X.values, Y.values, validation_split=0.33, epochs=200, batch_size=100, verbose=0)\n\n\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"2d5df817-f465-a473-fc15-f823951542fb"},"source":"We have good accuracy although this model tens to overfit:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9bc7af90-31fd-2c22-f76f-a5d1e0579c39"},"outputs":[],"source":"print(\"Training accuracy: %.2f%% / Validation accuracy: %.2f%%\" % \n      (100*history.history['acc'][-1], 100*history.history['val_acc'][-1]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7226b25f-2124-c2af-1c80-38c1b61b171b"},"source":"We are going to obtain the values of the layer previous to the output layer:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43c47c35-f7ed-199c-4c97-0b37fcb6a889"},"outputs":[],"source":"from keras import backend as K\nimport numpy as np\n\nlayer_of_interest=0\nintermediate_tensor_function = K.function([model.layers[0].input],[model.layers[layer_of_interest].output])\nintermediate_tensor = intermediate_tensor_function([X.iloc[0,:].values.reshape(1,-1)])[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8021a601-66b6-89ae-19ab-80d224c4ccfe"},"outputs":[],"source":"intermediates = []\ncolor_intermediates = []\nfor i in range(len(X)):\n    output_class = np.argmax(Y.iloc[i,:].values)\n    intermediate_tensor = intermediate_tensor_function([X.iloc[i,:].values.reshape(1,-1)])[0]\n    intermediates.append(intermediate_tensor[0])\n    if(output_class == 0):\n        color_intermediates.append(\"#0000ff\")\n    else:\n        color_intermediates.append(\"#ff0000\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"a197a930-cd16-9c2e-2011-84fa4f8c9d07"},"source":"The penultimate layer has 10 neurons. We are going to build a t-SNE projection:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93338989-2de6-4fdc-856a-ba75612edec6"},"outputs":[],"source":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2, random_state=0)\nintermediates_tsne = tsne.fit_transform(intermediates)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"232934dc-c67b-c1c6-10b1-ac5598ada68d"},"outputs":[],"source":"plt.figure(figsize=(8, 8))\nplt.scatter(x = intermediates_tsne[:,0], y=intermediates_tsne[:,1], color=color_intermediates)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"59452356-950c-de04-accd-c82899d6f0c4"},"source":"## Conclusion\n\nWe have obtained a clear image where the different classes are very identificable (poison and edible mushrooms)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}