{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Citim datele"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"nRowsRead = 1000\ndf1 = pd.read_csv('/kaggle/input/Bucharest_HousePriceDataset.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'Bucharest_HousePriceDataset.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Incarcam librariile"},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\nfrom IPython.display import HTML\nimport math\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation, rc\nimport numpy as np\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import LinearRegression\nimport torch\nimport torch.nn as nn\nimport sklearn\nimport torch.nn.functional as F\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rezolvarea problemei prin REGRESIE"},{"metadata":{"trusted":true},"cell_type":"code","source":"class GDLinearRegression(nn.Module):\n  \"\"\"A simple Linear Regression model\"\"\"\n\n  def __init__(self):\n    super().__init__()\n    # We're initializing our model with random weights\n    self.w = nn.Parameter(torch.randn(6, requires_grad = True))\n    self.b = nn.Parameter(torch.randn(1, requires_grad = True))\n\n  def __call__(self, x: torch.Tensor) -> torch.Tensor:\n    x = torch.Tensor(x)\n    result = x @ self.w+self.b\n    return result\n\n  # PyTorch is accumulating gradients\n  # After each Gradient Descent step we should reset the gradients\n  def zero_grad(self):\n    self.w.grad.zero_()\n    self.b.grad.zero_()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MSE():\n  \"\"\"The Mean Squared Error loss\"\"\"\n  \n  def __call__(self, x: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n    x = torch.Tensor(x)\n    target = torch.Tensor(target)\n    #mse = (abs(x-target)).sum()\n    mse = ((x-target)**2).sum().sqrt().mean()\n    return mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GD():\n  \"\"\"Gradient Descent optimizer\"\"\"\n\n  def __init__(self, params: torch.Tensor, lr: int):\n    self.w, self.b = list(params)\n    self.lr = lr\n\n\n  def step(self):\n   # print(f'lr:{self.lr} w.grad*lr: {self.w.grad} w: {self.w}')\n    self.w -= self.lr*self.w.grad # Todo\n    #print(f'w nou: {self.w} gradient nou {self.w.grad}')\n    self.b -= self.lr*self.b.grad # Todo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model: GDLinearRegression, data: torch.Tensor, \n          labels: torch.Tensor, optim: GD, criterion: MSE):\n  \"\"\"Linear Regression train routine\"\"\"\n\n  predictions = model(data) # Todo\n  loss = criterion(labels,predictions) # Todo\n  #loss_history.append(loss.item())\n  loss.backward() # Todo\n  #print(f'loss{loss}')\n  \n  with torch.no_grad():\n    optim.step() # Todo\n    model.zero_grad()\n  \n  return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Manipularea datelor\n\nImpartim datele in training si validation in proportie de 80% respectiv 20% si le normalizam standar(le ducem intr-o distributie normala)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df1.drop(columns='Scor').values\n\ny=df1[['Scor']].values.ravel()\nx_train, x_valid, y_train, y_valid = train_test_split(X,y, train_size = 0.8)\n\nstd_scale = preprocessing.StandardScaler().fit(x_train)\nx_train = std_scale.transform(x_train)\nx_train = torch.tensor(x_train).float()\n\n#Folosim aceeasi deviatie standard de la training pentru test\nx_valid = std_scale.transform(x_valid)\nx_valid = torch.tensor(x_valid).float()\n\nmse = MSE()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cautam cel mai bun learning rate in [0.001,100]"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_loss=10**1000\nbest_lr = 0\ntotal_steps = 100\nfor idx in np.linspace(0.001,20,100):\n    lr = idx\n    total_steps = 100\n\n    model = GDLinearRegression()\n    optimizer = GD(model.parameters(), lr=lr)\n    criterion = MSE()\n\n    for i in range(total_steps):\n        train(model, x_train, y_train, optimizer, criterion)\n\n    with torch.no_grad():\n        y_pred = model(x_train)\n    if best_loss > mse(y_pred,y_train).item():\n        best_loss = mse(y_pred,y_train).item()\n        best_lr = idx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Antrenam modelul cu lr-ul gasit."},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = best_lr\ntotal_steps = 500\nmodel = GDLinearRegression()\noptimizer = GD(model.parameters(), lr=lr)\ncriterion = MSE()\n\nfor i in range(total_steps):\n    train(model, x_train, y_train, optimizer, criterion)\n\nwith torch.no_grad():\n    y_pred = model(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acuratetea pe training"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    y_pred = model(x_train)\npredicted = torch.round(y_pred).numpy()\naccuracy = (predicted==y_train).sum()/predicted.shape[0]\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acuratetea pe validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    y_pred = model(x_valid)\npredicted = torch.round(y_pred).numpy()\naccuracy = (predicted==y_valid).sum()/predicted.shape[0]\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Matricea de confuzie"},{"metadata":{"trusted":true},"cell_type":"code","source":"regression_matrix = confusion_matrix(predicted,y_valid)\nregression_mse = mse(predicted,y_valid)\nprint(regression_matrix)\nprint('MSE:', regression_mse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cautam o coloana pentru care regresia ar functiona mai bine\n\nGasim coloana 'Nr Camere'."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df1.drop(columns='Nr Camere').values\n\ny=df1[['Nr Camere']].values.ravel()\nx_train, x_valid, y_train, y_valid = train_test_split(X,y, train_size = 0.8)\n\nstd_scale = preprocessing.StandardScaler().fit(x_train)\nx_train = std_scale.transform(x_train)\nx_train = torch.tensor(x_train).float()\n\n#Folosim aceeasi deviatie standard de la training pentru test\nx_valid = std_scale.transform(x_valid)\nx_valid = torch.tensor(x_valid).float()\n\nmse = MSE()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = best_lr\ntotal_steps = 500\nmodel = GDLinearRegression()\noptimizer = GD(model.parameters(), lr=lr)\ncriterion = MSE()\n\nfor i in range(total_steps):\n    train(model, x_train, y_train, optimizer, criterion)\n\nwith torch.no_grad():\n    y_pred = model(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acuratetea pe training"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    y_pred = model(x_train)\npredicted = torch.round(y_pred).numpy()\naccuracy = (predicted==y_train).sum()/predicted.shape[0]\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acuratetea pe validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    y_pred = model(x_valid)\npredicted = torch.round(y_pred).numpy()\naccuracy = (predicted==y_valid).sum()/predicted.shape[0]\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Matricea de confuzie"},{"metadata":{"trusted":true},"cell_type":"code","source":"regression_matrix1 = confusion_matrix(predicted,y_valid)\nregression_mse1 = mse(predicted,y_valid)\nprint(regression_matrix1)\nprint('MSE:', regression_mse1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rezolvarea problemei prin CLASIFICARE"},{"metadata":{},"cell_type":"markdown","source":"## Manipularea datelor\n\nImpartim datele in training si validation in proportie de 80% respectiv 20% si le normalizam standar(le ducem intr-o distributie normala)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df1.drop(columns='Scor').values\n\ny=df1[['Scor']].values\ny=y-1\nx_train, x_valid, y_train, y_valid = train_test_split(X,y, train_size = 0.8)\n\nstd_scale = preprocessing.StandardScaler().fit(x_train)\nx_train = std_scale.transform(x_train)\nx_train = torch.tensor(x_train).float()\n\n#Folosim aceeasi deviatie standard de la training pentru test\nx_valid = std_scale.transform(x_valid)\nx_valid = torch.tensor(x_valid).float()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Construim doua layere pentru reteaua neruonala\n\nFolosim functia de activare relu pentru layer-ul 1, iar pentru a doua nu este nevoie deoarece folosim cross entropy ca functie de loss."},{"metadata":{"trusted":true},"cell_type":"code","source":"class TwoLayer(nn.Module):\n    def __init__(self, in_size: int, hidden_size: int, out_size: int):\n        super().__init__()\n        self._layer1 = nn.Linear(in_size, hidden_size)\n        self._layer2 = nn.Linear(hidden_size, out_size)\n    def forward(self, x):\n        x = self._layer1(x)\n        x = torch.relu(x)\n    \n        x = self._layer2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Antrenam modelul pe datele de training\n\n\nConform Teoremei de universalitate, o functie este aproximata arbitrar de bine de o retea nuronala cu un strat ascuns crescand arbitrar de mult adancimea layer-ului ascuns."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = TwoLayer(6,5000,5)\nNUM_EPOCHS = 2000\n\noptim = torch.optim.SGD(model.parameters(), lr=2.5)\nfor i in range(NUM_EPOCHS):\n    model.train()\n    optim.zero_grad()\n    output = model(x_train)\n    criterion = nn.CrossEntropyLoss()\n    target = torch.tensor(y_train).long().squeeze(1)\n    loss = criterion(output, target)\n    loss.backward()\n    optim.step()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acuratetea pe training"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = np.array(torch.argmax(model(x_train), dim=-1))\naccuracy = (predicted==y_train.ravel()).sum()/predicted.shape[0]\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acuratetea pe validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = np.array(torch.argmax(model(x_valid), dim=-1))\naccuracy = (predicted==y_valid.ravel()).sum()/predicted.shape[0]\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Matricea de confuzie pentru clasificare"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_matrix = confusion_matrix(predicted,y_valid)\nclass_mse = mse(predicted,y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Toate cele 3 matrici de confuzie"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Regresie scor\\n\\n',regression_matrix)\nprint('\\nClasificare scor\\n\\n', class_matrix)\nprint('\\nRegresie Nr. Camere\\n\\n',regression_matrix1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cele 3 erori MSE"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Regresie scor\\n\\n',regression_mse)\nprint('\\nClasificare scor\\n\\n', class_mse)\nprint('\\nRegresie Nr. Camere\\n\\n',regression_mse1)\n","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}