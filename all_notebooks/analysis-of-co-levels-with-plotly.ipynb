{"cells":[{"metadata":{"_uuid":"c34148dde971f5def78a78a1c0762de5e783b77b"},"cell_type":"markdown","source":"# Carbon Monoxide (CO) analysis with Plotly"},{"metadata":{"_uuid":"23fda21fb3ee3d114b6468ff3ec0275ce128ee00"},"cell_type":"markdown","source":"** Import data analysis and visualization libraries**"},{"metadata":{"trusted":true,"_uuid":"dbef2513fd4d93db5083a52978e4bd45ddb3ea4c"},"cell_type":"code","source":"import pandas as pd \nimport numpy as np ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a1d77732fc123d5c8b34e0458d78636533bb4e8"},"cell_type":"code","source":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b99a13b2c575fc9d55ad81b5de5aabad1e298bd0"},"cell_type":"markdown","source":"** Cufflinks has got some internal error wih latest version 3.0.0 of plotly <br>\nCheck https://github.com/santosjorge/cufflinks/issues/119 <br>\nHad to replace those one liners that worked with dataframe with actual script**"},{"metadata":{"trusted":true,"_uuid":"81bb1de86a2b378fb9a27151f25eba47ed695ef1"},"cell_type":"code","source":"#import cufflinks as cf\n#cf.go_offline()\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9368335276acdea66cbdc29c19073c2fc9a92c26"},"cell_type":"code","source":"df = pd.read_csv('../input/CO_level_2000_-.csv')\ndel df['Unnamed: 0']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b1a702ef8e8ed9810c9ce3d1e8b1f8937a54f3c"},"cell_type":"markdown","source":"** Eliminate duplicate entries of same date of same location **"},{"metadata":{"trusted":true,"_uuid":"9e3235053d0ce5e2af904ea9b7e218444418f5f0"},"cell_type":"code","source":"df = df.groupby(['Address','State','County','City','Date']).mean().reset_index()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0178c6c90988eb1a5bd74544cf359b9d17ca9b3"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1cb7b935fa86748c999394add19ca73be70f8db"},"cell_type":"markdown","source":"** Examine states in record **"},{"metadata":{"trusted":true,"_uuid":"4d6e762923d23bf731bca90b0fb8d698326a2cfc"},"cell_type":"code","source":"df['State'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62b26cffb1ec74f460216bf1ca57bf3b6fee895a"},"cell_type":"markdown","source":"** We have Puerto Rico and Country of Mexico that we need to exclude while using Maps **"},{"metadata":{"trusted":true,"_uuid":"6f6762ad0ec45052f9eaf83f1e9849cb900a7691"},"cell_type":"code","source":"df = df[~df['State'].isin(['Puerto Rico', 'Country Of Mexico'])]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bcefe9c6aa3c99bf4a36c2f8d34c11818968a66"},"cell_type":"markdown","source":"** Add month and year columns to help analysing data by month and year**"},{"metadata":{"trusted":true,"_uuid":"24fa5f738eb1e967d364c553ab1ba6a6abe503f3"},"cell_type":"code","source":"tempYear = []\ntempMonth = []\ntotalTuples = df.count()['State']\nfor i in range(totalTuples):\n    delement = (df['Date'].iloc[i]).split('-')\n    tempYear.append(int(delement[0]))\n    tempMonth.append(delement[0]+'-'+delement[1])\ndf['Year'] = tempYear\ndf['Month'] = tempMonth\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a5482b4777ebdaee8f2d07b026219037d80178c"},"cell_type":"markdown","source":"** Take number of addresses present in each state **"},{"metadata":{"trusted":true,"_uuid":"3c6ae551c848307063ac9b5ccaacd4d1eeca31c6"},"cell_type":"code","source":"stateData = {}\naddrDict = {}\nfor i in df['State'].unique():\n    #create a dicionary of data frames for state-wise record\n    stateData[i] = df[df['State'] == i]\n    addrDict[i] = stateData[i]['Address'].nunique()\naddrdf = pd.DataFrame.from_dict(addrDict, orient = 'index', columns = ['Address Count']).reset_index().rename(columns = {'index' : 'State'})\n\n# addrdf\naddrdf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8794cd18dad3d6d80850834047e77051172bd004"},"cell_type":"markdown","source":"** Visualize above**"},{"metadata":{"trusted":true,"_uuid":"686de003d5effb5e74b2ca927fe4629afee43924"},"cell_type":"code","source":"data = go.Bar(x = addrdf['State'], \n              y = addrdf['Address Count'], \n              text = addrdf['State'])\nlayout = go.Layout(dict(title = 'Number of unique addresses per State', \n                        xaxis = dict(title = 'State'),\n                        yaxis = dict(title = 'Count')))\nfig = dict(data = [data],layout = layout)\niplot(fig)\n\n#addrdf.iplot(kind='bar', x='State', y='Address Count', title='Number of unique addresses per State (Zoom in or hover over)', orientation='h')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee855f7b0ab56fc45ef9c38ac8c26e32c8e29f6e"},"cell_type":"markdown","source":"**Highest number of locations come from California (148), followed by Florida (42), Pennsylvania (39), Texas (35), Ohio (30), and so on.**"},{"metadata":{"_uuid":"544567ecabc1be25d65b6beb2877b16a4f17cf47"},"cell_type":"markdown","source":"** Check number of records in each year **"},{"metadata":{"trusted":true,"_uuid":"3c8d172b2b8ab90ad812a1d7cec486061743b0f1"},"cell_type":"code","source":"yeardf = df.groupby('Year').count().reset_index()\n\ndata = go.Bar(x = yeardf['Year'], \n              y = yeardf['Address'], \n              text = yeardf['Year'])\nlayout = go.Layout(dict(title = 'Number of records per year', \n                        xaxis = dict(title='Year'),\n                        yaxis = dict(title = 'Count')))\nfig = dict(data=[data],layout = layout)\niplot(fig)\n\n# df.groupby('Year').count().reset_index().iplot(kind='bar', x='Year', y='Address', title='Number of records per year')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1925cada56cd9d359b2177dad208e3e34c98d3f2"},"cell_type":"markdown","source":"**Records goes down as we walk right.**"},{"metadata":{"_uuid":"da4a6a3ff4462569bae5a3aa47c10a71de208ef6"},"cell_type":"markdown","source":"** Check for what months we have records for 2018**"},{"metadata":{"trusted":true,"_uuid":"6984ea9f4da6e00047629839749d18c1e8e53c78"},"cell_type":"code","source":"df[df['Year'] == 2018]['Month'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79278b7e31e32c17fcc9e49cb26ce3002ee9fc72"},"cell_type":"markdown","source":"** It is till 2018-05**"},{"metadata":{"_uuid":"8eed650f1ddb612cfcc7f6220a369bb64111022f"},"cell_type":"markdown","source":"** Not all addresses records lie from 2000-01 to 2018-05. Take some examples.**"},{"metadata":{"trusted":true,"_uuid":"8b29c7e365dd5702843e2a14886026dd6f0fcd59"},"cell_type":"code","source":"datesAddr = ['3847 W EARLL DR-WEST PHOENIX STATION', '6767 Ojo De Agua', 'LFC #1-LAS FLORES CANYON', 'NW Corner Interstate 10 & Etiwanda Ave', '700 North Bullis Road', '10 S. 11th St/ Evansville- Lloyd', '1301 E. 9TH ST.', '4113 SHUTTLESWORTH DRIVE']\ndatesState = ['Arizona', 'Texas', 'California', 'California', 'California', 'Indiana', 'Ohio', 'Alabama']\ndatesStart = []\ndatesEnd = []\nfor i in range(len(datesAddr)):\n    datesStart.append(df[df['Address'] == datesAddr[i]]['Date'].min())\n    datesEnd.append(df[df['Address'] == datesAddr[i]]['Date'].max())\n    datesAddr[i] += ', '+datesState[i]\ndatesDF = pd.DataFrame([datesAddr, datesStart, datesEnd],index=['Address','Start date','Last Date']).transpose()\ndatesDF#.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d789bc3e196c2419f49b762318cd619833422449"},"cell_type":"markdown","source":"** 0th and 6th record seem covered a lot **"},{"metadata":{"_uuid":"d26788d0065c35842d565c2e849c264b32832160"},"cell_type":"markdown","source":"** Check records with maximum values in Arithmetic Mean year-wise**"},{"metadata":{"trusted":true,"_uuid":"c38cb7916dd575499818aeb768e78afc1fd5c3c6"},"cell_type":"code","source":"maximumYear = df[['Year','Arithmetic Mean']]\nmaximumYear = maximumYear.groupby('Year').max().reset_index()\n\nmaxTable = pd.DataFrame()\nfor i in range(19):\n    x = maximumYear.iloc[i]['Arithmetic Mean']\n    record = df[df['Year'] == (2000 + i)]\n    record = record[record['Arithmetic Mean'] == x].head(1) # pick only one\n    maxTable = maxTable.append(record)\nmaxTable = maxTable[['Address','State','Arithmetic Mean','Month']]\nmaxTable","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2a98d4220d179456e8b489a8a5a30897322808a"},"cell_type":"markdown","source":"** Check records with minimum values in Arithmetic Mean year-wise**"},{"metadata":{"trusted":true,"_uuid":"1023b4dc8d26beb0b43f5a0a5f9cd5d5ac6d3971"},"cell_type":"code","source":"# lets extract minimum records year - wise. Same logic upside - down.\nminimumYear = df[['Year','Arithmetic Mean']]\n# neglect 0 and negative values\nminimumYear = minimumYear[minimumYear['Arithmetic Mean'] > 0]\nminimumYear = minimumYear.groupby('Year').min().reset_index()\n\nminTable = pd.DataFrame()\nfor i in range(19):\n    x = minimumYear.iloc[i]['Arithmetic Mean']\n    record = df[df['Year'] == (2000 + i)]\n    record = record[record['Arithmetic Mean'] == x].head(1) # pick one record\n    minTable = minTable.append(record)\nminTable = minTable[['Address','State','Arithmetic Mean','Month']]\nminTable","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc0b81b8d9c5f1fd16648ac39b5d83ee76f7918e"},"cell_type":"markdown","source":"** Pick a address for further analysis . We will pick '3847 W EARLL DR-WEST PHOENIX STATION, Arizona' as it appears in maxTable where year=2018. We can simply change this value to analyse other address in further analysis**"},{"metadata":{"trusted":true,"_uuid":"6216e217c5aa9a59307ed1972bd0bff1c075e5a8"},"cell_type":"code","source":"addr = '3847 W EARLL DR-WEST PHOENIX STATION'\naddr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd2e5ca7daf090a842ceff9409b82cbb34f39252"},"cell_type":"markdown","source":"** Check month wise record count for selected address**\n"},{"metadata":{"trusted":true,"_uuid":"9923da4669df847a3ce05a58c57455485bfb4c4b"},"cell_type":"code","source":"addrdf = stateData['Arizona'][stateData['Arizona']['Address'] == addr]\n\ntempdf = addrdf.groupby('Month').count().reset_index()\ndata = go.Bar(x = tempdf['Month'], \n              y = tempdf['Address'], \n              text = tempdf['Month'])\nlayout = go.Layout(dict(title = 'Number of records for selected address month wise', \n                        xaxis = dict(title = 'Year'),\n                        yaxis = dict(title = 'Count')))\nfig = dict(data = [data],layout = layout)\niplot(fig)\n\n#addrdf.groupby('Month').count().reset_index().iplot(kind='bar', x='Month', y='Address', title='Number of records for selected address month wise')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0520bda4ff853445a82ed5ff1c8b55adbb45b00e"},"cell_type":"markdown","source":"** Records in month July-2002 and May-2005 seem missing, otherwise they are complete **"},{"metadata":{"_uuid":"d74a4b9836237fb6ca9951f5f241c978b51d04f6"},"cell_type":"markdown","source":"**Examine change in values from December 2016 to November 2017 (one season cycle in U.S.)<br>\nWe will also take an extra for December 2017<br>\nSet layout to fix a range for ease of comparison and pass title as month **"},{"metadata":{"_uuid":"1eaed45d66cac64b077fb6ee022bc54f3c6c9459"},"cell_type":"markdown","source":"** Lets plot for every month from December 2016 to December 2017<br>\nHover over graph to get reading**"},{"metadata":{"trusted":true,"_uuid":"a95446ebbfd1cbaf0a10ebd2c0fd4894815b8998"},"cell_type":"code","source":"seasonrange = ['2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12']\n\nfor i in range(len(seasonrange)):\n    tempdf = addrdf[addrdf['Month'] == seasonrange[i]]\n    data = go.Scatter(x = tempdf['Date'], \n                           y = tempdf['Arithmetic Mean'],\n                           text = tempdf['Date'], \n                           mode = 'lines+markers', \n                           name = seasonrange[i])\n    fig = dict(data = [data],layout = go.Layout(dict(title = seasonrange[i], \n                                                 xaxis = dict(title = 'Days'), \n                                                yaxis = dict(range = [0, 2], title = 'CO (in ppm)'))))\n    iplot(fig)\n\n#for i in range(len(seasonrange)):\n#    addrdf[addrdf['Month']==seasonrange[i]].iplot(x='Date',y='Arithmetic Mean',layout=go.Layout(yaxis=dict(range=[0,2]),title=seasonrange[i]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66e45e675e50a8f134fde6263d0745a9cb51aea9"},"cell_type":"markdown","source":"**In Winter, CO Level seems high. While CO Level goes a bit low for Summer, it rises Autumn and Winter.**"},{"metadata":{"_uuid":"23a5ab2d742fd72c5f4ce5fa5d0c5076f2a7f491"},"cell_type":"markdown","source":"**For seasonal analysis, make separate DF to simplify further**"},{"metadata":{"trusted":true,"_uuid":"4e27ed01962be14772538b4c6bff47a02e9c82ce"},"cell_type":"code","source":"winterdf = addrdf[addrdf['Month'].isin(['2016-12', '2017-01', '2017-02'])][['Arithmetic Mean', '1st Max Hour']]\nspringdf = addrdf[addrdf['Month'].isin(['2017-03', '2017-04', '2017-05'])][['Arithmetic Mean', '1st Max Hour']]\nsummerdf = addrdf[addrdf['Month'].isin(['2017-06', '2017-07', '2017-08'])][['Arithmetic Mean', '1st Max Hour']]\nautumndf = addrdf[addrdf['Month'].isin(['2017-09', '2017-10', '2017-11'])][['Arithmetic Mean', '1st Max Hour']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5572936b1028699843654c82788db2e82c8a86f5"},"cell_type":"markdown","source":"** Check how CO Mean values are distributed by seasons**"},{"metadata":{"trusted":true,"_uuid":"cf5b3f27706b1517a4babf23d5251c4841b67b50"},"cell_type":"code","source":"seasondf = [winterdf, springdf, summerdf, autumndf]\ndftext = ['Winter', 'Spring', 'Summer', 'Autumn']\n\ndata = []\nfor i in range(len(seasondf)):\n    data.append(go.Box(y = seasondf[i]['Arithmetic Mean'], \n                  name = dftext[i]))\nlayout = go.Layout(title = 'Distribution of Arithmetic Mean across different season (2016-12 to 2017-11)', \n                   xaxis = dict(title = 'Season'), \n                   yaxis = dict(title = 'CO (in ppm)'))\nfig = dict(data = data, layout = layout)\niplot(fig)\n\n#pd.concat([winterdf['Arithmetic Mean'], springdf['Arithmetic Mean'], summerdf['Arithmetic Mean'], autumndf['Arithmetic Mean']], axis=1, keys=['Winter','Spring','Summer','Autumn']).iplot(kind='box')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b05453460f3bd1980a1f172b1a1c2bbde971b29"},"cell_type":"markdown","source":"**It is high in winter because of inversion. Check -->> https://en.wikipedia.org/wiki/Inversion_(meteorology)  **"},{"metadata":{"_uuid":"7c77e96d7a0c19eae19d3b136c3f855c1863a9cc"},"cell_type":"markdown","source":"**Check 1st Max Hour value to find distirbution of hour values at which max values are recorded. <br>\nBecause of same phenomenon, distribution of hour early in morning for Summer is high **"},{"metadata":{"trusted":true,"_uuid":"0ce029a1bf53450cb7a1fda9c3bcb96c16ee62f4"},"cell_type":"code","source":"data = []\nfor i in range(len(seasondf)):\n    data.append(go.Box(y = seasondf[i]['1st Max Hour'], \n                  name = dftext[i]))\nlayout = go.Layout(title = 'Distribution of Hour values at which maximum reading was taken', \n                   xaxis = dict(title = 'Season'), \n                   yaxis = dict(title = 'Hours'))\nfig = dict(data = data, layout = layout)\niplot(fig)\n\n#pd.concat([winterdf['1st Max Hour'], springdf['1st Max Hour'], summerdf['1st Max Hour'], autumndf['1st Max Hour']], axis=1, keys=['Winter','Spring','Summer','Autumn']).iplot(kind='box')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"687159884d2d9ab1e3b147a1a12e05e27b45ca3d"},"cell_type":"markdown","source":"**Follows same trend as for CO Mean.**"},{"metadata":{"_uuid":"26dc83f42223bec1afbc81df07e4747c35560115"},"cell_type":"markdown","source":"** Transform data for choropleth maps**"},{"metadata":{"trusted":true,"_uuid":"a33471a7405a5ede4689fa664af95a5a9f056520"},"cell_type":"code","source":"winterdf = df[df['Month'].isin(['2016-12', '2017-01', '2017-02'])][['Arithmetic Mean', 'State']]\nspringdf = df[df['Month'].isin(['2017-03', '2017-04', '2017-05'])][['Arithmetic Mean', 'State']]\nsummerdf = df[df['Month'].isin(['2017-06', '2017-07', '2017-08'])][['Arithmetic Mean', 'State']]\nautumndf = df[df['Month'].isin(['2017-09', '2017-10', '2017-11'])][['Arithmetic Mean', 'State']]\n\n# group by and sort by State to map it easily ahead\nwinterdf = winterdf.groupby('State').mean().reset_index().sort_values('State')\nspringdf = springdf.groupby('State').mean().reset_index().sort_values('State')\nsummerdf = summerdf.groupby('State').mean().reset_index().sort_values('State')\nautumndf = autumndf.groupby('State').mean().reset_index().sort_values('State')\n                                                                      \nabbState = ['US State:', 'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming', 'Commonwealth/Territory:', 'American Samoa', 'District Of Columbia', 'Federated States of Micronesia', 'Guam', 'Marshall Islands', 'Northern Mariana Islands', 'Palau', 'Puerto Rico', 'Virgin Islands', 'Military \"State\":', 'Armed Forces Africa', 'Armed Forces Americas', 'Armed Forces Canada', 'Armed Forces Europe', 'Armed Forces Middle East', 'Armed Forces Pacific']\nabbAB = ['Abbreviation:', 'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'Abbreviation:', 'AS', 'DC', 'FM', 'GU', 'MH', 'MP', 'PW', 'PR', 'VI', 'Abbreviation:', 'AE', 'AA', 'AE', 'AE', 'AE', 'AP']\nabbDF = pd.DataFrame([abbState,abbAB]).transpose()\n\n#small correction, so things go smooth ahead\nabbDF.iloc[53][0] = 'District Of Columbia'\n\n# creating label to display when hovered over\nmapA = []\nmapS = []\nfor i in winterdf.index:\n    mapA.append(str(winterdf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == winterdf['State'].iloc[i]][1].values[0])\nwinterdf['text'] = mapA\nwinterdf['code'] = mapS\n\nmapA = []\nmapS = []\nfor i in springdf.index:\n    mapA.append(str(springdf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == springdf['State'].iloc[i]][1].values[0])\nspringdf['text'] = mapA\nspringdf['code'] = mapS\n\nmapA = []\nmapS = []\nfor i in summerdf.index:\n    mapA.append(str(summerdf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == summerdf['State'].iloc[i]][1].values[0])\nsummerdf['text'] = mapA\nsummerdf['code'] = mapS\n\nmapA = []\nmapS = []\nfor i in autumndf.index:\n    mapA.append(str(autumndf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == autumndf['State'].iloc[i]][1].values[0])\nautumndf['text'] = mapA\nautumndf['code'] = mapS","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fa8fc54400f4f89b61d1a213242bbd93daf4e51"},"cell_type":"markdown","source":"** Map state-wise distribution of Arithmetic Mean in Winter**"},{"metadata":{"trusted":true,"_uuid":"1e8116e42625e1da0be5f4d9d7f854224981849f"},"cell_type":"code","source":"data = dict(type='choropleth',\n            locations = winterdf['code'],\n            z = winterdf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = winterdf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'Arithmetic Mean Value in Winter by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d120b4d14d70c3aaae5ddb6187232c879f1879c8"},"cell_type":"markdown","source":"** Map state-wise distribution of Arithmetic Mean in Spring**"},{"metadata":{"trusted":true,"_uuid":"183eb45397e4e5fad8f2e8d5ea73e72eba091464"},"cell_type":"code","source":"data = dict(type='choropleth',\n            locations = springdf['code'],\n            z = springdf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = springdf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'CO Mean Value in Spring by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17e2ac186b27652591df67c98059e2d9aeebf39f"},"cell_type":"markdown","source":"** Map state-wise distribution of Arithmetic Mean in Summer**"},{"metadata":{"trusted":true,"_uuid":"f5522c4138fd3f244e989c13468ea2c4cf6713c3"},"cell_type":"code","source":"data = dict(type='choropleth',\n            locations = summerdf['code'],\n            z = summerdf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = summerdf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'CO Mean Value in Summer by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2416e269ee7f46dffaf7a91b49253bb15085899a"},"cell_type":"markdown","source":"** Map state-wise distribution of Arithmetic Mean in Autumn**"},{"metadata":{"trusted":true,"_uuid":"5afeef25ac49f037ceae6a666b2b5fd0b4e1b566"},"cell_type":"code","source":"data = dict(type='choropleth',\n            locations = autumndf['code'],\n            z = autumndf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = autumndf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'CO Mean Value in Autumn by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89029c702383a7057111cf656139268445c43e4f"},"cell_type":"markdown","source":"**Import Linear Regression from scikit-learn to predict further values for before selected address**"},{"metadata":{"trusted":true,"_uuid":"f3a338a9e3f0616fe813773723d14ddfff34adb3"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33cb7837e6b57d648dd08e5d8873daa7f5a26a4d"},"cell_type":"markdown","source":"**Reduce addrdf to Month and Arithmetic Mean columns only.**"},{"metadata":{"trusted":true,"_uuid":"3a4496c1c488caf800fb410b9074f66ba541eedd"},"cell_type":"code","source":"chosenAddress = addrdf[['Month','Arithmetic Mean']]\n#aggregate them\nchosenAddress = chosenAddress.groupby('Month').mean().reset_index().reset_index()\n# we will use monthID on X-axis such that the first month in record will have monthID = 0\nchosenAddress = chosenAddress.rename(columns = {'index':'monthID'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c29989a8bbffcb2585529dfad196f0055f3456f"},"cell_type":"markdown","source":"**While prediction, following method will map input month to monthID**"},{"metadata":{"trusted":true,"_uuid":"595327b168d1bcd6849542ba67d6fa57379c1adc"},"cell_type":"code","source":"start = addrdf['Month'].min()\n# start is first month in record of given address is of form '2000-01‘\n# tofind is input feature for which the CO Mean values is to be predicted is of form '2018-11‘\ndef toID(tofind,start = start):\n    startY = int(start.split('-')[0])\n    startM = int(start.split('-')[1])\n    tofindY = int(tofind.split('-')[0])\n    tofindM = int(tofind.split('-')[1])\n    id = 12 - startM\n    id += ((tofindY - startY) - 1 ) * 12\n    id += tofindM\n    return id","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e625b8931d05a19f3c4f0d010e22f28021742e6b"},"cell_type":"markdown","source":"** Initilaise model, do train test split and train model using train_data**"},{"metadata":{"trusted":true,"_uuid":"16846b7b00b39d067adb039b6363277f146611e5"},"cell_type":"code","source":"# init our model\nlm = LinearRegression()\n# lets get data ready\nX = chosenAddress[['monthID']] #feature\nY = chosenAddress[['Arithmetic Mean']] #label\n# split train and test data\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=101)\n# train our model\nlm.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9bb0395fbdc3c0e20b01c0fb118fbdc417d283c"},"cell_type":"code","source":"print(\"Intercept is \"+str(lm.intercept_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bb3e48c9708d7934fb788ab508813e53bb3b757"},"cell_type":"code","source":"print(\"Coefficient is \"+str(lm.coef_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25b25e92e935be970ae42b61a2b2256e0e9c5893"},"cell_type":"markdown","source":"** Visualize our trained model**"},{"metadata":{"trusted":true,"_uuid":"55dd7b662dbe59c9cf8d4ace76b63ece02d2c41f"},"cell_type":"code","source":"# predictions (Y) for trained data\nline = X_train['monthID'] * lm.coef_[0] + lm.intercept_[0]\n\n# display values\n#annotation = go.Annotation(x = 3.5, y = 3, text = '$R^2 = 0.9551,\\\\Y = 0.716X + 19.18$',  showarrow = False, font = go.Font(size=16))\n\n# actual points\ntrain = go.Scatter(x = X_train['monthID'],\n                   y = Y_train['Arithmetic Mean'],\n                   mode = 'markers',\n                   marker = dict(color = 'rgb(255, 127, 14)'),\n                   name = 'Data')\n\n# fitted line\nfit = go.Scatter(x = X_train['monthID'],\n                 y = line,\n                 mode = 'lines',\n                 marker = dict(color = 'rgb(31, 119, 180)'),\n                 name = 'Fit')\n\nlayout = go.Layout(title = 'Linear Fit Model',\n                   xaxis = dict(title = 'Month ID'),\n                   yaxis = dict(title = 'CO (in ppm)'))\n                   \ndata = [train, fit]\n\nfig = go.Figure(data=data, layout=layout)\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d06909170ccbf35cd03dce8880d38dd6c14cf8a5"},"cell_type":"markdown","source":"** Check its accuracy by by plotting distribution of predicted_value - Y_test values **"},{"metadata":{"trusted":true,"_uuid":"1e052a8eeb9bea12f6d930e3081f1a533cad9f8f"},"cell_type":"code","source":"predictions = lm.predict(X_test)\ndata = go.Histogram(x = (Y_test - predictions)['Arithmetic Mean'],\n                    xbins = dict(start = -6, end = 6, size = 0.1))\nlayout = go.Layout(xaxis = dict(title = 'Error'))\n\nfig = dict(data = [data], layout = layout)\niplot(fig)\n\n#(Y_test - predictions).iplot(kind='hist', bins=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52783e4f8afde6301dd291d322105dd2633ebe38"},"cell_type":"markdown","source":"**Predict a value**"},{"metadata":{"trusted":true,"_uuid":"2b6a18511d1557dc02eeda9f5873c9adf5764578"},"cell_type":"code","source":"inMonth = '2018-08'\nprint('In month '+inMonth+', predicted value of CO Mean is '+str(lm.predict([[toID(inMonth)]])[0][0])[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51834e8cbc7d50aa99c97d10fd119a45cb418527"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2b9cf4d8578abdffdf30c50cd330e41b8b657e23"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}