{"cells":[{"metadata":{"executionInfo":{"elapsed":1526,"status":"ok","timestamp":1593503029995,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"qwNXTTBAJRm-","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32641,"status":"ok","timestamp":1593503061128,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"J1JELAAwJhnH","outputId":"89b75fc3-61a5-4140-f6e9-14149b54475e","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/real-estate-dataset/Real estate.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32633,"status":"ok","timestamp":1593503061133,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"8WtTIo8sPRmy","outputId":"3ef87107-6460-4f93-828c-9eda1399290d","trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32630,"status":"ok","timestamp":1593503061134,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"Wob4cd_zO3Y8","trusted":true},"cell_type":"code","source":"features=['house age', 'distance to the nearest MRT station','number of convenience stores', 'latitude', 'longitude']\nX=data[features]\ny=data['house price of unit area']\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"fZAqDQuRJOQi"},"cell_type":"markdown","source":"## LINEAR REGRESSION"},{"metadata":{"executionInfo":{"elapsed":32626,"status":"ok","timestamp":1593503061136,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"il3NRgVRLwrz","trusted":true},"cell_type":"code","source":"model1=LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32620,"status":"ok","timestamp":1593503061137,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"rmav8tVjPf2M","outputId":"ebf5db6d-13b1-453a-fc2f-02602bd55984","trusted":true},"cell_type":"code","source":"model1.fit(train_X,train_y)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32615,"status":"ok","timestamp":1593503061138,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"pKaAu6X7PuAj","outputId":"67888f58-8ef3-4327-8a31-26f210145753","trusted":true},"cell_type":"code","source":"val_predictions1 = model1.predict(val_X)\nval_predictions1","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32613,"status":"ok","timestamp":1593503061140,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"MHZFSsKRYQdD","trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32606,"status":"ok","timestamp":1593503061141,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"W9vvAqFKYiVH","outputId":"0555a5a1-2026-4ac0-9ed2-56af0d9a3926","trusted":true},"cell_type":"code","source":"print(\"Mean absolute error: \")\nprint(mean_absolute_error(val_y, val_predictions1))","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":32602,"status":"ok","timestamp":1593503061143,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"JC1HgS9QXpBM","outputId":"2600dde6-95f1-481d-e2bc-123dd4a25f32","trusted":true},"cell_type":"code","source":"print(\"Coefficients\") \nprint(model1.coef_)\nprint(\"Intercept\") \nprint(\"%2f\"%model1.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"id":"3CYoyMBOuGTG"},"cell_type":"markdown","source":"INTERPRETATION -\nIn linear regression,\n\n\nThe hypothesis function h(theta)=\ntheta_0 + theta_1 * x1 + theta_2 * x2 +...\nwhere theta 1 , theta 2 are coefficients and x1,x2 are features.\n\nHere, h = -433.789415 -2.39157343e-01(house age) -4.73776424e-03 (distance to the nearest MRT station)+ 1.09332205e+00(number of convenience stores) + 2.24000967e+02(latitude) -4.20969538e+01(longitude) \n\nThe above function will fit the data given (not perfectly since mean absolute error of 6 is involved)."},{"metadata":{"id":"3KvAn6pAZ7ai"},"cell_type":"markdown","source":"## DECISION TREE"},{"metadata":{"executionInfo":{"elapsed":33306,"status":"ok","timestamp":1593503061855,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"N8fQaaK_h-zg","outputId":"92f924e3-dc75-413b-f41b-5e5fb88f7c76","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/bank-note-authentication-uci-data/BankNote_Authentication.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":33304,"status":"ok","timestamp":1593503061856,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"o3LzIRUSiHFF","trusted":true},"cell_type":"code","source":"features=['variance','skewness','curtosis','entropy']\nX=data[features]\ny=data['class']\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":33302,"status":"ok","timestamp":1593503061857,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"UUxa05bzPz9D","trusted":true},"cell_type":"code","source":"# Specify Model\nmodel2 = DecisionTreeClassifier(random_state=1)\n# Fit Model\nfit=model2.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":33301,"status":"ok","timestamp":1593503061858,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"PgfEmoRcRxtt","trusted":true},"cell_type":"code","source":"val_predictions2 = model2.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":33294,"status":"ok","timestamp":1593503061859,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"ddxZNrjISKE0","outputId":"26160dda-0e66-4fa5-cfed-9f92cb8a4158","trusted":true},"cell_type":"code","source":"print(\"Mean absolute error: \")\nprint(mean_absolute_error(val_y, val_predictions2))","execution_count":null,"outputs":[]},{"metadata":{"id":"bmBHdnGdc444"},"cell_type":"markdown","source":"We have checked error to find the accuracy and it is found to be almost 0."},{"metadata":{"executionInfo":{"elapsed":35112,"status":"ok","timestamp":1593503063686,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"NBodRWrlkdBZ","outputId":"d5d4c16e-7912-492f-a969-32ae95d0065b","trusted":true},"cell_type":"code","source":"from sklearn import tree\nfig, ax = plt.subplots(figsize=(25, 10))\ntree.plot_tree(fit,fontsize=10,filled=True,feature_names=features)\nplt.title(\"Decision Tree\",size=25)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ydr3nxaYmgNX"},"cell_type":"markdown","source":"INTERPRETATION -\n\nThe colour codes (blue and brown) are for 2 classes - authentic and non authentic notes.\n\nThe tree is divided by minimising the gini impurity everytime. Gini impurity is a measure of variables that are classified incorrectly. For example, at the root node, variance<=0.765 given the minimum gini(0.494) among all the splits. Once it becomes 0,the group is perfectly homogeneous and there is no further classification(the leaf nodes).\n\nWhen we need to predict the class, we will check the constraint on every node down the tree to the left and right child till we reach the gini impurity 0 ie leaf node."},{"metadata":{"id":"jcOUpu1dYPJq"},"cell_type":"markdown","source":"## Neural Networks"},{"metadata":{"id":"hC5VyK6Ka7Lt"},"cell_type":"markdown","source":"We are using Keras in the sequential API to define a Neural network that will be train this data with an input dimension of 4 since there are 4 features.We will then have a layer of 16, then 8, then 6, and finally 1(last layer is a vector). The final layer will be activated by a sigmoid function which will push it towards a 1 or a 0. This Neural Network can then be used to predict future values. "},{"metadata":{"executionInfo":{"elapsed":36542,"status":"ok","timestamp":1593503065125,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"SVh-r_OGU9kG","outputId":"a0b9faeb-7051-4e08-a2b4-ed692b78e039","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nclassifier = Sequential() \n\nclassifier.add(Dense(units = 16, activation ='relu', input_dim = 4))\nclassifier.add(Dense(units = 8, activation = 'relu'))\nclassifier.add(Dense(units = 6, activation = 'relu'))\nclassifier.add(Dense(units = 1, activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"id":"eqoQlYQgbWQb"},"cell_type":"markdown","source":"Here, we have to specify the optimizer and loss function. On each iteration, it measures how well it did in training using the loss function. It then tries to improve on that using the optimizer."},{"metadata":{"executionInfo":{"elapsed":36543,"status":"ok","timestamp":1593503065128,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"IQZuBGGbVCBR","trusted":true},"cell_type":"code","source":"classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"id":"wB2UWgQxbgBe"},"cell_type":"markdown","source":"We fit the data using fit, passing it the training data -- i.e. for this set of X, this is what the Y should look like. The training itself takes a Fit function. Here in the training we pass x's and y's, and specify how many times it will loop, where a loop is it making a guess at the relationship between the x and the y.It measures how well or how bad it does using the loss function, and then it improves on its guess using the optimizer. \n\nThe NN will then spot the patterns in the data, and build a neural network that could replicate that. "},{"metadata":{"executionInfo":{"elapsed":91955,"status":"ok","timestamp":1593503120546,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"OmzvG0UOVG-e","outputId":"ab1e47ae-6fc4-42a6-8454-cce06dde567e","trusted":true},"cell_type":"code","source":"classifier.fit(train_X, train_y, batch_size = 1, epochs = 50)","execution_count":null,"outputs":[]},{"metadata":{"id":"be5ELeUEb5kS"},"cell_type":"markdown","source":"To predict new values, the Neural Network uses predict. We are passing the test values for X (which the Neural Network hasn't previously seen) and it will give back a set of predictions."},{"metadata":{"executionInfo":{"elapsed":91953,"status":"ok","timestamp":1593503120547,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"JHR5FSOBWaOT","trusted":true},"cell_type":"code","source":"val_predictions3 = classifier.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":7099,"status":"ok","timestamp":1593503267804,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"hOkl2lXuMIqA","outputId":"4c666263-67d2-4869-9b36-157aed45a25f","trusted":true},"cell_type":"code","source":"pip install ann_visualizer","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1111,"status":"ok","timestamp":1593503815505,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"pLeBw2t_MjAm","outputId":"2262ba2b-3766-4aff-d4ae-054b66383096","trusted":true},"cell_type":"code","source":"classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1241,"status":"ok","timestamp":1593503662075,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"x4ddN7R5NwJ-","outputId":"c19d4987-ac56-4a4b-a7af-d3c73fd17094","trusted":true},"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\n\nplot_model(classifier, show_shapes=True,show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"fw25tQxacFT_"},"cell_type":"markdown","source":"We calculate the error to get an idea of accuracy"},{"metadata":{"executionInfo":{"elapsed":91946,"status":"ok","timestamp":1593503120548,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"X7N4Dy8rcDqm","outputId":"b5f4daa4-1eb1-4f16-f5d1-24183f85d97c","trusted":true},"cell_type":"code","source":"mae=mean_absolute_error(val_y,val_predictions3)\nprint(mae)","execution_count":null,"outputs":[]},{"metadata":{"id":"VNGSVs3UaM6U"},"cell_type":"markdown","source":"The error is negligible. This implies that we have successfully trained and correctly predicted."},{"metadata":{"id":"WpTzsRPWLwij"},"cell_type":"markdown","source":"## tSNE on text"},{"metadata":{"executionInfo":{"elapsed":91940,"status":"ok","timestamp":1593503120549,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"1_bob267Lva0","outputId":"a1e0c1ac-cc40-4f0f-8090-8a4e6952cafb","trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":100314,"status":"ok","timestamp":1593503128926,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"YEbxMkgUN_d6","trusted":true},"cell_type":"code","source":"tsne = TSNE(n_components=2, random_state=0)\n#fitting tSNE model to our data\n#this is the same data we used above (bank note authentication)\ndata_tsne = tsne.fit_transform(data)\n#converting into dataframe\ndf_tsne=pd.DataFrame(data=data_tsne,columns=['X','Y'])\ndf_tsne['label']=data['Class']","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":100709,"status":"ok","timestamp":1593503129327,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"yXm9boW4OCPF","outputId":"22cc47a9-b2c1-4674-a578-89ea825147e0","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 5))\ng = sns.lmplot(x='X',y='Y',data=df_tsne, fit_reg=False,hue='label', size=6)\nplt.title(\"tSNE plot\",size=25)","execution_count":null,"outputs":[]},{"metadata":{"id":"z2oxhmqlOLVT"},"cell_type":"markdown","source":"INTERPRETATION -\nWe have 2 labels 0 and 1 denoting non authentic and authentic banknotes.\nThe data was 4 dimensional which was converted to 2D by using tSNE. \n\nNow, the above plot uses these 2 dimensions of tSNE dataframe. The 2 categories are colour coded using class column of the data. Thus, It is observed thar records of same categories are clustered together(except a few outliers).\n"},{"metadata":{"id":"L4k7ZkvtQxPx"},"cell_type":"markdown","source":"## tSNE on image MNIST"},{"metadata":{"executionInfo":{"elapsed":100708,"status":"ok","timestamp":1593503129329,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"H7-WtJpHH-yR","trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_digits","execution_count":null,"outputs":[]},{"metadata":{"id":"FkTASMRicaDP"},"cell_type":"markdown","source":"Steps followed:\n1. Loading data\n2. Taking the first 1000 values for convenience(time consuming process)\n3. Applying tSNE and fitting the model\n4. Converting the fit into dataframe for plotting\n5. Plotting the model"},{"metadata":{"executionInfo":{"elapsed":100706,"status":"ok","timestamp":1593503129330,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"Cmk9MgDxQwZg","trusted":true},"cell_type":"code","source":"df =load_digits()\nred_df=df.data[:1000]","execution_count":null,"outputs":[]},{"metadata":{"id":"5FJDC2QrTo5_"},"cell_type":"markdown","source":"### Parameters of tsne\nn_components - int, optional (default: 2)\nDimension of the embedded space.\n\nrandom_state - int, RandomState instance, default=None\nDetermines the random number generator. Pass an int for reproducible results across multiple function calls. \n\nperplexity - float, optional (default: 30)\nThe perplexity is related to the number of nearest neighbors(expected density). \nLarger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. \nDifferent values can result in significanlty different results.\n\nlearning_rate - float, optional (default: 200.0)\nThe learning rate for t-SNE is usually in the range [10.0, 1000.0]. \nIf the learning rate is too high, the data may look like a ‘ball’ with any point approximately equidistant from its nearest neighbours. \nIf the learning rate is too low, most points may look compressed in a dense cloud with few outliers. \n\nn_iter - int, optional (default: 1000)\nMaximum number of iterations for the optimization. Should be at least 250."},{"metadata":{"executionInfo":{"elapsed":122036,"status":"ok","timestamp":1593503150666,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"vAPeK9bJS7Dj","outputId":"e2923508-7162-4b2b-d17b-3225400e9918","trusted":true},"cell_type":"code","source":"model1 = TSNE(n_components=2, random_state=0, perplexity=30, learning_rate=200, n_iter=1000)\nmodel2 = TSNE(n_components=2, random_state=0, perplexity=50, learning_rate=200, n_iter=2000)\ntsne1 = model1.fit_transform(red_df)\ntsne2 = model2.fit_transform(red_df)\nprint(tsne1)\nprint(tsne2)\n# fit_transform(self, X[, y])\n# Fit X into an embedded space and return that transformed output.","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":122032,"status":"ok","timestamp":1593503150668,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"sxZstQeaTBH4","outputId":"800423f2-0ee7-453a-c935-3fdd90f08312","trusted":true},"cell_type":"code","source":"df_tsne1 = pd.DataFrame(data=tsne1, columns=[\"X\", \"Y\"])\ndf_tsne1['label']=df.target[:1000]\ndf_tsne1","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":122026,"status":"ok","timestamp":1593503150669,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"uZ9YBx26VfCr","outputId":"f43b8480-951e-43fa-98bd-4261eef3f3f2","trusted":true},"cell_type":"code","source":"df_tsne2 = pd.DataFrame(data=tsne2, columns=[\"X\", \"Y\"])\ndf_tsne2['label']=df.target[:1000]\ndf_tsne2","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":122728,"status":"ok","timestamp":1593503151379,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"-_XCnmE9TPYt","outputId":"def0bf44-c68c-452b-dd2e-03d96f90b107","trusted":true},"cell_type":"code","source":"g = sns.lmplot(x='X',y='Y',data=df_tsne1, fit_reg=False, hue='label',size=6)\nplt.title(\"tSNE plot 1\",size=25)","execution_count":null,"outputs":[]},{"metadata":{"id":"pEWuscKb4ydO"},"cell_type":"markdown","source":"The various colours denote the various digits like 0,1,2,3,4...etc.\nPoints corresponding to same digit are clustered together.\n\nWe have applied model 2 below with increased perplexity and number of iterations to see if the accuracy is increased."},{"metadata":{"executionInfo":{"elapsed":123745,"status":"ok","timestamp":1593503152403,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"C-UKyffmV7UU","outputId":"f2919c8e-c88f-4c2a-aa9b-fe922f6d2a51","trusted":true},"cell_type":"code","source":"g = sns.lmplot(x='X',y='Y',data=df_tsne2, fit_reg=False,hue='label', size=6)\nplt.title(\"tSNE plot 2\",size=25)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ral0V1E0bwR8"},"cell_type":"markdown","source":"We observe that the images corresponding to the different digits are separated into different clusters of points.There is very little overlapping because of some similarity. For example, all the blue(dark) points and pink points that represent 0 and 6 respectilvely are very separate whereas there are some outliers of 9 and 1."},{"metadata":{"id":"0j-3l9I2BVPq"},"cell_type":"markdown","source":"## ERROR METRICS"},{"metadata":{"id":"EmpqMA_7cjEk"},"cell_type":"markdown","source":"When evaluating a clustering algorithm we have 2 cases -\n1. when we know the actual class variables, we can use homogeneity,completeness and v_measure score\n2. If we don't know ground truth labels, we need to use silhouette score."},{"metadata":{"id":"TkSTAE7_r2Ni"},"cell_type":"markdown","source":"### SILHOUETTE SCORE\nReturns the mean of all Silhouette coefficients.\n\n\nCoefficient of a sample s= (b - a)/max(a,b) where,\n\n\na is the average distance between s and all the other data points in the cluster to which s belongs\n\nb is the minimum average distance from s to all clusters to which it does not belong"},{"metadata":{"executionInfo":{"elapsed":123744,"status":"ok","timestamp":1593503152404,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"xXVYBpiy03LZ","trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, homogeneity_score, completeness_score, v_measure_score","execution_count":null,"outputs":[]},{"metadata":{"id":"tHLp4HbNdPu5"},"cell_type":"markdown","source":"CASE 1"},{"metadata":{"executionInfo":{"elapsed":123737,"status":"ok","timestamp":1593503152405,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"YBZKA25Dc6_z","outputId":"74bd76f4-af92-4a10-af51-2a418a25032f","trusted":true},"cell_type":"code","source":"df=data\n#dropping class column to perform k means\ndf.drop('Class',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123734,"status":"ok","timestamp":1593503152405,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"N0oT5v2P0A66","trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=2, random_state=0).fit(df)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123731,"status":"ok","timestamp":1593503152406,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"yb4t3XW00xrf","trusted":true},"cell_type":"code","source":"#kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123724,"status":"ok","timestamp":1593503152406,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"xDJQHG2lAp2C","outputId":"cb9d3333-c02d-47a7-c5eb-c2187d8c2d0f","trusted":true},"cell_type":"code","source":"h=homogeneity_score(data['Class'], kmeans.labels_)\nh","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123717,"status":"ok","timestamp":1593503152407,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"g2YNkCvsAtQO","outputId":"dc557a45-f549-4f73-b6ca-bedb7c1fbfca","trusted":true},"cell_type":"code","source":"c=completeness_score(data['Class'], kmeans.labels_)\nc","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123707,"status":"ok","timestamp":1593503152407,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"BfkYSd7O32kb","outputId":"d3ab9046-31db-4c38-a782-83276763cd8d","trusted":true},"cell_type":"code","source":"print(v_measure_score(data['Class'], kmeans.labels_) )\n#harmonic mean of completeness and homogeneity\n2/((1/h)+(1/c))","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123702,"status":"ok","timestamp":1593503152408,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"vk3oLbjZdh3F","outputId":"dbd80c20-1691-4e41-8a5c-7e3146d1f4e0","trusted":true},"cell_type":"code","source":"silhouette_score(df, kmeans.labels_)","execution_count":null,"outputs":[]},{"metadata":{"id":"QyHoThBnm8nI"},"cell_type":"markdown","source":"The above scores indicate that there is very poor clustering probably because k means assumes that all classes have the same variance i.e. each cluster has roughly equal number of observations."},{"metadata":{"executionInfo":{"elapsed":123695,"status":"ok","timestamp":1593503152408,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"N59LEG17nROi","outputId":"bdc55499-5e64-48d8-d24f-bdacda5b4ba9","trusted":true},"cell_type":"code","source":"data['Class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"SdypwGwYeakl"},"cell_type":"markdown","source":"CASE 2"},{"metadata":{"executionInfo":{"elapsed":123689,"status":"ok","timestamp":1593503152409,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"-VALY_5XcPYx","outputId":"5b5aac16-db77-4f36-a0aa-570d1bff0634","trusted":true},"cell_type":"code","source":"df2 = pd.read_csv('../input/wholesale-customers-data/Wholesale customers data.csv')\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123687,"status":"ok","timestamp":1593503152410,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"1wGrAA77cbu9","trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=2, random_state=0).fit(df2)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":123680,"status":"ok","timestamp":1593503152410,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"VmKqEGiWcR4j","outputId":"2abd9124-d77b-41d6-c6c2-9175a6e605c7","trusted":true},"cell_type":"code","source":"silhouette_score(df2, kmeans.labels_)","execution_count":null,"outputs":[]},{"metadata":{"id":"f5nlA5YSo9x2"},"cell_type":"markdown","source":"From silhouette score, it can be said that the clustering performance is moderate."},{"metadata":{"id":"EnQ2PeXFeqVf"},"cell_type":"markdown","source":"The number of clusters is taken as 2 previously. Using the Silhouette score for different no. of clusters we can check the appropriate k to be used."},{"metadata":{"executionInfo":{"elapsed":124648,"status":"ok","timestamp":1593503153384,"user":{"displayName":"Smiti Singhal","photoUrl":"","userId":"12352297004710772046"},"user_tz":-330},"id":"Ep_rMicH1zcI","outputId":"5d5bcaba-84b8-4f03-d319-df95beba8a4e","trusted":true},"cell_type":"code","source":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans(random_state=0)\n\n# Call the KElbowVisualizer with the silhouette metric \nviz = KElbowVisualizer(model, k=(2,6), metric='silhouette', timings=False)\n\n# Fit the data and visualize\nviz.fit(df2)\nviz.poof() ","execution_count":null,"outputs":[]},{"metadata":{"id":"Tbrk-1GUe-2X"},"cell_type":"markdown","source":"Clearly k should be 2 as it has the highest silhouette score."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}