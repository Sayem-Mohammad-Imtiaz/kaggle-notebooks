{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n\n# パーセプトロン\nclass Perceptron(object):\n    # 重みを設定する\n    def __init__(self, w):\n\n        self.w = w\n\n    # 入力値と重みから予測する\n\n    def net_input(self, X):\n\n        return np.dot(X, self.w[1:]) + self.w[0]\n\n    # 単位ステップ関数による判別\n\n    def predict(self, X):\n\n        return np.where(self.net_input(X) >= 0.0, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w_and = np.array([-0.0337565463634, 0.0238824358635, 0.0147182824774])\nw_or = np.array([-0.00375654636337, 0.0038824358635, 0.00471828247737])\nw_nand = np.array([0.0162434536366, -0.0161175641365, -0.00528171752263])\nw_nor = np.array([0.00624345363663, -0.0161175641365, -0.0152817175226])\nw_xor = np.array([-0.00375654636337, 0.0038824358635, -0.00528171752263])\n\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n\nY_AND = [0, 0, 0, 1]\nY_OR = [0, 1, 1, 1]\nY_NAND = [1, 1, 1, 0]\nY_NOR = [1, 0, 0, 0]\nY_XOR = [1, 0, 0, 1]\n\ndef print_perceptron(perceptron, X, Y):\n    for i in range(len(X)):\n        print(\"X:\", X[i], \"Y:\", Y[i], \"predict:\", perceptron.predict(X[i]))\n\nprint(\"AND回路\")\nprint_perceptron(Perceptron(w_and), X, Y_AND)\nprint(\"OR回路\")\nprint_perceptron(Perceptron(w_or), X, Y_NOR)\nprint(\"NAND回路\")\nprint_perceptron(Perceptron(w_nand), X, Y_NAND)\nprint(\"NOR回路\")\nprint_perceptron(Perceptron(w_nor), X, Y_NOR)\nprint(\"XOR回路\")\nprint_perceptron(Perceptron(w_xor), X, Y_XOR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Adaline(object):\n    w = [] #重み\n# errors_ = [] #誤分類回数\n\n    def __init__(self,eta = 0.01, n_iter=50, random_state=1):\n        #学習率:eta\n        #学習回数:n_iter\n        #乱数シード:random_state\n        self.eta = eta\n        self.n_iter = n_iter\n        self.random_state = random_state\n        \n    def net_input(self,X):\n        return np.dot(X,self.w[1:]) + self.w[0]\n    \n    def predict(self, X):\n        return np.where(self.net_input(X) >= 0.0, 1, 0)\n    \n    def show_w(self):\n        for i in range(len(self.w)):\n            print(\"w[\",i,\"]:\",self.w[i])\n    def fit(self, X, Y):\n        # 重みの初期化（バイアス＋重み（入力値の種類数））\n        rgen = np.random.RandomState(self.random_state)\n        # 正規分布に従った乱数生成\n        # 平均:loc = 0\n        # 標準偏差:scale = 0.01\n        # 出力配列サイズ: 入力データ種類数 + 1(バイアス分)\n        self.w = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n        self.errors_=[]\n        \n        for i in range(self.n_iter):\n            errors = 0\n            # 重み更新式はw:=w-ηΔw\n            # ΔｗはコストJ(w)をwで微分した値なので、結果として\n            # 「-(ラベル-予測)*入力値」となる（合成関数の微分）\n            for xi, target in zip(X, Y):\n                update = self.eta * (target - self.predict(xi))\n                self.w[1:] += update * xi\n                self.w[0] += update\n                # 誤差があった回数だけ＋１する\n                errors += int(update != 0.0)\n            self.errors_.append(errors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AND_X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\nAND_Y = [0, 0, 0, 1]\nadaline = Adaline()\nadaline.show_w()\nadaline.fit(AND_X, AND_Y)\nprint(\"AND回路\")\nadaline.show_w()\nprint(adaline.predict(np.array([0,0])))\nprint(adaline.predict(np.array([0,1])))\nprint(adaline.predict(np.array([1,0])))\nprint(adaline.predict(np.array([1,1])))\n\nOR_X = np.array([[0,0],[0,1],[1,0],[1,1]])\nOR_Y = [0,1,1,1]\nadaline.fit(OR_X,OR_Y)\nprint(\"OR回路\")\nadaline.show_w()\nprint(adaline.predict(np.array([0,0])))\nprint(adaline.predict(np.array([0,1])))\nprint(adaline.predict(np.array([1,0])))\nprint(adaline.predict(np.array([1,1])))\n\nNAND_X = np.array([[0,0],[0,1],[1,0],[1,1]])\nNAND_Y = [1,1,1,0]\nadaline.fit(NAND_X,NAND_Y)\nprint(\"NAND回路\")\nadaline.show_w()\nprint(adaline.predict(np.array([0,0])))\nprint(adaline.predict(np.array([0,1])))\nprint(adaline.predict(np.array([1,0])))\nprint(adaline.predict(np.array([1,1])))\n\nNOR_X = np.array([[0,0],[0,1],[1,0],[1,1]])\nNOR_Y = [1,0,0,0]\nadaline.fit(NOR_X,NOR_Y)\nprint(\"NOR回路\")\nadaline.show_w()\nprint(adaline.predict(np.array([0,0])))\nprint(adaline.predict(np.array([0,1])))\nprint(adaline.predict(np.array([1,0])))\nprint(adaline.predict(np.array([1,1])))\n\nXOR_X = np.array([[0,0],[0,1],[1,0],[1,1]])\nXOR_Y = [0,1,1,0]\nadaline.fit(XOR_X,XOR_Y)\nprint(\"XOR回路\")\nadaline.show_w()\nprint(adaline.predict(np.array([0,0])))\nprint(adaline.predict(np.array([0,1])))\nprint(adaline.predict(np.array([1,0])))\nprint(adaline.predict(np.array([1,1])))\n\n#w_and = np.array([-0.0337565463634, 0.0238824358635, 0.0147182824774])\n#w_or = np.array([-0.00375654636337, 0.0038824358635, 0.00471828247737])\n#w_nand = np.array([0.0162434536366, -0.0161175641365, -0.00528171752263])\n#w_nor = np.array([0.00624345363663, -0.0161175641365, -0.0152817175226])\n#w_xor = np.array([-0.00375654636337, 0.0038824358635, -0.00528171752263])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/iris/Iris.csv')\ndf = df.loc[:, [\"SepalLengthCm\",\"PetalLengthCm\",\"Species\"]]\ndf = df[df[\"Species\"].isin([\"Iris-setosa\",\"Iris-versicolor\"])]\ndf = df.replace({\"Species\":{\"Iris-setosa\":0,\"Iris-versicolor\":1}})\nprint(df)\n\n\nada = Adaline(eta=0.01,n_iter=100)\nada.fit(X,Y_AND)\n\ncnt=0\nfor i in range(iris_X):\n    if iris_Y[i] == and_ada.predict(X[i]):\n        cnt += 1\n    print(cnt/len(iris_X))\n\"\"\"\n\nada = Adaline(eta=0.01,n_iter=100)\nX=np.array([[0,0],[0,1],[1,0],[1,1]])\nY_AND = [0,0,0,1]\nY_OR = [0,1,1,1]\nY_NAND = [1,1,1,0]\nY_NOR = [1,0,0,0]\n\nada.fit(X, Y_AND)\nprint(\"AND回路\")\nfor i in range(len(X)):\n    print(ada.predict(X[i]))\n\nada.fit(X, Y_OR)\nprint(\"OR回路\")\nfor i in range(len(X)):\n    print(ada.predict(X[i]))\n\nada.fit(X, Y_NAND)\nprint(\"NAND回路\")\nfor i in range(len(X)):\n    print(ada.predict(X[i]))\n    \nada.fit(X, Y_NOR)\nprint(\"NOR回路\")\nfor i in range(len(X)):\n    print(ada.predict(X[i]))\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\n\niris = load_iris()\nfrom sklearn.model_selection import train_test_split\ndata_X = iris.data\ndata_y = np_utils.to_categorical(iris.target)\n\nX_train, X_test, Y_train, Y_test = train_test_split(data_X, data_y, test_size=0.3)\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(4, )))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer=SGD(),\n             metrics=['accuracy'])\n\n\nresult = model.fit(X_train, Y_train,\n         batch_size=20, epochs=400,\n         verbose=1, validation_split=0.2)\n\ntrain_score = model.evaluate(X_train, Y_train)\ntest_score = model.evaluate(X_test, Y_test)\nprint(\"\\ntrain-loss:\", train_score[0])\nprint('train-accuracy:', train_score[1])\nprint(\"\\ntest-loss:\", test_score[0])\nprint('test-accuracy:', test_score[1])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\nplt.title('Accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='test')\nplt.legend()\n\nplt.figure()\nplt.title('categorical_crossentropy Loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='test')\nplt.legend()\nplt.show()\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(4, )))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(32))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer=SGD(),\n             metrics=['accuracy'])\n\nresult = model.fit(X_train, Y_train,\n         batch_size=20, epochs=400,\n         verbose=1, validation_split=0.2)\n\n#計算打ち切り処理\nfrom keras.callbacks import EarlyStopping\nearly_stopping =  EarlyStopping(\n                            monitor='val_loss',\n                            min_delta=0.0,\n                            patience=5,\n)\n\n# モデル作成（省略）\nresult = model.fit(X_train, Y_train,\n         batch_size=20, epochs=100,\n         verbose=1, validation_split=0.2,\n                  callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}