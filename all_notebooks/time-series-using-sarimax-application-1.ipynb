{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nfrom statsmodels.tsa.stattools import adfuller\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Reading the data\ndf = pd.read_csv(\"../input/portland-oregon-average-monthly-.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"828eb5918a272230c1735b3d0195db5e8056afcf"},"cell_type":"code","source":"# A glance on the data \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = [\"month\", \"average_monthly_ridership\"]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"835be2a74f99fce4afe24478038a41eb59d6c8c1"},"cell_type":"code","source":"# getting some information about dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60582b6176f4ab4d4a49e3054f34beb3da11cd04"},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to convert the datatypes of month to index and ridership to integer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df = df.iloc[:-1,:]   #removing last row","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"363289a42ab27d847f69570f836e00bee7ec7b18"},"cell_type":"markdown","source":"Changing data type of both the column\n* Assign int to ```monthly_ridership_data``` column\n* Assign datetime to ```month``` column","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df['average_monthly_ridership'] = pd.to_numeric(df['average_monthly_ridership'])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"9427ddd6d60fd2a7011e0848b47d9970cf4c0a04"},"cell_type":"code","source":"df['month'] = pd.to_datetime(df['month'], format = '%Y-%m')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"655a033716107144447aafb866746906b608cb71"},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61a0a416983614dfbced580e700140909c3d316f"},"cell_type":"markdown","source":"# Time Series Analysis\n\nAs you all know how important data analysis is for data scientists.It gives us a brief understanding of the data and a very strange but intriguing confidence about our prediction model.Well, Time series analysis is no different.But time series problems have very special orientation when it comes to analysis.But before we move into that, let me introduce you to some jargons (Just Kidding it is pure and simple english) which are frequently used in this problem domain.\n\n**Trend**:- As the name suggests trend depicts the variation in the output as time increases.It is often non-linear. Sometimes we will refer to trend as “changing direction” when it might go from an increasing trend to a decreasing trend.\n\n**Level**:- It basically depicts baseline value for the time series.\n\n**Seasonal**:- As its name depicts it shows the repeated pattern over time. In layman terms, it shows the seasonal variation of data over time.\n\n**Noise**:- It is basically external noises that vary the data randomly.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"3ef285f1b78b798ae9766ee6bdf71bf84d495c86"},"cell_type":"code","source":"# Normal line plot so that we can see data variation\n# We can observe that average number of riders is increasing most of the time\n# We'll later see decomposed analysis of that curve\ndf.plot.line(x = 'month', y = 'average_monthly_ridership')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above plot we can see that the graph is going upwards therfore there is upward trend.\nAlso, there is repeating pattern although it is not 100% consistent from start to end but still it hints us that there is some seasonal behavior. The time period for that seems to be 1 year. Now there are different ways to verify this, I personally prefer visualizing ACF and PACF plots which also show patterns at seasonal lags. Also, if you see that durin year 1967, the variance in series is higher than in earlier years(not strictly), therefore one most commonly used method to remove variance is by doing log transformation.\n\nTo model a time series, it has to be stationary i.e. we have to remove variance, trend and seasonality. It night not be possible to remove it 100% but we will perform Dickey-fuller test under claim stationarity at 5% or 1% rejection region.","execution_count":null},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"17a8118b03025f6bb064527f4dc85dfe6eccbd88"},"cell_type":"code","source":"rider = df[['average_monthly_ridership']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Log Transformation","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"log_ridership = np.log(df[['average_monthly_ridership']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_ridership.plot.line()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is not much change but it is safe to perform log transformation to make it more stationary.","execution_count":null},{"metadata":{"_uuid":"dce2c1fe92777ece04a36a8c8b714c5adf47b96f"},"cell_type":"markdown","source":"## Trend Removal\n\nNow we see an upward trend, so we will use most common method of differenceing(order 1) i.e. with previous term to remove trend.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"e65047709f1bffd691f74081cc3a233f554af4a3"},"cell_type":"code","source":"# 1st order differencing\nrider_single_diff = (log_ridership.diff()).dropna()  # 1st term will be NAN\n\n#NOTE: diff(diff(X)) is 2nd order differencing \nrider_double_diff = (rider_single_diff.diff()).dropna()  \n\n#seasonal differencing of order 1\nrider_single_seasonal_diff = (rider_single_diff.diff(periods=12)).dropna()  # 1st term will be NAN\n\nrider_single_diff.plot.line()\nplt.title('1st Order Diff')\nplt.show()\n\nrider_double_diff.plot.line()\nplt.title('2nd Order Diff')\nplt.show()\n\nrider_single_seasonal_diff.plot.line()\nplt.title('1st Order Seasonal Diff')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations from above 3 graphs:\n\nGraph A: 1st order differencing\nWe can see that it has removed upward trend. However, the series is still not stationary as it is showing seasonla behavior. Therefore, we will have to remove it.\n\nGraph B: 2nd order differencing\nThere is not much difference w.r.t 1st order. So we will keep our model relatively simple and go aheaf with 1st order diff i.e d=1\n\nGraph C: Taking seasonal difference of 1st order diff series has removed both upward trend and seasonality. Therefore, d=1 and D=1 and m=12(seasonal order). Note even if you don't take seasonal difference, the series might pass stationarity test but by this method  would yield better results.\n\nNow we have to check if it passes the Dickey-Fuller test. I am hopeful it will!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Perform Dickey–Fuller test:\nprint('Results of Dickey Fuller Test:')\ndftest = adfuller(rider_single_seasonal_diff.average_monthly_ridership, autolag='AIC') #Note: the input should not be a dataframe but a panda series\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint(dfoutput)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! We can see that p-value is very small. Smaller than inverse of speed of light!\n\nTherefore, I am happy to declare that our series is now stationary. So we proceed to model it.\n\nNow there are different packages available in python for that. Following are two most commonly used ones:\n\n1) ARIMA(): In this you need to pass a series and order p, d, q. It will fit and generate forecast.\nTo generate forecasts, here we first explicitly need to create dates on which to make future predictions. Also, It doesn't have in-bult option to take seasonal difference therefore you have to first take that difference and then pass it and after generating predictions, reverse engineer the difference part which is a little lengthy process. \n\n2) SARIMAX(): In this you need to pass series and order (p,d,q)x(P,D,Q)x(m). It will fit and generate forecasts. Here we have flexibility to simply define the number of period over which future predictions are to be made w/o manually creating dates at initial stages.\n\nNOTE: In both, since they don't have in-built option to do log transformation, we have to pass log transformed series and later reverse engineer the predictions to get meaningful values.","execution_count":null},{"metadata":{"_uuid":"2958077eb2898611a9bdb6d786502c309890f178"},"cell_type":"markdown","source":"## [Periodicity and Autocorrelation](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/)\n\nAuto correlation is the most famous way to understand seasonal variation till now. We can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a serial correlation, or an autocorrelation.In this plot vertical axis is represented by the following equations:-\n\n> $C_n = \\sum_{t = 1}^{n - h} (y(t) - \\hat{y}) (y(t + n) - \\hat{y}) / n$\n\n> $C_0 = \\sum_{t = 1}^{n} (y(t) - \\hat{y})^2 / n$\n\nHorizontal axis represents time lag(previous time steps)  h.\n\nNote that the ACF and PACF plots help us to find (p,q)X(P,Q). Therefore we will use log transformed series with d=1, D=1. However, if you want to confirm the seasonality order then you can skip doing seasonal difference and then you will see seasonal patterns in those plots.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"7dbd0b9fed823b716a1bae55527f7e38ac6ec07f"},"cell_type":"code","source":"#ACF and PACF plots:\nimport statsmodels.api as sm\nsm.graphics.tsa.plot_acf(rider_single_seasonal_diff.values.squeeze(), lags=40)\nplt.title('ACF')\nplt.show()\n\nsm.graphics.tsa.plot_pacf(rider_single_seasonal_diff.values.squeeze(), lags=40)\nplt.title('PACF')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations from above graphs:\n\n1) ACF: We can see that most of the correlations are just noises(therefore, q=0). There is a significant spike at lag 11,12 which indicates Q=1.\n\n2) PACF: It has same story here as well, p=0 and P=1. Note that correlation at around 24,36 are also significant therefore we can try P=2 as well. We will not try P=3 as it would make model very complicated and lead to overfitting.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Forecasting","execution_count":null},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"689ba067663a05227db369409fe5fe51bc858987"},"cell_type":"code","source":"#for our model we need dates as indexes\ndf = df.set_index('month')\n\n#doing log transformation on data\ndf['average_monthly_ridership'] = np.log(df[['average_monthly_ridership']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f01354dba60e8d0fd01ea4d7a213a66238b1aa85"},"cell_type":"code","source":"# Applying Seasonal ARIMA model to forcast the data \nmod = sm.tsa.SARIMAX(df['average_monthly_ridership'], trend='n', order=(0,1,0), seasonal_order=(1,1,1,12))\nresults = mod.fit()\nprint(results.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I tried different model with P=1,2. Following is the brief comparison:\n\n1) AIC: Almost same\n\n2) Prob(Q): Model_1 > Model_2 (which indicates Model_1 has lesser correlation in data, which is good)\n\n3) P>|Z| :  Lower is the P-value better it is. It tells us about coefficients of AR, MA terms. P-value is lower when P=1\n\nThe Ljung–Box test may be defined as:\n\nH0: The data are independently distributed (i.e. the correlations in the population from which the sample is taken are 0, so that any observed correlations in the data result from randomness of the sampling process).\n\nHa: The data are not independently distributed; they exhibit serial correlation.\n\nIn our case, p-value is significant therefore we reject the null hypothesis and say that there are no correlations.","execution_count":null},{"metadata":{"_uuid":"33f2b40b0fd8adb7e0e028390dfa18e9f1cc5a47"},"cell_type":"markdown","source":"## To check your model","execution_count":null},{"metadata":{"trusted":true,"_uuid":"a3638af48819a34c78a647e95e0c8d30b460adc7","collapsed":true},"cell_type":"code","source":"df['forecast'] = results.predict(start = 102, end= 120, dynamic= True)  \ndf[['average_monthly_ridership', 'forecast']].plot(figsize=(12, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the values are still log transformed.","execution_count":null},{"metadata":{"_uuid":"e3fcaebc331b3432378c59bd451740929c429e8e"},"cell_type":"markdown","source":"## To generate future forecasts","execution_count":null},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"7d027f06eaecb86a0b7956b2ade827c87ec0f0ab"},"cell_type":"code","source":"def forcasting_future_months(df, no_of_months):\n    df_predict = df.reset_index()\n    mon = df_predict['month']\n    mon = mon + pd.DateOffset(months = no_of_months)\n    future_dates = mon[-no_of_months -1:]\n    df_predict = df_predict.set_index('month')\n    future = pd.DataFrame(index=future_dates, columns= df_predict.columns)\n    df_predict = pd.concat([df_predict, future])\n    df_predict['forecast'] = results.predict(start = 114, end = 125, dynamic= True)  \n    df_predict[['average_monthly_ridership', 'forecast']].iloc[-no_of_months - 12:].plot(figsize=(12, 8))\n    plt.show()\n    return df_predict[-no_of_months:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7f53c9cccacc67c52b8ad3410f331fc0dbdcdce","collapsed":true},"cell_type":"code","source":"predicted = forcasting_future_months(df,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20200fa9593f5b791162857c35b6db34bcc33b7b","collapsed":true},"cell_type":"markdown","source":"Converting values back to normal by taking exponential","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df = df.apply(np.exp)\nforecast = predicted.apply(np.exp)\nfinal = df.append(forecast)\nfinal[['average_monthly_ridership', 'forecast']].plot(figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hurray! You have made it to THE END.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}