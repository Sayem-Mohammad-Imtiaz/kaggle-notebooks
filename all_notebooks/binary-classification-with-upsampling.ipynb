{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting vehicle insurance purchase using Binary Classification and Upsampling\n\nBuilding a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimize its business model and revenue.\n\nWe have information about:\n\nDemographics (gender, age, region code type),\nVehicles (Vehicle Age, Damage),\nPolicy (Premium, sourcing channel) etc."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import libraries and functions required for data modeling and manipulation\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pycaret\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, GridSearchCV, StratifiedKFold\n\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsRegressor, KernelDensity, KDTree\nfrom sklearn.metrics import *\n\nfrom imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler, SMOTENC, SVMSMOTE\nfrom imblearn.under_sampling import TomekLinks, NearMiss, RandomUnderSampler\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load and view the data\nThe data has been split into training and test sets already.  We'll read in and examine the shape and format of the data sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/imbalanced-data-practice/aug_train.csv')\ntest = pd.read_csv('../input/imbalanced-data-practice/aug_test.csv')\n\nprint(\"Training Data\")\nprint(train.shape)\nprint(train.head())\nprint(\"Testing Data\")\nprint(test.shape)\nprint(test.head())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training/Testing data split is about 83/17.  Would typically split the data closer to 70/30, but the sample size is large enough so this is probably ok."},{"metadata":{},"cell_type":"markdown","source":"### Check for any missing data\nMissing data is typically handled through imputation (mean, median, random) or records may be removed if they are deemed immaterial."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train - Missing Data')\nprint(train.isna().any())\nprint('Test - Missing Data')\nprint(test.isna().any())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All variables show a value of \"False\", no imputation or record removal is required."},{"metadata":{},"cell_type":"markdown","source":"### Check data types"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Identify categorical variables stored as type 'object' vs. variables that are numeric\n\ncategories = [c for c in train.columns if train[c].dtypes =='object']\nprint('Categories', categories)\n\nnumerics = [c for c in train.columns if c not in categories]\nprint('Numerics', numerics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert categorical variables to \"dummy\" coded variables\n\nfor c in categories:\n    le=LabelEncoder()\n    le.fit(list(train[c].astype('str')) + list(test[c].astype('str')))\n    train[c] = le.transform(list(train[c].astype(str))) \n    test[c] = le.transform(list(test[c].astype(str))) \n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check data types again; data types should all be numeric now\n\ntrain.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove the ID field for modeling, store in a variable for later use if needed\n\ntrain_id = train.pop('id')\ntest_id = test.pop('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a copy of the data set to be used for model evaluation/selection\n\ntrain2 = train.copy()\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the target field from the train data and store in a variable for analysis of predictors/later use\n\ntarget = train.pop('Response')\n\n#Confirm shape of data matches expectation\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate a correlation matrix to check for collinearity\n\nplt.figure(figsize=(15,12))\nsns.heatmap(pd.concat([train,target], axis=1).corr(), annot=True, cmap=\"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation matrix shows no strong correlations between any of the predictors and the Response variable\n\nThe strongest correlation we see between predictors is the negatively correlated relationship between Vehicle Damage and Previously Insured.  This could reinforce a theory that someone who experienced an event where their vehicle was damaged prompted them to seek coverage."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check distribution of Response variable\n\nax = sns.countplot(x = target)\nsns.set(font_scale=1.5)\nfig = plt.gcf()\nfig.set_size_inches(10,5)\nax.set_ylim(top=500000)\nfor p in ax.patches:\n    ax.annotate('{:.2f}%'.format(100*p.get_height()/len(target)), (p.get_x()+ 0.3, p.get_height()+10000))\n\nplt.title('Distribution of Target')\nplt.ylabel('Frequency [%]')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the Response data is heavily imbalanced which may adversely impact our model.  Upsampling or Downsampling should be explored."},{"metadata":{},"cell_type":"markdown","source":"### Use the pycaret package for model selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set up the pycaret classification environment\n\nfrom pycaret.classification import *\nexp_clf101 = setup(data = train2, target = 'Response', session_id=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use the compare model function to evaluate the performance of several models fit on the training data\n\nbest_model = compare_models(exclude = ['xgboost', 'catboost', 'svm', 'qda', 'nb', 'ada', 'gbc', 'lightgbm'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Classifier is the model with the highest Accuracy and AUC "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use the create model function to view model plots\n\nrf1 = create_model('rf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the AUC curve\n\nplot_model(rf1, plot='auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot feature importance to show the level of relevance of each of the variables in the model\n\nplot_model(rf1, plot='feature')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Vintage is the most important feature in the model, just ahead of Annual Premium. "},{"metadata":{},"cell_type":"markdown","source":"### Model the data using a Random Forest Classifier with cross validation\nWe'll return both the auc and recall scores for the model.\n\nRecall is of particular interest because it represents the the ratio of results that were actually True (e.g., Purchases) compared to the number of results predicted to be True"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_auc = []\nscore_recall = []\ntrain_rf = np.zeros(len(train))\ntest_rf = np.zeros(len(test))\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n\nfor fold, (train_ind, val_ind) in enumerate(folds.split(train, target)):\n    print('fold:', fold)\n    trn_data, val_data = train.iloc[train_ind], train.iloc[val_ind]\n    y_train, y_val = target.iloc[train_ind], target.iloc[val_ind]\n    \n    rf = RandomForestClassifier(n_estimators=150, max_depth=5, criterion='gini', max_features=0.8, n_jobs= -1, random_state=11)\n    rf.fit(trn_data, y_train)\n    train_rf[val_ind] = rf.predict_proba(val_data)[:, 1]\n    y = rf.predict_proba(trn_data)[:, 1]\n    \n    print('val auc:' , roc_auc_score(y_val, train_rf[val_ind]))\n    print('val recall:' , recall_score(y_val, np.where(train_rf[val_ind] > 0.5, 1, 0)))\n   \n    score_auc.append(roc_auc_score(y_val, train_rf[val_ind]))\n    score_recall.append(recall_score(y_val, np.where(train_rf[val_ind] > 0.5, 1, 0)))\n                        \n    test_rf += rf.predict_proba(test)[:, 1]/folds.n_splits\n    \nprint(' Model auc: --> ', np.mean(score_auc))\nprint(' Model recall: --> ', np.mean(score_recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"AUC values look pretty good, but Recall values are all 0.  That's not a good sign for our model, which isn't able to predict Positive values (Purchases).  This may be due to the class imbalance issue mentioned earlier.\n\nLet's take a look at the confusion matrix..."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_rf_01 = np.where(train_rf > 0.5, 1, 0)\n\ncf_matrix = confusion_matrix(target, train_rf_01)\ngroup_names = ['True Negative','False Positive','False Negative','True Positive']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nplt.figure(figsize=(12,8))\nsns.set(font_scale=1.6)\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now see no predictions were made for Positive (Response = 1) values.  \n\nNext we'll try upsampling to attempt to fix our class imbalance issue and see if our model improves."},{"metadata":{},"cell_type":"markdown","source":"### Upsampling w/ SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Used default imblearn parameters\n\nsmote= SMOTE(sampling_strategy='minority', k_neighbors=5)\n\ntml = TomekLinks()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_auc = []\nscore_recall = []\ntrain_rf = np.zeros(len(train))\ntest_rf = np.zeros(len(test))\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=123)\n\nfor fold, (train_ind, val_ind) in enumerate(folds.split(train, target)):\n    print('fold:', fold)\n    trn_data, val_data = train.iloc[train_ind], train.iloc[val_ind]\n    y_train, y_val = target.iloc[train_ind], target.iloc[val_ind]\n    \n    #Upsample our training data and response variable\n    train_upsample, y_upsample = smote.fit_resample(trn_data, y_train)\n    \n    rf = RandomForestClassifier(n_estimators=150, max_depth=5, criterion='gini', max_features=0.8, n_jobs= -1, random_state=11)\n    rf.fit(train_upsample, y_upsample)\n    train_rf[val_ind] = rf.predict_proba(val_data)[:, 1]\n    y = rf.predict_proba(train_upsample)[:, 1]\n    \n    print('val auc:' , roc_auc_score(y_val, train_rf[val_ind]))\n    print('val recall:' , recall_score(y_val, np.where(train_rf[val_ind] > 0.5, 1, 0)))\n   \n    score_auc.append(roc_auc_score(y_val, train_rf[val_ind]))\n    score_recall.append(recall_score(y_val, np.where(train_rf[val_ind] > 0.5, 1, 0)))\n                        \n    test_rf += rf.predict_proba(test)[:, 1]/folds.n_splits\n    \nprint(' Model auc: --> ', np.mean(score_auc))\nprint(' Model recall: --> ', np.mean(score_recall))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now our AUC values have decreased slightly, but we have Recall values that look good. (Average is 0.90699)\n\nLet's again look at the confusion matrix..."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_rf_01 = np.where(train_rf > 0.5, 1, 0)\n\ncf_matrix = confusion_matrix(target, train_rf_01)\ngroup_names = ['True Negative','False Positive','False Negative','True Positive']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nplt.figure(figsize=(12,8))\nsns.set(font_scale=1.6)\n\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n\nWe should evaluate which metric is most important to us based on our use case and train/select our model to optimize that metric.  In this case, we are particularly interested in Recall which tells us our True Positive rate (Purchases).\n\nThe Random Forest performs pretty well in predicting Recall.  We can consider additional adjustments/tuning to try to improve the model such as modifying the train/test data split, alternative upsampling/downsampling approaches, other model types, etc."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}