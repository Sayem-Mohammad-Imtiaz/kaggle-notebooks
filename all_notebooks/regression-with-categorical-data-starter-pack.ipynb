{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Regression with categorical data starter pack","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Introduction\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.\n\n## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using matplotlib. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Some import","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os # accessing directory structure\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport pandas_profiling\nimport pandas_summary as ps\nimport shap\n\n\n# Data processing, metrics and modeling\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.decomposition import PCA\nimport collections\n\n# Lgbm\nimport lightgbm as lgb\n\n# Hyper_opt\nfrom hyperopt import hp\nfrom hyperopt import fmin, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nimport hyperopt.pyll\nfrom hyperopt.pyll import scope\n\n# Suppr warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Plots\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import rcParams\n\n# Others\nimport shap\nimport datetime\nfrom tqdm import tqdm_notebook\nimport sys\nimport pickle\nimport re\nimport json\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.width', 1000)\npd.set_option('use_inf_as_na', True)\n\nwarnings.simplefilter('ignore')\nmatplotlib.rcParams['figure.dpi'] = 100\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Immediately, do the right thing. Reduce the amount of memory under the data frame when reading.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = reduce_mem_usage(pd.read_csv('../input/regression-with-categorical-data/train.csv'))\ntest_df = reduce_mem_usage(pd.read_csv('../input/regression-with-categorical-data/test.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good optimization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## With this amount, you can use gradient boosting.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using pandas_summary we’ll see describe the columns. By the way, here you can immediately see if reduce_mem_usage worked correctly, in some cases it gives inf ... If something went wrong, then the infs will appear in min and max.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"dfs = ps.DataFrameSummary(train_df)\nprint('categoricals: ', dfs.categoricals.tolist())\nprint('numerics: ', dfs.numerics.tolist())\ndfs.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfs = ps.DataFrameSummary(test_df)\nprint('categoricals: ', dfs.categoricals.tolist())\nprint('numerics: ', dfs.numerics.tolist())\ndfs.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df['target'].hist();","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"train_df[train_df['target']>25000]['target'].hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Log it","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df['target'] = np.log1p(train_df['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df['target'].hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y = train_df['target']\ntrain_df.drop('target', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Much better!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In the id column, some insider is unlikely to be sewn up, we will drop. It’s more correct, of course, to index the data frame by id, but there is no task to build a pipeline, so we’ll omit this moment)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.drop('id', axis=1, inplace=True)\ntest_df.drop('id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's check the columns in the test and train","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df.columns.tolist() == test_df.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's look at the distributions, correlations, and other characteristics of the samples.","execution_count":null},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"pandas_profiling.ProfileReport(train_df)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"pandas_profiling.ProfileReport(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering will not do. Hypothesis - the number of features is excessive. We will look for top features and exclude those that negatively affect quality.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"cat = train_df.select_dtypes(include=['category']).columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_df, y, test_size=0.25, random_state=777)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We will use more modern methods. We will choose hyperparameters as a hyperopt, and not a gridscaerch.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n# Чем больше P, тем меньше мы хотим штрафовать за разницу между train  и test\np = 0.8\n# k - количество итераций\nk = 30\n\nskf = KFold(n_splits=3, shuffle=True, random_state=7)\n\ndef score(params):\n    print('Training with params:')\n    print(params)\n    w=[]\n    best_iter = []\n    \n\n    for train_index, val_index in skf.split(X_train, y_train):\n        x_train_1, x_valid_1 = X_train.iloc[train_index, :], X_train.iloc[val_index, :]\n        y_train_1, y_valid_1 = y_train.iloc[train_index], y_train.iloc[val_index]\n        train_data = lgb.Dataset(x_train_1, label=y_train_1, categorical_feature=cat)\n        val_data = lgb.Dataset(x_valid_1, label=y_valid_1, categorical_feature=cat, reference=train_data)\n        gbm = lgb.train(params,\n                        train_data,\n                        valid_sets = [train_data, val_data],\n                        valid_names=['train', 'val'],\n                        num_boost_round = 5000,\n                        verbose_eval = False, \n                        categorical_feature=cat\n                       )\n        w.append([gbm.best_score['train']['rmse'], gbm.best_score['val']['rmse']])\n        best_iter.append(gbm.best_iteration)\n    nrounds = np.mean(best_iter)\n    print('best iter:', int(nrounds), 'all iter:', best_iter)\n    res = list(np.mean(w, axis=0))\n    print(\"\\t rmse train {0}, rmse test {1}, dif {2}, \\n\\t final score {3} \\n\\n\".format(res[0], res[1], np.power(np.square(res[0]-res[1]), p), +res[1]+np.power(np.square(res[0]-res[1]), p)))\n    return {'loss': +res[1]+np.power(np.square(res[0]-res[1]), p), 'status': STATUS_OK, \n            'mean_rmse_train': res[0], 'mean_rmse_test': res[1], 'best_iter': int(nrounds)}\n\ndef optimize(trials):\n    space = {\n        #'max_depth': hp.choice('max_depth', [-1, 6, 7]),\n        'max_depth': -1,\n        'max_bin': scope.int(hp.uniform('max_bin', 100, 2500)),\n        'num_leaves': scope.int(hp.uniform('num_leaves', 20, 200)),\n        'lambda_l1': hp.quniform('lambda_l1', 0, 8, 0.25),\n        'learning_rate': hp.quniform('learning_rate', 0.01 , 0.05, 0.005),\n        'bagging_fraction': hp.quniform('bagging_fraction', 0.3, 0.9, 0.1),\n        'metric': ('rmse',),\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'nthread': 8,\n        'early_stopping_rounds': 20,\n        'silent':1,\n    }\n    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=k)\n    print(best)\n\ntrials = Trials()\noptimize(trials)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's train a model with selected hyperparameters.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"params = trials.best_trial['misc']['vals']\nparams['max_depth'] = -1\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'regression'\nparams['metric'] = ('l1', 'l2')\nparams['nthread'] = 8\nparams['early_stopping_rounds'] = 100\nparams['silent'] = 1\nparams['num_leaves'] = int(params['num_leaves'][0])\nparams['max_bin'] = int(params['max_bin'][0])\nparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_ds = lgb.Dataset(X_train, label=y_train, categorical_feature=cat, )\nval_ds = lgb.Dataset(X_val, label=y_val, categorical_feature=cat, reference=train_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nbooster = lgb.train(params, train_ds, num_boost_round=10000, valid_sets=[train_ds, val_ds], valid_names=['train', 'valid'], verbose_eval=100, categorical_feature=cat, early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Значимость фичей по gain lightgbm:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"gain = booster.feature_importance(importance_type='gain')\ntotal = sum(gain)\ntmp = pd.DataFrame({'Name': X_train.columns.tolist(), 'Value': gain/total})\ntmp = tmp.sort_values('Value', ascending=False)\ntmp.index = range(1, tmp.shape[0]+1)\ntmp.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Choosing the number of features by gain\nFrom each iteration, we will drop from lightgbm training one bundle according to min gain. For us, the difference between the train and the test, as well as the metric on validation, is important","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ni = 0\nf = pd.DataFrame(columns=['Number_of_cols', 'rmse_test', 'rmse_train', 'rmse_diff'])\nk = tmp.shape[0]\nwhile k > 10:\n    columns = list(tmp.loc[:k, 'Name'])\n    w=[]\n    best_iter = []\n    for train_index, val_index in skf.split(X_train, y_train):\n        x_train_2, x_valid_2 = X_train.loc[train_index, columns], X_train.loc[val_index, columns]\n        y_train_2, y_valid_2 = y_train.iloc[train_index], y_train.iloc[val_index]\n        cat_2 = x_train_2.select_dtypes(include=['category']).columns.tolist()\n        train_data_2 = lgb.Dataset(x_train_2, label=y_train_2, categorical_feature=cat_2)\n        val_data_2 = lgb.Dataset(x_valid_2, label=y_valid_2, categorical_feature=cat_2, reference=train_data_2)\n        gbm_2 = lgb.train(params,\n                        train_data_2,\n                        valid_sets = [train_data_2, val_data_2],\n                        valid_names=['train', 'val'],\n                        num_boost_round = 5000,\n                        verbose_eval = False, \n                        categorical_feature=cat_2\n                       )\n        w.append([gbm_2.best_score['train']['l1'], gbm_2.best_score['val']['l1']])\n        best_iter.append(gbm_2.best_iteration)\n    nrounds = np.mean(best_iter)\n    res = list(np.mean(w, axis=0))\n    \n    rmse_test = res[0]\n    rmse_train = res[1]\n    f.loc[i, :] = k, rmse_test, rmse_train, rmse_test - rmse_train\n    print('n columns ', k, 'rmse_test ', rmse_test, 'rmse_train ', rmse_train, 'diff ', rmse_train - rmse_test)\n    i+=1\n    k-=5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HOW MUCH NOISE !!!!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Choose the optimal number of features by the difference and the validation metric. More than half of the features do not carry informational content.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp.head(55)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"column = tmp.head(55)['Name'].tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we narrow the selection ranges with a hyperparameter and remove insignificant features","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n# Чем больше P, тем меньше мы хотим штрафовать за разницу между train  и test\np = 0.8\n# k - количество итераций\nk = 250\n\ncat = X_train[column].select_dtypes(include=['category']).columns.tolist()\n\nskf = KFold(n_splits=3, shuffle=True, random_state=7)\n\ndef score(params):\n    print('Training with params:')\n    print(params)\n    w=[]\n    best_iter = []\n    \n\n    for train_index, val_index in skf.split(X_train, y_train):\n        x_train_1, x_valid_1 = X_train[column].iloc[train_index, :], X_train[column].iloc[val_index, :]\n        y_train_1, y_valid_1 = y_train.iloc[train_index], y_train.iloc[val_index]\n        train_data = lgb.Dataset(x_train_1, label=y_train_1, categorical_feature=cat)\n        val_data = lgb.Dataset(x_valid_1, label=y_valid_1, categorical_feature=cat, reference=train_data)\n        gbm = lgb.train(params,\n                        train_data,\n                        valid_sets = [train_data, val_data],\n                        valid_names=['train', 'val'],\n                        num_boost_round = 5000,\n                        verbose_eval = False, \n                        categorical_feature=cat\n                       )\n        w.append([gbm.best_score['train']['rmse'], gbm.best_score['val']['rmse']])\n        best_iter.append(gbm.best_iteration)\n    nrounds = np.mean(best_iter)\n    print('best iter:', int(nrounds), 'all iter:', best_iter)\n    res = list(np.mean(w, axis=0))\n    print(\"\\t rmse train {0}, rmse test {1}, dif {2}, \\n\\t final score {3} \\n\\n\".format(res[0], res[1], np.power(np.square(res[0]-res[1]), p), +res[1]+np.power(np.square(res[0]-res[1]), p)))\n    return {'loss': +res[1]+np.power(np.square(res[0]-res[1]), p), 'status': STATUS_OK, \n            'mean_rmse_train': res[0], 'mean_rmse_test': res[1], 'best_iter': int(nrounds)}\n\ndef optimize(trials):\n    space = {\n        #'max_depth': hp.choice('max_depth', [-1, 6, 7]),\n        'max_depth': -1,\n        'max_bin': scope.int(hp.uniform('max_bin', 1000, 2000)),\n        'num_leaves': scope.int(hp.uniform('num_leaves', 8, 60)),\n        'lambda_l1': hp.quniform('lambda_l1', 0.5, 2.25, 0.125),\n        'learning_rate': hp.quniform('learning_rate', 0.03 , 0.06, 0.005),\n        'bagging_fraction': hp.quniform('bagging_fraction', 0.6, 0.9, 0.01),\n        'metric': ('rmse',),\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'nthread': 8,\n        'early_stopping_rounds': 20,\n        'silent':1,\n    }\n    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=k)\n    print(best)\n\ntrials = Trials()\noptimize(trials)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error is clearly reduced!","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"params = trials.best_trial['misc']['vals']\nparams['max_depth'] = -1\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'regression'\nparams['metric'] = ('l1', 'l2')\nparams['nthread'] = 8\nparams['early_stopping_rounds'] = 100\nparams['silent'] = 1\nparams['num_leaves'] = int(params['num_leaves'][0])\nparams['max_bin'] = int(params['max_bin'][0])\nparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_ds = lgb.Dataset(X_train[column], label=y_train, categorical_feature=cat, )\nval_ds = lgb.Dataset(X_val[column], label=y_val, categorical_feature=cat, reference=train_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nbooster = lgb.train(params, train_ds, num_boost_round=10000, valid_sets=[train_ds, val_ds], valid_names=['train', 'valid'], verbose_eval=100, categorical_feature=cat, early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature importance","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"shap.initjs()\nexplainer = shap.TreeExplainer(booster)\nshap_values = explainer.shap_values(X_val[column])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"shap.summary_plot(shap_values, X_val[column], plot_type='bar', max_display=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict\n\nDo not forget to expose the predict","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"pred_train = np.expm1(booster.predict(X_train[column]))\npred_val = np.expm1(booster.predict(X_val[column]))\npred_test = np.expm1(booster.predict(test_df[column]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metrics","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(metrics.mean_absolute_error(y_train, pred_train))\nprint(metrics.mean_squared_error(y_train, pred_train))\nprint(metrics.mean_squared_log_error(y_train, pred_train))\nprint(metrics.median_absolute_error(y_train, pred_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Val","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"print(metrics.mean_absolute_error(y_val, pred_val))\nprint(metrics.mean_squared_error(y_val, pred_val))\nprint(metrics.mean_squared_log_error(y_val, pred_val))\nprint(metrics.median_absolute_error(y_val, pred_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Here you need to highlight the bucket with the business and calculate the metric that is understandable for the business -% of the bucket getting into the bucket. You can also calculate the% hit in the 20% interval.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Check out my guide to linear regressions:\nhttps://www.kaggle.com/podsyp/complete-linear-model-guide","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}