{"cells":[{"metadata":{"id":"sbJuwxJ5cO2c"},"cell_type":"markdown","source":"1-VERİ HAZIRLAMA AŞAMASI\n"},{"metadata":{"id":"89G5nptPcVja"},"cell_type":"markdown","source":"Gerekli kütüphaneleri çağıralım "},{"metadata":{"id":"THValPY7cMYg","trusted":true},"cell_type":"code","source":"#Genel komutlar\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pandas import read_csv\n#RMSE ile tahmin hatalarımı belirlemek için sqrt çağırdım.(evaluate forecast)\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n#Verisetini ayıklamak için çağırdım\nfrom numpy import split\nfrom numpy import array\n\n#LSTM MMODELLETİM İÇİN GEREKLİ KERAS KÜTÜPHANELERİM\nfrom keras.optimizers import Adam\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import LSTM\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard","execution_count":null,"outputs":[]},{"metadata":{"id":"EcPU7HoAtqYF","trusted":true},"cell_type":"code","source":"path = \"../input/solar-radiation-dataset/2017_2019.csv\"\ndf = pd.read_csv(path)","execution_count":null,"outputs":[]},{"metadata":{"id":"_1SR0tvUf7RW"},"cell_type":"markdown","source":"Verisetini oluşturuken oluşan boş sütunu sildim"},{"metadata":{"id":"7bJc_Vr6f4K-","trusted":true},"cell_type":"code","source":"df=df.drop(['Unnamed: 18',\"DHI\",\"DNI\",\"Clearsky DHI\" ,\"Clearsky DNI\",\"Clearsky GHI\"], axis = 1) \n","execution_count":null,"outputs":[]},{"metadata":{"id":"opzrVa9wgCDR"},"cell_type":"markdown","source":"-Zaman sütunlarını birleştirip datetime'a çevirdim, sonra diğer sütunları sildim.\n\n-Datetime sütununu index yaptım ."},{"metadata":{"id":"vs6XzwNJfu1l","trusted":true},"cell_type":"code","source":"cols = [\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"]\ndf[\"date_time\"] = df[cols].apply(lambda row: \"-\".join(row.values.astype(str)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"1IVeOPkif2tM","trusted":true},"cell_type":"code","source":"df['date_time'] = pd.to_datetime(df['date_time'], format='%Y-%m-%d-%H-%M')","execution_count":null,"outputs":[]},{"metadata":{"id":"7wAhQipsggb3","trusted":true},"cell_type":"code","source":"df=df.drop([\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"Pmn5PrCjglB-","trusted":true},"cell_type":"code","source":"df=df.set_index('date_time') #Columnu index yapmak için","execution_count":null,"outputs":[]},{"metadata":{"id":"CEeBausA283r"},"cell_type":"markdown","source":"Tahmin etmek istediğim değeri son sütuna alıyorum."},{"metadata":{"id":"t8cu22eEh-sE","outputId":"b69623b4-c01e-47f8-a7a2-7af4173a040b","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"9QvFlNgA3ENt","trusted":true},"cell_type":"code","source":"df1 = df.pop('GHI') # GHI sütununu sil ve df1 içine kaydet.\ndf['GHI']=df1 # GHI  serisini yeni bir sütun olarak sona ekle.\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ApgVMNIsM0Lk"},"cell_type":"markdown","source":"Verisetini LSTM modelinde öğrenilecek şekile getirmek için 3 boyutlu hale getirmem lazım. Tek bir inputta"},{"metadata":{"id":"A6F0SH5XDIfy","trusted":true},"cell_type":"code","source":"# split into days\nfrom numpy import split\nfrom numpy import array\n\n \n# split a univariate dataset into train/test sets\ndef split_dataset(df):\n  train=df[100608:104448]\n\n  test=df[104448:]\n  train = array(split(train, len(train)/4))#günlük bölme yaptığım için 96 aldım.\n  test = array(split(test, len(test)/4))\n  return train, test","execution_count":null,"outputs":[]},{"metadata":{"id":"E7r5RuIbjOql"},"cell_type":"markdown","source":"Keras kütüphanesi ile hazırlanacak neural networklerde inputları numpy array olarak ayırmak zorundayız.\n\nSinir ağları modelleri numpy arrayi olarak işlenir."},{"metadata":{"id":"reFHv0vOEGZO","trusted":true},"cell_type":"code","source":"train, test = split_dataset(df.values)#verisetini yukarıda yazılan fonksiyon içinde ayırdım.","execution_count":null,"outputs":[]},{"metadata":{"id":"TVBTsKzDKiMP"},"cell_type":"markdown","source":"Her bir günde 15 dk'lık 96 ölçüm var.Modeli denerken işlemi hızlandırmak için şimdilik 40 günlük bir öğrenme veri seti oluşturdum.Her bir satırda 13 özellik(feature) var.Bu yüzden modele okutacağımız öğrenme şeklini 40,96,13  olarak oluşturdum.\nTest setini de küçük tutmak adına 1 hafta sonrası olarak aldım.7,96,13"},{"metadata":{"id":"cgAS8wnwGdm9","outputId":"02350ae5-b994-4a9e-b4d6-0ef40d5a9526","trusted":true},"cell_type":"code","source":"print('train shape == {}.'.format(train.shape))\nprint('test shape == {}.'.format(test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-R7vYmRrKTAO"},"cell_type":"markdown","source":"Her bir çıktıya rmse uygulama işlemi."},{"metadata":{"id":"rkx8mUb3EoiQ","trusted":true},"cell_type":"code","source":"def evaluate_forecasts(actual, predicted):\n\tscores = list()\n\t# Her bir gerçek (test) değerini döngüye sokup rmse değerini ölçmek için yazılmıştır.\n\tfor i in range(actual.shape[1]):\n\t\t# calculate mse\n\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n\t\t# calculate rmse\n\t\trmse = sqrt(mse)\n\t\t# store\n\t\tscores.append(rmse)#hepsini score dosyasına kaydet\n\t# calculate overall RMSE\n\ts = 0\n\tfor row in range(actual.shape[0]):\n\t\tfor col in range(actual.shape[1]):\n\t\t\ts += (actual[row, col] - predicted[row, col])**2\n\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n\treturn score, scores","execution_count":null,"outputs":[]},{"metadata":{"id":"RgSqpsoNMQS-","trusted":true},"cell_type":"code","source":"# Skoru (Rmse değerlerini) görselleştirme\ndef summarize_scores(name, score, scores):\n\ts_scores = ', '.join(['%.1f' % s for s in scores])\n\tprint('%s: [%.3f] %s' % (name, score, s_scores))","execution_count":null,"outputs":[]},{"metadata":{"id":"1prdy2Xrh_64"},"cell_type":"markdown","source":"Verisetinde bir trend yakalaması için  uygun timestep(zamanaralığı) değeri ayarlamaya çalıştım.\n\n!!!! BURASINI OPTİMİZE ETMELİYİM!!!!\n\nNe kadar bir zamanı tahmin etmeliyim (96 data=1 gün).\n\nHangi zaman aralığını input hangisini output almalıyım?\nSolar radyasyon verisi sabah 8 akşam 5 aralığında ölçülüyor genelde. Bu saatler dışında radyasyon sıfıra çok yakın . bu yüzden 1 günü traine (X) ve bu günün sabahını outputa koyarsam(y) saçma bir  sonuca ulaşabilirim. "},{"metadata":{"id":"VCebRn8CHrAk","trusted":true},"cell_type":"code","source":"\n# input ve output değerlerini ayarlama\ndef to_supervised(train, n_input, n_out=4):\n\t# flatten data\n\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n\tX, y = list(), list()\n\tin_start = 0\n\t# step over the entire history one time step at a time\n\tfor _ in range(len(data)):\n\t\t# define the end of the input sequence\n\t\tin_end = in_start + n_input\n\t\tout_end = in_end + n_out\n\t\t# ensure we have enough data for this instance\n\t\tif out_end <= len(data):\n\t\t\tX.append(data[in_start:in_end, :])\n\t\t\ty.append(data[in_end:out_end, 0])\n\t\t# move along one time step\n\t\tin_start += 1\n\treturn array(X), array(y)","execution_count":null,"outputs":[]},{"metadata":{"id":"1ffnIOj11LuU"},"cell_type":"markdown","source":"Modeldi hızlandırmak veya iyileştirmek için uygulanabilecek şeyler. \n\n-nöron sayısını değiştirmek\n\n-dropout layerı eklemek\n\n-aktivasyon fonksiyonlarını değiştirmek\n\n-optimizerı değiştirmek.(adam ideal olabilir )"},{"metadata":{"id":"dgw7fRNh16lr"},"cell_type":"markdown","source":"#Eklemem gerek!:\n-Daha sağlıklı bir analiz için model süresi . \nLoss grafiği(gradient descent minimuma yaklaşıyor mu ? )\n-tensorflowda bir model kurmak  durumu hızlandırabilir bunu da denemem lazım .\n#Warning \nSistemin cuDNN e göre çalışmaması modeli yavaşlatıyor sanırım .\n\n-( Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU)"},{"metadata":{"id":"163TvpNTKD_g","trusted":true},"cell_type":"code","source":"# train the model\ndef build_model(train, n_input):\n\n\n\t# prepare data\n\ttrain_x, train_y = to_supervised(train, n_input)\n\t# define parameters\n\tverbose, epochs, batch_size = 1, 50, 16\n  #timesteps bizim belirlediğimiz 96 değeri(1 gün)\n  #feature ,özellik sayısı = 13\n  #çıktı,(n_output) değeri y nin 2. değeri \n\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n\t# reshape output into [samples, timesteps, features]\n\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n\t# define model\n\tmodel = Sequential()\n\tmodel.add(LSTM(128, activation='relu', input_shape=(n_timesteps, n_features))) #giriş değerini 200 nöronla deneme\n\tmodel.add(RepeatVector(n_outputs)) # iki boyutlu girdiyi 3 boyuta çevirme komutu.input_shape=(n_timesteps,n_outputs, n_features)olur\n\tmodel.add(LSTM(128,  activation='relu',return_sequences=True))\n\tmodel.add(TimeDistributed(Dense(64, activation='relu')))#time distribute girdi ve çıktısı 3 D olmalıdır.\n\tmodel.add(TimeDistributed(Dense(1)))\n\n\tmodel.compile(optimizer = Adam(learning_rate=0.01), loss='mean_squared_error')\n\t# fit network\n\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"id":"Gj0uN5MaK_61","trusted":true},"cell_type":"code","source":"def forecast(model, history, n_input):\n\t# flatten data\n\tdata = array(history)\n\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n\t# retrieve last observations for input data\n\tinput_x = data[-n_input:, :]\n\t# reshape into [1, n_input, n]\n\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n\t# forecast the next week\n\tyhat = model.predict(input_x, verbose=0)\n\t# we only want the vector forecast\n\tyhat = yhat[0]\n\treturn yhat\n ","execution_count":null,"outputs":[]},{"metadata":{"id":"8MuEPZrqLHOj","trusted":true},"cell_type":"code","source":"# modeli train üstünde çalıştırıp,test ile karşılaştırmak\ndef evaluate_model(train, test, n_input):\n\t\n\tmodel = build_model(train, n_input)\n\tmodel.history.history.keys()\n\thistory = [x for x in train]\n\tmyloss = model.history.history[\"loss\"]\n\n\tpredictions = list()\n\tfor i in range(len(test)):\n\t\t# Traini tahmin etme ve y headi oluşturma\n\t\tyhat_sequence = forecast(model, history, n_input)\n\t\t# tahminleri kaydetme\n\t\tpredictions.append(yhat_sequence)\n\t\t# get real observation and add to history for predicting the next week\n    #test verilerinin indexe göre dizilişi ve tahmin\n\t\thistory.append(test[i, :])\n\t# evaluate predictions hours for each day\n\tpredictions = array(predictions)\n\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n\treturn score, scores","execution_count":null,"outputs":[]},{"metadata":{"id":"yzXvnerZLd9l","outputId":"eb1b4010-3d18-4f43-a174-4d919a165c01","trusted":true},"cell_type":"code","source":"n_input = 4\nscore, scores = evaluate_model(train, test, n_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summarize_scores('lstm:rmse ortalama', score, scores)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}