{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading the data\ncreditCardData = pd.read_csv(\"../input/ccdata/CC GENERAL.csv\")\n\n#Features and Meaning\n# CUSTID: Identification of Credit Card holder \n# BALANCE: Balance amount left in customer's account to make purchases\n# BALANCE_FREQUENCY: How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n# PURCHASES: Amount of purchases made from account\n# ONEOFFPURCHASES: Maximum purchase amount done in one-go\n# INSTALLMENTS_PURCHASES: Amount of purchase done in installment\n# CASH_ADVANCE: Cash in advance given by the user\n# PURCHASES_FREQUENCY: How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n# ONEOFF_PURCHASES_FREQUENCY: How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n# PURCHASES_INSTALLMENTS_FREQUENCY: How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n# CASH_ADVANCE_FREQUENCY: How frequently the cash in advance being paid\n# CASH_ADVANCE_TRX: Number of Transactions made with \"Cash in Advance\"\n# PURCHASES_TRX: Number of purchase transactions made\n# CREDIT_LIMIT: Limit of Credit Card for user\n# PAYMENTS: Amount of Payment done by user\n# MINIMUM_PAYMENTS: Minimum amount of payments made by user  \n# PRC_FULL_PAYMENT: Percent of full payment paid by user\n# TENURE: Tenure of credit card service for user\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"creditCardData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting some insights from our data\ncreditCardData.info()\n#and we observe some Null data at #MINIMUM_PAYMENTS and #CREDIT_LIMIT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#In case we need more statistical insights let's use .describe()\ncreditCardData.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can get a rough idea of our missing Data using a heatmap\nsns.heatmap(creditCardData.isnull(),yticklabels = False,cbar = False, cmap = \"Blues\",linecolor = \"Black\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#or\ncreditCardData.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's fill the #MINIMUM_PAYMENTS with the mean\ncreditCardData.loc[(creditCardData['MINIMUM_PAYMENTS'].isnull() == True), 'MINIMUM_PAYMENTS'] = creditCardData['MINIMUM_PAYMENTS'].mean()\n#accesed each row of with MINIMUM_PAYMENTS col Null and replaced it with the mean of the column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking again\ncreditCardData.isnull().sum()\n#MINIMUM_PAYMENTS is fixed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's fix credit limit with the same way\ncreditCardData['CREDIT_LIMIT'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"creditCardData.loc[(creditCardData['CREDIT_LIMIT'].isnull() == True), 'CREDIT_LIMIT'] = creditCardData['CREDIT_LIMIT'].mean()\ncreditCardData['CREDIT_LIMIT'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's drop the CUST_ID column because we have no need for it\ncreditCardData.drop(['CUST_ID'],axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see if length changed from 18 to 17\nn = len(creditCardData.columns)\nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Columns Remaining\ncreditCardData.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heatmap with the corellation matrix\nplt.matshow(creditCardData.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize = (20,10))\nsns.heatmap(creditCardData.corr(),annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's Apply Elbow Method to get optimal 'K' for our model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#First let's scale our Data\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale and fit our data\ncreditCardScaled = scaler.fit_transform(creditCardData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"creditCardScaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize the for loop to calculate and store the WCSS for k 1 to 30\nscore = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_val = range(1,30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range_val:\n    model = KMeans(n_clusters = i)\n    model.fit(creditCardScaled)\n    score.append(model.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's plot our WCSS over the range\nplt.figure(figsize= (10,10))\nplt.plot(score,'bx-')\nplt.xticks(np.arange(0,30, step = 1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#as we can see the k before the plot get's linear is 8\n#so our optimal k for our Data is k = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's apply k-means\nmodel = KMeans(8)\nmodel.fit(creditCardScaled)\nlabels = model.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's get each centroid for each feature of each cluster\nmodel.cluster_centers_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_centroids = pd.DataFrame(data = model.cluster_centers_,columns = [creditCardData.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_centroids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's inverse our scaled feature to their initial form\ncluster_centroids = scaler.inverse_transform(cluster_centroids)\ncluster_centroids = pd.DataFrame(data = cluster_centroids,columns = [creditCardData.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_centroids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we can extract certain groups according to our needs\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now let's label our data according to the cluster they belong\nlabels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Also let's set the predictor\ny_model = model.fit_predict(creditCardScaled)\ny_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"creditCardDataLabeled = pd.concat([creditCardData,pd.DataFrame({'cluster':labels})],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"creditCardDataLabeled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Histogram for each cluster\nfor i in creditCardData.columns:\n    plt.figure(figsize = (35,5))\n    for j in range(8):\n        plt.subplot(1,8,j+1)\n        cluster = creditCardDataLabeled[creditCardDataLabeled['cluster'] == j]\n        cluster[i].hist(bins = 20)\n        plt.title('{} \\nCluster {}'.format(i,j))\n        \n    plt.show()    \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's Apply PCA\n#Get principal componets\npca = PCA(n_components = 2)\nprincipal_comp = pca.fit_transform(creditCardScaled)\nprincipal_comp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_dataframe = pd.DataFrame(data = principal_comp,columns = ['component_1','component_2'])\npca_dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concat Label with pca\npca_dataframe = pd.concat([pca_dataframe,pd.DataFrame({'cluster':labels})],axis = 1)\npca_dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's finally plot the clusters\nplt.figure(figsize=(10,10))\nax = sns.scatterplot(x = \"component_1\", y = \"component_2\", hue = \"cluster\",data = pca_dataframe, palette = ['green','red','pink','blue','gray','yellow','black','purple'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the_end","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}