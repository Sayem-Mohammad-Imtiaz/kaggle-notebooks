{"cells":[{"metadata":{"id":"6X8A-SDW0W2X","trusted":true},"cell_type":"code","source":"#from google.colab import files\n#uploaded = files.upload() \n#Please select file location","execution_count":null,"outputs":[]},{"metadata":{"id":"n5ka4SsKkGe5"},"cell_type":"markdown","source":"#**Data** **Preprocessing**","execution_count":null},{"metadata":{"id":"Q-acVsSPz7WR","outputId":"df11cd9d-b4d4-4ddf-9ec6-857b7128ccf6","trusted":true},"cell_type":"code","source":"#import statements\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve, KFold, StratifiedShuffleSplit\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\nimport random\nfrom sklearn.svm import SVC\nimport sklearn.metrics as sk\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import recall_score,auc, roc_auc_score, roc_curve,confusion_matrix,classification_report","execution_count":null,"outputs":[]},{"metadata":{"id":"8BA8YEtm7jBG","outputId":"8af522d4-46f4-41ec-da95-54ec31712f6d","trusted":true},"cell_type":"code","source":"#change the dataset location\ndf = pd.read_csv('/kaggle/input/bank-marketing/bank-additional-full.csv', sep = ';')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"STEMeQrf0sPb","outputId":"a7401532-8e65-4b95-c744-a2e7ad8be13b","trusted":true},"cell_type":"code","source":"#viewing data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"SKWVMRHz0uNQ","outputId":"76a72212-6f9f-4631-89f0-308dbb4ae6b1","trusted":true},"cell_type":"code","source":"#data info\ndf.info()\n#No null values in the data","execution_count":null,"outputs":[]},{"metadata":{"id":"foXImJEPUEky","outputId":"f881e111-aab1-430a-c6a7-a9b8d20b96ae","trusted":true},"cell_type":"code","source":"#Removing non-relevant variables\ndf1=df.drop(columns=['day_of_week','month','contact','poutcome'],axis=1)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"outputId":"bb1b1680-eb14-4341-e743-51a6fbe3d019","id":"be-AehEwc42c","trusted":true},"cell_type":"code","source":"#Replacing all the binary variables to 0 and 1\ndf1.y.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.default.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.housing.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1.loan.replace(('yes', 'no'), (1, 0), inplace=True)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"id":"gbHut2dZcB-z","outputId":"a3869d06-027e-42a4-eeaf-5d74ebd594a8","trusted":true},"cell_type":"code","source":"#creating Dummies for categorical variables\ndf2 = pd.get_dummies(df1)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"eS3kDX710wSt","outputId":"d0212d06-f807-4351-f8fb-ddedd1140a94","trusted":true},"cell_type":"code","source":"#Removing extra dummy variables & checking descriptive stats\ndf3=df2.drop(columns=['job_unknown','marital_divorced','education_unknown'],axis=1)\ndf3.describe().T","execution_count":null,"outputs":[]},{"metadata":{"id":"4TWrAOMtdaoT","outputId":"0a1b8110-2162-4195-da15-89dbd26d2068","trusted":true},"cell_type":"code","source":"#Correlation plot\nplt.figure(figsize=(14,8))\ndf3.corr()['y'].sort_values(ascending = False).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"id":"brHw-bqF8tgf","trusted":true},"cell_type":"code","source":"#Creating binary classification target variable\ndf_target=df3[['y']].values\ndf_features=df3.drop(columns=['y'],axis=1).values\nx1_train, x1_test, y1_train, y1_test = train_test_split(df_features, df_target, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"uSiofyyZergw","trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nx1_train = sc.fit_transform(x1_train)\nx1_test = sc.transform(x1_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"kUATU0-TDZnr"},"cell_type":"markdown","source":"#Define Functions","execution_count":null},{"metadata":{"id":"31Fc43QFDZPV","trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix\ndef confusionmat(y,y_hat):\n  from sklearn.metrics import confusion_matrix,accuracy_score\n  cm = confusion_matrix(y, y_hat)\n  accu=accuracy_score(y,y_hat)\n  print(cm,\"\\n\")\n  print(\"The accuracy is\",accu)","execution_count":null,"outputs":[]},{"metadata":{"id":"jqYunq_2DYVH","trusted":true},"cell_type":"code","source":"#Accuracy and Loss Curves\ndef learningcurve(history):\n  # list all data in history\n  print(history.history.keys())\n  # summarize history for accuracy\n  plt.plot(history.history['accuracy'])\n  plt.plot(history.history['val_accuracy'])\n  plt.title('model accuracy')\n  plt.ylabel('accuracy')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()\n  # summarize history for loss\n  plt.plot(history.history['loss'])\n  plt.plot(history.history['val_loss'])\n  plt.title('model loss')\n  plt.ylabel('loss')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"shXK-7UOOCt-","trusted":true},"cell_type":"code","source":"  # Applying k-Fold Cross Validation\n  from sklearn.model_selection import cross_val_score\n  def kfold(x1,y1):\n    return cross_val_score(estimator = classifier, X = x1, y = y1, cv = 10)","execution_count":null,"outputs":[]},{"metadata":{"id":"xecjPpMePmj8","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import learning_curve\ndef knn_learningcurve(c, df_features, df_target):\n  train_sizes, train_scores, test_scores = learning_curve(c, df_features, df_target,cv=10,n_jobs=-1)\n  train_scores_mean = np.mean(train_scores, axis=1)\n  train_scores_std = np.std(train_scores, axis=1)\n  test_scores_mean = np.mean(test_scores, axis=1)\n  test_scores_std = np.std(test_scores, axis=1)\n\n  plt.figure()\n  plt.title(\"KNNClassifier\")\n  plt.legend(loc=\"best\")\n  plt.xlabel(\"Training examples\")\n  plt.ylabel(\"Score\")\n\n  plt.grid()\n\n  plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                      train_scores_mean + train_scores_std, alpha=0.1,\n                      color=\"r\")\n  plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n  plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n              label=\"Training score\")\n  plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n              label=\"Cross-validation score\")\n\n  plt.legend(loc=\"best\")\n  # sizes the window for readability and displays the plot\n  # shows error from 0 to 1.1\n  plt.ylim(-.1,1.1)\n  plt.show","execution_count":null,"outputs":[]},{"metadata":{"id":"OcLegBljUnBU","trusted":true},"cell_type":"code","source":"#Roc Curve\ndef roc_auc(yTest,y_pred):\n    sns.set()\n    fpr, tpr, thresholds = roc_curve(yTest, y_pred)\n    roc_auc = auc(fpr,tpr)\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, 'b',label='AUC = %0.3f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')\n    plt.xlim([-0.1,1.0])\n    plt.ylim([-0.1,1.01])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Zo4hRIF02i9d"},"cell_type":"markdown","source":"#Artificial Neural Network","execution_count":null},{"metadata":{"id":"SEeWEssGC4p4"},"cell_type":"markdown","source":"##Experimenting with Number of Epoch","execution_count":null},{"metadata":{"id":"ED2BzNfQ2mxZ","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(16,activation=\"relu\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(32,activation=\"relu\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nepoch=[100,250,500]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"TU1oM_Gf45_d","outputId":"28a43bd6-782e-475a-cb12-e6dfab504f8c","trusted":true},"cell_type":"code","source":"for e in epoch:\n  # Fitting the ANN to the Training set\n  history=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=e,validation_split=0.3)\n  # Predicting the Test set results\n  y_pred = classifier.predict_classes(x1_test)\n  pre_score = sk.average_precision_score(y1_test, y_pred)\n  classifier.summary()\n  test_results = classifier.evaluate(x1_test, y1_test)\n  print(\"For epoch = {0}, the model test accuracy is {1}.\".format(e,test_results[1]))\n  print(\"The model test average precision score is {}.\".format(pre_score))\n  confusionmat(y1_test,y_pred)\n  learningcurve(history)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"QHmgVVMaDFVL"},"cell_type":"markdown","source":"##Experimenting with Number of Layers","execution_count":null},{"metadata":{"id":"NxqQ5W-ZPxoF","outputId":"9726bb78-c6f9-4ffa-9f6b-ec1daa9604d0","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(16,activation=\"relu\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"B6tsTBCdP7qN","outputId":"87476829-b0e4-4567-ae35-7088d363d932","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(16,activation=\"relu\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(32,activation=\"relu\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"XzvLI3YyP8tX","outputId":"1f1fd4ae-8576-4d58-cd84-72d12785b293","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(16,activation=\"relu\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(32,activation=\"relu\"))\n\n# Adding the third hidden layer\nclassifier.add(Dense(32,activation=\"relu\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"E1GKsTiMDFGw"},"cell_type":"markdown","source":"##Experimenting with Number of Nodes","execution_count":null},{"metadata":{"id":"wV4SjBNlQHFe","outputId":"cb3a0ff8-8fae-4d44-de4a-c47a86f8eccd","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(16,activation=\"relu\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"relu\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"igbgVc7rQLsv","outputId":"e95534cf-c143-473a-b284-d7c0cfbb605e","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"relu\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"relu\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"fyANw9ezQQtv","outputId":"75f79673-1e85-45b2-80c3-29f1c47d6aa2","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"relu\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(32,activation=\"relu\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"rySqRx5kDEyB"},"cell_type":"markdown","source":"##Experimenting with Activation Function","execution_count":null},{"metadata":{"id":"McsCw0sYQZ9P","outputId":"4681e180-0250-4d02-a6b6-04bd44e8358f","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"tanh\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"tanh\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"wW1IztkoRB53","outputId":"33854f02-3dbb-4dbb-d4ad-32d2712c8cdb","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"sigmoid\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"sigmoid\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"B3emtus1QxlV","outputId":"20841780-b324-4653-83f7-74b0b5105c64","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"softmax\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"softmax\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(100,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"rErOXtz1pYB5"},"cell_type":"markdown","source":"#Final ANN","execution_count":null},{"metadata":{"id":"mbT789HKpW8g","trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(32,activation=\"softmax\"))\n\n# Adding the second hidden layer\nclassifier.add(Dense(16,activation=\"softmax\"))\n\n# Adding the output layer\nclassifier.add(Dense(1,activation=\"sigmoid\"))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nhistory=classifier.fit(x1_train, y1_train, batch_size = 10, epochs=100,validation_split=0.3)\n# Predicting the Test set results\ny_pred = classifier.predict_classes(x1_test)\npre_score = sk.average_precision_score(y1_test, y_pred)\nclassifier.summary()\ntest_results = classifier.evaluate(x1_test, y1_test)\nprint(\"For epoch = {0}, the model test accuracy is {1}.\".format(e,test_results[1]))\nprint(\"The model test average precision score is {}.\".format(pre_score))\nconfusionmat(y1_test,y_pred)\nlearningcurve(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"R3iPJoWWUVsd"},"cell_type":"markdown","source":"#K-Nearest Neighbor","execution_count":null},{"metadata":{"id":"WdkziMsBFLoc"},"cell_type":"markdown","source":"##Experiment with Number of Neighbors","execution_count":null},{"metadata":{"id":"6Setp7xpUad3","outputId":"0403d2a0-63bf-4a06-e4f4-9e94bd52b565","trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nk_list=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\naccu_KNN=[]\nfor i in k_list:\n  # Fitting K-NN to the Training set\n  classifier = KNeighborsClassifier(n_neighbors = i)\n  history=classifier.fit(x1_train, y1_train)\n\n  # Predicting the Test set results\n  y_pred = classifier.predict(x1_test)\n\n  # 10 fold cross validation\n  accuracies = kfold(x1_train, y1_train)\n\n  accu_KNN+=[accuracies.mean()]\n  std=accuracies.std()\n  report=sk.classification_report(y1_test,y_pred)\n  confusionmat(y1_test, y_pred)\n\n  print(\"KNN with n= \",i)\n  print(\"The Classification report\\n\",report,end='\\n')\n  print(\"The Accuracy score with only 1 Training and Testing Data Set\\n\",sk.accuracy_score(y1_test,y_pred)*100,end='\\n')\n  #after using cross validation with 10 folds\n  print(\"The mean of the accuracy scores with using 10 fold-cross validation\\n\",accuracies.mean()*100,end='\\n')\n  print(\"The Standard Deviation of the accuracy scores with using 10 fold-cross validation\\n\",std*100,end='\\n')\n\n  knn_learningcurve(classifier, df_features, df_target)","execution_count":null,"outputs":[]},{"metadata":{"id":"x2LAB8n9YFk7","outputId":"3ae73bfc-8ab8-46ad-b56c-6cc98959138d","trusted":true},"cell_type":"code","source":"plt.plot(k_list,accu_KNN)\nplt.xlabel(\"k number\")\nplt.ylabel(\"Accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"R37TtaqeFVik"},"cell_type":"markdown","source":"##Experiment with Distance Metric","execution_count":null},{"metadata":{"id":"GKLeBeBkRNd_","outputId":"8656ecab-ce45-4c49-a127-0ca3d5a7d986","trusted":true},"cell_type":"code","source":"# Fitting K-NN to the Training set\nclassifier = KNeighborsClassifier(n_neighbors = 9,metric=\"manhattan\")\nhistory=classifier.fit(x1_train, y1_train)\n# Predicting the Test set results\ny_pred = classifier.predict(x1_test)\n\n# 10 fold cross validation\naccuracies = kfold(x1_train, y1_train)\naccu_KNN=accuracies.mean()\nstd=accuracies.std()\nreport=sk.classification_report(y1_test,y_pred)\nconfusionmat(y1_test, y_pred)\n\nprint(\"KNN with n= \",9)\nprint(\"The Classification report\\n\",report,end='\\n')\nprint(\"The Accuracy score with only 1 Training and Testing Data Set\\n\",sk.accuracy_score(y1_test,y_pred)*100,end='\\n')\n\nknn_learningcurve(classifier, df_features, df_target)","execution_count":null,"outputs":[]},{"metadata":{"id":"megfjZZnRUhJ","outputId":"9c0f58d0-bdbc-4b78-b4a3-534bc0207e0a","trusted":true},"cell_type":"code","source":"# Fitting K-NN to the Training set\nclassifier = KNeighborsClassifier(n_neighbors = 9,metric=\"chebyshev\")\nhistory=classifier.fit(x1_train, y1_train)\n# Predicting the Test set results\ny_pred = classifier.predict(x1_test)\n\n# 10 fold cross validation\naccuracies = kfold(x1_train, y1_train)\naccu_KNN=accuracies.mean()\nstd=accuracies.std()\nreport=sk.classification_report(y1_test,y_pred)\nconfusionmat(y1_test, y_pred)\n\nprint(\"KNN with n= \",9)\nprint(\"The Classification report\\n\",report,end='\\n')\nprint(\"The Accuracy score with only 1 Training and Testing Data Set\\n\",sk.accuracy_score(y1_test,y_pred)*100,end='\\n')\n#after using cross validation with 10 folds\nprint(\"The mean of the accuracy scores with using 10 fold-cross validation\\n\",accuracies.mean()*100,end='\\n')\nprint(\"The Standard Deviation of the accuracy scores with using 10 fold-cross validation\\n\",std*100,end='\\n')\n\nknn_learningcurve(classifier, df_features, df_target)","execution_count":null,"outputs":[]},{"metadata":{"id":"dPphPlVO0y4x","outputId":"e2a93941-b54c-47a5-e719-012c921574dd","trusted":true},"cell_type":"code","source":"# Fitting K-NN to the Training set\nclassifier = KNeighborsClassifier(n_neighbors = 9,metric=\"euclidean\")\nhistory=classifier.fit(x1_train, y1_train)\n# Predicting the Test set results\ny_pred = classifier.predict(x1_test)\n\n# 10 fold cross validation\naccuracies = kfold(x1_train, y1_train)\naccu_KNN=accuracies.mean()\nstd=accuracies.std()\nreport=sk.classification_report(y1_test,y_pred)\nconfusionmat(y1_test, y_pred)\n\nprint(\"KNN with n= \",9)\nprint(\"The Classification report\\n\",report,end='\\n')\nprint(\"The Accuracy score with only 1 Training and Testing Data Set\\n\",sk.accuracy_score(y1_test,y_pred)*100,end='\\n')\n#after using cross validation with 10 folds\nprint(\"The mean of the accuracy scores with using 10 fold-cross validation\\n\",accuracies.mean()*100,end='\\n')\nprint(\"The Standard Deviation of the accuracy scores with using 10 fold-cross validation\\n\",std*100,end='\\n')\n\nknn_learningcurve(classifier, df_features, df_target)","execution_count":null,"outputs":[]},{"metadata":{"id":"xMnkX_ajVpeG"},"cell_type":"markdown","source":"#Final K-NN","execution_count":null},{"metadata":{"id":"RytfQs-YYxOQ","outputId":"c0200b9e-7e8f-4e9c-d29a-04886bf84b45","trusted":true},"cell_type":"code","source":"# Fitting K-NN to the Training set\nclassifier = KNeighborsClassifier(n_neighbors = 9,metric=\"manhattan\")\nhistory=classifier.fit(x1_train, y1_train)\n# Predicting the Test set results\ny_pred = classifier.predict(x1_test)\n\nreport=sk.classification_report(y1_test,y_pred)\nconfusionmat(y1_test, y_pred)\n\nprint(\"KNN with n= \",9)\nprint(\"The Classification report\\n\",report,end='\\n')\nprint(\"The Accuracy score with only 1 Training and Testing Data Set\\n\",sk.accuracy_score(y1_test,y_pred)*100,end='\\n')\nknn_learningcurve(classifier, df_features, df_target)","execution_count":null,"outputs":[]},{"metadata":{"id":"98xQDwnBSPgT","outputId":"415bc275-6de3-4b8d-da2b-edd9929bc47b","trusted":true},"cell_type":"code","source":"roc_auc(y1_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"id":"QjE73rfag479"},"cell_type":"markdown","source":"#Comparisons","execution_count":null},{"metadata":{"id":"5RkWvVouVGpx","outputId":"4cf56804-3543-45d7-d215-16a965274070","trusted":true},"cell_type":"code","source":"distance_list=['euclidean','manhattan','chebyshev']\nAccuracy_test=[88.5137,88.5800,88.4031]\n \nd1=pd.DataFrame(list(zip(distance_list,Accuracy_test)),columns=['distance_list','Accuracy'])\nprint(d1)\n\n# this is for plotting purpose\nindex = np.arange(len(distance_list))\nplt.bar(distance_list, Accuracy_test,  width=0.3)\nplt.xlabel('Distance metric')\nplt.ylabel('Accuracy')\nplt.title('Comparison')\nplt.figure(figsize=(2,2))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"znU27J_nWhRO","outputId":"a193aead-3969-46b6-fd61-d5c0b2328beb","trusted":true},"cell_type":"code","source":"# knn and nn\ndistance_list=['Neual Network','KNN']\nAccuracy_test=[88.9265,88.5800]\n \nd1=pd.DataFrame(list(zip(distance_list,Accuracy_test)),columns=['Algorithm','Accuracy'])\nprint(d1)\n\n# this is for plotting purpose\nindex = np.arange(len(distance_list))\nplt.bar(distance_list, Accuracy_test,  width=0.3)\nplt.xlabel('Algorithms')\nplt.ylabel('Accuracy')\nplt.title('Comparison')\nplt.figure(figsize=(1,1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"UiwpICovhIAq","outputId":"58afd56a-abfe-4b28-e4a3-047b3805ccdc","trusted":true},"cell_type":"code","source":"# comparison between svm  knn nn decision trees ensemble\n\nAlgorithms=['SVM-rbf','Decision Trees','Boosting','Neural Networks','KNN-Manhattan']\nAccuracy_test=[88.78,85.29,89.52,88.93,88.58]\n \nd1=pd.DataFrame(list(zip(Algorithms,Accuracy_test)),columns=['Algorithms','Accuracy'])\nprint(d1)\n\n# this is for plotting purpose\nplt.bar(Algorithms, Accuracy_test, width=0.3)\nplt.xlabel('Algorithms')\nplt.tick_params(axis='x', rotation=60)\nplt.ylabel('Accuracy')\nplt.title('Comparison')\nplt.figure(figsize=(2,2))\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}