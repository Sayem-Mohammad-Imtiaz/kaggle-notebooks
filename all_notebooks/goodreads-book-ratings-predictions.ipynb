{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Goodreads Book Ratings Predictions\n![GoodReads](https://s.gr-assets.com/assets/facebook/goodreads_wide-e23f6858b6bf20dcaf8493237a214a0e.png)\n\n### Content\n1. Exploring Data.\n2. Analyze Data through visualizations.\n3. Data Preparation e.g.: [Ordinal Encoding, Handling Missing Values].\n4. Feature Engineering.\n5. Building Multiple Machine Learning Models.\n6. Compare models accuracy on training data.\n7. Make predictions using each model.\n8. Compare models accuracy on test data.\n9. Compare training VS test score for each model","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing and Exploring Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/goodreadsbooks/books.csv', error_bad_lines=False)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe() # Generate the summary table of the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes # Check the data types of all columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum() # Check if there's any missing value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Cleaning & Feature Engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nencoding = {'language_code':{'en-US': 'eng', 'en-GB': 'eng', 'en-CA': 'eng'}} # Unify the langauge codes\ndf.replace(encoding, inplace=True)\n\nenc = OrdinalEncoder()\nenc.fit(df[['language_code']])\ndf[['language_code']] = enc.fit_transform(df[['language_code']]) # Apply ordinal encoding on language_code to convert it into numerical column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['publication_date'] = pd.to_datetime(df['publication_date'], format='%m/%d/%Y', errors='coerce') # Convert data type of publication_date from object into date type\ndf[df['publication_date'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Since there are only 2 books with courrpted dates, I googled these 2 books to get the publication dates and put them manually","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.bookID == 31373, 'publication_date'] = '1999-10-01 00:00:00'\ndf.loc[df.bookID == 45531, 'publication_date'] = '1975-10-01 00:00:00'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year'] = pd.DatetimeIndex(df['publication_date']).year # Extract year of publication in a separate column\n\ndf.rename(columns = {'  num_pages': 'num_pages'}, inplace=True) # Rename the column to remove leading whitespaces","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['num_occ'] = df.groupby('title')['title'].transform('count') # Add a new feature which has the number of occurences of each book","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Calculating New Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['rate_occ'] = df['average_rating'] * df['num_occ']\ndf['rate_weight'] = df['average_rating'] * df['text_reviews_count']\ndf['rate_weight_2'] = df['average_rating'] * df['ratings_count']\ndf['rate_per_pages'] = df['average_rating'] * df['num_pages']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Analysis & Visualizations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(26, 10)\ncorr = df.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"num_occ\", y=\"average_rating\", data=df, height=7, aspect = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The upper visual says that any book appeared more than once has a good/high rate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(26, 10)\nsns.lineplot(x=\"year\", y=\"average_rating\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"language_code\", y=\"average_rating\", data=df, height=9, aspect = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"text_reviews_count\", y=\"average_rating\", data=df, height=9, aspect = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"num_pages\", y=\"average_rating\", data=df, height=9, aspect = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(26, 10)\nsns.lineplot(x=\"year\", y=\"text_reviews_count\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see from the visual above that starting from the 80s, the rate/number of reviews is getting higher than before, We can say that this's the effect of the computer & internet","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5. Creating Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"label = df['average_rating'].values\ndf.drop(['bookID', 'title', 'authors', 'isbn', 'isbn13', 'publication_date', 'publisher', 'average_rating'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the Data into 70% - 30%\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df, label, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4))\n\nparameters = {\n    'learning_rate': [0.001, 0.01, 0.02, 0.1, 0.2, 1.0],\n    'n_estimators': [10, 50, 100, 200]\n}\n\ngrad_Ada = GridSearchCV(model, parameters, refit=True)\ngrad_Ada.fit(X_train, y_train)\n\nprint('Best Score: ', grad_Ada.best_score_*100, '\\nBest Parameters: ', grad_Ada.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\n\nmodel  = LinearRegression()\n\nparameters = {\n    'fit_intercept': [True, False],\n    'normalize': [True, False],\n    \n}\n\ngrad_Linear = GridSearchCV(model, parameters, refit=True)\ngrad_Linear.fit(X_train, y_train)\n\nprint('Best Score: ', grad_Linear.best_score_*100, '\\nBest Parameters: ', grad_Linear.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nmodel = Ridge()\n\nparameters = {\n    'fit_intercept': [True, False],\n    'normalize': [True, False],\n    'max_iter': [1000, 100, 10000],\n    'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n}\n\ngrad_ridge = GridSearchCV(model, parameters, refit=True)\ngrad_ridge.fit(X_train, y_train)\n\nprint('Best Score: ', grad_ridge.best_score_*100, '\\nBest Parameters: ', grad_ridge.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor()\n\nparameters = {\n    'n_estimators': [50, 100, 150, 200],\n    'max_depth': [3, 5, 7, 10, 12, 15],\n    'min_samples_split': [5, 10, 15],\n    'min_samples_leaf': [5, 10, 15]\n}\n\ngrad_rf = GridSearchCV(model, parameters, refit=True, cv=10)\ngrad_rf.fit(X_train, y_train)\n\nprint('Best Score: ', grad_rf.best_score_*100, '\\nBest Parameters: ', grad_rf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = []\nl.append(('AdaBoost', grad_Ada.best_score_*100))\nl.append(('Linear Regression', grad_Linear.best_score_*100))\nl.append(('Ridge Regression', grad_ridge.best_score_*100))\nl.append(('Random Forest', grad_rf.best_score_*100))\nscores = pd.DataFrame(l, columns =['Model', 'Train Score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Make Predictions using the 4 Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_squared_error, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoost Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# AdaBoost Model\npred_adaboost = grad_Ada.predict(X_test)\n\n# Check Model Score\nprint(\"Residual sum of squares: \",  np.mean((pred_adaboost - y_test) ** 2))\nprint('RMSE: '+str(np.sqrt(mean_squared_error(y_test, pred_adaboost))))\nprint('Model Score on Test Data: ', grad_Ada.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Features Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from eli5.sklearn import PermutationImportance\nimport eli5\nperm = PermutationImportance(grad_Ada.best_estimator_, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,10))\nsns.regplot(pred_adaboost, y_test, marker=\"+\", line_kws={'color':'darkred','alpha':1.0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression Model\npred_lr = grad_Linear.predict(X_test)\n\n# Check Model Score\nprint(\"Residual sum of squares: \",  np.mean((pred_lr - y_test) ** 2))\nprint('RMSE: '+str(np.sqrt(mean_squared_error(y_test, pred_lr))))\nprint('Model Score on Test Data: ', grad_Linear.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Features Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(grad_Linear.best_estimator_, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,10))\nsns.regplot(pred_lr, y_test, marker=\"+\", line_kws={'color':'darkred','alpha':1.0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ridge Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge Regression Model\npred_ridge = grad_ridge.predict(X_test)\n\n# Check Model Score\nprint(\"Residual sum of squares: \",  np.mean((pred_ridge - y_test) ** 2))\nprint('RMSE: '+str(np.sqrt(mean_squared_error(y_test, pred_ridge))))\nprint('Model Score on Test Data: ', grad_ridge.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Features Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(grad_ridge.best_estimator_, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,10))\nsns.regplot(pred_ridge,y_test, marker=\"+\", line_kws={'color':'darkred','alpha':1.0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Model\npred_rf = grad_rf.predict(X_test)\n\n# Check Model Score\nprint(\"Residual sum of squares: \",  np.mean((pred_rf - y_test) ** 2))\nprint('RMSE: '+str(np.sqrt(mean_squared_error(y_test, pred_rf))))\nprint('Model Score on Test Data: ', grad_rf.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Features Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(grad_ridge.best_estimator_, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,10))\nsns.regplot(pred_rf,y_test, marker=\"+\", line_kws={'color':'darkred','alpha':1.0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l2 = []\nl2.append(('AdaBoost', grad_Ada.score(X_test, y_test)*100))\nl2.append(('Linear Regression', grad_Linear.score(X_test, y_test)*100))\nl2.append(('Ridge Regression', grad_ridge.score(X_test, y_test)*100))\nl2.append(('Random Forest', grad_rf.score(X_test, y_test)*100))\n\ntest_scores = pd.DataFrame(l2, columns =['Model', 'Test Score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores['Test Score'] = test_scores['Test Score']\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}