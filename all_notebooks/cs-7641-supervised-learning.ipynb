{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport math as mt\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\n# Classifiers\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Util Func's\ndef get_map(series):\n    _map = {}\n    for i, col in enumerate(series.unique()):\n        _map[col] = i\n    return _map\n\n@ignore_warnings(category=ConvergenceWarning)\ndef simulate(models, xTrain, yTrain, xTest, yTest):\n    errors = []\n    for model in models:\n        results = cross_validate(model, xTrain, yTrain, cv=3)\n        scores = results['test_score']\n        errors.append((1-(sum(scores)/len(scores)))*100.)\n    return errors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Introduction** #\nSupervised learning gives us an opportunity to apply mapping functions to training data in order tomake predictions.  These predictions can help much larger artificial intelligent systems make betterdecisions.  There are several models that can be used to make predictions.  We will be introduced tofive different machine learning models: kNN, Neural Network, Decision Tree, Boosting and SVC. We will experiment and examine the effectiveness of each model for two different classification problems."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Load Mushroom Data\nshroom_data = pd.read_csv('../input/mushroom-classification/mushrooms.csv')\n# Load NASA Datta\nnasa_data = pd.read_csv('../input/nasa-asteroids-classification/nasa.csv')\n\n# Data Preparation\nfor col in shroom_data.columns:\n    shroom_data[col] = shroom_data[col].map(get_map(shroom_data[col]))    \nfor col in ['Hazardous']:\n    nasa_data[col] = nasa_data[col].map(get_map(nasa_data[col]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Extraction** #\nFor the purpose of this project we will be doing a random 20/80 test to train split on our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shroom Data Split\nsplit = .20\ntest_sz = mt.ceil(len(shroom_data)*split)\ntrain_sz = mt.floor(len(shroom_data)*(1-split))\nshroom_train, shroom_test = train_test_split(shroom_data, train_size=train_sz, test_size=test_sz)\n\n# Nasa Data Split\ntest_sz = mt.ceil(len(nasa_data)*split)\ntrain_sz = mt.floor(len(nasa_data)*(1-split))\nnasa_train, nasa_test = train_test_split(nasa_data, train_size=train_sz, test_size=test_sz)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Extraction** #\nWe will use some manual data mining and educational guessing to figure out which features will produce the best results."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection\nnasa_ftrs = ['Absolute Magnitude', 'Est Dia in Miles(min)', 'Est Dia in Miles(max)', 'Miles per hour', 'Miss Dist.(miles)', 'Orbit Uncertainity', 'Minimum Orbit Intersection', 'Absolute Magnitude', 'Orbit Uncertainity', 'Minimum Orbit Intersection', 'Jupiter Tisserand Invariant', 'Epoch Osculation', 'Eccentricity', 'Semi Major Axis', 'Inclination',\n       'Asc Node Longitude', 'Orbital Period', 'Perihelion Distance', 'Perihelion Arg', 'Aphelion Dist', 'Perihelion Time', 'Mean Anomaly', 'Mean Motion']\nshroom_ftrs = ['cap-shape','cap-color','gill-size','gill-color', 'veil-type', 'veil-color', 'population']\n\n# Feature Extraction\nshroom_xTrain = shroom_train.copy()\nshroom_xTest  = shroom_test.copy()\nnasa_xTrain = nasa_train.copy()\nnasa_xTest  = nasa_test.copy()\n\nshroom_xTrain = shroom_xTrain[shroom_ftrs] / shroom_xTrain[shroom_ftrs].max().replace(to_replace=0, method='ffill')\nshroom_yTrain = shroom_train['class']\nshroom_xTest  = shroom_xTest[shroom_ftrs] / shroom_xTest[shroom_ftrs].max().replace(to_replace=0, method='ffill')\nshroom_yTest  = shroom_test['class']\n\nnasa_xTrain = nasa_xTrain[nasa_ftrs] / nasa_xTrain[nasa_ftrs].max()\nnasa_yTrain = nasa_train['Hazardous']\nnasa_xTest  = nasa_xTest[nasa_ftrs] / nasa_xTest[nasa_ftrs].max()\nnasa_yTest  = nasa_test['Hazardous']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Problem 1: Hazardous Asteroid Classification** #\n**Description**\n\nEveryone understands the potential impact asteroids can have on the planet.  After wiping out anentire species and reshaping our planet, we know they can be life threatening to anyone in the world.However, not all asteroids come in the same shape or size and identifying which are hazardous is veryimportant.  Machine learning algorithms can help with this type of classification problem.  UtilizingNASA’s Near Earth Object Web Service, an open API used to query asteroid information, we canapply machine learning models to classify hazardous asteroids\n\n**Results**\n\nBelow, we describe the initial results of our models.  Each model is from the ’sklearn’ library.  Weused each model’s default settings as the initial results.  These default values are:\n* DecisionTreeClassifier - Criterion=Entropy, Splitter=Best, MaxFeatuures=None, MaxNodes=None\n* MLPClassifier - HiddenLayers=100, ActivationFunction=Relu, Solver=adam, Alpha=0.0001, LearningRate=Constant(0.001), MaxIterations=100 beta1=0.9, beta2=0.999, epsilon=1e-8\n* SVC - kernel=rbf, degree=3, gamma= 1/(n\\_features * X.var())\n* KNeighborsClassifier - N-Neighbors=5, Weights=uniform\n* RandomForestClassifier - Criterion=Entropy, MaxFeature=auto, MaxLeafNodes=None, TreeCount=100"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"nasa_models = [ DecisionTreeClassifier(criterion='entropy'), MLPClassifier(max_iter=100), SVC(), KNeighborsClassifier(), RandomForestClassifier(criterion='entropy') ]\nbaselineMap = {}\n\n# Nasa Models\nbaselineMap['NASA'] = simulate(nasa_models, nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest)\n\nnasa_df = pd.DataFrame(baselineMap['NASA'], columns=['NASA'], index=['Decision Tree', 'Neural Network', 'SVC', 'KNN', 'Boosting'])\nnasa_baseline_chart = nasa_df.plot.bar(rot=0, title='Model Baseline Error', xlabel='Models', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(baselineMap['NASA'], columns=['NASA'], index=['Decision Tree', 'Neural Network', 'SVC', 'KNN', 'Boosting'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Analysis** #\n\nFor the analysis, we will experiment with a variety of model configurations and analyze their effects on error.  Ideally, we would like to find the best combination of configurations which produces the ’best’ results.  Best in the context of the Asteroid Classification problem will be maximizing the average test score from a cross validation with three folds."},{"metadata":{},"cell_type":"markdown","source":"**DecisionTree Experiments:**\n\nFor the Decision Tree analysis, we experimented with three different configuration settings:  Criterion, Max Features and Splitter Algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_experiments = {\n    'MaxFeatures' : [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ]\n  , 'MaxLeafNodes' : [ 10, 25, 50, 100, 150, 200, 400, 500, 1000, 1500, 2000]\n}\n\ndef generate_DT_test_models():\n    experiment_models = { 'Criterion' : [ DecisionTreeClassifier(criterion='gini')  ], 'MaxFeatures'  : [ ]\n                        , 'Splitter'  : [ DecisionTreeClassifier(splitter='random') ], 'MaxLeafNodes' : [ ] }\n    experiment_results = { 'Criterion' : [ ], 'MaxFeatures' : [ ], 'Splitter' : [ ], 'MaxLeafNodes' : [ ] }\n    \n    for key in dt_experiments.keys():\n        for setting in dt_experiments[key]:\n            if ('MaxFeatures' == key):\n                experiment_models[key].append(DecisionTreeClassifier(max_features=setting))\n            elif ('MaxLeafNodes' == key):\n                experiment_models[key].append(DecisionTreeClassifier(max_leaf_nodes=setting))\n    \n    return experiment_models, experiment_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nasa Models\nall_models, experiment_results = generate_DT_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest))\n\n# Criterion: Entropy v Gini\ndata = [ baselineMap['NASA'][0], experiment_results['Criterion'][0][0] ]\ndf = pd.DataFrame(data, columns=['NASA'], index=['Entropy', 'Gini'])\nchart = df.plot.bar(rot=0, title='Entropy v Gini', xlabel='Criterion', ylabel='Percent Error')\n\n# Splitter: Best v Random\ndata = [ baselineMap['NASA'][0], experiment_results['Splitter'][0][0] ]\ndf = pd.DataFrame(data, columns=['NASA'], index=['Best', 'Random'])\nchart = df.plot.bar(rot=0, title='Best v Random', xlabel='Splitter', ylabel='Percent Error')\n\n# Effects of Max Features\ndata = experiment_results['MaxFeatures'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=dt_experiments['MaxFeatures'])\nchart = df.plot(title='Effects of Max Features', xlabel='Max Features', ylabel='Percent Error')\n\n# Effects of Max Leaf Nodes\ndata = experiment_results['MaxLeafNodes'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=dt_experiments['MaxLeafNodes'])\nchart = df.plot(title='Effects of Max Leaf Nodes', xlabel='# of Nodes', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyzing the experiments, we see many interesting data points that can help improve our model. For the criterion of the model, we see that entropy is much better than gini. The splitter has more success with the best algorithm. The last two experiments help configure our tree. Max features is a ratio that tells the algorithm the ratio of maximum features when considering a split. We see that initially there is much larger error when considering less features, which is something we can logically assume. We want to find the sweet spot, which we would consider to be the lowest dip in the curve. We observe this point as somewhere between 0.6 to 0.7. Lastly, we look at the effects of limiting the maximum number of leaf nodes. Since we see a very low dip initially, we can assume that 10-50 should be an ideal configuration. "},{"metadata":{},"cell_type":"markdown","source":"**Boosting Experiments:**\n\nFor the Random Forest classifier analysis, we experimented with three different configuration settings:  Criterion, Number of Trees, Max Features and Max Leaf Nodes."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_experiments = {\n    'Trees' : [ 1, 2, 5, 10, 20, 30, 40, 50, 75, 100 ]\n  , 'MaxFeatures' : [ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 ]\n  , 'MaxLeafNodes' : [ 10, 25, 50, 100, 150, 200, 400, 500, 1000, 1500, 2000]\n}\n\ndef generate_RF_test_models():\n    experiment_models = { 'Criterion' : [ DecisionTreeClassifier(criterion='gini')  ], 'MaxFeatures'  : [ ]\n                        , 'Trees'  : [ ], 'MaxLeafNodes' : [ ] }\n    experiment_results = { 'Criterion' : [ ], 'MaxFeatures' : [ ], 'Trees' : [ ], 'MaxLeafNodes' : [ ] }\n    \n    for key in rf_experiments.keys():\n        for setting in rf_experiments[key]:\n            if ('Trees' == key):\n                experiment_models[key].append(RandomForestClassifier(n_estimators=setting))\n            elif ('MaxFeatures' == key):\n                experiment_models[key].append(RandomForestClassifier(max_features=setting))\n            elif ('MaxLeafNodes' == key):\n                experiment_models[key].append(RandomForestClassifier(max_leaf_nodes=setting))\n    \n    return experiment_models, experiment_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nasa Models\nall_models, experiment_results = generate_RF_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest))\n\n# Criterion: Entropy v Gini\ndata = [ baselineMap['NASA'][0], experiment_results['Criterion'][0][0] ]\ndf = pd.DataFrame(data, columns=['NASA'], index=['Entropy', 'Gini'])\nchart = df.plot.bar(rot=0, title='Entropy v Gini', xlabel='Criterion', ylabel='Percent Error')\n\n# Effects of Max Features\ndata = experiment_results['MaxFeatures'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=rf_experiments['MaxFeatures'])\nchart = df.plot(title='Effects of Max Features', xlabel='Max Features', ylabel='Percent Error')\n\n# Effects of Max Leaf Nodes\ndata = experiment_results['MaxLeafNodes'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=rf_experiments['MaxLeafNodes'])\nchart = df.plot(title='Effects of Max Leaf Nodes', xlabel='# of Nodes', ylabel='Percent Error')\n\n# Effects of Max Features\ndata = experiment_results['Trees'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=rf_experiments['Trees'])\nchart = df.plot(title='Effects of Tree Count', xlabel='# of Trees', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observing the results of the experiments for the Random Forest Classifier, we see that there are several configurations that we can tune to make our model better. First, we look at the criterion. We see that entropy is much better than it's gini counterpart. The effects of max features configuration shows that we should configure near 0.4 or 0.7. Our max leaf nodes shows a significant dip near 200 nodes and our tree count is initially high but slowly levels out near 10 trees. "},{"metadata":{},"cell_type":"markdown","source":"**Nueral Network Experiments:**\n\nFor the Nueral Network analysis, we experimented with four different configuration settings: Learning Rate, Hidden Layers, Max Iterations and Momentum."},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_experiments = { \n  'LearningRates' : [ 0.00001, 0.0000625, 0.0001, 0.000125, 0.00025, 0.0005, 0.001, 0.002, 0.004 ]\n, 'HiddenLayers'  : [ 1, 5, 10, 20, 25, 50, 100, 200 ]\n, 'MaxIterations' : [ 1, 5, 10 , 20, 25, 50, 100, 200, 400 ]\n, 'Momentum'      : [ 0.001, 0.1, 0.25, 0.45, 0.9, 0.99, 0.999, 0.9999 ]\n}\n\ndef generate_NN_test_models():\n    all_models = { 'LearningRates' : [], 'HiddenLayers' : [], 'MaxIterations' : [], 'Momentum' : [] }\n    experiment_results = { 'LearningRates' : [], 'HiddenLayers' : [], 'MaxIterations' : [], 'Momentum' : [] }\n    \n    for key in nn_experiments.keys():\n        for setting in nn_experiments[key]:\n            if ('LearningRates' == key):\n                    all_models['LearningRates'].append(MLPClassifier(learning_rate_init=setting, max_iter=100))\n            elif ('HiddenLayers' == key):\n                    all_models['HiddenLayers'].append(MLPClassifier(hidden_layer_sizes=(setting,), max_iter=100))\n            elif ('MaxIterations' == key):\n                    all_models['MaxIterations'].append(MLPClassifier(max_iter=setting))\n            elif ('Momentum' == key):\n                    all_models['Momentum'].append(MLPClassifier(solver='sgd', momentum=setting, max_iter=100))\n    \n    return all_models, experiment_results\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NASA Models\nall_models, experiment_results = generate_NN_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest))\n    \n# Effects of Learning Rate\ndata = experiment_results['LearningRates'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=nn_experiments['LearningRates'])\nchart = df.plot(title='Effects of Learning Rate', xlabel='Learning Rate', ylabel='Percent Error')\n\n# Effects of Hidden Layer\ndata = experiment_results['HiddenLayers'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=nn_experiments['HiddenLayers'])\nchart = df.plot(title='Effects of Hidden Layers', xlabel='# of Hidden Layers', ylabel='Percent Error')\n\n# Effects of Max Iterations\ndata = experiment_results['MaxIterations'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=nn_experiments['MaxIterations'])\nchart = df.plot(title='Effects of Max Iterations', xlabel='# of Max Iterations', ylabel='Percent Error')\n\n# Effects of Momentum\ndata = experiment_results['Momentum'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=nn_experiments['Momentum'])\nchart = df.plot(title='Effects of Momentum', xlabel='Momentum', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyzing the experiments, we see many areas of improvement for our Neural Network. First, we look at the learning rate. We run the default configuration and modify the learning rate only to show the effects of this configuration. Interesting enough, we see that as the learning rate increases, our percent error decreases so we will want to increase our learning rate to improve our model. Next, we see very similar relationships for our hidden layers and max iteration configurations. Both of which, decrease the percent error as we increase the value. We must proceed with caution though, in fear that we may overfit our data if the values are too high. Lastly, the most interesting experiment resrult was the effects of momentum. As you can see as we increase momentum, there is hardly any effect and then from 0.9 to 1.0 we see a rather drastic decrease in percent error. "},{"metadata":{},"cell_type":"markdown","source":"**k-Nearest Neighbor Experiments:**\n\nFor the KNN analysis, we experimented with two different configuration settings: Varying K-Neighbors and Weights."},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_experiments = { \n  'VaryingK' : [ 1, 5, 10, 20, 50, 100, 200, 500, 1000 ]\n, 'Weights'  : [ 'distance' ]\n}\n\ndef generate_KNN_test_models():\n    all_models = { 'VaryingK' : [], 'Weights' : [ KNeighborsClassifier(weights='distance') ] }\n    experiment_results = { 'VaryingK' : [], 'Weights' : [] }\n    \n    for key in knn_experiments.keys():\n        for setting in knn_experiments[key]:\n            if ('VaryingK' == key):\n                    all_models['VaryingK'].append(KNeighborsClassifier(n_neighbors=setting, weights='distance'))\n    \n    return all_models, experiment_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nasa Models\nall_models, experiment_results = generate_KNN_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest))\n    \n# Effects of K\ndata = experiment_results['VaryingK'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=knn_experiments['VaryingK'])\nchart = df.plot(title='Effects of K', xlabel='K', ylabel='Percent Error')\n\n# Weight: Uniform v Distance\ndata = [ baselineMap['NASA'][3], experiment_results['Weights'][0][0] ]\ndf = pd.DataFrame(data, columns=['NASA'], index=['Uniform', 'Distance'])\nchart = df.plot.bar(rot=0, title='Uniform v Distance', xlabel='Weight', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For our KNN experiments, we first observe the effects of K. We can see an initial dip and then a drastic increase in percent error as K increases. We identify the best K somewhere between 5 to 10. Our weight algorithm doesn't show much difference but we will go with distance to be consitent with our K test."},{"metadata":{},"cell_type":"markdown","source":"**SVC Experiments:**\n\nFor the SVC analysis, we experimented with four different configuration settings: Kernel, Degree, Gamma and Max Iterations."},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_experiments = { \n  'Kernel'  : [ 'linear', 'poly', 'rbf', 'sigmoid' ]\n, 'Degree'  : [ 1, 2, 3, 4, 5, 6, 7, 8 ]\n, 'Gamma'   : [ 'auto' ]\n, 'MaxIter' : [ 1, 5, 10 , 20, 25, 50, 100, 200, 400 ]\n}\n\ndef generate_SVC_test_models():\n    all_models = { 'Kernel' : [], 'Degree' : [ ], 'Gamma' : [ ], 'MaxIter' : [ ] }\n    experiment_results = { 'Kernel' : [], 'Degree' : [ ], 'Gamma' : [ ], 'MaxIter' : [ ] }\n    \n    for key in svc_experiments.keys():\n        for setting in svc_experiments[key]:\n            if ('Kernel' == key):\n                all_models['Kernel'].append(SVC(kernel=setting))\n            elif ('Degree' == key):\n                all_models['Degree'].append(SVC(kernel='poly', degree=setting))\n            elif ('Gamma' == key):\n                all_models['Gamma'].append(SVC(gamma=setting))\n            elif ('MaxIter' == key):\n                all_models['MaxIter'].append(SVC(max_iter=setting))\n    \n    return all_models, experiment_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nasa Models\nall_models, experiment_results = generate_SVC_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest))\n    \n# Effects of Degree\ndata = experiment_results['Degree'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=svc_experiments['Degree'])\nchart = df.plot(title='Effects of Degree', xlabel='# of Degrees', ylabel='Percent Error')\n\n# Effects of Max Iterations\ndata = experiment_results['MaxIter'][0]\ndf = pd.DataFrame(data, columns=['NASA'], index=svc_experiments['MaxIter'])\nchart = df.plot(title='Effects of Max Iterations', xlabel='# of Max Iterations', ylabel='Percent Error')\n\n# Effects of Kernels\ndata = [ baselineMap['NASA'][2] ]\nfor i in experiment_results['Kernel'][0]:\n    data.append(i)\ndf = pd.DataFrame(data, columns=['NASA'], index=['base', 'linear', 'poly', 'rbf', 'sigmoid'])\nchart = df.plot.bar(rot=0, title='Effects of Kernels', xlabel='Kernel Type', ylabel='Percent Error')\n\n# Effects of Gamma\ndata = [ baselineMap['NASA'][2], experiment_results['Gamma'][0][0] ]\ndf = pd.DataFrame(data, columns=['NASA'], index=['Scale', 'Auto'])\nchart = df.plot.bar(rot=0, title='Scale v Auto', xlabel='Gamma Type', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyzing our experiments for our SVC model, we see that there are many interesting data points that will help improve our model. First, we look at the effects of the kernel, we want to pick a kernel that will perform well on our data and we see that our initial indications show 'poly' as the best. We then further this initial inidication with an experiment using the 'poly' kernel, but varying the degrees. We see that 6 degrees shows a much lower percent error! Next, we look at the gamma. We see that scale is much better than auto, but auto with 'poly' kernl is much better so that is how we will configure our final model."},{"metadata":{},"cell_type":"markdown","source":"# **Conclusion** #\n\nOur experiments show many interesting data points that we can learn from to improve our models. First, we look at our Decision Tree experiments and conclude that the combination of Gini criterion, Best splitter and 0.9 max features produces a much more accurate model. Next, the Neural Network will use 0.004 as the Learning Rate, 200 Hidden Layers, 0.999 momentum and 400 max iterations. Our SVC model will use the poly kernel with 6 degrees, the Random Forest Boost model will uuse 10 trees with 200 nodes and entroy while utilizing max feature ratio of .4 and lastly our KNN model will use k=20 and distance as it's weight algorithm. We can see from the chart below that each model has greatly decreased it's percent error compared to it's baseline."},{"metadata":{"trusted":true},"cell_type":"code","source":"nasa_models = [ DecisionTreeClassifier(criterion='entropy', splitter='best', max_features=0.6), MLPClassifier(learning_rate_init=0.004, hidden_layer_sizes=200, max_iter=400, momentum=0.999), SVC(kernel='poly', degree=6), KNeighborsClassifier(n_neighbors=20, weights='distance'), RandomForestClassifier(n_estimators=10, max_leaf_nodes=200, max_features=0.4, criterion='entropy') ]\nimproved = simulate(nasa_models, nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest)\n\nimprv_df = pd.DataFrame(improved, columns=['Improved'], index=['Decision Tree', 'Neural Network', 'SVC', 'KNN', 'Boosting']).join(nasa_df)\nnasa_baseline_chart = imprv_df.plot.bar(rot=0, title='Model Baseline Error', xlabel='Models', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lastly, we take time to compare the models themselves. We see that the Neural Network had the largest improvement and overall our Random Forest is the most accurate. We can explain this by observing the data itself and noticing many of the features are continuous values. Decision Trees and Neural Networks would perform much better on this type of data because these models are best at finding clear splits in the data. SVC and KNN would not perform as well because the data is not naturally clumping together."},{"metadata":{},"cell_type":"markdown","source":"# Problem 2: Edible Mushroom Classification #\n\n**Description**\n\nEvolution allows for species to naturally extend their senses through biological changes. Now, machine learning can also provide a similar level of extension for humans by classifying edible foods. In a life-threatening situation, understanding what you can eat to survive can be the difference between life and death. Machine learning algorithms can help with this type of classification problem. We will start with a simpler problem by classifying which mushrooms are edible.\n\n**Results**\n\nBelow, we describe the initial results of our models.  Each model is from the ’sklearn’ library.  Weused each model’s default settings as the initial results.  These default values are:\n* DecisionTreeClassifier - Criterion=Entropy, Splitter=Best, \n* MLPClassifier - HiddenLayers=100, ActivationFunction=Relu, Solver=adam, Alpha=0.0001, LearningRate=Constant(0.001), MaxIterations=100 beta1=0.9, beta2=0.999, epsilon=1e-8\n* SVC - kernel=rbf, degree=3, gamma= 1/(n\\_features * X.var())\n* KNeighborsClassifier - N-Neighbors=5, Weights=uniform\n* RandomForestClassifier - Criterion=Entropy, MaxFeature=auto, MaxLeafNodes=None, TreeCount=100"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shroom Models\nshroom_models = [ DecisionTreeClassifier(criterion='entropy'), MLPClassifier(max_iter=100), SVC(), KNeighborsClassifier(), RandomForestClassifier() ]\nbaselineMap['MUSHROOM'] = simulate(shroom_models, shroom_xTrain, shroom_yTrain, shroom_xTest, shroom_yTest)\n\nshroom_df = pd.DataFrame(baselineMap['MUSHROOM'], columns=['MUSHROOM'], index=['Decision Tree', 'Neural Network', 'SVC', 'KNN', 'Boosting'])\nshroom_baseline_chart = shroom_df.plot.bar(rot=0, title='Model Baseline Error', xlabel='Models', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(baselineMap['MUSHROOM'], columns=['MUSHROOM'], index=['Decision Tree', 'Neural Network', 'SVC', 'KNN', 'Boosting'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Analysis** #\n\nFor the analysis, we will experiment with a variety of model configurations and analyze their effects on error. Ideally, we would like to find the best combination of configurations which produces the 'best' results. Best in the context of the Asteroid Classification problem will be maximizing the average test score from a cross validation with three folds."},{"metadata":{},"cell_type":"markdown","source":"**DecisionTree Experiments:**\n\nFor the Decision Tree analysis, we experimented with three different configuration settings:  Criterion, Max Features and Splitter Algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shroom Models\nall_models, experiment_results = generate_DT_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], shroom_xTrain, shroom_yTrain, shroom_xTest, shroom_yTest))\n    \n# Criterion: Entropy v Gini\ndata = [ baselineMap['MUSHROOM'][0], experiment_results['Criterion'][0][0] ]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=['Entropy', 'Gini'])\nchart = df.plot.bar(rot=0, title='Entropy v Gini', xlabel='Criterion', ylabel='Percent Error')\n\n# Splitter: Best v Random\ndata = [ baselineMap['MUSHROOM'][0], experiment_results['Splitter'][0][0] ]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=['Best', 'Random'])\nchart = df.plot.bar(rot=0, title='Best v Random', xlabel='Splitter', ylabel='Percent Error')\n\n# Effects of Max Features\ndata = experiment_results['MaxFeatures'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=dt_experiments['MaxFeatures'])\nchart = df.plot(title='Effects of Max Features', xlabel='Ratio of Max Features', ylabel='Percent Error')\n\n# Effects of Max Leaf Nodes\ndata = experiment_results['MaxLeafNodes'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=dt_experiments['MaxLeafNodes'])\nchart = df.plot(title='Effects of Max Leaf Nodes', xlabel='# of Nodes', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Decision Tree experiments show some interesting results. We notice that for this particular data set the max leaf nodes performance peaks at a much lower value than our previous experiments. We see a significant drop in percent error around 0.8 ratio of max features and unfortunately the difference between criterion and splitter algorithms didn't make much difference."},{"metadata":{},"cell_type":"markdown","source":"**Boosting Experiments:**\n\nFor the Random Forest classifier analysis, we experimented with three different configuration settings:  Criterion, Number of Trees, Max Features and Max Leaf Nodes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nasa Models\nall_models, experiment_results = generate_RF_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], nasa_xTrain, nasa_yTrain, nasa_xTest, nasa_yTest))\n\n# Criterion: Entropy v Gini\ndata = [ baselineMap['MUSHROOM'][0], experiment_results['Criterion'][0][0] ]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=['Entropy', 'Gini'])\nchart = df.plot.bar(rot=0, title='Entropy v Gini', xlabel='Criterion', ylabel='Percent Error')\n\n# Effects of Max Features\ndata = experiment_results['MaxFeatures'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=rf_experiments['MaxFeatures'])\nchart = df.plot(title='Effects of Max Features', xlabel='Max Features', ylabel='Percent Error')\n\n# Effects of Max Leaf Nodes\ndata = experiment_results['MaxLeafNodes'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=rf_experiments['MaxLeafNodes'])\nchart = df.plot(title='Effects of Max Leaf Nodes', xlabel='# of Nodes', ylabel='Percent Error')\n\n# Effects of Max Features\ndata = experiment_results['Trees'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=rf_experiments['Trees'])\nchart = df.plot(title='Effects of Tree Count', xlabel='# of Trees', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the Random Forest Classifier experiments, we notice a lot of great data points to improve our model. First we observe the criterion. Gini is significantly better than entropy for this data set so we will definitely configure our model to reflect this improvement. Next, we see a significant dip in max feature ratio around 0.5. Lastly, we see two significant dips around 500 nodes for max leaf nodes and 20 trees. "},{"metadata":{},"cell_type":"markdown","source":"**Nueral Network Experiments:**\n\nFor the Nueral Network analysis, we experimented with four different configuration settings: Learning Rate, Hidden Layers, Max Iterations and Momentum."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shroom Models\nall_models, experiment_results = generate_NN_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], shroom_xTrain, shroom_yTrain, shroom_xTest, shroom_yTest))\n\n# Effects of Learning Rate\ndata = experiment_results['LearningRates'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=nn_experiments['LearningRates'])\nchart = df.plot(title='Effects of Learning Rate', xlabel='Learning Rate', ylabel='Percent Error')\n\n# Effects of Hidden Layer\ndata = experiment_results['HiddenLayers'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=nn_experiments['HiddenLayers'])\nchart = df.plot(title='Effects of Hidden Layers', xlabel='# of Hidden Layers', ylabel='Percent Error')\n\n# Effects of Max Iterations\ndata = experiment_results['MaxIterations'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=nn_experiments['MaxIterations'])\nchart = df.plot(title='Effects of Max Iterations', xlabel='# of Max Iterations', ylabel='Percent Error')\n\n# Effects of Momentum\ndata = experiment_results['Momentum'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=nn_experiments['Momentum'])\nchart = df.plot(title='Effects of Momentum', xlabel='Momentum', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For our Neural Network experiments, we notice a few of the same results as our previous data set. As the learning rate increases the percent error greatly decreases. We see the more layers you have, the more procise the algorithm will be and momentum has a much more profound effect the closer we are to 1.0. Lastly, we observe the effects of max iterations. Just like the previous experiments we know that more iterations we give our algorithm to train, the better outcomes it will produce."},{"metadata":{},"cell_type":"markdown","source":"**k-Nearest Neighbor Experiments:**\n\nFor the KNN analysis, we experimented with two different configuration settings: Varying K-Neighbors and Weights."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shroom Models\nall_models, experiment_results = generate_KNN_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], shroom_xTrain, shroom_yTrain, shroom_xTest, shroom_yTest))\n    \n# Effects of K\ndata = experiment_results['VaryingK'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=knn_experiments['VaryingK'])\nchart = df.plot(title='Effects of K', xlabel='K', ylabel='Percent Error')\n\n# Weight: Uniform v Distance\ndata = [ baselineMap['MUSHROOM'][3], experiment_results['Weights'][0][0] ]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=['Uniform', 'Distance'])\nchart = df.plot.bar(rot=0, title='Uniform v Distance', xlabel='Weight', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The KNN experiments for this classification problem was the most interesting out of all of the experiments because of how well it was able to predict. We see that the effects of K can be profound. When the values are too small then we know that the data set is more complex than just a few clusters. For this data set, we see that the distance algorithm and as K approaches 50 it achieves the lowest percent error."},{"metadata":{},"cell_type":"markdown","source":"**SVC Experiments:**\n\nFor the SVC analysis, we experimented with four different configuration settings: Kernel, Degree, Gamma and Max Iterations."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shroom Models\nall_models, experiment_results = generate_SVC_test_models()\nfor key in all_models.keys():\n    experiment_results[key].append(simulate(all_models[key], shroom_xTrain, shroom_yTrain, shroom_xTest, shroom_yTest))\n    \n# Effects of Degree\ndata = experiment_results['Degree'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=svc_experiments['Degree'])\nchart = df.plot(title='Effects of Degree', xlabel='# of Degrees', ylabel='Percent Error')\n\n# Effects of Max Iterations\ndata = experiment_results['MaxIter'][0]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=svc_experiments['MaxIter'])\nchart = df.plot(title='Effects of Max Iterations', xlabel='# of Max Iterations', ylabel='Percent Error')\n\n# Effects of Kernels\ndata = [ baselineMap['MUSHROOM'][2] ]\nfor i in experiment_results['Kernel'][0]:\n    data.append(i)\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=['base', 'linear', 'poly', 'rbf', 'sigmoid'])\nchart = df.plot.bar(rot=0, title='Effects of Kernels', xlabel='Kernel Type', ylabel='Percent Error')\n\n# Effects of Gamma\ndata = [ baselineMap['MUSHROOM'][2], experiment_results['Gamma'][0][0] ]\ndf = pd.DataFrame(data, columns=['MUSHROOM'], index=['Scale', 'Auto'])\nchart = df.plot.bar(rot=0, title='Scale v Auto', xlabel='Gamma Type', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we observe the SVC experiments, we notice that we are not seeing that much performance gain. The gamma type doesn't really give us a sense of which could drastically improve our model so we keep it at 'auto'. Next, we look at the kernel type. Many of them are within the 20-25 range, so there is still not a clear winner. We then decide to go with the 'poly' kernel and observe the effects of the varying degrees. When analyzing these variations, we notice that the higher degree produces the lowest percent error so we will decide to choose 8."},{"metadata":{},"cell_type":"markdown","source":"# **Conclusion** #\nOur experiments show many interesting data points for all of our models. We noticed that our Decision Tree was much better with a max feature ratio around 0.8. This infers that we need to consider around 80% of our features to have the best outcome.  Next, we look at the Neural Network. We find many great data points that will improve our model. We decide to configure our learning rate to be 0.004, with 200 hidden layers, 100 max iterations and momentum of 0.999. Our SVC model showed a much better performance using a poly kernel with 8 degrees. Our Random Forest also showed some performance improvemnt using Gini criterion. Lastly, our KNN experiments show 50 is the best configuration for K and distance as the best weight algorithm. Below we can observe the improvements shown by tuning our models using what we've learned from our experiments:"},{"metadata":{"trusted":true},"cell_type":"code","source":"shroom_models = [ DecisionTreeClassifier(max_features=0.8), MLPClassifier(learning_rate_init=0.004, hidden_layer_sizes=200, max_iter=100, momentum=0.999), SVC(kernel='poly', degree=8), KNeighborsClassifier(n_neighbors=50, weights='distance'), RandomForestClassifier(criterion='gini') ]\nimproved = simulate(shroom_models, shroom_xTrain, shroom_yTrain, shroom_xTest, shroom_yTest)\n\ndf = pd.DataFrame(improved, columns=['Improved'], index=['Decision Tree', 'Neural Network', 'SVC', 'KNN', 'Boosting']).join(shroom_df)\nshroom_baseline_chart = df.plot.bar(rot=0, title='Model Baseline v Improved', xlabel='Models', ylabel='Percent Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we take time to compare and contrast our models and determine how well they classify edible mushrooms. We see that our SVC and Neural Network had the best performance improvements while the Decision Tree, Random Forest and KNN has a much lower percent error. We can explain this by looking at the data itself. We observe that many of the data points are discrete values for each of the features. If modified correctly during feature extraction, we can manipulate the data to have these discrete values cluster very well. This would work well for the KNN model and is why I believe the KNN model would be best for this type of classification problem. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}