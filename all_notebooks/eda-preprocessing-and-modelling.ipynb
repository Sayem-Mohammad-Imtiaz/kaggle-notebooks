{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom lightgbm import LGBMClassifier\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.feature_selection import SelectFwe, f_regression\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom tpot.builtins import OneHotEncoder, StackingEstimator\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/janatahack/train_8wry4cB.csv')\ntest = pd.read_csv('/kaggle/input/janatahack/test_Yix80N0.csv')\nsample = pd.read_csv('/kaggle/input/janatahack/sample_submission_opxHi4g.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(train.info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.apply(lambda x:len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gender - Male and Female\nUnique session id\n9402 unique products"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['gender'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More females view then male"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['startTime'] = pd.to_datetime(train['startTime'])\ntrain['endTime'] = pd.to_datetime(train['endTime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could also see that there is some inconsitency in start and end time"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.append(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['session_id','startTime','endTime','ProductList','gender']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ProductCount'] = df.ProductList.str.count(';')+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ProductList']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['startTime'] = pd.to_datetime(df['startTime'])\ndf['endTime'] = pd.to_datetime(df['endTime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom itertools import chain\n\n# return list from series of comma-separated strings\ndef chainer(s):\n    return list(chain.from_iterable(s.str.split(';')))\n\n# calculate lengths of splits\nlens = df['ProductList'].str.split(';').map(len)\n\n# create new dataframe, repeating or chaining as appropriate\ndf1 = pd.DataFrame({'session_id': np.repeat(df['session_id'], lens),\n                    'startTime': np.repeat(df['startTime'], lens),\n                    'endTime':np.repeat(df['endTime'],lens),\n                    'ProductCount': np.repeat(df['ProductCount'], lens),\n                    'ProductList': chainer(df['ProductList']),\n                    'gender':np.repeat(df['gender'],lens)})\n\nprint(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['TimeTaken'] = abs(df1['endTime'] - df1['startTime']).astype('timedelta64[m]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[['Date','Time']] = df1['startTime'].astype(str).str.split(\" \",expand=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Date'] = pd.to_datetime(df1['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Day'] = df1['Date'].apply(lambda x: x.weekday())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['TimeTaken'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[['Category','SubCategory','SubSubCategory','SubSubSubCategory','Extra']] = df1['ProductList'].str.split(\"/\",expand=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df1['Extra']\ndel df1['ProductList']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df1['Time']\ndel df1['Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df1['session_id'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changing the orders"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df1[['session_id','TimeTaken','Day','ProductCount','Category','SubCategory','SubSubCategory','SubSubSubCategory','gender']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['TimeTaken'] = df1.TimeTaken.apply(lambda x:int(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing \ncolumns = ['Category','SubCategory','SubSubCategory','SubSubSubCategory']\nlabel_encoder = preprocessing.LabelEncoder() \n  \nfor i in columns:\n    df1[i]= label_encoder.fit_transform(df1[i]) \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['session_id'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = df1[df1['gender'].isnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1 = df1[df1['gender'].isnull() == False]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing \ncolumns = ['gender']\n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \n  \nfor i in columns:\n    train1[i]= label_encoder.fit_transform(train1[i]) \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train1['Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train1['Day'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1.groupby('Day')['gender'].size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train1['ProductCount'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train1['Day'],train1['gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test1['gender']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extra_tree(Xtrain,Ytrain,Xtest):\n    extra = ExtraTreesClassifier()\n    extra.fit(Xtrain, Ytrain) \n    extra_prediction = extra.predict(Xtest)\n    return extra_prediction\ndef Xg_boost(Xtrain,Ytrain,Xtest):\n    xg = XGBClassifier(loss='exponential', learning_rate=0.05, n_estimators=1000, subsample=1.0, criterion='friedman_mse', \n                                  min_samples_split=2, \n                                  min_samples_leaf=5, min_weight_fraction_leaf=0.0, max_depth=10, min_impurity_decrease=0.0, \n                                  min_impurity_split=None, \n                                  init=None, random_state=None, max_features=None, verbose=1, max_leaf_nodes=None, warm_start=False, \n                                  presort='deprecated', \n                                  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n    xg.fit(Xtrain, Ytrain) \n    xg_prediction = xg.predict(Xtest)\n    return xg_prediction\ndef LGBM(Xtrain,Ytrain,Xtest):\n    lgbm = LGBMClassifier(boosting_type='gbdt', num_leaves=40,\n                            max_depth=5, learning_rate=0.05, n_estimators=1000, subsample_for_bin=200, objective='binary', \n                            min_split_gain=0.0, min_child_weight=0.001, min_child_samples=10,\n                            subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0,\n                            reg_lambda=0.0, random_state=None, n_jobs=1, silent=True, importance_type='split')\n    #lgbm = LGBMClassifier(n_estimators= 500)\n    lgbm.fit(X_train, Y_train)\n    lgbm_preds = lgbm.predict(X_test)\n    return lgbm_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train1.columns)\nprint(test1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train1[['TimeTaken','Day','ProductCount','Category', 'SubCategory', 'SubSubCategory','SubSubSubCategory']]\nY_train = train1['gender']\nX_test = test1[['TimeTaken','Day','ProductCount', 'Category', 'SubCategory', 'SubSubCategory','SubSubSubCategory']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from autoviml.Auto_ViML import Auto_ViML","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'gender'\nscoring_parameter = 'balanced-accuracy'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nm, feats, trainm, testm = Auto_ViML(train1, target, test1,\n                                    scoring_parameter=scoring_parameter,\n                                    hyper_param='GS',feature_reduction=True,\n                                     Boosting_Flag='Boosting_Flag',Binning_Flag=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam = pd.read_csv('/kaggle/input/sample/gender_Binary_Classification_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest1['gender'] = sam['gender_predictions']\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('Auto.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()\ncate_features_index = np.where(X_train.dtypes != float)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(X_train,Y_train,train_size=0.99,random_state=1236)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import Pool, CatBoostClassifier, cv, CatBoostRegressor\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(iterations=7000, learning_rate=0.001, l2_leaf_reg=3.5, depth=5, \n                           rsm=0.99, loss_function= 'Logloss', eval_metric='AUC',use_best_model=True,random_seed=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtrain,ytrain,cat_features=cate_features_index,eval_set=(xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predss = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest1['gender'] = predss\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('FinalSubmission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"All other models for refference"},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_xg = Xg_boost(X_train,Y_train,X_test)\n#pred_et = extra_tree(X_train,Y_train,X_test)\npred_l = LGBM(X_train,Y_train,X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 - female, 1 male","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['gender'] = pred_xg\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DXG.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['gender'] = pred_et\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DETC.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest1['gender'] = pred_l\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DPCLGBM.csv',index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=0).fit(X_train, Y_train)\nans = clf.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(pred_l))\ntest1['gender'] = ans\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DLR.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators=100).fit(X_train, Y_train)\nprediction_of_ada = ada.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(loss='exponential', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', \n                                  min_samples_split=2, \n                                  min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=10, min_impurity_decrease=0.0, \n                                  min_impurity_split=None, \n                                  init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, \n                                  presort='deprecated', \n                                  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001).fit(X_train, Y_train)\nprediction_of_gbc = gbc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=10).fit(X_train, Y_train)\nprediction_of_rf = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest1['gender'] = prediction_of_ada\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DADA.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest1['gender'] = prediction_of_gbc\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('Dgbc.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest1['gender'] = prediction_of_rf\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DRF.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X_train,Y_train)\n\n# Predicted class\nnri = neigh.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest1['gender'] = nri\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('Dknn.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.calibration import CalibratedClassifierCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier()\nmetLearn=CalibratedClassifierCV(model, method='isotonic', cv=2)\nmetLearn.fit(X_train, Y_train)\ntestPredictions = metLearn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def submissions(predictions_by_model,string):\n    test1['gender'] = predictions_by_model\n    testn = test1[['session_id','gender']]\n    print(testn.isna().sum())\n    test_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\n    dic = {1:'male',0:'female'}\n    test_final['gender'] = test_final['gender'].map(dic)\n    test_final.to_csv(string.csv,index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['gender'] = testPredictions\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DCCV.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\n\n# sklearn tools for model training and assesment\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import PredefinedSplit\nfrom sklearn.model_selection import GridSearchCV, ParameterGrid\nfrom sklearn.metrics import (roc_curve, auc, accuracy_score)\n\n# specify your configurations as a dict\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': {'binary_logloss', 'auc'},\n    'metric_freq': 1,\n    'is_training_metric': True,\n    'max_bin': 255,\n    'learning_rate': 0.1,\n    'num_leaves': 63,\n    'tree_learner': 'serial',\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'min_data_in_leaf': 50,\n    'min_sum_hessian_in_leaf': 5,\n    'is_enable_sparse': True,\n    'use_two_round_loading': False,\n    'is_save_binary_file': False,\n    'output_model': 'LightGBM_model.txt',\n    'num_machines': 1,\n    'local_listen_port': 12400,\n    'machine_list_file': 'mlist.txt',\n    'verbose': 0,\n    'subsample_for_bin': 200000,\n    'min_child_samples': 20,\n    'min_child_weight': 0.001,\n    'min_split_gain': 0.0,\n    'colsample_bytree': 1.0,\n    'reg_alpha': 0.0,\n    'reg_lambda': 0.0\n}\n\n\nlgb_train = lgb.Dataset(X_train, Y_train)\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_eval = lgb.Dataset(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\ngbm = lgb.train(params,\n                lgb_train,\n                valid_sets=lgb_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\ngridParams = {\n    'learning_rate': [ 0.1],\n    'num_leaves': [63],\n    'boosting_type' : ['gbdt'],\n    'objective' : ['binary']\n}\n\nmdl = lgb.LGBMClassifier(\n    task = params['task'],\n    metric = params['metric'],\n    metric_freq = params['metric_freq'],\n    is_training_metric = params['is_training_metric'],\n    max_bin = params['max_bin'],\n    tree_learner = params['tree_learner'],\n    feature_fraction = params['feature_fraction'],\n    bagging_fraction = params['bagging_fraction'],\n    bagging_freq = params['bagging_freq'],\n    min_data_in_leaf = params['min_data_in_leaf'],\n    min_sum_hessian_in_leaf = params['min_sum_hessian_in_leaf'],\n    is_enable_sparse = params['is_enable_sparse'],\n    use_two_round_loading = params['use_two_round_loading'],\n    is_save_binary_file = params['is_save_binary_file'],\n    n_jobs = -1\n)\n\nscoring = {'AUC': 'roc_auc'}\n\n# Create the grid\n#grid = GridSearchCV(mdl, gridParams, verbose=2, cv=5, scoring=scoring, n_jobs=-1, refit='AUC')\n# Run the grid\n\n\n#print('Best parameters found by grid search are:', grid.best_params_)\n#print('Best score found by grid search is:', grid.best_score_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yes = gbm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yess =[]\nfor i in yes:\n    if i>=0.5:\n        yess.append(1)\n    else:\n        yess.append(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['gender'] = yess\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DDCCV.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import h2o\nh2o.init()\ntrain2 = h2o.H2OFrame(train1)\ntest2 = h2o.H2OFrame(X_test)\ntrain1.columns\ny = 'gender'\nx = train2.col_names\nx.remove(y)\ntrain2['gender'] = train2['gender'].asfactor()\ntrain2['gender'].levels()\nfrom h2o.automl import H2OAutoML\naml1 = H2OAutoML(max_models = 30, max_runtime_secs=200, seed = 1)\naml1.train(x = x, y = y, training_frame = train2)\npreds = aml1.predict(test2)\nprint(sample.columns)\ntest1['gender'] = preds\n#ans=h2o.as_list(preds) \n#sample['gender'] = ans['predict']\n#sample.to_csv('Solution_H2O(Divided).csv',index=False)\n#lb = aml.leaderboard\n#lb.head()\n#lb.head(rows=lb.nrows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['gender'] = (h2o.as_list(preds['predict']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntestn = test1[['session_id','gender']]\nprint(testn.isna().sum())\ntest_final = testn.drop_duplicates(subset='session_id', keep='first', inplace=False)\ndic = {1:'male',0:'female'}\ntest_final['gender'] = test_final['gender'].map(dic)\ntest_final.to_csv('DH2o.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}