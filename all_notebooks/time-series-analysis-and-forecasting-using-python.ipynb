{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Time-Series Data - Load, Clean, Visualize","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/others/daily-total-female-births-CA.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## But the date column is identified as object, we need to specify to look it as date type using one of pandas functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/others/daily-total-female-births-CA.csv\", parse_dates=[0])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For efficiency we import data as time-series","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is our time series date data and vales are births columns.\n\nseries = pd.read_csv(\"/kaggle/input/others/daily-total-female-births-CA.csv\", parse_dates=[0], index_col=[0], squeeze=True)\nseries.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(series.shape)\ntype(series)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filtering by Time","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(series['1959-05'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Descriptive Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"series.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time Series - Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndf['births'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.index = df.date # X-axis is date column now\nprint(df.head())\ndf['births'].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's zoom in","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfplot = df[(df['date']>'1959-03-01') & (df['date']<'1959-06-01')]\ndfplot.births.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting Trend lines using seaborn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndf = pd.read_csv(\"/kaggle/input/others/daily-total-female-births-CA.csv\", parse_dates=[0])\nsns.regplot(x=df.index.values, y=df.births)\n\n### Increasing Trend","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Polynomial Trendline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### Quadratic TL\nsns.regplot(x=df.index.values, y=df.births, order=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Cubic TL\nsns.regplot(x=df.index.values, y=df.births, order=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA of us-airlines-monthly-aircraft-miles-flown.csv","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"us_miles = pd.read_csv('../input/others/us-airlines-monthly-aircraft-miles-flown.csv', parse_dates=[0])\nus_miles.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_miles['MilesMM'].plot() # This shows seasonality, peak during end of the year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=us_miles.index.values, y=us_miles['MilesMM'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seasonality Removal - Aggregated by year and taking mean of milesMM|","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"us_miles['year'] = us_miles['Month'].dt.year\nus_miles.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_miles.groupby('year')['year','MilesMM'].head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's take the mean value of milesMM for each year","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(us_miles.groupby('year')['MilesMM'].mean())\nus_miles.groupby('year')['MilesMM'].mean().plot()\nplt.title('Seasonality Removed - MilesMM')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Lag Plots\nUsed to check whether a single column feature values are dependent on each other, like daily temperature is +/- (3 to 5)C of previous day's value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"us_miles['lags']= us_miles['MilesMM'].shift(1)\nus_miles.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=us_miles['lags'], y=us_miles['MilesMM'])\nplt.title('Positive Correlation is exhibited')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Also you can use\nfrom pandas.plotting import lag_plot\nlag_plot(us_miles['MilesMM'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Auto-Correlation Plots\nTo check the correlation of the feature variable with itself with delayed values of itself","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import autocorrelation_plot\nautocorrelation_plot(us_miles['MilesMM'])\n\n# X-axis is lag value +1 (like previous plt) , +2, +3, ...90 lags and \\\n# Y-axis is correlation of actual MilesMM and it's lagged values, +ve means positive correlation and -ve vice versa.\n\n# From the plot we see the first 5 lags are highly correlated with actual MilesMM feature.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## End of TS - Data - Load, Clean, Visualize","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## A time series data must be transformed to be modeled into a supervised learning problem.\n\n## The process of creating or inventing new features from the time series dataset is also called feature engineering (date --> Insights)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Types of Features\n\n1. Date-time Features --> These are the components of the time step itself for each observations (Date --> Day, Month, Year)\n\n2. Lag Features --> These are values at prior time steps\n\n3. Window Features --> Summary of values over a fixed window\n\n_______________________________________________________________\n\n## Window Features :\n* Rolling Window : Add a summary of the values for the previous time steps\n* Expanding Window : Include all previous data in the series","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##  Date-time Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/others/daily-total-female-births-CA.csv', parse_dates=[0])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = df.copy()\nfeatures['Year'] = df['date'].dt.year\nfeatures['Month'] = df['date'].dt.month\nfeatures['Days'] = df['date'].dt.day\n\n# New features (year, month, days from date)\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lag Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features['lag1'] = df['births'].shift(1)\nfeatures['lag2'] = df['births'].shift(365)\n\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Window Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take n and n-1 values of all date values and averages them into a single unit (window = 2)\n# Take n , n-1, and n-2 values of all date values and averages them into a single unit (window = 3)\n\nfeatures['Roll_mean'] = df['births'].rolling(window=2).mean() \nfeatures['Roll_Max'] = df['births'].rolling(window=3).max() # Mean or Max or Min\n\nfeatures.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Expanding Features (It consider all the values before a particular date value and performs operations)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features['Expanding_Max'] = df['births'].expanding().max()\nfeatures.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Resampling \n## Changing Frequency of the data to our convenient format (year-->month, month-->week, week-->day)\n## simply changing the frequency of the available data to match the frequency of the required forecast\n\n1. Upsampling (Quaterly data --> Monthly)\n2. Downsampling (Quaterly data --> Yearly)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/others/us-airlines-monthly-aircraft-miles-flown.csv', parse_dates=[0])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Downsampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Downsampling (12 months = 4 Quarters)\n# 'Q' - Quaterly, 'A' - Annually\nquaterly_miles = df.resample('Q', on='Month').mean() # Quarter has 3 sets and taking mean out of it\nquaterly_miles.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yearly_miles = df.resample('A', on='Month').sum()\nyearly_miles.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Upsampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_miles = df.resample('D', on='Month').mean() # Only creates structure, later fill them\ndaily_miles.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To fill the data between day 1 and day 30, we can interpolate a linear function to fill those values\ninterpolated_df = daily_miles.interpolate(method='linear')\ninterpolated_df.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interpolated_df.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For smoothing , we replace linear with polynomial function (quadratic= order=2, third degree polynomial order=4)\npoly_interpolated_df = daily_miles.interpolate(method='spline', order=2)\npoly_interpolated_df.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_interpolated_df.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing the two plots for smoothening\ninterpolated_df.plot()\npoly_interpolated_df.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Decomposing Time Series Model - For Detection\n\n1. Additive Model -->\npred(t) = Level(Avg value) + Trend(+ve / -ve trend) + Seasonality(short term cycles in series) + noise(random variation)\n2. Multiplicative Model -->\npred(t) = Level(Avg value) * Trend(+ve / -ve trend) * Seasonality(short term cycles in series) * noise(random variation)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndf = pd.read_csv('../input/others/us-airlines-monthly-aircraft-miles-flown.csv', parse_dates=[0])\ndf.index = df.Month\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_add = seasonal_decompose(df['MilesMM'], model='additive')\nresults_add.plot()\n# Original, Trend, Seasonality, Noise (Residual vales)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_mul = seasonal_decompose(df['MilesMM'], model='multiplicative')\nresults_mul.plot()\n# Original, Trend, Seasonality, Noise (Residual vales)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Differencing Time Series (For removing trend and seasonality from the data)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['lags'] = df['MilesMM'].shift(1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MilesMM-lags'] = df['MilesMM'].diff(periods=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for those 3 patterns in the original dataset\ndf.index = df.Month\nresult_1 = seasonal_decompose(df['MilesMM'], model='additive')\nresult_1.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The differencing must have removed the trend, but not the seasonality. let's check\n# Refer the y-axis, the range is less which means there's no trend\nresult_2 = seasonal_decompose(df.iloc[1:,3], model='additive')\nresult_2.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MilesMM'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MilesMM-lags'].plot() # Seasonality for first 3 values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['MilesMM-lags12'] = df['MilesMM'].diff(periods=12)\ndf['MilesMM-lags12'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The second differencing must have removed the seasonality. let's check\n# Refer the y-axis, the range is less which means there's no seasonality and trend\nresult_3 = seasonal_decompose(df.iloc[12:,4], model='additive')\nresult_3.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}