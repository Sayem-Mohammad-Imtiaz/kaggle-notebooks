{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install nb_black -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext nb_black","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nfor dirname, _, filenames in os.walk(\"/kaggle/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndata.drop([\"Unnamed: 32\", \"id\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verify how much 'NaN' in the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### All dataset\nCorrelation between all the variables at dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntable = data\ntable[\"diagnosis_b\"] = table.diagnosis.map({\"M\": 1.0, \"B\": 0.0})\ntable = table.corr()\n\nwith sns.axes_style(\"white\"):\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(25, 25))\n    sns.heatmap(\n        round(table, 2),\n        cmap=\"Reds\",\n        mask=mask,\n        vmax=table.max().max(),\n        vmin=table.min().min(),\n        linewidths=0.5,\n        annot=True,\n        annot_kws={\"size\": 12},\n    ).set_title(\"Correlation Matrix Breast Cancer Wisconsin Dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a lot of strong correlationship between some variables. Paying atention on the description some correlation are similar like **area_mean** with **perimeter_mean**. But our focus is the **diagnosis_b** (as diagnosis binary) let the this particular column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data, hue='diagnosis_b', vars=['radius_mean',\n'texture_mean',\n'perimeter_mean',\n'area_mean',\n'smoothness_mean',\n'compactness_mean',\n'concavity_mean',\n'concave points_mean',\n'symmetry_mean',\n'fractal_dimension_mean'])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The Target","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A strong (almost 1) correlationship here means a malignant cancer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\naux = table[[\"diagnosis_b\"]].sort_values(\"diagnosis_b\", ascending=False)\naux[\"columns\"] = table.index\nfig = px.bar(\n    aux,\n    x=\"columns\",\n    y=\"diagnosis_b\",\n    hover_data=[\"columns\", \"diagnosis_b\"],\n    color=\"diagnosis_b\",\n    height=600,\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a few variables with the same impact in the target.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Compare columns values\nInside the dataset are three types of data, there are: ** mean**, **worst** and **se**. Let's see all this three together at the same graph to 10 categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\n\ndef plot_violin(columns, name):\n    final = []\n    for col in columns:\n        aux = data[[\"diagnosis\", col]]\n        aux[\"type\"] = col\n        aux.columns = [\"diagnosis\", f\"{name} values\", \"type\"]\n        final.append(aux)\n\n    df = pd.concat(final)\n    fig = px.violin(\n        df,\n        y=f\"{name} values\",\n        x=\"type\",\n        color=\"diagnosis\",\n        box=True,\n        points=\"all\",\n        hover_data=df.columns,\n    )\n    fig.update_layout(\n        title_text=f\"Values of {name} by the target (B,M)\",\n        xaxis_title=\"Diagnosis (0 = B = benign, 1 = M = malignant)\",\n    )\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Radius\nThe radius means of distances from the centre to points on the perimeter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"radius\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Texture\nThe standard deviation of grey-scale values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"texture\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perimeter\nThe perimeter of a point.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"perimeter\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Area\nThe area of a point.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"area\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Smoothness\nThe local point variation in radius lengths.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"smoothness\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compactness\nCompactness is calculated by the expression -> (perimeter^2 / area - 1.0).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"compactness\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concavity\nThe severity of concave portions of the contour.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"concavity\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concave\nThe number of concave portions of the contour.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"concave points\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Symmetry\nThe symmetry with the point itself.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"symmetry\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fractal\nThe fractal dimension is calculate by (\"coastline approximation\" - 1).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = \"fractal_dimension\"\nplot_violin([f\"{col}_mean\", f\"{col}_se\", f\"{col}_worst\"], col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Models to baseline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = data.drop([\"diagnosis\", \"diagnosis_b\"], axis=1)\ny = data.diagnosis.values\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### DummyClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\n\ndc = DummyClassifier(strategy=\"most_frequent\")\ndc.fit(train_x, train_y)\ndc.score(test_x, test_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RandomForestClassifier ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nimport random\n\nSEED = 1234\nrandom.seed(SEED)\n\nrfc = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\nrfc.fit(train_x, train_y)\nrfc.score(test_x, test_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reduce features\nThere are too many features, let's reduce them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, chi2\n\nSEED = 1234\nrandom.seed(SEED)\n\nselect_k = SelectKBest(chi2, k=5)\n\nselect_k.fit(train_x, train_y)\ntrain_x_k = select_k.transform(train_x)\ntest_x_k = select_k.transform(test_x)\n\nrfck = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\nrfck.fit(train_x_k, train_y)\nrfck.score(test_x_k, test_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RFE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nSEED = 12345\nrandom.seed(SEED)\n\nrfc_aux = RandomForestClassifier(\n    n_estimators=100, max_depth=2, random_state=0, n_jobs=-1\n)\nrfc_rfe = RFE(estimator=rfc_aux, n_features_to_select=5, step=1,)\n\nrfc_rfe.fit(train_x, train_y)\ntrain_x_rfe = rfc_rfe.transform(train_x)\ntest_x_rfe = rfc_rfe.transform(test_x)\n\nrfc_aux.fit(train_x_rfe, train_y)\nrfc_aux.score(test_x_rfe, test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.columns[rfc_rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RFECV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\nSEED = 12345\nrandom.seed(SEED)\n\nrfc_aux_cv = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\nrfc_rfecv = RFECV(estimator=rfc_aux_cv, cv=10, step=1, scoring=\"accuracy\", n_jobs=-1)\n\nrfc_rfecv.fit(train_x, train_y)\ntrain_x_rfecv = rfc_rfecv.transform(train_x)\ntest_x_rfecv = rfc_rfecv.transform(test_x)\n\nrfc_aux_cv.fit(train_x_rfecv, train_y)\nrfc_aux_cv.score(test_x_rfecv, test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.columns[rfc_rfecv.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Partial results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\npca = PCA(n_components=\"mle\")\npca_result = pca.fit(normalize(x, norm=\"max\"))\ntrain_x_pca = pca_result.transform(train_x)\ntest_x_pca = pca_result.transform(test_x)\n\npca_model = RandomForestClassifier(\n    n_estimators=100, max_depth=2, random_state=0, n_jobs=-1\n)\npca_model.fit(train_x_pca, train_y)\n\n\nm_c = confusion_matrix(test_y, pca_model.predict(test_x_pca))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c, annot=True, cmap=\"Reds\", fmt=\"d\").set(xlabel=\"Predict\", ylabel=\"Real\")\nprint(\n    \"Inicial number of features: \",\n    test_x_pca.shape[1],\n    \" with the acurracy: \",\n    pca_model.score(test_x_pca, test_y),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Inicial, 30 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"m_c = confusion_matrix(test_y, rfc.predict(test_x))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c, annot=True, cmap=\"Reds\", fmt=\"d\").set(xlabel=\"Predict\", ylabel=\"Real\")\nprint(\n    \"Inicial number of features: \",\n    train_x.shape[1],\n    \" with the acurracy: \",\n    rfc.score(test_x, test_y),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SelectKBest, 5 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"m_c_k = confusion_matrix(test_y, rfck.predict(test_x_k))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_k, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)\nprint(\n    \"SelectKBest number of features: \",\n    train_x_k.shape[1],\n    \" with the acurracy: \",\n    rfck.score(test_x_k, test_y),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RFE, 5 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"m_c_rfe = confusion_matrix(test_y, rfc_aux.predict(test_x_rfe))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_rfe, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)\nprint(\n    \"RFE number of features: \",\n    train_x_rfe.shape[1],\n    \" with the acurracy: \",\n    rfc_aux.score(test_x_rfe, test_y),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RFECV, 14 features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"m_c_rfecv = confusion_matrix(test_y, rfc_aux_cv.predict(test_x_rfecv))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_rfecv, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)\nprint(\n    \"RFECV number of features: \",\n    rfc_rfecv.n_features_,\n    \" with the acurracy: \",\n    rfc_aux_cv.score(test_x_rfecv, test_y),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization by 2 components","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\npca = PCA(n_components=2)\npca_result = pca.fit_transform(normalize(x, norm=\"max\"))\ny_color = [\"red\" if el == \"M\" else \"blue\" for el in y]\n\nfig = go.Figure(\n    data=go.Scatter(\n        x=pca_result[:, 0],\n        y=pca_result[:, 1],\n        mode=\"markers\",\n        marker={\"color\": y_color},\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TSNE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\nfrom sklearn.preprocessing import normalize\nimport plotly.graph_objects as go\n\ntsne = TSNE(n_components=2)\ntsne_result = tsne.fit_transform(normalize(x, norm=\"max\"))\n\nfig = go.Figure(\n    data=go.Scatter(\n        x=tsne_result[:, 0],\n        y=tsne_result[:, 1],\n        mode=\"markers\",\n        marker={\"color\": y_color},\n    )\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tunning a Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n# Models\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n\nmodels = [\n    (\"SVC\", SVC()),\n    (\"RandomForestClassifier\", RandomForestClassifier()),\n    (\"SGDClassifier\", SGDClassifier()),\n    (\"MLPClassifier\", MLPClassifier()),\n    (\"DecisionTreeClassifier\", DecisionTreeClassifier()),\n    (\"NearestCentroid\", NearestCentroid()),\n    (\"KNeighborsClassifier\", KNeighborsClassifier()),\n]\n\n\ndef train_test_validation(model, name, X, Y):\n    print(f\"Starting {name}.\")  # Debug\n    ini = time.time()  # Start clock\n    scores = cross_val_score(model, X, Y, cv=4)  # Cross-validation\n    fim = time.time()  # Finish clock\n    print(f\"Finish {name}.\")  # Debug\n    return (name, scores.mean(), scores.max(), scores.min(), fim - ini)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nresults = [ train_test_validation(model[1], model[0], x, y) for model in models ] # Testing for all models\nresults = pd.DataFrame(results, columns=['Classifier', 'Mean', 'Max', 'Min', 'TimeSpend (s)']) # Making a data frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=2, cols=1, shared_yaxes=True)\nx_plot = results[\"Classifier\"]\ny_plot = round(results[\"Mean\"] * 100, 2)\nz_plot = round(results[\"TimeSpend (s)\"], 2)\n\n# Plots\nfig.add_trace(go.Bar(x=x_plot, y=y_plot, text=y_plot, textposition=\"auto\"), 1, 1)\nfig.add_trace(go.Bar(x=x_plot, y=z_plot, text=z_plot, textposition=\"auto\"), 2, 1)\n\nfig.update_layout(height=800, width=1000, title_text=\"Traing Models Results\")\n\n# Update xaxis properties\nfig.update_xaxes(title_text=\"Acurracy by Crossvalidation\", row=1, col=1)\nfig.update_xaxes(title_text=\"Time Spended by traing\", row=2, col=1)\n\n# Update yaxis properties\nfig.update_yaxes(title_text=\"Accurracy in percent (%)\", row=1, col=1)\nfig.update_yaxes(title_text=\"Time in seconds (s)\", row=2, col=1)\n\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=25)]\n# Number of features to consider at every split\nmax_features = [\"auto\", \"sqrt\"]\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num=25)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {\n    \"n_estimators\": n_estimators,\n    \"max_features\": max_features,\n    \"max_depth\": max_depth,\n    \"min_samples_split\": min_samples_split,\n    \"min_samples_leaf\": min_samples_leaf,\n    \"bootstrap\": bootstrap,\n}\n\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation,\n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=random_grid,\n    n_iter=300,\n    cv=3,\n    verbose=2,\n    random_state=42,\n    n_jobs=-1,\n)\n# Fit the random search model\nrf_random.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bp = dict(rf_random.best_params_)\nbp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 1234\nrandom.seed(SEED)\n\nrf_tunned = RandomForestClassifier(\n    n_estimators=bp[\"n_estimators\"],\n    min_samples_split=bp[\"min_samples_split\"],\n    min_samples_leaf=bp[\"min_samples_leaf\"],\n    max_features=bp[\"max_features\"],\n    max_depth=bp[\"max_depth\"],\n    bootstrap=bp[\"bootstrap\"],\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tunned.fit(train_x, train_y)\nrf_tunned.score(test_x, test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m_c = confusion_matrix(test_y, rf_tunned.predict(test_x))\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c_rfe, annot=True, cmap=\"Reds\", fmt=\"d\").set(\n    xlabel=\"Predict\", ylabel=\"Real\"\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}