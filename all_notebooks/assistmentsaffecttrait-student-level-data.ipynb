{"cells":[{"metadata":{"_uuid":"40729c5bfba04850d251959fabe4f01ab20f01c9"},"cell_type":"markdown","source":"# Predicting STEM Choice by Affect and Behavior in Online Mathematical Problem-Solving: Gender and Methodology Differences\n### This kernel presents the code and results of data analysis, preparation, and exploration or binning on the data set provided [ASSISTments](http://www.assistments.org) project and its \" [ASSISTments Data Mining Competition 2017](http://sites.google.com/view/assistmentsdatamining/data-mining-competition-2017)\" in the aspect of affect traits (or student-level affect and behavior).  \n### The kernels on affective states (or action-level affect and behaivor) are presented on the kernels of \n\"[AssistmentsAffectState_action-level data](https://www.kaggle.com/meishiuchiu1/assistmentsaffectstate-action-level-data)\", \"[AssistmentsAffectState_randomForestFeatureAll](http://www.kaggle.com/meishiuchiu1/assistmentsaffectstate-randomforestfeatureall)\", \"[AssistmentsAffectState_randomForestFeatureFemale](http://www.kaggle.com/meishiuchiu1/assistmentsaffectstate-randomforestfeaturefemale)\", and \"[AssistmentsAffectState_randomForestFeatureMale](http://www.kaggle.com/meishiuchiu1/assistmentsaffectstate-randomforestfeaturemale)\".\n"},{"metadata":{"trusted":true,"_uuid":"d4beb10cacce48c0531bec205cc2a3b462cae0ba"},"cell_type":"code","source":"# conventional way to import pandas\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee6c0c7d2edd504894c4b7b1e7393049270778aa","_kg_hide-input":true},"cell_type":"code","source":"#read file.\ndf = pd.read_csv('../input/anonymized_full_release_competition_dataset20181128.csv')\n#replace spaces with underscores for all columns \ndf.columns = df.columns.str.replace(' ', '_')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa01f1bb4fe0c7c27582a241252d1e6391a50141","scrolled":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5e06cba15cc09467f9107b2cf13532df320e861"},"cell_type":"markdown","source":"# data preparation"},{"metadata":{"trusted":true,"_uuid":"177b84d8a9334e81243a37c1e31e5190f498f27a"},"cell_type":"code","source":"#locate a value in a column as Nan https://stackoverflow.com/questions/45416684/python-pandas-replace-multiple-columns-zero-to-nan?rq=1\nimport numpy as np\ndf.loc[df['MCAS'] == -999.0,'MCAS'] = np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36623b0630a5d41f87d3183a28aba87b40ab66d2"},"cell_type":"code","source":"# create the 'genderFemale' dummy variable using the 'map' method\ndf['genderFemale'] = df.InferredGender.map({'Female':1, 'Male':0})\n# Removing unused columns\nlist_drop = ['InferredGender']\ndf.drop(list_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02aa228bb65391ba957463f9ca9d41aefa77adbf"},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b92827a83244e328b00170f408c9198b44a7cf1"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"066904f52dfa3ecfad6e86a919198ea481a5b1f0"},"cell_type":"code","source":"# create dummy variables for multiple categories; this drops nominal columns and creates dummy variables\ndfDummy=pd.get_dummies(df, columns=['MiddleSchoolId'], drop_first=True)\ndfDummy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e117f5f0ecac74004fbefaaa1b6417a35fa93e26","scrolled":true},"cell_type":"code","source":"#use observations only with no missing in isSTEM\ndfStem=dfDummy.dropna(subset=['isSTEM'], how='any')\ndfStem.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cac5cb6ceadc929a57c64b2263ee58026a39c1ec"},"cell_type":"code","source":"#locate columns with the data type of object\ndfStem.loc[:, dfStem.dtypes == 'object'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9748af380fe3c10904b5470291f5926795a25f26"},"cell_type":"code","source":"# use means to transform df to student level data\nstud = dfStem.groupby('studentId').mean()\nstud.shape # from 84 to 78 columns due to delete object columns and 'isSTEM'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ed2729360939d2f572e7003dca87f719ba249c0"},"cell_type":"code","source":"stud.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ac0bb7a32aa8545a0f2292f4da785c24165a801"},"cell_type":"markdown","source":"# Regression: data preparation\nreferences\nhttps://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb\nhttps://stackoverflow.com/questions/29763620/how-to-select-all-columns-except-one-column-in-pandas/29763653\n##missing data (no missing data needed in logistic regression)\nhttps://www.analyticsindiamag.com/5-ways-handle-missing-values-machine-learning-datasets/"},{"metadata":{"trusted":true,"_uuid":"24d5b2372f092d93db2ee1277f2fda21fc6bb901"},"cell_type":"code","source":"#Find column names with missing data because sklearn does not allow missing data\nstud.columns[stud.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe29da8fd2cbb7352fdc882188934f9c4bd6e879"},"cell_type":"code","source":"# impute MCAS missing values with median\nMCAS_median = np.nanmedian(stud['MCAS'])\nnew_MCAS = np.where(stud['MCAS'].isnull(), MCAS_median, stud['MCAS'])\nstud['MCAS'] = new_MCAS\nstud.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fea4ce0b2c747599bb35badd4a2419a498971df0"},"cell_type":"markdown","source":"# correlation"},{"metadata":{"trusted":true,"_uuid":"3cda35545f1c7b7d6fbc56b002218dc18c20ba7b"},"cell_type":"code","source":"feature_colsCor= [\n  'isSTEM',\n 'AveResBored',\n 'AveResEngcon',\n 'AveResConf',\n 'AveResFrust',\n 'AveResOfftask',\n 'AveResGaming']\ncorrAll = stud[feature_colsCor]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e636f2f1d4a6f4a5534af5ffc16820353a831ed0"},"cell_type":"code","source":"from scipy.stats import pearsonr\nimport pandas as pd\n\ndef calculate_pvalues(df):\n    df = df.dropna()._get_numeric_data()\n    dfcols = pd.DataFrame(columns=df.columns)\n    pvalues = dfcols.transpose().join(dfcols, how='outer')\n    for r in df.columns:\n        for c in df.columns:\n            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n    return pvalues\n\nrho = corrAll.corr()\nrho = rho.round(4)\npval = calculate_pvalues(corrAll) \n# create three masks\nr1 = rho.applymap(lambda x: '{}*'.format(x))\nr2 = rho.applymap(lambda x: '{}**'.format(x))\n# apply them where appropriate\nrho = rho.mask(pval< 0.05,r1)\nrho = rho.mask(pval< 0.01,r2)\nrho","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70978e088aef950bbc2382f2a9a752234f438648"},"cell_type":"code","source":"#reference: http://seaborn.pydata.org/tutorial/distributions.html\nimport seaborn as sns\nsns.pairplot(corrAll); #corrAll = stud[feature_colsCor]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34ad0e068aa10bf0de26d5e51bcea2185e77c8bc"},"cell_type":"code","source":"corrAll.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"267bad3fccfb96044d2fc81199b98811e1341079"},"cell_type":"code","source":"corrAll.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0328a425a5076c26fabf8e4077a61ea36c51a4e"},"cell_type":"code","source":"corrAll.kurt()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91c51dd8df2e4abf9761ef99a7c4655be2b06801"},"cell_type":"markdown","source":"# Regression: seclect needed features"},{"metadata":{"trusted":true,"_uuid":"c3e90e42c87906661397094e2d63276ffaf672f5"},"cell_type":"code","source":"# list(stud) to copy column names\nfeature_cols = [\n 'AveResBored',\n 'AveResEngcon',\n 'AveResConf',\n 'AveResFrust',\n 'AveResOfftask',\n 'AveResGaming']\nX = stud[feature_cols]\ny = stud.isSTEM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2a201b362ea855fbea84aaf11dc4624b2a57280"},"cell_type":"code","source":"#Find column names with missing data because sklearn does not allow missing data\nX.columns[X.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8beeb729fb5b0cae8f911654e71a04a56ba225dd"},"cell_type":"markdown","source":"# Regression"},{"metadata":{"trusted":true,"_uuid":"7dbc994b55845ed879e55b06e4248c3ab931c072"},"cell_type":"code","source":"#Compute linear regression standardized coefficient (beta) with Python\n#https://stackoverflow.com/questions/33913868/compute-linear-regression-standardized-coefficient-beta-with-python\nimport statsmodels.api as sm\nfrom scipy.stats.mstats import zscore","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d797397f03c506055bb647145b77f616e51a622"},"cell_type":"markdown","source":"# logit regression for all predictors"},{"metadata":{"trusted":true,"_uuid":"20b700b3cd9663dc708e51007e1e85c7ea17e425"},"cell_type":"code","source":"#logistic regression result is ok.\nlogit = sm.Logit(y, X).fit()\nlogit.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50b842733ef75fcb9af174ecbaed0852f0eeb4a5"},"cell_type":"code","source":"#odds ratio with conf. intervals; odds ratio as effect sizes; results hard to explain with relative importance\nparams = logit.params\nconf = logit.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9177123b67c59112246ecf9bc1ced19646f2717f"},"cell_type":"code","source":"#negative pseudo R-square, cannot do y2 = zscore(y)\nXz = zscore(X)\nlogitXz = sm.Logit(y, Xz).fit()\nlogitXz.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c87acb6c0db7ee516c9d880aa77a4e1f081f2c0f"},"cell_type":"code","source":"#odds ratio with conf. intervals; odds ratio as effect sizes; results hard to explain with relative importance\nparams = logitXz.params\nconf = logitXz.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d57358b62b653142db4e888e3a3a3b98dac4068a"},"cell_type":"markdown","source":"# Logit regression for individual predictor_raw score\n"},{"metadata":{"trusted":true,"_uuid":"8b4dd6b5d2a31bcfb0bc3ee289b0fc652e2c6d47"},"cell_type":"code","source":"logit1 = sm.Logit(y, stud.AveResBored).fit()\nlogit1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"123b5c2c1b0476eb9a1aa1121204b9c15f7ef16b"},"cell_type":"code","source":"#odds ratio with conf. intervals; OR hard to explain\nparams = logit1.params\nconf = logit1.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c70abe88f27ca0bb7dc87ddb4b88501db4d13f0"},"cell_type":"code","source":"logit2 = sm.Logit(y, stud.AveResEngcon).fit() # significant but negative, not good because Engcon is positive in meaning.\nlogit2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"646927ad57120c90ae412f89701fd3222ae3b26d"},"cell_type":"code","source":"#odds ratio with conf. intervals; OR hard to explain\nparams = logit2.params\nconf = logit2.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11acca77618d38ccf386e4a32a152a7480c19133"},"cell_type":"code","source":"logit3 = sm.Logit(y, stud.AveResConf).fit()\nlogit3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5d36bbd7c3c84fc444f5aa3c0b82533d11a38ad"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit3.params\nconf = logit3.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d1e99dd7816da4e663c5d90273949568a0263f7"},"cell_type":"code","source":"logit4 = sm.Logit(y, stud.AveResFrust).fit()\nlogit4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc3c00c66178996bf02f49a397a11d8f2c10fd15"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit4.params\nconf = logit4.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c56b1a4e2199aee894ab60593c21fa225234bea"},"cell_type":"code","source":"logit5 = sm.Logit(y, stud.AveResOfftask).fit()\nlogit5.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2708d8ab36ce89c8a6e766935365afa0d44aaf70"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit5.params\nconf = logit5.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffbde8870498bdcd104215f7b89d3e5ce026e3ff"},"cell_type":"code","source":"logit6 = sm.Logit(y, stud.AveResGaming).fit()\nlogit6.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8e31ba1de8b15392ed0c47282a45b5e60953143"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit6.params\nconf = logit6.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31c7e5acc07f623451d6d33b65b0993ee3df27a5"},"cell_type":"markdown","source":"# Logit regression for individual predictor_zscore(predictor)\n### negative pseudo r-squared; no significant regression coefficients"},{"metadata":{"trusted":true,"_uuid":"89f60c5a63886fc313519b4162ced4e8a258087e"},"cell_type":"code","source":"logit1z = sm.Logit(y, zscore(stud.AveResBored)).fit()\nlogit1z.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a858719d088396be7077cdd7ae15b34d2ce850d4"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit1z.params\nconf = logit1z.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5df23d5c853f47f58dbaf5524869f2aaa5cacec"},"cell_type":"code","source":"logit2z = sm.Logit(y, zscore(stud.AveResEngcon)).fit()\nlogit2z.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c9d2e9e34ebb451408480b7d6c75d74928f2448"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit2z.params\nconf = logit2z.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"857f6c8ee9bbe5f93c8413eda4d1ae7306b04b76"},"cell_type":"code","source":"logit3z = sm.Logit(y, zscore(stud.AveResConf)).fit()\nlogit3z.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21b5e6396bac93de87e1a4e65342cdb33e8c9145"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit3z.params\nconf = logit3z.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"299140ca4589cdea872abdcc4d1548f4ebb0f6eb"},"cell_type":"code","source":"logit4z = sm.Logit(y, zscore(stud.AveResFrust)).fit()\nlogit4z.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73b9af52cb7b16510eed728f4f5bc9fa91e01004"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit4z.params\nconf = logit4z.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"369c8882608f8adaeb5800dd47d255b06393a9de"},"cell_type":"code","source":"logit5z = sm.Logit(y, zscore(stud.AveResOfftask)).fit()\nlogit5z.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cad48216c64612007440ebc0b6fe1b69a16323bc"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit5z.params\nconf = logit5z.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4233d1dbaa6714e49134d829ccfdd10116b59751"},"cell_type":"code","source":"logit6z = sm.Logit(y, zscore(stud.AveResGaming)).fit()\nlogit6z.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4622e6b092198205a85ac20f9a31f058ba4f69d"},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logit6z.params\nconf = logit6z.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c41e8bf823837eda5627f9768872ac75fd150898"},"cell_type":"markdown","source":"# OLS regression for all predictors together\n### raw score of y and X: positive concentrating; negative gaming\n### zscore of both y and X as effect sizes; negative gaming: same results as logit regression"},{"metadata":{"trusted":true,"_uuid":"327cf0067f3dc1d3906bf7f417712ded98858a31"},"cell_type":"code","source":"sm.OLS(y, X).fit().summary() # large R-squared, go for this because also good result for individual predictor OLS result ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37c04cc5e8cb81af7e354311237e4405751ec424"},"cell_type":"code","source":"# as effect size measures\nXz = zscore(X)\nyz = zscore(y)\norzxy = sm.OLS(yz, Xz).fit()\norzxy.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b253025a62ec7ed8321076868506221bfa68066b"},"cell_type":"code","source":"orzx = sm.OLS(y, Xz).fit() #lower Adj. R-squared than both y and x zscore-->no use\norzx.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3974351b646ef9587af73b92db2ced9c3b8bd9fa"},"cell_type":"markdown","source":"# OLS regression for individual predictor_raw score"},{"metadata":{"trusted":true,"_uuid":"a1cfde85c600b6c0d04beccd380694f2e7156d0d"},"cell_type":"code","source":"sm.OLS(y, stud.AveResBored).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34a1f6c48925b3bf4ce56e9a799e47a6299dbe17"},"cell_type":"code","source":"sm.OLS(y, stud.AveResEngcon).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a57f79b0d063753e1aea1bbe6e18d4d95f510fdf"},"cell_type":"code","source":"sm.OLS(y, stud.AveResConf).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5304470c0f4deb34ed83ed9dd3f8523621a85603"},"cell_type":"code","source":"sm.OLS(y, stud.AveResFrust).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e7335fdd66f3f02ef659ce759c54755a222e531"},"cell_type":"code","source":"sm.OLS(y, stud.AveResOfftask).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b94c7d2747ee93d955650c133880601e3b07a7be"},"cell_type":"code","source":"sm.OLS(y, stud.AveResGaming).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4eac9ce4eb41ed21867f787d215856e92b601d92"},"cell_type":"code","source":"sm.OLS(y, zscore(stud.AveResBored)).fit().summary() # zscore x1 with negative adj. r-squared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba24cafd13434e00e9ffbac262213ab2c4cca672"},"cell_type":"code","source":"sm.OLS(zscore(y), zscore(stud.AveResBored)).fit().summary() \n# zscore y and x1 with negative adj. r-squared; same value as correlation between y and x1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7c003817424909d6f4bc6d543807a96be82f608"},"cell_type":"markdown","source":"# OLS regression for individual predictor_zscore\n"},{"metadata":{"trusted":true,"_uuid":"4aaae31d94bb345f26ce90f20eefe6435ff933ca"},"cell_type":"code","source":"sm.OLS(zscore(y), zscore(stud.AveResBored)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44e071197ff8f7aa9eb5d8098c7c1141e09ad781"},"cell_type":"code","source":"sm.OLS(zscore(y), zscore(stud.AveResEngcon)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1821ef7411945618cba20d234d5ce6d1c01d3275"},"cell_type":"code","source":"sm.OLS(zscore(y), zscore(stud.AveResConf)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81671b493d9f02e6be5313010c40cb1195babd83"},"cell_type":"code","source":"sm.OLS(zscore(y), zscore(stud.AveResFrust)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1bd784784d72710a9d1782f65e5137f002761ff"},"cell_type":"code","source":"sm.OLS(zscore(y), zscore(stud.AveResOfftask)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a288a0a80f4b14511f4cdaf8563d98852154442d"},"cell_type":"code","source":"sm.OLS(zscore(y), zscore(stud.AveResGaming)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"273fbc4545eb7e5212e39dd31885969cdf830f4d"},"cell_type":"markdown","source":"# random forest: feature selection"},{"metadata":{"trusted":true,"_uuid":"cd4a9c041fff3b90b690eb313e3d6a2072f78bb5"},"cell_type":"code","source":"!pip install eli5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3c8822fdd90af7db80c901f132c85a4470942be"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nmy_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)\n#https://www.kaggle.com/dansbecker/permutation-importance?utm_medium=email&utm_source=mailchimp&utm_campaign=ml4insights\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, feature_names = val_X.columns.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e7367db3cf90d8a2d74791e91c76e87b88c709c"},"cell_type":"code","source":"import shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(my_model)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_values = explainer.shap_values(val_X)\n\n# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_values[1], val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf02039631b41ec2189c224a9fb542e937c7bd24"},"cell_type":"markdown","source":"# ROC and AUC: Logit regression"},{"metadata":{"trusted":true,"_uuid":"338262a45ed5bdfb027261fa12d4f7bbe54e64f3"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_predict = model.predict(X_test)\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\ny_predict_probabilities = model.predict_proba(X_test)[:,1]\n\nfpr, tpr, _ = roc_curve(y_test, y_predict_probabilities)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange',\n         lw=2, label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"578c10f35af04258da52402be8f551699937942e"},"cell_type":"markdown","source":"## ROC and AUC: Random Forest"},{"metadata":{"trusted":true,"_uuid":"933eba8454beb3c31b2c06ac22abbcf4a3bf4fab"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nmy_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)\nval_y = my_model.predict(train_X)\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\ny_predict_probabilities2 = model.predict_proba(train_X)[:,1]\n\nfpr2, tpr2, _ = roc_curve(val_y, y_predict_probabilities2)\nroc_auc2 = auc(fpr2, tpr2)\n\nplt.figure()\nplt.plot(fpr2, tpr2, color='darkorange',\n         lw=2, label='ROC curve (area = %0.3f)' % roc_auc2)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0209d531b506336df7d73b375284886e3adca846"},"cell_type":"code","source":"#random forest: too high accuracy and R-squared\n#https://www.kaggle.com/shrutimechlearn/step-by-step-assumptions-linear-regression?utm_medium=email&utm_source=intercom&utm_campaign=datanotes-2019\nfrom sklearn.metrics import r2_score\n\nrf_tree = RandomForestClassifier(random_state=0)\nrf_tree.fit(X,y)\nrf_tree_y_pred = rf_tree.predict(X)\nprint(\"Accuracy: {}\".format(rf_tree.score(X,y)))\nprint(\"R squared: {}\".format(r2_score(y_true=y,y_pred=rf_tree_y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8ea191f2b2c82c0723f7fb4e93f1f57750523ef"},"cell_type":"markdown","source":"# group females vs. males"},{"metadata":{"trusted":true,"_uuid":"4fbebc55b0604dfdfe51599d6ff647ac93c0d9dd"},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b571ac63956901f89af219443f0de13df7ed748"},"cell_type":"code","source":"female=stud[stud.genderFemale == 1]\nmale=stud[stud.genderFemale == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"634fc2a2023a6ef46c15e9d90fe8cad225fb7f10"},"cell_type":"code","source":"female.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ebbba66a3b3dde2d99f6162d284186b02eabca3"},"cell_type":"code","source":"male.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7baa7cca61348f6e30bdafdb24a52c298cbf3a2"},"cell_type":"markdown","source":"# female correlation"},{"metadata":{"trusted":true,"_uuid":"3b028f64d9f0cbd2e2425fc909993d286ba054ea"},"cell_type":"code","source":"corrF = female[feature_colsCor]\nrho = corrF.corr()\nrho = rho.round(4)\npval = calculate_pvalues(corrF) \n# create three masks\nr1 = rho.applymap(lambda x: '{}*'.format(x))\nr2 = rho.applymap(lambda x: '{}**'.format(x))\n# apply them where appropriate\nrho = rho.mask(pval< 0.05,r1)\nrho = rho.mask(pval< 0.01,r2)\nrho","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"053fa4a56b98f2d795cff2d34ab9da93ebc07628"},"cell_type":"markdown","source":"# female regression"},{"metadata":{"trusted":true,"_uuid":"ee68ea0153a86934c9bb11998ff1e8d5822b84be"},"cell_type":"code","source":"feature_colsF = [\n 'AveResBored',\n 'AveResEngcon',\n 'AveResConf',\n 'AveResFrust',\n 'AveResOfftask',\n 'AveResGaming']\nXF = female[feature_colsF]\nyF = female.isSTEM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"574971a42152339e04359d499b2b24f0086dfd21"},"cell_type":"code","source":"#Compute linear regression standardized coefficient (beta) with Python\n#https://stackoverflow.com/questions/33913868/compute-linear-regression-standardized-coefficient-beta-with-python\nimport statsmodels.api as sm\nfrom scipy.stats.mstats import zscore\n\n#logistic regression result is ok.\nlogitF = sm.Logit(yF, XF).fit()\nlogitF.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af93f309be42aaf97040893a025e93a84c8e60cb"},"cell_type":"code","source":"#odds ratio with conf. intervals; results hard to explain with relative importance\nparams = logitF.params\nconf = logitF.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## female_Logit regression for individual predictor_raw score"},{"metadata":{"trusted":true},"cell_type":"code","source":"logitF1 = sm.Logit(yF, female.AveResBored).fit()\nlogitF1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitF1.params\nconf = logitF1.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitF2 = sm.Logit(yF, female.AveResEngcon).fit()\nlogitF2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitF2.params\nconf = logitF2.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitF3 = sm.Logit(yF, female.AveResConf).fit()\nlogitF3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitF3.params\nconf = logitF3.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitF4 = sm.Logit(yF, female.AveResFrust).fit()\nlogitF4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitF4.params\nconf = logitF4.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitF5 = sm.Logit(yF, female.AveResOfftask).fit()\nlogitF5.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitF5.params\nconf = logitF5.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitF6 = sm.Logit(yF, female.AveResGaming).fit()\nlogitF6.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitF6.params\nconf = logitF6.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# female_OLS regression for all predictors together"},{"metadata":{"trusted":true,"_uuid":"061159adde17826e7e9a2330bb8989c87b719261"},"cell_type":"code","source":"sm.OLS(yF, XF).fit().summary()#sig: concentrate positive; game negative ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8581557e44e4a242d8ea978a37993a3ae708d157"},"cell_type":"code","source":"sm.OLS(zscore(yF), zscore(XF)).fit().summary() # as effect sizes --> x2 become negative and non-significant-->hard to explain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## female_OLS regression for individual predictor_zscore"},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yF), zscore(female.AveResBored)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yF), zscore(female.AveResEngcon)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yF), zscore(female.AveResConf)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yF), zscore(female.AveResFrust)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yF), zscore(female.AveResOfftask)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yF), zscore(female.AveResGaming)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ff71751f40f0174299fd8af0d356b8bc645ea8e"},"cell_type":"markdown","source":"# female feature seleciton"},{"metadata":{"trusted":true,"_uuid":"8d0d432c058ac3e0ce9455ae1a47e091e90b8b52"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_XF, val_XF, train_yF, val_yF = train_test_split(XF, yF, random_state=1)\nmy_modelF = RandomForestClassifier(random_state=0).fit(train_XF, train_yF)\npermF = PermutationImportance(my_modelF, random_state=1).fit(val_XF, val_yF)\neli5.show_weights(permF, feature_names = val_XF.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3108ea998e1c47d520018bedbf07867a521e8b77"},"cell_type":"code","source":"import shap  # package used to calculate Shap values\n# Create object that can calculate shap values\nexplainerF = shap.TreeExplainer(my_modelF)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_valuesF = explainer.shap_values(val_XF)\n\n# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_valuesF[1], val_XF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"865e9c2a405b5b1fff80e20afb11a4917108ae61"},"cell_type":"code","source":"# Female_ROC and AUC: Logit regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nXF_train, XF_test, yF_train, yF_test = train_test_split(XF, yF, random_state=1)\n\nmodelF = LogisticRegression()\nmodelF.fit(XF_train, yF_train)\n\ny_predictF = model.predict(XF_test)\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\ny_predict_probabilitiesF = modelF.predict_proba(XF_test)[:,1]\n\nfprF, tprF, _ = roc_curve(yF_test, y_predict_probabilitiesF)\nroc_aucF = auc(fprF, tprF)\n\nplt.figure()\nplt.plot(fprF, tprF, color='darkorange',\n         lw=2, label='ROC curve (area = %0.3f)' % roc_aucF)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f7269a73b68f695cb736e9c4b90f698ee649de3"},"cell_type":"code","source":"#Female_ROC and AUC: Random Forest\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_XF, val_XF, train_yF, val_yF = train_test_split(XF, yF, random_state=1)\nmy_modelF = RandomForestClassifier(random_state=0).fit(train_XF, train_yF)\nval_yF = my_modelF.predict(train_XF)\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\ny_predict_probabilities2F = model.predict_proba(train_XF)[:,1]\n\nfpr2F, tpr2F, _ = roc_curve(val_yF, y_predict_probabilities2F)\nroc_auc2F = auc(fpr2F, tpr2F)\n\nplt.figure()\nplt.plot(fpr2F, tpr2F, color='darkorange',\n         lw=2, label='ROC curve (area = %0.3f)' % roc_auc2F)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3039345afd72210af72e13e6195ce6c3404514fe"},"cell_type":"markdown","source":"# male correlation"},{"metadata":{"trusted":true,"_uuid":"acbbec15df8b1135aab89c60786bdcf3fa8acca7"},"cell_type":"code","source":"corrM = male[feature_colsCor]\nrho = corrM.corr()\nrho = rho.round(4)\npval = calculate_pvalues(corrM) \n# create three masks\nr1 = rho.applymap(lambda x: '{}*'.format(x))\nr2 = rho.applymap(lambda x: '{}**'.format(x))\n# apply them where appropriate\nrho = rho.mask(pval< 0.05,r1)\nrho = rho.mask(pval< 0.01,r2)\nrho","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbe4f435d91dd517c4130d79266d800a2cafd4d8"},"cell_type":"markdown","source":"# male regression"},{"metadata":{"trusted":true,"_uuid":"0d8974f3ecefe323001d94578ff2f02301de60a2"},"cell_type":"code","source":"feature_colsM = [\n 'AveResBored',\n 'AveResEngcon',\n 'AveResConf',\n 'AveResFrust',\n 'AveResOfftask',\n 'AveResGaming']\nXM = male[feature_colsM]\nyM = male.isSTEM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d94fc783e6b24cd2a76e5ce8253cdae92fcd5e37"},"cell_type":"code","source":"#Compute linear regression standardized coefficient (beta) with Python\n#https://stackoverflow.com/questions/33913868/compute-linear-regression-standardized-coefficient-beta-with-python\nimport statsmodels.api as sm\nfrom scipy.stats.mstats import zscore\n\n#logistic regression result: no significant predictors\nlogitM = sm.Logit(yM, XM).fit()\nlogitM.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe0b53da3b4641695e0f1211f4c65fdb4068ba8e"},"cell_type":"code","source":"#odds ratio with conf. intervals; results hard to explain with relative importance\nparams = logitM.params\nconf = logitM.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## male_Logit regression for individual predictor_raw score"},{"metadata":{"trusted":true},"cell_type":"code","source":"logitM1 = sm.Logit(yM, male.AveResBored).fit()\nlogitM1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitM1.params\nconf = logitM1.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitM2 = sm.Logit(yM, male.AveResEngcon).fit()\nlogitM2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitM2.params\nconf = logitM2.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitM3 = sm.Logit(yM, male.AveResConf).fit()\nlogitM3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitM3.params\nconf = logitM3.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitM4 = sm.Logit(yM, male.AveResFrust).fit()\nlogitM4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitM4.params\nconf = logitM4.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitM5 = sm.Logit(yM, male.AveResOfftask).fit()\nlogitM5.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitM5.params\nconf = logitM5.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logitM6 = sm.Logit(yM, male.AveResGaming).fit()\nlogitM6.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#odds ratio with conf. intervals\nparams = logitM6.params\nconf = logitM6.conf_int()\nconf['OR'] = params\nconf.columns = ['2.5%', '97.5%', 'OR']\nnp.exp(conf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# male_OLS regression for all predictors together"},{"metadata":{"trusted":true,"_uuid":"f9682d1887b13494e930f0065e076f47f2ad1859"},"cell_type":"code","source":"sm.OLS(yM, XM).fit().summary() #all non-significant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff5911622efcc8256545d685f881842bcf268ce4"},"cell_type":"code","source":"sm.OLS(zscore(yM), zscore(XM)).fit().summary() # as effect sizes, all non-significant","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## male_OLS regression for individual predictor_zscore"},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yM), zscore(male.AveResBored)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yM), zscore(male.AveResEngcon)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yM), zscore(male.AveResConf)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yM), zscore(male.AveResFrust)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yM), zscore(male.AveResOfftask)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.OLS(zscore(yM), zscore(male.AveResGaming)).fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e33a840d79dce86b29da320c483c29fbab896edd"},"cell_type":"markdown","source":"# male feature seleciton"},{"metadata":{"trusted":true,"_uuid":"14c4e23b590528aeeeeeb3513821c8d7cb858bc7"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_XM, val_XM, train_yM, val_yM = train_test_split(XM, yM, random_state=1)\nmy_modelM = RandomForestClassifier(random_state=0).fit(train_XM, train_yM)\npermM = PermutationImportance(my_modelM, random_state=1).fit(val_XM, val_yM)\neli5.show_weights(permM, feature_names = val_XM.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52f57e33d5522144a8427b1d74641492ce7ed2bb"},"cell_type":"code","source":"import shap \n# Create object that can calculate shap values\nexplainerM = shap.TreeExplainer(my_modelM)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_valuesM = explainer.shap_values(val_XM)\n\n# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_valuesM[1], val_XM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13312cd6da494b022f097735194114f83359fef1"},"cell_type":"code","source":"# Male_ROC and AUC: Logit regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nXM_train, XM_test, yM_train, yM_test = train_test_split(XM, yM, random_state=1)\n\nmodelM = LogisticRegression()\nmodelM.fit(XM_train, yM_train)\n\ny_predictM = model.predict(XM_test)\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\ny_predict_probabilitiesM = modelM.predict_proba(XM_test)[:,1]\n\nfprM, tprM, _ = roc_curve(yM_test, y_predict_probabilitiesM)\nroc_aucM = auc(fprM, tprM)\n\nplt.figure()\nplt.plot(fprM, tprM, color='darkorange',\n         lw=2, label='ROC curve (area = %0.3f)' % roc_aucM)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6a5f3a43f1276ede9abb3bf97d9be60e3231c4b"},"cell_type":"code","source":"#Male_ROC and AUC: Random Forest\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_XM, val_XM, train_yM, val_yM = train_test_split(XM, yM, random_state=1)\nmy_modelM = RandomForestClassifier(random_state=0).fit(train_XM, train_yM)\nval_yM = my_modelM.predict(train_XM)\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\ny_predict_probabilities2M = model.predict_proba(train_XM)[:,1]\n\nfpr2M, tpr2M, _ = roc_curve(val_yM, y_predict_probabilities2M)\nroc_auc2M = auc(fpr2M, tpr2M)\n\nplt.figure()\nplt.plot(fpr2M, tpr2M, color='darkorange',\n         lw=2, label='ROC curve (area = %0.3f)' % roc_auc2M)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# multicollinearity checking VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Writing a function to calculate the VIF values; https://statinfer.com/204-1-9-issue-of-multicollinearity-in-python/\nimport statsmodels.formula.api as sm\ndef vif_cal(input_data, dependent_col):\n    x_vars=input_data.drop([dependent_col], axis=1)\n    xvar_names=x_vars.columns\n    for i in range(0,xvar_names.shape[0]):\n        y=x_vars[xvar_names[i]] \n        x=x_vars[xvar_names.drop(xvar_names[i])]\n        rsq=sm.ols(formula=\"y~x\", data=x_vars).fit().rsquared  \n        vif=round(1/(1-rsq),3)\n        print (xvar_names[i], \" VIF = \" , vif)#Calculating VIF values using that function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif_cal(input_data=corrAll, dependent_col=\"isSTEM\") #all student data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif_cal(input_data=corrF, dependent_col=\"isSTEM\") #female data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif_cal(input_data=corrM, dependent_col=\"isSTEM\") #male data","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}