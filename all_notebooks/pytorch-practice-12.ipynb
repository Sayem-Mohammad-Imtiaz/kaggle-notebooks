{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-resnet18-mnist.ipynb)\n\n## Code Modules, Classes, & Functions\n\n[GoogleColaboratory Variant](https://colab.research.google.com/drive/1OBmekkzdgivSLrJq_6HTtHZKc5ZNXbqX)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nfrom torch.utils.data.dataset import Subset\nimport tensorflow.image as timage\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def display_examples(data_loader,img_size):\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(11,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size),\n                      cmap=pl.cm.bone)\n        break","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()/num_examples*100\n@register_line_magic\ndef print_acc(n):\n    if int(n)==1:\n        data_loader=\\\n        [train_loader,valid_loader,test_loader]\n    if int(n)==2:\n        data_loader=\\\n        [train_loader2,valid_loader2,test_loader2]\n    print('Train accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[0])))\n    print('Valid accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[1])))\n    print('Test accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[2])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"random_seed=12; batch_size=128\ntr0=(.5); tr1=(.25); img_size=28\ntrans=transforms\\\n.Compose([transforms.Resize((img_size,img_size)),\n          transforms.ToTensor(),\n          transforms.Normalize(tr0,tr1)])\ntrain_ids=torch.arange(0,54000)\nvalid_ids=torch.arange(54000,60000)\ntrain_valid=tmnist(root='data',train=True,\n                   download=True,transform=trans)\ntrain=Subset(train_valid,train_ids)\nvalid=Subset(train_valid,valid_ids)\ntest=tmnist(root='data',train=False, \n            transform=trans)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\nvalid_loader=tdl(dataset=valid,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_examples(valid_loader,img_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=1-np.array(f[keys[1]],dtype='float32')/255\nx=timage.resize(x,[img_size,img_size])\nx=(np.dot(x.numpy(),[.299,.587,.114]))\\\n.reshape(-1,1,img_size,img_size)\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\nrandom_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\nvalid2=TData(x_valid,y_valid)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,shuffle=True,\n                  batch_size=batch_size2)\nvalid_loader2=tdl(dataset=valid2,shuffle=True,\n                  batch_size=batch_size2)\ntest_loader2=tdl(dataset=test2,shuffle=False,\n                 batch_size=batch_size2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_examples(valid_loader2,img_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ResNet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv3x3(in_planes,out_planes,stride=1):\n    return tnn.Conv2d(in_planes,out_planes,\n                      kernel_size=3,stride=stride,\n                      padding=1,bias=False)\nclass BasicBlock(tnn.Module):\n    expansion=1\n    def __init__(self,inplanes,planes,\n                 stride=1,downsample=None):\n        super(BasicBlock,self).__init__()\n        self.conv1=conv3x3(inplanes,planes,stride)\n        self.bn1=tnn.BatchNorm2d(planes)\n        self.relu=tnn.ReLU(inplace=True)\n        self.conv2=conv3x3(planes,planes)\n        self.bn2=tnn.BatchNorm2d(planes)\n        self.downsample=downsample\n        self.stride=stride\n    def forward(self,x):\n        residual=x\n        y=self.conv1(x); y=self.bn1(y)\n        y=self.relu(y)\n        y=self.conv2(y); y=self.bn2(y)\n        if self.downsample is not None:\n            residual=self.downsample(x)\n        y+=residual\n        y=self.relu(y)\n        return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNet(tnn.Module):\n    def __init__(self,block,layers,num_classes,grayscale):\n        self.inplanes=64\n        if grayscale: in_dim=1\n        else: in_dim=3\n        super(ResNet,self).__init__()\n        self.conv1=tnn\\\n        .Conv2d(in_dim,64,kernel_size=7,stride=2,\n                padding=3,bias=False)\n        self.bn1=tnn.BatchNorm2d(64)\n        self.relu=tnn.ReLU(inplace=True)\n        self.maxpool=tnn\\\n        .MaxPool2d(kernel_size=3,stride=2,padding=1)\n        self.layer1=self._make_layer(block,64,layers[0])\n        self.layer2=self._make_layer(block,128,\n                                     layers[1],stride=2)\n        self.layer3=self._make_layer(block,256,\n                                     layers[2],stride=2)\n        self.layer4=self._make_layer(block,512,\n                                     layers[3],stride=2)\n        self.avgpool=tnn.AvgPool2d(7,stride=1)\n        self.fc=tnn.Linear(512*block.expansion,num_classes)\n        for m in self.modules():\n            if isinstance(m,tnn.Conv2d):\n                n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n                m.weight.data.normal_(0,(2./n)**.5)\n            elif isinstance(m,tnn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n    def _make_layer(self,block,planes,blocks,stride=1):\n        downsample=None\n        if stride!=1 or self.inplanes!=planes*block.expansion:\n            downsample=tnn.Sequential(\n                tnn.Conv2d(self.inplanes,planes*block.expansion,\n                           kernel_size=1,stride=stride,bias=False),\n                tnn.BatchNorm2d(planes*block.expansion))\n        layers=[]\n        layers.append(block(self.inplanes,planes,\n                            stride,downsample))\n        self.inplanes=planes*block.expansion\n        for i in range(1,blocks):\n            layers.append(block(self.inplanes,planes))\n        return tnn.Sequential(*layers)\n    def forward(self,x):\n        x=self.conv1(x); x=self.bn1(x)\n        x=self.relu(x); x=self.maxpool(x)\n        x=self.layer1(x)\n        x=self.layer2(x)\n        x=self.layer3(x)\n        x=self.layer4(x)\n#        x=self.avgpool(x)        \n        x=x.view(x.size(0),-1)\n        logits=self.fc(x)\n        probs=tnnf.softmax(logits,dim=1)\n        return logits,probs\ndef ResNN(num_classes):\n    model=ResNet(block=BasicBlock,layers=[2,2,2,2],\n                num_classes=num_classes,\n                grayscale=True)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%200:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)//batch_size,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader),\n                   model_acc(model,valid_loader)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(random_seed)\nnum_classes=10; learning_rate=.001\nmodel=ResNN(num_classes)\nmodel.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run 55","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc 1","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets.long())\n            optimizer2.zero_grad(); cost.backward()\n            optimizer2.step()\n            if not batch_ids%50:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)//batch_size2,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader2),\n                   model_acc(model,valid_loader2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(random_seed)\nnum_classes=33; learning_rate=.001\nmodel=ResNN(num_classes)\nmodel.to(dev)\noptimizer2=torch.optim.Adam(model.parameters(),\n                            lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run2 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc 2","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}