{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns \nimport spacy \nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation,  PCA, NMF\nimport random ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/covid19-public-media-dataset/covid19_articles_20200512.csv',index_col='Unnamed: 0')\n\ndf2 = pd.read_csv('/kaggle/input/covid19-public-media-dataset/covid19_articles_20200526.csv',index_col='Unnamed: 0')\ndf2.head()\n\ndf3 = pd.read_csv('/kaggle/input/covid19-public-media-dataset/covid19_articles_20200504.csv',index_col='Unnamed: 0')\ndf3.head()\n\n# concatenating sources \ndf = pd.concat([df,df2,df3],ignore_index=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize sources and their counts \norder_by = df['domain'].value_counts().index\nsns.catplot(data=df,x='domain',kind='count',aspect=3,order=order_by)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# topic areas\n# here we can see 7 topic_areas, where general category is in majority \norder_by = df['topic_area'].value_counts().index\nsns.catplot(kind='count',x='topic_area',aspect=3,data=df,order=order_by)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dates aggregation \ndf.date.value_counts().sort_index().plot()\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm',disable=['parser','ner','tokenizer'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://www.kaggle.com/jannalipenkova/covid-19-media-overview\nRELEVANT_POS_TAGS = [\"PROPN\", \"VERB\", \"NOUN\", \"ADJ\"]\n\nCUSTOM_STOPWORDS = [\"say\", \"%\", \"will\", \"new\", \"would\", \"could\", \"other\", \n                    \"tell\", \"see\", \"make\", \"-\", \"go\", \"come\", \"can\", \"do\", \n                    \"such\", \"give\", \"should\", \"must\", \"use\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Preprocessing \ndef preprocess(txt):\n  '''\n  Take text pass through spacy's pipeline \n  Normalize text using remove stopwords from CUSTOM_STOPWORDS, take words which are RELEVENT_POS_TAGS and\n  take lemma and use that in smaller version of alphabet\n  '''\n  doc = nlp(txt)\n  rel_tokens = \" \".join([tok.lemma_.lower() for tok in doc if tok.pos_ in RELEVANT_POS_TAGS and tok.lemma_.lower() not in CUSTOM_STOPWORDS])\n  return rel_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm.pandas()\nprocessed_content = df[\"content\"].progress_apply(preprocess)\ndf[\"processed_content\"] = processed_content","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Latent Dirichlet Allocation\nLDA performs clustering inside, and is topic modeling technique.\nIt assumes that similar topics shares similar group of words or vocab.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer(max_features=2**11,min_df=10,stop_words='english') # count vectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm = cv.fit_transform(df['processed_content'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LDA = LatentDirichletAllocation(n_components=7,random_state=42,n_jobs=-1) # LDA topic Modeling Technique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LDA.fit(dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the vocabulary length of words \nlen(cv.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get some random words \nrandom_word_id = random.randint(0,2048)\ncv.get_feature_names()[10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the topics \nLDA.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LDA.components_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"single_topic = LDA.components_[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the last 10 values which has high prob\ntop_ten_words = single_topic.argsort()[-10:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from here we can see, that words like \"Pay, company, coronavirus, worker \" are related to business \nfor index in top_ten_words:\n    print(cv.get_feature_names()[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the highest probability words per topic \nfor i,topic in enumerate(LDA.components_):\n    print(f'The top 25 words for topic #{i}')\n    print([cv.get_feature_names()[index] for index in topic.argsort()[-25:]])\n    print('\\n\\n')\n\n# Here we can check topic#1 related to financial, topic # 3 relates to tech, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results = LDA.transform(dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Topic'] = topic_results.argmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Non-Negative Matrix Factorization\nNMF with clustering also performs dimensionality reduction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=2**11,min_df=10, stop_words='english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm = tfidf.fit_transform(df['processed_content'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nmf_model  = NMF(n_components=7,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nmf_model.fit(dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf.get_feature_names()[1480]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,topic in enumerate(nmf_model.components_):\n    print(f'The top 25 words for topic #{i}')\n    print([tfidf.get_feature_names()[index] for index in topic.argsort()[-25:]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Here we can see that \n# nmfNumeric_to_topic = {0:'',1:'finance',2:'',3:'business',4:'healthcare',5:'',6:''}\n#it depends on how we infer topics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results = nmf_model.transform(dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NMF_Topic'] = topic_results.argmax(axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}