{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing all neccesary Libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom lightgbm import LGBMClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom catboost import CatBoostClassifier\n\n\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import roc_curve","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/jobathon-may-2021-credit-card-lead-prediction/train.csv\")\ntest = pd.read_csv(\"../input/jobathon-may-2021-credit-card-lead-prediction/test.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape,test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info() ## Information of Dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ratio of null values\ntrain.isnull().sum()/train.shape[0] *100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ratio of null values\ntest.isnull().sum()/test.shape[0] *100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#categorical features\ncategorical = train.select_dtypes(include =[np.object])\nprint(\"Categorical Features in Train Set:\",categorical.shape[1])\n\n#numerical features\nnumerical= train.select_dtypes(include =[np.float64,np.int64])\nprint(\"Numerical Features in Train Set:\",numerical.shape[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#categorical features\ncategorical = test.select_dtypes(include =[np.object])\nprint(\"Categorical Features in Test Set:\",categorical.shape[1])\n\n#numerical features\nnumerical= test.select_dtypes(include =[np.float64,np.int64])\nprint(\"Numerical Features in Test Set:\",numerical.shape[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Credit_Product'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Credit_Product'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Figure Shows the Frequency of Is_Lead\nplt.figure(figsize=(8,5))\nsns.set_style('whitegrid')\nsns.countplot(x='Is_Lead', data=train, palette='RdBu_r')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling missing Data\n### 3 Basic Methods to deal with this problem\n#### 1) To delete the Data rows containing NaN Values.  \nCon:- This will also delete the data which may be important for the prediction and it is not recommended when the dataset is small also for this competition we cannot drop null values as it will give dimension error while submission.  \n#### 2) To use Mode value  \ncon:- I have used mode value but it is giving low accuracy and also reults in biasing","metadata":{}},{"cell_type":"markdown","source":"#### 3)Here I have used \"Missing\" term in null values instead of picking up the mode value which results in bias","metadata":{}},{"cell_type":"code","source":"dummy3_train = train\ndummy3_test = test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy3_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy3_train[\"Credit_Product\"].fillna('Missing', inplace=True)\ndummy3_test[\"Credit_Product\"].fillna('Missing', inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy3_train[\"Credit_Product\"].isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy3_train = dummy3_train.drop(columns=['ID'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding the data\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nobjList = dummy3_train.select_dtypes(include = \"object\").columns\n#Label Encoding for object to numeric conversion\nfor feat in objList:\n    dummy3_train[feat] = le.fit_transform(dummy3_train[feat].astype(str))\n\nprint(dummy3_train.info())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding the data\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nobjList = dummy3_test.select_dtypes(include = \"object\").columns\nobjList = objList.delete(0)\n#Label Encoding for object to numeric conversion\nfor feat in objList:\n    dummy3_test[feat] = le.fit_transform(dummy3_test[feat].astype(str))\n\nprint(dummy3_test.info())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dummy3_train.drop(columns = ['Is_Lead'], axis=1) #Entire dataset except Target column\ny = dummy3_train['Is_Lead'] #Target column","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the data to be between -1 and 1\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n# After Scaling normalize the data to predict better results\nX = normalize(X)\nX","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling of Machine-Learning Models","metadata":{}},{"cell_type":"code","source":"# 20% data as validation set\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=22)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train shape\", X_train.shape)\nprint(\"X_test shape\", X_test.shape)\nprint(\"y_train shape\", y_train.shape)\nprint(\"y_test shape\", y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_LR = LogisticRegression()\nmodel_LR.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logpred = model_LR.predict(X_test)\nprint(confusion_matrix(y_test, logpred))\nprint(round(accuracy_score(y_test, logpred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logacc = accuracy_score(y_test, logpred)\nlogf1score = f1_score(y_test, logpred)\nlogrecall = recall_score(y_test, logpred)\nlogbal = balanced_accuracy_score(y_test, logpred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = model_LR.predict_proba(X_test)\n\nprobs = probs[:, 1]\nlrauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",lrauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb = GaussianNB().fit(X_train, y_train)\n# predict on test set\nnb_pred = nb.predict(X_test)\nprint(confusion_matrix(y_test, nb_pred))\nprint(round(accuracy_score(y_test, nb_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nbacc = accuracy_score(y_test, nb_pred)\nnbf1score = f1_score(y_test, nb_pred)\nnbrecall = recall_score(y_test, nb_pred)\nnbbal = balanced_accuracy_score(y_test, nb_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = nb.predict_proba(X_test)\nprobs = probs[:, 1]\nnbauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",nbauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train model\nsgd = SGDClassifier(loss= \"modified_huber\", shuffle = True, random_state= 101).fit(X_train, y_train)\n# predict on test set\nsgd_pred = sgd.predict(X_test)\nprint(confusion_matrix(y_test, sgd_pred))\nprint(round(accuracy_score(y_test, sgd_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgdacc = accuracy_score(y_test, sgd_pred)\nsgdf1score = f1_score(y_test, sgd_pred)\nsgdrecall = recall_score(y_test, sgd_pred)\nsgdbal = balanced_accuracy_score(y_test, sgd_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = sgd.predict_proba(X_test)\nprobs = probs[:, 1]\nsgdauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",sgdauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\ndtree = DecisionTreeClassifier(max_depth = 10, random_state= 101, max_features =None , min_samples_leaf\n= 30).fit(X_train, y_train)\n# predict on test set\ndtree_pred = dtree.predict(X_test)\nprint(confusion_matrix(y_test, dtree_pred))\nprint(round(accuracy_score(y_test, dtree_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtreeacc = accuracy_score(y_test, dtree_pred)\ndtreef1score = f1_score(y_test, dtree_pred)\ndtreerecall = recall_score(y_test, dtree_pred)\ndtreebal = balanced_accuracy_score(y_test, dtree_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = dtree.predict_proba(X_test)\nprobs = probs[:, 1]\ndtreeauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",dtreeauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb = LGBMClassifier()\nlgb.fit(X_train, y_train)\nlgb_pred = lgb.predict(X_test)\nprint(confusion_matrix(y_test, lgb_pred))\nprint(round(accuracy_score(y_test, lgb_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbacc = accuracy_score(y_test, lgb_pred)\nlgbf1score = f1_score(y_test, lgb_pred)\nlgbrecall = recall_score(y_test, lgb_pred)\nlgbbal = balanced_accuracy_score(y_test, lgb_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = lgb.predict_proba(X_test)\nprobs = probs[:, 1]\nlgbauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",lgbauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\nprint(confusion_matrix(y_test, xgb_pred))\nprint(round(accuracy_score(y_test, xgb_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgbacc = accuracy_score(y_test, xgb_pred)\nxgbf1score = f1_score(y_test, xgb_pred)\nxgbrecall = recall_score(y_test, xgb_pred)\nxgbbal = balanced_accuracy_score(y_test, xgb_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = xgb.predict_proba(X_test)\nprobs = probs[:, 1]\nxgbauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",xgbauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ada = AdaBoostClassifier()\nada.fit(X_train, y_train)\nada_pred = ada.predict(X_test)\nprint(confusion_matrix(y_test, ada_pred))\nprint(round(accuracy_score(y_test, ada_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adaacc = accuracy_score(y_test, ada_pred)\nadaf1score = f1_score(y_test, ada_pred)\nadarecall = recall_score(y_test, ada_pred)\nadabal = balanced_accuracy_score(y_test, ada_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = ada.predict_proba(X_test)\nprobs = probs[:, 1]\nadaauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",adaauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlp = MLPClassifier()\nmlp.fit(X_train, y_train)\nmlp_pred = mlp.predict(X_test)\nprint(confusion_matrix(y_test, mlp_pred))\nprint(round(accuracy_score(y_test, mlp_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlpacc = accuracy_score(y_test, mlp_pred)\nmlpf1score = f1_score(y_test, mlp_pred)\nmlprecall = recall_score(y_test, mlp_pred)\nmlpbal = balanced_accuracy_score(y_test, mlp_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = mlp.predict_proba(X_test)\nprobs = probs[:, 1]\nmlpauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",mlpauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint(confusion_matrix(y_test,rf_pred))\nprint(round(accuracy_score(y_test, rf_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfacc = accuracy_score(y_test, rf_pred)\nrff1score = f1_score(y_test, rf_pred)\nrfrecall = recall_score(y_test, rf_pred)\nrfbal = balanced_accuracy_score(y_test, rf_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = rf.predict_proba(X_test)\nprobs = probs[:, 1]\nrfauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",rfauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gr = GradientBoostingClassifier()\ngr.fit(X_train, y_train)\ngr_pred = gr.predict(X_test)\nprint(confusion_matrix(y_test,gr_pred))\nprint(round(accuracy_score(y_test, gr_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gracc = accuracy_score(y_test, gr_pred)\ngrf1score = f1_score(y_test, gr_pred)\ngrrecall = recall_score(y_test, gr_pred)\ngrbal = balanced_accuracy_score(y_test, gr_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = gr.predict_proba(X_test)\nprobs = probs[:, 1]\ngrauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",grauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat = CatBoostClassifier()\ncat.fit(X_train, y_train)\ncat_pred = cat.predict(X_test)\nprint(confusion_matrix(y_test,cat_pred))\nprint(round(accuracy_score(y_test, cat_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catacc = accuracy_score(y_test, cat_pred)\ncatf1score = f1_score(y_test, cat_pred)\ncatrecall = recall_score(y_test, cat_pred)\ncatbal = balanced_accuracy_score(y_test, cat_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = cat.predict_proba(X_test)\nprobs = probs[:, 1]\ncatauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",catauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing the Models","metadata":{}},{"cell_type":"code","source":"models = [('Logistic Regression', logacc, logf1score, logrecall, logbal, lrauc),\n          ('Naive_Bayes', nbacc, nbf1score, nbrecall, nbbal, nbauc),\n          ('SGD Classifier', sgdacc, sgdf1score, sgdrecall, sgdbal, sgdauc),\n          ('Decision TreeClassifier', dtreeacc, dtreef1score, dtreerecall, dtreebal, dtreeauc),\n          ('LGBM Classifier', lgbacc, lgbf1score, lgbrecall, lgbbal, lgbauc),\n          ('XGB Classifier', xgbacc, xgbf1score, xgbrecall, xgbbal, xgbauc),\n          ('AdaBoost Classifier', adaacc, adaf1score, adarecall, adabal, adaauc),\n          ('MLP Classifier', mlpacc, mlpf1score, mlprecall, mlpbal, mlpauc),\n          ('RandomForest Classifier', rfacc, rff1score, rfrecall, rfbal, rfauc),\n          ('Gradient Boosting Classifier', gracc, grf1score, grrecall, grbal, grauc),\n          ('CatBoost Classifier', catacc, catf1score, catrecall, catbal, catauc)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = pd.DataFrame(data=models, columns=['Models', 'Accuracy of model', 'F1 Score', 'Recall Score', 'Balanced Accuracy Score', 'ROC AUC Score'])\ncm = sns.light_palette(\"green\", as_cmap=True)\ns = predict.style.background_gradient(cmap=cm)\ns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style=\"whitegrid\")\nax = sns.barplot(y=\"Models\", x=\"ROC AUC Score\", data=predict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyper-Parameter Tuning and  Ensemble Top Model","metadata":{}},{"cell_type":"markdown","source":"The Top Models are:  \n1) LGBM Classifier  \n2) XGB Classifier  \n3) CatBoost Classifier  \n4) MLP Classifier  \n5) Gradient Boosting Classifier  ","metadata":{}},{"cell_type":"markdown","source":"Parameter Tuning using RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"# from scipy.stats import randint\n# from sklearn.model_selection import RandomizedSearchCV\n\n# cbc = CatBoostClassifier()\n\n# # Creating the hyperparameter grid\n# param_dist = { \"learning_rate\": np.linspace(0,0.2,5),\n#               \"max_depth\": randint(3, 10)}\n               \n# #Instantiate RandomSearchCV object\n# rscv = RandomizedSearchCV(cbc , param_dist, scoring='roc_auc', cv =5)\n\n# #Fit the model\n# rscv.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Print the tuned parameters and score\n# print(rscv.best_params_)\n# print(rscv.best_score_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb = LGBMClassifier()\n# rs_params = {\n\n#         'bagging_fraction': (0.5, 0.8),\n#         'bagging_frequency': (5, 8),\n\n#         'feature_fraction': (0.5, 0.8),\n#         'max_depth': (10, 13),\n#         'min_data_in_leaf': (90, 120),\n#         'num_leaves': (1200, 1550)\n\n# }\n\n# # Initialize a RandomizedSearchCV object using 5-fold CV-\n# rs_cv = RandomizedSearchCV(cbc , param_dist, scoring='roc_auc', cv =5)\n\n# # Train on training data-\n# rs_cv.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(rs_cv.best_params_)\n# print(rs_cv.best_score_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensembling CatBoostClassifier and LGBMClassifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\n\n\n# define the base models\nlevel0 = list()\nlevel0.append(('lgb', LGBMClassifier(learning_rate = 0.05, max_depth = 3)))\nlevel0.append(('cat', CatBoostClassifier(learning_rate = 0.15000000000000002, max_depth = 3)))\n\nlr = LogisticRegression() ##Base Model\n# define the stacking ensemble\nmodel = StackingClassifier(estimators=level0, final_estimator=lr, cv=10)\n\n# fit the model on all available data\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pred = model.predict(X_test)\nprint(confusion_matrix(y_test, model_pred))\nprint(round(accuracy_score(y_test, model_pred),2)*100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modacc = accuracy_score(y_test, model_pred)\nmodf1score = f1_score(y_test, model_pred)\nmodrecall = recall_score(y_test, model_pred)\nmodbal = balanced_accuracy_score(y_test, model_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\nprobs = model.predict_proba(X_test)\nprobs = probs[:, 1]\nmodauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",modauc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing Top Models after Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"models = [('LGBM Classifier', lgbacc, lgbf1score, lgbrecall, lgbbal, lgbauc),\n          ('XGB Classifier', xgbacc, xgbf1score, xgbrecall, xgbbal, xgbauc),\n          ('CatBoost Classifier', catacc, catf1score, catrecall, catbal, catauc),\n          ('MLP Classifier', mlpacc, mlpf1score, mlprecall, mlpbal, mlpauc),\n          ('Gradient Boosting Classifier', gracc, grf1score, grrecall, grbal, grauc),\n          ('Ensemble Model', modacc, modf1score, modrecall, modbal, modauc)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = pd.DataFrame(data=models, columns=['Models', 'Accuracy of model', 'F1 Score', 'Recall Score', 'Balanced Accuracy Score', 'ROC AUC Score'])\ncm = sns.light_palette(\"violet\", as_cmap=True)\ns = predict.style.background_gradient(cmap=cm)\ns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Submission","metadata":{}},{"cell_type":"code","source":"test1 = dummy3_test.copy()\ndummy3_test = dummy3_test.drop('ID', axis=1)\ndummy3_test = scaler.fit_transform(dummy3_test)\ndummy3_test = normalize(dummy3_test)\ndummy3_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probstest = model.predict_proba(dummy3_test)\nprobstest = probstest[:, 1]\ntest1[\"Is_Lead\"] = probstest\ntest1[[\"ID\",\"Is_Lead\"]].to_csv(\"Final-Submission.csv\",index=False)\ntest1[[\"ID\",\"Is_Lead\"]].head()\nprint(\"Submission Successful\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}