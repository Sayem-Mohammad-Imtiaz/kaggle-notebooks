{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"75d09d88-11e1-7879-077a-c4d07fdb2cdd"},"source":"## Notebook Goals ##\n\nThe analyses that have been posted so far focus on prediction of outcomes with respect to variables that are known at the game's end. These will be correlated somewhat with the result of the game, but I don't think that they are 'predictive' in the colloquial sense. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5233f53-e49b-6e2e-94e0-2a6c90a9f462"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import defaultdict, Counter\nimport itertools\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom patsy.contrasts import Diff\nsns.set_style('white')\n\ndf = pd.read_csv(\"../input/catanstats.csv\")\ndf.me.fillna(0, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9e14244-18fe-c1eb-dcf2-49bd60d8100f"},"outputs":[],"source":"Here I make a bunch of features that I think might be predictive. These include:\n\n1. The expected number of cards (ec) on any roll\n2. The ability to build items without needing to trade\n3. Having ports that you can use"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90d5c3ac-db0b-d639-7b37-349ddf4bc1b6"},"outputs":[],"source":"# turn the numbers that a player is on into a probability of resources per roll\nprobs = defaultdict(int)\nfor d1, d2 in itertools.combinations_with_replacement(range(1, 7), 2):\n    s = d1 + d2\n    probs[s] += 1 if d1 == d2 else 2\nprobs = {k:v/sum(probs.values()) for k, v in probs.items()}\n\nresources = \"LCSWO\"\nsettlement_res = set(\"LCSW\")\nroad_res = set(\"WC\")\ndcard_res = set(\"SOW\")\n\ndef get_row_ec(row, cards=resources):\n    ec = 0\n    nums = row[15:27].tolist()[0::2]\n    vals = row[15:27].tolist()[1::2]\n    for n, v in zip(nums, vals):\n        if v in cards:\n            ec += probs[n]\n    return ec\n\ndef two_port(row):\n    # two ports are only considered useful if you sit on a resource that it trades\n    vals = row[15:27].tolist()[1::2]\n    s = sum(1 for v in vals if v[0] == '2' and v[1] in vals)\n    return s\n\ndef three_port(row):\n    vals = row[15:27].tolist()[1::2]\n    s = sum(1 for v in vals if v[0] == '3')\n    return s\n\ndef city(row):\n    # fast city-building if there are more than 1 ore and a wheat\n    vals = row[15:27].tolist()[1::2]\n    if vals.count('O') >= 2 and 'W' in vals:\n        return 1\n    return 0\n\ndef can_build(row, req):\n    # see if the adjacent tiles contain the input set\n    vals = row[15:27].tolist()[1::2]\n    if req.issubset(vals):\n        return 1\n    return 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2bf2faf2-9ac0-12de-ffcd-24b965b39490"},"outputs":[],"source":"# get the features\ndf['init_ec'] = df.apply(get_row_ec, axis=1)\ndf['two_port'] = df.apply(two_port, axis=1)\ndf['three_port'] = df.apply(three_port, axis=1)\ndf['city'] = df.apply(city, axis=1)\ndf['settlement'] = df.apply(can_build, axis=1, args=(settlement_res,))\ndf['road'] = df.apply(can_build, axis=1, args=(settlement_res,))\ndf['dcard'] = df.apply(can_build, axis=1, args=(dcard_res,))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5bd32180-183d-2a6a-2c51-6e22ddc64cbd"},"outputs":[],"source":"## Expected Cards vs. Points##\nThe initial expected number of cards per turn correlates with points significantly with a value of 0.29"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b14f16eb-a6ff-f441-8d3c-62aeb35be843"},"outputs":[],"source":"g = sns.jointplot(df.init_ec, df.points, alpha=0.5);"},{"cell_type":"markdown","metadata":{"_cell_guid":"d3add925-8558-3d68-a8b0-4de508015460"},"source":"## Point Prediction ##\n\nHere I try to predict points with the features in a linear model. It's not very effective.\n\nYou can play with adding in the other factors I made, but none of them were significant or useful for predicting.\n\nI also subtracted 2 from the points since every player starts with two victory points, so we're making a model that is for 'points above starting'."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff044dc6-6491-085e-9b1a-bd2be50a72c7"},"outputs":[],"source":"model_eqn = \"I(points-2) ~ 1 + (init_ec + C(dcard) + C(me))\"\nmodel = sm.OLS.from_formula(model_eqn, df).fit()\nprint(model.summary())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5acd63ea-d344-2b32-527e-ae104e77b874"},"outputs":[],"source":"mn, mx = 1, 13\nplt.scatter(model.model.endog+2, model.fittedvalues+2);\nplt.xlim(mn, mx); plt.ylim(mn, mx); plt.plot([mn, mx], [mn, mx], '-k', lw=1);\nplt.ylabel(\"Fit Value\"); plt.xlabel(\"Actual Value\"); plt.title(\"Actual by Fit\");"},{"cell_type":"markdown","metadata":{"_cell_guid":"78455b4b-1b4c-96a4-60e1-a49d66115af7"},"source":"Let's try breaking up the EC by card type and see if that has anything to do with it"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca55ae70-5f31-0a34-d4b2-15d7adfd9f3e"},"outputs":[],"source":"# break EV up by card type\ninputs = []\nfor card in \"LCSWO\":\n    inputs.append('ec_' + card)\n    df['ec_' + card] = df.apply(get_row_ec, axis=1, args=(card,))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c667fd3b-4aa0-c58a-923f-276d807c9de0"},"outputs":[],"source":"model_eqn = \"I(points - 2) ~ -1 + (\" + \" + \".join(inputs) + \")\" #**2\nmodel = sm.OLS.from_formula(model_eqn, df).fit()\nprint(model.summary())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"faae6bc2-f188-5f36-9482-f5d659c03d12"},"outputs":[],"source":"mn, mx = 1, 13\nplt.scatter(model.model.endog+2, model.fittedvalues+2);\nplt.xlim(mn, mx); plt.ylim(mn, mx); plt.plot([mn, mx], [mn, mx], '-k', lw=1);\nplt.ylabel(\"Fit Value\"); plt.xlabel(\"Actual Value\"); plt.title(\"Actual by Fit\");"},{"cell_type":"markdown","metadata":{"_cell_guid":"a12495e0-9767-4975-309b-22edabb79a43"},"source":"That didn't help much. What's the point of statistical significance when it doesn't predict well? Bleah!"},{"cell_type":"markdown","metadata":{"_cell_guid":"61cdd15f-dd98-7cd9-104f-ff70bf585d6b"},"source":"## Winner Prediction ##\n\nLet's skip point prediction, since that isn't going so well, and try to predict the winner.\n\nI'm going to quickly do a logistic regression example and show that the accuracy from the confusion matrix isn't the right measure. The right measure is who among the 4 players has the highest win probability matching the actual winner."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1bdd389a-a2aa-c3c5-bce5-fadc075a518a"},"outputs":[],"source":"df['win'] = 0\nwincol = df.columns.tolist().index('win')\n\nfor gnum in df.gameNum.unique():\n    rows = df[df.gameNum == gnum]\n    win_idx = rows.points.argmax()\n    df.iloc[win_idx, wincol] = 1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17f41f8d-45be-c791-c7b6-b970d9443794"},"outputs":[],"source":"# First, predict the winner based only on the player position and whether or not our kind data\n# gatherer was the player\nmodel_eqn = \"win ~ 1 + C(me) + C(player)\"\nmodel = sm.Logit.from_formula(model_eqn, df).fit()\nprint(model.summary())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5bf29cc-a5cb-b206-b174-aa9a86ab304e"},"outputs":[],"source":"t = model.pred_table()\nprint(t)\nprint(\"Accuracy:\",np.diag(t).sum()/t.sum())"},{"cell_type":"markdown","metadata":{"_cell_guid":"bb37d98a-27fc-d538-0701-cbe06c3dc29c"},"source":"The standard accuracy measure won't do here, because we're really predicting the winner from a set of 4. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca2f475c-0879-c710-a82f-a92c4ba10da0"},"outputs":[],"source":"def model_pred(model, data):\n    right = 0\n    tried = 0\n    for gnum in df.gameNum.unique():\n        print(gnum)\n        rows = df[df.gameNum == gnum]\n        win_idx = rows.points.argmax()\n        max_idx = -1\n        max_pts = 0\n        pred_max_idx = -1\n        pred_max_p = -1\n        for idx, r in rows.iterrows():\n            p = model.predict(r)\n            if p > pred_max_p:\n                pred_max_p = p\n                pred_max_idx = idx\n            if r.points > max_pts:\n                max_pts = r.points\n                max_idx = idx\n        tried += 1\n        right += 1 if max_idx == pred_max_idx else 0\n    return right/tried"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f4ad0a1-10d3-3946-c446-b5e565c7ab5c"},"outputs":[],"source":"model_pred(model, df)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2d60b332-9631-ce6d-a01f-9f5102d8702c"},"source":"As nice as the accuracy is, the skill of the model is basically 0 (we'd get the same answer picking 'me' the whole time)."},{"cell_type":"markdown","metadata":{"_cell_guid":"a0efeb72-4686-6d6c-c884-7a4c6aecc60e"},"source":"## Multinomial Logistic ##\n\nLet's try to account for all the players at once and pick one through 4 using a multinomial logistic regression."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc60b7e9-fa5d-a1e3-4aa1-01968c4c6909"},"outputs":[],"source":"# make new data, where a single row is a full game\ngame_rows = []\nfor gnum in df.gameNum.unique():\n    gamerow = []\n    rows = df[df.gameNum == gnum]\n    for idx, r in rows.iterrows():\n        # Add whatever you think is predictive for each player here\n        gamerow.extend([r.init_ec, r.me])\n        if r.win:\n            winner = idx % 4\n    gamerow += [winner]\n    game_rows.append(gamerow)\n    \ngamedf = pd.DataFrame(game_rows)\n# I ignored column names and just renamed the last one to winner\ngamedf.rename(columns={gamedf.shape[1]-1:'WINNER'}, inplace=True)\n# Rename all the default numbered columns to 'V#'\ngamedf.rename(columns={x: \"V{}\".format(x) for x in gamedf.columns if x != 'WINNER'}, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e67e49b1-15a1-263f-cf86-c0d435b15853"},"outputs":[],"source":"inputs = [x for x in gamedf.columns if x != \"WINNER\"]\n# NOTE: I cheat here a bit and don't set the `me` variable as categorical.\nmodel_eqn = \"WINNER ~ -1 + \" + \" + \".join(inputs)\nmodel = sm.MNLogit.from_formula(model_eqn, gamedf).fit()\nprint(model.summary())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d98bd28-384c-db8b-3e1d-ca481642b6ff"},"outputs":[],"source":"t = model.pred_table()\nprint(t)\nprint(\"Accuracy:\",np.diag(t).sum()/t.sum())"},{"cell_type":"markdown","metadata":{"_cell_guid":"a336294a-2ecb-bfe7-b33b-5e4ab47449e0"},"source":"Doing the MNLogit gives a better than 50% accuracy just by considering all the players together. Try the model and only use `r.me` for the inputs. You should get a 50% accuracy, which is what we'd expect.\n\nThe coefficients on all the variables don't make the most sense, but hey, our model is moderately skillful.\n\nThe real problem is that there isn't any out of sample prediction to test our model quality. I'll switch over to scikit for ease of CV."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"430ba08e-c5fc-ffe1-fe6c-e4ac7c794007"},"outputs":[],"source":"from sklearn import linear_model\nfrom sklearn.cross_validation import KFold, cross_val_score\n\nX = gamedf[[x for x in gamedf.columns if x != 'WINNER']].as_matrix()\ny = gamedf.WINNER\n\nlogreg = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs')\n\n# holdout one at a time.\nkf = KFold(len(gamedf), n_folds=50, shuffle=False)\nprint(\"Average CV accuracy:\", cross_val_score(logreg, X, y, cv=kf).mean())"},{"cell_type":"markdown","metadata":{"_cell_guid":"2223fb33-7957-597d-0954-5621dcad9e34"},"source":"## Conclusions and Future Work##\n\nThis was a pretty quick look at predicting winners and points using only up-front information. Cross-validation with a multinomial logistic wasn't able to show consistent improvement over always assuming that `me` always won. \n\nThere's a lot more than could be done for feature creation and selection, though. I think what I've shown is that it's hard to predict who will win knowing only the initial board state (which is a real plus for the game, I would hope this is true!). The data are also biased due to the poster's skill at the game.\n\nIt was my hope that the features related to building capabilities would turn out to be useful, but Catan must give enough options for ways to earn points that there aren't very clear relationships between starting and ending. I think we've seen this happen where someone thinks they will build settlements, but really only be able to get longest road or go for development cards to build largest army and get victory points. We also don't get to capture strategies like building near a port for the first expansion. \n\nI'd be really curious to see what neural network does with a whole bunch of possible features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3db28e9e-5b7a-0865-2505-cd9d2bec07bd"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbed2107-acf9-178e-84bc-bf017e605bcd"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}