{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"panda_path = '/kaggle/input/isic-2019/ISIC_2019_Training_GroundTruth.csv'\nimage_dir = '/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ground_truth = pd.read_csv(panda_path)\nground_truth.drop('UNK', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, img in enumerate(ground_truth.image):\n    img = img+'.jpg'\n    ground_truth.image[index]=img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#val_truth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ground_truth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ground_truth.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_rows = (np.random.rand(25330//5)*25330).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dataframe = ground_truth.iloc[val_rows]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dataframe.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sums = []\nfor col in ground_truth.columns[1:]:\n    sums.append(sum(val_dataframe[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sums_full = []\nfor col in ground_truth.columns[1:]:\n    sums_full.append(sum(ground_truth[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalize\ndef avg(l):\n    return sum(l)/len(l)\nfull_avg = avg(sums_full)\nval_avg = avg(sums)\nsums = [val/val_avg for val in sums]\nsums_full = [val/full_avg for val in sums_full]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sums)\nprint(sums_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create class weights\nmax_val = max(sums)\nclass_weights = {}\nfor ind, val in enumerate(sums, start=0):\n    class_weights[ind] = max_val/sums[ind]\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ground_truth.drop(val_rows, inplace=True, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'There are {len(ground_truth)} many images in the train set')\nprint(f'There are {len(val_dataframe)} many images in the train set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import vgg16\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = ground_truth.columns.size\nnum_classes -= 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vgg(num_classes, trainable=False):\n    vgg_model = VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n    for layer in vgg_model.layers:\n        layer.trainable = trainable\n\n    x = Flatten()(vgg_model.output)\n    x2 = Dropout(0.5)(x)\n    prediction = Dense(num_classes, activation='softmax')(x2)\n    full_model = Model(inputs=vgg_model.input, outputs=prediction)\n    return full_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model = vgg(num_classes, trainable=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(ResNet50(weights='imagenet', input_shape=(224, 224, 3)))\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layer_count=0\nfor layer in model.layers[0].layers:\n    if layer_count > 165:\n        layer.trainable = True\n    else:\n        layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ground_truth.columns\nlabels = labels[1:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gen = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input)\ntrain_gen = data_gen.flow_from_dataframe(dataframe=ground_truth, directory=image_dir, x_col='image', target_size=(224, 224),\n                                     y_col=labels, class_mode='raw', batch_size=32)\nval_gen = data_gen.flow_from_dataframe(dataframe=val_dataframe, directory=image_dir, \n                                       x_col='image', y_col=labels, class_mode='raw', batch_size=32, target_size=(224, 224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_class_freqs(labels):\n    \n    # total number of patients (rows)\n    N = labels.shape[0]\n    \n    positive_frequencies = np.mean(labels, axis=0)\n    negative_frequencies = 1 - positive_frequencies\n\n    ### END CODE HERE ###\n    return positive_frequencies, negative_frequencies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_pos, freq_neg = compute_class_freqs(train_gen.labels)\nfreq_pos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndata = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\ndata = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \n    \n    def weighted_loss(y_true, y_pred):\n       \n        loss = 0.0\n        \n\n        for i in range(len(pos_weights)):\n            # for each class, add average weighted loss for that class \n            loss += K.mean(-(pos_weights[i]*y_true[:, i]*K.log(y_pred[:, i]+epsilon)\n                             + neg_weights[i]*(1-y_true[:, i])*K.log((1-y_pred[:, i])+epsilon)))\n        return loss\n    \n    return weighted_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#focal loss function --> focusses on training mainly the hard examples, gives lower weights to easy examples\n# def focal_loss(y_true, y_pred):\n#     gamma = 2.0\n#     alpha = 0.25\n#     pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n#     pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n#     return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\ndef focal_loss(gamma=2., alpha=4.):\n\n    gamma = float(gamma)\n    alpha = float(alpha)\n\n    def focal_loss_fixed(y_true, y_pred):\n        \"\"\"Focal loss for multi-classification\n        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n        Notice: y_pred is probability after softmax\n        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n        Focal Loss for Dense Object Detection\n        https://arxiv.org/abs/1708.02002\n\n        Arguments:\n            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n\n        Keyword Arguments:\n            gamma {float} -- (default: {2.0})\n            alpha {float} -- (default: {4.0})\n\n        Returns:\n            [tensor] -- loss.\n        \"\"\"\n        epsilon = 1.e-9\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n\n        model_out = tf.add(y_pred, epsilon)\n        ce = tf.multiply(y_true, -K.log(model_out))\n        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n        reduced_fl = tf.reduce_max(fl, axis=1)\n        return tf.reduce_mean(reduced_fl)\n    return focal_loss_fixed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.metrics import AUC\nfrom keras import backend as K\npos_weights = freq_neg\nneg_weights = freq_pos\nmetrics = ['accuracy']\n#vgg_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss=get_weighted_loss(pos_weights, neg_weights), metrics=metrics)\nvgg_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss=focal_loss(), metrics=metrics)\nprint('model has compiled')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\ncallback = EarlyStopping(monitor='val_accuracy', patience=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = vgg_model.fit(train_gen, steps_per_epoch=20747//32, \n                        epochs=20, validation_data=val_gen, validation_steps=5066//32)#, class_weight=class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reset_ind_val = val_dataframe.reset_index().drop(['index'], axis=1)\nreset_ind_val.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reset_ind_val.iloc[0][0]\nprint(np.argmax(reset_ind_val.iloc[0][1:].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_loss'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_image(index, model, dataframe=reset_ind_val, img_dir=image_dir, labels=labels):\n    row = dataframe.iloc[index]\n    path = os.path.join(img_dir, row[0])\n    img = load_img(path, target_size=(224, 224))\n    img_arr = img_to_array(img)\n    image = np.expand_dims(img_arr, axis=0)\n    image = preprocess_input(image)\n    preds = model.predict(image)\n    if np.argmax(row[1:].values) == np.argmax(preds):\n        return True, labels[np.argmax(preds)]\n    return False, labels[np.argmax(preds)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reset_ind_val.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copied from Coursera util package\nfrom keras.preprocessing import image\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom tensorflow.compat.v1.logging import INFO, set_verbosity\nimport cv2\n\ndef get_roc_curve(labels, predicted_vals, generator):\n    auc_roc_vals = []\n    for i in range(len(labels)):\n        try:\n            gt = generator.labels[:, i]\n            pred = predicted_vals[:, i]\n            auc_roc = roc_auc_score(gt, pred)\n            auc_roc_vals.append(auc_roc)\n            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n            plt.figure(1, figsize=(10, 10))\n            plt.plot([0, 1], [0, 1], 'k--')\n            plt.plot(fpr_rf, tpr_rf,\n                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n            plt.xlabel('False positive rate')\n            plt.ylabel('True positive rate')\n            plt.title('ROC curve')\n            plt.legend(loc='best')\n        except:\n            print(\n                f\"Error in generating ROC curve for {labels[i]}. \"\n                f\"Dataset lacks enough examples.\"\n            )\n    plt.show()\n    return auc_roc_vals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = vgg_model.predict_generator(val_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_nums = []\nfor arr in preds:\n    class_nums.append(np.argmax(arr))\nclass_nums","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_gen.labels[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_rocs = get_roc_curve(labels, preds, val_gen)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model.save_weights('third_try.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}