{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction  \n## About the Dataset\nThis data set consists of Placement data of students in Jain University, Bangalore. It includes secondary and higher secondary school percentage and specialization. It also includes degree specialization, type and Work experience and salary offers to the placed students"},{"metadata":{},"cell_type":"markdown","source":"# Problem Statement\n**To predict whether or not a candidate will be placed(or employed) on the basis of his/her Secondary %, Higher Secondary %, Undergraduate Degree %, MBA % and Employability Test %**"},{"metadata":{},"cell_type":"markdown","source":"# The Methodology\n1. **Loading and Cleaning + Preprocessing the Data**\n2. **Exploratory Data Analysis(EDA)**\n    * Pairplot\n    * Clustermap to Visualize Correlation\n    * Bubble Plot(s)\n    * Tree Chart\n    * Pie Chart\n    * Histogram\n    * Trendline\n    * Violin Plot\n    * Swarm Plot\n3. **Predictive Modelling**\n    * Logistic Regression\n    * Naive Bayes Classifier\n    * Random Forest Classifier\n    * Support Vector Machine(SVM) Classifier\n    * Deep Neural Network(DNN)\n"},{"metadata":{},"cell_type":"markdown","source":"# Importing Relevant Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '../input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_csv_data = pd.read_csv(data_path)\nraw_csv_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_comp = raw_csv_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_comp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_comp.fillna(df_comp['salary'].mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dropping sl_no as it is an insignificant feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_comp['sl_no']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_comp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_comp.status)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pairplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df_comp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation between Salary, Employability Test %, Secondary Education % and Higher Secondary Education %"},{"metadata":{"trusted":true},"cell_type":"code","source":"cor = df_comp.loc[:,[\"hsc_p\",\"ssc_p\",'etest_p',\"salary\"]]\nsns.clustermap(cor.corr(), center=0, cmap=\"vlag\",\n               linewidths=.75, figsize=(10, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Bubble Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install bubbly\n!pip install chart_studio","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender + Employability Test % v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_comp_bp = df_comp.head(30)\nfrom bubbly.bubbly import bubbleplot \nfrom plotly.offline import iplot\nimport chart_studio.plotly as py\n\n\nfigure = bubbleplot(dataset=df_comp_bp, x_column='etest_p', y_column='salary', \n    bubble_column='gender', size_column='salary', color_column='gender', \n    x_logscale=True, scale_bubble=2, height=350)\n\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Specialisation + Employability Test v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_comp_bp = df_comp.head(30)\nfrom bubbly.bubbly import bubbleplot \nfrom plotly.offline import iplot\nimport chart_studio.plotly as py\n\n\nfigure = bubbleplot(dataset=df_comp_bp, x_column='etest_p', y_column='salary', \n    bubble_column='specialisation', size_column='salary', color_column='specialisation', \n    x_logscale=True, scale_bubble=2, height=350)\n\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TreeChart"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Specialization v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tree = df_comp.groupby([\"hsc_b\",\"specialisation\"])[[\"salary\"]].mean().reset_index()\n\nfig = px.treemap(df_tree, path=['hsc_b','specialisation'], values='salary',\n                  color='salary', hover_data=['specialisation'],\n                  color_continuous_scale='rainbow')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Work Experience + Undergraduate Degree v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tree = df_comp.groupby([\"workex\",\"degree_t\"])[[\"salary\"]].mean().reset_index()\n\nfig = px.treemap(df_tree, path=['workex','degree_t'], values='salary',\n                  color='salary', hover_data=['degree_t'],\n                  color_continuous_scale='rainbow')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender + Undergraduate Degree v/s Employability Test %"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tree_1 = df_comp.copy()\ndf_tree_1['status'] = df_tree_1['status'].map({'Placed':1, 'Not Placed':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tree = df_tree_1.groupby([\"gender\",\"degree_t\"])[[\"etest_p\"]].mean().reset_index()\n\nfig = px.treemap(df_tree, path=['gender','degree_t'], values='etest_p',\n                  color='etest_p', hover_data=['degree_t'],\n                  color_continuous_scale='rainbow')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pie Chart"},{"metadata":{},"cell_type":"markdown","source":"## Gender v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pie = df_comp.groupby([\"gender\"])[[\"salary\"]].mean().reset_index()\n\nfig = px.pie(df_pie,\n             values=\"salary\",\n             names=\"gender\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Histogram"},{"metadata":{},"cell_type":"markdown","source":"## Gender + Degree% v/s Count of Status(# placed/not-placed)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(df_comp, x=\"degree_p\", y=\"status\", color=\"gender\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trendline"},{"metadata":{},"cell_type":"markdown","source":"## Degree% v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df_comp, x=\"degree_p\", y=\"salary\", trendline=\"ols\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Employability Test % v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df_comp, x=\"etest_p\", y=\"salary\", trendline=\"ols\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Violin Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nax = sns.violinplot(x=\"degree_t\", y=\"salary\", hue=\"specialisation\",\n                    data=df_comp, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Swarm Plot"},{"metadata":{},"cell_type":"markdown","source":"## Gender v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.swarmplot(x=\"gender\", y=\"salary\", data= df_comp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Work Experience v/s Salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.swarmplot(x=\"workex\", y=\"salary\", data=df_comp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_comp.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nstats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing Data for Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hsc_b'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log.ssc_b = df_log['ssc_b'].map({'Others':1, 'Central':0})\ndf_log.hsc_b = df_log['hsc_b'].map({'Others':1, 'Central':0})\ndf_log.hsc_s = df_log['hsc_s'].map({'Arts':2, 'Commerce':1, 'Science':0})\ndf_log.degree_t = df_log['degree_t'].map({'Others':2, 'Comm&Mgmt':1, 'Sci&Tech':0})\ndf_log.workex =  df_log['workex'].map({'Yes':1, 'No':0})\ndf_log.specalisation = df_log['specialisation'].map({'Mkt&HR':1, 'Mkt&Fin':0})\ndf_log.status = df_log['status'].map({'Placed':1, 'Not Placed':0})\ndf_log.gender = df_log['gender'].map({'F':1,'M':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Splitting the Data into Training and Testing Data with an 80:20 Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = df_log[['ssc_p', 'hsc_p', 'degree_p','workex', 'etest_p', 'mba_p']]\ntargets = df_log['status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(inputs, targets, test_size = 0.2, random_state = 365)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nresults_log = logreg.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=logreg.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Martix\n### [True Positive, False Negative]\n### [False Positive, True Negative]\n\n#### There is also a list of rates that are often computed from a confusion matrix for a binary classifier:\n#### Accuracy: Overall, how often is the classifier correct?\n#### Accuracy = (TP+TN)/total\n#### Misclassification Rate(Error Rate): Overall, how often is it wrong?\n#### Misclassification Rate = (FP+FN)/total\n#### True Positive Rate(Sensitivity or Recall): When it’s actually yes, how often does it predict yes?\n#### True Positive Rate = TP/actual yes\n#### False Positive Rate: When it’s actually no, how often does it predict yes?\n#### False Positive Rate=FP/actual no\n#### True Negative Rate(Specificity): When it’s actually no, how often does it predict no?\n#### True Negative Rate=TN/actual no\n#### Precision: When it predicts yes, how often is it correct?\n#### Precision=TP/predicted yes\n#### Prevalence: How often does the yes condition actually occur in our sample?\n#### Prevalence=actual yes/total"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = [0,1]\nfig, ax = plt.subplots()\ntick_marks = np.arange(1)\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"mako\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion Matrix', y=1.1, size = 24)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve\n#### Receiver Operating Characteristic(ROC) curve is a plot of the true positive rate(Recall) against the false positive rate. It shows the tradeoff between sensitivity and specificity.\n#### AUC(Area Under Curve) score for the case is 0.96. AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = logreg.predict_proba(x_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(x_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = model.score(x_test,y_test)\nprint(\"Accuracy = \" + str((acc*100).round(3))+\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nmodel.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validating Performance of Random Forest Model"},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = [0,1]\nfig, ax = plt.subplots()\ntick_marks = np.arange(1)\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"mako\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion Matrix', y=1.1, size = 24)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy = \"+ str(((model.score(x_test,y_test))*100).round(3))+\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_cv_score = cross_val_score(model, x_test, y_test, cv=10, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"=== Classification Report ===\")\nprint(classification_report(y_test, y_pred))\nprint('\\n')\nprint(\"=== All AUC Scores ===\")\nprint(rfc_cv_score)\nprint('\\n')\nprint(\"=== Mean AUC Score ===\")\nprint(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_roc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC (Receiver Operating Charateristic) Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_ROC_disp = plot_roc_curve(model, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n\n#Train the model using the training sets\nclf.fit(x_train, y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",str(((metrics.accuracy_score(y_test, y_pred))*100).round(3)) + \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Precision: what percentage of positive tuples are labeled as such?\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\n\n# Model Recall: what percentage of positive tuples are labelled as such?\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deep Neural Network(DNN) for Predicting Placement Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import numpy as np\nimport tensorflow as tf\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unscaled_inputs_all = df[['ssc_p','hsc_p','degree_p','etest_p','mba_p']]\ntargets_all = df_log['status']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Balancing the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_one_targets = int(np.sum(targets_all))\nzero_targets_counter = 0\nindices_to_remove = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(targets_all.shape[0]):\n    if targets_all[i] == 0:\n        zero_targets_counter +=1\n        if zero_targets_counter > num_one_targets:\n            indices_to_remove.append(i)\n\nunscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n\ntargets_equal_priors = np.delete(targets_all, indices_to_remove, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardizing the Inputs"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shuffling the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffled_indices = np.arange(scaled_inputs.shape[0])\nnp.random.shuffle(shuffled_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffled_inputs = scaled_inputs[shuffled_indices]\nshuffled_targets = targets_all[shuffled_indices]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the Data into Training, Validation and Testing Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"samples_count = shuffled_inputs.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples_count = int(0.8 * samples_count)\nvalidation_samples_count = int(0.8 * samples_count)\ntest_samples_count = samples_count - train_samples_count - validation_samples_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = shuffled_inputs[:train_samples_count]\ntrain_targets = shuffled_targets[:train_samples_count]\n\nvalidation_inputs = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\nvalidation_targets = shuffled_targets[train_samples_count:train_samples_count + validation_samples_count]\n\ntest_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\ntest_targets = shuffled_targets[train_samples_count + validation_samples_count:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving the DataFrames in .npz format"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.savez('placement_train_data', inputs = train_inputs, targets = train_targets)\nnp.savez('placement_validation_data', inputs = validation_inputs, targets = validation_targets)\nnp.savez('placement_test_data', inputs = test_inputs, targets = test_targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outlining the DNN Model"},{"metadata":{},"cell_type":"markdown","source":"### Loading the .npz files"},{"metadata":{"trusted":true},"cell_type":"code","source":"npz = np.load('/kaggle/working/placement_train_data.npz')\ntrain_inputs, train_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n\nnpz = np.load('/kaggle/working/placement_validation_data.npz')\nvalidation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n\nnpz = np.load('/kaggle/working/placement_test_data.npz')\ntest_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 5\noutput_size = 2\n\nhidden_layer_size = 55","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation='softmax')\n])\n\nmodel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n\nbatch_size = 55\nmax_epochs = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Early Stopping"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(patience = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fitting the Data to the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_inputs, train_targets,\n         batch_size = batch_size,\n         epochs= max_epochs,\n         callbacks = [early_stopping],\n         validation_data = (validation_inputs, validation_targets),\n         verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'], color = 'red', label = 'Training Loss')\nplt.plot(history.history['val_loss'], color = 'blue', label = 'Validation Loss')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'], color = 'red', label = 'Training Accuracy')\nplt.plot(history.history['val_accuracy'], color = 'blue', label = 'Validation Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Hence, We see that the DNN Model is the best perfroming model with 95.35% Validation Accuracy"},{"metadata":{},"cell_type":"markdown","source":"## Kindly upvote if you found this notebook useful! Thank you!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}