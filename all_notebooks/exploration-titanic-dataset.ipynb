{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic Survival Predictions - Machine Learning Exploration"},{"metadata":{},"cell_type":"markdown","source":"Hi, I'm Giodio Mitaart a Computer Science Student at BINUS University. In this notebook, I want to try to explore the titanic dataset to re-learn Machine Learning courses that I have studied. If you have any feedback, please write it here! Thank you: D"},{"metadata":{},"cell_type":"markdown","source":"### The main parts:\n1. Import important libraries\n2. Read and explore the dataset\n3. Data analysis\n4. Visualization\n5. Cleaning dataset\n6. Build the machine learning model"},{"metadata":{},"cell_type":"markdown","source":"## 1. Import important libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sb\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Read and explore the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/titanic/train.csv')\ntest_df = pd.read_csv('../input/titanic/test.csv')\n\n#quick look at the training data\ntrain_df.describe() #add parameter include='all' to see more","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the features list in the dataset\nprint(train_df.columns)\n\n#see the sample in order the get an idea of the features\ntrain_df.sample(5) #or we can use train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get insights using dtypes\ntrain_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some info that we gained:\n* Age, Fare, SibSp, Parch (Numerical Features)\n* Survived, Sex, Embarked, Pclass (Categorical Features)\n* Ticket, Cabin (Alphanumeric Features)"},{"metadata":{},"cell_type":"markdown","source":"The data types of every features:\n* Age: float\n* SibSp: int\n* Parch: int\n* Survived: int\n* Sex: string\n* Embarked: string\n* Pclass: int\n* Ticket: string\n* Cabin: string"},{"metadata":{"trusted":true},"cell_type":"code","source":"#quick look to the training dataset\ntrain_df.describe(include = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights:\n* There are 891 passengers\n* If we see carefully, there is a gap in Age features (891-714)/891 = 19.8% of the values is missing. Maybe we need to handle this because in my opinion age has a significant factors to determine passengers' survival possibility\n* The Cabin features also missing about 77% of its values. Because there is a significant gap, we will skip (drop) this column"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the missing values\ntrain_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's make some hypothesis:\n1. Age: Young people has the higher possibility to survive than the old ones\n2. Sex: Female chance to survive is higher than the male\n3. Pclass: If people from high class are more likely to survive\n4. Parch: People who travel alone has higher chance to survive than people who travel with family"},{"metadata":{},"cell_type":"markdown","source":"## 4. Visualization"},{"metadata":{},"cell_type":"markdown","source":"### Age feature visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#devide the ages into logical labels\ntrain_df['Age'] = train_df['Age'].fillna(-0.5)\ntest_df['Age'] = test_df['Age'].fillna(-0.5)\n\nbins = [-1, 0, 5, 12, 17, 25, 40, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teen', 'Young', 'Young Adult', 'Adult', 'Old']\n\ntrain_df['Group'] = pd.cut(train_df['Age'], bins, labels = labels)\ntest_df['Group'] = pd.cut(test_df['Age'], bins, labels = labels)\n\nsb.barplot(x='Group', y='Survived', data = train_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sex feature visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#show the bar plot of surrvival chance by sex\nsb.barplot(x='Sex', y='Survived', data = train_df)\n\n#show the percentage of female and male that survived\nprint('Female survived in percentage: ', train_df['Survived'][train_df['Sex'] == 'female'].value_counts(normalize=True)[1]*100)\nprint('Male survived in percentage: ', train_df['Survived'][train_df['Sex'] == 'male'].value_counts(normalize=True)[1]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that as the hypothesis above, female has a higher chance of survival than male."},{"metadata":{},"cell_type":"markdown","source":"### Pclass feature visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#show the bar plot of surrvival chance by sex\nsb.barplot(x='Pclass', y='Survived', data = train_df)\n\n#show the percentage of people survived by Pclass\nprint('Pclass 1 survived percentage: ', train_df['Survived'][train_df['Pclass'] == 1].value_counts(normalize = True)[1]*100)\nprint('Pclass 2 survived percentage: ', train_df['Survived'][train_df['Pclass'] == 2].value_counts(normalize = True)[1]*100)\nprint('Pclass 2 survived percentage: ', train_df['Survived'][train_df['Pclass'] == 3].value_counts(normalize = True)[1]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that as the hypothesis above, people with who come from high class has a higher chance to survive than the lower."},{"metadata":{},"cell_type":"markdown","source":"### Parch feature visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#show the bar plot for the parent with child survival\nsb.barplot(x='Parch', y='Survived', data = train_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Data Cleansing"},{"metadata":{},"cell_type":"markdown","source":"Clean our data for missing values and unwanted information."},{"metadata":{},"cell_type":"markdown","source":"### Quick look to the test data, and get some insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop Cabin and Ticket columns because there are not much useful information that can be gained from the features. Also, we will try to see embarked feature."},{"metadata":{},"cell_type":"markdown","source":"### Drop Cabin"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['Cabin'], axis = 1)\ntest_df = test_df.drop(['Cabin'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Ticket"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['Ticket'], axis = 1)\ntest_df = test_df.drop(['Ticket'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Embarked feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"#find insight from this feature\nprint('Total of people embarking in Southampton: ')\ns = train_df[train_df['Embarked'] == 'S'].shape[0]\nprint(s)\n\nprint('Total of people embarking in Cherbourg: ')\nc = train_df[train_df['Embarked'] == 'C'].shape[0]\nprint(c)\n\nprint('Total of people embarking in Queenstown: ')\nq = train_df[train_df['Embarked'] == 'Q'].shape[0]\nprint(q)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the information above, it's clear that majority of people embarked in Southampton. So, we can make an assumption to fill the missing values with S (Southampthon)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill the missing values in Embarked feature with S\ntrain_df = train_df.fillna({'Embarked': 'S'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine the train and test dataset\ncombine_df = [train_df, test_df]\n\n#extract title for every name in the combined dataset\n#how to extract data from string variable\n#https://www.kaggle.com/questions-and-answers/141854\nfor dataset in combine_df:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n#cross tabulation is a method to quantitatively analyze the relationship between multiple variables.\npd.crosstab(train_df['Title'], train_df['Sex'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Name feature"},{"metadata":{},"cell_type":"markdown","source":"After extract the data, now we will drop this feature since it will no longer used"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.drop(['Name'], axis = 1)\ntest_df = test_df.drop(['Name'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sex feature to numerical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#mapping sex type to numerical value\nsex_mapping = {\"male\":0, \"female\":1}\ntrain_df['Sex'] = train_df['Sex'].map(sex_mapping)\ntest_df['Sex'] = test_df['Sex'].map(sex_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#peek the data after mapping to numerical value\ntrain_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Embarked feature to numerical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#mapping embarked type to numerical value\nembarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\ntrain_df['Embarked'] = train_df['Embarked'].map(embarked_mapping)\ntest_df['Embarked'] = test_df['Embarked'].map(embarked_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop group and title (temporary)\ntrain_df = train_df.drop(['Group'], axis = 1)\ntest_df = test_df.drop(['Group'], axis = 1)\n\ntrain_df = train_df.drop(['Title'], axis = 1)\ntest_df = test_df.drop(['Title'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#peek the data after mapping\ntrain_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Testing Model"},{"metadata":{},"cell_type":"markdown","source":"Let's split the training data to 0.2 to test the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import sklearn's train_test_split\nfrom sklearn.model_selection import train_test_split\n\npredict = train_df.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train_df['Survived']\nx_train, x_test, y_train, y_test = train_test_split(predict, target, test_size = 0.22, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logisic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"#logistic regression and accuracy score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\ny_pred = lr.predict(x_test)\nacc_lr = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVM\nfrom sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_test)\nacc_svc = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"#random forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)So, what's the best model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_models = pd.DataFrame({\n    'ML_Model': ['Logistic Regression', 'Support Vector Machines',\n              'Random Forest'],\n    'Score_Accuracy': [acc_lr, acc_svc, \n              acc_randomforest]})\n\n\nml_models.sort_values(by='Score_Accuracy', ascending=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}