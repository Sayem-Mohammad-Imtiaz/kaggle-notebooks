{"cells":[{"metadata":{"_uuid":"13d075dbc6f1f46dc0823b033bb39748e612d156"},"cell_type":"markdown","source":"# **Introduction**\nIn this notebook, I will find solutions for PASSNYC: Data Science for Good challenge. This is third Data Science for Good competition organized by Kaggle. This notebook is a contribution to this challenge. \n\nPASSNYC is a not-for-profit, volunteer organization dedicated to broadening educational opportunities for New York City's talented underserved students. PASSNYC aims to identify talented underserved students within New York Cityâ€™s underperforming school districts in order to increase the diversity of students taking the Specialized High School Admissions Test. \n\nIn the third Data science for Good challenge, PASSNYC parter with Kaggle for targeting more accurate and granular talented students and schools. They provided us with some sample data for this solutions. "},{"metadata":{"_uuid":"04c20b8c3d65b46c127ad2757da8d126ab7d60b6"},"cell_type":"markdown","source":"# Dataset Overview \nIn this notebook, I used 10 datasets. Among them, 2 datasets are official meaning that is provided by PASSNYC. And another 5 additional datasets, those were collected from different sources. Below I provide all of this dataset overview, their sources and what features I take from those datasets. \n\n1. **2016 School Explorer.csv:** Consolidated school characteristics such as student demographics and standardized test performance from public data sources for 1270 NYC public elementary and middle schools. I use a lot of features from this dataset. Like ENI, Average Math Proficiency, Ethnicity percentage and lot more. \n\n2. **D5 SHSAT Registrations and Testers.csv: ** District 5 (Central Harlem) SHSAT (Specialized High School Test) data from the NYC Department of Education: Time series enrollment, SHSAT registrations & participation for that community. When I started working on this challenge, I used its number of SHSAT takers column. But it only contains a very few school information. Later, I found a better dataset compare to this. \n\n3. **nytdf.csv:** From [this post](https://www.kaggle.com/passnyc/data-science-for-good/discussion/60308) I have collected this dataset. This is an output file of [this kerenel](https://www.kaggle.com/rdisalv2/parsing-nyt-shsat-table/output). This contains the number of SHSAT taker information of at least over 550 schools. Instead of using D5 SHSAT Registrations and Testers dataset I use this dataset. Because it has more information. Though this dataset is collected from a Kernel and that kernel collect the data from NYT, this dataset is also currently available in [here](https://data.cityofnewyork.us/Education/2017-2018-SHSAT-Admissions-Test-Offers-By-Sending-/vsgi-eeb5/). \n\n4. **School Quality Dataset Report 2015-16:** This dataset is collected from [here](https://infohub.nyced.org/reports-and-policies/school-quality/school-quality-reports-and-resources). It is a very informative dataset. This dataset is very useful for this challenge. I used many columns from this dataset. Those are\n       'Enrollment', 'Percent Students with Disabilities', 'Percent Self-Contained', 'Percent in Temp Housing', 'Percent HRA Eligible',  'Years of principal experience at this school', 'Percent of teachers with 3 or more years of experience',  'Teacher Attendance Rate'\n       \n5. **NYC Schools Details:** This dataset is collected from [here](https://nimader.carto.com/tables/elem_schools_infowindow_master_file_with_ratios_12_11/public). It is a very useful and informative dataset. What uniques about this dataset is that it gives us each *schools zone family median income*. That was really helpful for this project. But I don't use this dataset in this notebook, because after merging this dataset with our school explorer dataset, I saw that this dataset has very few schools that were situated in New York City. For that reason, I don't use this dataset in this notebook. Though it doesn't mean it can't be used. In the future, it can useful for PASSNYC to further research. \n\n6. **NYC School Demographics:** This dataset is collected from [here](https://infohub.nyced.org/reports-and-policies/citywide-information-and-data/information-and-data-overview). It is also a very useful dataset. It contains information about NYC School demographics. I use a few features from this dataset. Those are \n        'Total Enrollment','# Female', '# Male', '# Poverty', '% Poverty'\n        \n    In this dataset, there are also many features that I not used. It can be useful for further analysis. \n \n7. **NY 2010-2011 Class Size - School-level detail:** This dataset is also useful. It gives us much information about school class size and more in a granular way. I used class size feature from this dataset. \n "},{"metadata":{"_uuid":"44739589eb9a8b71d946d56d0a1797e28298269d"},"cell_type":"markdown","source":"# Solution Overview\nI breakup the solution into two steps. First let's see some graphic of the solutions for easy understanding\n\n![Imgur](https://i.imgur.com/HwnOoQc.png)\n\n\n\n\nBefore solutions let's go to the problem first. The problem is the SHSAT exam is a gateway to get admission in NYC specialized schools. But if we analyze the NYC specialized high schools, we can see that there is not so diversity. Meaning Asian and white are the very higher percentage where black, female are low percentage. That's a few problems. So PASSNYC aim to get more students into the SHSAT exam, meaning diversity in SHSAT exam. That is the problem, how we can make SHSAT exam with more diversity. \n\n\nLet's come to my solution. The PASSNYC team provided us two datasets about NYC schools those are very useful. I have found other 5 additional datasets that are also useful and they are school label datasets. I merged them using DBN key. Then I take only useful column among this dataset and try to find the relationship with Number of SHSAT takers.  The new merged dataset has half of the rows compared to School exploere.csv dataset provided by PASSNYC. The reason for that the dataset nytdf.csv contains only half of the schools compared to School explore. Becuase we don't find any alternative we stick to it. The nytdf.csv has features called number of SHSAT takers. \n\n\nAfter that, I grouped all those useful columns in different fragment and calculated a weighted sum score for each group. Those groups are \n           \n           'score_education', 'score_educaton_system', 'score_school_quality','score_student_situation', 'score_gender'\nThen I try to find the relationship between these scores and number of SHSAT takers. Some scores are positively and some are negatively correlated with the number of SHSAT takers. \n\n\n\n![Imgur](https://i.imgur.com/ALQRBs0.png)\nRemember that our merged dataset has half of the rows compared to school explorer dataset because of merging with nytdf.csv. Now let's merge our dataset again but this time I will not include nytdf.csv because we don't need it. Becuase we already see the relationship between the number of SHSAT takers and different calculated score. We can now tell our calculated score has relation with the number of SHSAT takers. So after the second merge with datasets(not included nytdf.csv), now calculated those score again. \n\n\nThen apply a clustering algorithm, I used Kmeans. Then we can see that 5 distinct clusters in school. Now assign the cluster number to each school. After that calculate the median score of each score category by grouping with cluster number. We can now see which cluster score in the different category. Now we know that which cluster's school is more underrepresented in which category. \n"},{"metadata":{"_uuid":"1721c88ce69db2e419d499d028b69f1844b33675"},"cell_type":"markdown","source":"\n\n# Table of Contents\n\n[1. First Step](#first_step)\n   - [Load our dataset](#load_dataset)\n   - [Merge all datasets](#merge_all_dataset)\n   - [EDA](#eda_first_step)\n   - [Calculate Score and compare it with number of SHSAT takers](#calculate_score_first_step)\n\n[2. Second Step: Final model Building](#second_step)\n   - [Merge Dataset Again](#merge_dataset_second_step)\n   - [Calculate score](#calculate_score_second_step)\n   - [Applying Kmeans clustering algorithom](#applying_cluster_result)\n   - [EDA on cluster result](#eda_cluster_result)\n   \n[3. How PASSNYC implement these solution](#passnyc_implent_this_solutions)\n\n[4. Distribution of clusters on map](#distrubution_of_cluster)\n\n[5. Conclusion](#conclusion)"},{"metadata":{"_uuid":"505915c11f3b4698487169b1602da7b2f61dfbe8"},"cell_type":"markdown","source":"<a id='first_step'></a>\n<a id='load_dataset'></a>\n\n# 1. First Step\n# Load our datasets"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting \nplt.style.use('ggplot') # use ggplot style for beautify\nimport seaborn as sns # useful library for many visualization and finding relation\nimport geojson # load jeojson file in python\nimport folium # folium for plotting asesome map\nfrom folium.plugins import MarkerCluster # marker for clustering school marker\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"df_school_exlorer = pd.read_csv('../input/data-science-for-good/2016 School Explorer.csv') # load 2016 school explorer dataset\ndf_shsat_reg_test = pd.read_csv('../input/data-science-for-good/D5 SHSAT Registrations and Testers.csv') # load district5 schools SHSAT dataset\ndf_shsat_nyt = pd.read_csv('../input/parsing-nyt-shsat-table/nytdf.csv')\ndf_school_quality = pd.read_csv('../input/school-quality-dataset-report-201516/summery_school_quality_result.csv')\ndf_school_details = pd.read_csv('../input/nyc-schools-details/elem_schools_infowindow_master_file_with_ratios_12_11.csv')\ndf_school_demographics = pd.read_csv('../input/nyc-school-demographics/nyc_school_demographics.csv', encoding = \"ISO-8859-1\")\ndf_school_class_size = pd.read_csv('../input/ny-2010-2011-class-size-school-level-detail/2010-2011-class-size-school-level-detail.csv')\nprint(\"The shape of df_school_explorer \" + str(df_school_exlorer.shape)) # print the shape of dataset\nprint(\"The shape of df_shsat_reg_test \" + str(df_shsat_reg_test.shape)) # print the shape of dataset\nprint(\"The shape of df_shsat_nyt \" + str(df_shsat_nyt.shape))\nprint(\"The shape of df_school_quality \" + str(df_school_quality.shape))\nprint(\"The shape of df_school_details \" + str(df_school_details.shape))\nprint(\"The shape of df_school_demographics \" + str(df_school_demographics.shape))\nprint(\"The shape of df_school_class_size \" + str(df_school_class_size.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e51582b6057eb8c291789137382373d3e22a5843","scrolled":true,"collapsed":true},"cell_type":"code","source":"df_school_exlorer.head(2) # print the first two rwos of dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74940af904677511159ead2d2a109760f99def7d","collapsed":true},"cell_type":"code","source":"df_shsat_reg_test.head() # print the second datast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"437913e275ce27bb187d1de717f779a1229dcff3","collapsed":true},"cell_type":"code","source":"df_shsat_nyt.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"278d4598169e285ba4a0c16651ece2a14217ff54"},"cell_type":"markdown","source":"We see that our first dataset '2016 School Explorer.csv' has **1272 rows and 161 columns**.  We also saw a slight pick of our dataset and dataset description. "},{"metadata":{"_uuid":"1ca02e47aca2a8408d053d4c34aecc84183b91f0"},"cell_type":"markdown","source":"## Let's see the distribution of scools in New York city"},{"metadata":{"trusted":true,"_uuid":"8ac6338408b47cdd1b0be00143796b8c4f815ce2","collapsed":true},"cell_type":"code","source":"\nwith open('../input/minority-majority/nyc_scl_destrict.geojson') as f: # open the jeojson file\n    gj = geojson.load(f) # load the jeojson file \n\nkw = {\n    'prefix': 'fa',\n    'color': 'green',\n    'icon': 'adn'\n}\n\nfolium_map = folium.Map(location=[40.7128, -74.0060], zoom_start=11, tiles=\"Stamen Terrain\") # create the Map object \nmarker_cluster = MarkerCluster().add_to(folium_map) # marker cluster for clustering marker for easy understanding\nfolium.GeoJson(gj).add_to(folium_map) # add jeojson to the map. So that NYC school border should show on the map\n\nfor index, row in df_school_exlorer.iterrows(): # iter over every row in the dataset\n    folium.Marker(location=(row[\"Latitude\"],row[\"Longitude\"]), icon=folium.Icon(**kw)).add_to(marker_cluster) # plot a marker on the map for a school\n    \nfolium_map   # show the folium map","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aff3efbbd22150e1ac513912e3269faa60af344e"},"cell_type":"markdown","source":"That's look beautiful. We can see where the schools located. So we can easily plot different EDA in future for our analysis. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"70a403755ee721f27e41f3a4cea25ac96976b694"},"cell_type":"markdown","source":"<a id='merge_all_dataset'></a>\n\n# Merge all datasets\nIn this section, I will merge all dataset on DBN as a key. Also, I will do some preprocessing for usability. I have put comment before each line of code for easy understanding. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"84a6f1ef5015c166477f578a8526000c2d3af8fe"},"cell_type":"code","source":"# some preprocessing\ndf_school_exlorer = df_school_exlorer.rename(columns={'Location Code': 'DBN'}) # change key column name so that it matches with each other \ndf_school_details = df_school_details.rename(columns={'dbn': 'DBN'}) # change key column name so that it matches with each other \ndf_school_class_size = df_school_class_size.rename(columns={'SCHOOL NAME': 'School Name'}) # change key column name so that it matches with each other \ndf_school_demographics_new = df_school_demographics.loc[df_school_demographics['Year'] == '2017-18'] # we only need data on recent years \ndf_school_class_size_new = df_school_class_size.loc[df_school_class_size['GRADE '] == '08'] # we only need data on 8 grade\n\n\n# these are the columns name that will be used from School explorer \nneeded_columns_df_school_explorer = ['School Name', 'SED Code', 'DBN', 'District', \n                                     'Latitude', 'Longitude', 'Address (Full)',\n                                     'City', 'Zip', 'Grades', \n                                     'Grade Low','Grade High','Community School?',\n                                     'Economic Need Index', 'School Income Estimate',\n                                     'Percent ELL', 'Percent Asian', 'Percent Black', \n                                     'Percent Hispanic', \n                                     'Percent Black / Hispanic', 'Percent White',\n                                     'Student Attendance Rate', \n                                     'Percent of Students Chronically Absent', \n                                     'Rigorous Instruction %', 'Collaborative Teachers %',\n                                     'Supportive Environment %', 'Effective School Leadership %', \n                                     'Strong Family-Community Ties %',\n                                     'Trust %', 'Student Achievement Rating', \n                                     'Average ELA Proficiency', \n                                     'Average Math Proficiency',\n                                     'Grade 8 ELA - All Students Tested', \n                                     'Grade 8 ELA 4s - All Students', \n                                     'Grade 8 ELA 4s - American Indian or Alaska Native',\n                                     'Grade 8 ELA 4s - Black or African American',\n                                     'Grade 8 ELA 4s - Hispanic or Latino', \n                                     'Grade 8 ELA 4s - Asian or Pacific Islander',\n                                     'Grade 8 ELA 4s - White', 'Grade 8 ELA 4s - Multiracial', \n                                     'Grade 8 ELA 4s - Limited English Proficient',\n                                     'Grade 8 ELA 4s - Economically Disadvantaged', \n                                     'Grade 8 Math - All Students Tested', \n                                     'Grade 8 Math 4s - All Students',\n                                     'Grade 8 Math 4s - American Indian or Alaska Native', \n                                     'Grade 8 Math 4s - Black or African American',\n                                     'Grade 8 Math 4s - Hispanic or Latino', \n                                     'Grade 8 Math 4s - Asian or Pacific Islander', \n                                     'Grade 8 Math 4s - White',\n                                     'Grade 8 Math 4s - Multiracial', \n                                     'Grade 8 Math 4s - Limited English Proficient', \n                                     'Grade 8 Math 4s - Economically Disadvantaged']\n\n# these are the columns that will be used from School Quality dataset\nneeded_columns_df_school_quality = ['DBN','Enrollment',\n                                    'Percent Students with Disabilities',\n                                    'Percent Self-Contained',\n                                    'Percent in Temp Housing', \n                                    'Percent HRA Eligible', \n                                    'Years of principal experience at this school',\n                                    'Percent of teachers with 3 or more years of experience', \n                                    'Teacher Attendance Rate']\n\n# these are the columns that will be used from School Demographic dataset\nneeded_columns_df_school_demographic = ['DBN', 'Total Enrollment','# Female', '# Male', '# Poverty', '% Poverty']\n# # these are the columns that will be used from School Size dataset\nneeded_columns_df_school_size = ['School Name','AVERAGE CLASS SIZE']\n\n\npunctuation_contains_columns = ['School Income Estimate', 'Percent ELL', \n                                'Percent Asian', 'Percent Black', \n                                'Percent Hispanic', 'Percent Black / Hispanic', \n                                'Percent White', 'Student Attendance Rate',\n                                'Percent of Students Chronically Absent', \n                                'Rigorous Instruction %', \n                                'Collaborative Teachers %',\n                                'Supportive Environment %', \n                                'Effective School Leadership %', \n                                'Strong Family-Community Ties %',\n                                'Trust %', 'Percent Students with Disabilities',\n                                'Percent Self-Contained',\n                                'Percent in Temp Housing', \n                                'Percent HRA Eligible', \n                                'Percent of teachers with 3 or more years of experience',\n                                'Teacher Attendance Rate'] # list of column names that contains punctuation ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"409c9aae61dfd3f961e4781ca58f9e226eda801a","collapsed":true},"cell_type":"code","source":"# let's keep only those columns that we will be using \ndf_school_exlorer_new = df_school_exlorer[needed_columns_df_school_explorer]\ndf_school_quality_new = df_school_quality[needed_columns_df_school_quality]\ndf_school_demographics_new = df_school_demographics_new[needed_columns_df_school_demographic]\ndf_school_class_size_new = df_school_class_size_new[needed_columns_df_school_size]\n\n# lower case our school name because in this dataset we will be using School Name column as key\ndf_school_class_size_new['School Name'] = df_school_class_size_new['School Name'].str.lower()\ndf_school_exlorer_new['School Name'] = df_school_exlorer['School Name'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"29c955115addf753917839e0cc3f693a24ea5166"},"cell_type":"code","source":"# let's merge our alll datasets\ndf_shsat_nyt = pd.merge(df_school_exlorer_new, df_shsat_nyt, on='DBN')\ndf_shsat_nyt = pd.merge(df_school_quality_new, df_shsat_nyt, on='DBN')\ndf_shsat_nyt = pd.merge(df_shsat_nyt, df_school_demographics_new, on='DBN')\ndf_shsat_nyt = pd.merge(df_shsat_nyt, df_school_class_size_new, on='School Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f48cd06a475bd37834dfe5fabf0586a45e6e1644","collapsed":true},"cell_type":"code","source":"# some preprocessing\nfor col in punctuation_contains_columns: \n    df_shsat_nyt[col] = df_shsat_nyt[col].str.replace('[^\\w\\s]','') # remove punctuation from each column\n    \ndf_shsat_nyt = df_shsat_nyt.apply(pd.to_numeric, errors='ignore') # some of our percentage column values data type is str. change it to int\ndf_shsat_nyt.head() # print the head of our mereged dataset of two previous dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3201727c45cbb521dd7cfd1418173517f38f1544","collapsed":true},"cell_type":"code","source":"# let's print the shape\ndf_shsat_nyt.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16389314c4e6c765d65ab1a0b7a771daab02a4f2"},"cell_type":"markdown","source":"<a id='eda_first_step'></a>\n\n# EDA \n> In this section, I will do some analysis for finding meaningful information and key insights from merged datasets. More importantly, I will try find relationship between important columns and number of SHSAT takers for each school. "},{"metadata":{"trusted":true,"_uuid":"dbe55594c713fb079213c5534c8e50ff6f395d81","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=3)\nsns.regplot(x=\"Economic Need Index\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt,  ax=axs[0])\nsns.regplot(x=\"School Income Estimate\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[2])\nsns.regplot(x=\"Percent ELL\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[1])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2513993b8efa581c2de1b7f18c766c5223206bf4"},"cell_type":"markdown","source":"    Takeaways: \n    * We can see that as ENI increases the number of students who took SHSAT to decrease. \n    * In the second plot, we can see ELL increases the number of students who took SHSAT to decrease. \n    * In the last plot, we can see that as School Income increases the number of SHSAT participant incerase. But we are also seeing that very low   value in School Income Estimate. There may be lot of null values. \n\n"},{"metadata":{"trusted":true,"_uuid":"3aa8aa7e19619845cf51345165730a5b4588a8b7","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=5)\nsns.regplot(x=\"Percent Asian\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt,  ax=axs[0])\nsns.regplot(x=\"Percent Black\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[1])\nsns.regplot(x=\"Percent Hispanic\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[2])\nsns.regplot(x=\"Percent Black / Hispanic\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[3])\nsns.regplot(x=\"Percent White\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[4])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ae34c64f62b02f22470188df60630d9d8e14601"},"cell_type":"markdown","source":"    Takeaways:\n\n    * In this plot, we can see the number of SHSAT participant increases with Percent Asian and Percent White and decreases with Percent Black, Percent Hispanic, Percent Black/ Hispanic. \n\n    That means most of the SHSAT takers are Asian or White. Black and Hispanic are always low in the SHSAT exam. "},{"metadata":{"trusted":true,"_uuid":"dc43cb2e3ffaf678ee43b1023ab99b71df5d51be","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=5)\nsns.regplot(x=\"Grade 8 Math 4s - All Students\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt,  ax=axs[0])\nsns.regplot(x=\"Grade 8 ELA 4s - All Students\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[1])\nsns.regplot(x=\"Average Math Proficiency\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[2])\nsns.regplot(x=\"Average ELA Proficiency\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[3])\nsns.regplot(x=\"Strong Family-Community Ties %\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[4])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"116041a1ebe47da20764b13ade10dbaabc5018b7"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"714af4f49437418709f7e7e2ee086866fbd899a0","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=5)\nsns.regplot(x=\"Enrollment\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt,  ax=axs[0])\nsns.regplot(x=\"Percent Students with Disabilities\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[1])\nsns.regplot(x=\"Percent Self-Contained\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[2])\nsns.regplot(x=\"Percent in Temp Housing\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[3])\nsns.regplot(x=\"Percent HRA Eligible\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[4])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee63644a5ecb0e7e4593655e9680ad5e5af8e829","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=6)\nsns.regplot(x=\"Years of principal experience at this school\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt,  ax=axs[0])\nsns.regplot(x=\"Percent of teachers with 3 or more years of experience\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[1])\nsns.regplot(x=\"Teacher Attendance Rate\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[2])\nsns.regplot(x=\"# Poverty\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[3])\nsns.regplot(x=\"# Female\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[4])\nsns.regplot(x=\"# Male\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[5])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"049cd0d6ff430b668b7bd5505aae98dfba81c286","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=6)\nsns.regplot(x=\"Grade 8 ELA 4s - American Indian or Alaska Native\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt,  ax=axs[0])\nsns.regplot(x=\"Grade 8 ELA 4s - Black or African American\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[1])\nsns.regplot(x=\"Grade 8 ELA 4s - Hispanic or Latino\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[2])\nsns.regplot(x=\"Grade 8 ELA 4s - Asian or Pacific Islander\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[3])\nsns.regplot(x=\"Grade 8 ELA 4s - White\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[4])\nsns.regplot(x=\"AVERAGE CLASS SIZE\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt, ax=axs[5])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ce8e5514b7cf307bdd981b3d16221387d7c3491"},"cell_type":"markdown","source":"    Takeaways from all these plot:\n    We can see some column is positively or negetivly correlated with number of SHSAT takers. And some column value is always same. We will take that information and take descision when calculating score. "},{"metadata":{"_uuid":"64a9c840376637528c2dfc702c3444f4efe96fdd"},"cell_type":"markdown","source":"<a id='calculate_score_first_step'></a>\n\n# Calculate Score and compare it with number of SHSAT takers\n> In this section, I will try add diifferent category score to each school. This scores is calculated using weighted sum approach. And then I will try to find relationship among these scores and number of SHSAT takers. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"64447b8ee6f90f7e3848c499035b990332999ed1"},"cell_type":"code","source":"# these columns will be used to calculate teh ethnicity score\nethnicity_score_column = ['Percent Asian', \n                          'Percent Black', \n                          'Percent Hispanic', \n                          'Percent Black / Hispanic', \n                          'Percent White']\n# these columns will be used to calculate education score\neducation_score_column = ['Percent ELL',\n                          'Average ELA Proficiency', \n                          'Average Math Proficiency']\n# these columns will be used to calculate education system score\neducation_system_column = ['Percent of Students Chronically Absent', \n                          'Rigorous Instruction %',\n                          'Collaborative Teachers %',\n                          'Supportive Environment %',\n                          'Effective School Leadership %', \n                          'Strong Family-Community Ties %',\n                          'Trust %']\n# these columns will be used to calculate school quality score\nschool_quality_column = ['Student Attendance Rate',\n                         'Years of principal experience at this school',\n                         'Percent of teachers with 3 or more years of experience', \n                         'Teacher Attendance Rate',\n                         'Total Enrollment']\n# these columns will be used to calculate student situation score\nstudent_situation_column = ['Percent Students with Disabilities',\n                            'Percent Self-Contained',\n                            'Percent in Temp Housing', \n                            'Percent HRA Eligible', \n                            '# Poverty']\n\n# these columns will be used to calculate student gender score\nstudent_gender_column = ['# Female', '# Male']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04d24a8c5c7682540e65bc77b6c14ad98444ed05","collapsed":true},"cell_type":"code","source":"df_shsat_nyt_new = df_shsat_nyt.copy() # create new copy of merged dataset\n# calculate ethnicity score by weighted sum approces\ndf_shsat_nyt_new['score_ethnicity'] = df_shsat_nyt_new['Percent Asian'] * 0.2 + \\\n                                      df_shsat_nyt_new['Percent Black / Hispanic'] * 0.5 + \\\n                                      df_shsat_nyt_new['Percent White'] * 0.3\n# calculate education score by weighted sum approces        \ndf_shsat_nyt_new['score_education'] = df_shsat_nyt_new['Percent ELL'] * 0.4 + \\\n                                      df_shsat_nyt_new['Average ELA Proficiency'] * 0. + \\\n                                      df_shsat_nyt_new['Average Math Proficiency'] * 0.2\n\n# calculate education score by weighted sum approces    \ndf_shsat_nyt_new['score_educaton_system'] = df_shsat_nyt_new['Percent of Students Chronically Absent'] * 0.1 + \\\n                                      df_shsat_nyt_new['Rigorous Instruction %'] * 0.1 + \\\n                                      df_shsat_nyt_new['Collaborative Teachers %'] * 0.1 + \\\n                                      df_shsat_nyt_new['Supportive Environment %'] * 0.2 + \\\n                                      df_shsat_nyt_new['Effective School Leadership %'] * 0.2 + \\\n                                      df_shsat_nyt_new['Strong Family-Community Ties %'] * 0.2 + \\\n                                      df_shsat_nyt_new['Trust %'] * 0.1\n\n# calculate school quality score by weighted sum approces\ndf_shsat_nyt_new['score_school_quality'] = df_shsat_nyt_new['Student Attendance Rate'] * 0.2 + \\\n                                      df_shsat_nyt_new['Years of principal experience at this school'] * 0.2 + \\\n                                      df_shsat_nyt_new['Percent of teachers with 3 or more years of experience'] * 0.2 + \\\n                                      df_shsat_nyt_new['Teacher Attendance Rate'] * 0.2 + \\\n                                      df_shsat_nyt_new['Total Enrollment'] * 0.2\n\n# calculate student situation score by weighted sum approces                        \ndf_shsat_nyt_new['score_student_situation'] = df_shsat_nyt_new['Percent Students with Disabilities'] * 0.6 + \\\n                                      df_shsat_nyt_new['Percent Self-Contained'] *0.1 + \\\n                                      df_shsat_nyt_new['Percent in Temp Housing'] * 0.1 + \\\n                                      df_shsat_nyt_new['Percent HRA Eligible'] * 0.1 + \\\n                                      df_shsat_nyt_new['# Poverty'] * 0.1\n# calculate gender score by weighted sum approces                \ndf_shsat_nyt_new['score_gender'] = df_shsat_nyt_new['# Female'] * 0.5 + \\\n                                      df_shsat_nyt_new['# Male'] *0.5\n    \n\n# let's combined those score score with weighted sum approaches    \ndf_shsat_nyt_new['score_combined'] = df_shsat_nyt_new['score_ethnicity'] * 0.1 + \\\n                                      df_shsat_nyt_new['score_education'] * 0.2 + \\\n                                      df_shsat_nyt_new['score_educaton_system'] * 0.1 + \\\n                                      df_shsat_nyt_new['score_school_quality'] * 0.1 + \\\n                                      df_shsat_nyt_new['score_student_situation'] * 0.4 + \\\n                                      df_shsat_nyt_new['score_gender'] * 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a937b2453535de4ebb8dcb6209a54df0f2631dd1","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=6)\nsns.regplot(x=\"score_ethnicity\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt_new,  ax=axs[0])\nsns.regplot(x=\"score_education\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt_new, ax=axs[1])\nsns.regplot(x=\"score_educaton_system\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt_new, ax=axs[2])\nsns.regplot(x=\"score_school_quality\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt_new, ax=axs[3])\nsns.regplot(x=\"score_student_situation\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt_new, ax=axs[4])\nsns.regplot(x=\"score_gender\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt_new, ax=axs[5])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f75f1593276a06655d78a386b759ce93f44bf49"},"cell_type":"markdown","source":"    Takeaways:\n\n    - Number of SHSAT takers decreases with score ethnicity\n    - Number of SHSAT takers decreases with score education\n    - Number of SHSAT takers decreases with score education system\n    - Number of SHSAT takers increases with score school quality\n    - Number of SHSAT takers decreases with score students situation\n    - Number of SHSAT takers increases with score gender\n    \n    \n    Remember these ideas, because it will be used in later. "},{"metadata":{"trusted":true,"_uuid":"1db12b49d7db83066f0ef78d67dc1e8a7ab4fc44","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(20,8),ncols=1)\nsns.regplot(x=\"score_combined\", y=\"NumSHSATTestTakers\", data=df_shsat_nyt_new,  ax=axs)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4eebb1ea1fc77c961210a9b4d2b0008d28d867b"},"cell_type":"markdown","source":"We can also see that combined score is positively correlated with number of SHSAT takers. "},{"metadata":{"_uuid":"4b9a9aceef9016f5b4ebb6598667cfe4f51f4f5e"},"cell_type":"markdown","source":"<a id='second_step'></a>\n<a id='merge_dataset_second_step'></a>\n\n\n# Second Step: Final model Building\n\n# Merge Dataset Again\n> In this section, I will merge datasets again without nytdf.csv. "},{"metadata":{"trusted":true,"_uuid":"e15f141af1daeb9f23eed9fc15f0daec49319468","collapsed":true},"cell_type":"code","source":"df_school_exlorer = df_school_exlorer.rename(columns={'Location Code': 'DBN'}) # change key column name so that it matches with each other \ndf_school_details = df_school_details.rename(columns={'dbn': 'DBN'}) # change key column name so that it matches with each other \ndf_school_class_size = df_school_class_size.rename(columns={'SCHOOL NAME': 'School Name'}) # change key column name so that it matches with each other \ndf_school_demographics_new = df_school_demographics.loc[df_school_demographics['Year'] == '2017-18']\ndf_school_class_size_new = df_school_class_size.loc[df_school_class_size['GRADE '] == '08']\n\n\n# let's use pandas merge function to merge our two datasets\ndf_school_exlorer_new = df_school_exlorer[needed_columns_df_school_explorer]\ndf_school_quality_new = df_school_quality[needed_columns_df_school_quality]\ndf_school_demographics_new = df_school_demographics_new[needed_columns_df_school_demographic]\ndf_school_class_size_new = df_school_class_size_new[needed_columns_df_school_size]\n\ndf_school_class_size_new['School Name'] = df_school_class_size_new['School Name'].str.lower()\ndf_school_exlorer_new['School Name'] = df_school_exlorer['School Name'].str.lower()\n\ndf_model = pd.merge(df_school_exlorer_new, df_school_quality_new, on='DBN')\ndf_model = pd.merge(df_model, df_school_demographics_new, on='DBN')\n# df_model = pd.merge(df_model, df_school_class_size_new, on='School Name')\n\n\nfor col in punctuation_contains_columns: \n    df_model[col] = df_model[col].str.replace('[^\\w\\s]','') # remove punctuation from each column\n    \ndf_model = df_model.apply(pd.to_numeric, errors='ignore') # some of our percentage column values data type is str. change it to int\ndf_model.head() # print the head of our mereged dataset of two previous dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51185e5442a283273d75a161e685dc37a5aec7ec","collapsed":true},"cell_type":"code","source":"df_model.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"557f40ac393437eb37aa56a83266fb769284a1f8"},"cell_type":"markdown","source":"\n<a id='calculate_score_second_step'></a>\n\n# Calculate score\n> In this section, I will try to calculate score again for our new merged dataset. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9b1dd4ed1c33214b35ff6eae475051e8fa014f28"},"cell_type":"code","source":"df_model['score_ethnicity'] = df_model['Percent Asian'] * 0.2 + \\\n                                      df_model['Percent Black / Hispanic'] * 0.5 + \\\n                                      df_model['Percent White'] * 0.3\n        \ndf_model['score_education'] = df_model['Percent ELL'] * 0.4 + \\\n                                      df_model['Average ELA Proficiency'] * 0. + \\\n                                      df_model['Average Math Proficiency'] * 0.2\n\n    \ndf_model['score_educaton_system'] = df_model['Percent of Students Chronically Absent'] * 0.1 + \\\n                                      df_model['Rigorous Instruction %'] * 0.1 + \\\n                                      df_model['Collaborative Teachers %'] * 0.1 + \\\n                                      df_model['Supportive Environment %'] * 0.2 + \\\n                                      df_model['Effective School Leadership %'] * 0.2 + \\\n                                      df_model['Strong Family-Community Ties %'] * 0.2 + \\\n                                      df_model['Trust %'] * 0.1\n\n\ndf_model['score_school_quality'] = df_model['Student Attendance Rate'] * 0.2 + \\\n                                      df_model['Years of principal experience at this school'] * 0.2 + \\\n                                      df_model['Percent of teachers with 3 or more years of experience'] * 0.2 + \\\n                                      df_model['Teacher Attendance Rate'] * 0.2 + \\\n                                      df_model['Total Enrollment'] * 0.2\n\n                        \ndf_model['score_student_situation'] = df_model['Percent Students with Disabilities'] * 0.6 + \\\n                                      df_model['Percent Self-Contained'] *0.1 + \\\n                                      df_model['Percent in Temp Housing'] * 0.1 + \\\n                                      df_model['Percent HRA Eligible'] * 0.1 + \\\n                                      df_model['# Poverty'] * 0.1\n                \ndf_model['score_gender'] = df_model['# Female'] * 0.5 + \\\n                                      df_model['# Male'] *0.5\n    \n\n    \ndf_model['score_combined'] = df_model['score_ethnicity'] * 0.1 + \\\n                                      df_model['score_education'] * 0.2 + \\\n                                      df_model['score_educaton_system'] * 0.1 + \\\n                                      df_model['score_school_quality'] * 0.1 + \\\n                                      df_model['score_student_situation'] * 0.4 + \\\n                                      df_model['score_gender'] * 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6adef0eac38bcaf3819f39cdd093f55d45a3725b"},"cell_type":"markdown","source":"<a id='applying_cluster_result'></a>\n\n# Applying Kmeans clustering algorithom\n> In this section, I will try to apply clustering algorithom. I used Kmeans in this notebook. "},{"metadata":{"trusted":true,"_uuid":"649a40aa31652dd65fbd71f1ec765483b0e34f67","collapsed":true},"cell_type":"code","source":"# columns that will be used in Kmeans\nkmeans_column = ['Economic Need Index',\n                                     'Percent ELL', 'Percent Asian', 'Percent Black', \n                                     'Percent Hispanic', \n                                     'Percent Black / Hispanic', 'Percent White',\n                                     'Student Attendance Rate', \n                                     'Percent of Students Chronically Absent', \n                                     'Rigorous Instruction %', 'Collaborative Teachers %',\n                                     'Supportive Environment %', 'Effective School Leadership %', \n                                     'Strong Family-Community Ties %',\n                                     'Trust %', \n                                     'Average ELA Proficiency', \n                                     'Average Math Proficiency',\n                                     'Grade 8 ELA - All Students Tested', \n                                     'Grade 8 ELA 4s - All Students', \n                                     'Grade 8 ELA 4s - American Indian or Alaska Native',\n                                     'Grade 8 ELA 4s - Black or African American',\n                                     'Grade 8 ELA 4s - Hispanic or Latino', \n                                     'Grade 8 ELA 4s - Asian or Pacific Islander',\n                                     'Grade 8 ELA 4s - White', 'Grade 8 ELA 4s - Multiracial', \n                                     'Grade 8 ELA 4s - Limited English Proficient',\n                                     'Grade 8 ELA 4s - Economically Disadvantaged', \n                                     'Grade 8 Math - All Students Tested', \n                                     'Grade 8 Math 4s - All Students',\n                                     'Grade 8 Math 4s - American Indian or Alaska Native', \n                                     'Grade 8 Math 4s - Black or African American',\n                                     'Grade 8 Math 4s - Hispanic or Latino', \n                                     'Grade 8 Math 4s - Asian or Pacific Islander', \n                                     'Grade 8 Math 4s - White',\n                                     'Grade 8 Math 4s - Multiracial', \n                                     'Grade 8 Math 4s - Limited English Proficient', \n                                     'Grade 8 Math 4s - Economically Disadvantaged', 'Enrollment',\n                                    'Percent Students with Disabilities',\n                                    'Percent Self-Contained',\n                                    'Percent in Temp Housing', \n                                    'Percent HRA Eligible','Total Enrollment','# Female', '# Male', '# Poverty']\n\n# some preprocessing\ndf_test = df_model[kmeans_column]\ndf_test = df_test.apply(pd.to_numeric)\nfrom sklearn.preprocessing import Imputer\nfill_NaN = Imputer(missing_values=np.nan, strategy='mean', axis=1)\nimputed_DF = pd.DataFrame(fill_NaN.fit_transform(df_test))\nimputed_DF.columns = df_test.columns\nimputed_DF.index = df_test.index\ndf_test = imputed_DF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f07114fa09ab63fce47617705897531c76777601","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from copy import deepcopy\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport networkx as nx\nfrom tqdm import tqdm\n\nimport hdbscan\nfrom sklearn import manifold\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.preprocessing import scale\nfrom sklearn.decomposition import PCA\nfrom sklearn.base import clone\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scikitplot as skplt\nfrom matplotlib.ticker import NullFormatter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d33af59c434bb5da885eb6549b42da25be50027f","collapsed":true},"cell_type":"code","source":"def get_cluster_colors(clusterer, palette='Paired'):\n    \"\"\"Create cluster colors based on labels and probability assignments\"\"\"\n    n_clusters = len(np.unique(clusterer.labels_))\n    color_palette = sns.color_palette(palette, n_clusters)\n    cluster_colors = [color_palette[x] if x >= 0 else (0.5, 0.5, 0.5) for x in clusterer.labels_]\n    if hasattr(clusterer, 'probabilities_'):\n        cluster_colors = [sns.desaturate(x, p) for x, p in zip(cluster_colors, clusterer.probabilities_)]\n    return cluster_colors\n\n# Prepare figure\n_, ax = plt.subplots(1, 2, figsize=(20, 5))\nsettings = {'s':50, 'linewidth':0, 'alpha':0.2}\n\nprint(\">> Calculating elbow plot for KMeans\")\nkmeans = KMeans(random_state=42)\nskplt.cluster.plot_elbow_curve(kmeans, df_test, cluster_ranges=[1, 5, 6,10, 20], ax=ax[0])\n\nprint(\">> Dimensionality reduction using TSNE\")\nprojection = manifold.TSNE(init='pca', random_state=42).fit_transform(df_test)\n\nprint(\">> Clustering using K-Means\")\nkmeans = KMeans(n_clusters=5).fit(projection)\n\n# PLot on figure\nax[1].scatter(*projection.T, c=get_cluster_colors(kmeans), **settings)\nax[1].set_title('K-Means Clusters')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67145e97e2bfa2eb9bf713db7c228cb14e80ea79","collapsed":true},"cell_type":"markdown","source":"    Takeaways:\n    - We can see that the optimal number cluster is about 5 from the elbow plot\n    - After applysing Kmeans we can clearly see five different cluster "},{"metadata":{"_uuid":"936166d74a0963c15f6619e0d3322e0e9238e44c"},"cell_type":"markdown","source":"<a id='eda_cluster_result'></a>\n\n# EDA on cluster result\n> Let's do some analysis on cluster result"},{"metadata":{"trusted":true,"_uuid":"f96375a04423f95cb02e0d7542527becb3aae484","collapsed":true},"cell_type":"code","source":"# Get number of clusters identified by HDBSCAN\nunique_clusters = [c for c in np.unique(kmeans.labels_) if c > -1]\n\n# Placeholder for our plotting\n_, axes = plt.subplots(len(unique_clusters), 1, figsize=(15, 25))\n\n# Go through clusters identified by HDBSCAN\nfor i, label in enumerate(unique_clusters):\n    \n    # Get index of this cluster\n    idx = kmeans.labels_ == label\n    \n    # Identify feature where the median differs significantly\n    median_diff = (df_test.median() - df_test[idx].median()).abs().sort_values(ascending=False)\n    \n    # Create boxplot of these features for all vs cluster\n    top = median_diff.index[0:20]\n    temp_concat = pd.concat([df_test.loc[:, top], df_test.loc[idx, top]], axis=0).reset_index(drop=True)\n    temp_concat['Cluster'] = 'Cluster {}'.format(i+1)\n    temp_concat.loc[0:len(df_test),'Cluster'] = 'All respondees'\n    temp_long = pd.melt(temp_concat, id_vars='Cluster')\n    \n    sns.boxplot(x='variable', y='value', hue='Cluster', data=temp_long, ax=axes[i])\n    for tick in axes[i].get_xticklabels():\n        tick.set_rotation(90)\n    axes[i].set_title(f'Cluster #{i+1} - {idx.sum()} respondees')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1af0a62d81a8b23cb5573efd196efe1de9726a6f"},"cell_type":"markdown","source":"We can now see every cluster variable analysis. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e38f6859dbaa5d935f9681abbbd9b3e0039964c4"},"cell_type":"code","source":"df_model['c'] = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91390e75758fc8743feb939a01067e0960721ddc"},"cell_type":"markdown","source":"    - Number of SHSAT takers decreases with score ethnicity\n    - Number of SHSAT takers decreases with score education\n    - Number of SHSAT takers decreases with score education system\n    - Number of SHSAT takers increases with score school quality\n    - Number of SHSAT takers decreases with score students situation\n    - Number of SHSAT takers increases with score gender"},{"metadata":{"trusted":true,"_uuid":"0812af293aa5acc1bbc154c0294e48f53212e556","collapsed":true},"cell_type":"code","source":"df_model.groupby('c')['score_education', 'score_educaton_system', 'score_school_quality','score_student_situation', 'score_gender'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74d08880f0d6152c300162d2539857777f6a7fc0"},"cell_type":"markdown","source":"\n    - In score_education_system, we can see that cluster 1 has highest score. And we know that number of SHSAT takers decreases with score_eduation_system. So, we can say that cluster 1 has lower number of SHSAT takers because of education syste. \n    \n    \n    - We can see that cluster 0 has lowest number of score in score_school_quality and score_gender. And we know the number of SHSAT takers increases with those score. So cluster 0 schools has lower number of SHSAT because of low school qualitly and low gender diversity. \n    \n    - We can see that cluster 4 has highest number of score in score_students_situation and score_education. And we know that number of SHSAT takers decrases with thsoe score. So cluster 4 has low number of SHSAT takers because of low students situations and low education. \n    \n    \n    There is a lot we can derive from this information. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"560444e4f0da4851515a9ddb13ddf39abea011ba"},"cell_type":"markdown","source":"<a id='passnyc_implent_this_solutions'></a>\n\n# How PASSNYC implement these solution\n> Let's think that in case of  schools in cluster 0. How will PASSNYC help them. We know that cluster 0 has lower number of SHSAT because score school quality and score gender. And thsoe score are calculated using thse column \n\n\n    'Student Attendance Rate','Years of principal experience at this school', 'Percent of teachers with 3 or more years of experience',  'Teacher Attendance Rate',  'Total Enrollment','# Female', '# Male'\n    \n   So we know that in cluster 0 schools has lack in these features. So PASSNYC can help cluster 0 schools which these feature in mind. In this way, PASSNYC can help schools in a more granuler and accurate way that will bring more diverse students into SHSAT exam. \n   \n   ## Why this solutions is effective\n   The datasets used in the notebook are all school label meaning it's more granular. And school's are scored in different critriea.  PASSNYC can look each each score in different criteria and took effective steps. "},{"metadata":{"_uuid":"c0b03054b8c0dfcdaf6251dabcc9606686851a82"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"ed4908711219311ed4ca6d0bc6be6831e15bc583"},"cell_type":"markdown","source":"<a id='distrubution_of_cluster'></a>\n\n# Let's see a distribution of schools in each cluster in a map\n> In this section, I will try to plot schools destribution in different cluster. This will give us clear understanding where our schools are located. Hover over to school and click on the icon then the map will show you the school name and DBN number."},{"metadata":{"_uuid":"31ba449d4cb20a85c5569c9c1cd2f883f9e6966d"},"cell_type":"markdown","source":"# Cluster 0"},{"metadata":{"trusted":true,"_uuid":"1f729ff803438feed3015cc14d2032b3d947f761","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"   # show the folium map\ndf_cluster_0 = df_model.loc[df_model['c'] == 0]\nfolium_map = folium.Map(location=[40.7128, -74.0060], zoom_start=11, tiles=\"Stamen Terrain\") # create the Map object \nmarker_cluster = MarkerCluster().add_to(folium_map) # marker cluster for clustering marker for easy understanding\nfolium.GeoJson(gj).add_to(folium_map) # add jeojson to the map. So that NYC school border should show on the map\n\nfor index, row in df_cluster_0.iterrows(): # iter over every row in the dataset\n    folium.Marker(location=(row[\"Latitude\"],row[\"Longitude\"]), popup=folium.Popup(row['School Name'] + ' ' + row['DBN'], parse_html=True)).add_to(folium_map) # plot a marker on the map for a school\n\nfolium_map","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fef6c134c13e98f296fca3395147c15d59bdaf8e"},"cell_type":"markdown","source":"# Cluster 1"},{"metadata":{"trusted":true,"_uuid":"5a6e5df0f40636a805617c3bd8dff42cafe39409","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"   # show the folium map\ndf_cluster_1 = df_model.loc[df_model['c'] == 1]\nfolium_map = folium.Map(location=[40.7128, -74.0060], zoom_start=11, tiles=\"Stamen Terrain\") # create the Map object \nmarker_cluster = MarkerCluster().add_to(folium_map) # marker cluster for clustering marker for easy understanding\nfolium.GeoJson(gj).add_to(folium_map) # add jeojson to the map. So that NYC school border should show on the map\n\nfor index, row in df_cluster_1.iterrows(): # iter over every row in the dataset\n    folium.Marker(location=(row[\"Latitude\"],row[\"Longitude\"]), popup=folium.Popup(row['School Name'] + ' ' + row['DBN'], parse_html=True)).add_to(folium_map) # plot a marker on the map for a school\n\nfolium_map","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"411e0f4da18359a4fb8c95e63ce34cfcce27983d"},"cell_type":"markdown","source":"# Cluster 2"},{"metadata":{"trusted":true,"_uuid":"4ff862caac5d30873d8da1d9081bb63bb936e37a","collapsed":true},"cell_type":"code","source":"   # show the folium map\ndf_cluster_2 = df_model.loc[df_model['c'] == 2]\nfolium_map = folium.Map(location=[40.7128, -74.0060], zoom_start=11, tiles=\"Stamen Terrain\") # create the Map object \nmarker_cluster = MarkerCluster().add_to(folium_map) # marker cluster for clustering marker for easy understanding\nfolium.GeoJson(gj).add_to(folium_map) # add jeojson to the map. So that NYC school border should show on the map\n\nfor index, row in df_cluster_2.iterrows(): # iter over every row in the dataset\n    folium.Marker(location=(row[\"Latitude\"],row[\"Longitude\"]), popup=folium.Popup(row['School Name'] + ' ' + row['DBN'], parse_html=True)).add_to(folium_map) # plot a marker on the map for a school\n\nfolium_map","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a74291d3f3b7c471435191b09643ddd5abe6670a"},"cell_type":"markdown","source":"# Cluster 3"},{"metadata":{"trusted":true,"_uuid":"bab1d6db78a05a067c89b8cebca9bc5e8e5e261d","collapsed":true},"cell_type":"code","source":"   # show the folium map\ndf_cluster_3 = df_model.loc[df_model['c'] == 3]\nfolium_map = folium.Map(location=[40.7128, -74.0060], zoom_start=11, tiles=\"Stamen Terrain\") # create the Map object \nmarker_cluster = MarkerCluster().add_to(folium_map) # marker cluster for clustering marker for easy understanding\nfolium.GeoJson(gj).add_to(folium_map) # add jeojson to the map. So that NYC school border should show on the map\n\nfor index, row in df_cluster_3.iterrows(): # iter over every row in the dataset\n    folium.Marker(location=(row[\"Latitude\"],row[\"Longitude\"]), popup=folium.Popup(row['School Name'] + ' ' + row['DBN'], parse_html=True)).add_to(folium_map) # plot a marker on the map for a school\n\nfolium_map","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65c7aae081eda0d1175c2bce9329c3925d6bac93"},"cell_type":"markdown","source":"# Cluster 4"},{"metadata":{"trusted":true,"_uuid":"c9d96018f8da0b5ea23d0d8fc264b2210d45b4e5","collapsed":true},"cell_type":"code","source":"   # show the folium map\ndf_cluster_4 = df_model.loc[df_model['c'] == 4]\nfolium_map = folium.Map(location=[40.7128, -74.0060], zoom_start=11, tiles=\"Stamen Terrain\") # create the Map object \nmarker_cluster = MarkerCluster().add_to(folium_map) # marker cluster for clustering marker for easy understanding\nfolium.GeoJson(gj).add_to(folium_map) # add jeojson to the map. So that NYC school border should show on the map\n\nfor index, row in df_cluster_4.iterrows(): # iter over every row in the dataset\n    folium.Marker(location=(row[\"Latitude\"],row[\"Longitude\"]), popup=folium.Popup(row['School Name'] + ' ' + row['DBN'], parse_html=True)).add_to(folium_map).add_to(folium_map) # plot a marker on the map for a school\n\nfolium_map","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7626f24431de15dad53ba9ca972c9f2fdeb0bb0b"},"cell_type":"markdown","source":"<a id='conclusion'></a>\n\n# **Conclusion**\n> Thank you very much reading this notebook and solution. Hope this helpful. If you have any suggestion or you find any problem please let me in the comment section.  Hope this solution will help PASSNYC to target more diverse student and make SHSAT exam and specialized schools more diverse and fill those with talented candidate. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1aff2ea9b6bfe705028b5d46b5c664a572106dd2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}