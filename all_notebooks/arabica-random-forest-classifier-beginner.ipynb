{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn import metrics\n\nplt.rcParams['figure.figsize'] = [12, 7]\nsns.set(rc={'figure.figsize':(7,8)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/coffee-quality-database-from-cqi/arabica_data_cleaned.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> For this Classification Problem, i'm using features based on geographic, post-harvest information, category defects and total cupping point. I want to know how this variables can affect the flavor quality(Total.Cup.Points - Grading by Coffee Q.Grader) "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data[[\"Country.of.Origin\", \"Harvest.Year\", \"Variety\", \"Processing.Method\", \"Category.One.Defects\", \"Category.Two.Defects\", \"Quakers\", \"altitude_mean_meters\", \"Total.Cup.Points\"]]\ndf = df.dropna()\ndf = df.reset_index()\n\ndf = df.drop(\"index\", axis = 1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df = df[[\"Country.of.Origin\", \"Harvest.Year\", \"Variety\", \"Processing.Method\", \"Category.One.Defects\", \"Category.Two.Defects\", \"Quakers\", \"altitude_mean_meters\", \"Total.Cup.Points\"]]\n\ncleaned_df.head()\ncleaned_df.plot(kind='box', subplots=True, layout=(2,3), \n        sharex=False, sharey=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#All the data preparation goes here\n\n#Melakukan data cleaning untuk features harvest year\ncleaned_df.loc[cleaned_df[\"Harvest.Year\"] == \"2017 / 2018\", \"Harvest.Year\"] = \"2018\"\ncleaned_df.loc[cleaned_df[\"Harvest.Year\"] == \"2016 / 2017\", \"Harvest.Year\"] = \"2017\"\ncleaned_df.loc[cleaned_df[\"Harvest.Year\"] == \"2015/2016\", \"Harvest.Year\"] = \"2016\"\ncleaned_df.loc[cleaned_df[\"Harvest.Year\"] == \"2014/2015\", \"Harvest.Year\"] = \"2015\"\ncleaned_df.loc[cleaned_df[\"Harvest.Year\"] == \"2013/2014\", \"Harvest.Year\"] = \"2014\"\ncleaned_df.loc[cleaned_df[\"Harvest.Year\"] == \"2011/2012\", \"Harvest.Year\"] = \"2012\"\n\n#Mengkelompokan data negara asal menjadi others untuk negara yang memiliki data kopi dibawah 10\na = cleaned_df['Country.of.Origin'].value_counts() <= 5\nb = cleaned_df['Country.of.Origin'].value_counts()\nfor i in range(len(a.index)):\n    if(a[i]):\n        cleaned_df.loc[cleaned_df[\"Country.of.Origin\"] == a.index[i], \"Country.of.Origin\"] = \"Others\"\n        \n#Mengkelompokan data negara asal menjadi others untuk negara yang memiliki data kopi dibawah 10\na = cleaned_df['Variety'].value_counts() <= 1\nb = cleaned_df['Variety'].value_counts()\nfor i in range(len(a.index)):\n    if(a[i]):\n        cleaned_df.loc[cleaned_df[\"Variety\"] == a.index[i], \"Variety\"] = \"Others\"\n\n#Menghapus data altitude outliers yaang tidak masuk akal\ncleaned_df.drop(cleaned_df.loc[cleaned_df['altitude_mean_meters'] > 2000].index, inplace = True) \ncleaned_df.drop(cleaned_df.loc[cleaned_df['altitude_mean_meters'] < 182].index, inplace = True) \n\n#Melakukan perbaikan tipe data pada variabel dalam dataset \ncleaned_df.loc[:,\"Category.One.Defects\"] = cleaned_df[\"Category.One.Defects\"].astype(int)\ncleaned_df.loc[:,\"Harvest.Year\"] = cleaned_df[\"Harvest.Year\"].astype(int)\ncleaned_df.loc[:,\"Total.Cup.Points\"] = cleaned_df[\"Total.Cup.Points\"].astype(float)\ncleaned_df[\"Quakers\"] = cleaned_df[\"Quakers\"].astype(int)\n\n\n#Membuat features grading biji kopi berdasarkan features defects dan quakers\ncut_labels = [\"Specialty\", \"Premium\", \"Exchange\", \"Below Standard\"] # 1 = Specialty Grade, 2 = Premium Coffee Grade, 3 = Exchange Coffee Grade\ncut_bins = [-1, 3, 15, 23, 100]\ncleaned_df['Green.Beans.Grade'] = cleaned_df[\"Category.One.Defects\"].values + cleaned_df[\"Category.Two.Defects\"].values + cleaned_df[\"Quakers\"].values\ncleaned_df['Green.Beans.Grade'] = pd.cut(cleaned_df['Green.Beans.Grade'], bins=cut_bins, labels=cut_labels)\n\n#Membuat features Total Cupping Point menjadi categorical, menjadi features Cupping.Grade\ncut_labels = [\"UGQ\", \"Premium\", \"Specialty\"] # 1 = Specialty Quality, 2 = Premium Quality, 3 = Usually Good Quality\ncut_bins = [50, 80, 84, 90]\ncleaned_df['Cupping.Grade'] = pd.cut(cleaned_df['Total.Cup.Points'], bins=cut_bins, labels=cut_labels)\n\ncleaned_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> In this dataset, The data are unbalanced, To solve this im gonna do Random Over Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mengambil features yang akan digunakan\nmodel_df = cleaned_df[[\"Country.of.Origin\", \"Harvest.Year\", \"Variety\", \"Processing.Method\", \"Green.Beans.Grade\", 'Cupping.Grade', \"Category.One.Defects\",\t\"Category.Two.Defects\",\t\"Quakers\"]]\nax = sns.countplot(x=\"Cupping.Grade\", data=model_df)\nax.tick_params(labelsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_df = cleaned_df[[\"Country.of.Origin\", \"Harvest.Year\", \"Variety\", \"Processing.Method\", \"Green.Beans.Grade\", 'Cupping.Grade', \"Category.One.Defects\",\t\"Category.Two.Defects\",\t\"Quakers\"]]\ndf1 = model_df.loc[model_df[\"Cupping.Grade\"] == \"UGQ\"]\ndf2 = model_df.loc[model_df[\"Cupping.Grade\"] == \"Specialty\"]\nframes = [model_df, df1, df1, df2, df2]\nmodel_df = pd.concat(frames)\n\nax = sns.countplot(x=\"Cupping.Grade\", data=model_df)\nax.tick_params(labelsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\nencode_df = model_df.copy()\ncolumn_name = [\"Country.of.Origin\", \"Harvest.Year\", \"Variety\", \"Processing.Method\", \"Green.Beans.Grade\", 'Cupping.Grade']\n\nlabel = list()\nfor i in range(0,6):\n    encoder.fit(encode_df[column_name[i]])\n    encode_df.loc[:,column_name[i]] = (encoder.transform(encode_df[column_name[i]]))\n    label.append(encoder.inverse_transform(encode_df[column_name[i]]))\n\n    unique, counts = np.unique(label[i], return_counts=True)\n    print(np.asarray((unique, counts)).T)\n    unique, counts = np.unique(encode_df.loc[:,column_name[i]], return_counts=True)\n    print(np.asarray((unique, counts)).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\nX = encode_df.drop(\"Cupping.Grade\", axis = 1)\nY = encode_df[\"Cupping.Grade\"]\n# Split the data into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n\nprint('Training Features Shape:', x_train.shape)\nprint('Training Labels Shape:', y_train.shape)\nprint('Testing Features Shape:', x_test.shape)\nprint('Testing Labels Shape:', y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestClassifier\n# Instantiate model with 1000 decision trees\n\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 9)\nrf = RandomForestClassifier(n_estimators = 30, random_state = 42)\n# Train the model on training data\nrf.fit(x_train, y_train)\ny_pred=rf.predict(x_test)\n\nprint(\"Accuracy: %0.5f\" % (metrics.accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display\n\nimport os\nos.environ[\"PATH\"] += os.pathsep + 'D:/Anaconda/Library/bin/graphviz'\n\na = [\"Premium\", \"Specialty\", \"UGQ\"]\nlabels = X.columns\ngraph = Source(tree.export_graphviz(rf[10] ,feature_names = labels, class_names = a, max_depth = 2, filled = True))\ndisplay(SVG(graph.pipe(format='svg')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n\ncm = (confusion_matrix(y_test, y_pred))\na = [\"Premium\", \"Specialty\", \"UGQ\"]\n\nsns.heatmap(cm, xticklabels = a, yticklabels = a,annot=True, fmt='g')\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt\n\ny_probas = rf.predict_proba(x_test)\nskplt.metrics.plot_roc_curve(y_test, y_probas)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}