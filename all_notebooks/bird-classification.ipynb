{"cells":[{"metadata":{},"cell_type":"markdown","source":"Overview:\nThe goal is to train and test the bird classification data and get the highest accuracy as possible.\n\nDescription of Data:\nThe dataset contains 190 bird species. The training data has over 25k images, 950 test images, and 950 validation images.\n\nMethods Used:\nI used Keras Application ResNet to to train the data. It is a deep learning model that has pre-trained weight, making training large volumes of data efficient.\n\nI also used the Image Data Generator for data augmentation. This normalized the images.\n\nAt the end I added a Functional API model to evaluate the data.\n\nSummary of Models/Analysis:\nThe first model uses ResNet152. I decided to use the weights from ResNet152 to make the model simple. It is also a sequential model. It steps through layer by layer, making it a very simple. The layers included flatten layers and dense layers. The model performed pretty well really fast. The accuracy was around 99 percent.\n\nThe second model was a functional API. It only had one input layer and one output layer. It broke out into several different layes and was pulled back into one layers using a concatenation. The model accuracy was really high for this as well. Around 99 percent."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container {width:95% !importnat; }</style>\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Loading Libraries\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import backend\nfrom tensorflow.keras.layers import Dense, Input, Activation, Dropout, Flatten, BatchNormalization, Concatenate\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, SeparableConv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, Sequential\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import display # Library to help view images\nfrom PIL import Image # Library to help view images\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator # Library for data augmentation\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow.keras.applications import ResNet50, InceptionV3, ResNet152\n\nnp.random.seed(42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify the traning, validation, and test dirrectories.\nfrom fastai.vision import Path, ImageList, get_transforms, imagenet_stats\n\nsource_dir = Path('../input/100-bird-species/')\nsource_dir.ls()\ntrain_dir = os.path.join(source_dir, 'train')\nvalid_dir = os.path.join(source_dir, 'valid')\ntest_dir = os.path.join(source_dir, 'test')\n\nimg_src = (ImageList.from_folder(source_dir).split_by_folder(train='train',valid='valid')\n           .label_from_folder().add_test_folder('test').transform(get_transforms(), size=224))\n\nbird_data = img_src.databunch(bs=32).normalize(imagenet_stats)\nbird_data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Augmentation\ntrain_datagen = ImageDataGenerator(rescale = 1./255)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size = (224,224))\n\nvalidation_generator = train_datagen.flow_from_directory(valid_dir, target_size = (224, 224))\n\ntest_generator = test_datagen.flow_from_directory(test_dir,target_size = (224, 224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\n\nresnetModel = ResNet152(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n\nresnetModel.trainable = False \n\nresnet_train = Sequential()\nresnet_train.add(resnetModel)\nresnet_train.add(keras.layers.Flatten())\nresnet_train.add(keras.layers.Flatten())\nresnet_train.add(Dense(128, activation = 'relu'))\nresnet_train.add(Dense(1, activation = 'sigmoid'))\n\nresnet_train.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss = 'binary_crossentropy',\n    metrics = ['accuracy'])\n\nhistory = resnet_train.fit_generator(\n    train_generator,\n    steps_per_epoch=500,\n    epochs=50,\n    validation_data=validation_generator,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience = 4, restore_best_weights = True)])\n\n#Plot Model\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Evaluate test data.\ntest_loss, test_acc = resnet_train.evaluate_generator(test_generator, steps = 50)\nprint('ResNet_train_test_acc:', test_acc)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the model(s) and print (plot) the model.\n\nfrom tensorflow.keras.utils import plot_model\n\nbackend.clear_session()\n\nvisible = Input(shape = (224,224,3))\n\nconv11 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(visible)\n\nconv21 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv11)\n\nconv31 = BatchNormalization()(conv21)\n\nconv41 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv31)\n\nconv51 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv31)\nconv51 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv51)\n\nconv61 = AveragePooling2D((2,2), padding = 'same', strides = 1)(conv31)\nconv61 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv61)\n\nconv71 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv31)\nconv71 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv71)\nconv71 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv71)\n\nmerge = Concatenate(axis=-1)([conv41,conv51, conv61, conv71])\n\nbatch2 = BatchNormalization()(merge)\n\nsep2d = SeparableConv2D(32, (3,3), padding = 'same', activation = 'relu')(batch2)\nsep2d = SeparableConv2D(32, (3,3), padding = 'same', activation = 'relu')(sep2d)\nsep2d = BatchNormalization()(sep2d)\nsep2d = MaxPooling2D((2,2), padding = 'same')(sep2d)\nsep2d = Dropout(0.5)(sep2d)\n\nconv81 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(sep2d)\nconv81 = Conv2D(32, (3,3), padding = 'same', activation = 'relu')(conv81)\n\nbatch3 = BatchNormalization()(conv81)\n\nflat = Flatten()(batch3)\n\nbatch4 = BatchNormalization()(flat)\n\nhidden1 = Dense(64, activation='relu')(batch4)\ndrop = Dropout(0.5)(hidden1)\noutput = Dense(190, activation='softmax')(drop)\n\nmodelx = Model(inputs=visible, outputs = output)\n\nplot_model(modelx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compile, fit, plot, and assess.  \nmodelx.compile(optimizer = 'adam',\n               loss = 'binary_crossentropy',\n               metrics = ['accuracy'])\n\nhistory = modelx.fit_generator(\n    train_generator,\n    steps_per_epoch=500,\n    epochs=50,\n    validation_data=validation_generator,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience = 4, restore_best_weights = True)])\n\n#Plot Model\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Evaluate test data.\ntest_loss, test_acc = modelx.evaluate_generator(test_generator, steps = 50)\nprint('ResNet_train_test_acc:', test_acc)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}