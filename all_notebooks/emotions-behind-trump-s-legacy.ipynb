{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport collections\nimport seaborn as sns\nfrom ast import literal_eval\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set Parameterts"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=(16,8)\nsw = set(STOPWORDS) \nsns.set()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/trumps-legacy/Trumps Legcy.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean Tweets"},{"metadata":{},"cell_type":"markdown","source":"#### Emoji Pattern"},{"metadata":{"trusted":true},"cell_type":"code","source":"emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_tweets(tweet):\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(tweet)\n \n    tweet = re.sub(r':', '', tweet)\n    tweet = re.sub(r'‚Ä¶', '', tweet)\n    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n \n    tweet = emoji_pattern.sub(r'', tweet)\n \n    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n    filtered_tweet = []\n \n    for w in word_tokens:\n        if w not in stop_words and w not in string.punctuation:\n            filtered_tweet.append(w)\n    return ' '.join(filtered_tweet).lower()\n\ndf['text'] = df['text'].apply(lambda x: clean_tweets(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utilizing External Lexicon Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"emo_words_new = pd.read_csv('../input/emolex/DepecheMood.tsv', delimiter='\\t')\nemo_words_new['EMOTIONS'] = list(emo_words_new.eq(emo_words_new.max(1), axis=0).dot(emo_words_new.columns))\nemo_words_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install xlrd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install openpyxl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emo_words = pd.read_excel('../input/emolex/NRC EmoLex.xlsx')\nemo_words = emo_words[emo_words['association'] == 1]\nemo_words = emo_words.drop(['association'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_words = pd.read_excel('/kaggle/input/sentiment-lexicons/pos-words.xlsx')\nneg_words = pd.read_excel('/kaggle/input/sentiment-lexicons/neg-words.xlsx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filters = ['positive', 'negative']\nemolex_sents = emo_words[emo_words.emotion.isin(filters)]\nemolex_sents.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_pos = ['positive'] * len(pos_words)\nn_neg = ['negative'] * len(neg_words)\n\ntemp_pos_df = pd.DataFrame()\ntemp_pos_df['word'] = list(pos_words.words)\ntemp_pos_df['emotion'] = n_pos\n\ntemp_neg_df = pd.DataFrame()\ntemp_neg_df['word'] = list(neg_words.words)\ntemp_neg_df['emotion'] = n_neg\n\ntemp_final = pd.concat([temp_pos_df, temp_neg_df])\nemolex_sents = pd.concat([emolex_sents, temp_final])\n\nemolex_sents.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extracting Positive, Negative Words From Tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pos_neg_words(text):\n    pos = []\n    neg = []\n    for word in text.split():\n        if word in list(emolex_sents.word):\n            emo = emolex_sents[emolex_sents.word == word].iloc[0,1]\n            if emo == 'positive':\n                pos.append(word)\n            elif emo == 'negative':\n                neg.append(word)\n    return pos, neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos = []\nneg = []\ntexts = []\nfor text in df.text:\n    p, n = pos_neg_words(text)\n    pos.append(p)\n    neg.append(n)\n\ndf['positive_words'] = pos\ndf['negative_words'] = neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extracting Emotions From Tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Happy Emoticons\nemoticons_happy = set([\n    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n    '<3'\n    ])\n \n# Sad Emoticons\nemoticons_sad = set([\n    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n    ':c', ':{', '>:\\\\', ';('\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def emotion_of_text(text):\n    emo = []\n    for word in text.split():\n        if word in list(emo_words_new.WORDS):\n            e = emo_words_new[emo_words_new.WORDS == word].iloc[0,-1]\n            emo.append(e.lower())\n        if word in emoticons_happy:\n            print(word)\n            emo.append('happy')\n        if word in emoticons_sad:\n            print(word)\n            emo.append('sad')\n    return list(set(emo))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Uncomment the code in cell below to extract emotions. To save time, I already did it on a personal machine and will load the .csv instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"# emo = []\n\n# for text in df.text:\n#     emo.append(emotion_of_text(text))\n\n# df['emotions_in_tweet'] = emo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/trumpp/trump.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 20 Most Common Positive Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"the_list = list(df.text)\np_words = list(df.positive_words)\nflat_list = [item for sublist in p_words for item in literal_eval(sublist)]\np_words_count = collections.Counter(flat_list)\ndf2 = pd.DataFrame(p_words_count.most_common(20), columns=['word', 'frequency'])\ndf2.plot(kind='barh', x='word', figsize=(16,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 20 Most Common Negative Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_words = list(df.negative_words)\nflat_list = [item for sublist in n_words for item in literal_eval(sublist)]\nn_words_count = collections.Counter(flat_list)\ndf3 = pd.DataFrame(n_words_count.most_common(20), columns=['word', 'frequency'])\ndf3.plot(kind='barh', x='word', figsize=(16,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Emotions Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"e_words_count = {}\nfor emo_list in df.emotions_in_tweet:\n    for emo in literal_eval(emo_list):\n        if emo in e_words_count:\n            e_words_count[emo] += 1\n        else:\n            e_words_count[emo] = 1\n\nplt.pie([float(v) for v in e_words_count.values()], labels=[k for k in e_words_count],\n           autopct=None, startangle=140, explode=(0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02))\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Words Behind Most Dominant Emotion (Inspired)"},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_p = 0\npos_p = 0 \nangry_words = []\nfor row in df.iterrows():\n    if 'inspired' in literal_eval(row[1][-1]):\n        neg_p += len(set(literal_eval(row[1][-2])))\n        angry_words.append(literal_eval(row[1][-2]))\n        pos_p += len(set(literal_eval(row[1][-3])))\n        angry_words.append(literal_eval(row[1][-3]))\nangry_words = ' '.join([item for sublist in angry_words for item in sublist])\nwordcloud = WordCloud(width = 600, height = 600, \n                background_color ='white', \n                stopwords = sw, \n                min_font_size = 10).generate(angry_words) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Findings:\n* 62% Positive Words\n* 38% Negative Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}