{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## A combinação NumPy, Pandas e Scikit-Learn é muito poderosa\n\nEmbora O Scikit-Learn seja responsável por facilitar grande parte do pipeline de Machine Learning, dois componentes são essenciais para ler arquivos e manipular as informações: NumPy e Pandas. O NumPy auxilia a manipulação matricial dos dados, que é fundamental para aprendizado de máquina; enquanto o Pandas atua como um facilitador para a manipulação de dados de forma menos estruturada.\n\n*Esse conteúdo é baseado no capítulo 'Machine Learning' de Numerical Python, segunda edição, de Robert Johannson.*\n\nA seguir é utilizado o comando read_csv do Pandas para ter acesso aos dados do arquivo 'energy_data.csv', e o comando *describe* gera um sumário dos dados quando possível. A nomenclatura df para a variável vem de DataFrame do Pandas, mas poderia ser o nome que o programador quisesse dar.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/appliances-energy-prediction/KAG_energydata_complete.csv')\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esse conjunto de dados está disponível em https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction# e um Github do artigo que originou essa contribuição está disponível em https://github.com/LuisM78/Appliances-energy-prediction-data.\n\nO objetivo é utilizar as informações de clima fora e dentro de uma casa para estimar o consumo de energia elétrico que aquela casa, naquelas condições meteorológicas, demandaria. Portanto, serão considerados atributos todas as colunas exceto appliances e a data, e essa coluna será utilizada como *target*.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Appliances','date'],axis=1)\ny = df.Appliances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"São 27 atributos que farão a composição de X, e o total de amostras são 19735. Por se tratar de um problema de regressão, serão importados os módulos do Scikit-Learn para a separação dos dados e a geração dos regressores (modelos de regressão). Em seguida, os dados são separados com o comando *train_test_split* e um modelo de Regressão Linear é treinado com a função *fit*.\n\n**Vamos supor um cenário com 20 amostras do conjunto inicial para propósitos didáticos:**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn import linear_model\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X[:20], y[:20], test_size=0.5, random_state=42)\nmodel = linear_model.LinearRegression()\n\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Em seguida, é importante calcular o resíduo entre o que o modelo diz e o que de fato é. Esse resíduo também pode ser acumulado como erro utilizando alguma função. Vamos verificar então qual é o erro para o próprio conjunto de treino utilizando o erro quadrático médio, e depois o erro no teste.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"erro_treino = metrics.mean_squared_error(y_train,model.predict(X_train))\nprint('RMSE no treino:', np.sqrt(erro_treino))\n\nerro_teste = metrics.mean_squared_error(y_test,model.predict(X_test))\nprint('RMSE no teste:', np.sqrt(erro_teste))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"É possível perceber que o erro no treino é muito baixo, praticamente zero, enquanto que o erro no teste é bastante alto (> 104). Isso se deve a um fenômeno chamado **overfitting**. É muito comum que, quando o número de atributos seja maior que o número de amostras, a regressão fique sobreajustada (overfit) para os dados de treino, e não generaliza suficiente para o conjunto de teste.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = model.score(X_train, y_train)\nprint('r² no treino:', r2)\n\nr2 = model.score(X_test, y_test)\nprint('r² no teste:', r2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, também é possível visualizar essa diferença de forma gráfica. Compara-se o resíduo por amostra tanto no treino quanto no teste, e observa-se os coeficientes encontrados:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_residuals_and_coeff(resid_train, resid_test, coeff):\n    fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n    axes[0].bar(np.arange(len(resid_train)), resid_train)\n    axes[0].set_xlabel(\"núm. amostras\")\n    axes[0].set_ylabel(\"resíduo\")\n    axes[0].set_title(\"treino\")\n    axes[1].bar(np.arange(len(resid_test)), resid_test)\n    axes[1].set_xlabel(\"núm. amostras\")\n    axes[1].set_ylabel(\"resíduo\")\n    axes[1].set_title(\"teste\")\n    axes[2].bar(np.arange(len(coeff)), coeff)\n    axes[2].set_xlabel(\"núm. coeficientes\")\n    axes[2].set_ylabel(\"coeficiente\")\n    fig.tight_layout()\n    return fig, axes\n\nresiduo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"É possível perceber nas escalas dos resíduos que os erros são muito maiores no conjunto de teste do que no conjunto de treino. *Uma das formas de corrigir esse problema é aplicando regularização*, forçando os coeficientes a residirem num espaço próximo. As duas normais mais comuns de regularização são L1 e L2, respectivamente LASSO e Ridge. Enquanto que L2 favorece com coeficientes menores, L1 favorece modelos que têm poucos coeficientes próximos de zero.\n\n\n**Quando usar L1 ou L2?**\n\n* L1: Deseja-se eliminar o maior número de atributos que não contribuem com o problema;\n* L2: Limitar a magnitude dos coeficientes do modelo.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Utilizando Ridge — L2**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.Ridge()\nmodel.fit(X_train, y_train)\n\nerro_treino = metrics.mean_squared_error(y_train,model.predict(X_train))\nprint('RMSE no treino:', np.sqrt(erro_treino))\n\nerro_teste = metrics.mean_squared_error(y_test,model.predict(X_test))\nprint('RMSE no teste:', np.sqrt(erro_teste))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O erro no treino não é mais próximo a zero, mas é possível perceber que *o erro no teste diminuiu*. Vale lembrar que os dados do teste são mais parecidos com os dados do mundo real, ou seja, são informações que o modelo não teve acesso, portanto mais difíceis de serem previstas corretamente.\n\nGraficamente, é possível perceber uma mudança nos pesos também:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"residuo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Utilizando LASSO — L1**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.Lasso(alpha=2.5)\nmodel.fit(X_train, y_train)\n\nerro_treino = metrics.mean_squared_error(y_train,model.predict(X_train))\nprint('RMSE no treino:', np.sqrt(erro_treino))\n\nerro_teste = metrics.mean_squared_error(y_test,model.predict(X_test))\nprint('RMSE no teste:', np.sqrt(erro_teste))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residuo_treino = y_train - model.predict(X_train)\nresiduo_teste = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os resultados de erro no treino são mais baixos que do Ridge, porém mais altos que a regressão linear sem regularização, porém o erro no teste caiu aproximadamente para a metade. Também é possível perceber que L1 reduziu significativamente o número de atributos que, de fato, contribuem para a solução do problema.\n\nTambém é possível perceber que o **parâmetro alpha é configurável**, portanto é importante fazer uma varredura para identificar qual seria o melhor valor.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Exercícios\n\n1. **Faça a busca de melhor parâmetro de alpha para reduzir o erro quadrático médio nessa base de apenas 20 amostras, considerando L1 e L2. Considere utilizar as funções LassoCV e RidgeCV, e busque informações sobre elas na documentação do Scikit-Learn.**\n\n\n2. **Recarregue a base e não filtre apenas 20 amostras e aplique os modelos de regressão vistos. Tenha um olhar crítico para os seguintes questionamentos após codificar e ver os resultados:**\n    * Qual regressão teve o melhor resultado?\n    * Há algum sinal de overfitting?\n    * Todos atributos são relevantes para o problema?\n    * Todos coeficientes estão em uma mesma magnitude?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/appliances-energy-prediction/KAG_energydata_complete.csv')\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X[:20], y[:20], test_size=0.5, random_state=42)\n\nrmse_treino = []\nrmse_teste  = []\nalpha = []\n\nfor a in range(-4,8):\n    model = linear_model.Lasso(alpha=10**a)\n    model.fit(X_train, y_train)\n    \n    print(\"################################################\")\n    print('Alpha:', 10**a)\n    \n    rmse_treino.append(np.sqrt(metrics.mean_squared_error(y_train, model.predict(X_train))))\n    rmse_teste.append(np.sqrt(metrics.mean_squared_error(y_test, model.predict(X_test))))\n    alpha.append(a)\n    \n    print('MSE no treino:', rmse_treino[-1])\n    print('MSE no teste:', rmse_teste[-1])\n    \n    print(\"################################################\")\n\nplt.plot(alpha, rmse_treino, alpha, rmse_teste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse_treino = []\nrmse_teste  = []\nalpha = []\n\nfor a in range(-4,8):\n    model = linear_model.Ridge(alpha=10**a)\n    model.fit(X_train, y_train)\n    \n    print(\"################################################\")\n    print('Alpha:', 10**a)\n    \n    rmse_treino.append(np.sqrt(metrics.mean_squared_error(y_train, model.predict(X_train))))\n    rmse_teste.append(np.sqrt(metrics.mean_squared_error(y_test, model.predict(X_test))))\n    alpha.append(a)\n    \n    print('MSE no treino:', rmse_treino[-1])\n    print('MSE no teste:', rmse_teste[-1])\n    \n    print(\"################################################\")\n\nplt.plot(alpha, rmse_treino, alpha, rmse_teste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizando o Lasso CV\nlasso_reg = LassoCV(cv=5, random_state=0)\nlasso_reg.fit(X_train, y_train)\nbest_alpha_lasso = lasso_reg.alpha_\nprint(\"Best alpha => \", best_alpha_lasso)\n# Com este valor fazemos o cross validation para outros parâmetros","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizando o Ridge CV\nridge_reg = RidgeCV(cv=5)\nridge_reg.fit(X_train, y_train)\nbest_alpha_ridge = ridge_reg.alpha_\nprint(\"Best alpha => \", best_alpha_ridge)\n# Com este valor fazemos o cross validation para outros parâmetros","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos agora carregar todos os dados e comparar o desempenho utilizando L1 e L2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Appliances','date'],axis=1)\ny = df.Appliances\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=42)\n\nmodel = linear_model.Ridge(alpha = best_alpha_ridge)\nmodel.fit(X_train, y_train)\n\nerro_treino = np.sqrt(metrics.mean_squared_error(y_train,model.predict(X_train)))\nprint('RMSE no treino:', erro_treino)\n\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test,model.predict(X_test)))\nprint('RMSE no teste:', erro_teste)\n\nresiduo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Appliances','date'],axis=1)\ny = df.Appliances\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=42)\n\nmodel = linear_model.Lasso(alpha = best_alpha_lasso)\nmodel.fit(X_train, y_train)\n\nerro_treino = np.sqrt(metrics.mean_squared_error(y_train,model.predict(X_train)))\nprint('RMSE no treino:', erro_treino)\n\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test,model.predict(X_test)))\nprint('RMSE no teste:', erro_teste)\n\nresiduo_treino = y_train - model.predict(X_train)\nresiduo_teste  = y_test - model.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Em vez de utilizarmos o LassoCV ou RidgeCV, poderíamos também buscar por eles através do grid search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\n\ndata_gs, data_cv, target_gs, target_cv = train_test_split(X, y, test_size=0.95, random_state=42)\n\npipeline = Pipeline([('scaler', StandardScaler()), ('clf', linear_model.Ridge())])\n\n# utiliza-se GridSearchCV para achar os melhores parâmetros\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'clf__alpha': [0.1,1, 1.5, 3, 5, 7,10,100,1000]} # quais parâmetros e quais valores serão testados\nclf = GridSearchCV(pipeline, parameters, cv=3, iid=False) # clf vai armazenar qual foi a melhor configuração\nclf.fit(data_gs, target_gs)\n\nprint(clf.best_params_ )\n\n# utilizando validação cruzada para avaliar o modelo\nscores = cross_val_score(clf, data_cv, target_cv, cv=5, scoring='neg_mean_squared_error')\n\nscores = -scores\nscores = np.sqrt(scores)\n\nprint('RMSE - %.2f +- %.2f' % (scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('R²:', clf.score(X_test, y_test) )\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test, clf.predict(X_test)))\nprint('RMSE no treino:', erro_teste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Testando agora o Lasso","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gs, data_cv, target_gs, target_cv = train_test_split(X, y, test_size=0.95, random_state=42)\n\npipeline = Pipeline([('scaler', StandardScaler()), ('clf', linear_model.Lasso())])\n\n# utiliza-se GridSearchCV para achar os melhores parâmetros\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'clf__alpha': [0.1,1, 1.5, 3, 5, 7,10,100,1000]} # quais parâmetros e quais valores serão testados\nclf = GridSearchCV(pipeline, parameters, cv=3, iid=False) # clf vai armazenar qual foi a melhor configuração\nclf.fit(data_gs, target_gs)\n\nprint(clf.best_params_ )\n\n# utilizando validação cruzada para avaliar o modelo\nscores = cross_val_score(clf, data_cv, target_cv, cv=5, scoring='neg_root_mean_squared_error')\n\nscores = -scores\n# scores = np.sqrt(scores)\n\nprint('RMSE - %.2f +- %.2f' % (scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('R²:', clf.score(X_test, y_test) )\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test, clf.predict(X_test)))\nprint('RMSE no treino:', erro_teste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elasticnet combina L1 e L2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gs, data_cv, target_gs, target_cv = train_test_split(X, y, test_size=0.95, random_state=42)\n\npipeline = Pipeline([('scaler', StandardScaler()), ('clf', linear_model.ElasticNet())])\n\n# utiliza-se GridSearchCV para achar os melhores parâmetros\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'clf__alpha': [0.1,1, 1.5, 3, 5, 7,10,100,1000]} # quais parâmetros e quais valores serão testados\nclf = GridSearchCV(pipeline, parameters, cv=3, iid=False) # clf vai armazenar qual foi a melhor configuração\nclf.fit(data_gs, target_gs)\n\nprint(clf.best_params_ )\n\n# utilizando validação cruzada para avaliar o modelo\nscores = cross_val_score(clf, data_cv, target_cv, cv=5, scoring='neg_mean_squared_error')\n\nscores = -scores\nscores = np.sqrt(scores)\n\nprint('RMSE - %.2f +- %.2f' % (scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('R²:', clf.score(X_test, y_test) )\nerro_teste = np.sqrt(metrics.mean_squared_error(y_test, clf.predict(X_test)))\nprint('RMSE no treino:', erro_teste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"residuo_treino = y_train - clf.predict(X_train)\nresiduo_teste  = y_test - clf.predict(X_test)\n\nfig, ax = plot_residuals_and_coeff(residuo_treino, residuo_teste, clf.best_estimator_['clf'].coef_)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}