{"cells":[{"metadata":{"_cell_guid":"5a7c334d-3afa-4508-874f-3366da0a9c2c","_uuid":"1139f2793448fc6a647e9a0c8e8679963d9f206d","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\nimport gensim\nfrom gensim import corpora, models, similarities\nimport logging\nimport tempfile\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom collections import OrderedDict\nimport seaborn as sns\nimport pyLDAvis.gensim\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ninit_notebook_mode(connected=True) #do not miss this line\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7cdec987-42d7-495d-8aed-d904f430707a","_uuid":"2ab794b9bdd2400c1eb349493361f325fef51eee","trusted":true},"cell_type":"code","source":"datafile = '../input/data_elonmusk.csv'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"52abb44e-881a-4fa5-aaad-cca178c148b4","_uuid":"3247c5f08df034b7afe4be36e52a99baa625a5ba","trusted":true},"cell_type":"code","source":"import pandas as pd\ntweets = pd.read_csv(datafile, encoding='latin1')\ntweets = tweets.assign(Time=pd.to_datetime(tweets.Time)).drop('row ID', axis='columns')\n\nprint(\"Number of tweets: \",len(tweets['Tweet']))\ntweets.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"556c0eec-994f-4f72-82af-9da59e590a1b","_uuid":"940eb7b9c8715792165ad73a40400e8c06c7b775"},"cell_type":"markdown","source":"***Tweet Activity Over Years***"},{"metadata":{"_cell_guid":"f11bc329-639a-4498-bfc2-389318602350","_uuid":"1f37860fb232b0cca3b9dbd7924cc51e20556178","scrolled":false,"trusted":true},"cell_type":"code","source":"'''import plotly.plotly as py\nimport plotly.graph_objs as go\n'''\ntweets['Time'] = pd.to_datetime(tweets['Time'], format='%y-%m-%d %H:%M:%S')\ntweetsT = tweets['Time']\n\ntrace = go.Histogram(\n    x=tweetsT,\n    marker=dict(\n        color='blue'\n    ),\n    opacity=0.75\n)\n\nlayout = go.Layout(\n    title='Tweet Activity Over Years',\n    height=450,\n    width=1200,\n    xaxis=dict(\n        title='Month and year'\n    ),\n    yaxis=dict(\n        title='Tweet Quantity'\n    ),\n    bargap=0.2,\n)\n\ndata = [trace]\n\nfig = go.Figure(data=data, layout=layout)\npy.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b06b4ca0-f1ab-45a1-9550-1492a30c3c74","_uuid":"ffb58f64bee55b852c07d0bc87be430d1258d976","trusted":true},"cell_type":"code","source":"# Preparing a corpus for analysis and checking first 10 entries\n\ncorpus=[]\na=[]\nfor i in range(len(tweets['Tweet'])):\n        a=tweets['Tweet'][i]\n        corpus.append(a)\n        \ncorpus[0:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d117ab5e-3395-4430-8dad-0750a520c313","_uuid":"e6f1dd9faefafd8045c94fc71a033c201c5443ff","trusted":true},"cell_type":"code","source":"TEMP_FOLDER = tempfile.gettempdir()\nprint('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))\n\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"068cfe59-dbc2-4481-a20f-6cd321cbc4bb","_uuid":"df0a72a7a17efcf0da96a51753855ec2039cffb8","trusted":true},"cell_type":"code","source":"# removing common words and tokenizing\nlist1 = ['RT','rt']\nstoplist = stopwords.words('english') + list(punctuation) + list1\n\ntexts = [[word for word in str(document).lower().split() if word not in stoplist] for document in corpus]\n\ndictionary = corpora.Dictionary(texts)\ndictionary.save(os.path.join(TEMP_FOLDER, 'elon.dict'))  # store the dictionary, for future reference\n\n#print(dictionary)\n#print(dictionary.token2id)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b80d4a62-6126-48e5-aba8-8de557c5d00d","_uuid":"040914ec58061f9f66a39df81c8c1ae4cb9dbeb5","trusted":true},"cell_type":"code","source":"corpus = [dictionary.doc2bow(text) for text in texts]\ncorpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'elon.mm'), corpus)  # store to disk, for later use","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30731758-2dd0-482c-8ad8-995ebf37b686","_uuid":"547b528b1af3eac74eed647c6013c67304a44f42"},"cell_type":"markdown","source":"In the previous cells, I created a corpus of documents represented as a stream of vectors. To continue, lets use that corpus, with the help of Gensim."},{"metadata":{"_cell_guid":"8c2fae3e-3c57-4a1b-b302-7f9bfe2fb5a0","_uuid":"516974a573c993c655cec2ea8ccda4a3e4e3d899"},"cell_type":"markdown","source":"### Creating a transformation"},{"metadata":{"_cell_guid":"c8cc6eba-dfde-4078-93aa-49ec66b79483","_uuid":"95d9a030b86689a097ff84cf988ce6bfee42b6d6"},"cell_type":"markdown","source":"\nThe transformations are standard Python objects, typically initialized by means of a training corpus:\n\nDifferent transformations may require different initialization parameters; in case of TfIdf, the “training” consists simply of\ngoing through the supplied corpus once and computing document frequencies of all its features.\nTraining other models, such as Latent Semantic Analysis or Latent Dirichlet Allocation, is much more involved and,\nconsequently, takes much more time."},{"metadata":{"_cell_guid":"a7966606-dc6a-44a8-8fe5-d1a79929e203","_uuid":"91cd194bf43c84b564c693c6e0ea109d28724abc","trusted":true},"cell_type":"code","source":"tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47a7ad12-9917-4a74-b190-b6f039e87baf","_uuid":"902cd861d68967c9d6d78f7d074fe6e4d31e4547"},"cell_type":"markdown","source":"### Note\nTransformations always convert between two specific vector spaces. The same vector space (= the same set of feature ids) must be used for training as well as for subsequent vector transformations. Failure to use the same input feature space, such as applying a different string preprocessing, using different feature ids, or using bag-of-words input vectors where TfIdf vectors are expected, will result in feature mismatch during transformation calls and consequently in either garbage output and/or runtime exceptions."},{"metadata":{"_cell_guid":"31035482-743c-4143-a016-af6e7aafa8b2","_uuid":"12084cb081ffae38fd076b271f748faa6e3ff5af"},"cell_type":"markdown","source":"From now on, tfidf is treated as a read-only object that can be used to apply a transformation to a whole corpus:"},{"metadata":{"_cell_guid":"8d3211bd-a12d-4518-b822-eb92df9a564d","_uuid":"6ccc9986f35d02916c62139410d0cbc6455e3149","trusted":true},"cell_type":"code","source":"corpus_tfidf = tfidf[corpus]  # step 2 -- use the model to transform vectors","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6096b0ef-bb2b-40d1-aac4-f538dae0f1e3","_uuid":"39f769bd5e8fea11c952a7c33bf32b329618f837"},"cell_type":"markdown","source":"### LDA:\nhttps://en.wikipedia.org/wiki/Latent_Dirichlet_allocation"},{"metadata":{"_cell_guid":"7c793905-48bb-4526-9e78-1d5d1a9ed70b","_uuid":"8aca0810b66308f947046dd9689409fc56067b1a"},"cell_type":"markdown","source":"Latent Dirichlet Allocation, LDA is yet another transformation from bag-of-words counts into a topic space of lower dimensionality. LDA is a probabilistic extension of LSA (also called multinomial PCA), so LDA’s topics can be interpreted as probability distributions over words. These distributions are, just like with LSA, inferred automatically from a training corpus. Documents are in turn interpreted as a (soft) mixture of these topics (again, just like with LSA)."},{"metadata":{"_cell_guid":"cc49ccb3-bd68-4359-8fec-7f6cbff2a182","_uuid":"5771a4cc1b5f20878d52409e11f3fecaa59a9ac6","trusted":true},"cell_type":"code","source":"total_topics = 5","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8fb9df90-fdc2-491b-a2aa-02c0eca4c29a","_uuid":"db447043098a7546237bbaf4c7d1145103209160","trusted":true},"cell_type":"code","source":"lda = models.LdaModel(corpus, id2word=dictionary, num_topics=total_topics)\ncorpus_lda = lda[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dfbb2723-ec7e-490e-8abd-fb646335bc55","_uuid":"53e59fb13b5f55abb2e8158cdd0b244bcb055b3f","trusted":true},"cell_type":"code","source":"#Show first n important word in the topics:\nlda.show_topics(total_topics,5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5e31a267-03c5-4a4e-8a73-c72f7abd4644","_uuid":"25d66c5df87a0c365dcd0725e779dc8724ab63af","scrolled":true,"trusted":true},"cell_type":"code","source":"data_lda = {i: OrderedDict(lda.show_topic(i,25)) for i in range(total_topics)}\n#data_lda","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"409fed91-48dd-4355-9587-a6299b63f181","_uuid":"edeb3eedc9a10cc135c7bbef50fda042f330482d","trusted":true},"cell_type":"code","source":"df_lda = pd.DataFrame(data_lda)\ndf_lda = df_lda.fillna(0).T\nprint(df_lda.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6410b413-a0d4-49be-a2c4-6844cfc8cb0c","_uuid":"f81dd0ed3ef908b520c2416cf626473a4dd8acd6","trusted":true},"cell_type":"code","source":"df_lda","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"19a51407-5488-44d3-bdd2-9a0ec19ecf35","_uuid":"5206e6ec92bc2678c20b427efd788c0be67adcbd","trusted":true},"cell_type":"code","source":"g=sns.clustermap(df_lda.corr(), center=0, standard_scale=1, cmap=\"RdBu\", metric='cosine', linewidths=.75, figsize=(15, 15))\nplt.setp(g.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\nplt.show()\n#plt.setp(ax_heatmap.get_yticklabels(), rotation=0)  # For y axis","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc653426-6a63-4b41-887d-92d270dc1168","_uuid":"415d0d14427e94f9900776f3126d5bf8c2391beb","trusted":true},"cell_type":"code","source":"pyLDAvis.enable_notebook()\npanel = pyLDAvis.gensim.prepare(lda, corpus_lda, dictionary, mds='tsne')\npanel","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"language_info":{"name":"python","mimetype":"text/x-python","version":"3.6.4","nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":1}