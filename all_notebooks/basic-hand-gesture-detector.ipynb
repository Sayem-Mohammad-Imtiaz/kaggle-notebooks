{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers\nfrom keras.callbacks import LearningRateScheduler\nimport tensorflow as tf\nimport keras\nfrom keras import optimizers\nfrom keras.preprocessing.image import load_img, ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_list = os.listdir('../input/handgesture/build')\n\nimages = []\nlabels = []\nfor i in range(len(file_list)):\n    arr = file_list[i]\n    if 'one' in file_list[i]:\n        images.append(arr)\n        labels.append('1')\n    elif 'two' in file_list[i]:\n        images.append(arr)\n        labels.append('2')\n    elif 'three' in file_list[i]:\n        images.append(arr)\n        labels.append('3')\n    elif 'four' in file_list[i]:\n        images.append(arr)\n        labels.append('4')\n    elif 'openHand' in file_list[i]:\n        images.append(arr)\n        labels.append('5')\n    elif 'closeHand' in file_list[i]:\n        images.append(arr)\n        labels.append('0')\n        \ndf = pd.DataFrame({\n    'archivo': images,\n    'categoria': labels\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separamos dos conjuntos, train(80% del dataset) y test(20%).\ntrain, test = train_test_split(df, test_size=0.20, random_state=42)\n\n# Reseteamos los index para vayan al comienzo de daatframe.\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\n# Imprimimos el tamano de los dataframes.\nprint(train.shape, '<-->', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generador De Entrenamiento (Preprocesamiento de las imagenes)\nTAM_IMG = (100, 100)\n\"\"\"\nGeneramos nuevas imagenes en base a las pre existentes, por ejmplo, podemos cambiar el rango de rotacion, \ncortamos la imagen, hacemos zoom, volteamos, entre otras tecnicas para que de esta manera podamos tener\nuna mayor cantidad de imagenes para entrenar y hacer el testing.\n\n\"\"\"\ntrain_image_data = ImageDataGenerator(\n    rotation_range = 15,\n    rescale = 1./255,\n    zoom_range=0.25,\n    horizontal_flip = True,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1\n)\n\n# Procedemos ha generar las imagenes y preprocesarlas.\ntrain_generador = train_image_data.flow_from_dataframe(\n    train,\n    '../input/handgesture/build',\n    x_col = 'archivo',\n    y_col = 'categoria',\n    color_mode=\"grayscale\",\n    target_size = TAM_IMG,\n    class_mode = 'categorical'\n)\n\n# Escalamos la imagen diviendo cada pixel para 255.\ntest_image_data = ImageDataGenerator(rescale=1./255)\ntest_generador = test_image_data.flow_from_dataframe(\n    test,\n    '../input/handgesture/build',\n    color_mode=\"grayscale\",\n    x_col = 'archivo',\n    y_col = 'categoria',\n    target_size = TAM_IMG,\n    class_mode = 'categorical'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\n\nmodelo = Sequential()\n\nmodelo.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)))\nmodelo.add(BatchNormalization())\nmodelo.add(MaxPooling2D(pool_size=(2, 2)))\nmodelo.add(Dropout(0.25))\n\nmodelo.add(Conv2D(64, (3, 3), activation='relu'))\nmodelo.add(BatchNormalization())\nmodelo.add(MaxPooling2D(pool_size=(2, 2)))\nmodelo.add(Dropout(0.25))\n\nmodelo.add(Conv2D(128, (3, 3), activation='relu'))\nmodelo.add(BatchNormalization())\nmodelo.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodelo.add(Flatten())\nmodelo.add(Dense(256, activation = 'relu'))\nmodelo.add(BatchNormalization())\nmodelo.add(Dropout(0.5))\nmodelo.add(Dense(6, activation='softmax'))\n\nmodelo.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_shape = train.shape[0]\ntest_shape = test.shape[0]\n\nhistory = modelo.fit_generator(\n    train_generador,\n    epochs = 150,\n    validation_data = test_generador\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def guardar_pesos(nombre_archivo='pesos.h5'):\n    modelo.save_weights(nombre_archivo)\n\ndef guardar_modelo(nombre_archivo='modelo.json'):\n    modelo_json = modelo.to_json()\n    with open(nombre_archivo, \"w\") as json_file:\n        json_file.write(modelo_json)\n        \nguardar_pesos()\nguardar_modelo()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = '../input/handgesture/build/170openHand.png'\n\nimg = Image.open(data).convert('L')\nimg = img.resize((100, 100))\nimg = np.asarray(img)\nimg = img.reshape(-1, 100, 100, 1)\nimg = img//255\nvalues = modelo.predict(img)\ny_classes = values.argmax(axis=-1)\nprint(y_classes[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = float(tf.__version__.split('.')[0] + '.' + tf.__version__.split('.')[1])\nval","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}