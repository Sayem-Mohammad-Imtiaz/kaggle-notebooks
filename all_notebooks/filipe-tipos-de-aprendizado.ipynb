{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Supervised Learning: Avocado Prices\nO dataset foi escolhido para o tipo de aprendizado supervisionado dado que é possível utilizar dados como preço médio (coluna *AvaregePrice*) para classificação de abacates convencionais ou orgânicos (coluna *type*), por exemplo.\n***\n**Métrica de avaliação:** Matriz de confusão, Acurácia e F-Score -> Dado o problema de classificação binária, é interessante a utilização de uma matriz de confusão para identificação do número de verdadeiros positivos (TP), falsos positivos (FP), verdadeiros negativos (TN) e falsos negativos (FN), como ilustrado na figura abaixo:\n\n![1](https://miro.medium.com/max/462/1*7EYylA6XlXSGBCF77j_rOA.png)\n\n* TP - Verdadeiro positivo: Previu positivo e a previsão é verdadeira;\n* FP - Falso positivo (Erro tipo 1): Previu positivo e a previsão é falsa;\n* TN - Verdadeiro negativo: Previu negativo e a previsão é verdadeira;\n* FN - Falso negativo (Erro tipo 2): Previu negativo e a previsão é falsa;\n\nA partir dessas quantidades, e entendendo positivo como uma classificação de abacate tradicional e negativo como de abacate orgânico, é possível então obter-se as seguintes métricas para avaliação do modelo:\n\n* Acurácia (quanto o meu modelo acertou das previsões possíveis?):\n![2](https://miro.medium.com/max/589/1*tNTpugu1beoC3f6ivswnsA.png)\n* Recall (qual proporção de positivos foi identificados corretamente?):\n![2](https://miro.medium.com/max/198/1*zgmkLfNNRtFwCHp8m46AKA.png)\n* Precisão (qual a proporção de identificações positivas foi realmente correta?):\n![2](https://miro.medium.com/max/238/1*pJrHo_sp-pnLFl6Ww3imUw.png)\n* F-Score (qual a média harmonica do Recall e da Precisão?):\n![2](https://miro.medium.com/max/358/1*98FaAKfPWo-EBTbjsxm4GA.png)\n\nTratam-se de métricas interessantes para um problema de classificação dado que representam não só a quantidade de erros cometidos pelo classificador (confusões de uma classe por outra) mas também os tipo de erro cometidos, apesar de alguns parâmetros serem calculadas de um ponto de vista da classificação positiva (não levando em consideração verdadeiros negativos) e assumindo pesos iguais para os diferentes tipos de erros cometidos (que não necessariamente possuiram o mesmo custo).\n\n**Referências:**\n\n[1] Understanding Confusion Matrix: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62 (Acesso em 12/02/2020)\n\n[2] Entendendo o que é Matriz de Confusão com Python: https://medium.com/data-hackers/entendendo-o-que-%C3%A9-matriz-de-confus%C3%A3o-com-python-114e683ec509 (Acesso em 12/02/2020)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Supervised Learning: Avocado Prices\ndf_avocado = pd.read_csv(\"../input/avocado-prices/avocado.csv\")\ndf_avocado.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unsurpevised Learning: The Cure discography\nO dataset foi escolhido para o tipo de aprendizado não-supervisionado dado que é possível utilizar informações como popularidade da música (coluna *track_popularity*) em conjunto com a positividade da música (coluna *valence*), danceabilidade da música (colunas *danceability*) ou proporção de instrumental/vocal na música (colunas *instrumentalness* e *speechiness*, respectivamente) para mapear padrões relacionados a preferência de consumidores com relação ao tipo de música produzida pelo artista, por exemplo.\n***\n**Métrica de avaliação:** Método do cotovelo e V-measure -> Entendendo a análise como um problema de clusterização - de forma que os possíveis clusters formados indicariam a quantidade de positividade, danceabilidade ou proporção instrumental/vocal que melhor preveem uma alta popularidade de uma faixa (e, possívelmente, alto faturamento) - as métricas escolhidas para avaliação partem da ideia de inicialmente encontrar um número adequado de clusters (pelo método do cotovelo ou coeficiente de silhueta, por exemplo) seguido pela avaliação do processo em si (Homogeneidade e Completude, levando ao V-measure).\n\n* Homogeneidade: descreve a proximidade do resultado a um clustering perfeitamente homogêneo (cada cluster tem seus pontos pertencentes a um mesmo rótulo de classe, como ilustrado a seguir);\n![1](https://media.geeksforgeeks.org/wp-content/uploads/20190715113441/homoNotcomp.png)\n* Completude: descreve a proximidade do resultado a um clustering perfeitamente completo (todos os pontos pertencentes a um mesmo rótulo de classe estão agrupados no mesmo cluster, como ilustrado a seguir);\n![1](https://media.geeksforgeeks.org/wp-content/uploads/20190715113440/compNothomo.png)\n\nSendo N o número de amostras de dados, C o número de rótulos de diferentes classes, K o número de clusters e ack um número de pontos pertencentes à classe c e ao cluster k, a homogeneidade h é calculada por:\n![1](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-4fc4befceaac208a4595c8852f985267_l3.svg)\n![1](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a31a0212a86497bf672036de74d57279_l3.svg)\n![1](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-419d1ca8e2b5aa231dc20c2492e0aee6_l3.svg)\ne a completude c é calculada por:\n![1](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fb556fa62eccb5070cad1fbe9cc49239_l3.svg)\n![1](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f1c98517e15bd1eaecb9dc87c4a1e8d8_l3.svg)\n![1](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-863ba66694fa3039f5610bd167d65079_l3.svg)\n\n* V-measure (Vβ), com β ajustável para dar mais importância para a Homogeneidade ou para a Completude:\n![1](https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-919bece276dde748c26d541cb05743fd_l3.svg)\n\nTrata-se de uma metrica relativamente confiável e que independe do número de classes e de clusters, do tamanho dos dados e do algoritmo de clustering utilizado.\n\n**Referências:**\n\n[1] ML | V-Measure for Evaluating Clustering Performance: https://www.geeksforgeeks.org/ml-v-measure-for-evaluating-clustering-performance/ (Acesso em 13/02/2020)\n\n[2] Clustering metrics better than the elbow-method: https://towardsdatascience.com/clustering-metrics-better-than-the-elbow-method-6926e1f723a6 (Acesso em 13/02/2020)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Unsurpevised Learning: The Cure discography\ndf_cure = pd.read_csv(\"../input/the-cure-discography/thecure_discography.csv\")\ndf_cure.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reinforcement Learning: 3 million Sudoku puzzles with ratings\nO dataset foi escolhido para o tipo de aprendizado por reforço dada a alta complexidade do domínio, a possibilidade de avaliar o desempenho do agente incrementalmente de acordo com a solução fornecida e a possibilidade de recompensar/punir o agente proporcionalmente de acordo com o número de pistas/dificuldade de um jogo (colunas *clues* e *difficulty*, respectivamente).\n***\n**Métrica de avaliação:** \"Função de recompensa acumulada\" -> É possivel avaliar o algoritmo de aprendizado por reforço pela recompensa que a política adotada recebe ao atuar no ambiente do jogo, traçando a recompensa acumulada como função do número de etapas feitas até o momento, de forma que um algoritmo tem melhor desempenho que outro caso seu gráfico esteja consistentemente acima do outro.\n\n![1](https://artint.info/figures/ch11/rl-reward-plot-4.png)\n\nA métrica escolhida é interessante por conter alguns parâmetros deriváveis importantes:\n1. A inclinação assintótica pós-estabilização do algoritmo mostra o quão boa é a política adotada;\n2. O ponto de mínimo da curva mostra o quanto de recompensa deve ser sacrificada antes da política começar a melhorar;\n3. O cruzamento com o eixo horizontal mostra quantas etapas levam para recuperar o custo de aprendizado.\n\n**Referências:**\n\n[1] Evaluating Reinforcement Learning Algorithms: https://artint.info/html/ArtInt_267.html (Acesso em 12/02/2020)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Reinforcement Learning: 3 million Sudoku puzzles with ratings\ndf_sudoku = pd.read_csv(\"../input/3-million-sudoku-puzzles-with-ratings/sudoku-3m.csv\")\ndf_sudoku.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}