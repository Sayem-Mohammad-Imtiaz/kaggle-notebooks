{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.decomposition import PCA\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom math import sqrt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/car-price-prediction/CarPrice_Assignment.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(labels=['car_ID','CarName'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_quant_cols = df[['symboling','wheelbase','carlength','carwidth','carheight','curbweight',\n                  'enginesize','boreratio','stroke','compressionratio','horsepower',\n                  'peakrpm','citympg','highwaympg','price']]\ndf_cat_cols = df.drop(df_quant_cols.columns,axis=1)\n\nprint(df_quant_cols.columns, df_cat_cols.columns, sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Uni-Variate Analysis"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Analyzing Quantitative variables.\nplt.figure(figsize=(30, 30))\nsns.set(font_scale=1.5)\nind = 1\n\nfor col in df_quant_cols.columns:\n    plt.subplot(5, 3, ind)\n    sns.boxplot(x=df_quant_cols[col])\n    ind += 1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Analyzing categorical variables.\nplt.figure(figsize=(30, 30))\nsns.set(font_scale=1.5)\nind = 1\n\nfor col in df_cat_cols.columns:\n    plt.subplot(3, 3, ind)\n    sns.countplot(x=df_cat_cols[col])\n    ind += 1\n    \nsns.set(font_scale=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Insights from categorical features visualization\n1. Car names are widely distributed.\n2. Fueltype gas is having high proportion than diesel(~12%).\n3. Sedan type cars are highly preferred.\n4. 4-wheel drives are hardly used.\n5. Engine location - Almost every car has front engine.\n6. Engine type - ohc is vastly used than any other types.\n7. Cylinder numbers - cars with 4 cylinders are highly used.\n8. Fuel system - mpfi, 2bbl are widely used."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking target variable's distribution.\nsns.distplot(df.price)\nprint(\"Skew of target variable:\",df.price.skew())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target variable is right skewed."},{"metadata":{},"cell_type":"markdown","source":"# Bi-Variate analysis"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 30))\nsns.set(font_scale=1.5)\nind = 1\n\nfor col in df_cat_cols.columns:\n    plt.subplot(3, 3, ind)\n    sns.barplot(x=df[col], y=df.price)\n    ind += 1\n\nsns.set(font_scale=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Insights from categorical variables which are influencing target variable\n1. Fueltype - Diesel cars are slightly high in cost than gas.\n2. Aspiration - Turbo is high in cost than ordinary.\n3. Car type - Convertible and hardtop are costlier than others.\n4. Engine location - Cars with rear engines are highly expensive.\n5. Cylinder number - 3 cylinder cars are very cheaper."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(15,8))\nsns.heatmap(df_quant_cols.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Insights from Quantitative variables which are influencing target variable\n1. Symboling, Carheight, stroke, Compressionratio, peakrpm are not correlated with target variable(Price).\n2. We are having multicollinearity."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using get_dummies to do one-hot encoding.\ndf_cat_cols = pd.get_dummies(data=df_cat_cols,drop_first=False)\ndf_cat_cols.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_quant_cols = df_quant_cols.drop('price',axis=1)\ndf_quant_cols.columns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Joining both Quantitative and Categorical variables.\ndf_new = df_quant_cols.join(df_cat_cols,how='right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_regressor_scores(regr):\n    global X, y, X_train, X_test, y_train, y_test\n    # Prediction with training dataset:\n    y_pred_DTR_train = regr.predict(X_train)\n\n    # Prediction with testing dataset:\n    y_pred_DTR_test = regr.predict(X_test)\n\n    # Find training accuracy for this model:\n    accuracy_DTR_train = r2_score(y_train, y_pred_DTR_train)\n    print(\"Training Accuracy for Decision Tree Regression Model: \", accuracy_DTR_train)\n\n    # Find testing accuracy for this model:\n    accuracy_DTR_test = r2_score(y_test, y_pred_DTR_test)\n    print(\"Testing Accuracy for Decision Tree Regression Model: \", accuracy_DTR_test)\n\n    # Find RMSE for training data:\n    RMSE_DTR_train = sqrt(mean_squared_error(y_train, y_pred_DTR_train))\n    print(\"RMSE for Training Data: \", RMSE_DTR_train)\n\n    # Find RMSE for testing data:\n    RMSE_DTR_test = sqrt(mean_squared_error(y_test, y_pred_DTR_test))\n    print(\"RMSE for Testing Data: \", RMSE_DTR_test)\n\n    # Prediction with 10-Fold Cross Validation:\n    y_pred_cv_DTR = cross_val_predict(regr, X, y, cv=10)\n\n    # Find accuracy after 10-Fold Cross Validation\n    accuracy_cv_DTR = r2_score(y, y_pred_cv_DTR)\n    print(\"Accuracy for 10-Fold Cross Predicted Decision Tree Regression Model: \", accuracy_cv_DTR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_preprocess(x,y,std_scale=False,min_max_scale=False):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n    \n    if std_scale or min_max_scale:\n        if std_scale:\n            scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n        else:\n            scaler = MinMaxScaler(copy=True,feature_range=(0,1))\n        scaler.fit(x_train)\n        train_scaled = scaler.transform(x_train)\n        test_scaled = scaler.transform(x_test)\n        return(train_scaled, test_scaled, y_train, y_test)\n    else:\n        return(x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_vif(X):\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    return(vif)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model - 1\n\nLinear Regression - All features and outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_new\ny = df.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = data_preprocess(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearRegression()\nreg.fit(X_train,y_train)\nprint(\"Train Score :\", reg.score(X_train,y_train))\nprint(\"Test Score :\", reg.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_train)\ndf_residuals = pd.DataFrame({'Actual': y_train, 'Predicted': y_pred})\ndf_residuals.insert(2,\"ErrorTerm\",(df_residuals.Actual - df_residuals.Predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_residuals.ErrorTerm)\nprint(\"Residual mean :\", df_residuals.ErrorTerm.mean())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"X_endog = sm.add_constant(X_train)\nres = sm.OLS(y_train, X_endog)\nres.fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model - 2\n\nLinear Regression after filtering features from previous model."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_new[['curbweight','enginesize']]\ny = df.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = data_preprocess(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg=LinearRegression()\nreg.fit(X_train,y_train)\nprint(\"Train Score :\", reg.score(X_train,y_train))\nprint(\"Test Score :\", reg.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_train)\ndf_residuals = pd.DataFrame({'Actual': y_train, 'Predicted': y_pred})\ndf_residuals.insert(2,\"ErrorTerm\",(df_residuals.Actual - df_residuals.Predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_residuals.ErrorTerm)\nprint(\"Residual mean :\", df_residuals.ErrorTerm.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_endog = sm.add_constant(X_train)\nres = sm.OLS(y_train, X_endog)\nres.fit().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calc_vif(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.join(y).corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After Doing multiple iterations on filtering features based on their significance of impact on target feature, We come to a conclusion that Linear regression is not doing well with scores"},{"metadata":{},"cell_type":"markdown","source":"\n# Model - 3\n\n# Decision Tree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_new\ny = df.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = data_preprocess(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_reg = DecisionTreeRegressor(random_state=0)\ndtree_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_regressor_scores(dtree_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Post Pruning"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = dtree_reg.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\nprint(ccp_alphas)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\nax.set_xlabel(\"effective alpha\")\nax.set_ylabel(\"total impurity of leaves\")\nax.set_title(\"Total Impurity vs effective alpha for training set\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfs = []\nfor ccp_alpha in ccp_alphas:\n    clf = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n    clf.fit(X_train, y_train)\n    clfs.append(clf)\nprint(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n      clfs[-1].tree_.node_count, ccp_alphas[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfs = clfs[:-1]\nccp_alphas = ccp_alphas[:-1]\n\nnode_counts = [dtree_reg.tree_.node_count for dtree_reg in clfs]\ndepth = [dtree_reg.tree_.max_depth for dtree_reg in clfs]\nfig, ax = plt.subplots(1, 2,figsize=(20,8))\nax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle=\"steps-post\")\nax[0].set_xlabel(\"alpha\")\nax[0].set_ylabel(\"number of nodes\")\n\nax[1].plot(ccp_alphas, depth, marker='o', drawstyle=\"steps-post\")\nax[1].set_xlabel(\"alpha\")\nax[1].set_ylabel(\"depth of tree\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = [dtree_reg.score(X_train, y_train) for dtree_reg in clfs]\ntest_scores = [dtree_reg.score(X_test, y_test) for dtree_reg in clfs]\n\nfig, ax = plt.subplots(figsize=(15,5))\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n        drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n        drawstyle=\"steps-post\")\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_reg = DecisionTreeRegressor(random_state=0,ccp_alpha=0.55e+06)\ndtree_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print_regressor_scores(dtree_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Model - 5\n\nRandom forest regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_new\ny = df.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = data_preprocess(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [100, 500, 1000, 1500]\nmax_features = ['auto', 'sqrt']\nmax_depth = [2, 3, 5, 6, 8, None]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4, 10]\noob_score = [True, False]\n\nparams_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf, 'oob_score': oob_score}\n\n\nrf_reg = RandomForestRegressor(random_state=0)\n\nrf_reg = GridSearchCV(rf_reg, params_grid, cv=3, verbose=2, n_jobs=-1)\n\nrf_reg.fit(X_train, y_train)\nbest_params = rf_reg.best_params_\nprint(f\"Best parameters: {best_params}\")\n\nrf_reg = RandomForestRegressor(**best_params)\nrf_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print_regressor_scores(rf_reg)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}