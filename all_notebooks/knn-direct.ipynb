{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \n\nfrom csv import reader\nfrom math import sqrt\n\n\n# Load and convert a dataset\n\ndef load_data(data_csv):\n    \"\"\"\n    This funciton opens a dataset, turns it to a list, and return that list.\n    Each element in that list is also a list.\n    This list will be used as a train dataset or a test dataset.\n    \"\"\"\n    dataset = list()\n    # Open and read a dataset\n    with open(data_csv, 'r') as data:\n        csv_reader = reader(data)\n        #  For each row, append the whole row of that row into the list\n        for row in csv_reader:\n            if not row:\n                continue\n            dataset.append(row)\n    # Since the dataframe is turned to a list, the column indexes are removed\n    dataset.pop(0)\n    return dataset\n\n\n\n\n# Because the datasets are lists, all entries are string type.\n# The needed entries will be turned to float or integer for further uses.\n\ndef float_data_converter(dataset, column):\n    \"\"\"\n    This function turns all values in a specific column to float type.\n    \"\"\"\n    for row in dataset:\n        row[column] = float(row[column])\n    return\n     \n\ndef numerical_data_converter(dataset, column):\n    \"\"\"\n    This function turns the atom type column in a dataset to numbers for knn uses.\n    This fuction returns a dictionary where keys are atom types and values are integers.\n    \"\"\"\n    # Create a set of atom types\n    atom_types = [row[column] for row in dataset]\n    # Assign atom types to a set so they don't repeat\n    key = set(atom_types)\n    # Asign a number to each atom type\n    numerical_atom_types = dict()\n    for i, value in enumerate(key):\n        numerical_atom_types[value] = i\n    for row in dataset:\n        row[column] = numerical_atom_types[row[column]]\n    return numerical_atom_types\n \n    \n    \n# Process train and test data when being input as directories\n    \ndef data_processor(train_data_dir, test_data_dir):\n    \"\"\"\n    This function turns two the input data (train and test) to to lists that will later be used.\n    It takes in two directories and returns two lists where tall values are float and the atom types are enumerated.\n    \"\"\"\n    train_data = load_data(train_data_dir)\n    test_data = load_data(test_data_dir)\n    datasets = (train_data, test_data)\n    # Convert datasets to useful lists\n    for ds in datasets:\n        for i in range(len(ds[0])-2):\n            float_data_converter(ds, i)\n        numerical_data_converter(ds, len(ds[0])-1)\n    return (train_data, test_data)  \n    \n    \n            \n# Find the euclidean distance of two data rows\n    \ndef distance_calculator(row1, row2):\n    \"\"\"\n    This function calculates the Euclidean distance of two rows.\n    It returns the distance.\n    \"\"\"\n    distance_squared = 0.0\n    for i in range(len(row1)-2):\n        distance_squared += (row1[i] - row2[i])**2\n    distance = sqrt(distance_squared)\n    return distance\n\n\n\n# Find the values that are closest to the test value\n\ndef closest_neighbors_finder(train_data, test_row, k):\n    \"\"\"\n    This function takes a row from a test dataset and find its closest neighbors from a train dataset.\n    k is the number of neighbors.\n    This function returns a list of neighbors.\n    \"\"\"\n    distances = list()\n    for train_row in train_data:\n        distance = distance_calculator(test_row, train_row)\n        distances.append((train_row, distance))\n    # Sort distances list aka train rows from biggest to smallest based on their distance \n    distances.sort(key=lambda tup: tup[1])\n    neighbors_list = list()\n    for i in range(k):\n        neighbors_list.append(distances[i][0])\n    return neighbors_list\n\n\n\n\n\n# Make a prediction with neighbors\n\ndef type_predictor(train_data, test_row, k):\n    \"\"\"\n    This function uses the train data to predict the type of a test row.\n    It employs the previous closet_neighbors_finder function to predict.\n    It returns a predicted type for a test row.\n    \"\"\"\n    neighbors_list = closest_neighbors_finder(train_data, test_row, k)\n    # Create a list of types. This set contains k number of types\n    type_list = [row[-1] for row in neighbors_list]\n    # Based on how many times the type appears in the type list to predict type\n    # Convert list of type to set so the entries don't repeat\n    predicted_type = max(set(type_list), key=type_list.count)\n    return predicted_type\n \n# knn\ndef k_nearest_neighbors(train_data, test_data, k):\n    \"\"\"\n    This function is the final funtion to use knn to predict the type of atom.\n    It takes in a train dataset, a test dataset as lists, and an input number of neighbors (k).\n    It returns a list of predicted types for all rows in the test dataset. \n    \"\"\"\n    # Avoid users from inputing k that is greater than the sample size\n    assert k <= len(train_data), \"[!] k can't be greater than the size of dataset.\"\n    \n    predictions = list()\n    for test_row in test_data:\n        result = type_predictor(train_data, test_row, k)\n        predictions.append(result)\n    return(predictions)\n\n# Calculate knn accuracy\ndef knn_accuracy_test(train_data, test_data, k):\n    \"\"\"\n    This function calculate the accuracy percentage of the knn algorithm.\n    It takes train data and test data as lists, and a value of k, and retunrs the accuracy of that k.\n    \"\"\"\n    # Avoid users from inputing k that is greater than the sample size\n    assert k <= len(train_data), \"[!] k can't be greater than the size of dataset.\"\n    # The actual typess from the test dataset\n    real = [row[-1] for row in test_data]\n    # The predicted types from knn algorithm\n    predict = k_nearest_neighbors(train_data, test_data, k)\n    count = 0\n    for i in range(len(real)):\n        if real[i] == predict[i]:\n            count+=1\n    accuracy_percentage = ( count / float(len(predict)) ) * 100\n    return accuracy_percentage\n\n\n\n# Evaluate accuracy of all k values\ndef knn_k_evaluation(train_data_dir, test_data_dir):\n    \"\"\"\n    This function evaluates the accuracy of all possible k values.\n    It takes the train data directory and the test data directory.\n    It returns the accuracy for each k as a histogram and a dictionary.\n    \"\"\"\n    train_data, test_data = data_processor(train_data_dir, test_data_dir)\n    k_range = np.arange(1, len(ds_train)+1)\n    result = {}\n    for k in k_range:\n        result[k] = knn_accuracy_test(train_data, test_data, k)    \n    # Plot a histogram from the result dictionary\n    plt.bar(list(result.keys()), result.values(), color='b')\n    plt.xlabel('k')\n    plt.ylabel('Accuracy (%)')\n    plt.show()\n    print(result)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}