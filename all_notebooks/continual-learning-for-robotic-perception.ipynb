{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PROJECT 2 - Continual Learning (CL) for Robotic Perception\n---\n\n* Richanshu Jha - rj1469@nyu.edu\n* Disha Papneja - dp3074@nyu.edu"},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{},"cell_type":"markdown","source":"Importing the required development library toolkits. Pytorch 4.0 is used for developing our neural nets."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport random\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the MNIST Dataset\nThe data has been loaded from Kaggle. (This is the original MNIST dataset). It is a dataset of 28*28 grayscale images.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"##LOADING THE MNIST DATASET\ntrainData = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\ntestData = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\n\nmnistData = pd.concat([trainData, testData], axis=0)\nprint('Merged data loaded with shape: ', str(mnistData.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reshaping the data and getting the labels\nThe shape of each image is 28x28 pixels, which is why the shape of the Dataset is (N x 28 x 28)"},{"metadata":{"trusted":true},"cell_type":"code","source":"labelData = mnistData['label'].to_numpy()\nfeatureData = mnistData.drop(['label'], axis = 1)\nfeatureData = featureData/255\nfeatureData = featureData.to_numpy().reshape(featureData.shape[0], 28, 28)\nprint('Reshaped MNIST features shape: ', str(featureData.shape))\nprint('Reshaped MNIST labels shape: ', str(labelData.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions\nHere, we define 3 important helper functions:\n* `splitData`:   Splits the dataset into training and testing pairs according to the provided split ratio\n* `rotateData`:  Takes a dataset of images and Rotates all images in it by the given rotation. This is to implement rotation in the MNIST dataset.\n* `createTasks`: Creates 3 Tasks from a set of training and testing pairs. Each task is given a rotation. The algorithm to calculate the rotation for each task has been taken from the code in the repository that was provided along with the problem statement of the project, for the MNIST Rotations dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"#SPLITS DATA INTO TRAINING AND TESTING PAIRS\ndef splitData(features, labels, ttRatio):\n    n = int(features.shape[0] * ttRatio)\n    xTrain = features[:n] \n    xTest = features[n:]\n    yTrain = labels[0:n]\n    yTest = labels[n:]\n    print('Split the data')\n    print('Training features shape: ', str(xTrain.shape))\n    print('Training labels shape: ', str(xTest.shape))\n    print('Testing features shape: ', str(yTrain.shape))\n    print('Testing features shape: ', str(yTest.shape))\n    return(xTrain, xTest, yTrain, yTest)\n\n#ROTATION ACCORIDING TO THE CODE PROVIDED FOR THE PROJECT\ndef rotateData(d, rotation):\n    result = torch.FloatTensor(d.shape[0], 784)\n    tensor = transforms.ToTensor()\n\n    for i in range(d.shape[0]):\n        img = Image.fromarray(d[i])\n        result[i] = tensor(img.rotate(rotation)).view(784)\n    return result\n\n#GENERATING TASKS. USING ROTATION OF THE DATASET FROM THE CODE PROVIDED IN THE MNIST DATASET LINK FOR THE PROJECT.\ndef createTasks(xTrain, xTest, yTrain, yTest, nTasks, minRot, maxRot):\n    tasksTrain = []\n    tasksTest = []\n    for t in range(nTasks):\n        minR = 1.0 * t / nTasks * (maxRot - minRot) + minRot\n        maxR = 1.0 * (t + 1) / nTasks * (maxRot - minRot) + minRot\n        rot = random.random() * (maxR - minR) + minR\n        print('Creating Task ', str(t+1), ' With rotation %0.3f'%(rot))\n        tasksTrain.append([rot, rotateData(xTrain, rot), yTrain])\n        tasksTest.append([rot, rotateData(xTest, rot), yTest])\n        \n    print('Completed Creation of Tasks')\n    return(np.array(tasksTrain), np.array(tasksTest))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initializing the Training and Testing pairs\nA high ratio of 0.9 has been taken since we wanted to use as much data for training as possible, since we would be using deep neural networks which require large datasets to train. As a team we agreed at just 0.1 of the dataset (7000 images) would still be a reasonable amount of testing data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"xTrain, xTest, yTrain, yTest = splitData(featureData, labelData, 0.9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper function to display images from the training, testing sets\nThe first 10 training images are displayed on the screen along with their labels for reference"},{"metadata":{"trusted":true},"cell_type":"code","source":"##HELPER FUNCTION TO DISPLAY THE IMAGES TO CHECK OUT OUR DATA\ndef displayImages(features,labels, m, n):\n    f, axarr = plt.subplots(m,n)\n    f.set_figheight(3*m)\n    f.set_figwidth(3*n)\n    x = 0\n    for i in range(m):\n        for j in range(n):\n            if(m == 1):\n                axarr[j].imshow(features[x])\n                axarr[j].set_title(labels[x])\n                axarr[j].axis('off')\n            elif(n == 1):\n                axarr[i].imshow(features[x])\n                axarr[i].set_title(labels[x])\n                axarr[i].axis('off')\n            else:\n                axarr[i, j].imshow(features[x])\n                axarr[i, j].set_title(labels[x])\n                axarr[i, j].axis('off')\n            x += 1\n            \ndisplayImages(xTrain, yTrain, 2,5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Neural Network\nFor this project, a fairly simple neural network is used. Since we are using different Rotations in the tasks, spatial relations would mostly be preserved across the Tasks (as opposed to using Permutations). Due to this we chose a convolutional network with 3 Convolution Layers and 2 fully connected layers."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and testing functions\nThe following funtions are helper functions that we will use to train and test models. The batch size here is 256 and we run it for 3 epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef train(model, device, x_train, t_train, optimizer, epoch):\n    model.train()\n    \n    for start in range(0, len(t_train)-1, 256):\n      end = start + 256\n      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n      x, y = x.to(device), y.to(device)\n      optimizer.zero_grad()\n      output = model(x)\n      loss = F.cross_entropy(output, y)\n      loss.backward()\n      optimizer.step()\n        \n    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n\ndef test(model, device, x_test, t_test):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for start in range(0, len(t_test)-1, 256):\n      end = start + 256\n      with torch.no_grad():\n        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n        x, y = x.to(device), y.to(device)\n        output = model(x)\n        test_loss += F.cross_entropy(output, y).item()\n        pred = output.max(1, keepdim=True)[1]\n        correct += pred.eq(y.view_as(pred)).sum().item()\n\n    print('Testing Accuracy: ' + str(correct) + '/' + str(len(t_test)) + ' -> %0.3f'%(correct / len(t_test)))\n    return (100 * correct / len(t_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creation of Tasks"},{"metadata":{"trusted":true},"cell_type":"code","source":"tasksTrain, tasksTest = createTasks(xTrain, xTest, yTrain, yTest, 3, 0, 90)\nprint(tasksTrain.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Displaying the result of applying rotations\nHere, the first 5 images from each task have been displayed along with their labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONVERTS THE TASKS WHICH HAVE TENSORS INTO PURELY ND ARRAY.\ndef npTasks(tasks):\n    res = []\n    for t in range(len(tasks)):\n        res.append(np.array(tasks[t][1]).reshape(tasks[t][1].shape[0],28,28))\n    return(np.array(res))\n\nnpTrain = npTasks(tasksTrain)\nnpTest = npTasks(tasksTest)\n\n#SHOWING ROTATION TASKS (5 Per Task)\ndisplayImages(npTrain[0], yTrain, 1, 5)\ndisplayImages(npTrain[1], yTrain, 1, 5)\ndisplayImages(npTrain[2], yTrain, 1, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vanilla Neural Networks\nHere we have first tested the results by directly using our neural network. For each task, we use the training set of that task. To calculate the accuracy, we test it with the test sets of each of the tasks. This is the model using no Continual Learning approach. We did this in order to compare it with the continual learning approach so as to compare the differences between the two."},{"metadata":{"trusted":true},"cell_type":"code","source":"## WITHOUT CONTINUAL LEARNING\nuse_cuda = True\nuse_cuda = use_cuda and torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nmodel = Net().to(device)\nmodel.float()\ntorch.manual_seed(1)\n\nResults = []\n\n#The model will be trained for each task and tested against the combined test sets of all tasks\n\ndef noCLTrainTest(xTrain, yTrain, xTest, yTest, epochs):\n    res = []\n    model = Net().to(device)\n    model.float()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    for epoch in range(epochs):\n        train(model, device, xTrain.reshape(xTrain.shape[0],1,28,28) , yTrain, optimizer, epoch)\n        print('')\n        res.append(test(model, device, xTest.reshape(xTest.shape[0],1,28,28) , yTest))\n    return(res)\n\nprint('--------')\n#TASK 1\nxTr, yTr = npTrain[0], yTrain\nxTe = np.concatenate([npTest[0], npTest[1], npTest[2]])\nyTe = np.concatenate([yTest, yTest, yTest])\nResults.append(noCLTrainTest(xTr ,yTr , xTe, yTe, 3))\n\nprint('--------')\n#TASK 2\nxTr, yTr = npTrain[1], yTrain\nxTe = np.concatenate([npTest[0], npTest[1], npTest[2]])\nyTe = np.concatenate([yTest, yTest, yTest])\nResults.append(noCLTrainTest(xTr ,yTr , xTe, yTe, 3))\n\nprint('--------')\n#TASK 3\nxTr, yTr = npTrain[2], yTrain\nxTe = np.concatenate([npTest[0], npTest[1], npTest[2]])\nyTe = np.concatenate([yTest, yTest, yTest])\nResults.append(noCLTrainTest(xTr ,yTr , xTe, yTe, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Elastic Weights Consolidation\nWe considered multiple approaches to continual learning. Our final 2 options were Elastic weights consolidation, and using Rehearsal techniques. Rehearsal techniques are fairly straight forward to implement and can give a much higher accuracy than EWC if the entire previous dataset of previous is considered while training for the next tasks. In this implementation, there would be some tradeoff between acuracy and memory usage depending on how much of the past Tasks' datasets we choose to concatenate with the next one.\n\nHowever, the project is continual Learning (CL) for Robotic Perception. If we consider the use case for robots, we must consider the fact that there would be a memory and time constraint. Here, increasing the dataset after each task means a linear increase in the memory and time requirements as time goes on hence we did not see this as an ideal method for this project. \n\nWe have implemented Elastic Weight Consolidation which doesn't use any previous data. In this model we save the model parameters and the square of the gradients as the fisher and optpar data for each task. When we calculate the loss, we add an extra parameter to the loss: `(fisher * (optpar - param).pow(2)).sum() * ewcLambda`. This allows us to store some weight information from the previous tasks.\n\nEWC is a part of a techniques called regularization. Regularization approaches alleviate catastrophic forgetting by imposing constraints on the updateof the neural weights.  Such approaches are typically inspired by theoretical neuroscience modelssuggesting  that  consolidated  knowledge  can  be  protected  from  forgetting  through  synapses  witha  cascade  of  states  yielding  different  levels  of  plasticity.From a computational perspective,  this is generally modelled via additional regularization terms that penalize changes in the mapping function of a neural network, like we did in our implementation of EWC.It is based on the computation of the importance of each weight (fisher information) and a squared regularization loss, penalizing changes in the most important wheights for the previous tasks.It has the great advantage of not using any of the previous tasks data!"},{"metadata":{"trusted":true},"cell_type":"code","source":"## USING ELASTIC WEIGHTS CONSOLIDATION (REGULARIZATION)\nfisherDict = {}\noptparDict = {}\newcLambda = 0.8\n\n## CALLED FOR EACH TASK TO UPDATE THE FISHER AND OPTPAR DICTS\n## THESE WILL BE USED TO CALCULATE THE LOSS\ndef updateGradientDicts(t, xTr, yTr):\n    model.train()\n    optimizer.zero_grad()\n\n    #FINDING THE GRADIENTS\n    for start in range(0, len(yTr)-1, 256):\n        end = start + 256\n        x, y = torch.from_numpy(xTr[start:end]), torch.from_numpy(yTr[start:end]).long()\n        x, y = x.to(device), y.to(device)\n        output = model(x)\n        loss = F.cross_entropy(output, y)\n        loss.backward()\n\n    fisherDict[t] = {}\n    optparDict[t] = {}\n\n    #UPDATING THE GRADIENTS STORED IN FISHER AND OPTPAR DICT\n    for name, param in model.named_parameters():\n        optparDict[t][name] = param.data.clone()\n        fisherDict[t][name] = param.grad.data.clone().pow(2)\n    \n#MODIFIED TRAINING METHOD WITH REGULARIZATION LOSS \n#CALCULATED USING THE FISHER AND OTPAR DICT VALUES)\ndef ewcTrain(model, device, t, xTr, yTr, optimizer, epoch):\n    model.train()\n\n    for start in range(0, len(yTr)-1, 256):\n        end = start + 256\n        x, y = torch.from_numpy(xTr[start:end]), torch.from_numpy(yTr[start:end]).long()\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = F.cross_entropy(output, y)\n        \n        ## ADDITION OF REGULARIZATION LOSS\n        for task in range(t):\n            for name, param in model.named_parameters():\n                if task in fisherDict:\n                    fisher = fisherDict[task][name]\n                    optpar = optparDict[task][name]\n                    loss += (fisher * (optpar - param).pow(2)).sum() * ewcLambda\n        \n        loss.backward()\n        optimizer.step()\n    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and testing the EWC Model\nThe training and evaluation of the EWC model has been done in the same way as the non CL Model. The model is trained once for each task, with only the dataset associated with that task. The combined testing dataset of all tasks is used for the evaluation of the model. We need also to modify our train function to add the new regularization loss."},{"metadata":{"trusted":true},"cell_type":"code","source":"## TRAINING AND TESTING THE CONTINUAL LEARNING MODEL USING EWC\nmodel = Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\ndef ewcCLTrainTest(xTrain, yTrain, xTest, yTest, epochs, t):\n    res = []\n    for epoch in range(epochs):\n        ewcTrain(model, device, t, xTrain.reshape(xTrain.shape[0],1,28,28) , yTrain, optimizer, epoch)\n        res.append(test(model, device, xTest.reshape(xTest.shape[0],1,28,28) , yTest))\n        \n    updateGradientDicts(t, xTrain.reshape(xTrain.shape[0],1,28,28), yTrain)\n    return(res)\n\nprint('--------')\n#TASK 1\nxTr, yTr = npTrain[0], yTrain\nxTe = np.concatenate([npTest[0], npTest[1], npTest[2]])\nyTe = np.concatenate([yTest, yTest, yTest])\nResults.append(ewcCLTrainTest(xTr ,yTr , xTe, yTe, 3, 0))\n\nprint('--------')\n#TASK 2\nxTr, yTr = npTrain[1], yTrain\nxTe = np.concatenate([npTest[0], npTest[1], npTest[2]])\nyTe = np.concatenate([yTest, yTest, yTest])\nResults.append(ewcCLTrainTest(xTr ,yTr , xTe, yTe, 3, 1))\n\nprint('--------')\n#TASK 3\nxTr, yTr = npTrain[2], yTrain\nxTe = np.concatenate([npTest[0], npTest[1], npTest[2]])\nyTe = np.concatenate([yTest, yTest, yTest])\nResults.append(ewcCLTrainTest(xTr ,yTr , xTe, yTe, 3, 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting the Results\nThe accuracies of the models at their second epochs have been plotted. The x-axis is the number of tasks performed."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plotting the Results\nResults = np.array(Results).reshape(2,3,3)\n\n#TO FORCE X TO TAKE INTEGER VALUES ONLY\nX = [1,2,3]\nfrom matplotlib.ticker import MaxNLocator\nax = plt.figure().gca()\nax.xaxis.set_major_locator(MaxNLocator(integer=True))\nminVal, maxVal = min(Results.flatten()), max(Results.flatten())\n\nplt.xlabel('Tasks')\nplt.ylabel('Accuracy')\nplt.ylim((minVal-minVal%10)-10, 10+(maxVal-maxVal%10))\nplt.plot(X, Results[0,:,1], label = 'No CL')\nplt.plot(X, Results[1,:,2], label = 'CL Using EWC')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nIt is evident from the graph that as the number of tasks increases, there is a significant relative increase in the accuracy of the model that applies the Continous Learning technique of Elastic Weights Consolidation, as compared to the model that that does not employ any Continous Learning Techniques. As discussed earlier, many other techniques can also be applied to this but some (for example: Naive method, Shuffled Rehersal techniques etc.) are not the best options for this since they result in an ever increasing memory requirement as the number of tasks increases which would bot not be an ideal solution for most cases of robotic perception. The strength of using EWC is that the memory requirement increments are negligible compared to these techniques. In general, a large number of real life applications in machine learning involve data is dynamic, streamed, or occurs in batches such that the model needs to retrain at constant intervals. it is noted and observed that Continual Learning techniques is the solution to these machine learning problems."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}