{"cells":[{"metadata":{"id":"XnFmLhgCGEpZ"},"cell_type":"markdown","source":"# Artificial Neural Network Simplified (Churn Dataset)\n\n### **Goals of the project -** \n* To understand the basic implemetation of the ANN\n* To build the ANN layer by layer and understanding the significance of each layer and the arguments used\n* To understand how to cross validate the results of ANN\n* Learn to fine tune the ANN using Grid Search Mechanism\n","execution_count":null},{"metadata":{"id":"ilCdMQauMrlN","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport warnings  \nwarnings.filterwarnings('ignore') # to ignore the warnings","execution_count":null,"outputs":[]},{"metadata":{"id":"4oVf5qyJMzaU","outputId":"feebe870-58cc-40d0-e00e-5eded246b374","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/churn-modelling/Churn_Modelling.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"awCv73wvGlCI"},"cell_type":"markdown","source":"## **Step 1** : Pre-processing","execution_count":null},{"metadata":{"id":"S7PeuwU5NHwC","trusted":true},"cell_type":"code","source":"# encoding the categorical columns and getting rid of the redundant columns\ngeog = pd.get_dummies(data['Geography'], drop_first=True)\ngend = pd.get_dummies(data[\"Gender\"], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"LJt98sYdNKwa","trusted":true},"cell_type":"code","source":"# converting these columns to 'int'\ngeog = geog.astype(int)\ngend = gend.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"id":"ww2vQzqLNM0K","trusted":true},"cell_type":"code","source":"# concatenating these encoded variables to the original dataset\ndata1 = pd.concat([data, gend, geog], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"INr35dTnNPHS","trusted":true},"cell_type":"code","source":"# seperating the independent and dependent variables\n\n# taking only the important variables(columns names) from the orignal dataset\nfeature_cols = ['CreditScore', 'Age', 'Tenure', 'Balance',\n                'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Male', 'Germany', 'Spain']\n\nx = data1[feature_cols]\ny = data1['Exited']","execution_count":null,"outputs":[]},{"metadata":{"id":"G-Vb1G3KNT-p","trusted":true},"cell_type":"code","source":"# splitting the data into training and testing\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"Jy9usArWNWEi","trusted":true},"cell_type":"code","source":"# scaling the data to crush the impact of variable with larger weight in the analysis\n# this method equalizes range and variability in the dataset\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"y9hJGPBVHR3p"},"cell_type":"markdown","source":"## **Step - 2** : Building the Artificial Neural Network","execution_count":null},{"metadata":{"id":"WDxRwOeDNX-B","trusted":true},"cell_type":"code","source":"# importing the required libraries to form an Artificial Neural Network\nfrom keras.models import Sequential     # required to initialize the neural network coz ANN is a sequence of layers\nfrom keras.layers import Dense          # to build the layers in ANN","execution_count":null,"outputs":[]},{"metadata":{"id":"cbiB8hviNZiB","trusted":true},"cell_type":"code","source":"# initializing the ANN\nann_classifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"id":"1CnxbRB9HetA"},"cell_type":"markdown","source":"**Step 2.1 :** Adding the input layer and the 1st hidden layer","execution_count":null},{"metadata":{"id":"V3jn7i3ANcL4","trusted":true},"cell_type":"code","source":"ann_classifier.add(Dense(units=6, kernel_initializer = 'uniform', activation='relu', input_dim=11))","execution_count":null,"outputs":[]},{"metadata":{"id":"WOGu45MKHqfS"},"cell_type":"markdown","source":"**Arguments used -**\n* `units` = no. of nodes in hidden layer, generally half of the total of all variables\n* `kernel_initializer` = 'uniform' means assigining weights between 0 and 1 in a uniform manner\n* `activation='relu'` means assigning rectifier function at the hidden layer\n* `input_dim=11` means no. of input neurons in the input layer (no. of variables in training set)","execution_count":null},{"metadata":{"id":"zf3scBflIOEE"},"cell_type":"markdown","source":"**Step 2.2 :** Adding the 2nd hidden layer\n\nThis time, there is no need to specify the input layer as the operation above tells this layer what input to expect","execution_count":null},{"metadata":{"id":"XmZMgt0VNeXk","trusted":true},"cell_type":"code","source":"ann_classifier.add(Dense(units=6, kernel_initializer = 'uniform', activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"id":"VVtgAYBKI1qR"},"cell_type":"markdown","source":"**Step 2.3 :** Adding the output layer","execution_count":null},{"metadata":{"id":"nxP0OcItNgkF","trusted":true},"cell_type":"code","source":"ann_classifier.add(Dense(units=1, kernel_initializer = 'uniform', activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"id":"T00CtwNgJBSD"},"cell_type":"markdown","source":"**Step 2.4 :** Compiling the ANN","execution_count":null},{"metadata":{"id":"aSdZUUu3Nikd","trusted":true},"cell_type":"code","source":"ann_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"1MvutdeqJHkm"},"cell_type":"markdown","source":"**Arguments used -** \n* `optimizer` = name of the algorithm we want to apply, usually SGD algorithm known by 'adam'\n* `loss` = it is a loss function within SGD algorithm, or the function we need to optimize to find optimal weights usually based on the activation function used for the o/p layer, or the type of dependent variable\n* `metrics` parameter has [ ] coz it expects a list of values as the weights have been calculated after each observation or each batch of observations. Hence the algorithm uses this parameter to calculate the accuracy to improve the model performance","execution_count":null},{"metadata":{"id":"9AO48wENJ6VF"},"cell_type":"markdown","source":"**Step 2.5 :** Fitting the ANN to the training set\n\n**Arguments used -**\n* `batch_size` means after how many observations the weights should be updated\n* `epochs` means how many times you want to run through the network\n* `1` epoch would signify that whole data has been passed through the network once","execution_count":null},{"metadata":{"id":"NNlQzCT9NlS5","outputId":"afd9c475-75bd-4701-f46e-cbcb30343ff5","trusted":true},"cell_type":"code","source":"ann_classifier.fit(x_train, y_train, batch_size=10, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"id":"zSpYBSuGKhBv"},"cell_type":"markdown","source":"## **Step 3 :** Predicting the results for test set","execution_count":null},{"metadata":{"id":"yMuuOy4KNnv4","trusted":true},"cell_type":"code","source":"y_pred = ann_classifier.predict(x_test)\ny_pred = y_pred > 0.5       ","execution_count":null,"outputs":[]},{"metadata":{"id":"NET2xmqvLvob"},"cell_type":"markdown","source":"* Here we set a threshold of 0.5 \n* People having this score greater than 0.5 means a probability of leaving the bank\n* Hence we apply a trick here that if values are less than 0.5 then it would return False and if greater than 0.5 it would return True\n* Then we plot the Confusion Matrix for the same","execution_count":null},{"metadata":{"id":"Ydkz7jX0N8o9","outputId":"a101f0fc-5de8-4252-fc5a-b652ed2fd86c","trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(\"The accuracy obtained on testing set is\", round((accuracy_score(y_test, y_pred) * 100), 2), '%')","execution_count":null,"outputs":[]},{"metadata":{"id":"xLURgbGlMvbZ"},"cell_type":"markdown","source":"## **Step 4 :** Evluating the ANN (Cross Validation)","execution_count":null},{"metadata":{"id":"IbHq3NVlNIlb"},"cell_type":"markdown","source":"**Step 4.1 :** Wrapping k-fold cross validation into keras model","execution_count":null},{"metadata":{"id":"fSSN_M_mN_Qn","trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"id":"FeVVuq2GNHEn"},"cell_type":"markdown","source":"**Step 4.2 -** Building a function to initialize the ANN and its respective layers","execution_count":null},{"metadata":{"id":"aGItmvVkOBYy","trusted":true},"cell_type":"code","source":"def build_classifier():\n    from keras.models import Sequential\n    from keras.layers import Dense\n    ann_classifier = Sequential()\n    ann_classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11))\n    ann_classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n    ann_classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n    ann_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return ann_classifier","execution_count":null,"outputs":[]},{"metadata":{"id":"q_L0xF1MNZzv"},"cell_type":"markdown","source":"**Step 4.3 -** Performing the cross validation","execution_count":null},{"metadata":{"id":"_fAccawZOFSY","outputId":"a23b50e9-c486-4b60-e15c-56492ad5da97","trusted":true},"cell_type":"code","source":"ann_classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\naccuracies = cross_val_score(estimator=ann_classifier, X=x_train, y=y_train, cv=7, n_jobs=-1)\n# will contain 10 accuracies returned by kfold cv\nprint(\"The average of the accuracies is\", round((accuracies.mean() * 100), 2), '%')\nprint(\"The standard deviation of the accuracies is \", accuracies.std())","execution_count":null,"outputs":[]},{"metadata":{"id":"_ROdUiaTN48M"},"cell_type":"markdown","source":"## **Step 5 :** Tuning the ANN \n* This is usually done for the sake of ease in choosing the best parameters for the ANN instead of manually imputing them over and over\n* This method also saves time by avoiding trial and error\n* We use the Grid Search method for this task","execution_count":null},{"metadata":{"id":"CFuvR7VoOJim","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\ndef build_classifier(optimizer):\n    from keras.models import Sequential\n    from keras.layers import Dense\n    ann_classifier = Sequential()\n    ann_classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11))\n    ann_classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n    ann_classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n    ann_classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    return ann_classifier","execution_count":null,"outputs":[]},{"metadata":{"id":"0Qmeff93O-C2"},"cell_type":"markdown","source":"A small change we do while building this model is that the 'optimizer' argument is passed while calling the function so that it can use the optimizers provided in the list below","execution_count":null},{"metadata":{"id":"FLrHbLFWOXWj","outputId":"f587579f-90f7-4e04-eb21-9a0714f77146","trusted":true},"cell_type":"code","source":"# here we set what parameters to pass to check for the optimal values suggested by this method\nann_classifier = KerasClassifier(build_fn = build_classifier)\n\n# we pass these arguments of parameters as a list\nparams = {'batch_size': [25, 32], 'nb_epoch': [100, 200, 300], 'optimizer': ['adam', 'rmsprop']}\n\ngrid_search = GridSearchCV(estimator=ann_classifier, param_grid=params, cv=10, scoring='accuracy')\ngrid_search = grid_search.fit(x_train, y_train)\nbest_parameters = grid_search.best_params_      # will give the best parameters\nbest_accuracy = grid_search.best_score_         # will give the best accuracy score","execution_count":null,"outputs":[]},{"metadata":{"id":"6Ly-zb_YObII","outputId":"4b71b864-6179-4f6c-9161-d55ce4397de5","trusted":true},"cell_type":"code","source":"# checking the parameters obtained by the grid search mechanism\nprint(best_parameters)\nprint(best_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"id":"xZMahoNsPxvZ"},"cell_type":"markdown","source":"## **Step - 6 :** Running the ANN again based on parameters obtained above","execution_count":null},{"metadata":{"id":"YNo09WH2PAnM","outputId":"73bfbdde-db22-4d17-92e2-1033903ad782","trusted":true},"cell_type":"code","source":"# defining the layers\nann_classifier2 = Sequential()\nann_classifier2.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11))\nann_classifier2.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\nann_classifier2.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\nann_classifier2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nann_classifier2.fit(x_train, y_train, batch_size=25, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"id":"AAISbPaGP7nM","trusted":true},"cell_type":"code","source":"# predicting the result\ny_pred2 = ann_classifier2.predict(x_test)\ny_pred2 = y_pred2 > 0.5","execution_count":null,"outputs":[]},{"metadata":{"id":"plGVfrWcQNWp","outputId":"2c5185ba-ba60-4fc9-ed8e-40885ca4394a","trusted":true},"cell_type":"code","source":"print('The accuracy obtained after tuning the ANN is', round((accuracy_score(y_test, y_pred2) * 100), 2), '%')","execution_count":null,"outputs":[]},{"metadata":{"id":"x6NdlK9YFgue","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}