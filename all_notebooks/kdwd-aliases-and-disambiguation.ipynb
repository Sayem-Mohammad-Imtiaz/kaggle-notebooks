{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kensho Derived Wikimedia Dataset - Entity Aliases and Disambiguation Candidates with Anchor Link Statistics\n\nLet's see how we can use the link annotated text of the KDWD to calculate aliases for entities in Wikipedia as well as candidate disambiguation targets from text input.  The first problem (entity aliases) asks, \"What text spans are typically used to refer to a Wikipedia page?\".  The second (disambiguation candidates) asks, \"What entities are typically refered to by a text span?\"    "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from collections import Counter\nimport json\nimport os\nimport re\nimport subprocess\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\nsns.set_context('talk')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check the input directory to see what files we have access to."},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All of the KDWD files have one \"thing\" per line. We'll hard code the number of lines in the files we're going to use so we can have nice progress bars when streaming through them.  We will also define a simple text normalizer function. "},{"metadata":{"trusted":true},"cell_type":"code","source":"MIN_VIEWS = 5\nMIN_ANCHOR_TARGET_COUNT = 2\nNUM_KLAT_LINES = 5_343_564\nNUM_PAGE_LINES = 5_362_174\nkdwd_path = os.path.join(\"/kaggle/input\", \"kensho-derived-wikimedia-data\")\n\ndef text_normalizer(text):                              \n    \"\"\"Return text after stripping external whitespace and lower casing.\"\"\"   \n    return text.strip().lower()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Collect (anchor text, target page) statistics from link annotated text\nHere we create a class for iterating over lines in the link annotated text file and count occurrences of (anchor text, target page) tuples.  The [anchor text](https://en.wikipedia.org/wiki/Anchor_text) of a link is the visible, clickable text that is usually highlighted blue.  The target page is the page you land on after clicking the link.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"class KdwdLinkAnnotatedText:\n    def __init__(self, file_path):\n        self.file_path = file_path\n    def __iter__(self):\n        with open(self.file_path) as fp:\n            for line in fp:\n                yield json.loads(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = os.path.join(kdwd_path, \"link_annotated_text.jsonl\")\nklat = KdwdLinkAnnotatedText(file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anchor_target_counts = Counter()\nfor page in tqdm(\n    klat, \n    total=NUM_KLAT_LINES, \n    desc='calculating anchor-target counts'\n):\n    for section in page['sections']:\n        spans = [\n            (offset, offset + length) for offset, length in \n            zip(section['link_offsets'], section['link_lengths'])]\n        anchor_texts = [section['text'][ii:ff] for ii,ff in spans]\n        keys = [\n            (anchor_text, target_page_id) for anchor_text, target_page_id in \n            zip(anchor_texts, section['target_page_ids'])]\n        anchor_target_counts.update(keys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df = pd.DataFrame([\n    (row[0][0], row[0][1], row[1]) for row in anchor_target_counts.most_common()],\n    columns=['anchor_text', 'target_page_id', 'anchor_target_count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalize and re-group anchor text\nHere we apply a simple text normalization function to the anchor texts and merge those that normalize to the same string.  For example \"Chicago \" and \"chicago\" will be the same after normalization. "},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df[\"normalized_anchor_text\"] = at_count_df[\"anchor_text\"].apply(text_normalizer)\nat_count_df = at_count_df.loc[at_count_df['normalized_anchor_text'].str.len() > 0, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df = (                                               \n    at_count_df.                                              \n    groupby([\"normalized_anchor_text\", \"target_page_id\"])[\"anchor_target_count\"].   \n    sum().                                                               \n    to_frame(\"anchor_target_count\").\n    sort_values('anchor_target_count', ascending=False).\n    reset_index()                                                        \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that normalization and re-grouping took us from 12,128,173 to 11,405,840 rows"},{"metadata":{},"cell_type":"markdown","source":"# Anchor target count distribution\nLets examine the distribution of (anchor text, target page) tuples."},{"metadata":{},"cell_type":"markdown","source":"## Zipf style plot \n\nBelow we plot tuple frequency (the number of times a tuple occurs) vs rank (rank order when sorted by count).  This is a [Zipfian](https://en.wikipedia.org/wiki/Zipf%27s_law) plot but we use the (anchor text, target page) tuples as opppsed to words.  Note that in this plot the most frequently occuring tuples are on the left.  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"num_rows = at_count_df.shape[0]\nii_rows_logs = np.linspace(0, np.log10(num_rows-1), 30)\nii_rows = [int(el) for el in 10**ii_rows_logs]\nrows = at_count_df.iloc[ii_rows, :]\nindexs = np.log10(rows.index.values)\ncounts = np.log10(rows['anchor_target_count'].values + 1)\n\nfig, ax = plt.subplots(figsize=(12,8))\nax.scatter(indexs, counts)\nax.set_xlabel('log10 (anchor text, target page) rank')\nax.set_ylabel('log10 count')\nax.set_title('Zipf style plot for (anchor text, target page) tuples');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of Counts\nBelow we plot a straightforward histogram of the (anchor text, target page) counts.  Note that in this plot the most frequently occuring tuples are on the right. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"atc = at_count_df['anchor_target_count'].values\nlogatc = np.log10(atc)\n\nfig, ax = plt.subplots(figsize=(12,8))\npatches = ax.hist(logatc, log=True, bins=30)\nax.set_xlabel('log10 (anchor text, target page) count')\nax.set_ylabel('log10 count')\nax.set_title('Distribution of (anchor text, target page) Counts');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load page data\nNow that we have (anchor text, target page) tuple counts, lets load in page metadata about the target pages. "},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = os.path.join(kdwd_path, \"page.csv\")\npage_df = pd.read_csv(\n    file_path, \n    keep_default_na=False) # dont read the page title \"NA\" as a null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"page_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge anchor-target counts with page metadata"},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df = pd.merge(\n    at_count_df,\n    page_df,\n    how=\"inner\",\n    left_on=\"target_page_id\",\n    right_on=\"page_id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df = at_count_df.rename(columns={\n    'title': 'target_page_title',\n    'item_id': 'target_item_id',\n    'views': 'target_page_views'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df = at_count_df[[\n    \"normalized_anchor_text\",\n    \"target_page_id\",\n    \"target_item_id\",\n    \"target_page_title\",\n    \"target_page_views\",\n    \"anchor_target_count\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filter on anchor-target count and page views"},{"metadata":{"trusted":true},"cell_type":"code","source":"bool_mask_1 = at_count_df[\"anchor_target_count\"] >= MIN_ANCHOR_TARGET_COUNT\nbool_mask_2 = at_count_df[\"target_page_views\"] >= MIN_VIEWS\nbool_mask = bool_mask_1 & bool_mask_2\nat_count_df = at_count_df.loc[bool_mask, :].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculate conditional probabilities \n * P(anchor text | target page)\n * P(target page | anchor text)"},{"metadata":{"trusted":true},"cell_type":"code","source":"norm = at_count_df.groupby(\"target_page_id\")[\"anchor_target_count\"].transform(\"sum\")\nat_count_df[\"p_anchor_given_target\"] = at_count_df[\"anchor_target_count\"] / norm\nnorm = at_count_df.groupby(\"normalized_anchor_text\")[\"anchor_target_count\"].transform(\"sum\")\nat_count_df[\"p_target_given_anchor\"] = at_count_df[\"anchor_target_count\"] / norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at_count_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pagt = at_count_df['p_anchor_given_target'].values\nptga = at_count_df['p_target_given_anchor'].values\n\nfig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(16,6))\naxes[0].hist(pagt, log=True, bins=41)\naxes[0].set_xlabel('P(anchor|target)')\naxes[0].set_ylabel('log10 count')\naxes[0].set_ylim(1e3, 1e7)\n\n\naxes[1].hist(ptga, log=True, bins=41)\naxes[1].set_xlabel('P(target|anchor)')\naxes[1].set_ylim(1e3, 1e7)\n\nfig.suptitle('Distribution of conditional probabilities');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create anchor-target class to provide entity alias and text disambiguation functionality "},{"metadata":{"trusted":true},"cell_type":"code","source":"class AnchorTargetStats:\n    \n    def __init__(\n        self,\n        at_count_df,\n        text_normalizer,\n    ):\n        \"\"\"Anchor-target statistics \n        \n        Args:\n            at_count_df: (normalized_anchor_text, target_page) counts and metadata\n            text_normalizer: text cleaning function for anchor texts\n        \"\"\"\n        self._at_count_df = at_count_df\n        self.text_normalizer = text_normalizer\n\n    def get_aliases_from_page_id(self, page_id):\n        \"\"\"Return anchor strings used to refer to entity\"\"\"\n        bool_mask = self._at_count_df['target_page_id'] == page_id\n        return (\n            self._at_count_df.\n            loc[bool_mask].copy().\n            sort_values('p_anchor_given_target', ascending=False)\n        )\n    \n    def get_disambiguation_candidates_from_text(self, text):\n        \"\"\"Return candidate entities for input text\"\"\"\n        normalized_text = self.text_normalizer(text)\n        bool_mask = self._at_count_df['normalized_anchor_text'] == normalized_text\n        return (\n            self._at_count_df.\n            loc[bool_mask].copy().\n            sort_values('p_target_given_anchor', ascending=False)\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anchor_target_stats = AnchorTargetStats(at_count_df, text_normalizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Entity alias examples"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_pagt(aliases, page_title, width=0.7):\n    \"\"\"Plot P(anchor|target) for a specific page\"\"\"\n    labels = aliases['normalized_anchor_text'].values\n    probas = aliases['p_anchor_given_target'].values\n    yy = np.arange(len(labels)) \n\n    figsize = (16, len(probas) * 16/25)\n    fig, axes = plt.subplots(1, 2, figsize=figsize)\n    \n    ax = axes[0]\n    rects = ax.barh(yy, probas, width)\n    ax.set_yticks(yy)\n    ax.set_yticklabels(labels)\n    ax.set_xlabel('P(anchor text|target page)')\n    ax.set_ylabel('normalized anchor text')\n    \n    ax = axes[1]\n    log_probas = np.log10(1 + 100 * probas)\n    rects = ax.barh(yy, log_probas, width)\n    ax.set_yticks(yy)\n    ax.set_yticklabels([])\n    ax.set_xlabel('log10[1 + 100 * P(anchor text|target page)]')\n\n    fig.suptitle(f'anchor texts for target_page=\"{page_title}\"');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"page_id = 18717338   # https://en.wikipedia.org/wiki/United_States_dollar\naliases = anchor_target_stats.get_aliases_from_page_id(page_id)\naliases.head(25)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_pagt(aliases.head(25), \"United States dollar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"page_id = 651269   # https://en.wikipedia.org/wiki/S&P_Global\naliases = anchor_target_stats.get_aliases_from_page_id(page_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pagt(aliases, \"S&P Global\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"page_id = 32544339   # https://en.wikipedia.org/wiki/Hydraulic_fracturing\naliases = anchor_target_stats.get_aliases_from_page_id(page_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pagt(aliases, \"Hydraulic fracturing\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"page_id = 58900   # https://en.wikipedia.org/wiki/Unmanned_aerial_vehicle\naliases = anchor_target_stats.get_aliases_from_page_id(page_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pagt(aliases.head(25), \"Unmanned aerial vehicle\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"page_id = 25226624   # https://en.wikipedia.org/wiki/Patient_Protection_and_Affordable_Care_Act\naliases = anchor_target_stats.get_aliases_from_page_id(page_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pagt(aliases.head(25), \"Patient Protection and Affordable Care Act\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Disambiguation candidate examples"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_ptga(disambigs, anchor_text, width=0.7):\n    \"\"\"Plot P(target|anchor) for a specific page\"\"\"\n    labels = disambigs['target_page_title'].values\n    probas = disambigs['p_target_given_anchor'].values\n    yy = np.arange(len(labels)) \n\n    figsize = (16, len(probas) * 16/25)\n    fig, axes = plt.subplots(1, 2, figsize=figsize)\n    \n    ax = axes[0]\n    rects = ax.barh(yy, probas, width)\n    ax.set_yticks(yy)\n    ax.set_yticklabels(labels)\n    ax.set_xlabel('P(target page|anchor text)')\n    ax.set_ylabel('page title')\n   \n    ax = axes[1]\n    log_probas = np.log10(1 + 100 * probas)\n    rects = ax.barh(yy, log_probas, width)\n    ax.set_yticks(yy)\n    ax.set_yticklabels([])\n    ax.set_xlabel('log10[1 + 100 * P(target page|anchor text)]')\n    \n    fig.suptitle(f'page titles for anchor_text=\"{anchor_text}\"');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \"chicago\"\ndisambigs = anchor_target_stats.get_disambiguation_candidates_from_text(text)\ndisambigs.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ptga(disambigs.head(25), text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \"point\"\ndisambigs = anchor_target_stats.get_disambiguation_candidates_from_text(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ptga(disambigs.head(25), text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = 'pound'\ndisambigs = anchor_target_stats.get_disambiguation_candidates_from_text(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ptga(disambigs.head(25), text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = 'abc'\ndisambigs = anchor_target_stats.get_disambiguation_candidates_from_text(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ptga(disambigs.head(25), text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = 'aca'\ndisambigs = anchor_target_stats.get_disambiguation_candidates_from_text(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ptga(disambigs.head(25), text)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}