{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Predicting Loan Default\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Please upvote if you like this kernel.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# General Libraries\nimport pandas as pd\nimport numpy as np\nfrom itertools import product\nimport warnings\nfrom tqdm import tqdm\n\n# Plotting libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Preprocessing, modelling & evaluation\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler, label_binarize\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import r2_score,  accuracy_score, precision_recall_fscore_support\nfrom sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n\n# Language Processing\nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import word_tokenize\n\nwarnings.filterwarnings('ignore')\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\nsns.set_style('whitegrid')\n\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom scipy.stats import describe,skew","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I will be using only train data for this project\ntrain_data = pd.read_csv('/kaggle/input/lt-vehicle-loan-default-prediction/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum() #missing values only in employment type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding unique data\ntrain_data.apply(lambda x: len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Employment.Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Percentage of missing values is {0}%'.format(round(100*train_data['Employment.Type'].isnull().sum()/len(train_data),3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing null values in Employment.Type to 'unknown'\ntrain_data.fillna('unknown', inplace=True)\ntrain_data['Employment.Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum() #Great!, no missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#opening the description of file and reading it\nfile= open(\"/kaggle/input/lt-vehicle-loan-default-prediction/data_dictionary.csv\", \"r\")\nprint(file.read())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loan_default.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loan_default.value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fraction of loan default\nfraud_frac = train_data.loan_default.value_counts().min() / train_data.shape[0]\nprint(\"Fraction of loan default: {}\".format(\"%.3f\" % fraud_frac))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Percentage way of representing loan default \nprint('Percentage of loan default is {0}%'.format(round(100*train_data.loan_default.value_counts().min()/len(train_data), 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data['manufacturer_id'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data['PERFORM_CNS.SCORE'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data['PERFORM_CNS.SCORE.DESCRIPTION'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting categorical features into numerical features\ntrain_data['PERFORM_CNS.SCORE.DESCRIPTION'] = train_data['PERFORM_CNS.SCORE.DESCRIPTION'].replace({'No Bureau History Available': 0,'Not Scored: Not Enough Info available on the customer':0,'Not Scored: No Activity seen on the customer (Inactive)':0, 'Not Scored: Sufficient History Not Available':0,'Not Scored: No Updates available in last 36 months': 0,'Not Scored: Only a Guarantor': 0,'Not Scored: More than 50 active Accounts found': 0,'M-Very High Risk': 5,'L-Very High Risk': 5,'K-High Risk': 4,'J-High Risk':4,'I-Medium Risk':3,'H-Medium Risk':3,'G-Low Risk': 2,'F-Low Risk':2,'E-Low Risk': 2,'D-Very Low Risk':1,'C-Very Low Risk': 1, 'B-Very Low Risk':1,'A-Very Low Risk':1 })\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Renaming the column to make it more clear \ntrain_data.rename(columns={'PERFORM_CNS.SCORE.DESCRIPTION': 'Bureau_description'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (train_data['Employment.Type'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting up time marker\n\nd_marker= '08-11-19'\ndef days_between(d1, d2):\n    d1 = datetime.strptime(d1, \"%d-%m-%y\")\n    d2 = datetime.strptime(d2, \"%d-%m-%y\")\n    return abs((d2 - d1).days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nfrom datetime import datetime\n# age as on 1-1-2019 (in yrs)\ntrain_data['Date.of.Birth'] = train_data['Date.of.Birth'].apply(lambda x:  days_between(str(x),d_marker)/365)\n# Calculating time (in yrs) after disbursal\ntrain_data['DisbursalDate']= train_data['DisbursalDate'].apply(lambda x:  days_between(str(x),d_marker)/365)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dtypes #AVG Acc age and credit history length is still in 'object'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ntrain_data['average_act_age_in_months'] = train_data['AVERAGE.ACCT.AGE'].apply(lambda x : int(re.findall(r'\\d+',x)[0])*12 + int(re.findall(r'\\d+',x)[1]))\ntrain_data['credit_history_length_in_months'] = train_data['CREDIT.HISTORY.LENGTH'].apply(lambda x : int(re.findall(r'\\d+',x)[0])*12 + int(re.findall(r'\\d+',x)[1]))\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(columns=['AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to find correlation\nplt.figure(figsize=(50,50))\nsns.heatmap(train_data.corr(), annot=True, linewidths=3, linecolor='yellow', vmin= -1, vmax=1, cmap='bwr')\n#not so clear redrawn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_corr = train_data.corr()\ntrain_data_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(columns=['MobileNo_Avl_Flag'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot correlation\n\n# Set the default matplotlib figure size to 7x7:\nfix, ax = plt.subplots(figsize=(50,30))\n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(train_data_corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Plot the heatmap with seaborn.\n# Assign the matplotlib axis the function returns. This will let us resize the labels.\nax = sns.heatmap(train_data_corr, mask=mask, ax=ax, annot= True, cmap='bwr')\n\n# Resize the labels.\nax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=20)\nax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=20)\n\n# If you put plt.show() at the bottom, it prevents those useless printouts from matplotlib.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Visualisations**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndf = train_data[train_data['average_act_age_in_months']<175]\nsns.lineplot(x=df['average_act_age_in_months'],y=df['loan_default'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.subplots(figsize=(10, 7))\nsns.scatterplot(x='asset_cost', y='loan_default', data=train_data, alpha = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.subplots(figsize=(10, 7))\nsns.scatterplot(x='PRI.CURRENT.BALANCE', y='loan_default', data=train_data, alpha = 0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10,8))\nx = train_data['Date.of.Birth']\nplt.xlabel('Age')\nax = sns.distplot(x, bins=10, color='blue')\nax.set_title(\"Distribution of age variable\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Bureau_description'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting a donut chart for visualizing 'loan_default','Driving_flag', 'Bureau_description', 'Passport_flag'\n\nfig, ax = plt.subplots(1,5,figsize=(20,20))\ncolumns = ['loan_default','Driving_flag', 'Bureau_description', 'Passport_flag']\n\nfor i,column in enumerate(columns):\n    plt.subplot(1,5,i+1)\n    size = train_data[column].value_counts()\n    colors = ['lightblue', 'lightgreen', 'pink', 'orange', 'yellow']\n    \n\n    my_circle = plt.Circle((0, 0), 0.7, color = 'white')\n\n    plt.rcParams['figure.figsize'] = (20, 20)\n    plt.pie(size, colors = colors, shadow = True, autopct = '%.2f%%')\n    plt.title('Distribution of {}'.format(column), fontsize = 15)\n    p = plt.gcf()\n    p.gca().add_artist(my_circle)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies_Emp_t = pd.get_dummies(train_data['Employment.Type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies_Emp_t.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"By using accounts data (primary or secondary accs), let's do feature engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_engineering(df):\n    print('new_columns')\n    df.loc[:,'no_of_accts'] = df['PRI.NO.OF.ACCTS'] + df['SEC.NO.OF.ACCTS']\n    df.loc[:,'pri_inactive_accts'] = df['PRI.NO.OF.ACCTS'] - df['PRI.ACTIVE.ACCTS']\n    df.loc[:,'sec_inactive_accts'] = df['SEC.NO.OF.ACCTS'] - df['SEC.ACTIVE.ACCTS']\n    df.loc[:,'total_inactive_accts'] = df['pri_inactive_accts'] + df['sec_inactive_accts']\n    df.loc[:,'total_overdue_accts'] = df['PRI.OVERDUE.ACCTS'] + df['SEC.OVERDUE.ACCTS']\n    df.loc[:,'total_current_balance'] = df['PRI.CURRENT.BALANCE'] + df['SEC.CURRENT.BALANCE']\n    df.loc[:,'total_sanctioned_amount'] = df['PRI.SANCTIONED.AMOUNT'] + df['SEC.SANCTIONED.AMOUNT']\n    df.loc[:,'total_disbursed_amount'] = df['PRI.DISBURSED.AMOUNT'] + df['SEC.DISBURSED.AMOUNT']\n    df.loc[:,'total_installment'] = df['PRIMARY.INSTAL.AMT'] + df['SEC.INSTAL.AMT']\n    df['number_of_0'] = (df == 0).astype(int).sum(axis=1)\n    df.loc[:, 'loan_to_asset_ratio'] = df['disbursed_amount'] /df['asset_cost']\n    df.loc[:,'pri_tenure'] = (df['PRI.DISBURSED.AMOUNT']/( df['PRIMARY.INSTAL.AMT']+1)).astype(int)\n    df.loc[:,'sec_tenure'] = (df['SEC.DISBURSED.AMOUNT']/(df['SEC.INSTAL.AMT']+1)).astype(int)\n    df.loc[:,'disburse_to_sactioned_ratio'] =  np.round((df['total_disbursed_amount']+1)/(1+df['total_sanctioned_amount']),2)\n    df.loc[:,'active_to_inactive_act_ratio'] =  np.round((df['no_of_accts']+1)/(1+df['total_inactive_accts']),2)\n    df.loc[:,'bal_disburse_ratio'] = np.round((1+df['total_disbursed_amount'])/(1+df['total_current_balance']),2)\n    print('done')\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_engineering(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_subset = train_data[['disbursed_amount', 'asset_cost', 'Date.of.Birth', 'Employment.Type', 'DisbursalDate',\n                             'Aadhar_flag', 'PAN_flag', 'VoterID_flag', 'Driving_flag',\n                             'Passport_flag', 'PERFORM_CNS.SCORE', 'Bureau_description',\n                             'PRI.DISBURSED.AMOUNT', 'SEC.DISBURSED.AMOUNT',\n                             'PRIMARY.INSTAL.AMT', 'SEC.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS',\n                             'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES',\n                             'loan_default', 'average_act_age_in_months',\n                             'credit_history_length_in_months', 'no_of_accts', 'pri_inactive_accts',\n                             'sec_inactive_accts', 'total_inactive_accts', 'total_overdue_accts',\n                             'total_current_balance', 'total_sanctioned_amount',\n                             'total_disbursed_amount', 'total_installment',\n                             'loan_to_asset_ratio', 'pri_tenure', 'sec_tenure']]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_subset = pd.concat([features_subset, dummies_Emp_t], axis=1).drop('Employment.Type', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_subset.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating X and y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = X_subset['loan_default']\nX = X_subset.drop('loan_default', axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#**find columns with low variance!**\nlow_var_columns = []\nfor column in list(X.columns):\n    if np.max(X[column].value_counts(normalize=True)) > 0.99:\n        low_var_columns.append(column)\nlow_var_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max(y.mean(), 1 - y.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Baseline -- 78.3%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Classification Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr= LogisticRegression()\nprint(lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X_train, y_train)\n## Predict\npred_train_lr = lr.predict(X_train)\npred_test_lr = lr.predict(X_test)\n\n### Train data accuracy\nfrom sklearn.metrics import accuracy_score\nprint(\"Accuracy on train is:\", accuracy_score(y_train, pred_train_lr))\n      \n### Test data accuracy\nprint(\"Accuracy on test is:\", accuracy_score(y_test, pred_test_lr))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=7).fit(X)\nX = pca.fit_transform(X)\nX = pd.DataFrame(X, columns = ['p1','p2','p3','p4','p5','p6','p7'])\ntest_df = pd.DataFrame(pca.fit_transform(X_test), columns = ['p1','p2','p3','p4','p5','p6','p7'])\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure(figsize=(15,5))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\nplt.title('Dataset Explained Variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model):\n    # Checking accuracy\n    model = model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    print('accuracy_score',accuracy_score(y_test, pred))\n    print('recall_score',recall_score(y_test, pred))\n    print('f1_score',f1_score(y_test, pred))\n    print('roc_auc_score',roc_auc_score(y_test, pred))\n    # confusion matrix\n    print('confusion_matrix')\n    print(pd.DataFrame(confusion_matrix(y_test, pred)))\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model random forest\nrfc = RandomForestClassifier()\nrfc = train_model(rfc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#train model KNN\nknn = KNeighborsClassifier()\nknn = train_model(knn)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\ndtc = train_model(dtc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Naive Bayes**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nNB = GaussianNB()\n\nNB = train_model(NB)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adaboost Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import modules as necessary\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create adaboost-decision tree classifer object\nAdaboost = AdaBoostClassifier()\nAdaboost = train_model(Adaboost)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient Boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nGBM = GradientBoostingClassifier()\nGBM = train_model (GBM)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will use Random Forest model for feature importance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I define a few functions to make analysis more convenient and presentable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# udfs ----\n\n# function for creating a feature importance dataframe\ndef imp_df(column_names, importances):\n    df = pd.DataFrame({'feature': column_names,\n                       'feature_importance': importances}) \\\n           .sort_values('feature_importance', ascending = False) \\\n           .reset_index(drop = True)\n    return df\n\n# plotting a feature importance dataframe (horizontal barchart)\ndef var_imp_plot(imp_df, title):\n    imp_df.columns = ['feature', 'feature_importance']\n    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n       .set_title(title, fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Benchmark Model**\n\nI train a plain Random Forest model to have a benchmark. I set a random_state to ensure results comparability. I also use bootstrap and set oob_score = True to later use the out-of-bag error.\n\nBriefly, each tree in the random forest is trained on a different dataset, sampled with replacement from the original data. This results in around ~2/3 of distinct observations in each training set. The out-of-bag error is calculated on all the observations, but for calculating each row's error the model only considers trees which have not seen this row during training. This is similar to evaluating the model on a validation(test) set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_gs = RandomForestClassifier(n_estimators = 100,\n                           n_jobs = -1,\n                           oob_score = True,\n                           bootstrap = True,\n                           random_state = 42)\nrfc_gs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Testing Score: {:.2f}'.format(rfc_gs.score(X_train, y_train), \n                                                                                    rfc_gs.oob_score_,\n                                                                                    rfc_gs.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, there is no overfitting in the model, as it performs well on OOB sample and on the test set which is good. Let's move forward to feature importances (measured on the training set performance). Some of the approaches can also be used for testing/OOB sets, to gain further interpretability on the unseen data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Overall feature importances**\n\nBy overall feature importances I mean the ones derived at model level, i.e., saying that in a given model these features are most important in explaining the target variable.\n\n**Default Scikit-learn's feature importances**\n\nLet's start with decision trees to build some intuition. In decision trees, every node is a condition how to split values in a single feature, so that similar values of dependent variable end up in the same set after the split. The condition is based on impurity, which in case of classification problems is Gini impurity / information gain (entropy), while for regression trees its variance. So when training a tree we can compute how much each feature contributes to decreasing the weighted impurity. feature_importances_ in Scikit-Learn is based on that logic, but in case of Random Forest we are talking about averaging the decrease in impurity over trees.\n\nPros:\n\nfast calculation easy to retrieve - one command\n\nCons:\n\nbiased approach, as it has a tendency to inflate the importance of continuous features or high-cardinality categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"base_imp = imp_df(X_train.columns, rfc_gs.feature_importances_)\nbase_imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,20))\nvar_imp_plot(base_imp, 'Default feature importance (scikit-learn)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install rfpimp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom rfpimp import permutation_importances\nfrom rfpimp import plot_corr_heatmap\nviz = plot_corr_heatmap(X_train, figsize=(15,10))\nviz.view()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Permutation feature importance**\n\nThis approach directly measures feature importance by observing how random re-shuffling (thus preserving the distribution of the variable) of each predictor influences model performance.\n\nThe approach can be described in the following steps:\n\nTrain the baseline model and record the score (accuracy/R^2/any metric of importance) by passing validation set (or OOB set in case of Random Forest). This can also be done on the training set, at the cost of sacrificing information about generalisation. Re-shuffle values from one feature in the selected dataset, pass the dataset to the model again to obtain predictions and calculate the metric for this modified dataset. The feature importance is the difference between the benchmark score and the one from the modified (permuted) dataset. Repeat 2. for all feature in the dataset.\n\nPros:\n\napplicable to any model reasonably efficient reliable technique no need to retrain the model at each modification of the dataset\n\nCons:\n\nmore computationally expensive than default feature_importances permutation importance overestimates the importance of correlated predictors - Strobl et al (2008) As for the second problem with this method, I have already plotted the correlation matrix above. However, I will use a function from one of the libraries I use to visualise Spearman's correlations. The difference between standard Pearson's correlation is that this one first transforms variables into ranks and only then runs Pearson's correlation on the ranks.\n\nSpearman's correlation:\n\n-is nonparametric -does not assume linear relationship between variables -it looks for monotonic relationships.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from rfpimp import plot_corr_heatmap\nviz = plot_corr_heatmap(X_train, figsize=(15,10))\nviz.view()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def r2(rf, X_train, y_train):\n    return r2_score(y_train, rfc_gs.predict(X_train))\n\nperm_imp_rfpimp = permutation_importances(rfc_gs, X_train, y_train, r2)\nperm_imp_rfpimp.reset_index(drop = False, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,20))\nvar_imp_plot(perm_imp_rfpimp, 'Permutation feature importance (rfpimp)')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusions**\n\n Top 6 important predictors of loan default are  loan to asset ratio, disbursed amount, disbursal date, date of birth, asset cost, perform CNS score(credit score).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}