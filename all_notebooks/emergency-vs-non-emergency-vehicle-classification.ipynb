{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Problem Staement**","metadata":{}},{"cell_type":"markdown","source":"Fatalities due to traffic delays of emergency vehicles such as ambulance & fire brigade is a huge problem. In daily life, we often see that emergency vehicles face difficulty in passing through traffic. So differentiating a vehicle into an emergency and non emergency category can be an important component in traffic monitoring as well as self drive car systems as reaching on time to their destination is critical for these services.\n\nIn this problem, you will be working on classifying vehicle images as either belonging to the emergency vehicle or non-emergency vehicle category. For the same, you are provided with the train and the test dataset. Emergency vehicles usually includes police cars, ambulance and fire brigades.","metadata":{}},{"cell_type":"markdown","source":"**Data Description**\n\ntrain.zip: contains 2 csvs and 1 folder containing image data\n\ntrain.csv – [‘image_names’, ‘emergency_or_not’] contains the image name and correct class for 1646 (70%) train images\n\nimages – contains 2352 images for both train and test sets\n\ntest.csv: [‘image_names’] contains just the image names for the 706 (30%) test images\n\nsample_submission.csv: [‘image_names’,’emergency_or_not­’] contains the exact format for a valid submission (1 - For Emergency Vehicle, 0 - For Non Emergency Vehicle)","metadata":{}},{"cell_type":"markdown","source":"**Evaluation Metric**\n\nThe evaluation metric for this competition is Accuracy.","metadata":{}},{"cell_type":"code","source":"import cv2 as cv\nimport pandas as pd \nimport numpy as np \n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout,AveragePooling2D,BatchNormalization,Dense,Dropout\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications import VGG16,ResNet50,DenseNet121\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom tensorflow.keras import models\nfrom sklearn.utils import class_weight\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import *\n\nimport random\nrandom.seed(42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preparing the test and train generators**","metadata":{}},{"cell_type":"code","source":"train_datagen=ImageDataGenerator(horizontal_flip=True,preprocessing_function=preprocess_input,\n                                 width_shift_range=0.2,\n                                 zoom_range=0.2,\n                                height_shift_range=0.2,\n                                 rotation_range=30)\ntest_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n\n\ntraindir = \"../input/janatahack-computer-vision/data/train\"\ntestdir = \"../input/janatahack-computer-vision/data/val\"\n\ntrain_generator=train_datagen.flow_from_directory(\n    traindir,\n    target_size =(224,224),\n    class_mode=\"categorical\",\n    batch_size=64\n)\n\ntest_generator=test_datagen.flow_from_directory(\ntestdir,\ntarget_size =(224,224),\nclass_mode=\"categorical\",\nbatch_size=64\n)\n\nclass_weights = class_weight.compute_class_weight(\n               'balanced',\n                np.unique(train_generator.classes), \n                train_generator.classes)\n\n\n\nprint(train_generator.classes)\nprint(train_generator.class_indices)\nprint(class_weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Building the model Updating the weights trained from imagenet**\n\n**Include top = False means whether to include the fully connected layer at the top of the network, we don't require it so we have set it to False.**","metadata":{}},{"cell_type":"code","source":"resnet = DenseNet121(weights=\"imagenet\",include_top=False,input_shape=(224,224,3))\n\nmodel = models.Sequential()\nmodel.add(resnet)\nmodel.add(Flatten())\nmodel.add(Dense(2,activation=\"softmax\"))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting the model using SGD optimizer**","metadata":{}},{"cell_type":"markdown","source":"**Giving more weight to class 1 as it is highly imbalanced**","metadata":{}},{"cell_type":"code","source":"sgd = optimizers.Nadam(lr=0.00001)\ncheckpoint = ModelCheckpoint('./models/model-{epoch:03d}.h5', verbose=1, monitor='val_accuracy',save_best_only=True, mode='auto')  \nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\nhistory = model.fit_generator( train_generator,\n                              epochs=5, \n                              validation_data=test_generator,\n                              class_weight={0:1.22503962,1:0.84480874},callbacks=[checkpoint])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Saving the model**","metadata":{}},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading the model**","metadata":{}},{"cell_type":"code","source":"model=load_model(\"./model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predictions on test data**","metadata":{}},{"cell_type":"code","source":"testdir = \"../input/janatahack-computer-vision/data/test\"\n\nimages=[]\nnames=[]\nfor i in os.listdir():\n    if i[-4:]!=\".jpg\":\n        continue\n    img=cv.imread(i)\n    img=preprocess_input(img)\n    images.append(img)\n    names.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=np.array(images)\ndata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=model.predict(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Considering a cut-off threshold of 0.5 for predictions, all predictions greater than 0.5 are mapped to class 1 and all predictions lesser than 0.5 are mapped to class 0**","metadata":{}},{"cell_type":"code","source":"preds[preds>=0.5] = 1\npreds[preds<0.5] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Finding the class with the largest predicted probability using argmax**","metadata":{}},{"cell_type":"code","source":"max_pred = np.argmax(preds, axis=1)\nmax_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Subtracting 1 to get the optimum class**","metadata":{}},{"cell_type":"code","source":"final_output = abs(1 - max_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = pd.DataFrame({\"image_names\":names,\"emergency_or_not\": final_output})\nresult.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Submitting the predictions**","metadata":{}},{"cell_type":"code","source":"result.to_csv('/kaggle/working/submission.csv' , index = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}