{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndf.info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_val=[]\ncontinous_val=[]\nfor i in df.columns:\n    print('--------------')\n    print(i)\n    print('{}'.format(df[i].unique()))\n    if(len(df[i].unique())<=10):\n        categorical_val.append(i)\n    else:\n        continous_val.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 15))\n\nfor i, column in enumerate(categorical_val, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n    df[df[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, column in enumerate(continous_val, 1):\n    plt.subplot(3, 2, i)\n    df[df[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n    df[df[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ncorr=df.corr()\nsns.heatmap(corr,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_val.remove('target')\ndataset=pd.get_dummies(df,columns=categorical_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ns_sc = StandardScaler()\ncol_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\ndataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_train, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_train, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = dataset.drop('target', axis=1)\ny = dataset.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nparams={'C':np.logspace(-4,4,20),'solver':['liblinear']}\nlog_reg=LogisticRegression()\ngrid_search=GridSearchCV(log_reg,params,scoring='accuracy',n_jobs=-1,verbose=1,cv=5,iid=True)\ngrid_search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg=LogisticRegression(C=0.23357214690901212, class_weight=None, dual=False,\n                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n                   warm_start=False)\nlog_reg.fit(X_train,y_train)\n\nprint_score(log_reg, X_train, y_train, X_test, y_test, train=True)\nprint_score(log_reg, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = accuracy_score(y_test, log_reg.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, log_reg.predict(X_train)) * 100\n\ntuning_results_df = pd.DataFrame(data=[[\"Tuned Logistic Regression\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\ntrain_score = []\ntest_score = []\nneighbors = range(1, 21)\n\nfor k in neighbors:\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train, y_train)\n    train_score.append(accuracy_score(y_train, model.predict(X_train)))\n    test_score.append(accuracy_score(y_test, model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(neighbors,train_score,label='train score')\nplt.plot(neighbors,test_score,label='test score')\nplt.xticks(np.arange(1,21,1))\nplt.xlabel('neighbours')\nplt.legend()\n\nprint(f\"Maximum KNN score on the test data: {max(test_score)*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_classifier = KNeighborsClassifier(n_neighbors=19)\nknn_classifier.fit(X_train, y_train)\n\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = accuracy_score(y_test, knn_classifier.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, knn_classifier.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned K-nearest neighbors\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nparams = {\"C\":(0.1, 0.5, 1, 2, 5, 10, 20), \n          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n          \"kernel\":('linear', 'poly', 'rbf')}\nsvm=SVC(kernel='rbf',gamma=0.1,C=1)\nsvm_grid = GridSearchCV(svm, params, n_jobs=-1, cv=5, verbose=1, scoring=\"accuracy\")\nsvm_grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_model=SVC(C=5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\nsvm_model.fit(X_train,y_train)\n\nprint_score(svm_model, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_model, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = accuracy_score(y_test, svm_model.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, svm_model.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned Support Vector Machine\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nparams={'criterion':['gini','entropy'],\n       'splitter':['best','random'],\n       'max_depth':[int(i) for i in range(1,20)],\n       'min_samples_split':[2,3,4],\n       'min_samples_leaf':list(range(1,20))}\n\ntree = DecisionTreeClassifier(random_state=42)\ngrid_search_cv = GridSearchCV(tree, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3, iid=True)\ngrid_search_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_cv.best_estimator_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(criterion='gini', \n                              max_depth=3,\n                              min_samples_leaf=2, \n                              min_samples_split=2, \n                              splitter='random')\ntree.fit(X_train, y_train)\n\nprint_score(tree, X_train, y_train, X_test, y_test, train=True)\n\n\n#print_score(tree, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = accuracy_score(y_test, tree.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, tree.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned Decision Tree Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nn_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num=11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\nrandom_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n\nrand_forest = RandomForestClassifier(random_state=42)\n\nrf_random = RandomizedSearchCV(estimator=rand_forest, param_distributions=random_grid, n_iter=100, cv=3, \n                               verbose=2, random_state=42, n_jobs=-1)\n\n\nrf_random.fit(X_train, y_train)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_forest = RandomForestClassifier(bootstrap=True,\n                                     max_depth=70, \n                                     max_features='auto', \n                                     min_samples_leaf=4, \n                                     min_samples_split=10,\n                                     n_estimators=400)\nrand_forest.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(rand_forest, X_train, y_train, X_test, y_test, train=True)\nprint_score(rand_forest, X_train, y_train, X_test, y_test, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = accuracy_score(y_test, rand_forest.predict(X_test)) * 100\ntrain_score = accuracy_score(y_train, rand_forest.predict(X_train)) * 100\n\nresults_df_2 = pd.DataFrame(data=[[\"Tuned Random Forest Classifier\", train_score, test_score]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\ntuning_results_df = tuning_results_df.append(results_df_2, ignore_index=True)\ntuning_results_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}