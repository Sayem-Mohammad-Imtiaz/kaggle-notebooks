{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook aims to build a model to predict hemorrhage vs no-hemorrhage scenario in the CT-scans of head."},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline \n# If we don't do this then image will open as pop-up and not in notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image as im\n#import matplotlib as plt\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport torch\nfrom matplotlib.pyplot import imshow","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#from skimage import io\n#from skimage.viewer import ImageViewer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import wget\nimport time\nimport os\nimport copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"!ls -l ~/datasets/head-CT-hemorrhage/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class labels File"},{"metadata":{"trusted":false},"cell_type":"code","source":"labels = pd.read_csv(\"~/datasets/head-CT-hemorrhage/labels.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"labels.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"^ Note there is a space in the second column name"},{"metadata":{"trusted":false},"cell_type":"code","source":"labels.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting the data ready"},{"metadata":{"trusted":false},"cell_type":"code","source":"# PyTorch databuild libraries and modules\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, models, transforms","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's examine a sample image"},{"metadata":{"trusted":false},"cell_type":"code","source":"img1 = mpimg.imread('~/datasets/head-CT-hemorrhage/head_ct/000.png')\nimg1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"type(img1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"imgplot = plt.imshow(img1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"img2 = mpimg.imread('~/datasets/head-CT-hemorrhage/head_ct/010.png')\nimg2.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__^ Notice that img1 and img2 have different dimension. So we have to resize them to a same dimension__"},{"metadata":{"trusted":false},"cell_type":"code","source":"img1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"img1.max(), img1.min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Also, note that this image contains pixel values between 0 and 1, not between 0 to 255.__"},{"metadata":{"trusted":false},"cell_type":"code","source":"tt = (img1 * 255).astype(np.uint8)\ntt.max(), tt.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# So we force it from float to uint\ntt = im.fromarray((img1 * 255).astype(np.uint8))\ntt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"type(tt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class HeadHemorrhageDataset(Dataset):\n    \"\"\"CT scans of the head hemorrhage dataset.\"\"\"\n    \n    def __init__(self, root_dir, label_file, transform=None):\n        \"\"\"\n        Args:\n            root_dir (string): root_dir point to the directory with image data.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.root_dir = root_dir\n        self.labels = pd.read_csv(label_file)\n        self.transform = transform\n\n    def __len__(self):        \n        return len(os.listdir(self.root_dir))\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        image_id = idx\n        if len(str(idx))==1:\n            idx = '00'+str(idx)\n        if len(str(idx))==2:\n            idx = '0'+str(idx)\n                    \n        img_name = str(idx)+'.png'\n        \n        #print('Image id: '+str(image_id))\n        # columns from class_map: image_id, grapheme_root, vowel_diacritic, consonant_diacritic, grapheme\n        #img_label = labels.loc[labels['id'] == image_id, ' hemorrhage'].to_numpy()\n        img_label = self.labels.loc[image_id, ' hemorrhage']\n        #print('Image label: '+str(img_label))\n        # added to.numpy()[0] to remove index number\n                \n        img_path = os.path.join(self.root_dir,img_name)\n        image = mpimg.imread(img_path)\n        # This dataset contain a few 4-channel images towards the end. So ensure we select only first 3 channels as below\n        image = image[:,:,:3]\n        # convert from float to uint from 0 to 255\n        tt=im.fromarray((image * 255).astype(np.uint8))\n        \n        if self.transform:\n            img = self.transform(tt)\n            # sample = {'img_label': img_label, 'image': img_data}\n\n        return img, img_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Now let's create a PyTorch Dataset object with transformations\ntransformed_dataset = HeadHemorrhageDataset(root_dir='/home/ubuntu/datasets/head-CT-hemorrhage/head_ct/',\n                                            label_file='/home/ubuntu/datasets/head-CT-hemorrhage/labels.csv',\n                                           transform=transforms.Compose([\n                                               transforms.Resize((224,224)),\n                                               transforms.ToTensor(),\n                                               transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                           ]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tt = transformed_dataset.__getitem__(110)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(tt), tt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tt[0].max(), tt[0].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# to_pil = transforms.ToPILImage() \nimshow(tt[0][0], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tt = transformed_dataset.__getitem__(165)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(tt), tt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for i in range(0,199):\n    tt = transformed_dataset.__getitem__(i)\n    print(i,tt[0].shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a validation dataset from training data"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_size = int(0.8 * len(transformed_dataset))\nval_size = len(transformed_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, val_size])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(train_dataset), len(val_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_data = {}\nmodel_data['train'] = train_dataset\nmodel_data['val'] = val_dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting the dataloader ready"},{"metadata":{},"cell_type":"markdown","source":"Within a Python process, the Global Interpreter Lock (GIL) prevents true fully parallelizing Python code across threads. To avoid blocking computation code with data loading, PyTorch provides an easy switch to perform multi-process data loading by simply setting the argument num_workers to a positive integer."},{"metadata":{"trusted":false},"cell_type":"code","source":"dataloaders = {x: DataLoader(model_data[x], \n                             batch_size=10,\n                             #shuffle=True, \n                             num_workers=2)\n              for x in ['train', 'val']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(dataloaders['train'].dataset), len(dataloaders['val'].dataset), len(dataloaders['train']), len(dataloaders['val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# class_names = dataloaders['train'].dataset.\ndataset_sizes['train'], dataset_sizes['val']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(dataloaders['train'].dataset), len(dataloaders['val'].dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataloaders['train'].dataset.indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            \n            start_time = time.time()\n            \n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            \n            end_time = time.time()\n            hours, rem = divmod(end_time-start_time, 3600)\n            minutes, seconds = divmod(rem, 60)\n            print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# PyTorch libraries and modules\nfrom torch.optim import lr_scheduler\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Load a pretrained model and reset final fully connected layer.\n\nmodel_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\n# Ensuring the model is using GPU\nmodel_ft = model_ft.to(device)\n\n# As we have two classes (0 or 1) we will use cross-entropy as criterion\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Load a pretrained model and reset final fully connected layer.\n\nmodel_ft = models.resnet152(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\n# Ensuring the model is using GPU\nmodel_ft = model_ft.to(device)\n\n# As we have two classes (0 or 1) we will use cross-entropy as criterion\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is very interesting to see the validation accuracy gets stabilized at different level depending on complexity of the model. For the resnet18 the accuracy got stabilized at 95%, where as with resnet152 the accuracy got stabilized at 97.5%."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}