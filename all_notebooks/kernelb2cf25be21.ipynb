{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom sklearn import metrics\n\nfrom sklearn import neighbors\nfrom sklearn import naive_bayes\nfrom sklearn import discriminant_analysis\nfrom sklearn import linear_model\nfrom sklearn import tree\nfrom sklearn import ensemble\nfrom sklearn import svm\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 1: Visualizing the Data\nFor categorical features like \"SMOKING,\" a \"0\" indicates that the person does ***not*** belong to this class, while a \"1\" indicates that a person does belong to this class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_file = \"../input/lung-cancer-dataset-by-staceyinrobert/survey lung cancer.csv\"\nGENDER = \"GENDER\"\nAGE = \"AGE\"\nSMOKING = \"SMOKING\"\nLUNG_CANCER = \"LUNG_CANCER\"\nCHRONIC_DISEASE = \"CHRONIC DISEASE\"\ndata = pd.read_csv(data_file)\n\n# Convert the \"1/2\" categorical values to \"0/1\" and \"No/Yes\" in the lung cancer column into \"0/1\"\nfor col in data.columns:\n    if col != AGE:\n        data[col] = data[col].astype('category').cat.codes      \ndata ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate the data into people without lung cancer and those with it\nno_data = data[data[LUNG_CANCER] == 0]\nyes_data = data[data[LUNG_CANCER] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Investigation\nLet's look at a few features and how they correlate with lung cancer:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Age\nMost of the survey participants were > 40 years of age.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yes_data[AGE].plot(title=\"Age vs. lung cancer\", kind=\"hist\")\nno_data[AGE].plot(kind=\"hist\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Smoking","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yes_data[SMOKING].value_counts().plot(title=\"Smoking vs. lung cancer\", kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_data[SMOKING].value_counts().plot(title=\"Non-smoking vs. lung cancer\", kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chronic Disease","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yes_data[CHRONIC_DISEASE].value_counts().plot(title=\"Chronic disease vs. lung cancer\", kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_data[CHRONIC_DISEASE].value_counts().plot(title=\"Chronic disease vs. lung cancer\", kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2: Making Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate the data into training and validation sets\ndata_X = data.iloc[:, 0:15]\ndata_X = preprocessing.scale(data_X) # Scaling helps LinearSVC converge\ndata_y = data.iloc[:, 15]\ntrain_X, test_X, train_y, test_y = model_selection.train_test_split(data_X, data_y, test_size=0.5, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_classifiers(classifiers, train_X, train_y, test_X, test_y):\n    \"\"\"\n    Fits each classifier to the training data and runs it on the test data.\n    Prints out the training and test accuracies. \n    \"\"\"\n    results = [] # list of 3-tuples: (classifier name, train accuracy, test accuracy)\n    \n    # Baseline: a random predictor that guesses \"YES\" for each data point\n    rand_train_pred = np.full(train_y.size, 1)\n    rand_test_pred = np.full(test_y.size, 1)\n    \n    rand_train_results = (rand_train_pred == train_y)    \n    rand_train_acc = np.count_nonzero(rand_train_results) / train_y.size\n    \n    rand_test_results = (rand_test_pred == test_y)    \n    rand_test_acc = np.count_nonzero(rand_test_results) / test_y.size\n    \n    # Print out precision/recall details for test class\n    conf_mat = metrics.confusion_matrix(test_y, rand_test_pred)   \n    \n    print(f\"Random classifier\")\n    \n    # Precision rate = # true positives / (# predicted positives)\n    # Recall rate = # true positives / # positive data points\n\n    precision = conf_mat[1][1] / (conf_mat[1][1] + conf_mat[0][1])\n    recall = conf_mat[1][1] / (conf_mat[1][1] + conf_mat[1][0])\n    f1_score = 2 * ((precision * recall) / (precision + recall))\n\n    print(f\"Precision rate = {precision}\")    \n    print(f\"Recall rate = {recall}\")\n    print(f\"F1 score = {f1_score}\\n\")\n    \n    # Add random results to list\n    results.append( (\"Random Classifier\", rand_train_acc, rand_test_acc))\n    \n    for clf in classifiers:       \n        # Run classifier on train and test data\n        clf.fit(train_X, train_y)\n        train_pred = clf.predict(train_X)       \n        train_acc = metrics.accuracy_score(train_y, train_pred)\n        \n        test_pred = clf.predict(test_X)\n        test_acc = metrics.accuracy_score(test_y, test_pred)\n        \n        # Print out misclassification metrics\n        conf_mat = metrics.confusion_matrix(test_y, test_pred)   \n        precision = conf_mat[1][1] / (conf_mat[1][1] + conf_mat[0][1])\n        recall = conf_mat[1][1] / (conf_mat[1][1] + conf_mat[1][0])\n        f1_score = 2 * ((precision * recall) / (precision + recall))\n        \n        print(f\"{type(clf).__name__}\")\n        print(f\"Precision rate = {precision}\")    \n        print(f\"Recall rate = {recall}\")\n        print(f\"F1 score = {f1_score}\\n\")\n\n        # Store results\n        results.append( ((type(clf).__name__), train_acc, test_acc) )\n        \n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [\n    neighbors.KNeighborsClassifier(),\n    naive_bayes.GaussianNB(),\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    linear_model.LogisticRegression(solver=\"lbfgs\", max_iter=200),\n    tree.DecisionTreeClassifier(),\n    ensemble.AdaBoostClassifier(),\n    ensemble.RandomForestClassifier(n_estimators=100),\n    svm.LinearSVC(C=0.01, max_iter=100)\n]\nresults = run_classifiers(classifiers, train_X, train_y, test_X, test_y)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Results\nThe precision rates are all lower than the recall rates. This indicates that these models are more likely to predict positive, which is a consequence of having data skewed toward the positive class.\n\nThe Decision Tree and Random Forest Classifiers were able to classify the training data with 100% accuracy, but likely overfit the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graph the results\nclassifier_names = [clf[0] for clf in results]\ntrain_acc = [clf[1] for clf in results]\ntest_acc = [clf[2] for clf in results]\n\nfig, ax = plt.subplots(1, len(classifier_names), figsize=(18, 3), sharey=True)\nfor i in range(len(classifier_names)):\n    ax[i].scatter(classifier_names[i], train_acc[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Results\nAlthough the Decision Tree and Random Forest Classifiers had the highest training accuracies, the Linear Discriminant Analysis (LDA) classifier performed the best on the test data, with an accuracy of about 92%. It is likely that the Decision Tree and Random Forest classifiers overfit the training data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, len(classifier_names), figsize=(18, 3), sharey=True)\nfor i in range(len(classifier_names)):\n    ax[i].scatter(classifier_names[i], test_acc[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are significantly more data points belonging to class lung cancer than data points not in the class. **As a result, it seems that the predictive models were biased toward characteristics of data points in the lung cancer class.** This might explain the larger number of false positives than false negatives.\n\nFurthermore, it seems that the models do not generalize well to false negatives (i.e. when a person does not have lung cancer but the model predicts that they do). This could also be attributed to the disparity between the number data in the lung cancer class and those not in the class.\n\n**The random classifier is able to obtain an 85% accuracy just by predicting \"Yes\" on each data point, whereas the best predictive models are only able to obtain a 91% accuracy.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Number of data points belonging to class lung cancer = {yes_data.shape[0]}\")\nprint(f\"Number of data points *not* belonging to class lung cancer = {no_data.shape[0]}\")\nprint(f\"Percentage of data points belonging to class lung cancer = {yes_data.shape[0] / (data.shape[0])}\")\nprint(f\"Percentage of data points *not belonging to class lung cancer = {no_data.shape[0] / (data.shape[0])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}