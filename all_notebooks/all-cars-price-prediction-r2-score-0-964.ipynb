{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat(map(pd.read_csv, ['/kaggle/input/used-car-dataset-ford-and-mercedes/audi.csv', '/kaggle/input/used-car-dataset-ford-and-mercedes/bmw.csv','/kaggle/input/used-car-dataset-ford-and-mercedes/hyundi.csv', '/kaggle/input/used-car-dataset-ford-and-mercedes/merc.csv', '/kaggle/input/used-car-dataset-ford-and-mercedes/skoda.csv','/kaggle/input/used-car-dataset-ford-and-mercedes/toyota.csv','/kaggle/input/used-car-dataset-ford-and-mercedes/vauxhall.csv','/kaggle/input/used-car-dataset-ford-and-mercedes/ford.csv','/kaggle/input/used-car-dataset-ford-and-mercedes/vw.csv']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isnull())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the missing value in the tax column was in the tax(£) column. I have to drop replace the null values in tax with the values in tax(£). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tax=df.tax.fillna(df[['tax(£)']].max(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isnull())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We dont need the tax(£) again so we have to drop it ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['tax(£)'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,6))\nfig.add_subplot(1,2,1)\nsns.countplot(df['transmission'])\nfig.add_subplot(1,2,2)\nsns.countplot(df['fuelType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = 'year', y= 'price', data = df, kind='point', aspect=4);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"price\", y=\"transmission\", \n            data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"year\", y=\"price\", \n            data=df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = df.select_dtypes(exclude=['object'])\n\nfig = plt.figure(figsize=(20,8))\n\nfor col in range(len(num_cols.columns)):\n    fig.add_subplot(2,4,col+1)\n    sns.distplot(num_cols.iloc[:,col], hist=False, rug=True, kde_kws={'bw':0.1}, label='UV')\n    plt.xlabel(num_cols.columns[col])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,8))\n\nfor col in range(len(num_cols.columns)):\n    fig.add_subplot(2,4,col+1)\n    sns.scatterplot(x=num_cols.iloc[:,col], y=df['price'], label='MV')\n    plt.xlabel(num_cols.columns[col])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##Feature Engineering The categorical variables must be converted into something numerical. either one hot encording from sklearn or using get dummies function from pandas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cars","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = cars.drop(['price'], axis=1)\ny = cars['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nfrom math import sqrt\nfrom sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import Ridge,ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_clf=LinearRegression()\nbye_clf=BayesianRidge()\nrnd_clf = RandomForestRegressor()\nrid_clf = Ridge(alpha=2,max_iter=1000,random_state=1)\nele_clf = ElasticNet()\ngbr_clf=GradientBoostingRegressor()\nlss_clf=Lasso()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voting_clf = VotingRegressor([('lr', log_clf),('bye', bye_clf), ('rf', rnd_clf), ('rnd', rnd_clf), ('ele', ele_clf), ('gbr', gbr_clf), ('lss', lss_clf)])\nvoting_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"for clf in (log_clf, rnd_clf, rid_clf, bye_clf, voting_clf,ele_clf, gbr_clf,lss_clf):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(clf.__class__.__name__, 'r2_score', r2_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voting_clf2 = VotingRegressor([('lr', log_clf),('bye', bye_clf), ('rf', rnd_clf), ('rnd', rnd_clf), ('ele', ele_clf), ('gbr', gbr_clf),('lss', lss_clf)])\nvoting_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"for clf in (log_clf, rnd_clf, rid_clf, bye_clf,voting_clf2,ele_clf, gbr_clf,lss_clf):\n    clf.fit(X_train, y_train)\n    y_pred2 = clf.predict(X_test)\n    print(clf.__class__.__name__, 'r2_score', r2_score(y_test, y_pred2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MinMaxScaler reduced the accuracy of RandomForestRegressor which was the best model to be used in this data it reduced the r2_score from  0.964 to 0.954 but it improved the Ridge r2_score to  0.8607171252232906 and also BayesianRidge r2_score 0.8635266838140631","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler2 = StandardScaler()\nX_scaled2 = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_scaled2, y, test_size=0.15, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voting_clf3 = VotingRegressor([('lr', log_clf), ('rf', rnd_clf),('bye',bye_clf), ('rnd', rnd_clf), ('ele', ele_clf), ('gbr', gbr_clf),('lss', lss_clf)])\nvoting_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"for clf in (log_clf, rnd_clf, rid_clf, voting_clf2,ele_clf, gbr_clf,lss_clf):\n    clf.fit(X_train, y_train)\n    y_pred3 = clf.predict(X_test)\n    print(clf.__class__.__name__, 'r2_score', r2_score(y_test, y_pred3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***The result so far was without scaliing the data as it generated the best result with the RandomForestRegressor r2_score 0.964***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}