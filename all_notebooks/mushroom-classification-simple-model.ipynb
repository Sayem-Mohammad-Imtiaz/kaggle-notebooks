{"nbformat_minor":1,"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","metadata":{"_uuid":"cf2ce79f5f3819f164042140e9e915a650b1727c","_cell_guid":"0ecbd593-9fd5-4889-b924-217c764ec142"},"execution_count":null,"outputs":[]},{"source":"#Read data\ndata = pd.read_csv('../input/mushrooms.csv')\ndata.head()","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"#Convert to numpy array\ndataArray = np.array(data)\ntotal = len(dataArray)\nN = 7000","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Split into test and training sets\nX_train = dataArray[:N,1:]\ny_train = dataArray[:N,0]\nX_test = dataArray[N:,1:]\ny_test = dataArray[N:,0]","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Create a dic to convert each data point from char to int\ndicts = []\ncodes = []\ncodes.append('bcxfks')\ncodes.append('fgys')\ncodes.append('nbcgrpuewy')\ncodes.append('tf')\ncodes.append('alcyfmnps')\ncodes.append('adfn')\ncodes.append('cwd')\ncodes.append('bn')\ncodes.append('knbhgropuewy')\ncodes.append('et')\ncodes.append('bcuezr?')\ncodes.append('fyks')\ncodes.append('fyks')\ncodes.append('nbcgopewy')\ncodes.append('nbcgopewy')\ncodes.append('pu')\ncodes.append('nowy')\ncodes.append('not')\ncodes.append('ceflnpsz')\ncodes.append('knbhrouwy')\ncodes.append('acnsvy')\ncodes.append('glmpuwd')\nfor code in codes:\n    temp = {}\n    for i in range(0,len(code)):\n        temp[code[i]] = i\n    dicts.append(temp)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Number of features\nm  = X_train.shape[1]","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Training data points char->int using dict\nfor j in range(0,m):\n    for x in X_train:\n        x[j] = dicts[j][x[j]]","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Test data points char->int using dict\nfor j in range(0,m):\n    for x in X_test:\n        x[j] = dicts[j][x[j]]","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Class Labels; Posionous - 0, Edible - 1\nfor i in range(0,len(y_train)):\n    if y_train[i] == 'p':\n        y_train[i] = 0\n    else:\n        y_train[i] = 1\n        \nfor i in range(0,len(y_test)):\n    if y_test[i] == 'p':\n        y_test[i] = 0\n    else:\n        y_test[i] = 1","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Simple Model consisting of Affine and Softmax Layer, Cross Entropy Loss function thereafter \nmodel = nn.Sequential(nn.Linear(22,2),\n                     nn.Softmax())\n\ndType = torch.FloatTensor\nmodel.type(dType)\nlossFunc = nn.CrossEntropyLoss().type(dType)\n#Optimized using Adam\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-1)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Converting to tensor objects (Training data)\nX_train_torch = torch.FloatTensor(X_train)\nX_train_var = torch.autograd.Variable(X_train_torch)\ny_train_trch = torch.LongTensor(y_train)\ny_train_var = torch.autograd.Variable(y_train_trch)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"#Train\nepochs = 500\nfor epoch in range(0,epochs):\n    \n    optimizer.zero_grad()\n    forward = model(X_train_var)\n    loss = lossFunc(forward,y_train_var)\n    loss.backward()\n    optimizer.step()\n    \n    print(\"epoch \",epoch, \" loss = \", loss.data[0])","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"#Training data predictions\nout_train = model(X_train_var)\n_, pred_train = torch.max(out_train.data,1)\n#print(pred_train.size(0))\n#print(pred_train)\ncorrect = (pred_train == y_train_trch).sum()\nprint(\"Total correct  = \",correct,\"Train Accuracy = \", correct/len(X_train) )","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"#Converting to tensor objects (Test Data)\nX_test_torch = torch.FloatTensor(X_test)\ny_test_torch = torch.LongTensor(y_test)\nX_test_var = torch.autograd.Variable(X_test_torch)","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]},{"source":"out_test = model(X_test_var)\n_, pred_test = torch.max(out_test.data,1)\ncorrect = (pred_test == y_test_torch).sum()\nprint(\"Total Correct = \",correct,\"Test Accuracy = \", correct/len(y_test))","cell_type":"code","metadata":{},"execution_count":null,"outputs":[]},{"source":"","cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"outputs":[]}],"nbformat":4}