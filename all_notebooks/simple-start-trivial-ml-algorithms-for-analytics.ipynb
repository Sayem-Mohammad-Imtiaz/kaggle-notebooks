{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Starter notebook for: https://www.kaggle.com/podsyp/how-to-do-product-analytics"},{"metadata":{},"cell_type":"markdown","source":"# Business goal:\n- Perform data analysis.\n- Identify predictors affecting sales.\n- Offer a binary classification model for customers / buyers.\n- Segment customers."},{"metadata":{},"cell_type":"markdown","source":"### Import libraries, configure pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport datetime\n\nimport pandas_summary as ps\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest, f_classif, chi2\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom xgboost.sklearn import XGBClassifier\nfrom xgboost import plot_importance\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('use_inf_as_na', True)\nrandom_state = 17","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Legend:\nWe are an online store of sports goods: clothing, shoes, accessories and sports nutrition. On the main page of the store we show users banners in order to stimulate their sales. Now one of 5 banners is randomly displayed there. Each banner advertises a specific product or the entire company. Our marketers believe that the experience with banners can vary by segment, and their effectiveness may depend on the characteristics of user behavior.\nThe manager of the company had an offer from partners to sell this place for a banner and advertise another service there (payment is assumed according to the CPC model).\nHelp the manager make a decision."},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.read_csv('/kaggle/input/how-to-do-product-analytics/product.csv', sep=',')\nfull_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Description:\nYou have information about which banner appeared to the user, whether he clicked on it, as well as information about user purchases.\n* order_id - unique purchase number (NA for banner clicks and impressions)\n* user_id - unique identifier of the client\n* page_id - unique page number for event bundle (NA for purchases)\n* product - banner / purchase product\n* site_version - version of the site (mobile or desktop)\n* time - time of the action\n* title - type of event (show, click or purchase)\n* target - target class"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Предобратка to_datetime для разведки"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df['time'] = full_df['time'].apply(pd.to_datetime)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = ps.DataFrameSummary(full_df)\nprint('categoricals: ', dfs.categoricals.tolist())\nprint('numerics: ', dfs.numerics.tolist())\ndfs.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check NaN."},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* is_Buy - бинарная фича на основе fillna для page_id (1 для покупок)\n* +Доп проверка на качество данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ('order_id', 'page_id'):\n    full_df[i] = full_df[i].fillna(0).apply(lambda x: x if x == 0 else 1)\n    print(full_df.groupby([i]).size().sort_values(ascending=False).head(2))\n    print('\\n')\nprint(full_df.groupby(['title']).size().sort_values(ascending=False).head())\nsns.countplot('title', data=full_df)\nplt.show();\nfull_df.drop(['order_id', 'page_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate 2 binary features\n* is_banner_click - 1, if ever a client clicked on a banner\n* is_first_conversion - 1, if the first is a client visit"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = full_df.assign(num_conversion=full_df.groupby(['user_id'])['time'].rank(method='first', ascending=True))\nsns.countplot('num_conversion', data=full_df)\nplt.show();\nfull_df['IsBanner_click'] = full_df['title'].apply(lambda x: 1 if x == 'banner_click' else 0)\nfull_df['IsBanner_click'] = full_df.groupby('user_id').IsBanner_click.transform(np.mean).apply(lambda x: 0 if x == 0 else 1)\nfull_df['IsFirst_conversion'] = full_df['num_conversion'].apply(lambda x: 1 if x == 1 else 0)\nfull_df.drop(['user_id', 'title'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Working with dates\n- Seasonality (binary time_IsMorning, time_IsDaylight, time_IsEvening, time_IsNight)\n- Time of day (binary time_IsWinter)\n- Hour time_Hour\n- Day number in the month time_Day\n- Day number in the week time_Week_Day\n- Year * 100 + Month time_Year_Month"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df['time_IsMorning'] = full_df['time'].apply(lambda ts: 1 if (ts.hour >= 6) and (ts.hour < 10) else 0)\nfull_df['time_IsDaylight'] = full_df['time'].apply(lambda ts: 1 if (ts.hour >= 10) and (ts.hour < 16) else 0)\nfull_df['time_IsEvening'] = full_df['time'].apply(lambda ts: 1 if (ts.hour >= 16) and (ts.hour < 23) else 0)\nfull_df['time_Hour'] = full_df['time'].apply(lambda ts: ts.hour)\nfull_df['time_Day'] = full_df['time'].apply(lambda ts: ts.day)\nfull_df['time_Week_Day'] = full_df['time'].apply(lambda ts: datetime.date(ts.year, ts.month, ts.day).weekday() + 1)\nfull_df['time_Year_Month'] = full_df['time'].apply(lambda ts: ts.year * 100 + ts.month)\nfull_df.drop(['time'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['product', 'site_version']:\n    print('\\n')\n    print(full_df.groupby([i]).size().sort_values(ascending=False).head())\n    sns.countplot(i, data=full_df)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df['SV_IsMobile'] = full_df['site_version'].map({'desktop': 0, 'mobile': 1})\nfull_df.drop(['site_version'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Applying one hot encoding to the 'product' attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.get_dummies(full_df, columns=['product'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = ps.DataFrameSummary(full_df)\nprint('categoricals: ', dfs.categoricals.tolist())\nprint('numerics: ', dfs.numerics.tolist())\ndfs.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Great imbalance of the classes of the vector y "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot('target', data=full_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Manual random-balancing of classes + Selection of matrix X and vector y"},{"metadata":{"trusted":true},"cell_type":"code","source":"access_df = full_df.drop(['product_clothes', 'product_company', 'product_sneakers', 'product_sports_nutrition'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of data points in the minority class\nnumber_records_fraud = len(full_df[full_df.target == 1])\nfraud_indices = np.array(full_df[full_df.target == 1].index)\n\n# Picking the indices of the normal classes\nnormal_indices = full_df[full_df.target == 0].index\n\n# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\nrandom_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\n# Appending the 2 indices\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n\n# Under sample dataset\nunder_sample_data = full_df.iloc[under_sample_indices,:]\n\nX = under_sample_data.ix[:, under_sample_data.columns != 'target']\ny = under_sample_data.ix[:, under_sample_data.columns == 'target']\n\n# Showing ratio\nprint(\"Perc. of banner click or show result: \", len(under_sample_data[under_sample_data.target == 0])/len(under_sample_data))\nprint(\"Perc. of order result: \", len(under_sample_data[under_sample_data.target == 1])/len(under_sample_data))\nprint(\"Total number of transactions in resampled data: \", len(under_sample_data))\nsns.countplot('target', data=y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Data is balanced and ready for normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalization of matrix X"},{"metadata":{"trusted":true},"cell_type":"code","source":"stand_X = pd.DataFrame(preprocessing.scale(X), columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Python class for quick analysis of a feature set.\n\n- withdrawal of the rating of signs on simple algorithms \"out of the box\" + average rating\n- test of the current feature set on simple models without selection of hyperparameters and regularization\n\n#### testing of simple models (including KNN) I do under the need to show precedents - it is important for business"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Feat_Importance:\n    df = None\n    columns = None\n    random_state = None\n    ranks = {}\n        \n    def __init__(self, X, y, columns, random_state=56, show_dict='N', show_plot='N'):\n        self.X = X\n        self.y = y\n        self.names = columns\n        self.random_state = random_state\n        self.show_dict = show_dict\n        self.show_plot = show_plot\n        \n    def __rank_to_dict(self, ranks, names, order=1):\n        minmax = MinMaxScaler()\n        ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n        ranks = map(lambda x: round(x, 2), ranks)\n        return dict(zip(names, ranks))\n    \n    def feat_stats(self):\n        self.ranks = {}\n        self.get_KBest()\n        self.get_LogReg()\n        self.get_XGBC()\n        \n    def get_KBest(self):\n        selector = SelectKBest(f_classif)\n        selector.fit(self.X, self.y)\n        scores = selector.scores_\n        scores = pd.Series(scores).fillna(0)\n        self.ranks[\"KBest\"] = self.__rank_to_dict(scores, self.names)\n        if self.show_dict == 'Y': \n            print('===== KBest dict =====\\n', self.ranks[\"KBest\"], '\\n\\n\\n')\n        if self.show_plot == 'Y': \n            print('===== KBest plot =====\\n', self.X.shape)\n            plt.bar(range(len(self.names)), -np.log10(selector.pvalues_))\n            plt.xticks(range(len(self.names)), self.names, rotation='vertical');\n            \n    def get_LogReg(self):\n        model_LogRegRidge = LogisticRegression(penalty='l2', C=0.15, \n                                               random_state=self.random_state, solver='liblinear', \n                                               n_jobs=-1)\n        model_LogRegRidge.fit(self.X, self.y)\n        self.ranks[\"LogRegRidge\"] = self.__rank_to_dict(list(map(float, \n                                    model_LogRegRidge.coef_.reshape(len(self.names), -1))),\n                                    self.names, order=1)\n        \n        if self.show_dict == 'Y': \n            print('===== LogRegRidge dict =====\\n', self.ranks[\"LogRegRidge\"], '\\n\\n\\n')\n        if self.show_plot == 'Y':\n            print('===== LogRegRidge plot =====\\n', self.X.shape)\n            listsRidge = sorted(self.ranks[\"LogRegRidge\"].items(), key=operator.itemgetter(1))\n            dfRidge = pd.DataFrame(np.array(listsRidge).reshape(len(listsRidge), 2),\n                       columns=['Features', 'Ranks']).sort_values('Ranks')\n            dfRidge['Ranks'] = dfRidge['Ranks'].astype(float)\n            dfRidge.plot.bar(x='Features', y='Ranks', color='blue')\n            plt.xticks(rotation=90)\n    \n    def get_XGBC(self):\n        model_XGBC = XGBClassifier(objective='binary:logistic',\n                           max_depth=7, min_child_weight=5,\n                           gamma=0, random_state=random_state, n_jobs=-1,\n                           learning_rate=0.1, n_estimators=200)\n        model_XGBC.fit(self.X, self.y)\n        self.ranks[\"XGBC\"] = self.__rank_to_dict(model_XGBC.feature_importances_, self.names)\n        if self.show_dict == 'Y': \n            print('===== XGBClassifier dict =====\\n', self.ranks[\"XGBC\"], '\\n\\n\\n')\n        if self.show_plot == 'Y':\n            print('===== XGBClassifier plot =====\\n', self.X.shape)\n            plot_importance(model_XGBC)\n            plt.show()\n    \n    def stats_df(self):\n        r = {}\n        for name in self.names:\n            r[name] = round(np.mean([self.ranks[method][name] for method in self.ranks.keys()]), 2)\n        methods = sorted(self.ranks.keys())\n        self.ranks['Mean'] = r\n        methods.append('Mean')\n\n        row_index, AllFeatures_columns = 0, ['Feature', 'Scores']\n        AllFeats = pd.DataFrame(columns=AllFeatures_columns)\n        for name in self.names:\n            AllFeats.loc[row_index, 'Feature'] = name\n            AllFeats.loc[row_index, 'Scores'] = [self.ranks[method][name] for method in methods]\n            row_index += 1\n        AllFeatures_only = pd.DataFrame(AllFeats.Scores.tolist(), )\n        AllFeatures_only.rename(columns={0: 'KBest', 1: 'LogRegRidge', 2: 'XGB Classifier', 3: 'Mean'}, inplace=True)\n        AllFeatures_only = AllFeatures_only[['KBest', 'LogRegRidge', 'XGB Classifier', 'Mean']]\n        AllFeatures_compare = AllFeats.join(AllFeatures_only).drop(['Scores'], axis=1)\n        return AllFeatures_compare\n    \n    def simple_test(self):\n        x_train, x_valid, y_train, y_valid = train_test_split(self.X, self.y, test_size=0.3, random_state=random_state+37)\n        mods = ('BernoulliNB', 'KNeighborsClassifier', 'RandomForestClassifier')\n        for nu, model in enumerate([BernoulliNB(), KNeighborsClassifier(n_jobs=-1), \n                      RandomForestClassifier(n_jobs=-1)]):\n            model.fit(x_train, y_train)\n            predicted = model.predict(x_valid)\n            print(mods[nu])\n            print('------ accuracy ------\\n', metrics.accuracy_score(y_valid, predicted))\n            #print('------ confusion_matrix ------\\n', metrics.confusion_matrix(y_valid, predicted))\n            print('------ roc_auc_score ------\\n', metrics.roc_auc_score(y_valid, predicted))\n            print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi = Feat_Importance(stand_X, y, stand_X.columns)\nfi.feat_stats()\nfi_df = fi.stats_df()\ndisplay(fi_df.sort_values(by=['Mean'], ascending=[False]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Remove obviously weak signs by the condition 'Mean'> 0.21"},{"metadata":{"trusted":true},"cell_type":"code","source":"stand_X = stand_X[fi_df[fi_df['Mean'] > 0.21].Feature.values]\nstand_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi = Feat_Importance(stand_X, y, stand_X.columns)\nfi.feat_stats()\nfi_df = fi.stats_df()\ndisplay(fi_df.sort_values(by=['Mean'], ascending=[False]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi.simple_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nsns.heatmap(stand_X.corr(), xticklabels=stand_X.columns, yticklabels=stand_X.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seaborn correlation matrix\n\nThe correlation matrix looks critical.\n- After analyzing the correlation of the pandas dataframe object and the table of the influence of attributes on the model, remove features with high correlation values."},{"metadata":{"trusted":true},"cell_type":"code","source":"stand_X = stand_X.drop(['IsFirst_conversion'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There is no critical correlation in the current feature set."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nsns.heatmap(stand_X.corr(), xticklabels=stand_X.columns, yticklabels=stand_X.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test the current feature set."},{"metadata":{"trusted":true},"cell_type":"code","source":"fi = Feat_Importance(stand_X, y, stand_X.columns)\nfi.feat_stats()\nfi_df = fi.stats_df()\ndisplay(fi_df.sort_values(by=['Mean'], ascending=[False]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi.simple_test()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split into test and validation samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(stand_X, y, test_size=0.3, random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### Test the current set of features on effective models with the selection of hyperparameters."},{"metadata":{},"cell_type":"markdown","source":"* Random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"r_for = RandomForestClassifier()\nprint(r_for)\nfor_params = {'max_depth': np.arange(4, 10), 'max_features': np.arange(0.25, 0.5, 1), 'n_estimators': [30, 50, 60]}\nfor_grid = GridSearchCV(r_for, for_params, cv=2, n_jobs=-1)\nfor_grid.fit(x_train, y_train)\nprint('best score / best params: ', for_grid.best_score_, for_grid.best_params_)\ny_pred = for_grid.predict(x_valid)\nprint('classification_report: \\n', metrics.classification_report(y_pred, y_valid))\nprint('accuracy_score: ', metrics.accuracy_score(y_pred, y_valid))\nprint('roc_auc_score: ', metrics.roc_auc_score(y_pred, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_r = LogisticRegression()\ngrid_values = {'penalty': ['l2'], 'C': [0.0001, 0.001, 0.01, 0.1]}\nlr_grid = GridSearchCV(log_r, param_grid=grid_values, cv=2, n_jobs=-1)\nlr_grid.fit(x_train, y_train)\nprint('best score / best params: ', lr_grid.best_score_, lr_grid.best_params_)\ny_pred = lr_grid.predict(x_valid)\nprint('classification_report: \\n', metrics.classification_report(y_pred, y_valid))\nprint('accuracy_score: ', metrics.accuracy_score(y_pred, y_valid))\nprint('roc_auc_score: ', metrics.roc_auc_score(y_pred, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Gradient boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_m = XGBClassifier()\nxgb_params = [\n    {\"n_estimators\": [300, 350],\n     \"max_depth\": [3,  5],\n     \"learning_rate\": [0.01, 0.05]}\n]\nxgb_grid = GridSearchCV(xgb_m, xgb_params, cv=2, refit=True, verbose=1, n_jobs=-1)\nxgb_grid.fit(x_train, y_train)\nprint('best score / best params: ', xgb_grid.best_score_, xgb_grid.best_params_)\ny_pred = xgb_grid.predict(x_valid)\nprint('classification_report: \\n', metrics.classification_report(y_pred, y_valid))\nprint('accuracy_score: ', metrics.accuracy_score(y_pred, y_valid))\nprint('roc_auc_score: ', metrics.roc_auc_score(y_pred, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusions\n\nEnhanced sample clustering. The goal is to blur product_company in one cluster."},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_stand_df = stand_X\ncluster_stand_df['target'] = preprocessing.scale(y)\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=3, random_state=random_state).fit(cluster_stand_df)\nunique, counts = np.unique(kmeans.labels_, return_counts=True)\nprint(np.asarray((unique, counts)).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_df = X[[i for i in stand_X.columns if i != 'target']]\ncluster_df['target'] = y\ncluster_df['Cluster'] = kmeans.labels_ # 497444","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_df['Cluster'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 3 - customer share 23.53%. The share of “buying” customers is 0.69. Customers buying product_clothes and most often clicking on the banner.\n* Cluster 1 - customer share 32.85%. The proportion of \"buying\" customers is 0.578. The most conversions. The largest share of desktop users.\n* Cluster 0 - customer share 43.61%. The share of \"buying\" customers is 0.315. Customers in the categories product_accessories, product_company, product_sports_nutrition. Least click and order products. The target audience. The largest share of \"mobile\" users. Perhaps the banner is not very attractive in the mobile version."},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_df.groupby('Cluster').mean().sort_values(by=['target'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.violinplot(x='target', y='Cluster',\n                         data=cluster_df, height=4, aspect=.7)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(fi_df.sort_values(by=['Mean'], ascending=[False]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.violinplot(x='target', y='num_conversion',\n                         data=cluster_df[cluster_df['num_conversion'] <= 10], height=4, aspect=.7)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- IsBanner_click - people who have ever clicked on a banner (without an order) are more likely to make a purchase.\n- time_IsMorning - in the morning, shopping activity is low."},{"metadata":{"trusted":true},"cell_type":"code","source":"feat = [f for f in cluster_df.columns if 'Is' in f]\nfor i in feat:\n    print(i)\n    plt.figure()\n    tmp = cluster_df[cluster_df[i] == 1]\n    tmp['target'].hist(figsize=(6, 3), bins=2, color = 'red')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most significant features:\n- time_Day - buy more at the end of the month.\n- time_Hour - buy more at night.\n- time_Year_Month - Shopping activity increases in the months with fewer weekends and holidays."},{"metadata":{"trusted":true},"cell_type":"code","source":"feat = [f for f in cluster_df.columns if 'time' in f]\nfor i in feat:\n    print(i)\n    plt.figure()\n    cluster_df[cluster_df['target'] == 1][i].hist(figsize=(5, 3), alpha=0.4, color = 'green')\n    cluster_df[cluster_df['target'] == 0][i].hist(figsize=(5, 3), alpha=0.4, color = 'red')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- product_clothes - product_clothes is most actively sold, the largest number of banner impressions.\n- product_sneakers - 2nd product in terms of popularity and sales.\n- product_accessories and product_sports_nutrition need to research sales figures, add features."},{"metadata":{"trusted":true},"cell_type":"code","source":"feat = [f for f in cluster_df.columns if 'product' in f and '_company' not in f]\nfor i in feat:\n    print(i)\n    plt.figure()\n    tmp = cluster_df[cluster_df[i] == 1]\n    tmp['target'].hist(figsize=(6, 3), bins=3)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}