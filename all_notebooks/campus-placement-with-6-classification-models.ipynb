{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Salary column has 67 null values. Using salary mean to fill the null values.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['salary'].fillna(df['salary'].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting data in to two sets categorical and numerical for EDA.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_feat = df.select_dtypes(include=['object'])\nnumerical_feat = df.select_dtypes(include=['float64'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Numerical Feature Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(numerical_feat, x='ssc_p', y='hsc_p', color='degree_p', size = 'etest_p', hover_data=['mba_p'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(numerical_feat, x='ssc_p', color=df['status'], height=500, width=600, title='SSC Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='hsc_p', color=df['status'], height=500, width=600, title='HSC Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='degree_p', color=df['status'], height=500, width=600, title='Degree Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='etest_p', color=df['status'], height=500, width=600, title='Employability test Percentage VS Status',trendline=\"ols\")\nfig.show()\n\nfig = px.scatter(numerical_feat, x='mba_p', color=df['status'], height=500, width=600, title='MBA Percentage VS Status',trendline=\"ols\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(x = numerical_feat['salary'].value_counts().index, y=numerical_feat['salary'].value_counts())\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Univariate Analysis Of Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors=['mediumturquoise','lightgreen','seagreen','palegreen','olive']\n\nfor col in categorical_feat:\n    plt.figure()\n    categorical_feat[col].value_counts().plot.pie(wedgeprops={\"edgecolor\":\"k\",'linewidth': 2},textprops={'color':'k'}, pctdistance=0.7, autopct='%.2f%%',\n                                                 figsize=(5,5), labels=None, subplots=True, colors=colors)\n    plt.title('{} Distribution'.format(col), fontsize=17, ha='right')\n    plt.legend(labels=categorical_feat[col].value_counts().index, loc='best', bbox_to_anchor=(1, 0.25, 0.5, 0.5))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_feat = categorical_feat.drop('status',1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bivariate Analysis Of Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical_feat:\n    sns.countplot(x = categorical_feat[col], hue=df['status'], palette =['salmon','lightblue'])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Label encoding to convert categorical values into numerical values as many algorithms can't handle categorical values.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n \ngender = le.fit_transform(df['gender'])\nssc_b = le.fit_transform(df['ssc_b'])\nhsc_b = le.fit_transform(df['hsc_b'])\ndegree_t = le.fit_transform(df['degree_t'])\nworkex = le.fit_transform(df['workex'])\nspecialisation = le.fit_transform(df['specialisation'])\nstatus = le.fit_transform(df['status'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# droping columns\n\ndf.drop(['sl_no','gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex','specialisation','status'],1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Scaling\nI will use Standard Scaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n#df[['ssc_p','hsc_p','degree_p','etest_p','mba_p','salary']] = StandardScaler().fit_transform(df[['ssc_p','hsc_p','degree_p','etest_p','mba_p','salary']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Appending Label encoded columns to dataframe\n\ndf['gender'] = gender\ndf['ssc_b'] = ssc_b\ndf['hsc_b'] = hsc_b\ndf['degree_t'] = degree_t\ndf['workex'] = workex\ndf['specialisation'] = specialisation\ndf['status'] = status\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation with Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nfig.suptitle('Correlation between Status and features',fontsize=20)\nax=sns.heatmap(df.corr()[[\"status\"]].sort_values(\"status\"),vmax=1, vmin=-1, cmap=\"YlGnBu\", annot=True, ax=ax);\nax.invert_yaxis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = df.iloc[:,:-1]\ny = df.iloc[:,-1]\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracies = dict()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Models"},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nreg = LogisticRegression()\nreg.fit(x_train, y_train)\n\n#Make prediction\ny_pred = reg.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracies['Logistic Regression'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: '+str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Confusion Matrix Of Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(reg, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.PuRd, normalize='true')\nplt.title('Confusion Matrix Of Campus Placement')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Kernel SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(x_train, y_train)\n\ny_pred = classifier.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracies['Kernel SVM'] = accuracy_score(y_test, y_pred)\nprint('Accuray is: '+str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix Of Kernel SVM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(classifier, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.Blues, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(x_train, y_train)\n\ny_pred = gnb.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracies['Naive Bayes'] = accuracy_score(y_test, y_pred)\nprint('Accuray is: '+str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix Of Naive Bayes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(gnb, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.Purples, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNeighbors Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\n\ny_pred = knn.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccuracies['KNeighbors Classifier'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: '+str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix Of KNeighbors Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(knn, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.pink, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier(criterion = 'entropy', random_state= 0)\ndtc.fit(x_train, y_train)\n\n#Make Prediction\ny_pred = classifier.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracies['Decision Tree Classification'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Confusion Matrix Of Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(dtc, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.bone, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators= 2, random_state= 0)\nrfc.fit(x_train, y_train)\n\n#Make Prediction\ny_pred = classifier.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracies['Random Tree Classification'] = accuracy_score(y_test, y_pred)\nprint('Accuracy is: ' + str(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confusion Matrix** Of Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(rfc, x_test, y_test, display_labels=['Placed','Not Placed'], cmap=plt.cm.copper, normalize='true')\nplt.title('Confusion Matrix of Campus Placement')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_df = pd.DataFrame(list(accuracies.items()), columns=['Model Name','Accuracy Score'])\naccuracy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(8, 6))\nsns.set_color_codes('pastel')\nsns.barplot(y='Model Name', x='Accuracy Score', data=accuracy_df, color='pink')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}