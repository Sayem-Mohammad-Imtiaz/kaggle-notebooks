{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Introduction</h1>\n<p>Welcome! In this notebook i'm going to analyze different asteroids data and implement a Machine Learning Classfier to predict the hazard for different asteroids</p>\n<h3>My main objectives on this project are:</h3>   \n<ul>\n    <li>Applying exploratory data analysis and trying to get some insights about our dataset</li>\n    <li>Getting data in better shape by transforming and feature engineering to help us in building better models</li>\n    <li>Building and tuning a XGBClassifer to get some results on predicting Hazard</li>\n</ul>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Importing Libraries</h2>\n<p>Lets start by importing some packages we are going to need</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Meeting the data\n<p>Lets open the data and see what we have</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Opening the data\ndata = pd.read_csv('../input/nasa-asteroids-classification/nasa.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see the shapes of the data so we know what we are dealing with\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets observe some of his elements\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividing the label and features columns in X, y and then eliminating irrelevant features such as name and ids\nX = data.copy()\nX.drop(columns=['Neo Reference ID', 'Name', 'Orbit ID', 'Hazardous'], inplace=True)\ny = data['Hazardous'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n<p>Exploratory Data Analysis</p>\n\n<p>Lets create a heatmap graphic here. With this graphics we can see the correlation between different features</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = X.corr()\n\nf, ax = plt.subplots(figsize=(14,12))\nplt.title('Correlation of numerical attributes', size=16)\nsns.heatmap(correlation)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Observations</h4>\n<li>Let's focus on the lighter parts of the graph</li>\n<ol>\n    <li>The Estimated Diameters have a high correlation because they are telling the \"same thing\"</li>\n    <li>The Relatives velocity have a high correlation because they are telling the \"same thing\"</li>\n    <li>The Miss Distance have a high correlation because they are telling the \"same thing\"</li>\n</ol>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can see there are 8 columns indicating Min and Max values of the Estimated Diameter of asteroids\n#We are going to create a new column with the Mean value of KM(min) and KM(max) and then eliminate the rest\nX['avg_dia'] = X[['Est Dia in KM(min)', 'Est Dia in KM(max)']].mean(axis=1)\nX.drop(columns=['Est Dia in KM(min)', 'Est Dia in KM(max)', 'Est Dia in M(min)',\n               'Est Dia in M(max)', 'Est Dia in Miles(min)', 'Est Dia in Miles(max)',\n               'Est Dia in Feet(min)', 'Est Dia in Feet(max)'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are 3 columns indicating Relative Velocity\n#We are going to just leave the Relative Velocity km per hr\nX.drop(columns=['Relative Velocity km per sec', 'Miles per hour'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are 4 columns indicating Miss Distance\n#We are going to just leave Mist Distance in kilometers\nX.drop(columns=['Miss Dist.(Astronomical)', 'Miss Dist.(lunar)', 'Miss Dist.(miles)'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see the variability of categorical columns\ncat_columns = X.select_dtypes(include=['object']).columns\n#We dont count these 2 columns because they are dates, we will process them later\ncat_columns = cat_columns.drop(['Close Approach Date', 'Orbit Determination Date'])\nfor col in cat_columns:\n    print(X[col].value_counts(ascending=True, normalize=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Observations</h4>\n<li>We can see both \"Orbiting Body\" and \"Equinox\" have only 1 possible value, so we are going to eliminate them</li>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Eliminating Orbiting Body and Equinox columns\nX.drop(columns=cat_columns, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Data\n<ul>\n    <li>Lets see if there any missing values and visualize them</li>\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<li>Luckily we don't have any missing values, so we can proceed with modeling</li>"},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing + Pipeline\n<li>First, lets split the data into train and test dataframes</li>\n<p>Steps:</p>\n<ol>\n    <li>Extract year, month and day from the date columns so we can use them as numerical features</li>\n    <li>Add Year, Month and Day for each date column to the dataset</li>\n    <li>Eliminate date columns from the dataset</li>\n    <li>Fit the model</li>\n</ol>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Pipeline\nfrom sklearn.pipeline import Pipeline\n#Import model and GridSearch for Hyperparameter Optimization\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import the BaseEstimator\nfrom sklearn.base import BaseEstimator\n\n#Define Date pre-processor class\nclass DateProcessor(BaseEstimator):\n\n    def __init__(self):\n        pass\n\n    def fit(self, documents, y=None):\n        return self\n\n    def transform(self, df):\n        dateCols = ['Close Approach Date', 'Orbit Determination Date']\n        new_df = df.copy()\n        for col in dateCols:\n            \n            new_df[col] = pd.to_datetime(new_df[col], errors=\"coerce\",format=\"%Y-%m-%d\")\n            #df.dropna(axis=1, subset=['date'], inplace=True)\n            \n            newColsDict = {'day': str(col) + \" day\", 'month': str(col) + \" month\", 'year': str(col) + \" year\"}\n            new_df[newColsDict['day']] = new_df[col].dt.day\n            new_df[newColsDict['month']] = new_df[col].dt.month\n            new_df[newColsDict['year']] = new_df[col].dt.year\n            \n        new_df.drop(inplace=True, columns=dateCols)\n        return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining the pipeline\n\"\"\"\nobjective= 'binary:logistic',\n    nthread=4,\n    seed=42,\n    learning_rate = 0.2,\n    max_depth = 3,\n    n_estimators = 65,\n    tree_method='gpu_hist',\n    verbosity=2\n\"\"\"\nestimator = XGBClassifier(seed=42)\nmodel_pipeline = Pipeline(steps=[\n                                ('process_dates', DateProcessor()),\n                                ('XGBoost', estimator)\n                                ])\nmodel_pipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Score\nmodel_pipeline.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets try another score method\nfrom sklearn.metrics import accuracy_score\n\ny_pred = model_pipeline.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# End\nThanks for going all the way down through my notebook! I hope you were able to get something usefull from this. Feel free to ask your questions and use my code"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}