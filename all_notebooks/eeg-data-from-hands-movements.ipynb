{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EEG - Data from hands movements"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings(action='ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nimport tensorflow as tf\nimport gc\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Read dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/eeg-data-from-hands-movement/Dataset/user_a.csv', delimiter=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_users = [pd.read_csv('../input/eeg-data-from-hands-movement/Dataset/user_'+user+'.csv', delimiter=',') for user in ['a','b','c','d']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Data Exploration\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntarget = 'Class'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = dataset.columns       # .columns gives columns names in data\nfeatures = col[1:]\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[target].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=target, data=dataset, palette=\"bone\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotScatterMatrix(dataset, 20, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Data Analysis\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlist_cor = pd.DataFrame(dataset[features].corr().unstack().abs().sort_values().drop_duplicates())\nlist_cor.columns = ['correlation_index']\nlist_corr_high = list(list_cor[-33:-1]['correlation_index'].index)\nlist_corr_high","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n#### Missing data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntotal = dataset[features].isnull().sum().sort_values(ascending = False)\npercent = (dataset[features].isnull().sum()/dataset[features].isnull().count()*100).sort_values(ascending = False)\nmissing  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Data Preprocessing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, features, target):        \n    \n    list_cor = pd.DataFrame(df[features].corr().unstack().abs().sort_values().drop_duplicates())\n    list_cor.columns = ['correlation_index']\n    list_corr_high = list(list_cor[-33:-1]['correlation_index'].index)\n    list_corr_high\n    \n    for eletrods in list_corr_high:\n        df['__'.join(list(eletrods))] = df.apply(lambda row: abs(row[eletrods[0]] - row[eletrods[1]]), axis=1)\n    \n    col = df.columns       # .columns gives columns names in data\n    features = col[1:]\n    \n    y = df.drop(features, axis=1)\n    y = to_categorical(y)\n    X = df[features]\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    # Scale X with a standard scaler\n    transformer = StandardScaler() \n\n    X_train_transformer = transformer.fit_transform(X_train)\n    X_test_transformer = transformer.transform(X_test)\n\n    return X_train_transformer, X_test_transformer, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Models\n"},{"metadata":{},"cell_type":"markdown","source":"### RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(X):  \n    k2 = int(X.shape[1]**(1/2))\n    inputs = tf.keras.Input(shape=(X.shape[1],))\n    expand_dims = tf.reshape(inputs, (-1,k2, k2), name=None)\n    lstm = tf.keras.layers.LSTM(32, return_sequences=True)(expand_dims)\n    drop = tf.keras.layers.Dropout(.4)(lstm)\n    lstm = tf.keras.layers.LSTM(16, return_sequences=True)(expand_dims)\n    drop = tf.keras.layers.Dropout(.4)(lstm)\n    flatten = tf.keras.layers.Flatten()(lstm)\n    outputs = tf.keras.layers.Dense(3, activation='softmax')(flatten)    \n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(dataset, features, target, build_model=build_model):\n    X_train, X_test, y_train, y_test = preprocess_inputs(dataset, features, target)\n\n    class_model = build_model(X_train)\n\n    history = class_model.fit(\n        X_train,\n        y_train,\n        validation_split=0.3,\n        batch_size=32,\n        epochs=30,\n        verbose=0,\n        callbacks=[\n            tf.keras.callbacks.EarlyStopping(\n                monitor='val_loss',\n                patience=3,\n                restore_best_weights=True\n            )\n        ]\n    )\n\n    print(\"Accuracy: %.2f%% (+/- %.2f%%)\" % (np.mean(history.history['accuracy'])*100, np.std(history.history['accuracy'])*100)) \n\n    class_acc = class_model.evaluate(X_test, y_test, verbose=0)[1]\n    print(\"Test Accuracy (Class Model): {:.2f}%\".format(class_acc * 100))\n    \n    y_pred = np.array(list(map(lambda x: np.argmax(x), class_model.predict(X_test))))\n    clr = classification_report(y_test.argmax(axis=-1) , y_pred)\n#     print(\"Classification Report:\\n----------------------\\n\", clr)\n    \n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracy_history(history):\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loss_history(history):\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dfs in dataset_users:\n    history = train_model(dfs, features, target)\n    plot_accuracy_history(history)\n    plot_loss_history(history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}