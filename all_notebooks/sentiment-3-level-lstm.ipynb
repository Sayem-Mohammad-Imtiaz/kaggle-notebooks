{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"LABEL_LENGTH = 2363\nTRAIN_LENGTH = 1891\ndata = pd.read_csv('/kaggle/input/twitter-airline-sentiment/Tweets.csv')\ndata = data[['airline_sentiment','text']]\ndata['airline_sentiment'].replace(['positive','negative','neutral'],[1,0,2],inplace=True)\nneg_len = len(data[data['airline_sentiment'] == 0])\npos_len = len(data[data['airline_sentiment'] == 1])\nneut_len = len(data[data['airline_sentiment'] == 2])\n\nneg_train = data[data['airline_sentiment'] == 0][:TRAIN_LENGTH]\nneg_test = data[data['airline_sentiment'] == 0][TRAIN_LENGTH:LABEL_LENGTH]\n\npos_train = data[data['airline_sentiment'] == 1][:TRAIN_LENGTH]\npos_test = data[data['airline_sentiment'] == 1][TRAIN_LENGTH:LABEL_LENGTH]\n\nneut_train = data[data['airline_sentiment'] == 2][:TRAIN_LENGTH]\nneut_test = data[data['airline_sentiment'] == 2][TRAIN_LENGTH:LABEL_LENGTH]\n\ntrain_data = np.concatenate((neg_train,pos_train,neut_train),axis=0)\nnp.random.shuffle(train_data)\ntest_data = np.concatenate((neg_test,pos_test,neut_test),axis=0)\nnp.random.shuffle(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nclass Doc(object):\n    def __init__(self):\n        self.text = ''\n        self.words = []\nclass Pipeline(object):\n    def __init__(self,text=''):\n        self.pipe = []\n        self.doc = Doc()\n    def add_pipe(self,fun):\n        self.pipe.append(fun)\n    def __call__(self,text):\n        self.doc.text = text\n        result = self.doc\n        for fun in self.pipe:\n            result = fun(result)\n        return result\ndef tokenize_words(doc):\n    doc.words = nltk.word_tokenize(doc.text.lower())\n    return doc\ndef filter_words(doc):\n    stopwords = [word for word in nltk.corpus.stopwords.words('english') if word not in ['out','on','off']]\n    doc.words = list(filter(lambda word:re.match(r'[a-z]{2,}',word) and word not in stopwords,doc.words))\n    return doc\ndef pos_tag(doc):\n    doc.words = nltk.pos_tag(doc.words)\n    return doc\ndef get_wordnet_pos(treebank_tag):\n    if treebank_tag.startswith('J'):\n        return nltk.corpus.wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return nltk.corpus.wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return nltk.corpus.wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return nltk.corpus.wordnet.ADV\n    else:\n        return ''\ndef word_lemmas(doc):\n    for i in range(0,len(doc.words)):\n        curr_word , tag = doc.words[i]\n        new_word=''\n        for letter in curr_word:\n            if re.match('[a-z]',letter):\n                 new_word+=letter\n        position = get_wordnet_pos(tag)\n        if position != '':\n            new_word = nltk.stem.WordNetLemmatizer().lemmatize(new_word,pos=position)\n        else:\n            new_word=nltk.stem.WordNetLemmatizer().lemmatize(new_word)\n        doc.words[i] = new_word\n    return doc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\n\n# Load pre-trained Word2Vec model.\nmodel = gensim.models.KeyedVectors.load_word2vec_format('/kaggle/input/googles-trained-word2vec-model-in-python/GoogleNews-vectors-negative300.bin', binary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seq_to_vec(doc):\n    result = np.zeros(300,dtype='float32')\n    count = 0\n    for word in doc.words:\n        try:\n            wv = model[str(word)]\n            result+=np.nan_to_num(wv)\n            count+=1\n        except:\n            continue\n    if count > 0:\n        result = result/count\n    result = result.reshape((1,result.shape[0]))\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_line = Pipeline()\npipe_line.add_pipe(tokenize_words)\npipe_line.add_pipe(filter_words)\npipe_line.add_pipe(pos_tag)\npipe_line.add_pipe(word_lemmas)\npipe_line.add_pipe(seq_to_vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ntrain_y = train_data[:,0]\ntrain_x = train_data[:,1]\ntest_x = test_data[:,1]\ntest_y =test_data[:,0]\ntrain_y = train_y.astype('int32',copy=False)\ntest_y = test_y.astype('int32',copy=False)\ntrain_y = to_categorical(train_y,num_classes = 3,dtype='int32')\ntest_y = to_categorical(test_y,num_classes = 3,dtype='int32')\ntrain_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_train_x = np.zeros((train_x.shape[0],1,300),dtype='float32')\nfor i in range(0,len(train_x)):\n    temp_train_x[i] =  pipe_line(train_x[i])\ntemp_train_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = temp_train_x\ntemp_test_x = np.zeros((test_x.shape[0],1,300),dtype='float32')\nfor i in range(0,len(test_x)):\n    temp_test_x[i] =  pipe_line(test_x[i])\ntest_x = temp_test_x\ntest_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n\nmodel_lstm = Sequential()\n\n# Recurrent layer\nmodel_lstm.add(LSTM(units=64, return_sequences=False, \n               dropout=0.1, recurrent_dropout=0.1,use_bias=True, activation='relu'))\n\n# Output layer\nmodel_lstm.add(Dense(3, activation='softmax'))\n\n# Compile the model\nmodel_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhistory = model_lstm.fit(train_x,  train_y, \n                    batch_size=500, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = model_lstm.evaluate(test_x, test_y,verbose = 2) \nprint('accuracy : ',accuracy[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm.save(\"model_sentiment.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel1 = load_model('model_sentiment.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_pred = pipe_line('i will buy this product').reshape((1,1,300))\nnp.argmax(model1.predict(input_pred).squeeze(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}