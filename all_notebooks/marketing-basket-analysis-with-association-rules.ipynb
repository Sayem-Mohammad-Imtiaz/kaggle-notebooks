{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import parallel_coordinates\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/supermarket/GroceryStoreDataSet.csv'\n\ndf = pd.read_csv(path,names = ['items'], sep = ',')\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_1  = df['items'].apply(lambda x : x.split(','))\ndf_1.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"liste = []\n\nfor i in range(len(df_1)):\n    x = df_1[i]\n    print(x)\n    liste.append(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = TransactionEncoder()\npred = encoder.fit_transform(liste)\ndf = pd.DataFrame(pred,columns = encoder.columns_)\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequency = apriori(df,min_support = 0.15,use_colnames = True,verbose = 1)\nfrequency","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules =  association_rules(frequency,metric = 'lift',min_threshold = 0.8)\nrules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (30,30))\npivot = rules.pivot(index = 'consequents', \n                   columns = 'antecedents', values= 'lift')\nsns.heatmap(pivot,annot=True,cbar=False,ax = ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig = px.scatter(x=rules['support'], y=rules['confidence'])\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules['antecedent'] = rules['antecedents'].apply(lambda antecedents : list(antecedents)[0])\nrules['consequent'] = rules['consequents'].apply(lambda consequents : list(consequents)[0])\nrules['rule'] = rules.index\nrules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules.sort_values('lift',ascending = False).head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules.sort_values('confidence',ascending = False).head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules[(rules['confidence']>0.79) & (rules['lift'] > 1.65)]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## from 21 combines we reached out to 2 with highly confidence and it is not just a coincidence\n\nprint(len(rules[(rules['confidence']>0.79) & (rules['lift'] > 1.65)]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cords = rules[['antecedent','consequent','rule']]\n\nparallel_coordinates(cords,'rule',colormap = 'ocean')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The parallel_coordinates chart shows that Bread and Biscuit are good two items as a antecedent and consequent.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules[(rules['leverage']< 0 ) & (rules['lift'] < 0.9)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## (BISCUIT,BREAD) and (TEA,BREAD) have lowest leverage with the minimum lift value in entire dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}