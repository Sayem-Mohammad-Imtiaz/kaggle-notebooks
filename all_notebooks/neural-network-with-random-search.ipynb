{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nimport subprocess\ndef install(package):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\",\"install\",package])\ninstall(\"mlrose\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import six\nimport sys\nsys.modules['sklearn.externals.six'] = six # hack: some library issue\nimport mlrose\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/drug-classification/drug200.csv\")\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\n\ndef label_encoder(y):\n    le = LabelEncoder()\n    data[y] = le.fit_transform(data[y])\n\n#data['Na_to_K_Bigger_Than_15'] = [1 if i >=15.015 else 0 for i in data.Na_to_K]\n#label_list = [\"Sex\",\"BP\",\"Cholesterol\",\"Na_to_K\",\"Na_to_K_Bigger_Than_15\",\"Drug\"]\n\nlabel_list = [\"Sex\",\"BP\",\"Cholesterol\",\"Na_to_K\",\"Drug\"]\n\nfor l in label_list:\n    label_encoder(l)\n    \nX, y = data.drop(['Drug'], axis=1), data['Drug']\nX_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, random_state=101)\n\n\n# Normalize feature data\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\ny_train = y_train.to_frame()\ny_test = y_test.to_frame()\n\n# One hot encode target values\none_hot = OneHotEncoder()\ny_train_hot = one_hot.fit_transform(y_train).todense()\ny_test_hot =  one_hot.transform(y_test).todense()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, multilabel_confusion_matrix, classification_report\nimport time\n\nresults = {}\ntime_map =  {}\ncurve_map = {}\n\ndef decode_one_hot(data):\n    return pd.DataFrame(data).idxmax(axis=1).to_frame()\n\ndef get_report(true_data, pred):\n    r = classification_report(decode_one_hot(true_data), decode_one_hot(pred), output_dict=True, zero_division = 0)\n    print(classification_report(decode_one_hot(true_data), decode_one_hot(pred), zero_division=0))\n    results = r['weighted avg']\n    results['accuracy'] = r['accuracy']\n    return results\n\nfor algorithm in ('random_hill_climb', 'simulated_annealing', 'genetic_alg'):\n    # Initialize neural network object and fit object\n    \n    nn_model1 = mlrose.NeuralNetwork(hidden_nodes = [8], activation = 'relu',\n                                     algorithm = algorithm, max_iters = 200000,\n                                     bias = True, is_classifier = True, learning_rate = 0.001,\n                                     early_stopping = True, clip_max = 5, max_attempts = 100, restarts=0, schedule = mlrose.ExpDecay(exp_const=0.001), random_state = 3, curve=True)\n    start = time.time()\n    nn_model1.fit(X_train, y_train_hot)\n    end = time.time()\n    \n    # Predict labels for train set and assess accuracy\n    y_train_pred = nn_model1.predict(X_train_scaled)\n    y_test_pred = nn_model1.predict(X_test_scaled)\n    \n    results[(f'{algorithm} train')] = get_report(y_train_hot, y_train_pred)\n    results[(f'{algorithm} test')] = get_report(y_test_hot, y_test_pred)\n    time_map[algorithm] = int(end - start)\n    curve_map[algorithm] = nn_model1\n    \nprint(time_map)\nprint(results)\n#print(y_test_hot)\n#print(pd.DataFrame(y_test_hot))\n#print(pd.DataFrame(y_test_pred))\n#print(pd.DataFrame(y_test_hot).idxmax(axis=1).to_frame().corrwith(pd.DataFrame(y_test_pred).idxmax(axis=1), axis =0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(curve_map['random_hill_climb'].fitted_weights)\nprint(curve_map['random_hill_climb'].predicted_probs)\nprint(curve_map['random_hill_climb'].fitness_curve)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(curve_map['simulated_annealing'].fitted_weights)\nprint(curve_map['simulated_annealing'].predicted_probs)\nprint(curve_map['simulated_annealing'].fitness_curve)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\ndef plot_results(data, title, xlabel, ylabel):\n    fig, ax = plt.subplots()\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_title(title)\n    \n    ax.plot([i for i in range(len(data))], data, marker='o', label=title)\n    ax.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(curve_map['random_hill_climb'].fitness_curve, 'RHC fitness_curve', 'iteration', 'fitness', )\nplot_results(curve_map['simulated_annealing'].fitness_curve, 'SA fitness_curve', 'iteration', 'fitness', )\nplot_results(curve_map['genetic_alg'].fitness_curve, 'GA fitness_curve', 'iteration', 'fitness', )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\ndef plot_results(results, title, xlabel, ylabel, skipped_algorithms=[]):\n    fig, ax = plt.subplots()\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_title(title)\n    \n\n    keys = sorted(results.keys())\n    #print(keys)\n    values = [results[key][ylabel] for key in keys]\n    ax.bar(keys,values)\n    ax.set_xticklabels(keys, rotation = 90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(results, 'precision', 'algorimth', 'precision')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(results, 'recall', 'algorimth', 'recall')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(results, 'f1-score', 'algorimth', 'f1-score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(results, 'accuracy', 'algorimth', 'accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algorithm = 'random_hill_climb'\n    \nnn_model1 = mlrose.NeuralNetwork(hidden_nodes = [8], activation = 'relu',\n                                 algorithm = algorithm, max_iters = 200000,\n                                 bias = True, is_classifier = True, learning_rate = 0.001,\n                                 early_stopping = True, clip_max = 5, max_attempts = 100, restarts=0, schedule = mlrose.ExpDecay(exp_const=0.001), random_state = 3, curve=True)\nstart = time.time()\nnn_model1.fit(X_train, y_train_hot)\nend = time.time()\n\n# Predict labels for train set and assess accuracy\ny_train_pred = nn_model1.predict(X_train_scaled)\ny_test_pred = nn_model1.predict(X_test_scaled)\n\nresults= {}\nresults[(f'{algorithm} train')] = get_report(y_train_hot, y_train_pred)\nresults[(f'{algorithm} test')] = get_report(y_test_hot, y_test_pred)\n\nplot_results(nn_model1.fitness_curve, 'RHC fitness_curve 2', 'iteration', 'fitness', )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algorithm = 'simulated_annealing'\n    \nnn_model1 = mlrose.NeuralNetwork(hidden_nodes = [8], activation = 'relu',\n                                 algorithm = algorithm, max_iters = 200000,\n                                 bias = True, is_classifier = True, learning_rate = 0.001,\n                                 early_stopping = True, clip_max = 5, max_attempts = 100, restarts=0, schedule = mlrose.ExpDecay(exp_const=0.001), random_state = 3, curve=True)\nstart = time.time()\nnn_model1.fit(X_train, y_train_hot)\nend = time.time()\n\n# Predict labels for train set and assess accuracy\ny_train_pred = nn_model1.predict(X_train_scaled)\ny_test_pred = nn_model1.predict(X_test_scaled)\n\nresults= {}\nresults[(f'{algorithm} train')] = get_report(y_train_hot, y_train_pred)\nresults[(f'{algorithm} test')] = get_report(y_test_hot, y_test_pred)\n\nplot_results(nn_model1.fitness_curve, 'SA fitness_curve 2', 'iteration', 'fitness', )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}