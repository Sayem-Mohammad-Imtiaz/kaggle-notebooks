{"cells":[{"metadata":{},"cell_type":"markdown","source":"<b> References </b>\n\n1. https://github.com/EthicalML/xai/tree/master/examples\n(Published here for learning purposes only)\n\nThis library is developed and mainted by The Institute for Ethical Machine Learning\n(https://github.com/EthicalML)\n\n2. https://towardsdatascience.com/identifying-and-correcting-label-bias-in-machine-learning-ed177d30349e"},{"metadata":{},"cell_type":"markdown","source":"<h1> Assesing Bias in Algorithm </h1>\n\n\nWhen attempting to assess bias in algorithms, researchers commonly look at four key metrics:\n\n<h2> Demographic parity </h2>\n<p>Classifier should make positive predictions on a protected population group at the same rate as the entire population.</p>\n\n\n<h2> Demographic parity </h2>\n<p> Similar to demographic parity but without the classifier knowing which protected population groups exist and which data points relate to such protected groups.</p>\n\n\n<h2> Equal opportunity </h2>\n<p> Classifier should have equal true positive rates on a protected population group as those of the entire population.</p>\n\n<h2> Equalized odds </h2>\n<p> Classifier should have both equal true positive and false positive rates on a protected population group as those of the entire population.Each high-level metric is expressed as a non-negative number which describes how close the classifier is to full fairness, with a score of 0 representing no bias </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install xai\n!pip install xai_data\nimport sys, os\nimport pandas as pd\nimport numpy as np\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\n# Use below for charts in dark jupyter theme\n\nTHEME_DARK = False\n\nif THEME_DARK:\n    # This is used if Jupyter Theme dark is enabled. \n    # The theme chosen can be activated with jupyter theme as follows:\n    # >>> jt -t oceans16 -T -nfs 115 -cellw 98% -N  -kl -ofs 11 -altmd\n    font_size = '20.0'\n    dark_theme_config = {\n        \"ytick.color\" : \"w\",\n        \"xtick.color\" : \"w\",\n        \"text.color\": \"white\",\n        'font.size': font_size,\n        'axes.titlesize': font_size,\n        'axes.labelsize': font_size, \n        'xtick.labelsize': font_size, \n        'ytick.labelsize': font_size, \n        'legend.fontsize': font_size, \n        'figure.titlesize': font_size,\n        'figure.figsize': [20, 7],\n        'figure.facecolor': \"#384151\",\n        'legend.facecolor': \"#384151\",\n        \"axes.labelcolor\" : \"w\",\n        \"axes.edgecolor\" : \"w\"\n    }\n    plt.rcParams.update(dark_theme_config)\n\nsys.path.append(\"..\")\n\nimport xai\nimport xai.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = [\"gender\", \"workclass\", \"education\", \"education-num\", \"marital-status\",\n                   \"occupation\", \"relationship\", \"ethnicity\", \"loan\"]\ncsv_columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n                   \"occupation\", \"relationship\", \"ethnicity\", \"gender\", \"capital-gain\", \"capital-loss\",\n                   \"hours-per-week\", \"loan\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset description:\nListing of attributes: \n\n1. y >50K, <=50K. \n2. age\t continuous. \n\n3. workclass\t Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov,Without-pay, Never-worked. \n\n4. fnlwgt\t continuous. \n\n5. education\t Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n\n6. education-num\t continuous. \n\n7. marital-status\t Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n\n8. occupation\t Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n\n9. relationship\t Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n\n10. race\t White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. \n\n11. sex\t Female, Male. \n\n12. capital-gain\t continuous. \n\n13. capital-loss\t continuous. \n\n14. hours-per-week\t continuous. \n\n15. native-country\t United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = xai.data.load_census()\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = \"loan\"\nprotected = [\"ethnicity\", \"gender\", \"age\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here,we look at the gender imbalance,a trait that we definitely DO NOT want any model built on this data to carry and learn.\nView class imbalances for protected columns"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"\ndf_groups = xai.imbalance_plot(df, \"gender\", categorical_cols=categorical_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To see how gender imbalance correlates with loan,"},{"metadata":{"trusted":true},"cell_type":"code","source":"groups = xai.imbalance_plot(df, \"gender\", \"loan\", categorical_cols=categorical_cols)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"bal_df = xai.balance(df, \"gender\", \"loan\", upsample=0.8, categorical_cols=categorical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = xai.correlations(df, include_categorical=True, plot_type=\"matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proc_df = xai.normalize_numeric(bal_df)\nproc_df = xai.convert_categories(proc_df)\nx = proc_df.drop(\"loan\", axis=1)\ny = proc_df[\"loan\"]\n\nx_train, y_train, x_test, y_test, train_idx, test_idx = \\\n    xai.balanced_train_test_split(\n            x, y, \"gender\", \n            min_per_group=300,\n            max_per_group=300,\n            categorical_cols=categorical_cols)\n\nx_train_display = bal_df[train_idx]\nx_test_display = bal_df[test_idx]\n\nprint(\"Total number of examples: \", x_test.shape[0])\n\ndf_test = x_test_display.copy()\ndf_test[\"loan\"] = y_test\n\n_= xai.imbalance_plot(df_test, \"gender\", \"loan\", categorical_cols=categorical_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are able to also analyse the interaction between inference results and input features. For this, we will train a single layer deep learning model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, mean_squared_error, roc_curve, auc\n\nfrom keras.layers import Input, Dense, Flatten, \\\n    Concatenate, concatenate, Dropout, Lambda\nfrom keras.models import Model, Sequential\nfrom keras.layers.embeddings import Embedding\n\ndef build_model(X):\n    input_els = []\n    encoded_els = []\n    dtypes = list(zip(X.dtypes.index, map(str, X.dtypes)))\n    for k,dtype in dtypes:\n        input_els.append(Input(shape=(1,)))\n        if dtype == \"int8\":\n            e = Flatten()(Embedding(X[k].max()+1, 1)(input_els[-1]))\n        else:\n            e = input_els[-1]\n        encoded_els.append(e)\n    encoded_els = concatenate(encoded_els)\n\n    layer1 = Dropout(0.5)(Dense(100, activation=\"relu\")(encoded_els))\n    out = Dense(1, activation='sigmoid')(layer1)\n\n    # train model\n    model = Model(inputs=input_els, outputs=[out])\n    model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n\ndef f_in(X, m=None):\n    \"\"\"Preprocess input so it can be provided to a function\"\"\"\n    if m:\n        return [X.iloc[:m,i] for i in range(X.shape[1])]\n    else:\n        return [X.iloc[:,i] for i in range(X.shape[1])]\n\ndef f_out(probs, threshold=0.5):\n    \"\"\"Convert probabilities into classes\"\"\"\n    return list((probs >= threshold).astype(int).T[0])\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model = build_model(x_train)\n\nmodel.fit(f_in(x_train), y_train, epochs=50, batch_size=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(f_in(x_test), y_test, verbose=1)\nprint(\"Error %.4f: \" % score[0])\nprint(\"Accuracy %.4f: \" % (score[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = model.predict(f_in(x_test))\npred = f_out(probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_= xai.metrics_plot(\n        y_test, \n        probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Identify metric imbalances grouped by protected columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = xai.metrics_plot(\n    y_test, \n    probabilities, \n    df=x_test_display, \n    cross_cols=[\"gender\", \"ethnicity\"],\n    categorical_cols=categorical_cols)\n#look at how recall for Black male is low but accuracy is high.\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"_ = [xai.metrics_plot(\n    y_test, \n    probabilities, \n    df=x_test_display, \n    cross_cols=[p],\n    categorical_cols=categorical_cols) for p in protected]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xai.confusion_matrix_plot(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xai.confusion_matrix_plot(y_test, pred, scaled=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = xai.roc_plot(y_test, probabilities)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"_ = [xai.roc_plot(\n    y_test, \n    probabilities, \n    df=x_test_display, \n    cross_cols=[p],\n    categorical_cols=categorical_cols) for p in protected]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"_= xai.pr_plot(y_test, probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = [xai.pr_plot(\n    y_test, \n    probabilities, \n    df=x_test_display, \n    cross_cols=[p],\n    categorical_cols=categorical_cols) for p in protected]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = xai.smile_imbalance(\n    y_test, \n    probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d[[\"correct\", \"incorrect\"]].sum().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = xai.smile_imbalance(\n    y_test, \n    probabilities,\n    threshold=0.75,\n    display_breakdown=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_bars = [\"true-positives\", \"true-negatives\", \n                \"false-positives\", \"false-negatives\"]\nd[display_bars].sum().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"d = xai.smile_imbalance(\n    y_test, \n    probabilities,\n    bins=9,\n    threshold=0.75,\n    manual_review=0.00001,\n    display_breakdown=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d[[\"correct\", \"incorrect\", \"manual-review\"]].sum().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_avg(x, y):\n    return model.evaluate(f_in(x), y, verbose=0)[1]\n\nimp = xai.feature_importance(x_test, y_test, get_avg)\n\nimp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}