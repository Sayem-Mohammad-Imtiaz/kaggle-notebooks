{"cells":[{"metadata":{},"cell_type":"markdown","source":"****We will try to find out similarity between paintings and also how machine learning algorithms do it****"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import glob\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/best-artworks-of-all-time/artists.csv')\ndf = df.drop(columns=['bio', 'wikipedia'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we will try to create the histogram of all of the paintings of an artist, so a type of average histogram, We are doing this because we want to see if we can find similarity based on this feature, after this we will move forward to machine learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"artists_hist_dict = {}\nfor ii in glob.glob('../input/best-artworks-of-all-time/images/images/*'):\n    blue_hist = []\n    red_hist = []\n    green_hist = []\n    for j in glob.glob(ii + '/*'):\n        img = cv2.imread(j)\n        for i, col in enumerate(['b', 'g', 'r']):\n            hist = cv2.calcHist([img], [i], None, [256], [0, 256])\n            if col=='b':\n                blue_hist.append(hist)\n            elif col=='g':\n                green_hist.append(hist)\n            elif col=='r':\n                red_hist.append(hist)\n\n    blue_hist = sum(blue_hist)/len(blue_hist)\n    green_hist = sum(green_hist)/len(green_hist)\n    red_hist = sum(red_hist)/len(red_hist)\n    artists_hist_dict[j.split('/')[-2]] = [blue_hist, green_hist, red_hist]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"equivalent_artists = []\nfor i in artists_hist_dict:\n    score_max = 0\n    for j in artists_hist_dict:\n        score = 0\n        if i!=j:\n            for k,l in zip(artists_hist_dict[j], artists_hist_dict[i]):     \n                score = score + cv2.compareHist(k, l, cv2.HISTCMP_CORREL)\n                score = score/3.0\n            if score > score_max:\n                score_max = score\n                similar_artist = j\n    equivalent_artists.append((i,similar_artist, score_max))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(artist_1,  artist_2, title_of_plot):\n    blue_hist1, green_hist1, red_hist1 = artists_hist_dict[artist_1]\n    blue_hist2, green_hist2, red_hist2 = artists_hist_dict[artist_2]\n    fig, axs = plt.subplots(2,figsize=(5,5))\n    fig.tight_layout()\n    #fig.suptitle('score :' + title_of_plot )\n    axs[0].title.set_text(artist_1)\n    axs[0].plot(blue_hist1, color = 'b')\n    axs[0].plot(green_hist1, color = 'g')\n    axs[0].plot(red_hist1, color = 'r')\n    axs[1].title.set_text(artist_2)\n    axs[1].plot(blue_hist2, color = 'b')\n    axs[1].plot(green_hist2, color = 'g')\n    axs[1].plot(red_hist2, color = 'r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find closest artists based on histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in equivalent_artists:\n    plot(i[0], i[1], str(i[2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****From here we will try to make an autoencoder**** "},{"metadata":{"trusted":true},"cell_type":"code","source":"all_artwork = []\nall_labels = []\nfor ii in glob.glob('../input/best-artworks-of-all-time/images/images/*'):\n    for j in glob.glob(ii + '/*'):\n        all_artwork.append(cv2.resize(cv2.imread(j), (128,128)))\n        all_labels.append(ii.split('/')[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_artwork = np.asarray(all_artwork)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The aim of the encoder is so that we can get a compressed representation,  \nlater we will apply T-SNE to see if the compressions are distributed like the training data or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nimport keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=(128,128,3))\n##--encoder--##\nconv = Conv2D(8, kernel_size=3, activation='relu')(inputs)\nconv = MaxPooling2D(pool_size=(2, 2))(conv)\nconv = Conv2D(8, kernel_size=3, activation='relu')(conv)\nconv = Conv2D(8, kernel_size=3, activation='relu')(conv)\nconv = MaxPooling2D(pool_size=(2, 2))(conv)\nconv = Conv2D(16, kernel_size=3, activation='relu')(conv)\n###\ndeconv = Conv2DTranspose(16, kernel_size=3, activation='relu')(conv)\ndeconv = UpSampling2D(size=(2, 2),interpolation='nearest')(deconv)\ndeconv = Conv2DTranspose(8, kernel_size=3, activation='relu')(deconv)\ndeconv = Conv2DTranspose(8, kernel_size=3, activation='relu')(deconv)\ndeconv = UpSampling2D(size=(2, 2),interpolation='nearest')(deconv)\ndeconv = Conv2DTranspose(8, kernel_size=3, activation='relu')(deconv)\n##--get--back--image--##\nimg = Conv2DTranspose(3, kernel_size=3, activation='relu')(deconv)\n\nmodel = Model(inputs=inputs, outputs=img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(lr = 0.0001)\nmodel.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_model = model.fit(all_artwork/255.0,  all_artwork/255.0, shuffle= True, epochs = 50,  batch_size=8,verbose=1)\nprint(history_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ind, layer in enumerate(model.layers):\n    print(ind,\" \",layer.name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model we have created is very small, and with very few parameters, our aim is to just create a model which compresses images, we dont aim for a great reconstructor, we just want to extract features from the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfor i in [random.randint(0, len(all_artwork)) for i in range(10)]:\n    original_art_works =all_artwork[i]\n    plt.title('original')\n    plt.imshow(original_art_works)\n    plt.show()\n    reconstructed_art_works = np.squeeze(model.predict(np.asarray([original_art_works/255.0])))\n    plt.title('reconstruction')\n    plt.imshow(reconstructed_art_works)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let;s get the compressed feature from the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_output = model.get_layer(model.layers[6].name).output\nget_latent_vector = Model(inputs=model.input, outputs=model_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_vectors = []\nlatent_labels = []\nall_artwork = []\nfor ii in glob.glob('../input/best-artworks-of-all-time/images/images/*'):\n    for j in glob.glob(ii + '/*'):\n        all_artwork.append(cv2.resize(cv2.imread(j), (128,128)))\n        latent_vectors.append(np.squeeze(get_latent_vector.predict(np.asarray([cv2.resize(cv2.imread(j), (128,128))/255.0]))))\n        latent_labels.append(ii.split('/')[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nc = list(zip(all_artwork,  latent_vectors, latent_labels))\n\nrandom.shuffle(c)\n\nall_artwork, latent_vectors, latent_labels = zip(*c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lv = []\nfor i in range(len(latent_vectors)):\n    lv.append(np.reshape(latent_vectors[i],  (27*27*16)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_labels = np.asarray(latent_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sn\nfrom sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2, random_state=0,  perplexity=100, learning_rate=10.0)\ndata = tsne_model.fit_transform(np.asarray(lv[0:2000]))\nprint(data.shape)\ntsne_data = np.vstack((data.T, latent_labels[0:2000])).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\ng = sn.FacetGrid(tsne_df, hue=\"label\",  size=10).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\ng.set(xticklabels=[], yticklabels=[])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lv1 = []\nfor i in range(len(all_artwork)):\n    lv1.append(np.reshape(all_artwork[i],  (128*128*3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sn\nfrom sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2, random_state=0,  perplexity=100, learning_rate=10.0)\ndata = tsne_model.fit_transform(np.asarray(lv1[0:2000])/255.0)\nprint(data.shape)\ntsne_data = np.vstack((data.T, latent_labels[0:2000])).T\ntsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\ng = sn.FacetGrid(tsne_df, hue=\"label\",  size=10).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\ng.set(xticklabels=[], yticklabels=[])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see what features did our compressed feature even extracts"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor kk in range(3):\n    plt.imshow(all_artwork[kk])\n    plt.show()\n    fig, ax = plt.subplots(nrows=4, ncols=4, figsize = (10,10))\n\n    i = 0\n    for row in ax:\n        for col in row:\n            col.imshow(latent_vectors[kk][:,:,i])\n            i = i+1\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}