{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering from my Feature Engineering notebook","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import h2o\n#connecting to cluster\nh2o.init(strict_version_check=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_csv = \"/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\"\ndata = h2o.import_file(data_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rename(columns={\"PAY_0\": \"PAY_1\"}) #for consistency\ndata.rename(columns={'default.payment.next.month': \"DEFAULT\"}) #easier\n\ncols_names = data.columns #because we know the data type for all the columns (they are all ints)\ncols_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_categorical = ['ID',\n 'LIMIT_BAL',\n  'AGE',\n 'BILL_AMT1',\n 'BILL_AMT2',\n 'BILL_AMT3',\n 'BILL_AMT4',\n 'BILL_AMT5',\n 'BILL_AMT6',\n 'PAY_AMT1',\n 'PAY_AMT2',\n 'PAY_AMT3',\n 'PAY_AMT4',\n 'PAY_AMT5',\n 'PAY_AMT6']\n\ntarget = \"DEFAULT\"\n\ncategorical = [item for item in cols_names if item not in not_categorical and item != target]\ncategorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Onehot encoding (as labels are already encoded as numbers)\n\ndata_onehot = pd.get_dummies(data.as_data_frame(), columns=categorical)\ndata_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the ID column\n\ndata_onehot = data_onehot.drop(columns=['ID'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_onehot.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating equally sized bins for age - 5 categories\n\nprint(data_onehot['AGE'].describe())\n\n#add age bins to make it all-inclusive - in case new data may come\n\ndata_onehot['AGE_BINS'] = pd.qcut(data_onehot['AGE'], 5)\n\n#Add age bins for ages (0, 20.999] and (79.0, ) - even though there may be no data for this in the present dataset, it is important to do this in case we have future data\n\ndata_onehot['AGE_BINS_(0, 20.999]'] = 0 #in the same format as after one hot encoding (doing this two cells later)\ndata_onehot['AGE_BINS_(79.0, )'] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_onehot.head() #it works!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we use one hot encoding for these categories\n\ndata_age = pd.get_dummies(data_onehot, columns=['AGE_BINS'])\ndata_age = data_age.drop(columns=['AGE'])\ndata_age.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#some statistical featurs\n\nbill_amt_cols = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\npay_amt_cols = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n\n#mean of Bill_amt and Pay_amt, max, min, std, var\n\ndata_age['BILL_AMT_MEAN'] = data_age[bill_amt_cols].mean(axis=1)\ndata_age['PAY_AMT_MEAN'] = data_age[pay_amt_cols].mean(axis=1)\n\ndata_age['BILL_AMT_MAX'] = data_age[bill_amt_cols].max(axis=1)\ndata_age['PAY_AMT_MAX'] = data_age[pay_amt_cols].max(axis=1)\n\ndata_age['BILL_AMT_MIN'] = data_age[bill_amt_cols].min(axis=1)\ndata_age['PAY_AMT_MIN'] = data_age[pay_amt_cols].min(axis=1)\n\ndata_age['BILL_AMT_MED'] = data_age[bill_amt_cols].median(axis=1)\ndata_age['PAY_AMT_MED'] = data_age[pay_amt_cols].median(axis=1)\n\ndata_age['BILL_AMT_STD'] = data_age[bill_amt_cols].std(axis=1)\ndata_age['PAY_AMT_STD'] = data_age[pay_amt_cols].std(axis=1)\n\ndata_age['BILL_AMT_VAR'] = data_age[bill_amt_cols].var(axis=1)\ndata_age['PAY_AMT_VAR'] = data_age[pay_amt_cols].var(axis=1)\n\n\ndata_age.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#some new variables\n\n#payment fraction of bill statement\nfor i in range(1, 7):        \n    data_age['PAY_FRAC_' + str(i)] = data_age[pay_amt_cols[i-1]] / data_age[bill_amt_cols[i-1]]\ndata_age = data_age.fillna(0)\n\n\n#fraction of credit limit used (bill_amt / limit_bal)\nfor i in range(1, 7):        \n    data_age['USED_CREDIT' + str(i)] = data_age[bill_amt_cols[i-1]] / data_age['LIMIT_BAL']\ndata_age = data_age.fillna(0)\n\n\ndata_age.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_age['PAY_FRAC_1'].max()\n\n\n\n#There are 540. Three simple ways to deal: delete feature, delete rows, set to zero. Have to test.\n\n#Setting to zero\n\nfor i in range (1, 7):\n    #print(len(data_age[data_age['PAY_FRAC_' + str(i)] == np.inf])) #0 of them are -np.inf\n    data_age['PAY_FRAC_' + str(i)] = data_age['PAY_FRAC_' + str(i)].replace({np.inf: 0})\n    #print(len(data_age[data_age['PAY_FRAC_' + str(i)] == np.inf]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling\n\n#Using standard scalar scaling\n#Multiple methods such as min-max scaling, standard scaling, etc. All have different advantages and depend on the distribution of data.\n#Can always change this in the next iterations of the ML pipeline. Trial and error process.\n\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nscaled_features = data_age.copy()\n\ncol_names = ['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4' ,'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4' ,'PAY_AMT5', 'PAY_AMT6', 'PAY_FRAC_1', 'PAY_FRAC_2', 'PAY_FRAC_3', 'PAY_FRAC_4', 'PAY_FRAC_5', 'PAY_FRAC_6', 'USED_CREDIT1', 'USED_CREDIT2', 'USED_CREDIT3', 'USED_CREDIT4', 'USED_CREDIT5', 'USED_CREDIT6', 'BILL_AMT_MEAN',\n 'PAY_AMT_MEAN',\n 'BILL_AMT_MAX',\n 'PAY_AMT_MAX',\n 'BILL_AMT_MIN',\n 'PAY_AMT_MIN',\n 'BILL_AMT_MED',\n 'PAY_AMT_MED',\n 'BILL_AMT_STD',\n 'PAY_AMT_STD',\n 'BILL_AMT_VAR',\n 'PAY_AMT_VAR']\nfeatures = scaled_features[col_names]\nscaler = StandardScaler().fit(features.values)\nfeatures = scaler.transform(features.values)\n\nscaled_features[col_names] = features\nscaled_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_df = pd.DataFrame(scaled_features, columns=['LIMIT_BAL', 'BILL_AMT1', 'PAY_AMT1', 'USED_CREDIT1'])\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(6, 5))\n\nax1.set_title('Before Scaling')\nsns.kdeplot(data_age['LIMIT_BAL'], ax=ax1) #kernel density estimate plot (non-parametric way to estimate the probability density function of a random variable.)\nsns.kdeplot(data_age['BILL_AMT1'], ax=ax1)\nsns.kdeplot(data_age['PAY_AMT1'], ax=ax1)\nsns.kdeplot(data_age['USED_CREDIT1'], ax=ax1)\nax2.set_title('After Standard Scaler')\nsns.kdeplot(scaled_df['LIMIT_BAL'], ax=ax2)\nsns.kdeplot(scaled_df['BILL_AMT1'], ax=ax2)\nsns.kdeplot(scaled_df['PAY_AMT1'], ax=ax2)\nsns.kdeplot(scaled_df['USED_CREDIT1'], ax=ax2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see here how the data is scaled. Now, we have the dataframe *scaled_features.*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_features.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model development","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_data = scaled_features['DEFAULT']\nX_data = scaled_features.copy().drop(columns=['DEFAULT'])\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Fold cross validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10)\nmodel_accuracy = accuracies.mean()\nmodel_standard_deviation = accuracies.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generating reports on metrics\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC Curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\narea_under_curve = roc_auc_score(y_test, classifier.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % area_under_curve)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Incredibly small area under the ROC curve. This means the model isn't that good at discriminating, which is concerning.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### H2O Rulefit Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#H2O Rulefit\n\ndata = h2o.H2OFrame(scaled_features.copy())\ndata.types","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like all the 'int' variables are actually the one-hot-encoded variables. Converting them to factor:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.types:\n    if data.types[col] == 'int':\n        data[col] = data[col].asfactor()\n        \ndata.types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\ntrain, test = data.split_frame(ratios = [0.7], destination_frames=[\"train\", \"test\"], seed = 1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from h2o3_rule_fit import H2ORuleFit\n\ncols = data.columns\ncols.remove('DEFAULT')\n\nrulefit_model = H2ORuleFit(algorithm = \"DRF\", seed = 1234)\n#GLM model with Lasso regularization\n\nrulefit_model.train(training_frame = train, x = cols, y = 'DEFAULT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Intercept: \" + str(round(rulefit_model.intercept.get(\"Intercept\"), 10)))\nprint(\"\\n\\n\")\n\nrules = rulefit_model.rule_importance\nfor i in range(len(rules)):\n    print(\"Coefficient:\" + str(round(rules.iloc[i][\"coefficient\"], 15)) \n          + \"\\nRule: \" + rules.iloc[i][\"rule\"] + \"\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rulefit_model.varimp_plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rulefit_model.coverage_table(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rulefit_model.predict(test)\npredictions = test[\"DEFAULT\"].cbind(predictions)\npredictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positives = predictions[predictions[\"predict\"] == \"1\"]\nnegatives = predictions[predictions[\"predict\"] == \"0\"]\nnegatives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"How many times we correctly predicted defaulted: {:.2%}\".format(positives[positives[\"DEFAULT\"] == positives[\"predict\"]].nrow/positives.nrow))\nprint(\"How many times we correctly predicted not defaulted: {:.2%}\".format(negatives[negatives[\"DEFAULT\"] == negatives[\"predict\"]].nrow/negatives.nrow))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy with RuleFit Model: {:.2%}\".format(predictions[predictions[\"DEFAULT\"] == predictions[\"predict\"]].nrow/predictions.nrow))\nprint(\"Accuracy with Constant Model: {:.2%}\".format(predictions[predictions[\"DEFAULT\"] == \"0\"].nrow/predictions.nrow))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some important conclusions:\n1. The GLM is weak when trying to predict defaulting (low recall).\n2. RuleFit doesn't seem to help much.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Other H2O Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### GLM","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Binomial Classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = h2o.H2OFrame(scaled_features.copy())\n\nfor col in data.types:\n    if data.types[col] == 'int':\n        data[col] = data[col].asfactor()\n\n#As H2O prefers the predictor/response columns instead of the whole dataframes\ndata_y = 'DEFAULT'\ndata_X = [col for col in data.columns if col != 'DEFAULT']\n\n# Splitting the dataset into the Training set and Test set\ntrain, test = data.split_frame(ratios = [0.7], destination_frames=[\"train\", \"test\"], seed = 1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Binomial classification, chooses automatic solver, didn't specify model_id (although it makes it easier for flow) because wanted to use default\n#No validation frame being defined (being consistent with the others - choosing default option)\n\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\n\nbinom_model = H2OGeneralizedLinearEstimator(family='binomial', solver='AUTO')\nbinom_model.train(data_X, data_y, training_frame=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binom_model.model_performance(test)\n\n#what is threshold?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting Machine - Automatically selecting best distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = h2o.H2OFrame(scaled_features.copy())\n\nfor col in data.types:\n    if data.types[col] == 'int':\n        data[col] = data[col].asfactor()\n\n#As H2O prefers the predictor/response columns instead of the whole dataframes\ndata_y = 'DEFAULT'\ndata_X = [col for col in data.columns if col != 'DEFAULT']\n\n# Splitting the dataset into the Training set and Test set\ntrain, test = data.split_frame(ratios = [0.7], destination_frames=[\"train\", \"test\"], seed = 1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Not defining number of trees, max_depth and lr (typical parameters) as want to use default value. Alos choosing AUTO\n\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\n\ngb_model = H2OGradientBoostingEstimator(distribution='AUTO')\ngb_model.train(data_X, data_y, training_frame=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_gb = gb_model.predict(test)\n\nfrom sklearn.metrics import f1_score\n\nf1_sc = f1_score(test['DEFAULT'].as_data_frame(), predict_gb['predict'].as_data_frame())\nroc_score = roc_auc_score(test['DEFAULT'].as_data_frame(), predict_gb['p1'].as_data_frame())\n\nprint(\"F1 Score :\", f1_sc)\nprint(\"ROC Score :\", roc_score, gb_model.model_performance(test).auc())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_model.model_performance(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_model.F1()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find out what distribution is selected - for some reason it has been remarkably difficult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### H2O's AutoML","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = h2o.H2OFrame(scaled_features.copy())\n\nfor col in data.types:\n    if data.types[col] == 'int':\n        data[col] = data[col].asfactor()\n\n#As H2O prefers the predictor/response columns instead of the whole dataframes\ndata_y = 'DEFAULT'\ndata_X = [col for col in data.columns if col != 'DEFAULT']\n\n# Splitting the dataset into the Training set and Test set\ntrain, test = data.split_frame(ratios = [0.7], destination_frames=[\"train\", \"test\"], seed = 1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\n# Time: 12 minutes\n\nfrom h2o.automl import H2OAutoML\n\naml = H2OAutoML(max_models=20, seed=1)\naml.train(x=data_X, y=data_y, training_frame=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Storing the best model\nbest_aml = aml.leader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_aml = best_aml.predict(test)\n\nfrom sklearn.metrics import f1_score\n\n\nf1_sc = f1_score(test['DEFAULT'].as_data_frame(), predict_aml['predict'].as_data_frame())\nroc_score = roc_auc_score(test['DEFAULT'].as_data_frame(), predict_aml['p1'].as_data_frame())\n\nprint(\"F1 Score :\", f1_sc)\nprint(\"ROC Score :\", roc_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_aml.F1(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some ideas for going forward:\n\n- Compare the different models (not going to be that useful though)\n- Tune the best models\n- Add to sheet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import f1_score\n\ny_data1 = scaled_features['DEFAULT']\nX_data1 = scaled_features.copy().drop(columns=['DEFAULT'])\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_data1, y_data1, test_size = 0.3)\n\nmodel = GradientBoostingClassifier()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nf1_sc = f1_score(y_test,y_pred)\nproba = model.predict_proba(X_test)\nroc_score = roc_auc_score(y_test, proba[:,1])\n\nprint(\"F1 Score :\", f1_sc)\nprint(\"ROC Score :\", roc_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nproba = model.predict_proba(X_test)\nroc_score = roc_auc_score(y_test, proba[:,1])\n\nprint(classification_report(y_test,y_pred, zero_division=1))\nprint(\"F1 Score :\", f1_sc)\nprint(\"ROC Score :\", roc_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **WIP** - to be continued","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}