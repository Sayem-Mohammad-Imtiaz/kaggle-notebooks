{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Training data\napp_train = pd.read_csv('../input/train.csv')\nownership = pd.read_csv('../input/Building_Ownership_Use.csv')\nstructure = pd.read_csv('../input/Building_Structure.csv')\nprint('Training data shape: ', app_train.shape)\napp_train = app_train.merge(ownership, on = 'building_id', how = 'left')\napp_train = app_train.merge(structure, on = 'building_id', how = 'left')\napp_train.drop(['district_id_x', 'district_id_y', 'vdcmun_id_x', 'vdcmun_id_y', 'ward_id_y'], axis=1, inplace=True)\nprint('Training data shape: ', app_train.shape)\napp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1127f6f7561cab065643d12b151f9bb4ab411aca"},"cell_type":"code","source":"# Testing data features\napp_test = pd.read_csv('../input/test.csv')\nprint('Testing data shape: ', app_test.shape)\napp_test = app_test.merge(ownership, on = 'building_id', how = 'left')\napp_test = app_test.merge(structure, on = 'building_id', how = 'left')\napp_test.drop(['district_id_x', 'district_id_y', 'vdcmun_id_x', 'vdcmun_id_y', 'ward_id_y'], axis=1, inplace=True)\nprint('Testing data shape: ', app_test.shape)\napp_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f135f3e577071e3306fa118ebb941f3a92856528"},"cell_type":"code","source":"#Converting the object target to int type\ntarget = {'Grade 1': 1, 'Grade 2': 2, 'Grade 3': 3, 'Grade 4': 4, 'Grade 5': 5}\napp_train['damage_grade'].replace(target, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3317a7ca216feca3f71712e8dd6a87b1a29202c"},"cell_type":"code","source":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7824890ad439934186ce833bfba6a1aeae2bd16f"},"cell_type":"code","source":"#identify null values in main data train & finding its impact on target values\nmissing_values_table(app_train)\n# app_train[app_train['has_repair_started'].isnull()]['damage_grade'].plot.hist()\n#app_train[app_train['count_families'].isnull()]['damage_grade'].plot.hist()\n#app_train['damage_grade'].plot.hist()\n\n#Registering anomaly info in dataset before imputing it\napp_train['has_repair_started_flag'] = app_train['has_repair_started'].isnull()\n#app_train['has_repair_started_flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a862d091850717ba5d168d9cac7f3507a76949d"},"cell_type":"code","source":"#identify null values in main data test, like train data\nmissing_values_table(app_test)\napp_test['has_repair_started_flag'] = app_test['has_repair_started'].isnull()\napp_test['has_repair_started_flag'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccede3d47e2342327df0e2613ef0101d9caa55f9"},"cell_type":"markdown","source":"**Feature Engineering**"},{"metadata":{"trusted":true,"_uuid":"b4495a1a683256f25005aff874ec142ca0edff53"},"cell_type":"code","source":"app_train['foundation_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ec0a79a79c61eb53c14dade7bffc2c3992317dd"},"cell_type":"code","source":"# app_train['count_floors_change'] = ((app_train['count_floors_post_eq']-app_train['count_floors_pre_eq'])*100)/app_train['count_floors_pre_eq']\n# app_train['height_ft_change'] = ((app_train['height_ft_post_eq']-app_train['height_ft_pre_eq'])*100)/app_train['height_ft_pre_eq']\n# app_test['count_floors_change'] = ((app_test['count_floors_post_eq']-app_test['count_floors_pre_eq'])*100)/app_test['count_floors_pre_eq']\n# app_test['height_ft_change'] = ((app_test['height_ft_post_eq']-app_test['height_ft_pre_eq'])*100)/app_test['height_ft_pre_eq']\n\napp_train['count_floors_change'] = (app_train['count_floors_post_eq']/app_train['count_floors_pre_eq'])\napp_train['height_ft_change'] = (app_train['height_ft_post_eq']/app_train['height_ft_pre_eq'])\napp_test['count_floors_change'] = (app_test['count_floors_post_eq']/app_test['count_floors_pre_eq'])\napp_test['height_ft_change'] = (app_test['height_ft_post_eq']/app_test['height_ft_pre_eq'])\n\napp_train.drop(['count_floors_post_eq', 'height_ft_post_eq'], axis=1, inplace=True)\napp_test.drop(['count_floors_post_eq', 'height_ft_post_eq'], axis=1, inplace=True)\n# app_train['height_ft_change'].plot.hist()\n#app_train.plot(x='count_floors_pre_eq', y='count_floors_post_eq', style='o')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"072a814a21a9ba59c16ca792238334047616b7ae"},"cell_type":"code","source":"\nfor i in ['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other']:\n    app_train[i+'_age'] = app_train[i] * app_train['age_building']\n    app_test[i+'_age'] = app_test[i] * app_test['age_building']\napp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99e1300ccc387c69ff1c4789418c94320a79c14e"},"cell_type":"code","source":"# for i in ['has_secondary_use', 'has_secondary_use_hotel', 'has_secondary_use_rental', 'has_secondary_use_institution']:\n#     app_train[i+'_age'] = app_train[i] * app_train['age_building']\n#     app_test[i+'_age'] = app_test[i] * app_test['age_building']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd59eb7c29aaf820a2f511772ce9dcee56d19895"},"cell_type":"markdown","source":"**Column Types**\n\nProcessing categorical variables"},{"metadata":{"trusted":true,"_uuid":"e43f0ed2f978f2f19ff4ba717c5eabe2b0283b54"},"cell_type":"code","source":"print(app_train.select_dtypes('object').nunique())\nprint(app_test.select_dtypes('object').nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41f3090ab2d9759c3553696658b7b6965648de92"},"cell_type":"code","source":"#Remove column 'building_id' as it is unique for every row & doesnt have any impact\ntrain_building_id = app_train['building_id']\ntest_building_id = app_test['building_id']\napp_train.drop(['building_id'], axis=1, inplace=True)\napp_test.drop(['building_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7b6063905d09e1d15aa41cf0cb2afba282faa29"},"cell_type":"code","source":"# one-hot encoding of categorical variables\napp_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad66ffe019594bd6fd6cd851afdfdc9f1ccdb9e6"},"cell_type":"code","source":"for i in ['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone', 'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick', 'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered', 'has_superstructure_rc_engineered', 'has_superstructure_other']:\n    app_train[i+'_mortar_foundation'] = app_train[i] * app_train['foundation_type_Mud mortar-Stone/Brick']\n    app_test[i+'_mortar_foundation'] = app_test[i] * app_test['foundation_type_Mud mortar-Stone/Brick']\n    \nfor i in ['has_geotechnical_risk', 'has_geotechnical_risk_fault_crack', 'has_geotechnical_risk_flood', 'has_geotechnical_risk_land_settlement', 'has_geotechnical_risk_landslide', 'has_geotechnical_risk_liquefaction', 'has_geotechnical_risk_other', 'has_geotechnical_risk_rock_fall']:\n    app_train[i+'_mortar_foundation'] = app_train[i] * app_train['foundation_type_Mud mortar-Stone/Brick']\n    app_test[i+'_mortar_foundation'] = app_test[i] * app_test['foundation_type_Mud mortar-Stone/Brick']\n    \napp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9133f2d8d4f4b8e26e20b57750b8c41d8a2e194"},"cell_type":"markdown","source":"**Anomalies**\n\nWork on finding anamalies in the dataset, check if any column has same number of unique vales as length of df or any outliers in the data"},{"metadata":{"trusted":true,"_uuid":"e35dfa89c30de77ca37bb4726da0acfe476affcb","scrolled":false},"cell_type":"code","source":"print(app_train.age_building.describe()) #No anomalies found\n#app_train.age_building.plot.hist()\n#print(app_train.age_building.value_counts().head(20))\n# app_test.describe()\n\n# Set the style of plots\nplt.style.use('fivethirtyeight')\n\n# Plot the distribution of ages in years\nplt.hist(app_train['age_building'], edgecolor = 'k', bins = 25, range=[0, 60])\nplt.title('Age Matrix'); plt.xlabel('Age'); plt.ylabel('Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f866def31885afbbfeb88e8553d2aadc04cc388"},"cell_type":"code","source":"plt.figure(figsize = (10, 8))\n\n# KDE plot for area_assesed_Building removed\nsns.kdeplot(app_train.loc[app_train['damage_grade'] == 1, 'age_building'], label = 'damage_grade == 1')\n# KDE plot for area_assesed_Building removed\nsns.kdeplot(app_train.loc[app_train['damage_grade'] == 2, 'age_building'], label = 'damage_grade == 2')\n# KDE plot for area_assesed_Building removed\nsns.kdeplot(app_train.loc[app_train['damage_grade'] == 3, 'age_building'], label = 'damage_grade == 3')\n# KDE plot for area_assesed_Building removed\nsns.kdeplot(app_train.loc[app_train['damage_grade'] == 4, 'age_building'], label = 'damage_grade == 4')\n# KDE plot for area_assesed_Building removed\nsns.kdeplot(app_train.loc[app_train['damage_grade'] == 5, 'age_building'], label = 'damage_grade == 5')\n\n# Labeling of plot\nplt.xticks([0, 20, 40, 50, 60,80, 100])\nplt.xlabel('Building Age'); plt.ylabel('Age'); plt.title('Age');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3e46217fc4dd6b9cfc89ab90c0109de814f601c9"},"cell_type":"markdown","source":"**Correlations**\n\nNow that we have dealt with the categorical variables and the outliers, let's continue with the EDA.\n\nThe correlation coefficient is not the greatest method to represent \"relevance\" of a feature, but it does give us an idea of possible relationships within the data. Some general interpretations of the absolute value of the correlation coefficent are:\n\n\n.00-.19 “very weak”\n\n.20-.39 “weak”\n\n.40-.59 “moderate”\n\n.60-.79 “strong”\n\n.80-1.0 “very strong”"},{"metadata":{"trusted":true,"_uuid":"86ba352e8a3ad60c9c0e1625f542ed1309c4794d","scrolled":true},"cell_type":"code","source":"# Find correlations with the target and sort\ncorrelations = app_train.corr()['damage_grade'].sort_values()\n\n# Display correlations\nprint('Most Positive Correlations:\\n', correlations.tail(10))\nprint('\\nMost Negative Correlations:\\n', correlations.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8eb8a641ed2e98f24178d17c60f8ea252cde0fb"},"cell_type":"code","source":"def plot_feature_importances(df):\n    \"\"\"\n    Plot importances returned by a model. This can work with any measure of\n    feature importance provided that higher importance is better. \n    \n    Args:\n        df (dataframe): feature importances. Must have the features in a column\n        called `features` and the importances in a column called `importance\n        \n    Returns:\n        shows a plot of the 15 most importance features\n        \n        df (dataframe): feature importances sorted by importance (highest to lowest) \n        with a column for normalized importance\n        \"\"\"\n    \n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n\n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    # Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee219bd38977667ec7c3ff20a9f598bc537b1cb9"},"cell_type":"code","source":"imp_features=['area_assesed_Building removed', 'condition_post_eq_Damaged-Rubble unclear', 'condition_post_eq_Damaged-Rubble clear' ,'area_assesed_Both', 'condition_post_eq_Not damaged','has_repair_started_flag']\nscor = app_train[imp_features+['damage_grade']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3369dbb1b7d8f823c9ed4fc16acf91acd413af1","scrolled":true},"cell_type":"code","source":"# # Set the style of plots\nplt.style.use('fivethirtyeight')\n\n# Plot the distribution of ages in years\nplt.hist(scor['area_assesed_Building removed'], edgecolor = 'k', bins = 10)\nplt.title('Area assessed'); plt.xlabel('Area'); plt.ylabel('Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b1eae63f090be14bc12d595f67f6a0829e3004b","scrolled":true},"cell_type":"code","source":"plt.figure(figsize = (5, 4))\n\n# KDE plot for area_assesed_Building removed\nsns.kdeplot(scor.loc[scor['area_assesed_Building removed'] == 0, 'damage_grade'], label = 'area_assesed == 0')\n# KDE plot for area_assesed_Building removed\nsns.kdeplot(scor.loc[scor['area_assesed_Building removed'] == 1, 'damage_grade'], label = 'area_assesed == 1')\n\n# Labeling of plot\nplt.xlabel('Damage Grade'); plt.ylabel('Density'); plt.title('Area');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1263bd752900a7e80086544fe5c1d2f2d83f277e"},"cell_type":"code","source":"# Area information into a separate dataframe\narea_data = scor[['damage_grade', 'area_assesed_Building removed']]\narea_data.groupby('damage_grade').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0885f4d4d77bb49fc76a2f98737abbcbbd5c077f"},"cell_type":"code","source":"# Area information into a separate dataframe\narea_data = scor[['damage_grade', 'area_assesed_Both']]\narea_data.groupby('damage_grade').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d11a779aa68da6c5d015426abdca133b0d9716a1"},"cell_type":"code","source":"plt.figure(figsize = (5, 4))\n\n# KDE plot for area_assesed_Both\nsns.kdeplot(scor.loc[scor['area_assesed_Both'] == 0, 'damage_grade'], label = 'area_assesed_both == 0')\n# KDE plot for area_assesed_Both\nsns.kdeplot(scor.loc[scor['area_assesed_Both'] == 1, 'damage_grade'], label = 'area_assesed_both == 1')\n\n# Labeling of plot\nplt.xlabel('Damage Grade'); plt.ylabel('Density'); plt.title('Area');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7aefbd8ad232df024c2a5f6ef8bd5298712ed848"},"cell_type":"code","source":"# Area information into a separate dataframe\narea_data = scor[['damage_grade', 'has_repair_started_flag']]\narea_data.groupby('damage_grade').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eddc00953849f89c3aaeb43a76cb5e95a80d1c48"},"cell_type":"code","source":"plt.figure(figsize = (5, 4))\n\n# KDE plot for has_repair_started_flag\nsns.kdeplot(scor.loc[scor['has_repair_started_flag'] == 0, 'damage_grade'], label = 'area_assesed_both == 0')\n# KDE plot for has_repair_started_flag\nsns.kdeplot(scor.loc[scor['has_repair_started_flag'] == 1, 'damage_grade'], label = 'area_assesed_both == 1')\n\n# Labeling of plot\nplt.xlabel('Damage Grade'); plt.ylabel('Density'); plt.title('Area');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fda216c9213208af88d33b444d54983313fe65e7"},"cell_type":"code","source":"data_corrs = scor.corr()\ndata_corrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b5b82c6a46597c5ffdf78cad5f183e912959e44"},"cell_type":"code","source":"plt.figure(figsize = (8, 6))\n\n# Heatmap of correlations\nsns.heatmap(data_corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"639d357eebeebedcfb3e56e027923da66ea02bac"},"cell_type":"markdown","source":"**Prediction**\n\nUse of random forest, xgboost"},{"metadata":{"trusted":true,"_uuid":"309aed9350371fa89d77caf8113885dc2ba8db1d"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\n\ntrain_labels = app_train['damage_grade']\n# Drop the target from the training data\nif 'damage_grade' in app_train:\n    train = app_train.drop(columns = ['damage_grade'])\nelse:\n    train = app_train.copy()\n    \n# Feature names\nfeatures = list(train.columns)\n\n# Copy of the testing data\ntest = app_test.copy()\n\n# Median imputation of missing values\nimputer = SimpleImputer(strategy = 'median')\n\n# Scale each feature to 0-1\nscaler = MinMaxScaler(feature_range = (0, 1))\n\n# Fit on the training data\n# imputer.fit(train)\n\n# Transform both training and testing data\ntrain = imputer.fit_transform(train)\ntest = imputer.transform(test)\n\n# Repeat with the scaler\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b6c15d5871de8758f4c00fe415eeb7ab7fb2f1"},"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n# from xgboost import XGBRegressor\n\n# Make the random forest classifier\nclf = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n# print(clf.feature_importances_)\n\n# Make the model with the specified regularization parameter\n# clf = LogisticRegression(C = 0.0001)\n\n#Use XGBooster\n# clf = XGBRegressor(n_estimators=100, learning_rate=0.1, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00075445a9d737adac013c0fafb07e2a721dcfa9"},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.metrics import f1_score\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(\n    train, train_labels, test_size=0.25)\n# Train on the training data\n# clf.fit(X_train, y_train, early_stopping_rounds=5, \n#              eval_set=[(X_test, y_test)], verbose=True)\nclf.fit(X_train, y_train)\n\nf1_score(y_test, clf.predict(X_test), average='weighted')\n# clf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"605befdf3a60ddec40ad5c800886130f22b57e35"},"cell_type":"code","source":"# Extract feature importances\nfeature_importance_values = clf.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n# Show the feature importances for the default features\nfeature_importances_sorted = plot_feature_importances(feature_importances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3b5c4898625a71122fe14edc2243cb80c2ab2ca"},"cell_type":"code","source":"#Prediction with classifier\ny=clf.predict(test)\nprediction=pd.DataFrame({'building_id': test_building_id, 'damage_grade':y})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"232e19f5e3a2b565e86ab17de6a239097108a1f9"},"cell_type":"code","source":"prediction.damage_grade = np.round(prediction.damage_grade)\ntarget = {1: 'Grade 1', 2: 'Grade 2', 3: 'Grade 3', 4: 'Grade 4', 5: 'Grade 5'}\nprediction.damage_grade.replace(target, inplace=True)\nprediction.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"508ed11cea9fe27e40bfe622114028808c18683a"},"cell_type":"code","source":"#prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"899978be6121abbc62aca91f9ce557e57507b76e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}