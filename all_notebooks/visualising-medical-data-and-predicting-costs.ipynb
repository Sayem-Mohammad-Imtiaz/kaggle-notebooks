{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n# Visualisation Credits \n\n# 1) Janio Martinez Backman\n# Distribution of Charges, Age Analysis, Weight Status vs Charges,Obesity and Smoking using plotly\n\n# 2) Dandelion \n# -Distribution of Age using seaborn","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pylab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16a862f445447796c292595b1344c9b07924478c"},"cell_type":"code","source":"# Plotly Packages\nfrom plotly import tools\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abf2d8795b3e28cc770836fe9feee0a7e1c43e91"},"cell_type":"code","source":"# Matplotlib and Seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom string import ascii_letters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f456113646f131cb70015f3ad47e80bcb1d9fb7b"},"cell_type":"code","source":"# Statistical Libraries\nfrom scipy.stats import norm\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3728971b700975f3cb8b55b4b1d734ee07fd1843"},"cell_type":"code","source":"# Regression Modeling\nimport statsmodels.api as sm\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0646af36b21651ac6441b921df36105173f6a2f1"},"cell_type":"code","source":"# Plotly offline is surprisingly inconsistent regarding when iplot works/ does not work, increasing data rate limit \n# hels. If not a permanent and solution would be using the online api with user credentials and links to plots\n\n# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n\n\n# Path for installing new packages (<the output> -m pip install pandas)\nfrom sys import executable\nprint(executable)\n\n# Install packages to the python 3 kernel in jupyter notebook\n# //anaconda/envs/ipykernel_py3/bin/python -m pip install <package-name>","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddca852f1b39e48718417afd757a7e7510b84d00"},"cell_type":"code","source":"#df = pd.read_csv(\"insurance.csv\")\ndf = pd.read_csv(\"../input/insurance.csv\")\ndf.head()\n\n# Let's store the original dataframe in another variable.\noriginal_df = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc60532aa902617b0fced8b2d27aa7146759110a"},"cell_type":"code","source":"# Distribution of Medical Charges\n\n# Types of Distributions: We have a right skewed distribution in which most patients are being charged \n# between  2000− 12000. Using Logarithms: Logarithms helps us have a normal distribution which could help us in \n# a number of different ways such as outlier detection\n\ncharge_dist = df[\"charges\"].values\nlogcharge = np.log(df[\"charges\"])\n\ntrace0 = go.Histogram(\n    x=charge_dist,\n    histnorm='probability',\n    name=\"Charges Distribution\",\n    marker = dict(\n        color = '#FA5858',\n    )\n)\ntrace1 = go.Histogram(\n    x=logcharge,\n    histnorm='probability',\n    name=\"Charges Distribution using Log\",\n    marker = dict(\n        color = '#58FA82',\n    )\n)\n\nfig = tools.make_subplots(rows=2, cols=1,\n                          subplot_titles=('Charge Distribution','Log Charge Distribution'),\n                         print_grid=False)\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\n\nfig['layout'].update(showlegend=True, title='Charge Distribution', bargap=0.05)\niplot(fig, filename='custom-sized-subplot-with-subplot-titles')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f82bf3f799c52a24101af0a51ce170bffc93c85c"},"cell_type":"code","source":"# Age Analysis:\n\n# Turning Age into Categorical Variables:\n# Young Adult: from 18 - 35\n# Senior Adult: from 36 - 55\n# Elder: 56 or older\n# Share of each Category: Young Adults (42.9%), Senior Adults (41%) and Elder (16.1%)\n\ndf['age_cat'] = np.nan\nlst = [df]\n\nfor col in lst:\n    col.loc[(col['age'] >= 18) & (col['age'] <= 35), 'age_cat'] = 'Young Adult'\n    col.loc[(col['age'] > 35) & (col['age'] <= 55), 'age_cat'] = 'Senior Adult'\n    col.loc[col['age'] > 55, 'age_cat'] = 'Elder'\n    \n    \nlabels = df[\"age_cat\"].unique().tolist()\namount = df[\"age_cat\"].value_counts().tolist()\n\ncolors = [\"#ff9999\", \"#b3d9ff\", \" #e6ffb3\"]\n\ntrace = go.Pie(labels=labels, values=amount,\n               hoverinfo='label+percent', textinfo='value', \n               textfont=dict(size=20),\n               marker=dict(colors=colors, \n                           line=dict(color='#000000', width=2)))\n\ndata = [trace]\nlayout = go.Layout(title=\"Amount by Age Category\")\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='basic_pie_chart')\n\nplt.figure(figsize=(12,5))\nplt.title(\"Distribution of age\")\nax = sns.distplot(df[\"age\"], color = 'g')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b620d1619a686a0c28fbfe9562bd22d280efc347"},"cell_type":"code","source":"# Weight Status: \n# https://www.cancer.org/cancer/cancer-causes/diet-physical-activity/body-weight-and-cancer-risk/adult-bmi.html  \n# Turning BMI into Categorical Variables:  \n# Under Weight: Body Mass Index (BMI)  <  18.5 \n# Normal Weight: Body Mass Index (BMI)  ≥  18.5 and Body Mass Index (BMI)  <  24.9 \n# Overweight: Body Mass Index (BMI)  ≥  25 and Body Mass Index (BMI)  <  29.9 \n# Obese: Body Mass Index (BMI)  >  30\n\ndf[\"weight_condition\"] = np.nan\nlst = [df]\n\nfor col in lst:\n    col.loc[col[\"bmi\"] < 18.5, \"weight_condition\"] = \"Underweight\"\n    col.loc[(col[\"bmi\"] >= 18.5) & (col[\"bmi\"] < 24.986), \"weight_condition\"] = \"Normal Weight\"\n    col.loc[(col[\"bmi\"] >= 25) & (col[\"bmi\"] < 29.926), \"weight_condition\"] = \"Overweight\"\n    col.loc[col[\"bmi\"] >= 30, \"weight_condition\"] = \"Obese\"\n    \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bce03cc29b1eab4e2d62976fb52a52a35346de01"},"cell_type":"code","source":"# Weight Status vs Charges\n\n# Overweight: Notice how there are two groups of people that get significantly charged more than the other group of overweight people.\n# Obese: Same thing goes with the obese group, were a significant group is charged more than the other group.\n\nfig = ff.create_facet_grid(\n    df,\n    x='age',\n    y='charges',\n    color_name='weight_condition',\n    show_boxes=False,\n    marker={'size': 10, 'opacity': 1.0},\n    colormap={'Underweight': 'rgb(208, 246, 130)', 'Normal Weight': 'rgb(166, 246, 130)',\n             'Overweight': 'rgb(251, 232, 238)', 'Obese': 'rgb(253, 45, 28)'}\n)\n251, 232, 238\n\n\nfig['layout'].update(title=\"Weight Status vs Charges\", width=800, height=600, plot_bgcolor='rgb(251, 251, 251)', \n                     paper_bgcolor='rgb(255, 255, 255)')\n\n\niplot(fig, filename='facet - custom colormap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"655838876e63df3232e688b9dfc6bbe2f3d92461"},"cell_type":"code","source":"# What Percentage of Obese that Smoked Paid aBove Average from the total obese patients?\n# 79% of Obese were non-smokers while the 21% left were smokers\n\ntotal_obese = len(df.loc[df[\"weight_condition\"] == \"Obese\"])\n\nobese_smoker_prop = len(df.loc[(df[\"weight_condition\"] == \"Obese\") & (df[\"smoker\"] == \"yes\")])/total_obese\nobese_smoker_prop = round(obese_smoker_prop, 2)\n\nobese_nonsmoker_prop = len(df.loc[(df[\"weight_condition\"] == \"Obese\") & (df[\"smoker\"] == \"no\")])/total_obese\nobese_nonsmoker_prop = round(obese_nonsmoker_prop, 2)\n\n\n# Average charge by obese_smokers and obese_nonsmoker\ncharge_obese_smoker = df.loc[(df[\"weight_condition\"] == \"Obese\") & (df[\"smoker\"] == \"yes\")].mean().iloc[3]\ncharge_obese_nonsmoker = df.loc[(df[\"weight_condition\"] == \"Obese\") & (df[\"smoker\"] == \"no\")].mean().iloc[3]\n\n\nprint(\"The percentage of obese smokers is \",obese_smoker_prop * 100)\nprint(\"The average charge for an obese smoker is \", round(charge_obese_smoker,2))\nprint(\"************************************************************\")\nprint(\"The percentage of obese non-smokers is \",obese_nonsmoker_prop * 100)\nprint(\"The average charge for an obese non-smoker is \", round(charge_obese_nonsmoker,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d2eb688bfdccde4913f8a37d802a90fedbc5dd1"},"cell_type":"code","source":"# Two subplots one with weight condition and the other with smoker.\n\nf, (ax1, ax2) = plt.subplots(ncols=2, figsize=(18,8))\nsns.scatterplot(x=\"bmi\", y=\"charges\", hue=\"weight_condition\", data=df, palette=\"Set1\", ax=ax1)\nax1.set_title(\"Relationship between Charges and BMI by Weight Condition\")\nax1.annotate('Obese Cluster \\n (Does this cluster has \\n the Smoking Attribute?)', xy=(37, 50000), xytext=(30, 60000),\n            arrowprops=dict(facecolor='black'),\n            fontsize=12)\nsns.scatterplot(x=\"bmi\", y=\"charges\", hue=\"smoker\", data=df, palette=\"Set1\", ax=ax2)\nax2.set_title(\"Relationship between Charges and BMI by Smoking Condition\")\nax2.annotate('Obese Smoker Cluster ', xy=(35, 48000), xytext=(20, 60000),\n            arrowprops=dict(facecolor='black'),\n            fontsize=12)\nax2.annotate('The Impact of Smoking to \\n Charges on other \\n Weight Conditions ', xy=(25, 26000), xytext=(17, 40000),\n            arrowprops=dict(facecolor='black'),\n            fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4238858f82a154241104a12d23c85cde82589383"},"cell_type":"code","source":"# Separation in Charges between Obese Smokers vs Non-Obese Smokers\n# In this chart we can visualize how can separate obese smokers and obese non-smokers into different clusters \n# of groups. Therefore, we can say that smoking is a characteristic that definitely affects patient's charges.\n\n\n# Creating a Scatter Plot with all the Obese\n\nobese_smoker = df.loc[(df[\"weight_condition\"] == \"Obese\") & (df[\"smoker\"] == \"yes\")]\nobese_nonsmoker = df.loc[(df[\"weight_condition\"] == \"Obese\") & (df[\"smoker\"] == \"no\")]\n\n\ntrace0 = go.Scatter(\n    x = obese_smoker[\"age\"].values,\n    y = obese_smoker[\"charges\"].values,\n    name = 'Smokers',\n    mode = 'markers',\n    marker = dict(\n        size = 10,\n        color = '#DF0101',\n        line = dict(\n            width = 2,\n            color = 'rgb(0, 0, 0)'\n        )\n    )\n)\n\ntrace1 = go.Scatter(\n    x = obese_nonsmoker[\"age\"].values,\n    y = obese_nonsmoker[\"charges\"].values,\n    name = 'Non-Smokers',\n    mode = 'markers',\n    marker = dict(\n        size = 10,\n        color = '#00FF40',\n        line = dict(\n            width = 2,\n        )\n    )\n)\n\ndata = [trace0, trace1]\n\nlayout = dict(title = 'Clear Separation between Obese Smokers and Non-Smokers in Charges',\n              yaxis = dict(zeroline = False,\n                          title=\"Patient Charges\",\n                          titlefont=dict(size=16)),\n              xaxis = dict(zeroline = False,\n                          title=\"Age of the Patient\",\n                          titlefont=dict(\n                          size=16))\n             )\n\nfig = dict(data=data, layout=layout)\niplot(fig, filename='styled-scatter')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c44b3b9569640c788e027aacc47953603460e744"},"cell_type":"code","source":"# Predicting cost of treatment with linear regression\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n#new_df = original_df.copy()\n\n# Sex\n\nle.fit(df.sex.drop_duplicates()) \ndf.sex = le.transform(df.sex)\n\n# Smoking Staus\n\nle.fit(df.smoker.drop_duplicates()) \ndf.smoker = le.transform(df.smoker)\n\n# Region\n\nle.fit(df.region.drop_duplicates()) \ndf.region = le.transform(df.region)\n\n# Age Category (Our created variable)\n\nle.fit(df.age_cat.drop_duplicates()) \ndf.age_cat = le.transform(df.age_cat)\n\n# Weight Condition (Our created variable)\n\nle.fit(df.weight_condition.drop_duplicates()) \ndf.weight_condition = le.transform(df.weight_condition)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f078930c775ca8336476d54327f1e9466498604"},"cell_type":"code","source":"# x = df.drop(['charges'], axis = 1)\nx = df[['sex','children','smoker','age','bmi']]\ny = df.charges\n\nx_train,x_test,y_train,y_test = train_test_split(x,y, random_state = 0)\nlr = LinearRegression().fit(x_train,y_train)\n\ny_train_pred = lr.predict(x_train)\ny_test_pred = lr.predict(x_test)\n\nscore = round(lr.score(x_test,y_test)*100,2)\n\n# model evaluation\nrmse = mean_squared_error(y_test, y_test_pred)\nr2 = r2_score(y_test, y_test_pred)\n\n# printing values\nprint('Slope:' ,lr.coef_)\nprint('Intercept:', lr.intercept_)\nprint('Root mean squared error: ', rmse)\nprint('R2 score: ', r2)\n\n# predicted values\n\nplt.plot(x_test,y_test_pred, color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"630bc623315887b6945e197f33c5fb3f5f1dce04"},"cell_type":"code","source":"# This Linear Regression yields graph with many dimensions which we cannot plot since the dimension of the \n# graph increases as our features increase. In your case, X has four features. Scatter plot takes argument with \n# only one feature in X and only one class in y. We try taking only one feature for X (a continuous variable like age \n# or bmi) and plot a scatter plot. By doing so we will be able to study the effect of each feature on the dependent \n# variable (which is easier to comprehend than multidimensional plots). \n\n\nf, ax = plt.subplots()\nf.set_figheight(15)\nf.set_figwidth(15)\nf.suptitle('Effect of Age and BMI on Charges', fontsize=20)\n\n\n#Age\nplt.subplot(2,2,1)\nplt.scatter(x_test['age'],y_test, color=\"blue\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Charges\")\nplt.subplot(2,2,2)\nplt.scatter(x_test['age'],y_test_pred, color=\"red\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Predicted Charges\")\n\n#BMI\n\nplt.subplot(2,2,3)\nplt.scatter(x_test['bmi'],y_test, color=\"blue\")\nplt.xlabel(\"BMI\")\nplt.ylabel(\"Charges\")\nplt.subplot(2,2,4)\nplt.scatter(x_test['bmi'],y_test_pred,color=\"red\")\nplt.xlabel(\"BMI\")\nplt.ylabel(\"Predicted Charges\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de2ca4a69662a5cd27038edba585f7c96b9a4380"},"cell_type":"code","source":"# Predicting Insurance cost using Regression in Deep Learning\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# There are two different keras versions of tensorflow and pure keras. They don't not work together. \n# You have to change everything to one version\n\nx = df[['sex','children','smoker','age','bmi']]\ny = df.charges\n\nx_train,x_test,y_train,y_test = train_test_split(x,y, random_state = 0)\n\n#model=Sequential()\n#model.add(Dense(1,activation='relu',kernel_initializer='uniform',input_dim=4))\n#model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n#model.fit(x_train,y_train,epochs=10,batch_size=1)\n#predictions=model.predict(x_test)\n#print(predictions)\n\ndef build_model():\n  model = Sequential([\n    # Input Layer\n    Dense(12, input_dim=5, activation='relu'),\n    # Hidden Layers\n    Dense(8, activation='relu'),\n    Dense(4, activation='relu'),\n    # Output Layer\n   Dense(1, activation='linear')\n  ])\n\n\n  model.compile(loss='mse',\n                optimizer='rmsprop',\n                metrics=['accuracy'])\n  return model\n\nmodel = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2192ab883b29d020e2ca883d0ef06e69c76d574"},"cell_type":"code","source":"history=model.fit(x_train,y_train,epochs=300,batch_size=5)\ny_test_pred=model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d2cd03ea63fc457204364b02bbae2ea48e31fa5"},"cell_type":"code","source":"score=round(r2_score(y_test,y_test_pred)*100,2)\nprint(\"Our Artificial Neural Network Model predicts the cost of treatment with around\",score,\"% accuracy \\n\")\n\nx = range(335)\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.scatter(x, y_test, s=10, c='b', marker=\"s\", label='Real Values')\nax1.scatter(x, y_test_pred, s=10, c='r', marker=\"o\", label='Predicted')\nplt.legend(loc='upper left');\nplt.show()\n\n#The training set is fixed, but we set the initial weights of the neural network to a random value in a small range, \n# so each time you train the network you get slightly different results. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a835302744518227a610e68db8d3c546ead72c7a"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=50,max_depth=None,min_samples_split=4,min_samples_leaf=2)\nregressor.fit(x_train,y_train)\nscore = round(regressor.score(x_test,y_test),2)*100\nprint(\"Our Random Forest Regression Model predicts the cost of treatment with around\",score,\"% accuracy \\n\")\n\nx = range(335)\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.scatter(x, y_test, s=10, c='b', marker=\"s\", label='Real Values')\nax1.scatter(x, y_test_pred, s=10, c='r', marker=\"o\", label='Predicted')\nplt.legend(loc='upper left');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"badecf5fc20a7671200c7b25cae072398a798a9a"},"cell_type":"code","source":"#  This algorithm is also a great choice, if you need to develop a model in a short period of time. On top of that, \n# it provides a pretty good indicator of the importance it assigns to your features. Random Forests are also very \n# hard to beat in terms of performance. A more accurate prediction requires more trees, which results \n# in a slower model.\n\n# In the healthcare domain it is used to identify the correct combination of components in medicine and to analyze \n# a patient’s medical history to identify diseases.\n\n# When we use LabelEncoder the model will interpret the data to be in some kind of order, 0 < 1 < 2. \n# This is true for bmi, smoking status, age category and weight condtion, but not for things like region (city,country)\n# To overcome this problem, we use One Hot Encoder.\n\n# In eandom forest algorithm it is very easy to measure the relative importance of each feature on the prediction. \n# A general rule in machine learning is that the more features you have, the more likely your model will suffer from \n# overfitting and vice versa.\n\nimportances = pd.DataFrame({'feature':x_train.columns,'importance':np.round(regressor.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.head()\n\n# We could go read the research papers on the random forest and try to theorize the best hyperparameters, \n# but a more efficient use of our time is just to try out a wide range of values and see what works\n\n# n_estimators = number of trees in the foreset\n# max_features = max number of features considered for splitting a node\n# max_depth = max number of levels in each decision tree\n# min_samples_split = min number of data points placed in a node before the node is split\n# min_samples_leaf = min number of data points allowed in a leaf node\n# bootstrap = method for sampling data points (with or without replacement)\nimportances.plot.bar()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}