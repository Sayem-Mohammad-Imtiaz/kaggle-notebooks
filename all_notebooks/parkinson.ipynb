{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Parkinson Dataset\n## Γενικές πληροφορίες για το σετ δεδομένων\n\nΑυτό το σετ δεδομένων αποτελείται από ηχητικές ιατρικές μετρήσεις 42 ανθρώπων με την ασθένεια Parkinson σε αρχικό στάδιο. Οι άνθρωποι αυτοί προσλήφθηκαν για μια εξάμηνη δοκιμή μιας συσκευής τηλεπαρακολούθησης για εξ αποστάσεως διάγνωση της ασθένειας. Τα δεδομένα καταγράφονταν αυτόματα στα σπίτια των ασθενών.\n\nΟι στήλες περιλαμβάνουν έναν index number του κάθε ασθενή, την ηλικία του, το φύλο του, την χρονική διάρκεια από την αρχική ημερομηνία πρόσληψης, δύο δείκτες motor UPDRS και total UPDRS, και 16 άλλες ιατρικές ηχητικές μετρήσεις. Κάθε γραμμή σχετίζεται με ένα εκ των 5,875 διαφορετικών ηχητικών μετρήσεων από αυτούς του εθελοντές. **Ο κύριος στόχος μας είναι να προβλέψουμε τους δείκτες UPDRS (δηλαδή το 'motor_UPDRS' και 'total_UPDRS') από τις 16 ηχητικές μετρήσεις.**\n\nΜερικά ακόμα στοιχεία που μας δίνονται για το σετ δεδομένων είναι τα παρακάτω:\n\n* subject - Integer that uniquely identifies each subject\n* age - Subject age\n* sex - Subject gender '0' - male, '1' - female\n* test_time - Time since recruitment into the trial. The integer part is the \n* number of days since recruitment.\n* motor_UPDRS - Clinician's motor UPDRS score, linearly interpolated\n* total_UPDRS - Clinician's total UPDRS score, linearly interpolated\n* Jitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of \n* variation in fundamental frequency\n* Shimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - \n* Several measures of variation in amplitude\n* NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n* RPDE - A nonlinear dynamical complexity measure\n* DFA - Signal fractal scaling exponent\n* PPE - A nonlinear measure of fundamental frequency variation\n\nΟπότε αρχικά φορτώνουμε κάποιες χρήσιμες βιβλιοθήκες και το σετ δεδομένων μας."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport scipy as sc\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Βλέπουμε ότι στο σύνολο δεδομένων μας υπάρχει ένα feature με το όνομα `subject#`, το οποίο ουσιαστικά μας δείχνει ποιός ασθενής είναι ο καθένας. Η διάταξη του όμως δεν έχει κάποιο νόημα (είναι μη διατεταγμένο), οπότε μπορεί να μπερδέψει στην συνέχεια την εκπαίδευση των ταξινομητών μας. Θα πρέπει λοιπόν να βρούμε έναν τρόπο να το χειριστούμε έτσι ώστε να μας δίνει μια πληροφορία που να έχει κάποιο νοημα.\n\nΜπορούμε είτε να μετατρέψουμε το feature αυτό με one-hot encoding είτε να το πετάξουμε τελείως. Η πρώτη μέθοδος θα μας πρόσθετε υπερβολικά πολλά χαρακτηριστικά, οπότε θα δοκιμάσουμε την δεύτερη. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/parkinsons-telemonitoring-data/telemonitoring_parkinsons_updrs.data.csv')\ndataset[0:30]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Στην συνέχεια βλέπουμε ότι υπάρχουν ονοματά στις στήλες (δηλαδή στα διαφορετικά features). Βλέπουμε συγκεκριμένα ότι έχουμε 22 διαφορετικές features και 5875 το πλήθος εγγραφές."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data Column Names:',dataset.columns)\nprint('Length of Column Name List:',len(dataset.columns))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Πετάμε τελείως την μεταβλητή `subject#` γιατί είναι μη διατεταγμένη και μπορεί να μπερδέψει τα δεδομένα μας."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(['subject#'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Πριν κάνουμε οτιδήποτε, πρέπει αν σιγουρευτούμε ότι δεν υπάρχουν missing values σε διάφορα χαρακτηριστικά. Αυτό είναι ένα σημαντικό βήμα, γιατί σε περίπτωση που υπάρχουν πρέπει να αποφασήσουμε πως θα πρέπει να τα χειριστούμε. Μπορούμε ας πούμε να τα διαγράψουμε είτε αν ακολουθήσουμε άλλες τεχνικές όπως είναι αυτές του Expectation Maximization (EM) ή το pseudo-EM.\n\nΣτην δικιά μας περίπτωση ευτυχώς δεν υπάρχουν καθόλου missing values, οπότε δεν θα μας απασχολήσει αυτό το πρόβλημα."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Χωρίζουμε τον πίνακα σε στοιχεία εισόδου και εξόδου \n\nX: Πίνακας Χαρακτηριστικών \n\nY: Πίνακας Ετικετών"},{"metadata":{"trusted":false},"cell_type":"code","source":"array = dataset.values\nX1 = array[:,0:4]\nX2 = array[:,6:]\nX = np.hstack((X1,X2))\nY = array[:,4:6]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Στην συνέχεια χωρίζουμε τα δεδομένα μας σε train και test, όπως φαίνεται παρακάτω. Φροντίζουμε το train set μας να είναι το 30% του αρχικού σετ δεδομένων μας."},{"metadata":{"trusted":false},"cell_type":"code","source":"# load and summarize the dataset\nfrom sklearn.model_selection import train_test_split\n\n# split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n\nprint('Train', X_train.shape, y_train.shape)\nprint('Test', X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection\n### Correlation\nΗ συσχέτιση (correlation) είναι ένα μέτρο που μας δείχνει εάν δύο τυχαίες μεταβλητές εξαρτώνται η μια από την άλλη. Το πιο κοινότυπο μέτρο συσχέτισης είναι αυτό της συσχέτισης Pearson, το οποίο υποθέτει ότι οι τυχαίες μας μεταβλητές κατανέμονται με Γκαουσιανή κανονική κατανομή και αναφέρεται στην γραμμική τους εξάρτηση.\n\nΤα μέτρα γραμμικής συσχέτισης είναι συνήθως στο διάστημα από -1 εώς 1 με το 0 να σημαίνει μη συσχέτιση. Για την εξαγωγή χαρακτησριστικών, ενδιαφερόμαστε να έχουμε ένα θετικό δείκτη. Όσο πιο μεγάλος είναι ο δέικτης συγκριτικά με την τυχαία μεταβλητή που θέλουμε να προβλέψουμε, σημαίνει ότι τα χαρακτηριστικά μας, είναι πολύ συσχετισμένες με αυτήν. Άρα έχουμε περισσότερες ελπίδες να φτιάξουμε ένα καλό μοντέλο με τέτοιου τύπου τυχαίες μεταβλητές.\n\nΈνας τρόπος να δούμε πόσο συσχετισμένες είναι οι τυχαίες μεταβλητές μας είναι με f-score. Το f-score είναι ένα μέτρο συσχέτισης, και προφανώς όσο πιο μεγάλο είναι για ένα χαρακτηριστικό, τόσοπιο πιθανό είναι να το κρατήσουμε στο τελικό μας μοντέλο.\n\nΣτην δικιά μας περίπτωση θέλουμε να προβλέψουμε δύο τυχαίες μεταβλητές y, αυτό σημαίνει ότι θα πρέπει να δούμε τις συσχετίσεις με κάθε μια από αυτές. Αρχικά λοιπόν μπορούμε να κάνουμε και ένα bar-plot με τα f-scores την πρώτη μεταβλητή motor UPDRS."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"from sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nfrom matplotlib import pyplot\n \n# feature selection\ndef select_features(X_train, y_train, X_test):\n\t# configure to select all features\n\tfs = SelectKBest(score_func=f_regression, k='all')\n\t# learn relationship from training data\n\tfs.fit(X_train, y_train)\n\t# transform train input data\n\tX_train_fs = fs.transform(X_train)\n\t# transform test input data\n\tX_test_fs = fs.transform(X_test)\n\treturn X_train_fs, X_test_fs, fs\n\n# feature selection\nX_train_fs, X_test_fs, fs = select_features(X_train, y_train[:,0], X_test)\n# what are scores for the features\nfor i in range(len(fs.scores_)):\n\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n# plot the scores\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Στην συνέχεια κάνουμε και ένα δεύτερο bar plot για την τυχαία μεταβλητή total UPDRS."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# feature selection\nX_train_fs, X_test_fs, fs = select_features(X_train, y_train[:,1], X_test)\n# what are scores for the features\nfor i in range(len(fs.scores_)):\n\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n# plot the scores\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mutual Information Feature Selection\n\nΠρόκειται για ένα μέτρο που προέρχεται από την θεωρία πληροφορίας. Το mutual information υπολογίζεται μεταξύ δύο μεταβλητών και μετράει την μείωση της αβεβαιότητας για μια τυχαία μεταβλητή, θεωρόντας γνωστή την τιμή μιας άλλης τυχαίας μεταβλητής.\n\nΜπορεί να χρησιμοποιηθεί με παρόμοιο τρόπο όπως και το f-score. Επομένως μπορούμε να θεωρήσουμε ότι τα k καλύτερα χαρακτηριστικά είναι αυτά με το μεγαλύτερο mutual information."},{"metadata":{"trusted":false},"cell_type":"code","source":"# example of mutual information feature selection for numerical input data\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression\nfrom matplotlib import pyplot\n\n# feature selection\ndef select_features(X_train, y_train, X_test):\n\t# configure to select all features\n\tfs = SelectKBest(score_func=mutual_info_regression, k='all')\n\t# learn relationship from training data\n\tfs.fit(X_train, y_train)\n\t# transform train input data\n\tX_train_fs = fs.transform(X_train)\n\t# transform test input data\n\tX_test_fs = fs.transform(X_test)\n\treturn X_train_fs, X_test_fs, fs\n \n# feature selection\nX_train_fs, X_test_fs, fs = select_features(X_train, y_train[:,0], X_test)\n# what are scores for the features\nfor i in range(len(fs.scores_)):\n\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n# plot the scores\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# feature selection\nX_train_fs, X_test_fs, fs = select_features(X_train, y_train[:,1], X_test)\n# what are scores for the features\nfor i in range(len(fs.scores_)):\n\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n# plot the scores\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filter method (Ηeatmap):\nΑπό την μια πλευρά ζητάμε να έχουμε συσχέτιση μεταξύ των features και των εξαρτημένων μεταβλητών y. Όμως από την άλλη μεριά (τουλάχιστον για να ισχύουν οι υποθέσεις του γραμμικού μοντέλου) θέλουμε τα feautures να είναι μεταξύ τους όσο το δυνατόν περισσότερο ασυσχέτιστα.\n\nΑσυσχέτιστα είναι τα features εάν έχουν τιμές κοντά στο μηδέν. Αν έχουν υψηλά correlations κατά απόλυτη τιμή (είτε θετικά είτε αρνητικά) τότε υπάρχει γενικά πρόβλημα. Πρέπει να προσπαθήσουμε να κρατήσουμε features με όσο το δυνατόν χαμηλότερες μεταξύ τους συσχετίσεις.\n\nΈνας τρόπος να δούμε τις συσχετίσεις μεταξύ των δεδομένων μας είναι με το heatmap."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = dataset.corr()\nsns.heatmap(cor, annot=False, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Επομένως μπορούμε να βάλουμε ένα threshold και να δούμε ποιές από τις τυχαίες μεταβλητές μας είναι περισσότερο θετικά συσχετισμένες με τις τυχαίες μεταβλητές y που θέλουμε να προβλέψουμε.\n\nΣτην προκειμένη περίπτωση βάζουμε ως threshlold το 0.1. Αυτός είναι και ένας τρόπος να κάνουμε επιλογή χαρακτηριστικών. Βέβαια με αυτόν τον τρόπο βλέπουμε πόσο συσχετισμένα είναι τα features με την y, όμως δεν ξέρουμε πόσο συσχετισμένα είναι μεταξύ τους. "},{"metadata":{"trusted":false},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor['motor_UPDRS'])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.1]\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor['total_UPDRS'])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.1]\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wrapper Method:\nΜια άλλη μέθοδος είναι να χρησιμοποιήσουμε έναν ταξινομητή machine learning και να τον δοκιμάσουμε επαναληπτικά σε υποσύνολα του αρχικού μας συνόλου δεδομένου, μέχρι να βρούμε σε ποιό από αυτά κάνει την καλύτερη πρόβλεψη. Πρόκειται για μια πιο ακριβή υπολογιστικά μέθοδο, αλλά είναι πιο ακριβής από τις προηγούμενες. Στην συγκεκριμένη περίπτωση χρησιμοποιούμε τον ταξινομητή oridnary least squares.\n\nΥπάρχουν αρκετοί τρόποι να κάνουμε αυτήν την διαδικασία. Εδώ θα χρησιμοποιήσουμε δύο από αυτές: το backward elimintaion και το RFE. \n\n#### i. Backward Elimination\nΌπως σημαίνει και το όνομα, αυτό που κάνουμε είναι να ξεκινάμε με ένα μοντέλο που περιέχει όλα όλα τα features και στην συνέχεια αρχίζουμε να αφαιρούμε επαναληπτικά ένα ένα αυτά τα features εξετάζοντας τον αλγόριθμο μηχανικής μάθησης που έχουμε επιλέξει, πότε έχει την καλύτερη δυνατή απόδοση.\n\nΕδώ εξετάζουμε την απόδοση του αλγορίθμου μας μέσω της μετρικής του p-value. Αν το p-value είναι μεγαλύτερο από 0.05 τότε αφαιρούμε το χακακτηριστικό, αλλιώς το κρατάμε."},{"metadata":{"trusted":false},"cell_type":"code","source":"import statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n\n#Adding constant column of ones, mandatory for sm.OLS model\nX_1 = sm.add_constant(X_train)\n#Fitting sm.OLS model\nmodel = sm.OLS(y_train[:,0],X_1).fit()\nmodel.pvalues","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Παραπάνω έχουμε κάνει ένα iteration. Θα αφαιρέσουμε χαρακτηριστικά με p-value>0.05. Μπορούμε να δημιουργήσουμε ένα loop και να κάνουμε επαναληπτικά αυτήν την διαδικασία μέχρι να καταλήξουμε στο καλύτερο δυνατό μοντέλο."},{"metadata":{"trusted":false},"cell_type":"code","source":"#Backward Elimination\ncols = list(pd.DataFrame(X_train).columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = pd.DataFrame(X_train)[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(pd.DataFrame(y_train[:,0]),X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ii. RFE (Recursive Feature Elimination)\n\nΕδώ πάλι αφαιρούμε χαρακτηριστικά μέχρις ότου να φτάσουμε στο βέλτιστο δυνατό μοντέλο. Η κύρια διαφορά είναι ότι πλέον χρησιμποιύμε accuracy score. Η RFE μέθοδος παίρνει ως input τον αριθμό των features που θέλουμε να έχουμε στο τελικό μας μοντέλο, καθώς και έναν ταξινομητή μέσω του οποίου θα υπολογίσουμε το accuracy score. Ως έξοδο μας εμφανίζει ένα ranking μεταξύ όλων των feautures που έχει κρατήσει."},{"metadata":{"trusted":false},"cell_type":"code","source":"model = LinearRegression()\n#Initializing RFE model\nrfe = RFE(model, 7)\n#Transforming data using RFE\nX_rfe = rfe.fit_transform(X_train,y_train[:,0])  \n#Fitting the data to model\nmodel.fit(X_rfe,y_train[:,0])\nprint(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Embedded Method\nΟι embedded methods είναι μέθοδοι για να κρατάμε προσεκτικά χαρατηριστικά που συμβάλουν περισσότερο σε κάθε iteration. Ένας τρόπος για να το κάνουμε αυτό είναι χρησιμοποιώντας regularization χρησιμοποιώντας ένα threshold ενός συντελεστή-δείκτη. Συγκεκριμένα θα χρησιμοποιήσουμε Lasso regularization. Αν ένα feature δεν σχετίζεται με το μοντέλο μας, βάζουμε συντελεστή 0 στο lasso. Και με αυτόν τον τρόπο όλα τα χαρακτηριστικά με συντελεστή 0 τα πετάμε από το μοντέλο μας."},{"metadata":{"trusted":false},"cell_type":"code","source":"reg = LassoCV()\nreg.fit(X_train, y_train[:,0])\nprint(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(X_train,y_train[:,0]))\ncoef = pd.Series(reg.coef_, index = pd.DataFrame(X_train).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"imp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Επιλογή χαρακτηριστικών\nΜπορούμε τώρα έχοντας κάνει όλη την παραπάνω δουλεία να διαλέξουμε ένα υποσύνολο των πιο σημαντικών features με τα οποία θα δουλέψουμε. Αυτό θα το κάνουμε κρατώντας μόνο εκείνα τα χαρακτηριστικά, τα οποία βρήκαμε στο προηγούμενο backward elimination."},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = pd.DataFrame(X_train)\nX_train = X_train[[0, 1, 2, 3, 4, 6, 9, 11, 12, 15, 16, 17, 18]]\nX_train = X_train.values\n\nX_test = pd.DataFrame(X_test)\nX_test = X_test[[0, 1, 2, 3, 4, 6, 9, 11, 12, 15, 16, 17, 18]]\nX_test = X_test.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Παρόλα αυτά, όπως βλέπουμε και παρακάτω, ακόμα υπάρχουν προβλήματα. Υπάρχουν ακόμα χαρακτηριστικά τα οποία είναι μεταξύ τους correlated. Συγκεκριμένα εάν δούμε τα `Shimmer, Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, Shimmer:APQ11, Shimmer:DDA`, αυτά έχουν στενές συσχετίσεις μεταξύ τους, κάτι που φαίνεται αρκετά λογικό, αφού μοιάζει να περιγράφουν παρόμοια πράγματα."},{"metadata":{"trusted":false},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = pd.DataFrame(X_train).corr()\nsns.heatmap(cor, annot=False, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Εκπαίδευση μοντέλων\nΣε αυτό το μέρος θα εκπαιδεύσουμε κάποιους παλινδρομητές, έτσι ώστε να μάθουν από τα δεδομένα μας και να κάνουν πρόβλεψη. Το πρώτο πράγμα που κάνουμε είναι να φορτώσουμε όλες τις βιβλιοθήκες της `sklearn` που θα μας χρειαστούν και στην συνέχεια.\n\nΟρίζουμε επίσης έναν scaler, και μια κλάση PCA που θα μας χρειαστούν στην συνέχεια για να κάνουμε το grid search με cross validation. Επίσης έχουμε δημιουργήσει μια συνάρτηση `compute_metrics`, η οποία δεδομένου ενός ταξινομητή που τον έχουμε κάνει fit σε κάποια δεδομένα, μας κάνει προβλέψεις, και υπολογίζει τις μετρικές $R^{2}$ και MSE για τα σύνολα εκπαίδευσης και ελέγχου."},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.decomposition import PCA\nfrom sklearn import linear_model\nfrom sklearn.svm import SVR\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport time\n\n# αρχικοποιούμε τους μετασχηματιστές χωρίς υπερ-παραμέτρους\nscaler = StandardScaler()\npca = PCA()\n\nn_components = [3, 5, 7, 8, 10, 12, 13]\n\ndef compute_metrics(model, x_tr, y_tr, x_ts, y_ts):\n    train_predict = model.predict(x_tr)\n    test_predict = model.predict(x_ts)\n\n    # Υπολογισμός Ορθότητας (Accuracy)\n    train_accuracy = r2_score(y_tr, train_predict)\n    test_accuracy = r2_score(y_ts, test_predict)\n\n    # Υπολογισμός Μέσου Τετραγωνικού Σφάλματος\n    train_MSE = mean_squared_error(y_tr, train_predict)\n    test_MSE = mean_squared_error(y_ts, test_predict)\n\n    print('Ορθότητα στο σύνολο δεδομένων εκπαίδευσης: {:.2%}'.format(\n      train_accuracy))\n    print('Ορθότητα στο σύνολο δεδομένων ελέγχου: {:.2%}\\n'.format(test_accuracy))\n    print('Μέσο Τετραγωνικό Σφάλμα στα δείγματα εκπαίδευσης: {:.4f}'.format(\n      train_MSE))\n    print('Μέσο Τετραγωνικό Σφάλμα στα δείγματα ελέγχου: {:.4f}'.format(test_MSE))\n    return train_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Εδώ ορίζουμε κάποια διανύσματα τα οποία βασικά θα μας χρειαστούν στην συνέχεια για να σχεδιάσουμε τα bar plots, που θα αποθηκεύουν τους χρόνους κάθε αλγορίθμου, τους χρόνους που χρειαζόμαστε για να τους κάνουμε tuning και τις μετρικές που βρίσκουμε από αυτούς."},{"metadata":{"trusted":false},"cell_type":"code","source":"names = ['Linear','Polynomial', 'Elastic-Net', 'Lasso', 'Tree', 'kNN', 'Forest', 'BGR']\ntimes = []\nCV_times = []\nr2 = []\nMSE = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Μέρος 1ο: Γραμμικά μοντέλα\nΑρχικά θα χρησιμοποιήσουμε γραμμικά μοντέλα. Είναι τα πιο κλασικά μοντέλα που μαθαίνει κανείς σε ένα πρώτο μάθημα στατιστικών προτύπων για να κάνει παλινδόμιση. Ας υπογραμμίσουμε ότι τόσο για το την γραμμική παλινδρόμιση όσο και για την πολυωνυμική παλινδρόμιση δεν χρειάζεται να κάνουμε tuning κάποια υπερπαράμετρο, μιας και για τον υπολογισμό των συντελεστών αυτών των μοντέλων το μόνο που πραγματικά που χρειάζεται είναι να κάνουμε ελαχιστοποίηση μιας συνάρτησης κόστους.\n\n#### Linear Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"start_time = time.time()\nclf = MultiOutputRegressor(LinearRegression())\nclf.fit(X_train, y_train)\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(clf, X_train, y_train, X_test, y_test)\ntimes.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nCV_times.append(0)\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Polynomial Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"pf2 = PolynomialFeatures(degree=2)\n\nx_train2 = pf2.fit_transform(X_train)\nx_test2 = pf2.fit_transform(X_test)\n\nstart_time = time.time()\nclf = lr = MultiOutputRegressor(LinearRegression())\nlr.fit(x_train2, y_train)\n\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(clf, x_train2, y_train, x_test2, y_test)\ntimes.append(time.time() - start_time)\n\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nCV_times.append(0)\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Elastic-Net\nΣτο elastic-net τώρα υπάρχουν κάποιες υπερπαράμετροι να ρυθμίσουμε. Για αυτόν τον λόγο κάνουμε ένα grid search με cross validation για να βρούμε τις βέλτιστες. Και βλέπουμε πράγματι ότι μετά από αυτήν την διαδικασία η ικανότητα πρόβλεψης και γενίκευσης του αλγορίθμου μας βελτιώνεται δραματικά. "},{"metadata":{"trusted":false},"cell_type":"code","source":"start_time = time.time()\nen = ElasticNet()\nen.fit(X_train,y_train)\ncompute_metrics(en, X_train, y_train, X_test, y_test)\ntimes.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"l1 = np.arange(0.1,1,0.2)\nalphas = np.arange(0,2,0.1)\npipe_en = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('ElasticNet', en)], memory = 'tmp')\nestimator_en = GridSearchCV(pipe_en, dict( pca__n_components=n_components, ElasticNet__alpha=alphas , ElasticNet__l1_ratio=l1), cv=5, scoring ='r2', n_jobs=-1)\nstart_time = time.time()\nestimator_en.fit(X_train, y_train)\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(estimator_en, X_train, y_train, X_test, y_test)\nCV_times.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lasso regression\nΠαρόμοια με τα προηγούμενα εργαζόμαστε και για την παλινδρόμιση του Lasso. Βλέπουμε και πάλι δραματική βελτίωση στην απόδοση μετά την διαδικασία του grid search."},{"metadata":{"trusted":false},"cell_type":"code","source":"start_time = time.time()\nlasso = linear_model.MultiTaskLasso()\nlasso.fit(X_train, y_train)\ncompute_metrics(lasso, X_train, y_train, X_test, y_test)\ntimes.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"alphas = np.arange(0.1,2,0.1)\npipe_lasso = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('lasso', lasso)], memory = 'tmp')\nestimator_lasso = GridSearchCV(pipe_lasso, dict( pca__n_components=n_components, lasso__alpha=alphas ), cv=5, scoring ='r2', n_jobs=-1)\nstart_time = time.time()\nestimator_lasso.fit(X_train, y_train)\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(estimator_lasso, X_train, y_train, X_test, y_test)\nCV_times.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Μέρος 2ο: Decission tree and k-Nearest Neighbors\n\nΤο Decission tree είναι ένας τρόπος να κάνουμε παλινδρόμιση, θέτοντας ερωτήσεις για τα δεδομένα μας. Τα δέντρα χρησιμοποιούν δύο συναρτήσεις impurity και total impurity έτσι ώστε να κάνουν τις 'βέλτιστες ερωτήσεις' για τα δεδομένα μας. Είναι μη γραμμικοί ταξινομητές, και έχουν διάφορες υπερπαραμέτρους όπως είναι ο συντελεστής CCP-a, το βάθος τους, ο αριθμός των nodes των φύλλων τους. Επίσης μπορούμε σε περίπτωση που έχει γίνει overfitting, να κάνουμε κλάδεμα του δέντρου έτσι ώστε να μην μαθαίνει υπερβολικά καλά τα δεδομένα εκπαίδευσης. \n\nΟ παλινδρομιτής kNN κάνει παλινδρόμιση, βλέποντας τις τιμές που έχουν οι κοντινότεροι γείτονες ενός στοιχείου στον χώρο των δεδομένων μας. Οι κύριες υπερπαράμετροι έχουν να κάνουν με τον αλγόριθμο τον οποίο μετράμε αποστάσεις στον χώρο των δεδομένων μας, καθώς και τον αριθμό των γειτόνων που κοιτάμε κάθε φορά."},{"metadata":{},"cell_type":"markdown","source":"#### Decission Tree Regressor\nΑυτός ο παλινδρομιτής παίρνει αρκετή ώρα για να tunarίστεί, επομένως κάναμε tuning μόνο στην παράμετρο CCP-a. Και πράγματι βελτιώνεται πολύ λίγο, βλέπουμε βέβαια ότι και χωρίς να κάνουμε grid search πετυχαίνουμε πολύ υψηλά scores. Αυτό προφανώς συμβαίνει γιατί τα δέντρα είναι πολύ ισχυροί μη γραμμικοί ταξινομητές, οπότε δεν χρειάζεται να κάνουμε πολύ tuning. \n\nΑς υπογραμμίσουμε επίσης ότι δεν κάναμε PCA. Το δοκιμάσαμε αλλά είδαμε ότι με PCA το grid search  βγάζει χειρότερα αποτελέσματα."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"start_time = time.time()\ntree = MultiOutputRegressor(DecisionTreeRegressor(random_state=0))\ntree.fit(X_train, y_train)\ncompute_metrics(tree, X_train, y_train, X_test, y_test)\ntimes.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"alphas = np.arange(0.0,2.0,0.2)\npipe_tree = Pipeline(steps=[('scaler', scaler), ('tree', tree)], memory = 'tmp')\ntreeCV = GridSearchCV(pipe_tree, dict(tree__estimator__ccp_alpha=alphas ), cv=5, scoring ='r2', n_jobs=-1)\n\nstart_time = time.time()\ntreeCV.fit(X_train, y_train)\n\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(treeCV, X_train, y_train, X_test, y_test)\nCV_times.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### k-Nearest neighbors\nΌσον αφορά τον kNN κάνουμε tuning δύο υπερπαραμέτρους που έχουν να κάνουν με τον αλγόριθμο που μετράει αποστάσεις, καθώς και τον αριθμό των κοντινότερων γειτόνων που χρησιμοποιούμε για να μάθουμε τα δεδομένα μας. Πάλι το PCA περισσότερο εμποδίζει, για αυτό από εδώ και στο εξής το έχουμε βγάλει. Βλέπουμε πάντως ότι η απόδοση του αλγορίθμου βελτιώνεται πάρα πολύ."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"neigh = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=3))\nstart_time = time.time()\nneigh.fit(X_train, y_train)\ncompute_metrics(neigh, X_train, y_train, X_test, y_test)\ntimes.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"algos = ['auto', 'ball_tree', 'kd_tree', 'brute']\nnum = [1,2,3,4,5,6]\npipe_neigh = Pipeline(steps=[('scaler', scaler), ('neigh', neigh)], memory = 'tmp')\nneighCV = GridSearchCV(pipe_neigh, dict( neigh__algorithm =algos, neigh__n_neighbors=num ), cv=5, scoring ='r2', n_jobs=-1)\n\nstart_time = time.time()\ntreeCV.fit(X_train, y_train)\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(treeCV, X_train, y_train, X_test, y_test)\nCV_times.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Μέρος 3ο: Μοντέλα Boosting-Ensemble\nΤα Random Forests είναι αλγόριθμοι που θυμίζουν πάρα πολύ τα δέντρα. Στην πραγματικότητα είναι συνδυασμοί από πολλά δέντρα μαζί και στην ουσία έχουν παρόμοιες υπερπαραμέτρους, για αυτό και εργαζόμαστε παρόμοια με τα δέντρα.\n\nΌσον αφορά το gradient boosting καταφεύγουμε στον ορισμό της Βικιπαίδειας:\n\n> Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.[1][2] When a decision tree is the weak learner, the resulting algorithm is called gradient boosted trees, which usually outperforms random forest. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function.\n\n####  Random Forest\nΌπως και στα δέντρα η απόδοση είναι ήδη πολύ υψηλή χωρίς τιουνάρισμα, οπότε μετα'την πλεγματική αναζήτηση βλεουμε πολύ μικρή αύξηση στην απόδοση."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"rd_for = MultiOutputRegressor(RandomForestRegressor(random_state=0))\nstart_time = time.time()\nrd_for.fit(X_train, y_train)\ncompute_metrics(rd_for, X_train, y_train, X_test, y_test)\ntimes.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"alphas = np.arange(0,1,0.2)\npipe_rdfor = Pipeline(steps=[('scaler', scaler), ('rd_for', rd_for)], memory = 'tmp')\nrdforCV = GridSearchCV(pipe_rdfor, dict( rd_for__estimator__ccp_alpha = alphas ), cv=5, scoring ='r2', n_jobs=-1)\n\nstart_time = time.time()\nrdforCV.fit(X_train, y_train)\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(rdforCV, X_train, y_train, X_test, y_test)\nCV_times.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gradient Boosting Regressor\nΚαι αυτή η τεχνική βασίζεται όπως είδαμε σε δέντρα, επομένως είναι λογικό να έχουμε πολύ υχηλή απόδοση εξαρχής. Εν τέλη βλέπουμε ότι μετά το τιουνάρισμα δεν έχουμε μεγάλη αύξηση της απόδοσης."},{"metadata":{"trusted":false},"cell_type":"code","source":"GBR = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\nstart_time = time.time()\nGBR.fit(X_train, y_train)\ncompute_metrics(GBR, X_train, y_train, X_test, y_test)\ntimes.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"alphas = np.arange(0.0,1.0,0.1)\npipe_gbr = Pipeline(steps=[('scaler', scaler), ('GBR', GBR)], memory = 'tmp')\ngbrCV = GridSearchCV(pipe_gbr, dict( GBR__estimator__alpha = alphas ), cv=5, scoring ='r2', n_jobs=-1)\n\nstart_time = time.time()\ngbrCV.fit(X_train, y_train)\ntrain_predict, test_predict, train_accuracy, test_accuracy, train_MSE, test_MSE = compute_metrics(gbrCV, X_train, y_train, X_test, y_test)\nCV_times.append(time.time() - start_time)\nprint(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n\nr2.append(test_accuracy)\nMSE.append(test_MSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"GBR.get_params().keys()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time and Metric Plots\nΣτην συνέχεια κάνουμε τα bar plots που ζητούνται στην άσκηση. Πρώτα από όλα συγκρίνουμε τους χρόνους που τρέχει ο κάθε ένα από τους αλγορίθμους και στην συνέχεια ο χρόνος που χρειάζεται να κάνουμε το grid search. Βεβαίως αυτός ο χρόνος εξαρτάται από το πλήθος των παραμέτρων που θέλουμε να τιουνάρουμε. Εμείς αναφερόμαστε στο τιουνάρισμα που καναμε εμείς.\n\nΒλέπουμε ότι γενικά τα boosting-ensemble μοντέλα χρειάζονται του μεγαλύτερους χρόνους."},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\n\nplot_data = {'names': names, 'times': times}\n\nsns.set_theme(style=\"whitegrid\")\ntips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"names\", y=\"times\", data=plot_data).set_title(\"Algorithm Times Barplot\",fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"plot_data = {'names': names, 'tuning times': CV_times}\n\nsns.set_theme(style=\"whitegrid\")\ntips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"names\", y=\"tuning times\", data=plot_data).set_title(\"Algorithm Tuning Times Barplot\",fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Όσον αφορά την απόδοση των ταξινομητών βλέπουμε ότι τα δάση έχουν την καλύτερη δυνατή απόδοση. Παρόλα αυτά, όλοι οι αλγόριθμοι έχουν γενικά καλή απόδοση, δεν υπάρχει κάποιος που να μας δίνει κακά αποτελέσματα.\n\nΊσως να είναι προτιμότεροι οι τέσσερεις τελευταίοι που έχουν και το μικρότερο μέσο τετραγωνικό σφάλμα."},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_data = {'names': names, 'R2 metric': r2}\n\nsns.set_theme(style=\"whitegrid\")\ntips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"names\", y=\"R2 metric\", data=plot_data).set(title='R2 metric bar plot', ylim=(0.9, 1.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_data = {'names': names, 'MSE metric': MSE}\n\nsns.set_theme(style=\"whitegrid\")\ntips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"names\", y=\"MSE metric\", data=plot_data).set_title(\"MSE metric Barplot\",fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}