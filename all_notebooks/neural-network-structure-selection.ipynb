{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Imports\n\n########################################################################\n# Python Standard Libraries\nimport os\nimport multiprocessing\nfrom timeit import default_timer as timer\nimport random\nimport math\n\n########################################################################\n# Numpy Library\nimport numpy as np # linear algebra\n\n########################################################################\n# Pandas Library\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n########################################################################\n# MATPLOT Library\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom matplotlib.ticker import MaxNLocator\n%matplotlib inline\n\n########################################################################\n# SKLearn Library\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, precision_recall_curve, classification_report, confusion_matrix, average_precision_score, roc_curve, auc, multilabel_confusion_matrix\n\n########################################################################\n# SCIPY Library\nfrom scipy.stats import gaussian_kde\nimport scipy.stats as st","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utility functions\n########################################################################\n# Print system information\ndef print_system_info():\n    mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n    mem_gib = mem_bytes/(1024.**3)  # e.g. 3.74\n    print(\"{:<23}{:f} GB\".format('RAM:', mem_gib))\n    print(\"{:<23}{:d}\".format('CORES:', multiprocessing.cpu_count()))\n    !lscpu\n\n########################################################################\n# Walk through input files\ndef print_input_files():\n    # Input data files are available in the \"../input/\" directory.\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n########################################################################\n# Dump text files\ndef dump_text_file(fname):\n    with open(fname, 'r') as f:\n        print(f.read())\n\n########################################################################\n# Dump CSV files\ndef dump_csv_file(fname, count=5):\n    # count: 0 - column names only, -1 - all rows, default = 5 rows max\n    df = pd.read_csv(fname)\n    if count < 0:\n        count = df.shape[0]\n    return df.head(count)\n\n########################################################################\n# Dataset related functions\nds_nbaiot = '/kaggle/input/nbaiot-dataset'\ndn_nbaiot = ['Danmini_Doorbell', 'Ecobee_Thermostat', 'Ennio_Doorbell', 'Philips_B120N10_Baby_Monitor', 'Provision_PT_737E_Security_Camera', 'Provision_PT_838_Security_Camera', 'Samsung_SNH_1011_N_Webcam', 'SimpleHome_XCS7_1002_WHT_Security_Camera', 'SimpleHome_XCS7_1003_WHT_Security_Camera']\n\ndef fname(ds, f):\n    if '.csv' not in f:\n        f = f'{f}.csv'\n    return os.path.join(ds, f)\n\ndef fname_nbaiot(f):\n    return fname(ds_nbaiot, f)\n\ndef get_nbaiot_device_files():\n    nbaiot_all_files = dump_csv_file(fname_nbaiot('data_summary'), -1)\n    nbaiot_all_files = nbaiot_all_files.iloc[:,0:1].values\n    device_id = 1\n    indices = []\n    for j in range(len(nbaiot_all_files)):\n        if str(device_id) not in str(nbaiot_all_files[j]):\n            indices.append(j)\n            device_id += 1\n    nbaiot_device_files = np.split(nbaiot_all_files, indices)\n    return nbaiot_device_files\n\ndef get_nbaiot_device_data(device_id, count_norm=-1, count_anom=-1):\n    if device_id < 1 or device_id > 9:\n        assert False, \"Please provide a valid device ID 1-9, both inclusive\"\n    if count_anom == -1:\n        count_anom = count_norm\n    device_index = device_id -1\n    device_files = get_nbaiot_device_files()\n    device_file = device_files[device_index]\n    df = pd.DataFrame()\n    y = []\n    for i in range(len(device_file)):\n        fname = str(device_file[i][0])\n        df_c = pd.read_csv(fname_nbaiot(fname))\n        count = count_anom\n        if 'benign' in fname:\n            count = count_norm\n        rows = count if count >=0 else df_c.shape[0]\n        print(\"processing\", fname, \"rows =\", rows)\n        y_np = np.ones(rows) if 'benign' in fname else np.zeros(rows)\n        y.extend(y_np.tolist())\n        df = pd.concat([df.iloc[:,:].reset_index(drop=True),\n                      df_c.iloc[:rows,:].reset_index(drop=True)], axis=0)\n    X = df.iloc[:,:].values\n    y = np.array(y)\n    Xdf = df\n    return (X, y, Xdf)\n\ndef get_nbaiot_devices_data():\n    devices_data = []\n    for i in range(9):\n        device_id = i + 1\n        (X, y) = get_nbaiot_device_data(device_id)\n        devices_data.append((X, y))\n    return devices_data\n#print_input_files()\nprint_system_info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_network_structure(method, layer_count_min, layer_count_max, node_count_min, node_count_max, samples_count, output_neuron_count):\n    structure = []\n    if method == 'random':\n        layer_count = random.randint(layer_count_min, layer_count_max)\n        for i in range(layer_count):\n            node_count = random.randint(node_count_min, node_count_max)\n            structure.append(node_count)\n    if method == 'heuristics':\n        N = samples_count\n        m = output_neuron_count\n        node_count_layer_1 = int(math.sqrt((m + 2) * N) + 2 * math.sqrt(N / (m + 2)))\n        node_count_layer_2 = int(m * math.sqrt(N / (m + 2)))\n        structure.append(node_count_layer_1)\n        structure.append(node_count_layer_2)\n\n    if method == 'genetic':\n        l = 10\n        chromosome = ''\n        for i in range(l):\n            x = random.randint(0, 1)\n            chromosome += '{}'.format(x)\n        chromosome_left = chromosome[0:6]\n        chromosome_right = chromosome[6:]\n        print('chromosome: {}'.format(chromosome))\n        print('split: {} {}'.format(chromosome_left, chromosome_right))\n        print('chromosome_left: {}'.format(chromosome_left))\n        print('chromosome_right: {}'.format(chromosome_right))\n        node_count_layer_1 = int(chromosome_left, 2) + random.randint(1, 10)\n        node_count_layer_2 = int(chromosome_right, 2) + random.randint(1, 10)\n        structure.append(node_count_layer_1)\n        structure.append(node_count_layer_2)\n    return structure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(select_network_structure('random', 5, 10, 10, 20, 100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(select_network_structure('heuristics', 5, 10, 10, 20, 100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(select_network_structure('genetic', 5, 10, 10, 20, 100, 2))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}