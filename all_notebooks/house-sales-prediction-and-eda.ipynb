{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Analysing House Sales in King County, USA\n## This kernel we will examine house sales from 1970 to 2010 for King county  and we will try to predict house price using multiple linear regression "},{"metadata":{},"cell_type":"markdown","source":"### Importing libs\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # for data analyse and data manupulation\nimport matplotlib.pyplot as plt # visualization\nimport numpy as np  \nimport folium # visualization\nimport seaborn as sns # visualization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding data "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize  data to  understand some important variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"groups = data.groupby(['grade'])['price'].mean()\nplt.figure(figsize=(10, 5))\nplt.xlabel('price')\ngroups.plot.barh()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groups = data.groupby(['bedrooms'])['price'].mean()\nplt.figure(figsize=(10, 5))\nplt.xlabel('price')\ngroups.plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groups = data.groupby(['bathrooms'])['price'].mean()\nplt.figure(figsize=(10, 10))\ngroups.plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.bathrooms, order = data['bathrooms'].value_counts().index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.bedrooms, order = data['bedrooms'].value_counts().index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.grade, order = data['grade'].value_counts().index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.condition, order = data['condition'].value_counts().index)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now , we will examine  house sales  from 1970 to 2010   with geographical heat map\n###  I will  separate dataset ;\n### from 1970 to 1980 ,\n### 1980 to 1990,\n### 1990 to 2000,\n### and 2000 to 2010\n\n###  I created a  function to generate map graph "},{"metadata":{"trusted":true},"cell_type":"code","source":"def generateBaseMap(map_location=[47.5,-122.161], zoom=9):\n    base_map = folium.Map(location=map_location, control_scale=True, zoom_start=zoom)\n    return base_map\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from folium.plugins import HeatMap\ndf_copy = data[np.logical_and(data.yr_built<=1980,data.yr_built >= 1970)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = data[np.logical_and(data.yr_built<=1990,data.yr_built >= 1980)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = data[np.logical_and(data.yr_built<=2000,data.yr_built >= 1990)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = data[np.logical_and(data.yr_built<=2010,data.yr_built >= 2000)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare regression data for prediction\n#### we will create a corralation table "},{"metadata":{"trusted":true},"cell_type":"code","source":"neededCols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront',\n            'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n            'yr_renovated', 'sqft_living15', 'sqft_lot15']\n\n\ncorr = data[neededCols].corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataForRegression = data[neededCols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataForRegression.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stats model  provide us some significant values like r2  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=dataForRegression.drop('price',axis=1)\ny=dataForRegression['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=42)\nlm = linear_model.LinearRegression() \nmodel = lm.fit(X_train[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15',\n       'sqft_lot15']], y_train)\n\nlm = sm.OLS(y_train, X_train)\nmodel1 = lm.fit()\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### r2 is 0.881 \n### our dataset is good for regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nprint('model accuracy is : ',model.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### the model have %65 accuracy but ;we will check cross validation score for better  verification "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.metrics import mean_squared_error, r2_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_train, model.predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_test, model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(model, X_train, y_train, cv = 100, scoring = \"r2\").mean()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now, we will try to find our model's prediction on the dataset and what is differece between real prices and predicted price "},{"metadata":{"trusted":true},"cell_type":"code","source":"predictedDatas=[]\nfor  row in range(0,len(dataForRegression)):\n    a=(model.predict([[dataForRegression['bedrooms'].values[row],dataForRegression['bathrooms'].values[row],dataForRegression['sqft_living'].values[row],dataForRegression['sqft_lot'].values[row],dataForRegression['floors'].values[row],\n        dataForRegression['waterfront'].values[row],dataForRegression['view'].values[row],dataForRegression['condition'].values[row],dataForRegression['grade'].values[row],dataForRegression['sqft_above'].values[row],\n        dataForRegression['sqft_basement'].values[row],dataForRegression['yr_built'].values[row],dataForRegression['yr_renovated'].values[row],dataForRegression['sqft_living15'].values[row],dataForRegression['sqft_lot15'].values[row]\n        ]]))\n    a=round(a[0],0)\n    predictedDatas.append(a)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = dataForRegression.price.values\nfinal_df = pd.DataFrame(final_df,columns=['Real_price'])\nfinal_df['predicted_prices'] = predictedDatas\nfinal_df['difference'] = abs(final_df['Real_price'] - final_df['predicted_prices'])\nfinal_df.tail(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### If we want to predict a house price  except from this  dataset , we can predict this way;\n#### we write our 15 criteria  to predict method "},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction= model.predict([[2,0,1180,6000,1,0,0,4,7,1180,0,1995,2010,1340,6000]]) \nprediction=round(prediction [0],0)\nprediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# As a result , \n### Popular areas from 1970 to 2010   are map valley, sammammish\n###  Most sales house type  has 3 bedroom, 2.5 bathroom , 7 grade level  and 3 Condition level \n### Also , we learnt how to make prediction with Multiple linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}