{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Kutuphanelerin yuklenmesi\nimport warnings\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nwarnings.simplefilter(action=\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verinin yuklenmesi\ndf = pd.read_csv(\"../input/diabetes/diabetes kopyas.csv\" , sep = \",\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2 degiskenin dusurulmesi\ndff = df.drop([\"Outcome\",\"Pregnancies\"] , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sıfırların yerine bos deger atanması\ndff = dff.replace(0 , np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bos deger kontrolu\ndff.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Degisken birlestirilmesi\ndf = pd.concat([dff , df[\"Pregnancies\"] , df[\"Outcome\"]] , axis = 1)\n\n#Eksik degerleri kategoriklere gore medyan ile doldurulması\nfor i in df.columns:\n    df[i] = df[i].fillna(df.groupby(\"Outcome\")[i].transform(\"median\"))\n\n    \n#Outcome degiskeninin kategoriye cevrilmesi\ndf[\"Outcome\"] = df.Outcome.astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SAYISAL DEGISKEN ANALIZI\nnum_cols = [col for col in df.columns if df[col].dtypes != 'O' and col not in \"Outcome\"]\nprint('Sayısal değişken sayısı: ', len(num_cols))\n\n\ndef hist_for_nums(data, numeric_cols):\n    col_counter = 0\n    data = data.copy()\n    for col in numeric_cols:\n        data[col].hist(bins=20)\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n        col_counter += 1\n    print(col_counter, \"variables have been plotted\")\n\n\nhist_for_nums(df, num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tum degiskenlerin violinplot ile incelemesi.\n#sns.lineplot(data=df, x=, y=\"\")\nfor i in df.columns:\n    if i == \"Outcome\":\n        pass\n    else:\n        sns.catplot(x= i, y=\"Outcome\",\n                    kind=\"violin\", inner=\"stick\", split=True,\n                    palette=\"pastel\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Degişken degerlerine yapılan baskılama islemi\ndf.loc[(df.Outcome == 1) & (df.Insulin <= 100) , \"Insulin\"] = 70\ndf.loc[(df.Outcome == 0) & (df.Insulin >= 200 ) , \"Insulin\"] = 200\ndf.loc[(df.Outcome == 0) & (df.Glucose >= 175 ) , \"Glucose\"] = 175","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Engineering\n\ndf[\"i_g\"] = (df.Glucose * df.Insulin) # cok iyi sonuc\n#df.Pregnancies = df.Pregnancies.replace(0,1)\ndf[\"g_p\"] = (df.Glucose * df.Pregnancies) \n#df[\"s_a\"] = (df.SkinThickness * df.Age)\n#df[\"gp_ig\"] = (df.g_p * df.i_g )\n#df[\"i_s\"] = (df.SkinThickness * df.Insulin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standartlastırma islemi.\nrobust_scaled = []\ndef robust_scaler(dataframe):\n    q1 = dataframe.quantile(0.05)\n    q3 = dataframe.quantile(0.95)\n    iqr = q1 - q3\n    for i in dataframe:\n        robust = (i - dataframe.median()) / iqr\n        robust_scaled.append(robust)\n    return pd.DataFrame(robust_scaled)\n\nfor i in num_cols:\n    df[i] = robust_scaler(df[i])\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding uygulanarak kategorik degiskenlerin sayısal degere cevirecek fonksiyonun yazılması\ndef one_hot_encoder(dataframe, categorical_columns, nan_as_category=False):\n    original_columns = list(dataframe.columns)\n    dataframe = pd.get_dummies(dataframe, columns=categorical_columns,\n                               dummy_na=nan_as_category, drop_first=True)\n    new_columns = [col for col in dataframe.columns if col not in original_columns]\n    return dataframe, new_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kategorik degiskenlerin secilesi\ncategorical_columns = [col for col in df.columns\n                           if len(df[col].unique()) <= 10\n                      and col != \"Outcome\"]\ncategorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encod isleminin uygulanısı\ndf, new_cols_ohe = one_hot_encoder(df,categorical_columns)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# EDA\n\ndf.head()\ndf.shape\ndf[\"Outcome\"].value_counts() * 100 / len(df)\n\n\n# SORU: sınıf oranları 1: 0.05, 0: 0.95\n# Böyle bir durumda ne yaparsınız?\n# 1. Oranlar böyle tamam ama frekanslar ne?\n# 2. Hepsine 1 desem zaten 95 başarılıyım. Neden model kuralım?\n# Dengesiz veri problemini araştırınız.\n\ndf.describe([0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).T\nsns.countplot(x='Outcome', data=df)\nplt.show()\n\ndf[\"Age\"].hist(edgecolor=\"black\")\nplt.show()\n\ndf.groupby(\"Outcome\").agg({\"Pregnancies\": \"mean\"})\ndf.corr()\n\n# -1,1\n# 0.7, 1\n# -0.7,-1\n\n# Data Preprocessing\n\ndf.isnull().sum()\n\n\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.10)\n    quartile3 = dataframe[variable].quantile(0.90)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef has_outliers(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    if dataframe[(dataframe[variable] < low_limit) | (dataframe[variable] > up_limit)].any(axis=None):\n        print(variable, \"yes\")\n\n\noutlier_thresholds(df, \"BloodPressure\")\n\n\nhas_outliers(df, \"Age\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Lojistik Regresyon (Logistic Regression)\n\ny = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\nX.head()\ny.head()\n\nlog_model = LogisticRegression().fit(X, y)\nlog_model.intercept_\nlog_model.coef_\n\nlog_model.predict(X)[0:10]\ny[0:10]\n\nlog_model.predict_proba(X)[0:10]\ny_pred = log_model.predict(X)\naccuracy_score(y, y_pred)\n\ncross_val_score(log_model, X, y, cv=10).mean()\n\nprint(classification_report(y, y_pred))\n\n\n\nlogit_roc_auc = roc_auc_score(y, log_model.predict(X))\nfpr, tpr, thresholds = roc_curve(y, log_model.predict_proba(X)[:, 1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# RF\n\nrf_model = RandomForestClassifier(random_state=12345).fit(X, y)\n\ncross_val_score(rf_model, X, y, cv=10).mean()\n\nrf_params = {\"n_estimators\": [200, 500],\n             \"max_features\": [5, 7],\n             \"min_samples_split\": [5, 10],\n             \"max_depth\": [5, None]}\n\nrf_model = RandomForestClassifier(random_state=12345)\n\ngs_cv = GridSearchCV(rf_model,\n                     rf_params,\n                     cv=10,\n                     n_jobs=-1,\n                     verbose=2).fit(X, y)\n\ngs_cv.best_params_\n\nrf_tuned = RandomForestClassifier(**gs_cv.best_params_)\ncross_val_score(rf_tuned, X, y, cv=10).mean()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# LightGBM\n\n\nlgbm = LGBMClassifier(random_state=12345)\ncross_val_score(lgbm, X, y, cv=10).mean()\n\n# model tuning\nlgbm_params = lgbm_params = {\"learning_rate\": [0.01, 0.5, 1],\n                             \"n_estimators\": [200, 500, 1000],\n                             \"max_depth\": [6, 8, 10],\n                             \"colsample_bytree\": [1, 0.5, 0.4 ,0.3 , 0.2]}\n\ngs_cv = GridSearchCV(lgbm,\n                     lgbm_params,\n                     cv=5,\n                     n_jobs=-1,\n                     verbose=2).fit(X, y)\n\nlgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X, y)\ncross_val_score(lgbm_tuned, X, y, cv=10).mean()\n\nfeature_imp = pd.Series(lgbm_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Değişken Önem Skorları')\nplt.ylabel('Değişkenler')\nplt.title(\"Değişken Önem Düzeyleri\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TUM MODELLER CV YONTEMI \nmodels = [('LR', LogisticRegression()),\n          ('KNN', KNeighborsClassifier()),\n          ('CART', DecisionTreeClassifier()),\n          ('RF', RandomForestClassifier()),\n          ('SVM', SVC(gamma='auto')),\n          ('XGB', GradientBoostingClassifier()),\n          (\"LightGBM\", LGBMClassifier())]\n\n# evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=123456)\n    cv_results = cross_val_score(model, X, y, cv=10, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15, 10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. YOL HOLDOUT + CV\n\n# Tum modellerin train validasyon skorları\n\nmodels = [('LR', LogisticRegression()),\n          ('KNN', KNeighborsClassifier()),\n          ('CART', DecisionTreeClassifier()),\n          ('RF', RandomForestClassifier()),\n          ('SVM', SVC(gamma='auto')),\n          ('XGB', GradientBoostingClassifier()),\n          (\"LightGBM\", LGBMClassifier())]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y, random_state=46)\n\n# evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=123456)\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15, 10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\nfor name, model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    msg = \"%s: (%f)\" % (name, acc)\n    print(msg)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}