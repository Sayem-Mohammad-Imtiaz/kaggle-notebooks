{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import modul and Create Session\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql import SparkSession\nappName=\"Sistem Rekomendasi Film\"\nspark = SparkSession.builder.master(\"local\").appName(appName).getOrCreate()\nsc=spark.sparkContext\nsc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#membuat data file ke DataFrame\nratings = spark.read.csv('../input/movielens/ratings.csv', header=True, inferSchema=True)\nmovies = spark.read.csv('../input/movielens/movies.csv', header=True, inferSchema=True)\ndf=ratings.join(movies,\"movieId\")\ndf.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pick the colomns the we need\ndata=df.select(\"userId\",\"movieId\",\"rating\")\ndata.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data with ration 80% training and 20% testing\nsplits=data.randomSplit([0.8,0.2])\ntrain=splits[0].withColumnRenamed(\"rating\",\"label\")\ntest=splits[1].withColumnRenamed(\"rating\",\"trueLabel\")\n\ntrain_row=train.count()\ntest_row=test.count()\n\n\nprint(\"Total data train is :\",train_row)\nprint(\"Total data test is:\", test_row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Modelling\nals=ALS(maxIter=19,regParam=0.01, userCol=\"userId\", itemCol=\"movieId\",ratingCol=\"label\")\nmodel=als.fit(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's Test and Evaluate\nprediction = model.transform(test)\nprediction.join(movies, \"movieId\").select(\n    \"userId\", \"title\", \"prediction\", \"trueLabel\").show(n=3, truncate=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator(\n    labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(prediction)\nprint (\"Root Mean Square Error (RMSE):\", rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#That's occur cause there were na data\n#let's clean\n\nprediction.count()\na = prediction.count()\nprint(\"Total NA before clean: \", a)\ncleanPred = prediction.dropna(how=\"any\", subset=[\"prediction\"])\nb = cleanPred.count()\nprint(\"Total NA after clean \", b)\nprint(\"Total NA: \", a-b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluate Again\nrmse = evaluator.evaluate(cleanPred)\nprint (\"Root Mean Square Error (RMSE):\", rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate top 10 movie recommendations for a specified set of users\nusers = ratings.select(als.getUserCol()).distinct().limit(3)\nuserSubsetRecs = model.recommendForUserSubset(users, 10)\nuserSubsetRecs.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RecommendbyUser=userSubsetRecs.toPandas()\nRecommendbyUser.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate top 10 user recommendations for a specified set of movies\nmovies = ratings.select(als.getItemCol()).distinct().limit(3)\nmovieSubSetRecs = model.recommendForItemSubset(movies, 10)\nmovieSubSetRecs.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RecommendbyMovie=movieSubSetRecs.toPandas()\nRecommendbyMovie.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}