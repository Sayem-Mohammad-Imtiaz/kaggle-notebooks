{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Restaurant Reviews Text Classification using PySpark\n\nIn this notebook, we will try to perform a text classification on the restaurant reviews using PySpark.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Libraries**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark --q","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Generic Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Apache Spark Libraries\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import IntegerType\n\n#Apache Spark ML CLassifier Libraries\nfrom pyspark.ml.classification import NaiveBayes\n\n#Apache Spark Evaluation Library\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n#Apache Spark Features libraries\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer\nfrom pyspark.ml.feature import Word2Vec\n\n#Apache Spark Pipelin Library\nfrom pyspark.ml import Pipeline\n\n#Apache Spark Fine Tuning Libraries\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n\n#Gensim Library for Text Processing\nimport gensim.parsing.preprocessing as gsp\nfrom gensim import utils\n\n\n\n#Tabulating Data\nfrom tabulate import tabulate\n\n#Garbage\nimport gc\n\n#Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Spark Session","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building Spark Session\nspark = (SparkSession.builder\n                  .appName('Restaurant Reviews Text Classification using Pyspark')\n                  .config(\"spark.executor.memory\", \"1G\")\n                  .config(\"spark.executor.cores\",\"4\")\n                  .getOrCreate())\n\n# Logging Level\nspark.sparkContext.setLogLevel('INFO')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Load","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"url = '../input/restaurant-reviews/Restaurant_Reviews.csv'\n\ndata = spark.read.csv(url, header=True, inferSchema=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration & Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#total records\ndata.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Types\ndata.printSchema()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting Liked column data to integer\ndata = data.withColumn('Liked', data['Liked'].cast(IntegerType()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Records per Liked column\ndata.groupby('Liked').count().show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling the null value with 0\ndata = data.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inspect data\ndata.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Pre-Processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create list of pre-processing func\nprocesses = [\n           gsp.strip_tags, \n           gsp.strip_punctuation,\n           gsp.strip_multiple_whitespaces,\n           gsp.strip_numeric,\n           gsp.remove_stopwords, \n           gsp.strip_short, \n           gsp.stem_text\n          ]\n\n# Create func to pre-process text\ndef proc_txt(txt):\n    text = txt[0]\n    text = text.lower()  #lowering the case\n    text = utils.to_unicode(text)\n    for p in processes:\n        text = p(text)\n    return (text,txt[1])    \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a temp dataset with processed data\ntemp_ds = data.rdd.map(lambda x : proc_txt(x))\n\n# Create a new Dataset\ndata_proc = temp_ds.toDF(['Proc_Review','Liked'])\n\n#Inspect New Dataset\ndata_proc.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the processed data into 90-10 ratio [90% - Training & 10% - Validation]\ntrain_data, test_data = data_proc.randomSplit([0.9, 0.1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Extraction (with TF-IDF Vectorizer)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#TF-IDF Vectorizing\ntok = Tokenizer(inputCol='Proc_Review', outputCol='Tok_Review')\nhashT = HashingTF(inputCol=tok.getOutputCol(), outputCol='raw_features_tf', numFeatures=30)\nidf = IDF(inputCol=hashT.getOutputCol(), outputCol='Features_tf', minDocFreq=5)\n\n#Create a TF-IDF pipeline\ntf_pipe = Pipeline(stages=[tok, hashT, idf])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit TF-IDF Pipeline to Training & Test Data\ntf_mod = tf_pipe.fit(train_data)\n\n#Transforming the data\ntrain_data = tf_mod.transform(train_data)\ntest_data = tf_mod.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build, Train & Evaluate Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to Create, Traing & Evaluate Multinomial NB Model\n\ndef mnb_mod(train,test):\n    \n    # Build Seperate Models for TF-IDF & Word2Vec\n    mnb_tf = NaiveBayes(smoothing=1.0, labelCol='Liked',featuresCol='Features_tf', modelType=\"multinomial\")\n    \n    # Fit the Models to Train Data\n    mnb_mod_tf = mnb_tf.fit(train)\n    \n    # Make Predictions\n    pred_tf = mnb_mod_tf.transform(test)\n    \n    # Evaluation\n    mnb_eval = BinaryClassificationEvaluator(labelCol='Liked')\n    \n    acc_tf = mnb_eval.evaluate(pred_tf)\n    \n    print(\"Multinomial Naive Bayes Model Accuracy =\", '{:.2%}'.format(acc_tf))\n        \n\n    \n#Applying the Function to vectorized data\nmnb_mod(train_data,test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine Tuning Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fine Tuning the model using Cross Validator & ParamBuilder\n\ndef MNB_CV(train,test):\n    \n    mnb = NaiveBayes(smoothing=1.0, labelCol='Liked',featuresCol='Features_tf', modelType=\"multinomial\")\n    \n    pipe = Pipeline(stages= [mnb])\n    \n    paramGrid = ParamGridBuilder().addGrid(mnb.smoothing, [1.0, 2.0, 3.0]).build()\n    \n    evaluate = BinaryClassificationEvaluator(labelCol=\"Liked\")\n    \n    crossValidator = CrossValidator(estimator=pipe,\n                                        evaluator=evaluate,\n                                        estimatorParamMaps=paramGrid,\n                                        numFolds=10)\n    \n    # use the Multinomial Model to train (fit) the model\n    # and Get the best Multinomial Naive Bayes model\n\n    cv = crossValidator.fit(train)\n    tuned_mod = cv.bestModel.stages[0]\n\n    predict = tuned_mod.transform(train)\n\n    acc_new = evaluate.evaluate(predict)\n    \n    print(\"Multinomial Naive Bayes Model Accuracy (fine tuned) =\", '{:.2%}'.format(acc_new)) \n\n\n# Applying the function to train & test data\nMNB_CV(train_data,test_data)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)![](https://cdn130.picsart.com/322267252359201.jpg?type=webp&to=min&r=640)\nWhat to say, the fine tuning was not tuned finely ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}