{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:32.177315Z","iopub.execute_input":"2021-05-21T19:33:32.177661Z","iopub.status.idle":"2021-05-21T19:33:32.185258Z","shell.execute_reply.started":"2021-05-21T19:33:32.17763Z","shell.execute_reply":"2021-05-21T19:33:32.183658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries\n\n**Import the usual libraries for pandas and plotting. You can import sklearn later on.**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:32.188056Z","iopub.execute_input":"2021-05-21T19:33:32.188486Z","iopub.status.idle":"2021-05-21T19:33:33.097691Z","shell.execute_reply.started":"2021-05-21T19:33:32.188439Z","shell.execute_reply":"2021-05-21T19:33:33.096908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the Data\n\n** Use pandas to read loan_data.csv as a dataframe called loans.**","metadata":{}},{"cell_type":"code","source":"loans = pd.read_csv('/kaggle/input/loan-data/loan_data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:33.099245Z","iopub.execute_input":"2021-05-21T19:33:33.099661Z","iopub.status.idle":"2021-05-21T19:33:33.141739Z","shell.execute_reply.started":"2021-05-21T19:33:33.099631Z","shell.execute_reply":"2021-05-21T19:33:33.140932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Check out the info(), head(), and describe() methods on loans.**","metadata":{}},{"cell_type":"code","source":"loans.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:33.143319Z","iopub.execute_input":"2021-05-21T19:33:33.143716Z","iopub.status.idle":"2021-05-21T19:33:33.174262Z","shell.execute_reply.started":"2021-05-21T19:33:33.143688Z","shell.execute_reply":"2021-05-21T19:33:33.173178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loans.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:33.175857Z","iopub.execute_input":"2021-05-21T19:33:33.176192Z","iopub.status.idle":"2021-05-21T19:33:33.239502Z","shell.execute_reply.started":"2021-05-21T19:33:33.176162Z","shell.execute_reply":"2021-05-21T19:33:33.238294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loans.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:33.241104Z","iopub.execute_input":"2021-05-21T19:33:33.241399Z","iopub.status.idle":"2021-05-21T19:33:33.261897Z","shell.execute_reply.started":"2021-05-21T19:33:33.241371Z","shell.execute_reply":"2021-05-21T19:33:33.260792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nLet's do some data visualization! We'll use seaborn and pandas built-in plotting capabilities, but feel free to use whatever library you want. Don't worry about the colors matching, just worry about getting the main idea of the plot.\n\n** Create a histogram of two FICO distributions on top of each other, one for each credit.policy outcome.**\n\n*Note: This is pretty tricky, feel free to reference the solutions. You'll probably need one line of code for each histogram, I also recommend just using pandas built in .hist()*","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nloans[loans['credit.policy']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='Credit.Policy=1')\nloans[loans['credit.policy']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='Credit.Policy=0')\nplt.legend()\nplt.xlabel('FICO')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:33.263313Z","iopub.execute_input":"2021-05-21T19:33:33.263611Z","iopub.status.idle":"2021-05-21T19:33:33.71699Z","shell.execute_reply.started":"2021-05-21T19:33:33.263583Z","shell.execute_reply":"2021-05-21T19:33:33.715321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Create a similar figure, except this time select by the not.fully.paid column.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nloans[loans['not.fully.paid']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='not.fully.paid=1')\nloans[loans['not.fully.paid']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='not.fully.paid=0')\nplt.legend()\nplt.xlabel('FICO')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:33.7186Z","iopub.execute_input":"2021-05-21T19:33:33.719163Z","iopub.status.idle":"2021-05-21T19:33:34.063599Z","shell.execute_reply.started":"2021-05-21T19:33:33.719125Z","shell.execute_reply":"2021-05-21T19:33:34.062084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid. **","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(11,7))\nsns.countplot(x='purpose',hue='not.fully.paid',data=loans,palette='Set1')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:34.06547Z","iopub.execute_input":"2021-05-21T19:33:34.065923Z","iopub.status.idle":"2021-05-21T19:33:34.324254Z","shell.execute_reply.started":"2021-05-21T19:33:34.065856Z","shell.execute_reply":"2021-05-21T19:33:34.322168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Let's see the trend between FICO score and interest rate. Recreate the following jointplot.**","metadata":{}},{"cell_type":"code","source":"sns.jointplot(x='fico',y='int.rate',data=loans,color='purple')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:34.325805Z","iopub.execute_input":"2021-05-21T19:33:34.326132Z","iopub.status.idle":"2021-05-21T19:33:35.007099Z","shell.execute_reply.started":"2021-05-21T19:33:34.326102Z","shell.execute_reply":"2021-05-21T19:33:35.006074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Create the following lmplots to see if the trend differed between not.fully.paid and credit.policy. Check the documentation for lmplot() if you can't figure out how to separate it into columns.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(11,7))\nsns.lmplot(y='int.rate',x='fico',data=loans,hue='credit.policy',\n           col='not.fully.paid',palette='Set1')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:35.008856Z","iopub.execute_input":"2021-05-21T19:33:35.009213Z","iopub.status.idle":"2021-05-21T19:33:36.718925Z","shell.execute_reply.started":"2021-05-21T19:33:35.009179Z","shell.execute_reply":"2021-05-21T19:33:36.717931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up the Data\n\nLet's get ready to set up our data for our Random Forest Classification Model!\n\n**Check loans.info() again.**","metadata":{}},{"cell_type":"code","source":"loans.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:36.724536Z","iopub.execute_input":"2021-05-21T19:33:36.724927Z","iopub.status.idle":"2021-05-21T19:33:36.745218Z","shell.execute_reply.started":"2021-05-21T19:33:36.724892Z","shell.execute_reply":"2021-05-21T19:33:36.743685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Features\n\nNotice that the **purpose** column as categorical\n\nThat means we need to transform them using dummy variables so sklearn will be able to understand them. Let's do this in one clean step using pd.get_dummies.\n\nLet's show you a way of dealing with these columns that can be expanded to multiple categorical features if necessary.\n\n**Create a list of 1 element containing the string 'purpose'. Call this list cat_feats.**","metadata":{}},{"cell_type":"code","source":"cat_feats = ['purpose']","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:36.747646Z","iopub.execute_input":"2021-05-21T19:33:36.748097Z","iopub.status.idle":"2021-05-21T19:33:36.753364Z","shell.execute_reply.started":"2021-05-21T19:33:36.748052Z","shell.execute_reply":"2021-05-21T19:33:36.751861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now use pd.get_dummies(loans,columns=cat_feats,drop_first=True) to create a fixed larger dataframe that has new feature columns with dummy variables. Set this dataframe as final_data.**","metadata":{}},{"cell_type":"code","source":"final_data = pd.get_dummies(loans,columns=cat_feats,drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:36.7551Z","iopub.execute_input":"2021-05-21T19:33:36.755411Z","iopub.status.idle":"2021-05-21T19:33:36.772624Z","shell.execute_reply.started":"2021-05-21T19:33:36.755378Z","shell.execute_reply":"2021-05-21T19:33:36.77138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:36.774305Z","iopub.execute_input":"2021-05-21T19:33:36.77476Z","iopub.status.idle":"2021-05-21T19:33:36.797186Z","shell.execute_reply.started":"2021-05-21T19:33:36.774716Z","shell.execute_reply":"2021-05-21T19:33:36.796338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split\n\nNow its time to split our data into a training set and a testing set!\n\n** Use sklearn to split your data into a training set and a testing set as we've done in the past.**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:36.798667Z","iopub.execute_input":"2021-05-21T19:33:36.799Z","iopub.status.idle":"2021-05-21T19:33:37.178501Z","shell.execute_reply.started":"2021-05-21T19:33:36.798968Z","shell.execute_reply":"2021-05-21T19:33:37.177157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = final_data.drop('not.fully.paid',axis=1)\ny = final_data['not.fully.paid']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.180094Z","iopub.execute_input":"2021-05-21T19:33:37.180525Z","iopub.status.idle":"2021-05-21T19:33:37.196321Z","shell.execute_reply.started":"2021-05-21T19:33:37.180492Z","shell.execute_reply":"2021-05-21T19:33:37.194675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training a Decision Tree Model\n\nLet's start by training a single decision tree first!\n\n** Import DecisionTreeClassifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.197851Z","iopub.execute_input":"2021-05-21T19:33:37.198174Z","iopub.status.idle":"2021-05-21T19:33:37.408463Z","shell.execute_reply.started":"2021-05-21T19:33:37.198144Z","shell.execute_reply":"2021-05-21T19:33:37.407119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**","metadata":{}},{"cell_type":"code","source":"dtree = DecisionTreeClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.410009Z","iopub.execute_input":"2021-05-21T19:33:37.410344Z","iopub.status.idle":"2021-05-21T19:33:37.415428Z","shell.execute_reply.started":"2021-05-21T19:33:37.410312Z","shell.execute_reply":"2021-05-21T19:33:37.414179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.417169Z","iopub.execute_input":"2021-05-21T19:33:37.417539Z","iopub.status.idle":"2021-05-21T19:33:37.514608Z","shell.execute_reply.started":"2021-05-21T19:33:37.41747Z","shell.execute_reply":"2021-05-21T19:33:37.513334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions and Evaluation of Decision Tree\n**Create predictions from the test set and create a classification report and a confusion matrix.**","metadata":{}},{"cell_type":"code","source":"predictions = dtree.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.51601Z","iopub.execute_input":"2021-05-21T19:33:37.516309Z","iopub.status.idle":"2021-05-21T19:33:37.524075Z","shell.execute_reply.started":"2021-05-21T19:33:37.516281Z","shell.execute_reply":"2021-05-21T19:33:37.522836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.525708Z","iopub.execute_input":"2021-05-21T19:33:37.526138Z","iopub.status.idle":"2021-05-21T19:33:37.542353Z","shell.execute_reply.started":"2021-05-21T19:33:37.526095Z","shell.execute_reply":"2021-05-21T19:33:37.541271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.543956Z","iopub.execute_input":"2021-05-21T19:33:37.544262Z","iopub.status.idle":"2021-05-21T19:33:37.565904Z","shell.execute_reply.started":"2021-05-21T19:33:37.544235Z","shell.execute_reply":"2021-05-21T19:33:37.56448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.567201Z","iopub.execute_input":"2021-05-21T19:33:37.567502Z","iopub.status.idle":"2021-05-21T19:33:37.581238Z","shell.execute_reply.started":"2021-05-21T19:33:37.567475Z","shell.execute_reply":"2021-05-21T19:33:37.579992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Random Forest model\n\nNow its time to train our model!\n\n**Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step.**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.583239Z","iopub.execute_input":"2021-05-21T19:33:37.583715Z","iopub.status.idle":"2021-05-21T19:33:37.616282Z","shell.execute_reply.started":"2021-05-21T19:33:37.583667Z","shell.execute_reply":"2021-05-21T19:33:37.615133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=600)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.617606Z","iopub.execute_input":"2021-05-21T19:33:37.617934Z","iopub.status.idle":"2021-05-21T19:33:37.623565Z","shell.execute_reply.started":"2021-05-21T19:33:37.617861Z","shell.execute_reply":"2021-05-21T19:33:37.622196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:37.625332Z","iopub.execute_input":"2021-05-21T19:33:37.62568Z","iopub.status.idle":"2021-05-21T19:33:46.080081Z","shell.execute_reply.started":"2021-05-21T19:33:37.625649Z","shell.execute_reply":"2021-05-21T19:33:46.079035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions and Evaluation\n\nLet's predict off the y_test values and evaluate our model.\n\n** Predict the class of not.fully.paid for the X_test data.**","metadata":{}},{"cell_type":"code","source":"predictions = rfc.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:46.081349Z","iopub.execute_input":"2021-05-21T19:33:46.081637Z","iopub.status.idle":"2021-05-21T19:33:46.478812Z","shell.execute_reply.started":"2021-05-21T19:33:46.081608Z","shell.execute_reply":"2021-05-21T19:33:46.477565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now create a classification report from the results. Do you get anything strange or some sort of warning?**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:46.480674Z","iopub.execute_input":"2021-05-21T19:33:46.481094Z","iopub.status.idle":"2021-05-21T19:33:46.486793Z","shell.execute_reply.started":"2021-05-21T19:33:46.481052Z","shell.execute_reply":"2021-05-21T19:33:46.48556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:46.488526Z","iopub.execute_input":"2021-05-21T19:33:46.488981Z","iopub.status.idle":"2021-05-21T19:33:46.508901Z","shell.execute_reply.started":"2021-05-21T19:33:46.488938Z","shell.execute_reply":"2021-05-21T19:33:46.507988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Show the Confusion Matrix for the predictions.**","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T19:33:46.510337Z","iopub.execute_input":"2021-05-21T19:33:46.510703Z","iopub.status.idle":"2021-05-21T19:33:46.520717Z","shell.execute_reply.started":"2021-05-21T19:33:46.510661Z","shell.execute_reply":"2021-05-21T19:33:46.519827Z"},"trusted":true},"execution_count":null,"outputs":[]}]}