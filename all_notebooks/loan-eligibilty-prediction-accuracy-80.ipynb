{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings \nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### important note : first i will do feature selcetion for buliding a model after that for next days i will complete notebook with data visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Lets load data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/loan-eligible-dataset/loan-train.csv')\ndf_test = pd.read_csv('../input/loan-eligible-dataset/loan-test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the Loan_ID column is not useful for us and building a model then we must drop it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(columns='Loan_ID', inplace = True)\ndf_test.drop(columns='Loan_ID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets get more data from our columns by df.info()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'whitegrid')\nplt.figure(figsize = (16,8))\nplt.subplot(2,2,1)\nsns.countplot(x = 'Gender' , data = df_train)\nplt.subplot(2,2,2)\nsns.countplot(x = 'Married', data= df_train)\nplt.subplot(2,2,3)\nsns.countplot(x = 'Gender', hue= 'Loan_Status', data = df_train)\nplt.subplot(2,2,4)\nsns.countplot(x = 'Married',hue = 'Loan_Status' , data= df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Its look like ApplicantIncome and LoanAmount have a linear relationship (or poly?) , and this relationship is make sense cause more income more loan amount can affort .","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## lets check it more","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,8))\nsns.scatterplot(x = 'LoanAmount' , y = 'ApplicantIncome' , hue = 'Loan_Status', data = df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And it is look like there is no obvious relationship between these 2 features and Loan_Status","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Lets check category variables more","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = 'whitegrid')\nplt.figure(figsize = (16,8))\nplt.subplot(2,2,1)\nsns.countplot(x = 'Education' , data = df_train)\nplt.subplot(2,2,2)\nsns.countplot(x = 'Property_Area', data= df_train)\nplt.subplot(2,2,3)\nsns.countplot(x = 'Education', hue= 'Loan_Status', data = df_train)\nplt.subplot(2,2,4)\nsns.countplot(x = 'Property_Area',hue = 'Loan_Status' , data= df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graduate = df_train['Education'].value_counts()['Graduate']\nnot_graduate = df_train['Education'].value_counts()['Not Graduate']\ngraduate_yes = df_train[df_train['Loan_Status'] == 'Y']['Education'].value_counts()['Graduate']\nnot_graduate_yes = df_train[df_train['Loan_Status'] == 'Y']['Education'].value_counts()['Not Graduate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(graduate_yes / graduate)\nprint(not_graduate_yes / not_graduate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"oh its look like if you are graduate you have more possiblity to take Loan","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"what percentage of people are self employed? and what percentage of people can take a loan?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,4))\nplt.subplot(1,2,1)\nplt.pie(df_train['Self_Employed'].value_counts(),explode = [0,0.2] , autopct='%.1f%%' , shadow = True , labels = ['No', 'Yes'])\nplt.title('percent of values in Self employed column')\nplt.subplot(1,2,2)\nplt.pie(df_train['Loan_Status'].value_counts(), explode = [0,0.2], autopct = '%.1f%%' , labels = ['N', 'Y'])\nplt.title('percent of acceptance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nsns.countplot('Self_Employed' , hue = 'Loan_Status' , data = df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"number of who are not self employed is high so the number of them who can take loan is higher than the rest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = 'Gender', y='ApplicantIncome' , data = df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it is showing us that men have higher median income than women and there are someones that have income more than 20 thousends dollar at year even its rising up to 80 thousends dollar but all of the women have 20 thousends dollar and lower .","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar('mean of Applicant Income',df_train['ApplicantIncome'].mean())\nplt.bar('mean of Loan Amount', df_train['LoanAmount'].mean())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"for the columns that are object type we need to take care of them by turn them into numerical columns.\\\nNow we need to know what value they have","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Unique values in Gender :',df_train['Gender'].unique())\nprint('Unique values in Married :',df_train['Married'].unique())\nprint('Unique values in Dependents :',df_train['Dependents'].unique())\nprint('Unique values in Education :',df_train['Education'].unique())\nprint('Unique values in Self Employed :',df_train['Self_Employed'].unique())\nprint('Unique values in Property Area :',df_train['Property_Area'].unique())\nprint('Unique values in Loan Status :',df_train['Loan_Status'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now when we know their value , we can turn them to numeric.\\\nit could be done by 3 ways ( at least the ways i know :) ).\\\n1.using replace method like what we are going to do\\\n2.using map method then we should build a dictionary\\\n3.using Lable encoder from sklearn library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Gender'] = df_train['Gender'].replace(['Male','Female'],[1,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Married'] = df_train['Married'].replace(['Yes','No'],[1,0])\ndf_train['Dependents'] = df_train['Dependents'].replace(['0','1','2'],[0,1,2])\ndf_train['Dependents'] = df_train['Dependents'].replace('3+' , 3)\ndf_train['Education'] = df_train['Education'].replace(['Graduate' , 'Not Graduate'],[1,0])\ndf_train['Self_Employed'] = df_train['Self_Employed'].replace(['Yes','No'],[1,0])\ndf_train['Property_Area'] = df_train['Property_Area'].replace(['Urban' ,'Rural' ,'Semiurban'],[0,1,2])\ndf_train['Loan_Status'] = df_train['Loan_Status'].replace(['Y','N'],[1,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets find out how many missing value we have","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets check if we drop the missing values then data is going to skewed or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = df_train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By comparing this two describe table , we realized that the mean for every column change near 1 percent then its a good technique ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"the Property Area column has 3 diffrent value , since we turn them to numric maybe there is no order between them so its better to have one column for every value.\\\nit could be done by 2 ways.\\\nfirst using pd.get_dummies method\\\nsecond using One Hot Encoder from sklearn library\\\ni think the first one is simple than the second ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = pd.get_dummies(df_temp , columns = ['Property_Area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets plot the Correlation Matrix\nto find the high correlated columns with Loan Status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df_temp.corr()\nplt.figure(figsize = (16,8))\nsns.heatmap(corr , annot = True )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"droping the nan value from test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Property_Area'] = df_test['Property_Area'].replace(['Urban' ,'Rural' ,'Semiurban'],[0,1,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.get_dummies(df_test , columns = ['Property_Area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Married'] = df_test['Married'].replace(['Yes', 'No'], [1,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tr_x = df_temp[['Married' , 'Credit_History' , 'Property_Area_1', 'Property_Area_2']].values\ndf_tr_y = df_temp['Loan_Status'].values\ndf_ts = df_test[['Married', 'Credit_History', 'Property_Area_1', 'Property_Area_2']].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets build models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import classification_report,plot_confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(df_tr_x , df_tr_y , test_size = 0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cls_lr = LogisticRegression()\ncls_lr.fit(x_train, y_train)\ny_pred = cls_lr.predict(x_test)\nprint(classification_report(y_test , y_pred))\nplot_confusion_matrix(cls_lr , x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy is not bad but the f1 score and recall is low.\\\nlet try with KFold Cross Validation to find the mean Accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val = cross_val_score(cls_lr , x_train, y_train , cv=10)\nprint(cross_val.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"well the accuracy is even lower than the first try.\\\nlets try Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cls_rf = RandomForestClassifier()\ncls_rf.fit(x_train, y_train)\ny_pred = cls_rf.predict(x_test)\nprint(classification_report(y_test , y_pred))\nplot_confusion_matrix(cls_rf, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Surprisingly the accuracy of Random Forest and Logistic Regressin is the same.\\\nnot only accuracy but also f1-score , recall and etc in the classification report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val = cross_val_score(cls_rf , x_train, y_train , cv=10)\nprint(cross_val.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets check the K Nearest Neighbors ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfor i in range(1,25): \n    cls_knn_2 = KNeighborsClassifier(n_neighbors=i)\n    cls_knn_2.fit(x_train, y_train)\n    score = cls_knn_2.score(x_test ,y_test)\n    results.append([score])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(list(range(1,25)) , results)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"above plot show us that with k is higher than 11 we have highest accuracy except when k equals to 20","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cls_knn = KNeighborsClassifier(n_neighbors=11)\ncls_knn.fit(x_train, y_train)\npredicted = cls_knn.predict(df_ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# to be continued .....","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## if you like this notebook please Upvote , thank you ! \n## i will be happy if you share your coments about this notebook :)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}