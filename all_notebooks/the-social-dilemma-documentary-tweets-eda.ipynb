{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0' role=\"tab\" aria-controls=\"home\" color=green><center>The Social Dilemma, a documentary-drama hybrid explores the dangerous human impact of social networking as the tech experts sound the alarm on the dangerous human impact of social networking.</center></h3>"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.thenews.com.pk/assets/uploads/tns/2019-07-07/568081_5906029_tns.jpg)"},{"metadata":{},"cell_type":"markdown","source":"## This notebook analyses the tweets with the trending #TheSocialDilemma hashtag made by the users of twitter!"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0' role=\"tab\" aria-controls=\"home\" color=green><center>Quick navigation</center></h3>\n\n* [1. Required Libraries](#1)\n* [2. Dataset Quick Overview](#2)\n* [3. Tweets EDA](#3)\n* [4. Tweets text analysis](#4)   \n\n    Kindly, Upvote the notebook!"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:green; border:0; color:white'><center>Required Libraries</center><h2><a id=\"1\"></a>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport itertools\n\n#plots\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom PIL import Image\nfrom nltk.corpus import stopwords\nstop=set(stopwords.words('english'))\nfrom nltk.util import ngrams\n\n\nimport re\nfrom collections import Counter\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport requests\nimport json\n\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(11.7,8.27)})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:green; border:0; color:white'><center>Dataset Quick Overview</center><h2>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"social=pd.read_csv('../input/the-social-dilemma-tweets/TheSocialDilemma.csv')\nsocial.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The dataset consists of 18,252 tweets with 14 columns!"},{"metadata":{},"cell_type":"markdown","source":"## Let's visualize some missing values!"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import missingno as mno\nmno.matrix(social)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"missed = pd.DataFrame()\nmissed['column'] = social.columns\n\nmissed['percent'] = [round(100* social[col].isnull().sum() / len(social), 2) for col in social.columns]\nmissed = missed.sort_values('percent',ascending=False)\nmissed = missed[missed['percent']>0]\n\nfig = sns.barplot(\n    x=missed['percent'], \n    y=missed[\"column\"], \n    orientation='horizontal'\n).set_title('Missed values percent for every column')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:green; border:0; color:white'><center>Tweets EDA</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"### Let's visualize the sentiment of the tweets!"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = social['Sentiment'].value_counts().reset_index()\nds.columns = ['Sentiment', 'Count']\nds = ds.sort_values(['Count'],ascending=False)\n#social = pd.merge(social, ds, on='user_name')\n\nfig = sns.barplot( \n    x=ds[\"Sentiment\"], \n    y=ds[\"Count\"], \n    orientation='vertical'\n).set_title('Sentiment of the tweets') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the tweets are positive in nature, which denotes a wide appreciation of the documentary among the users!"},{"metadata":{},"cell_type":"markdown","source":"## Lets Visualize the top 20 users by number of tweets\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = social['user_name'].value_counts().reset_index()\nds.columns = ['user_name', 'tweets_count']\nds = ds.sort_values(['tweets_count'],ascending=False)\nsocial = pd.merge(social, ds, on='user_name')\n\nfig = sns.barplot( \n    x=ds.head(20)[\"tweets_count\"], \n    y=ds.head(20)[\"user_name\"], \n    orientation='horizontal'\n).set_title('Top 20 users by number of tweets') \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The user \"OurPact\" has made the highest number of tweets! No let's look into OurPact's tweets alone!"},{"metadata":{"trusted":true},"cell_type":"code","source":"social[social['user_name']=='OurPact'][['text','Sentiment']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check the sentiment of the tweets made by the user name OurPact"},{"metadata":{"trusted":true},"cell_type":"code","source":"social[social['user_name']=='OurPact']['Sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The user name OurPact has created nearly 218 tweets with 213(majority) tweets in positive sentiment! Looks like Ourpact loved the documentary!"},{"metadata":{},"cell_type":"markdown","source":"### User created year by year"},{"metadata":{"trusted":true},"cell_type":"code","source":"social['user_created'] = pd.to_datetime(social['user_created'])\nsocial['year_created'] = social['user_created'].dt.year\ndata = social.drop_duplicates(subset='user_name', keep=\"first\")\ndata = data[data['year_created']>1970]\ndata = data['year_created'].value_counts().reset_index()\ndata.columns = ['year', 'number']\n\nfig = sns.barplot( \n    x=data[\"year\"], \n    y=data[\"number\"], \n    orientation='vertical'\n    #title='', \n).set_title('User created year by year')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 2009 has the highest number of users followed by the year 2011, who tweeted about the social dilemma documentary\n* The amount of users who joined in 2008 tweeted very less about the social dilemma documentary comapred to the other users who joined in the later years!\n"},{"metadata":{},"cell_type":"markdown","source":"## Top 20 Users location based on the number of tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = social['user_location'].value_counts().reset_index()\nds.columns = ['user_location', 'count']\nds = ds[ds['user_location']!='NA']\nds = ds.sort_values(['count'],ascending=False)\n\nfig = sns.barplot(\n    \n    x=ds.head(20)[\"count\"], \n    y=ds.head(20)[\"user_location\"], \n    orientation='horizontal'\n).set_title('Top 20 user locations by number of tweets')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### India holds the most number of tweets by location followed by San diego and Los angeles, California!"},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the number of tweets per location!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot\ndef pie_count(data, field, percent_limit, title):\n    \n    data[field] = data[field].fillna('NA')\n    data = data[field].value_counts().to_frame()\n\n    total = data[field].sum()\n    data['percentage'] = 100 * data[field]/total    \n\n    percent_limit = percent_limit\n    otherdata = data[data['percentage'] < percent_limit] \n    others = otherdata['percentage'].sum()  \n    maindata = data[data['percentage'] >= percent_limit]\n\n    data = maindata\n    other_label = \"Others(<\" + str(percent_limit) + \"% each)\"\n    data.loc[other_label] = pd.Series({field:otherdata[field].sum()}) \n    \n    labels = data.index.tolist()   \n    datavals = data[field].tolist()\n    \n    trace=go.Pie(labels=labels,values=datavals)\n    \n    layout = go.Layout(\n        title = title,\n        height=600,\n        width=600\n        )\n    \n    fig = go.Figure(data=[trace], layout=layout)\n    iplot(fig)\n    \npie_count(social, 'user_location', 0.5, 'Number of tweets per location')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 10 user sources by number of tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = social['source'].value_counts().reset_index()\nds.columns = ['source', 'count']\nds = ds.sort_values(['count'],ascending=False)\n\nfig = sns.barplot(\n    x=ds.head(10)[\"count\"], \n    y=ds.head(10)[\"source\"], \n    orientation='horizontal', \n).set_title('Top 10 user sources by number of tweets')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The most twitter tweets are made through the iphone! Followed by the android and very less people prefer web app comapred to iphone or android!"},{"metadata":{},"cell_type":"markdown","source":"## Total number of tweets for users and number of hashtags in every tweet"},{"metadata":{"trusted":true},"cell_type":"code","source":"social['hashtags'] = social['hashtags'].fillna('[]')\nsocial['hashtags_count'] = social['hashtags'].apply(lambda x: len(x.split(',')))\nsocial.loc[social['hashtags'] == '[]', 'hashtags_count'] = 0\nfig = sns.scatterplot( \n    x=social['hashtags_count'], \n    y=social['tweets_count']\n).set_title('Total number of tweets for users and number of hashtags in every tweet')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number of hashtags used in each tweet"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = social['hashtags_count'].value_counts().reset_index()\nds.columns = ['hashtags_count', 'count']\nds = ds.sort_values(['count'],ascending=False)\nds['hashtags_count'] = ds['hashtags_count'].astype(str) + ' tags'\nfig = sns.barplot( \n    x=ds[\"count\"], \n    y=ds[\"hashtags_count\"], \n    orientation='horizontal'\n).set_title('Distribution of number of hashtags in tweets')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most users use 1 hastag followed by 2 hashtag, where certain population uses no hastag while tweeting\n* Very less amount of people use more than 2 hashtags in their post "},{"metadata":{"trusted":true},"cell_type":"code","source":"social['date'] = pd.to_datetime(social['date']) \ndf = social.sort_values(['date'])\ndf['day'] = df['date'].astype(str).str.split(' ', expand=True)[0]\ndf['time'] = df['date'].astype(str).str.split(' ', expand=True)[1]\ndf.head()\n\nds = df.groupby(['day', 'user_name'])['hashtags_count'].count().reset_index()\nds = ds.groupby(['day'])['user_name'].count().reset_index()\nds.columns = ['day', 'number_of_users']\nds['day'] = ds['day'].astype(str)\nfig = sns.barplot( \n    x=ds['day'], \n    y=ds[\"number_of_users\"], \n    orientation='vertical',\n    #title='Number of unique users per day', \n    #width=800, \n    #height=800\n).set_title('Number of unique users per day')\n#fig.show()\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tweets distribution over days present in dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = df['day'].value_counts().reset_index()\nds.columns = ['day', 'count']\nds = ds.sort_values('count',ascending=False)\nds['day'] = ds['day'].astype(str)\nfig = sns.barplot( \n    x=ds['count'], \n    y=ds[\"day\"], \n    orientation=\"horizontal\",\n).set_title('Tweets distribution over days present in dataset')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tweets per day"},{"metadata":{"trusted":true},"cell_type":"code","source":"social['tweet_date']=pd.to_datetime(social['date']).dt.date\ntweet_date=social['tweet_date'].value_counts().to_frame().reset_index().rename(columns={'index':'date','tweet_date':'count'})\ntweet_date['date']=pd.to_datetime(tweet_date['date'])\ntweet_date=tweet_date.sort_values('date',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=go.Figure(go.Scatter(x=tweet_date['date'],\n                                y=tweet_date['count'],\n                               mode='markers+lines',\n                               name=\"Submissions\",\n                               marker_color='dodgerblue'))\n\nfig.update_layout(\n    title_text='Tweets per Day : ({} - {})'.format(social['tweet_date'].sort_values()[0].strftime(\"%d/%m/%Y\"),\n                                                       social['tweet_date'].sort_values().iloc[-1].strftime(\"%d/%m/%Y\")),template=\"plotly_dark\",\n    title_x=0.5)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The interesting factor is that the documentary was intially released on jan, 2020! Once the documentary was released in one of the major OTT platform(Netflix) on sept 9th, 2020! It started creating a quite a buzz in social media platforms like twitter, where people started to voice out their concerns on the impact of social media! \n\n### This is the reason where you identiy an steady increase in the number of tweets after sept 9th, 2020 but after a weeks time, the hype among people gradually decreased!"},{"metadata":{},"cell_type":"markdown","source":"## Tweet distribution - hourly"},{"metadata":{"trusted":true},"cell_type":"code","source":"social['hour'] = social['date'].dt.hour\nds = social['hour'].value_counts().reset_index()\nds.columns = ['hour', 'count']\nds['hour'] = 'Hour ' + ds['hour'].astype(str)\nfig = sns.barplot( \n    x=ds[\"hour\"], \n    y=ds[\"count\"], \n    orientation='vertical', \n).set_title('Tweets distribution over hours')\nplt.xticks(rotation='vertical')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Most number of tweets were made during 6 and 8 PM in the evenings and majorly most of the tweets were made during the evenings!"},{"metadata":{},"cell_type":"markdown","source":"### Top 10 hastags used in the tweet!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_hashtags(x): \n    return str(x).replace('[', '').replace(']', '').split(',')\n\ntweets_df = social.copy()\ntweets_df['hashtag'] = tweets_df['hashtags'].apply(lambda row : split_hashtags(row))\ntweets_df = tweets_df.explode('hashtag')\ntweets_df['hashtag'] = tweets_df['hashtag'].astype(str).str.lower().str.replace(\"'\", '').str.replace(\" \", '')\ntweets_df.loc[tweets_df['hashtag']=='', 'hashtag'] = 'NO HASHTAG'\n#tweets_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = tweets_df['hashtag'].value_counts().reset_index()\nds.columns = ['hashtag', 'count']\nds = ds.sort_values(['count'],ascending=False)\nfig = sns.barplot(\n    x=ds.head(10)[\"count\"], \n    y=ds.head(10)['hashtag'], \n    orientation='horizontal', \n).set_title('Top 10 hashtags')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style='background:green; border:0; color:white'><center>Tweets text analysis</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"## Prevalent words in tweets "},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_wordcloud(df, title):\n    wordcloud = WordCloud(\n        background_color='black',colormap=\"Oranges\", \n        stopwords=set(STOPWORDS), \n        max_words=50, \n        max_font_size=40, \n        random_state=666\n    ).generate(str(df))\n\n    fig = plt.figure(1, figsize=(14,14))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=16)\n    fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"build_wordcloud(social['text'], 'Prevalent words in tweets for all dataset')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prevalent words in tweets from India"},{"metadata":{"trusted":true},"cell_type":"code","source":"india_df = social.loc[social.user_location==\"India\"]\nbuild_wordcloud(india_df['text'], title = 'Prevalent words in tweets from India')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Refining the text (Important step)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_tag(string):\n    text=re.sub('<.*?>','',string)\n    return text\ndef remove_mention(text):\n    line=re.sub(r'@\\w+','',text)\n    return line\ndef remove_hash(text):\n    line=re.sub(r'#\\w+','',text)\n    return line\n\ndef remove_newline(string):\n    text=re.sub('\\n','',string)\n    return text\ndef remove_url(string): \n    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',string)\n    return text\ndef remove_number(text):\n    line=re.sub(r'[0-9]+','',text)\n    return line\ndef remove_punct(text):\n    line = re.sub(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]*','',text)\n    return line\ndef text_strip(string):\n    line=re.sub('\\s{2,}', ' ', string.strip())\n    return line\ndef remove_thi_amp_ha_words(string):\n    line=re.sub(r'\\bamp\\b|\\bthi\\b|\\bha\\b',' ',string)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"social['refine_text']=social['text'].str.lower()\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_tag(str(x)))\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_mention(str(x)))\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_hash(str(x)))\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_newline(x))\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_url(x))\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_number(x))\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_punct(x))\nsocial['refine_text']=social['refine_text'].apply(lambda x:remove_thi_amp_ha_words(x))\nsocial['refine_text']=social['refine_text'].apply(lambda x:text_strip(x))\n\nsocial['text_length']=social['refine_text'].str.split().map(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The average length for a IPL2020 Tweet using violin plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=go.Violin(y=social['text_length'], box_visible=True, line_color='black',\n                               meanline_visible=True, fillcolor='royalblue', opacity=0.6,\n                               x0='Tweet Text Length'))\n\nfig.update_layout(yaxis_zeroline=False,title=\"Distribution of Text length\",template='ggplot2')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Average length of the ipl2020 tweet: 13.06\n* Median lenght of the ipl 2020 tweet:15\n* Interquartile lie between : 10 and 18\n* Min: 0\n* Max: 27"},{"metadata":{},"cell_type":"markdown","source":"## N-GRAM"},{"metadata":{},"cell_type":"markdown","source":"## Listing below the top N-gram sequential words used in IPL2020 tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ngram_df(corpus,nrange,n=None):\n    vec = CountVectorizer(stop_words = 'english',ngram_range=nrange).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    total_list=words_freq[:n]\n    df=pd.DataFrame(total_list,columns=['text','count'])\n    return df\nunigram_df=ngram_df(social['refine_text'],(1,1),20)\nbigram_df=ngram_df(social['refine_text'],(2,2),20)\ntrigram_df=ngram_df(social['refine_text'],(3,3),20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = make_subplots(\n    rows=3, cols=1,subplot_titles=(\"Unigram\",\"Bigram\",'Trigram'),\n    specs=[[{\"type\": \"scatter\"}],\n           [{\"type\": \"scatter\"}],\n           [{\"type\": \"scatter\"}]\n          ])\n\nfig.add_trace(go.Bar(\n    y=unigram_df['text'][::-1],\n    x=unigram_df['count'][::-1],\n    marker={'color': \"blue\"},  \n    text=unigram_df['count'],\n    textposition = \"outside\",\n    orientation=\"h\",\n    name=\"Months\",\n),row=1,col=1)\n\nfig.add_trace(go.Bar(\n    y=bigram_df['text'][::-1],\n    x=bigram_df['count'][::-1],\n    marker={'color': \"blue\"},  \n    text=bigram_df['count'],\n     name=\"Days\",\n    textposition = \"outside\",\n    orientation=\"h\",\n),row=2,col=1)\n\nfig.add_trace(go.Bar(\n    y=trigram_df['text'][::-1],\n    x=trigram_df['count'][::-1],\n    marker={'color': \"blue\"},  \n    text=trigram_df['count'],\n     name=\"Days\",\n    orientation=\"h\",\n    textposition = \"outside\",\n),row=3,col=1)\n\nfig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.update_layout(title_text='Top N Grams',xaxis_title=\" \",yaxis_title=\" \",\n                  showlegend=False,title_x=0.5,height=1200,template=\"plotly_dark\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* social, watch, and media are the most used unigrams\n* social media, social dilemma, just watched are the most used bigrams in the social dilemma tweets\n* social dilemma neflix, wach social dilemma, keepin kids safe, kids safe online are the most used trigrams!"},{"metadata":{},"cell_type":"markdown","source":"\n<h2 style='background:green; border:0; color:white'><center> PART 2: Twitter sentiment classification models and techniques! Coming soon! Stay tuned! </center><h2>\n\n"},{"metadata":{},"cell_type":"markdown","source":"[Dataset Link with 10,000 and more tweets with #TheSocialDilemma hashtag](https://www.kaggle.com/kaushiksuresh147/the-social-dilemma-tweets)"},{"metadata":{},"cell_type":"markdown","source":"<h2 style='background:green; border:0; color:white'><center>Kindly upvote the notebook and the dataset!</center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}