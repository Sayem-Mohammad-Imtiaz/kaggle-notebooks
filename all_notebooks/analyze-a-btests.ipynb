{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![alt text](https://www.invespcro.com/blog/images/blog-images/ab-test-1-1.jpg)\n\n## Table of Contents\n- [Introduction](#intro)\n- [Part I - Data Wrangling](#Data_wrangling)\n- [Part II - Probability](#prob_test)\n- [Part III - A/B Test](#A/B_test)\n- [Part IV - A regression approach](#reg)\n- [Part V -  Influences associated with time](#time)\n- [Conclusion](#conc.)\n- [Limitations](#lim)\n\n<a id='intro'></a>\n### Introduction\nA/B tests are very commonly performed by data analysts and data scientists. For this project, I will be working to understand the results of an A/B test run by an e-commerce website. My goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.<br>\n\nDataset used is __ab_data.csv__ dataset.<br>\n\n### Information about features in dataset.\n\n- __user_id__ - unique identifier for each user\n- __timestamp__ - associated date and time for each visit to the website by a given user\n- __group__ - the category a user was grouped into pre-A/B test (control or treatment groups)\n- __landing_page__ - the page that was displayed to a user when they visited the company website (new_page or old_page)\n- __converted__ - whether a user converted or not (0 or 1) NB: Users in the control group ought to be displayed the old page, while those in the treatment group ought to see the new page.","metadata":{}},{"cell_type":"markdown","source":"__Importing important libraries__","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Loading Data__","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/ab-tests/ab_data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing Top-5 rows from our data.\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='Data_wrangling'></a>\n## PART I- Data Wrangling","metadata":{}},{"cell_type":"code","source":"# Size of our data. 1472390 entries.\ndf.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rows:294478, Columns:5\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of unique users in our data.\ndf.user_id.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"290584 unique users in our data.","metadata":{}},{"cell_type":"code","source":"# Null Values count in our data\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No null values in our data.","metadata":{}},{"cell_type":"code","source":"# Total number of duplicate users in our data.\ndf.user_id.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This could mean that some users were experimented more than once. Or it could be some kind of error.<br>\nWe will deal with duplicate data later.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Columns datatypes:\n- user_id ___int64___\n- timestamp ___object___\n- group ___object___\n- landing_page ___object___\n- converted ___int64___","metadata":{}},{"cell_type":"markdown","source":"__Calculated the proportion of users who were converted from one group to another.__","metadata":{}},{"cell_type":"code","source":"(df['converted']==1).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Approximately 12 percent of users were converted from one group to another but right now we don't know which group had higher conversion rate. We will find out later.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['group'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Their are two types of group in our `group` column:\n- Control\n- Treatment","metadata":{}},{"cell_type":"code","source":"df['landing_page'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Their are two types of page in our `landing_page`column:\n- Old Page\n- New Page","metadata":{}},{"cell_type":"markdown","source":"__The number of times the `new_page` and `treatment` don't line up.__","metadata":{}},{"cell_type":"code","source":"op = df.query('group == \"treatment\"')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op['landing_page'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that number of times the new_page and treatment don't line up is __1965__.","metadata":{}},{"cell_type":"markdown","source":"__The number of times the `old_page` and `control` don't line up.__","metadata":{}},{"cell_type":"code","source":"op2 = df.query('group == \"control\"')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op2['landing_page'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that number of times the old_page and control don't line up is __1928__.","metadata":{}},{"cell_type":"markdown","source":"So, now since we have the evidence that some groups and treatment don't line up as they should be, we can remove the rows which contain this erroneous data in order to make more accurate decisions further in our analysis.","metadata":{}},{"cell_type":"code","source":"# Getting the data where 'group' don't line up with 'landed_page'\nerror_df = df[((df['group']=='treatment')== (df['landing_page']=='new_page'))==False]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of indices of rows which contain erroneous data.\nindx = error_df.index.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making another dataframe df2 in order to remove erroneous data.\ndf2 = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping rows where 'group' don't line up with 'landed_page'.\ndf2.drop(index=indx,axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking.\ndf2[((df2['group']=='treatment')== (df2['landing_page']=='new_page'))==False].shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Checking unique user_ids in df2__","metadata":{}},{"cell_type":"code","source":"df2.user_id.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['user_id'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is one user id 773192 which is repeated two times in our data.<br>\nI will drop the row with this user id as we don't want duplicate data for our analysis.","metadata":{}},{"cell_type":"code","source":"# Row information for the repeated user id.\ndf2.query('user_id == \"773192\"')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping row.\ndf2.drop(index=2893,axis=0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.user_id.duplicated().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='prob_test'></a>\n## PART II- Probability test.","metadata":{}},{"cell_type":"markdown","source":"__What is the probability of an individual converting regardless of the page they receive?__","metadata":{}},{"cell_type":"code","source":"df2['converted'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the probability of an individual converting regardless of the page they receive is approx. __0.1196__.","metadata":{}},{"cell_type":"markdown","source":"__Given that an individual was in the `control` group, what is the probability they converted?__","metadata":{}},{"cell_type":"code","source":"df2[df2['group']=='control']['converted'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The probability of converting giving individual was in the control group is approx. __0.1203__.","metadata":{}},{"cell_type":"markdown","source":"__Given that an individual was in the `treatment` group, what is the probability they converted?__","metadata":{}},{"cell_type":"code","source":"df2[df2['group']=='treatment']['converted'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The probability of converting giving individual was in the treatment group is approx. __0.1188__.","metadata":{}},{"cell_type":"markdown","source":"__What is the probability that an individual received the new page?__","metadata":{}},{"cell_type":"code","source":"(df2['landing_page']=='new_page').sum()/df2.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Probability that an individual received the new page is approx. __0.5001__.","metadata":{}},{"cell_type":"code","source":"df2.head(20\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above analysis I have made several conclusions:<br>\n1- We cannot say that new treatment page leads to more conversion.<br>\n2- Probability of conversion when an individual was in control group was higher than probability of conversion when an individual was in treatment group.<br>\n3- Probability than an individual was given new page (__0.5001__) was higher than the probability of an individual who received old page (__0.4999__).\n","metadata":{}},{"cell_type":"markdown","source":"<a id='A/B_test'></a>\n## PART III- A/B Test","metadata":{}},{"cell_type":"markdown","source":"__Null Hypothesis__: Conversion rate of an individual who was landed new page is smaller or equal to the conversion rate of an individual who was landed old page.<br>\n__Alternative Hypothesis__:  Conversion rate of an individual who was landed new page is greater comapre to the conversion rate of an individual who was landed old page.<br>\n                                $H_0$ (Null Hypothesis): $p_{new}$ < = $p_{old}$.<br>\n                                $H_1$ (Alternative Hypothesis): $p_{new}$ > $p_{old}$.<br>\n","metadata":{}},{"cell_type":"markdown","source":"Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page.<br><br>\nI am taking type-1 error rate as 5% (0.05) because of the following reasons:\n- It is better to have low type-1 error rate. (Choosing alternative hypothesis when null hypothesis is correct is considered as type-1 error which is the worst type of error among type-1 and type-2).\n- If our p-value comes out to be greater than 0.05 (type-1 error rate) than we can say that we have failed to reject null hypothesis. But if it is opposite, than we can reject null hypothesis and go forward with our alternatie hypothesis.","metadata":{}},{"cell_type":"code","source":"# Null Hypothesis Pnew = Pold\nPnew = df2['converted'].mean()\nPold = df2['converted'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample size.\nn_new= df2[df2['landing_page']=='new_page']['group'].shape[0]\nn_old= df2[df2['landing_page']=='old_page']['group'].shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Simulating n_new and n_old transactions with a convert rate of Pnew and Pold under the null.\nnew_page_converted = np.random.binomial(1,p=Pnew,size=n_new)\nold_page_converted = np.random.binomial(1,p=Pold,size=n_old)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating the difference of the mean of new_page conversion rate and old_page conversion rate under the null.\n_diff = new_page_converted.mean() - old_page_converted.mean()\nprint(_diff)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that difference is approximately equal to 0 which means that sample size is good enough to perform hypothesis testing. I will perform the same steps above but this time I will iterate sample size over 10000 times in order to verify above result (__difference__). ","metadata":{}},{"cell_type":"code","source":"# Simulate 10,000 Pnew - Pold values using this same process above.\nnew = np.random.binomial(n_new,Pnew,10000)\nold = np.random.binomial(n_old,Pold,10000)\np_diff = []\np_diff.append(new/n_new-old/n_old)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a histogram of the p_diffs.\nplt.hist(p_diff);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This plot is exactly what I expected. Sampling distribution of p_diff is normally distributed.","metadata":{}},{"cell_type":"markdown","source":"__Calculating p-value.__<br>\np-value is the probability of observing your statistic (or one more extreme in favor of the alternative) if the null hypothesis is true.","metadata":{}},{"cell_type":"code","source":"# Calculating observed difference by taking conversion rate of new_page and old_page from df2 respectively.\n# Also, plotting histogram to show the p_diff under null and observed difference value.\n# If maximum p_diff values are present above the observed diff, than we can say that we have fail to reject null hypothesis.\nobs_diff = df2[df2['landing_page']=='new_page']['converted'].mean() - df2[df2['landing_page']=='old_page']['converted'].mean()\nplt.hist(p_diff)\nplt.axvline(obs_diff,c='red');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The red line in the above plot shows the location of observed difference value which is approx. __-0.00157__.","metadata":{}},{"cell_type":"code","source":"(np.array(p_diff) > obs_diff).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- p-value is 0.907.<br>\n- Since p-value is greater than type-1 error rate (0.05), we can say that we have failed to reject null hypothesis.\n- Conversion rate of new page is either smaller or equal to the conversion rate of old page which is our null hypothesis.","metadata":{}},{"cell_type":"markdown","source":"We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. We have calculated the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\n\nconvert_old = df2[df2['landing_page']=='old_page']['converted'].sum()\nconvert_new = df2[df2['landing_page']=='new_page']['converted'].sum()\nn_old = df2[df2['landing_page']=='old_page']['group'].shape[0]\nn_new = df2[df2['landing_page']=='new_page']['group'].shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm.stats.proportions_ztest([convert_old,convert_new],[n_old,n_new],alternative='smaller')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I observed that using stats.proportions_ztest, p-value (0.905) is still close to what we got above (0.907). This means that conversion rate of new page is either small or equal to the conversion rate of old page (Null Hypothesis). This result agrees with my findings.<br><br>","metadata":{}},{"cell_type":"markdown","source":"<a id='reg'></a>\n## PART IV- A regression approach","metadata":{}},{"cell_type":"code","source":"df2['ab_page'] = pd.get_dummies(df2.group)['treatment']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model, and fit the model using the two columns 'intercept' and 'ab_page'.\ndf2['intercept'] = 1\nli = sm.Logit(df2['converted'],df2[['intercept','ab_page']])\nm = li.fit()\nm.summary2()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The p-value obtained from above summary is 0.189 which is different from what we obtained in our A/B tests. This is because of change in null and alternative hypothesis.<br>\n- $H_0$ (Null Hypothesis): $p_{new}$ - $p_{old}$ = 0.<br>\n- $H_1$ (Alternative Hypothesis): $p_{new}$ - $p_{old}  !=0$.<br>\n\nBut it is still not statistically significant since p-value is greater than our type-1 error rate (0.05).","metadata":{}},{"cell_type":"markdown","source":"Now, I am considering other things that might influence whether or not an individual converts. I think it is a good idea to add other things because we might get to observed the conversion by an individual. But their are some disadvantages associated with adding more features:<br>\n1- Whether a feature added is independent of predictor variables or not. If it is not than we can get errors.<br>\n2- Adding features with high correlation factor with other features can damage our results and sometimes leads to wrong decisions. Thus we have to make sure that feature added is correlated to a certain level.","metadata":{}},{"cell_type":"markdown","source":"Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives. We will need to read in the countries.csv dataset and merge together our datasets on the approporiate rows.","metadata":{}},{"cell_type":"code","source":"# Loading countries data.\ncountries_df = pd.read_csv('../input/countries-data/countries.csv',index_col='user_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countries_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = df2.set_index('user_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joining countries data with df2 on 'user_id' index as this feature is common in both dataframes.\ndf4 = countries_df.join(df3,on='user_id',how='inner')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4['country'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting labels 'UK' and 'US' from categorical variable to dummy variable. \ndf4[['UK','US']] = pd.get_dummies(df4.country)[['UK','US']]\ndf4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model, and fit the model using the two columns created above.\nli2 = sm.Logit(df4['converted'],df4[['intercept','ab_page','UK','US']])\nm2 = li2.fit()\nm2.summary2()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Does it appear that country had an impact on conversion?<br>\n- No, it does not appear that country had an impact on conversion.\n- Although p-value of 'UK' is very close to type-1 error rate 0.05, it is still not statistically significant.\n- All p-values are greater than 0.05. This shows that adding 'country' feature does not influence the change in conversion rate of any page by an individual.","metadata":{}},{"cell_type":"markdown","source":"Though we have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion. We will create the necessary additional columns, and fit the new model.","metadata":{}},{"cell_type":"code","source":"df4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making another feature by interacting page and country feature.\ndf4['UK_treatment'] = df4['ab_page'] * df4['UK']\ndf4['US_treatment'] = df4['ab_page'] * df4['US']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model, and fit the model using the two columns created above.\nli3 = sm.Logit(df4['converted'],df4[['intercept','ab_page','UK','US','UK_treatment','US_treatment']])\nm3 = li3.fit()\nm3.summary2()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='time'> </a>\n## PART V- Influences associated with time","metadata":{}},{"cell_type":"code","source":"df4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br> ","metadata":{}},{"cell_type":"markdown","source":"__Trimming timestamp feature.__","metadata":{}},{"cell_type":"code","source":"df4['date'] = df4.timestamp.apply(lambda x: x[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>","metadata":{}},{"cell_type":"markdown","source":"__Converting datatype of date feature from object to datetime.__","metadata":{}},{"cell_type":"code","source":"df4['date'] = pd.to_datetime(df4['date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking datatype.\ndf4.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>","metadata":{}},{"cell_type":"markdown","source":"__Seperating 'year','month',and 'day' from date feature.__","metadata":{}},{"cell_type":"code","source":"df4['year'] = df4['date'].dt.year\ndf4['month'] = df4['date'].dt.month\ndf4['day'] = df4['date'].dt.day","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding week feature.\ndf4['week'] = df4['date'].dt.week","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4['week'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting week feature into dummy variable and taken week 1 as baseline.\ndf4[['week_2','week_3','week_4']] = pd.get_dummies(df4.week)[[2,3,4]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"li4 = sm.Logit(df4['converted'],df4[['intercept','ab_page','UK','US','UK_treatment','US_treatment','week_2','week_3','week_4']])\nm4 = li4.fit()\nm4.summary2()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='conc.'></a>\n# Conclusion","metadata":{}},{"cell_type":"markdown","source":"- From the summary in part-4 observed that their is no change in conversion rate.\n- The interaction between page landed and country does not produce any significant changes in conversion rate since p-value is greater than 0.05.\n- Overall, their is no evidence to say that conversion rate of new page is higher compare to old page since p-value for interaction of predictor variables with response variable is greater that alpha that is type-1 error rate(0.05).\n- From the summary in part-5, we can say that their is still no change in conversion rate by adding weeks in which A/B test was carried out by the company. But p-value of week-4 is the lowest compare to other weeks. So, I conclude that if the company carry out A/B test for longer time than I think that change in conversion rate by an individual can be observed.\n- Finally, I have concluded that group, webpage, country, and webpage given to an individual belonging to a particular country does not influence the change in conversion rate of new and old page.<br><br>\n__Company should stick with the old page for now and try to add some more features or content in new page.__","metadata":{}},{"cell_type":"markdown","source":"<a id='lim'> </a>\n# Limitations","metadata":{}},{"cell_type":"markdown","source":"- Not enough features in our dataset. Some more features might have helped us understand more about the conversion rate by user.\n- Not enough time given for A/B test by the company. A/B test was carried out only for 24 days which I think are not enough to select one page and reject another.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}