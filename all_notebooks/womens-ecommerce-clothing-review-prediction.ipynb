{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport nltk \nimport string\n\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv\")\ndata = data.iloc[:,2:]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter1 = data['Rating'] >= 4\ndf1 = data[filter1]\n\nfilter2 = data['Rating'] < 4\ndf2 = data[filter2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text1 = df1['Review Text'].str.lower().str.strip().str.cat(sep = \" \")\ntext1 = text1.translate(str.maketrans(\"\",\"\", string.punctuation))\n\ntext2 = df2['Review Text'].str.lower().str.strip().str.cat(sep = \" \")\ntext2 = text2.translate(str.maketrans(\"\",\"\", string.punctuation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_rating_above4 = nltk.word_tokenize(text1)\nwords_rating_below4 = nltk.word_tokenize(text2)\nstopwords = nltk.corpus.stopwords.words(\"english\")\n\nli1 = []\nli2 = []\n\nword_net_lemmatizer = WordNetLemmatizer()\n\nfor word in words_rating_above4: \n    if(word in stopwords):\n        continue\n    li1.append(word_net_lemmatizer.lemmatize(word, pos='v'))\n    \nfor word in words_rating_below4: \n    if(word in stopwords):\n        continue\n    li2.append(word_net_lemmatizer.lemmatize(word, pos='v'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq1 = nltk.FreqDist(li1)\n\nfreq2 = nltk.FreqDist(li2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = plt.figure(figsize = (20,10))\nplt.gcf().subplots_adjust() # to avoid x-ticks cut-off\nfreq1.plot(100, cumulative=False)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20,10))\nplt.gcf().subplots_adjust() # to avoid x-ticks cut-off\nfreq2.plot(100, cumulative=False)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Topics with rating above 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.fillna(\"\")\ndf2=df2.fillna(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(stop_words= stopwords)\nmatrix = vectorizer.fit_transform(df1['Review Text'])\nfeature_names = np.array(vectorizer.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n                                max_iter=200, random_state=0) \ndocument_topics = lda.fit_transform(matrix)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Set n to your desired number of tokens \nn = 8\n# Find top n tokens\ntopics = dict()\nfor idx, component in enumerate(lda.components_): \n    top_n_indices = component.argsort()[:-(n + 1): -1] \n    topic_tokens = [feature_names[i] for i in top_n_indices] \n    topics[idx] = topic_tokens\n\ntopics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Topic modeling with rating below 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer2 = CountVectorizer(stop_words= stopwords)\nmatrix2 = vectorizer2.fit_transform(df2['Review Text'])\nfeature_names2 = np.array(vectorizer2.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda2 = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n                                max_iter=200, random_state=0) \ndocument_topics2 = lda2.fit_transform(matrix2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set n to your desired number of tokens \nn = 8\n# Find top n tokens\ntopics2 = dict()\nfor idx, component in enumerate(lda2.components_): \n    top_n_indices2 = component.argsort()[:-(n + 1): -1] \n    topic_tokens2 = [feature_names2[i] for i in top_n_indices2] \n    topics2[idx] = topic_tokens2\n\ntopics2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Classification model"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.drop(['Age', 'Positive Feedback Count', 'Division Name', 'Department Name'], axis = 1)\n\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['Rating'] = data1['Rating'].apply(lambda x: 1 if(x>=4) else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data1.drop(['Rating'], axis = 1)\ny = data1['Rating']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX['Title'] = X['Title'].apply(lambda x: str(x))\nX['Review Text'] = X['Review Text'].apply(lambda x: str(x))\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['Title_Review'] = X['Title'] + \" \" + X['Review Text']\nX['Title_Review'] = X['Title_Review'].apply(lambda x: x.replace(\"nan\",\"\").strip())\nX = X.drop(['Review Text', \"Title\"], axis = 1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.lang.en.stop_words import STOP_WORDS\nfrom textblob import TextBlob\n\nword_net_lemmatizer = WordNetLemmatizer()\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\nstopwords1 = STOP_WORDS\nst2 = string.digits+string.punctuation\n\ndef lemmatize_text(text):\n    lis=[]\n    words = text.split()\n    for word in words:\n        if(word in stopwords1):\n            continue\n        lis.append(word_net_lemmatizer.lemmatize(word, pos='v'))\n    return lis\n\n\nX['Title_Review'] = X['Title_Review'].apply(lambda x: \" \".join(lemmatize_text(x)))\nX['Title_Review'] = X['Title_Review'].apply(lambda x: x.translate(str.maketrans(\"\",\"\", st2)))\nX['Title_Review'] = X['Title_Review'].apply(lambda x: x.lower())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\n\nX['Sentiment_Polarity'] = X['Title_Review'].apply(lambda x: TextBlob(x).sentiment[0])\nX['Sentiment_Subjectivity'] = X['Title_Review'].apply(lambda x: TextBlob(x).sentiment[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvect = TfidfVectorizer(stop_words='english')\ndf_text1 = vect.fit_transform(X['Title_Review'])\ndf_text1 = pd.DataFrame(df_text1.toarray(), columns= vect.get_feature_names())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = X.drop(['Title_Review'], axis = 1)\nX1 = pd.concat([X1, df_text1], axis = 1)\n\nX1 = pd.get_dummies(columns = ['Class Name'], data = X1)\nX1 = X1.iloc[:, :-1]\nX1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1st model with ratings as target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X1, y, random_state = 0, test_size = 0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n\nrf = RandomForestClassifier()\n\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\nprint(\"accuracy score is: {}\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Confusion matrix is:\")\nprint((confusion_matrix(y_test, y_pred)))\nprint(\"Classification report is:\")\nprint((classification_report(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2nd model with Recommended as target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X2 = X1.copy()\nX2['Rating'] = data['Rating']\ny2 = data['Recommended IND']\nX2= X2.drop(['Recommended IND'], axis = 1)\nX2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X2, y2, random_state = 0, test_size = 0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n\nrf = RandomForestClassifier()\n\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\nprint(\"accuracy score is: {}\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Confusion matrix is:\")\nprint((confusion_matrix(y_test, y_pred)))\nprint(\"Classification report is:\")\nprint((classification_report(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}