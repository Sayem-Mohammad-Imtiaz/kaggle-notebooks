{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries and data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, Binarizer\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:36.112027Z","iopub.execute_input":"2021-08-25T12:02:36.112359Z","iopub.status.idle":"2021-08-25T12:02:36.626177Z","shell.execute_reply.started":"2021-08-25T12:02:36.112277Z","shell.execute_reply":"2021-08-25T12:02:36.624959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\nhouse = pd.read_csv('../input/amsterdam-house-price-prediction/HousingPrices-Amsterdam-August-2021.csv')\nhouse","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:36.628817Z","iopub.execute_input":"2021-08-25T12:02:36.629264Z","iopub.status.idle":"2021-08-25T12:02:36.667352Z","shell.execute_reply.started":"2021-08-25T12:02:36.629218Z","shell.execute_reply":"2021-08-25T12:02:36.666268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Dataset Overview\n|  Column |              Comment              |\n|:-------:|:---------------------------------:|\n| Address | Residential address               |\n|   Zip   | Residential Zip code              |\n|  Price  | Residential price in Euros        |\n|   Area  | Residential area in square meters |\n|   Room  | Number of rooms at residence      |\n|   Lon   | Longitude coordinate              |\n|   Lat   | Latitude coordinates.             |","metadata":{}},{"cell_type":"markdown","source":"## Process Missing Values","metadata":{}},{"cell_type":"code","source":"# Check whether 'house' contains any Null or NaN\nhouse.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:36.66906Z","iopub.execute_input":"2021-08-25T12:02:36.669382Z","iopub.status.idle":"2021-08-25T12:02:36.67901Z","shell.execute_reply.started":"2021-08-25T12:02:36.669343Z","shell.execute_reply":"2021-08-25T12:02:36.677882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing value with median\nhouse.fillna(house.median(), inplace=True)\nhouse","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:36.680465Z","iopub.execute_input":"2021-08-25T12:02:36.680828Z","iopub.status.idle":"2021-08-25T12:02:36.719567Z","shell.execute_reply.started":"2021-08-25T12:02:36.680788Z","shell.execute_reply":"2021-08-25T12:02:36.718553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Dtype of 'house'\nhouse.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:36.720991Z","iopub.execute_input":"2021-08-25T12:02:36.72137Z","iopub.status.idle":"2021-08-25T12:02:36.743377Z","shell.execute_reply.started":"2021-08-25T12:02:36.721338Z","shell.execute_reply":"2021-08-25T12:02:36.742512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract road names from address","metadata":{}},{"cell_type":"code","source":"# Extract road names\nhouse['Road'] = house['Address'].str.split(',', expand=True)[0]\nhouse['Road'] = house['Road'].str.split(' ')\nhouse['Road_Extract'] = pd.Series()\n\nfor i in range(0, len(house), 1):\n    lst = house.iloc[i, 8]\n    lst_extract = [j for j in lst if j.isalpha()]\n    lst_extract = ''.join(lst_extract)\n    house.iloc[i, 9] = lst_extract\n\nhouse","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:36.744316Z","iopub.execute_input":"2021-08-25T12:02:36.744576Z","iopub.status.idle":"2021-08-25T12:02:37.047878Z","shell.execute_reply.started":"2021-08-25T12:02:36.744551Z","shell.execute_reply":"2021-08-25T12:02:37.046831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare which columns has the least unique values.\ncolumns_names = ['Address', 'Zip', 'Road_Extract']\n\nfor name in columns_names:\n    print(\"Length of {0}: {1}\".format(name, len(house[name].unique())))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:37.049194Z","iopub.execute_input":"2021-08-25T12:02:37.049518Z","iopub.status.idle":"2021-08-25T12:02:37.057741Z","shell.execute_reply.started":"2021-08-25T12:02:37.049488Z","shell.execute_reply":"2021-08-25T12:02:37.056617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Comment**\nPreprocessed column has the least length.  \nA variety sorts can cause overfitting on prediction.  \nTherefore, choosing for the least one can be efficient way.","metadata":{}},{"cell_type":"code","source":"# Drop unnecessary columns\nhouse.drop(['Unnamed: 0', 'Address', 'Zip', 'Road'], axis=1, inplace=True)\nhouse.rename(columns={'Road_Extract':'Road'}, inplace=True)\nhouse.reset_index(drop=True, inplace=True)\nhouse = house[['Road', 'Area', 'Room', 'Lat', 'Lon', 'Price']]\nhouse","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:37.0605Z","iopub.execute_input":"2021-08-25T12:02:37.060837Z","iopub.status.idle":"2021-08-25T12:02:37.087565Z","shell.execute_reply.started":"2021-08-25T12:02:37.060802Z","shell.execute_reply":"2021-08-25T12:02:37.086824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check Distribution","metadata":{}},{"cell_type":"code","source":"# Check distribution of Area, Room and Price\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 10))\n\nsns.distplot(house['Area'], ax=ax1)\nax1.set_title('Distribution of Area')\nsns.distplot(house['Room'], ax=ax2)\nax2.set_title('Distribution of Room')\nsns.distplot(house['Price'], ax=ax3)\nax3.set_title('Distribution of Price')\n\nplt.suptitle('Distribution of features', fontweight='bold')\nplt.tight_layout\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:37.089398Z","iopub.execute_input":"2021-08-25T12:02:37.089743Z","iopub.status.idle":"2021-08-25T12:02:38.162396Z","shell.execute_reply.started":"2021-08-25T12:02:37.089713Z","shell.execute_reply":"2021-08-25T12:02:38.161095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Comment**\nOverall, as you can see, most of features have biased values  \nSo, if we process Standard Scaling, we can have better results.  \n100 square meters, 3 rooms were the heighest in each feature: Area, Room","metadata":{}},{"cell_type":"markdown","source":"# Create Datasets","metadata":{}},{"cell_type":"code","source":"# Apply Standard Scaling\narea_scaler = StandardScaler()\nroom_scaler = StandardScaler()\n\narea_n = area_scaler.fit_transform(house['Area'].values.reshape(-1, 1))\nroom_n = room_scaler.fit_transform(house['Room'].values.reshape(-1, 1))\n\nhouse.insert(3, 'Area_Scaled', area_n)\nhouse.insert(4, 'Room_Scaled', room_n)\n\nhouse","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:38.164554Z","iopub.execute_input":"2021-08-25T12:02:38.165012Z","iopub.status.idle":"2021-08-25T12:02:38.197313Z","shell.execute_reply.started":"2021-08-25T12:02:38.164963Z","shell.execute_reply":"2021-08-25T12:02:38.196402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check distribution of Area_Scaled, Room_Scaled\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n\nsns.distplot(house['Area_Scaled'], ax=ax1)\nax1.set_title('Distribution of Area_Scaled')\nsns.distplot(house['Room_Scaled'], ax=ax2)\nax2.set_title('Distribution of Room_Scaled')\n\nplt.suptitle('Distribution of features scaled', fontweight='bold')\nplt.tight_layout\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:38.19868Z","iopub.execute_input":"2021-08-25T12:02:38.199032Z","iopub.status.idle":"2021-08-25T12:02:38.752129Z","shell.execute_reply.started":"2021-08-25T12:02:38.199001Z","shell.execute_reply":"2021-08-25T12:02:38.751355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard Scaling doesn't work\n# Maybe conerting into log1p can be another good idea.\n\narea_n = np.log1p(house['Area'])\nroom_n = np.log1p(house['Room'])\n\nhouse.insert(5, 'Area_Log', area_n)\nhouse.insert(6, 'Room_Log', room_n)\n\nhouse","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:38.7531Z","iopub.execute_input":"2021-08-25T12:02:38.753476Z","iopub.status.idle":"2021-08-25T12:02:38.786608Z","shell.execute_reply.started":"2021-08-25T12:02:38.753446Z","shell.execute_reply":"2021-08-25T12:02:38.78559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check distribution of Area_Log, Room_Log\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n\nsns.distplot(house['Area_Log'], ax=ax1)\nax1.set_title('Distribution of Area_Log')\nsns.distplot(house['Room_Log'], ax=ax2)\nax2.set_title('Distribution of Room_Log')\n\nplt.suptitle('Distribution of features applied of log', fontweight='bold')\nplt.tight_layout\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:38.787933Z","iopub.execute_input":"2021-08-25T12:02:38.788277Z","iopub.status.idle":"2021-08-25T12:02:39.321298Z","shell.execute_reply.started":"2021-08-25T12:02:38.788248Z","shell.execute_reply":"2021-08-25T12:02:39.320375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Comment**\nWe plotted each distribution of original, Standard Scaled and Log Scaled.  \nAt the last plot, we could see better distribution which scaler was Log (similar to Normal Distribution).","metadata":{}},{"cell_type":"code","source":"# Extract needed features for training\nhouse_train = house[['Road', 'Area_Log', 'Room_Log', 'Price', 'Lat', 'Lon']]\nhouse_train","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:39.324421Z","iopub.execute_input":"2021-08-25T12:02:39.324722Z","iopub.status.idle":"2021-08-25T12:02:39.347681Z","shell.execute_reply.started":"2021-08-25T12:02:39.324693Z","shell.execute_reply":"2021-08-25T12:02:39.346678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Process One-Hot Encoding\nhouse_train = pd.get_dummies(house_train)\nhouse_train","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:39.348891Z","iopub.execute_input":"2021-08-25T12:02:39.349181Z","iopub.status.idle":"2021-08-25T12:02:39.396372Z","shell.execute_reply.started":"2021-08-25T12:02:39.349153Z","shell.execute_reply":"2021-08-25T12:02:39.395261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set feature and label dataset as X, y\nX = house_train.drop('Price', axis=1, inplace=False)\ny = house_train['Price']\n\nprint('Shape of X: ', X.shape)\nprint('Shape of y: ', y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:39.397967Z","iopub.execute_input":"2021-08-25T12:02:39.398413Z","iopub.status.idle":"2021-08-25T12:02:39.408938Z","shell.execute_reply.started":"2021-08-25T12:02:39.398366Z","shell.execute_reply":"2021-08-25T12:02:39.407847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split X, y into train and test datasets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n\nprint('Shape of X_train: ', X_train.shape)\nprint('Shape of X_test: ', X_test.shape)\nprint('Shape of y_train: ', y_train.shape)\nprint('Shape of y_test: ', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:39.410314Z","iopub.execute_input":"2021-08-25T12:02:39.410699Z","iopub.status.idle":"2021-08-25T12:02:39.427667Z","shell.execute_reply.started":"2021-08-25T12:02:39.410667Z","shell.execute_reply":"2021-08-25T12:02:39.426861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Regression","metadata":{}},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Logistic Regression is one of the most fundamental estimator.\n# So, let's try with Logistic Regression, first.\n\nlr_reg = LogisticRegression(solver='liblinear')\nlr_reg.fit(X_train, y_train)\nlr_preds = lr_reg.predict(X_test)\n\nlr_mse = mean_squared_error(y_test, lr_preds)\nlr_rmse = np.sqrt(lr_mse)\n\nprint('MSE : {0:.3f}, RMSE : {1:.3f}'.format(lr_mse, lr_mse))\nprint('Variance score : {0:.3f}'.format(r2_score(y_test, lr_preds)))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:39.429173Z","iopub.execute_input":"2021-08-25T12:02:39.429457Z","iopub.status.idle":"2021-08-25T12:02:39.781167Z","shell.execute_reply.started":"2021-08-25T12:02:39.429432Z","shell.execute_reply":"2021-08-25T12:02:39.779935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ridge","metadata":{}},{"cell_type":"code","source":"ridge = Ridge(alpha=10)\nneg_mse_scores = cross_val_score(ridge, X, y, scoring=\"neg_mean_squared_error\", cv=5)\nrmse_scores = np.sqrt(-1 * neg_mse_scores)\navg_rmse = np.mean(rmse_scores)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:39.783147Z","iopub.execute_input":"2021-08-25T12:02:39.783621Z","iopub.status.idle":"2021-08-25T12:02:40.239488Z","shell.execute_reply.started":"2021-08-25T12:02:39.783574Z","shell.execute_reply":"2021-08-25T12:02:40.238239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Individual Negative MSE scores of cross validation 5 times: ', np.round(neg_mse_scores, 2))\nprint('Individual RMSE scores of cross validation 5 times: ', np.round(rmse_scores, 2))\nprint('Average of RMSE scores of cross validation 5 times : {0:.3f} '.format(avg_rmse))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T12:02:40.241484Z","iopub.execute_input":"2021-08-25T12:02:40.242316Z","iopub.status.idle":"2021-08-25T12:02:40.254682Z","shell.execute_reply.started":"2021-08-25T12:02:40.242245Z","shell.execute_reply":"2021-08-25T12:02:40.253107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Report\n**Summary**  \n* Features of datasets are few for training\n* If I had more various features, I could have made better results.\n\n**Comment**  \n1. I tried to reduce the number of unique values of 'Address' (919 --> 759)\n- Length of Address: 919\n- Length of Zip: 834\n- Length of Road_Extract: 759\n\n2. I also tried to make features more scaled as much as Normal Distribution by comapring 3 methods.\n3. I made Ridge model to regularize features.  \nComapring with Logistic Regression, the RMSE score was decreased from 323252587891.892 to 376525.286.  \nStill, the evaulation score of my models are low. I need to improve them.","metadata":{}}]}