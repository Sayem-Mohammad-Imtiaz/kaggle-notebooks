{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/100-bird-species')\nBASE_DIR ='../input/100-bird-species/'\nTRAIN_DIR = os.path.join(BASE_DIR,'train')\nTEST_DIR = os.path.join(BASE_DIR,'test')\nVALID_DIR = os.path.join(BASE_DIR,'valid')\nCONSOLIDATED = os.path.join(BASE_DIR, 'consolidated')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=32\nIMAGE_SIZE=[112,112]\nAUTOTUNE = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TCLASS_NAME = np.array([item for item in os.listdir(TEST_DIR)]) #classnames @train\nVCLASS_NAME = np.array([item for item in os.listdir(VALID_DIR)]) #VLIDATION CLASS NAMES\nCONSO_CLASS_NAME = np.array([item for item in os.listdir(CONSOLIDATED)])\nprint('Total Numbers of Training calsses:',len(TCLASS_NAME))\nprint('Total Number of Valid calsses:',len(VCLASS_NAME))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_LS_DS = tf.data.Dataset.list_files(str(TRAIN_DIR +'/*/*')) #LIST ALL THE TRAINING FILES\nVALID_LS_DS = tf.data.Dataset.list_files(str(VALID_DIR+'/*/*')) #LIST OF ALL VLAIDATION FILES\nCONSO_LS_DS = tf.data.Dataset.list_files(str(CONSOLIDATED+'/*/*'))\nTEST_LS_DS = tf.data.Dataset.list_files(str(TEST_DIR+'/*/*'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TOTAL_DS = TRAIN_LS_DS.concatenate(CONSO_LS_DS)\nTOTAL_DS = TOTAL_DS.concatenate(VALID_LS_DS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(list(TOTAL_DS.as_numpy_iterator()))\nDATASET_SIZE = 58006\n\n#sice our total data size is 58006 and then spliting it into train and valid files\n\ntrain_size = int(0.7 * DATASET_SIZE)\nval_size = int(0.15 * DATASET_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''for i in range(1,9):\n    print(TRAIN_DIR + '/'+ TCLASS_NAME[i] + f'/00{i}.jpg')'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets see some class images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"w=10\nh=10\nfig=plt.figure(figsize=(15, 15))\ncolumns = 3\nrows = 3\nfor i in range(1, columns*rows +1):\n    img = TOTAL_DS.take(20)\n    fig.add_subplot(rows, columns, i)\n    k = cv2.imread(TRAIN_DIR + '/'+ TCLASS_NAME[i] + f'/00{i}.jpg')\n    plt.imshow(k)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Beautiful Birds ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Reading Images with their labels *class* names using tensorflow","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_label(file_path):\n    parts =tf.strings.split(file_path, os.path.sep)\n    return parts[-2] == TCLASS_NAME\n\ndef decode_img(img):\n    img = tf.image.decode_jpeg(img,3)\n    img = tf.image.convert_image_dtype(img,tf.float32)\n    return tf.image.resize(img, ([*IMAGE_SIZE]))\ndef augment(img):\n    img = decode_img(img)\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_crop(img ,(*IMAGE_SIZE,3))\n    return img\ndef process_path(file_path):\n    label = get_label(file_path)\n    img =tf.io.read_file(file_path)\n    img = augment(img)\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DS= TOTAL_DS.map(process_path, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, label in DS.take(1):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Datasets need to be:\n* Well shuffled\n* Repeat after some time\n* Divide into batches\n* tensorflow prefetch technique ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset(ds, cache=True):\n    ds = ds.cache()\n    ds = ds.shuffle(1000)\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since given validation data is quite small So I combined all data except test data and then divided into the train and validaiton split ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"full_train_ds = get_dataset(DS)\n\ntrain_dataset = full_train_ds.take(train_size)\nvalid_dataset = full_train_ds.take(val_size)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"images augmenatation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, label_batch = next(iter(train_dataset))\ndef show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(25):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(TCLASS_NAME[label_batch[n]==1][0].title())\n      plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_batch(image_batch.numpy(), label_batch.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model_2 = tf.keras.applications.DenseNet121(\n    include_top=False, weights='imagenet', input_shape=(112,112,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''base_model_1 = tf.keras.applications.ResNet101(input_shape=(*IMAGE_SIZE,3),include_top = False,\n                                             weights ='imagenet')\nbase_model_1.trainable = True'''\n\n'''model = tf.keras.Sequential([base_model_1,\n                            tf.keras.layers.GlobalAveragePooling2D(),\n                            tf.keras.layers.Dense(len(TCLASS_NAME), activation='softmax')])\nmodel.summary()'''\n\n'''base_learning_rate = 0.001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n             loss =tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])'''\n\n'''loss0,accuracy0 = model.evaluate(valid_dataset, steps = validation_steps)'''\n\n'''history = model.fit(train_dataset,\n                    epochs=initial_epochs,steps_per_epoch = 20,\n                    validation_data=valid_dataset,validation_steps = 10)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_epochs = 20\nvalidation_steps=10\nbase_learning_rate = 0.0001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2 = tf.keras.Sequential([base_model_2,\n                            tf.keras.layers.GlobalAveragePooling2D(),\n                            tf.keras.layers.Dense(len(TCLASS_NAME), activation='softmax')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n             loss =['categorical_crossentropy'],metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_1 = model_2.fit(train_dataset,\n                    epochs=initial_epochs,steps_per_epoch = initial_epochs,\n                    validation_data=valid_dataset,validation_steps = validation_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history_1.history['accuracy']\nval_acc = history_1.history['val_accuracy']\n\nloss = history_1.history['loss']\nval_loss = history_1.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fine tuning the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(base_model_2.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_tune = 201\nbase_model_2.trainable = True\nfor layer in base_model_2.layers[:fine_tune]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n             loss =['categorical_crossentropy'],\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_tune_epochs = 20\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model_2.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch =  history_1.epoch[-1],\n                         validation_data=valid_dataset,\n                        steps_per_epoch=45,\n                    validation_steps=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def proces_test_path(filename):\n        img = tf.io.read_file(filename)\n        img = tf.image.decode_jpeg(img)\n        return (img)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_DS = TEST_LS_DS.map(proces_test_path, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Will update the Notebook as I deal with the newer problems.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}