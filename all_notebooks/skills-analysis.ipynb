{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook uses the Kaggle data-jobs-listings-glassdoor (details below). This data set scraped Glassdoor for the following key job terms: *data-scientist, software-engineer, data-analyst, research-scientist, business-analyst, product-manager, project-manager, data-engineer, statistician, dba, database-engineer, machine-learning-engineer*\n\nThe purpose of this analysis is to:\n\n* Identify the key skills required in the data industry by using the job market as a sample set\n\n* Cross analyse my own skills in comparison with the 'in demand skills' in the data job market\n\n* Identify areas to personally upskill in"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import packages\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# listing out all variable for use later\n# good practice to set all constants as upper case variables so they can be easily modified\nGLASSDOOR_FILE_PATH='/kaggle/input/data-jobs-listings-glassdoor/glassdoor.csv'\nGLASSDOOR_COLUMN_MAPPINGS = {\n    'header.jobTitle': 'Jobtitle',\n    'job.description': 'Jobdescription',\n    'map.country': 'Country',\n    'gaTrackerData.location': 'City',\n    'header.employerName':'Employer',\n    'overview.industry': 'Industry',\n    'overview.size': 'CompanySize',\n    'rating.starRating': 'Companystarrating'\n}\nCOUNTRY_CODE_FILE_PATH = '/kaggle/input/data-jobs-listings-glassdoor/country_names_2_digit_codes.csv'\nTRANSFORMATIONS = {'City': 'title', 'Country':'title', 'Jobdescription':'lower', 'Jobtitle':'lower', 'Industry':'lower'}\nCONSOLIDATIONS = {}\n\nCONSOLIDATIONS['Industry'] = {\n    ' technology ':\n        ['IT Services',\n         'Internet',\n         'Computer Hardware & Software',\n         'Enterprise Software & Network Solutions',\n         'cable, technology & telephone providers'\n        ],\n    ' financial services ':\n        [ 'Accounting',\n         'Banks & Building Societies',\n         'Investment Banking & Asset Management',\n         'Financial Analytics & Research',\n         'Financial Transaction Processing',\n         'Lending',\n         'stock exchanges',\n         'Insurance Operators'\n        ],\n    ' health ':\n        ['Healthcare Product Manufacturing',\n         'Healthcare Services & Hospitals',\n         'Health, Beauty & Fitness',\n         'Biotech & Pharmaceuticals'\n        ],\n    ' education ':\n        ['Colleges & Universities',\n         'Education Training Services'\n        ],\n    ' professional services':\n        ['Consulting',\n         'Advertising & Marketing',\n         'Legal',\n         'Staffing & Outsourcing'\n        ],\n    ' government agencies':\n        ['Government Agencies'],\n    ' consumer/retail':\n        ['Other Retail Shops', 'Publishing', 'TV Broadcasting & Cable Networks'],\n    ' other':\n        ['Aerospace & Defence',\n         'Sports & Recreation',\n         'Membership Organisations',\n         'Gambling',\n         'Airlines',\n         'Wood Product Manufacturing',\n         'Charitable Foundations',\n         'null'\n        ],\n    ' eur':\n        ['Utilities', 'Building & Construction', 'Mining', 'Building & Personnel Services'],\n    ' consumer/retail':\n        ['Grocery Shops & Supermarkets'],\n    ' unspecified industry':\n        ['null']\n}\n\n## consolidated the cloud cleanup into one sep with the industry cleanup\nCONSOLIDATIONS['Jobdescription'] = {\n    ' alibaba cloud ': ['alibaba'],\n    ' amazon web services (aws) ': [\n        'amazon web services',\n        'aws'\n    ],\n    ' google cloud platform (gcp) ': [\n        'google cloud platform',\n        'gcp',\n        'google cloud'\n    ],\n    ' ibm cloud ': [\n        'ibm'\n    ],\n    ' microsoft azure ': [\n        'azure'\n    ],\n    ' oracle cloud ': [\n        'oracle'\n    ],\n    ' red hat cloud ': [\n        'red hat'\n    ],\n    ' sap cloud ': [\n        'sap'\n    ],\n    ' salesforce cloud ': [\n        'salesforcre'\n    ],\n    ' vmware cloud ': ['vmware']\n    \n} \n\n\nCLOUDS = ['AWS', 'GCP', 'Azure']\n\nJOB_CATEGORIES = [\n    ('analyst|analytics', 'data analyst'),\n    ('scientist|science', 'data scientist'),\n    ('engineer|developer', 'data engineer'),\n    ('architect', 'data architect'),\n    ('database administrator', 'database administrator')\n]\n\nLANGUAGES = ['python', 'r', 'sql', 'c', 'java', 'javascript', 'matlab', 'scala', 'swift', 'julia']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the main file for glassdoor listings\nglassdoor_data = pd.read_csv(GLASSDOOR_FILE_PATH)\nglassdoor_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This approach utilizes a dictionary to limit the columns and appropriately map the column names\n# by externalizing this to a constant, it is easy to add, delete, or rename columns\nglassdoor = glassdoor_data[GLASSDOOR_COLUMN_MAPPINGS.keys()].copy().rename(columns=GLASSDOOR_COLUMN_MAPPINGS)\nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This table has a list of country names vs 2 digit codes\ncountry_codes = pd.read_csv(COUNTRY_CODE_FILE_PATH)\ncountry_codes.head()\n\n# We merge both by 2 digit code, and then fill the NaNs with the full country name\nglassdoor = pd.merge(glassdoor, country_codes, left_on='Country', right_on='Code', how='left')\n\n# Then replace the 2 digits codes with full name\nglassdoor.Country = glassdoor.Name.fillna(glassdoor.Country)\nglassdoor = glassdoor.drop(['Name', 'Code'], axis=1)\nglassdoor = pd.merge(glassdoor, country_codes, left_on='Country', right_on='Name', how='inner') #changed so that we can remove the dropna below\nglassdoor.head()\n\n# # Finally, this block removes any other values that do not match standard naming\n# glassdoor.dropna(subset=['Name'], inplace=True) ## Assuming there are no missing values in country codes, this can just use an inner join\nglassdoor = glassdoor.drop(['Name', 'Code'], axis=1)\nlistings_after = glassdoor.shape[0]\nprint('After removing countries names that don\\'t match standard naming there' \\\n      f'are {listings_after} job listings.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean up casing on the columns that are going to have user input/transformation applied to them later on in the notebook\n\n## Converting transformations to metadata and applying string transformations based on the value in the dictionary\nfor k, v in TRANSFORMATIONS.items():\n    glassdoor[k] = getattr(glassdoor[k].str, v)()\nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## since similar logic is used in multiple places, I created a function\ndef get_valid_response(cleansing_method, valid_values, invalid_response):\n    while True:\n        user_input = input()\n        user_value = getattr(user_input, cleansing_method)()\n        if user_value not in valid_values:\n            print(invalid_response)\n        else:\n            break\n    return user_value\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This block asks the user to narrow down the job location by either City or Country\n\n# enhancement: refactor to check that the answer that the user gives for city/country is a valid value in the dataset\n# enhancement: refactor to ask if they would like to analyse by a country or city at all\n\n\n\n\nstatement_question = print(\"Would you like to analyse by Country or City?\")\n# using the function defined above instead\ncountry_city = get_valid_response('title', ['Country','City'], 'Sorry, the value you entered does not match City or Country, please try again')\nglassdoor.dropna(subset=[country_city], inplace=True)\nif country_city == 'Country': \n    print(\"You have selected to analyse by Country. What Country would you like to analyse?\")\nelif country_city == 'City':\n    print(\"You have selected to analyse by City. What City would you like to analyse?\")\nelse:\n    print(\"Program Error\")\n\n# We can reuse the function here so that the user doesn't have to move forward if the city or country doesn't have any records\ncountry_city_value = country_city_value = get_valid_response('title', glassdoor[country_city].unique(), 'There are no records matching that request. Please try again')\n\n\n#This block takes the column the user selected - country or city - as well as the value to narrow down the location\nglassdoor = glassdoor[glassdoor[country_city] == (country_city_value)]\nglassdoor.head()\n\n#Unhash for double checking/testing\n#list = glassdoor['City'].unique().tolist()\n#list[-200:]\n\nlistings_after = glassdoor.shape[0]\nprint('After removing countries names that don\\'t match standard naming there' \\\n      f'are {listings_after} job listings.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of job titles that are data specific - note that the below filters for any that CONTAIN the following key terms in any combination \n# Seeing as we are mostly interested in 'data', titles that contain the word 'data' should cover most of the roles we are interested in. A few other terms have been added in for good measure.\njob_titles = ['data', 'analytics', 'machine learning']\n\n\n# Creating masks for each job title to identify where they appear\n## Since you already know that you lowercased the jobtitle, you could lowercase the job titles, too instead of ignorecase, but this is explicit and perfectly fine\njob_masks = [glassdoor.Jobtitle.str.contains(Jobtitle, flags=re.IGNORECASE, regex=True) for Jobtitle in job_titles]\n# Combining all masks where any value is True, return True\ncombined_mask = np.vstack(job_masks).any(axis=0)\ncombined_mask\n\n# Applying the mask to the dataset\nglassdoor = glassdoor[combined_mask].reset_index(drop=True)\nlistings_after = glassdoor.shape[0]\nprint(f'After refining job titles there were {listings_after} job listings.')\nglassdoor.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The below is a sample of the remaining job titles. From the list is there any remaining key words that you would like removed from the analysis? e.g. you might find it useful to remove certain levels such as graduate')\n\njob_title_list = glassdoor['Jobtitle'].unique().tolist()\njob_title_list[-200:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This question asks the user if they would like to remove any terms from job titles\n#e.g. you can choose to remove key terms related to level such as graduate or intern\n\n# job_question = print('Would you like to remove any key terms from the Job Title? Please enter Y or N')\n# #validate that the user is entering only Y or N\n# ## replaced to use common function\n\n## use recursion for the entire interaction\ndef cleanse_terms(glassdoor, continued=False):\n    if continued:\n        print('would you like to remove more terms?')\n    else:\n        print('Would you like to remove any key terms from the Job Title? Please enter Y or N')\n    user_answer = get_valid_response('upper', ['Y','N'], 'Sorry, you did not enter a valid input, please try again')\n    if user_answer == 'Y':\n        print (\"Enter the term you would like to remove. Please only enter a single term\")\n        user_input = input().lower()\n        term_mask = glassdoor['Jobtitle'].str.contains(user_input)\n        glassdoor = glassdoor[~term_mask]\n        listings_after_rem = glassdoor.shape[0]\n        print(f'After refining job titles there were {listings_after_rem} job listings.')\n        return cleanse_terms(glassdoor, True)\n    else:\n        print (\"You selected to continue with the data set as is\")\n        return glassdoor\n\ncleanse_terms(glassdoor)\n   \n#unhash statement to test/double check the list\n#list = newdp['Jobtitle'].unique().tolist()\n#print(list[-200:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean up and consolidation of industries\n# Initially we made everything lower case in this column, so no need to worry about casing\n\n### This metdata may be more readable if it's reversed and a bit easier to update - see CONSOLIDATIONS above\n\n# using regex to replace the group of terms instead of one at a time to save on performance\nfor field, consolidation in CONSOLIDATIONS.items():\n    for repl, finds in consolidation.items():\n        regex_pattern = r\"(?=(\"+'|'.join([f.lower() for f in finds])+ r\"))\"\n        function = lambda x: re.sub(regex_pattern, repl.lower(), x) if x==x else x\n        glassdoor[field] = list(map(function, glassdoor[field]))\n\n\nglassdoor['Industry'] = glassdoor['Industry'].fillna('other')   \nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this block creates a column that pulls out the reference to the 3 main cloud platforms. \n#The reason we flatten it and pull it into 3 different columns, rather than 1, is that is makes it easier for filtering and analysis in front end visualisation tools\n#It also allows for easy analysis and comparison of cloud platforms as a Job description may mention more than one cloud platform\n\n## Converted to metadata for maintainability and to reduce redundent code\n\n\nfor cloud in CLOUDS:\n    glassdoor['CloudPlatform({})'.format(cloud)] = glassdoor['Jobdescription'].str.extract('({})'.format(cloud.lower()), expand=True)\n\n\nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this block of code uses categorises the jobs into 6 categories: data engineer, data analyst, data scientist, business analyst, database administrator, data architect\n#this creates a new column called job category\n\n## moving this to metadata and using a recursive function to apply the nested ternary logic\n\n\n\ndef get_category(jobtitles, job_categories, index=0):\n    if index == (len(job_categories)-1):\n        terms, category = job_categories[index]\n        return np.where(jobtitles.str.contains(terms), category, 'other')\n    else:\n        terms, category = job_categories[index]\n        return np.where(jobtitles.str.contains(terms), category, get_category(jobtitles, job_categories, index+1))\n        \n        \nglassdoor['job_category'] = get_category(glassdoor['Jobtitle'], JOB_CATEGORIES)\n    \n\nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this block creates a column that pulls out the reference to the the top 10 coding languages for data. This was pulled from https://www.analyticsinsight.net/top-10-data-science-programming-languages-for-2020/ \n#The reason we flatten it and pull it into different columns, rather than 1, is that is makes it easier for filtering and analysis in front end visualisation tools\n#It also allows for easy analysis and comparison of coding languages as a Job description often mentions more than one coding language\n\n## Moving to metadata and iterating over it to reduce redundency in code\n\n\nfor language in LANGUAGES:\n    glassdoor['language_{}'.format(language)] = glassdoor['Jobdescription'].str.extract('(\\\\b{}\\\\b)'.format(language), expand=True)\n\n\nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since the counting and threshold logic is command, this is a function for applying it generically\n\ndef add_count_and_required(count_field, field_pattern, field_items, required_field, minimum):\n    count = glassdoor[[field_pattern.format(x) for x in field_items]].copy()\n    glassdoor[count_field] = count.apply(lambda x: x.count(), axis=1)\n    glassdoor[required_field] = list(map(lambda x: 1 if x >= minimum else 0, glassdoor[count_field]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select the columns required for this analysis\n\n## moving to use a generic implementation\nadd_count_and_required('count_languages', 'language_{}', LANGUAGES, 'language_req', 1)\n\nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## moving to use a generic implementation\nadd_count_and_required('count_platforms', 'CloudPlatform({})', CLOUDS, 'platform_req', 1)\n\n\nglassdoor.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# This creates another data frame with the counts of values in cloud platform and code language platforms\n\nCODE_COLUMN_MAPPINGS = {'language_python': 'Python', 'language_r': 'R', 'language_sql': 'SQL', 'language_c': 'C', 'language_java': 'Java', 'language_javascript': 'Javascript', 'language_matlab': 'MatLab', 'language_scala': 'Scala', 'language_swift': 'Swift', 'language_julia': 'Julia', 'CloudPlatform(AWS)': 'AWS', 'CloudPlatform(Azure)': 'Azure', 'CloudPlatform(GCP)': 'GCP' }\n\nglassdoor_code = glassdoor[CODE_COLUMN_MAPPINGS.keys()].copy().rename(columns=CODE_COLUMN_MAPPINGS)\n\ncode_platform_counts = glassdoor_code.count()\n\n#code_platform_counts.head()\n\ncode_file_name = 'code_platform_counts'\n\ncode_platform_counts.to_csv('{}.csv'.format(code_file_name),index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now to export the finalised data set\nprint(\"input a name for your final file \")\ninput7 = input()\nfile_name = input7.lower()\n\nglassdoor.to_csv('{}.csv'.format(file_name),index=False)\nprint(\"to access your file go to the right side panel and select 'data'>'Output'. Click the refresh button, the select the 3 dots to download the file\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}