{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#look for null values\ntrain_data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix the null value for bmi by using mean\ntrain_data.bmi = train_data.bmi.fillna(train_data.bmi.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check all categorical values\nnew_train = pd.DataFrame()\ncol_dict = []\nunique_dict = []\ncount_dict = []\nobj_col = train_data.select_dtypes(include='object')\nfor col in obj_col.columns:\n    col_dict.append(col)\n    unique_dict.append(obj_col[col].unique())\n    count_dict.append(obj_col[col].value_counts())\nnew_train['col_dict'] = col_dict\nnew_train['unique_dict'] = unique_dict\nnew_train['count_dict'] = count_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.stroke.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.histplot(x= train_data.stroke, legend=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clearly this is imbalanced dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train_data.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from above we see that ID is not at all related, hence can be dropped\n# age seems to be somehow correlated to stroke.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.drop('id', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding of all the categorical columns\nobj_col = train_data.select_dtypes(include='object')\nfor col in obj_col.columns:\n    #convert column types\n    obj_col[col] = obj_col[col].astype('category')\n    train_data[col+'_cat'] = obj_col[col].cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj_col.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_data = train_data.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_data = new_train_data.drop(columns=new_train_data.select_dtypes(include='object'), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(new_train_data.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets balance the data as it is highly imbalanced\n# lets try first cross validation\n# oversamplling otherwise number of data would be too less (oversampling with SMOTE)\n# BalancedBaggingClassifier with RandomForest as base estimator\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = new_train_data.drop(columns = 'stroke', axis=1)\ny = new_train_data.stroke","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import recall_score, f1_score, roc_auc_score, accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.ensemble import BalancedBaggingClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_model(model, params=None):\n    smoter = SMOTE(random_state=42)\n    \n    scores = []\n    if params is None:\n        params = {\n            'n_estimators': 100,\n            'max_depth': 5,\n            'random_state': 13\n        }\n        \n    Kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n    for i,j in Kfold.split(X,y):\n        X_train, X_test = X.iloc[i],X.iloc[j]\n        y_train, y_test = y.iloc[i], y.iloc[j]\n        \n        X_train_upsample, y_train_upsample = smoter.fit_resample(X_train, y_train)\n        model_obj  = model(**params).fit(X_train_upsample, y_train_upsample)\n        score = f1_score(y_test, model_obj.predict(X_test))\n        \n        scores.append(score)\n    return np.array(scores)\n        #summarize the train and test composition\n        #train_0, train_1 = len(y_train[y_train==0]), len(y_train[y_train==1])\n        #test_0, test_1 = len(y_test[y_test==0]), len(y_test[y_test==1])        \n\n        #print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_tracker = []\n# lets loop through the best params\nparams = {'n_estimators': [50, 100, 200],\n 'max_depth': [4, 6, 10, 12],\n 'random_state': [13]}\n\nfor n_est in params['n_estimators']:\n    for max_dep in params['max_depth']:\n        example_params = {'n_estimators' : n_est,\n                         'max_depth': max_dep,\n                         'random_state' : 13\n                         }\n        example_params['recall'] = score_model(RandomForestClassifier, example_params).mean()\n        \n        score_tracker.append(example_params)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(score_tracker, key = lambda x: x['recall'], reverse=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try score model with decisiontreeclassifier\nparams_dtc = {\n   'criterion': 'entropy',\n    'splitter': 'random',\n    'max_depth': 5,\n    'random_state': 13\n}\nscore_model(DecisionTreeClassifier, params_dtc)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best one is for n_est=100, max_depth=6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trying BalancedBaggingClassifier\nrfc = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\nbbc = BalancedBaggingClassifier(base_estimator=rfc, sampling_strategy='auto',\n                                replacement=False, random_state=3)\nX_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=33)\nbbc.fit(X_train, y_train)\npreds = bbc.predict(X_test)\nprint('recall score with BalancedBaggingClassifier_rfc: ', recall_score(y_test, preds))\n\n# try with DecisionTreeClassifier\ndtc = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=42)\nbbc_dtc = BalancedBaggingClassifier(base_estimator=dtc, sampling_strategy='auto',\n                                replacement=False, random_state=3)\nbbc_dtc.fit(X_train, y_train)\npreds_dtc = bbc_dtc.predict(X_test)\nprint('f1 score with BalancedBaggingClassifier_dtc: ', f1_score(y_test, preds_dtc))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}