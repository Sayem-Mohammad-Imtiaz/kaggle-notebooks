{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loading Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_bc = pd.read_csv('../input/credit-card-customers/BankChurners.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Viewing all Columns in play"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_desc = data_bc.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting view of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bc.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n             'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'],\n                      axis='columns', inplace=True)\n\ndata_desc = data_bc.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding out Columns that have numerical and non-numerical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_desc.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bc.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above two output we can identify non numerical columns"},{"metadata":{},"cell_type":"markdown","source":"# One hot encoding for non numerical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bc = pd.get_dummies(data_bc, columns=['Attrition_Flag', 'Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'])\n\ndata_bc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bc.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping one column each for one hot encoded columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bc1 = data_bc.drop(columns=['Attrition_Flag_Attrited Customer', 'Gender_F', 'Education_Level_College', \n                                 'Marital_Status_Divorced', 'Income_Category_Unknown', 'Card_Category_Blue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bc1.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Test and Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data_bc1[['CLIENTNUM', 'Customer_Age', 'Dependent_count', 'Months_on_book',\n       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio', 'Gender_M',\n       'Education_Level_Doctorate', 'Education_Level_Graduate',\n       'Education_Level_High School', 'Education_Level_Post-Graduate',\n       'Education_Level_Uneducated', 'Education_Level_Unknown',\n       'Marital_Status_Married', 'Marital_Status_Single',\n       'Marital_Status_Unknown', 'Income_Category_$120K +',\n       'Income_Category_$40K - $60K', 'Income_Category_$60K - $80K',\n       'Income_Category_$80K - $120K', 'Income_Category_Less than $40K',\n       'Card_Category_Gold', 'Card_Category_Platinum', 'Card_Category_Silver']]\nY=data_bc1[['Attrition_Flag_Existing Customer']]\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=0)\n\nX_train.to_csv('X_train.csv')\nX_test.to_csv('X_test.csv')\n\nY_train.to_csv('Y_train.csv')\nY_test.to_csv('Y_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading saved data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.read_csv('./X_train.csv')\nX_test = pd.read_csv('./X_test.csv')\nY_train = pd.read_csv('./Y_train.csv').to_numpy()[:,1]\nY_test = pd.read_csv('./Y_test.csv').to_numpy()[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg=LogisticRegression(C=1000,max_iter=50000)\nlog_reg.fit(X_train, Y_train)\n\n\nprint('--------------------------------------------------------------------------')\nprint('Logistic Regression:')\nprint('Traning Model accruracy scores: {:.3f}'.format(log_reg.score(X_train,Y_train)))\nprint('Test Model accruracy scores: {:.3f}'.format(log_reg.score(X_test,Y_test)))\nprint('--------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN method"},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN=KNeighborsClassifier(n_neighbors=20)\nKNN.fit(X_train, Y_train)\nY_pred=KNN.predict(X_test) #here we make our predictions\n\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\n#Checking the accuracy \nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n\nCount_row = []\nindex = 0\n\nfor i, row in ActVPred.iterrows():\n    if (row['Actual'] < 1):\n        if (row['Predicted'] < 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    else:\n        if (row['Predicted'] >= 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    index = index + 1\n    \nprint('--------------------------------------------------------------------------')\nprint('KNN:')\nprint('Model accruracy scores: {:.3f}'.format(Count_row.count(1)/index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"Clf =  RandomForestClassifier(n_estimators = 500, n_jobs = -1)\nClf.fit(X_train, Y_train)\nY_pred=Clf.predict(X_test) \n\n\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\n#Checking the accuracy \nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n\nCount_row = []\nindex = 0\n\nfor i, row in ActVPred.iterrows():\n    if (row['Actual'] < 1):\n        if (row['Predicted'] < 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    else:\n        if (row['Predicted'] >= 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    index = index + 1\n    \n    \nprint('--------------------------------------------------------------------------')\nprint('Random Forest Classifier:')\nprint('Model accruracy scores: {:.3f}'.format(Count_row.count(1)/index))\n\ncompare1 = pd.DataFrame()\ncompare1[0] = Clf.feature_importances_\ncompare1[1] = X_test.columns\n\nprint('Feature importance: ')\nprint(compare1.sort_values(by=0,ascending= False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network\n\nsolver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\nThe solver for weight optimization. \n\n-‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n\n-‘sgd’ refers to stochastic gradient descent.\n\n-‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n\nNote: The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better."},{"metadata":{"trusted":true},"cell_type":"code","source":"NN = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)\nNN.fit(X_train, Y_train)\n\nY_pred = NN.predict(X_test)\n\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\n#Checking the accuracy \nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n\nCount_row = []\nindex = 0\n\nfor i, row in ActVPred.iterrows():\n    if (row['Actual'] < 1):\n        if (row['Predicted'] < 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    else:\n        if (row['Predicted'] >= 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    index = index + 1\n    \n    \nprint('--------------------------------------------------------------------------')\nprint('Random Forest Classifier:')\nprint('Model accruracy scores: {:.3f}'.format(Count_row.count(1)/index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForestRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the best model from Grid Serach CV\nmodel = RandomForestRegressor(max_depth=15, random_state=42) \n\nmodel.fit(X_train, Y_train)\n\nY_pred = model.predict(X_test)\n\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\n#Checking the accuracy \nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n\nCount_row = []\nindex = 0\n\nfor i, row in ActVPred.iterrows():\n    if (row['Actual'] < 1):\n        if (row['Predicted'] < 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    else:\n        if (row['Predicted'] >= 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    index = index + 1\n    \nprint('--------------------------------------------------------------------------')\nprint('RandomForestRegressor:')\nprint('Model accruracy scores: {:.3f}'.format(Count_row.count(1)/index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nGNB = GaussianNB()\n\nGNB.fit(X_train, Y_train)\nY_pred = GNB.predict(X_test)\n\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\n#Checking the accuracy \nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n\nCount_row = []\nVisual_rep = []\nindex = 0\n\nfor i, row in ActVPred.iterrows():\n    if (row['Predicted'] < 0.5):\n        Visual_rep.append(0)\n    else:\n        Visual_rep.append(1)\n            \n    if (row['Actual'] < 1):\n        if (row['Predicted'] < 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    else:\n        if (row['Predicted'] >= 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    \n    index = index + 1\n    \nprint('--------------------------------------------------------------------------')\nprint('Naive Bayes:')\nprint('Model accruracy scores: {:.3f}'.format(Count_row.count(1)/index))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBRegressor()\nmodel.fit(X_train, Y_train)\nY_pred = model.predict(X_test)\n\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\n#Checking the accuracy \nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n\nCount_row = []\nVisual_rep = []\nindex = 0\n\nfor i, row in ActVPred.iterrows():\n    if (row['Predicted'] < 0.5):\n        Visual_rep.append(0)\n    else:\n        Visual_rep.append(1)\n        \n    if (row['Actual'] < 1):\n        if (row['Predicted'] < 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    else:\n        if (row['Predicted'] >= 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    index = index + 1\n    \nprint('--------------------------------------------------------------------------')\nprint('XGBoost:')\nprint('Model accruracy scores: {:.3f}'.format(Count_row.count(1)/index))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Representation of the prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.subplots(figsize=(10, 10))\nax = sns.heatmap(confusion_matrix(Visual_rep,Y_test),annot=True,cmap='coolwarm',fmt='d')\nax.set_title('Prediction On Original Data With XGBoost Confusion Matrix',fontsize=18)\nax.set_xticklabels(['Churn','Not Churn'],fontsize=18)\nax.set_yticklabels(['Predicted Churn','Predicted Not Churn'],fontsize=18)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"Cat = CatBoostClassifier(silent = True)\n\ndetails = Cat.fit(X_train, Y_train)\nY_pred = Cat.predict(X_test)\n\nActVPred = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\nprint(ActVPred)\n\n#Checking the accuracy \nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test, Y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))\n\nCount_row = []\nVisual_rep = []\nindex = 0\n\nfor i, row in ActVPred.iterrows():\n    if (row['Predicted'] < 0.5):\n        Visual_rep.append(0)\n    else:\n        Visual_rep.append(1)\n            \n    if (row['Actual'] < 1):\n        if (row['Predicted'] < 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    else:\n        if (row['Predicted'] >= 0.5):\n            Count_row.append(1)\n        else:\n            Count_row.append(0)\n    \n    index = index + 1\n    \nprint('--------------------------------------------------------------------------')\nprint('CatBoost:')\nprint('Model accruracy scores: {:.3f}'.format(Count_row.count(1)/index))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Representation of the prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.subplots(figsize=(10, 10))\nax = sns.heatmap(confusion_matrix(Visual_rep,Y_test),annot=True,cmap='coolwarm',fmt='d')\nax.set_title('Prediction On Original Data With CatBoost Confusion Matrix',fontsize=18)\nax.set_xticklabels(['Churn','Not Churn'],fontsize=18)\nax.set_yticklabels(['Predicted Churn','Predicted Not Churn'],fontsize=18)\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}