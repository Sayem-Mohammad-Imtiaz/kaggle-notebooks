{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom __future__ import print_function\nimport pandas as pd\nfrom pandas import read_excel\nfrom sklearn import decomposition, preprocessing, svm \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\nfrom scipy import interp\nfrom matplotlib import pyplot as plt\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nfrom sklearn import metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom keras.utils.np_utils import to_categorical\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, Dropout\nfrom keras import regularizers\nfrom keras.callbacks import History \nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom keras.utils import np_utils\nhistory = History()\n\n%matplotlib inline\n","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"2b0fed7ff566f57968a195dab9c9e8c093856142"},"cell_type":"markdown","source":"While looking at the 14-parameter dataset, 'slope', 'ca' and 'thal' had so many missing values that I went ahead and disregarded them entirely. Down to 10 parameters, I also noticed the numerous instances of missing data (notated by a '?\"). While looking through a few cases, it did not seem that simply interpolation would be able to correctly fill in the gaps. I decided to test whether or not the patient count was high enough to take out all of the rows containing empty data and still see reasonably high performance. This left me with 10 parameters for 261 patients."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"pD = pd.read_csv(\"../input/data.csv\",header = None, low_memory = False)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f164011189507bd0f2b0d54dd8de727c01e18b62"},"cell_type":"code","source":"pData = pD.as_matrix()","execution_count":88,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65e2c9775f19b0890c3427b9df57efd1a296036d"},"cell_type":"code","source":"# convert every '?' to a nan and then convert the array of strings to floats.\nlab = pData[0,:];\npData = np.delete(pData, (0), axis=0)\npData[pData == '?'] = np.nan;\npData = pData.astype('float32')\n# pData = pData[~np.isnan(pData).any(axis=1)]\n\n","execution_count":89,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6228402872080b43603daedd97357d3e3d7a58e"},"cell_type":"code","source":"# Grab all of the columns that aren't completely void, concatenate the target data and take out any row with remaining missing data.\nd = pData[:,0:pData.shape[1]-4];\nd = np.hstack((d,pData[:,pData.shape[1]-1].reshape(len(pData[:,0]),1)));\nd = d[~np.isnan(d).any(axis=1)]\ntargets = d[:,d.shape[1]-1];\nd = np.delete(d, (d.shape[1]-1), axis=1)\n","execution_count":90,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40bd121d9d523adf408126ba2411269904f77233"},"cell_type":"code","source":"# My first attempt was to use LDA and min-max normalization.\ndN = preprocessing.minmax_scale(d, feature_range=(-1, 1), axis=0, copy=True)\nlda = LinearDiscriminantAnalysis(n_components=3)\nX = lda.fit(dN, targets).transform(dN)  \ntargets = np.reshape(targets.astype(int),(len(targets),1))","execution_count":93,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e438501482320cfd51eda3e9660484efb968218"},"cell_type":"code","source":"# sort for easy plotting (out of habit)\nx = np.hstack((X,targets))\nx = x[x[:,1].argsort()]","execution_count":94,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba107e113adb37e6ed608c01faf8aa9dd7b10533"},"cell_type":"code","source":"# Determined how many patients belong to each group in order to plot accordingly.\ntype0 = sum(np.isin(x[:,1], 0));\ntype1 = sum(np.isin(x[:,1], 1));\nq=0;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.bar(np.linspace(1,type0,type0), x[0:type0,q], align='center', label='None')\nax1.bar(np.linspace(type0+1,type0+type1,type1), x[type0:type0+type1,q], color='red', align='center', label='Afflicted')\nplt.xlabel('Patient',fontsize=18)\nplt.ylabel('LDA Loading',fontsize=18)\nplt.title('1D LDA Bar Plot',fontsize=18)\nplt.legend(loc='upper left',prop={'size': 18});\nplt.show()","execution_count":95,"outputs":[]},{"metadata":{"_uuid":"59c07831aede13e4224da969e8b6e40c2aa6af12"},"cell_type":"markdown","source":"The plot above look reasonably promising, especially since LDA only used a single feature per patient. A decision-tree cross-validation and AUROC curve are shown below to illustrate the results further."},{"metadata":{"trusted":true,"_uuid":"f0a76554a974d1571c398b8c1525bc138d68ebd8"},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\n# cross_val_score(clf, x[:,0].reshape(len(x[:,0]),1), x[:,1], cv=5)\nfiveF = cross_val_score(clf, x[:,0].reshape(len(x[:,0]),1), x[:,1], cv=5)\nprint(\"All: \", fiveF, \". \\nAverage: \", np.mean(fiveF) )","execution_count":96,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"072482d33b0006d96ac9a5bc07f3f406fee44bb3"},"cell_type":"code","source":"X = x[:,0].reshape(x[:,0].shape[0],1);\n# X = x[:,0];\ny = x[:,1];\nn_samples, n_features = X.shape\ncv = StratifiedKFold(n_splits=5)\nclassifier = svm.SVC(kernel='linear', probability=True,\n                     random_state=0)\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nplt.figure(figsize=(10,10))\ni = 0\nfor train, test in cv.split(X, y):\n    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n    # Compute ROC curve and area the curve\n    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n    i += 1\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n         label='Chance', alpha=.8)\n\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlim([-0.01, 1.01])\nplt.ylim([-0.01, 1.01])\nplt.xlabel('False Positive Rate',fontsize=18)\nplt.ylabel('True Positive Rate',fontsize=18)\nplt.title('Cross-Validation ROC of LDA',fontsize=18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":97,"outputs":[]},{"metadata":{"_uuid":"f2844fc7b74691192bb48b0043ab41eafc7635dd"},"cell_type":"markdown","source":"Not bad, but maybe PCA can do a bit better."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fa8b7b75b7cca02becb92f683ecd78eace6919e1"},"cell_type":"code","source":"# Normalize appropriately for PCA\ndN = stats.zscore(d.astype(float), axis=0, ddof=1)\npca = decomposition.PCA(n_components=2)\npca.fit(dN)\nX = pca.transform(dN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7c6d206991ed09fe9c17e8f54cfd5951c22b171"},"cell_type":"code","source":"x = np.hstack((X,targets))\nx = x[x[:,2].argsort()]\n\ntype0 = sum(np.isin(x[:,2], 0));\ntype1 = sum(np.isin(x[:,2], 1));\n# type2 = sum(np.isin(x[:,2], 2));\nq=0;\nr=1;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.scatter(x[0:type0,q],x[0:type0,r],s=25, c='blue', marker=\"s\", label='None')\nax1.scatter(x[type0:type0+type1,q],x[type0:type0+type1,r],s=25, c='red', marker=\"o\", label='Afflicted')\nplt.xlabel('PC 1',fontsize=18)\nplt.ylabel('PC 2',fontsize=18)\nplt.title('2D PCA Scatter Plot',fontsize=18)\nplt.legend(loc='upper left',prop={'size': 18});","execution_count":99,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd52cb18a8122441a037a96c8d84213a4649a038"},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\n# cross_val_score(clf, x[:,0].reshape(len(x[:,0]),1), x[:,1], cv=5)\nfiveF = cross_val_score(clf, x[:,0:2], x[:,2], cv=5)\nprint(\"All: \", fiveF, \". \\nAverage: \", np.mean(fiveF) )","execution_count":100,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"759b4da2fefeaef3bc63a9e58409eadf22e0f483"},"cell_type":"code","source":"X = x[:,0:2];\ny = x[:,2];\nn_samples, n_features = X.shape\ncv = StratifiedKFold(n_splits=5)\nclassifier = svm.SVC(kernel='linear', probability=True,\n                     random_state=0)\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nplt.figure(figsize=(10,10))\ni = 0\nfor train, test in cv.split(X, y):\n    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n    # Compute ROC curve and area the curve\n    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n    i += 1\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n         label='Chance', alpha=.8)\n\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlim([-0.01, 1.01])\nplt.ylim([-0.01, 1.01])\nplt.xlabel('False Positive Rate',fontsize=18)\nplt.ylabel('True Positive Rate',fontsize=18)\nplt.title('Cross-Validation ROC of PCA',fontsize=18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":101,"outputs":[]},{"metadata":{"_uuid":"8ef5dbf923dc2994e37d9a5e1746c94ffb19b3e2"},"cell_type":"markdown","source":"Didn't perform quite as well as LDA, even with 2 PCs (trying more PCs doesn't give any significant performance improvement), but still good. Maybe an MLP can do a bit better."},{"metadata":{"trusted":true,"_uuid":"01c9d3965c39411ff1ffc1dc05f3eab95c86117d"},"cell_type":"code","source":"# One-hot encoding and back to min-max norm\ny = np_utils.to_categorical(targets,num_classes=2)\ndN = preprocessing.minmax_scale(d, feature_range=(0, 1), axis=0, copy=True)\n# 50/50 train/test\ntrain_X, test_X, train_y, test_y = train_test_split(dN, y, train_size=0.5, random_state=0)","execution_count":102,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3a01373f2920df9f14b79b9e7c2f26fcb1fad8e5"},"cell_type":"code","source":"# Model definition. Dropout did not seem to help much here\ndef create_baseline():\n    model = Sequential()\n    model.add(Dense(15, activation='relu',input_shape=(10,)))\n    model.add(Dense(10, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n#     model.add(Dropout(0.2))\n    model.add(Dense(2, activation='sigmoid',kernel_regularizer=regularizers.l2(0.0001)))\n    keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-7, decay=0.0, amsgrad=False)\n    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy',auc_roc])\n#     my_callbacks = [EarlyStopping(monitor='auc_roc', patience=50, verbose=1, mode='max')]\n    return model\n\n# This is a function seen at 'https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras' \n# by 'https://stackoverflow.com/users/7093436/tom'\ndef auc_roc(y_true, y_pred):\n    # any tensorflow metric\n    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n\n    # find all variables created for this metric\n    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n\n    # Add metric variables to GLOBAL_VARIABLES collection.\n    # They will be initialized for new session.\n    for v in metric_vars:\n        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n\n    # force to update metric values\n    with tf.control_dependencies([update_op]):\n        value = tf.identity(value)\n        return value","execution_count":116,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"22aecfce5adf130c2ebf27a8eabe9c8392a9b341"},"cell_type":"code","source":"# time to train\nmodel = create_baseline();\nhistory = model.fit(train_X, train_y,\n          validation_data=(test_X, test_y),\n          batch_size=32, epochs=500, verbose=1)","execution_count":117,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"431b309dd1f0b7ff766a69d6e7f4cabe200f4d18"},"cell_type":"code","source":"# AUROC curve and test accuracy for performance metric\ny_pred = model.predict_proba(test_X);\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(test_y[:,0], y_pred[:,0]);\nauc_keras = auc(fpr_keras, tpr_keras);\naccuracy = np.mean(np.equal(test_y, np.round(y_pred)));\nplt.figure(figsize=(10,10))\nplt.plot(fpr_keras, tpr_keras, color='black', label='AUC = {:.3f}'.format(auc_keras));\nplt.xlabel('False positive rate',fontsize=18);\nplt.ylabel('True positive rate',fontsize=18);\nplt.title('ROC curve: Max-Min Normalized - Test Accuracy = %0.2f' % (accuracy),fontsize=18);\nplt.legend(loc='lower right',fontsize=18);\n# print('Test Accuracy: ', np.mean(np.equal(test_y, np.round(y_pred))));\n","execution_count":118,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e521286180b82e5f8b7395c68fb94ddcba014e96"},"cell_type":"code","source":"# Train and test loss for reference.\ntrain_loss = history.history['loss']\nval_loss   = history.history['val_loss']\n# train_acc  = estimator.history['acc']\n# val_acc    = estimator.history['val_acc']\nxc         = range(500)\n\n_=plt.figure(figsize=(10,10))\nplt.plot(xc, train_loss,label='Training')\nplt.plot(xc, val_loss, label='Validation')\nplt.xlabel('Epochs',fontsize=18)\nplt.ylabel('Loss',fontsize=18)\nplt.title('Cost Curves',fontsize=18)\nplt.legend(loc=\"upper right\", prop={'size': 15})","execution_count":120,"outputs":[]},{"metadata":{"_uuid":"bcb547bf06deef0b8c46874cacf4dfa29bf7a053"},"cell_type":"markdown","source":"Not too shabby. I'm done for now, but it is always important to check which variables are the most valuable for the characterization in a biological study. I'm a bit surprised myself that these 10 variables performed so well."},{"metadata":{"trusted":true,"_uuid":"0fdfead4e75bd07514fd644fb681f458833febbc"},"cell_type":"code","source":"model = ExtraTreesClassifier();\nmodel.fit(dN, y);\nimportance = pd.DataFrame({ '1. Params' : lab[0:-4], '2. Importance' : model.feature_importances_});\nimportance","execution_count":122,"outputs":[]},{"metadata":{"_uuid":"fa809ef958d29730db5a1f265cbbd16a5f8b4519"},"cell_type":"markdown","source":"As high as ~27.5% with \"exang\" and only ~2% & 3% with \"fbs\" and \"restecg\". I'm assuming the three columns I threw out would have made a significant impact on performance... maybe one of you has an idea to work with it correctly."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"337bce8077c3dd9d7728035877a671c09e25e057"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}