{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm\nfrom keras.preprocessing import image\npd.options.display.max_columns = 50","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-21T20:11:34.423888Z","iopub.execute_input":"2021-08-21T20:11:34.424202Z","iopub.status.idle":"2021-08-21T20:11:38.715039Z","shell.execute_reply.started":"2021-08-21T20:11:34.424124Z","shell.execute_reply":"2021-08-21T20:11:38.714144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Retinal Disease Classification: Multiclass Classification\nThis notebook seeks to classify diseased eyes through use of a computer vision model in TensorFlow.","metadata":{}},{"cell_type":"markdown","source":"We'll start off by loading our data into a pandas dataframe and adding the paths to the image files. Since it's already divided into train, validate, and test directories we'll start with making a dataframe for each.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/retinal-disease-classification/Training_Set/Training_Set/RFMiD_Training_Labels.csv')\nval_df = pd.read_csv('/kaggle/input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv')\ntest_df = pd.read_csv('/kaggle/input/retinal-disease-classification/Test_Set/Test_Set/RFMiD_Testing_Labels.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.716607Z","iopub.execute_input":"2021-08-21T20:11:38.716917Z","iopub.status.idle":"2021-08-21T20:11:38.789862Z","shell.execute_reply.started":"2021-08-21T20:11:38.716883Z","shell.execute_reply":"2021-08-21T20:11:38.789136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['img_path'] = [f'/kaggle/input/retinal-disease-classification/Training_Set/Training_Set/Training/{id}.png' for id in train_df['ID']]\nval_df['img_path'] = [f'/kaggle/input/retinal-disease-classification/Evaluation_Set/Evaluation_Set/Validation/{id}.png' for id in val_df['ID']]\ntest_df['img_path'] = [f'/kaggle/input/retinal-disease-classification/Test_Set/Test_Set/Test/{id}.png' for id in test_df['ID']]","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.791559Z","iopub.execute_input":"2021-08-21T20:11:38.791931Z","iopub.status.idle":"2021-08-21T20:11:38.808147Z","shell.execute_reply.started":"2021-08-21T20:11:38.791895Z","shell.execute_reply":"2021-08-21T20:11:38.807346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploration and Feature Engineering","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop(labels=['ID'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.809796Z","iopub.execute_input":"2021-08-21T20:11:38.810194Z","iopub.status.idle":"2021-08-21T20:11:38.818375Z","shell.execute_reply.started":"2021-08-21T20:11:38.810161Z","shell.execute_reply":"2021-08-21T20:11:38.817603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = list(train_df.columns)\ncolumns.remove('img_path')\nd_total = 0\nfor col in columns:\n    print(col)\n    print(train_df[col].value_counts())\n    print('----------------')\n    if col != 'Disease_Risk':\n        d_total += train_df[col].sum()\n        \nprint(d_total)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.821184Z","iopub.execute_input":"2021-08-21T20:11:38.821433Z","iopub.status.idle":"2021-08-21T20:11:38.896559Z","shell.execute_reply.started":"2021-08-21T20:11:38.821409Z","shell.execute_reply":"2021-08-21T20:11:38.895847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some notes from this:\n* We can see that ODPM and HR have no positive examples so we will drop the columns.\n* Since we're trying to predict specific diseases, we'll drop Disease_Risk to help with imbalancing.\n* A lot of the columns have very few examples, so we will have to do some oversampling and use class weights.\n* Some images are representative of more than one disease, since d_total is greater than the total number of images. We'll need to do multilabel classification.","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop(labels=['Disease_Risk','ODPM', 'HR'], axis=1)\nval_df = val_df.drop(labels=['ID', 'Disease_Risk', 'ODPM', 'HR'], axis=1)\ntest_df = test_df.drop(labels=['ID', 'Disease_Risk', 'ODPM', 'HR'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.897672Z","iopub.execute_input":"2021-08-21T20:11:38.897986Z","iopub.status.idle":"2021-08-21T20:11:38.907599Z","shell.execute_reply.started":"2021-08-21T20:11:38.897953Z","shell.execute_reply":"2021-08-21T20:11:38.906713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DR has our highest count for diseases, so we'll use that number as our target for rebalancing the dataframe with oversampling.","metadata":{}},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.909143Z","iopub.execute_input":"2021-08-21T20:11:38.909596Z","iopub.status.idle":"2021-08-21T20:11:38.919586Z","shell.execute_reply.started":"2021-08-21T20:11:38.909479Z","shell.execute_reply":"2021-08-21T20:11:38.918833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['PTCR']==1]","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.922599Z","iopub.execute_input":"2021-08-21T20:11:38.92294Z","iopub.status.idle":"2021-08-21T20:11:38.965261Z","shell.execute_reply.started":"2021-08-21T20:11:38.922909Z","shell.execute_reply":"2021-08-21T20:11:38.964518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weight_calc(col):\n    total = len(train_df)\n    weight = (1 / train_df[col].sum()) *  total / 2\n    return weight","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.973294Z","iopub.execute_input":"2021-08-21T20:11:38.973897Z","iopub.status.idle":"2021-08-21T20:11:38.980862Z","shell.execute_reply.started":"2021-08-21T20:11:38.973859Z","shell.execute_reply":"2021-08-21T20:11:38.980001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train = list(train_df.drop(['img_path'], axis=1).columns)\nY_val = list(val_df.drop(['img_path'], axis=1).columns)\nY_test = list(test_df.drop(['img_path'], axis=1).columns)\nunq_disease = len(Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:38.993805Z","iopub.execute_input":"2021-08-21T20:11:38.994227Z","iopub.status.idle":"2021-08-21T20:11:39.003669Z","shell.execute_reply.started":"2021-08-21T20:11:38.994188Z","shell.execute_reply":"2021-08-21T20:11:39.002835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Was going to implement class weights for this solution, but TF currently does not support using class weights in its metrics.\n# class_weights = {}\n# for i in range(0, unq_disease):\n#     class_weights[f'{i}'] = weight_calc(Y_train[i])","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:39.018775Z","iopub.execute_input":"2021-08-21T20:11:39.019109Z","iopub.status.idle":"2021-08-21T20:11:39.029337Z","shell.execute_reply.started":"2021-08-21T20:11:39.019076Z","shell.execute_reply":"2021-08-21T20:11:39.028345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll display some images just to get an idea of what kind of data we're working with.","metadata":{}},{"cell_type":"code","source":"plt.subplots(3, 4, figsize=(240, 160))\nfor i in range(12):\n    plt.subplot(3,4, i + 1)\n    img = mpimg.imread(train_df.iloc[i][43])\n    plt.imshow(img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                                                horizontal_flip=True,\n                                                                vertical_flip=True,\n                                                                rotation_range=90,\n                                                                brightness_range=[0, 0.1])\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n# The value for class_mode in flow_from_dataframe MUST be 'raw' if you are attempting to do multilabel classification.\ntrain_gen = train_datagen.flow_from_dataframe(train_df, \n                                              x_col='img_path', \n                                              y_col=Y_train,\n                                              target_size=(150,150),\n                                              class_mode='raw',\n                                              batch_size=16,\n                                              shuffle=True)\nval_gen = val_datagen.flow_from_dataframe(val_df,\n                                          x_col='img_path',\n                                          y_col=Y_val,\n                                          target_size=(150,150),\n                                          class_mode='raw',\n                                          batch_size=8)\ntest_gen = test_datagen.flow_from_dataframe(test_df,\n                                            x_col='img_path',\n                                            y_col=Y_test,\n                                            target_size=(150,150),\n                                            class_mode='raw')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:39.060889Z","iopub.execute_input":"2021-08-21T20:11:39.061231Z","iopub.status.idle":"2021-08-21T20:11:47.463414Z","shell.execute_reply.started":"2021-08-21T20:11:39.061196Z","shell.execute_reply":"2021-08-21T20:11:47.462581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling\n\nTo approach this problem I'm creating a U-Net model to use for our classification.","metadata":{}},{"cell_type":"code","source":"def UNet(inputs):\n    # First convolution block\n    x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n    d1_con = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n    d1 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(d1_con)\n    \n    # Second convolution block\n    d2 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d1)\n    d2_con = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d2)\n    d2 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(d2_con)\n    \n    # Third convolution block\n    d3 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d2)\n    d3_con = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d3)\n    d3 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(d3_con)\n    \n    # Fourth convolution block\n    d4 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d3)\n    d4_con = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d4)\n    d4 = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(d4_con)\n    \n    # Bottleneck layer\n    b = tf.keras.layers.Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(d4)\n    b = tf.keras.layers.Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(b)\n    \n    # First upsampling block\n    u1 = tf.keras.layers.Conv2DTranspose(512, 3, strides =(2,2),padding='same')(b)\n    u1 = tf.keras.layers.Concatenate(axis=3)([u1, d4_con])\n    u1 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u1)\n    u1 = tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u1)\n    \n    # Second upsampling block\n    u2 = tf.keras.layers.Conv2DTranspose(256, 3, strides =(2,2),padding='valid')(u1)\n    u2 = tf.keras.layers.Concatenate(axis=3)([u2, d3_con])\n    u2 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u2)\n    u2 = tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u2)\n    \n    # Third upsampling block\n    u3 = tf.keras.layers.Conv2DTranspose(128, 3, strides =(2,2),padding='valid')(u2)\n    u3 = tf.keras.layers.Concatenate(axis=3)([u3, d2_con])\n    u3 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u3)\n    u3 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u3)\n    \n    # Fourth upsampling block\n    u4 = tf.keras.layers.Conv2DTranspose(64, 3, strides =(2,2),padding='same')(u3)\n    u4 = tf.keras.layers.Concatenate(axis=3)([u4, d1_con])\n    u4 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u4)\n    u4 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(u4)\n    \n    # Flatten and output\n    flat = tf.keras.layers.Flatten()(u4)\n    out = tf.keras.layers.Dense(units=unq_disease, activation='sigmoid')(flat)\n    model = tf.keras.Model(inputs=[inputs], outputs=[out])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:47.476154Z","iopub.execute_input":"2021-08-21T20:11:47.476481Z","iopub.status.idle":"2021-08-21T20:11:47.499692Z","shell.execute_reply.started":"2021-08-21T20:11:47.476446Z","shell.execute_reply":"2021-08-21T20:11:47.498853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the actual training, we'll use area under the curve (AUC) of the receiving operator characteristic (ROC) since it was one of the suggested metrics for the multilabel classification task. ROC is the default value for the curve parameter, so we just initialize the AUC metric from keras without passing any parameters to it.","metadata":{}},{"cell_type":"code","source":"auc = tf.keras.metrics.AUC(multi_label=True,thresholds=[0,0.5])\naucpr = tf.keras.metrics.AUC(curve='PR',multi_label=True,thresholds=[0,0.5])\ninputs = tf.keras.layers.Input(shape=(150,150,3))\nunet = UNet(inputs)\nunet.compile(optimizer='adam', loss='binary_crossentropy', metrics=[auc, aucpr])\nunet.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:47.500953Z","iopub.execute_input":"2021-08-21T20:11:47.501289Z","iopub.status.idle":"2021-08-21T20:11:49.684753Z","shell.execute_reply.started":"2021-08-21T20:11:47.501256Z","shell.execute_reply":"2021-08-21T20:11:49.683965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.fit(train_gen, epochs=5, validation_data=val_gen)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:49.687355Z","iopub.execute_input":"2021-08-21T20:11:49.687655Z","iopub.status.idle":"2021-08-21T20:11:53.884435Z","shell.execute_reply.started":"2021-08-21T20:11:49.687628Z","shell.execute_reply":"2021-08-21T20:11:53.882339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.evaluate(test_gen)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T20:11:53.885808Z","iopub.status.idle":"2021-08-21T20:11:53.886531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Glossary\nNot entirely necessary to know all of this for the classification tasks, but I wanted to know what all of these abbreviations stood for so I figured I'd put them down here. All definitions come from the source paper \"Retinal Fundus Multi-Disease Image Dataset (RFMiD): A Dataset for Multi-Disease Detection Research.\"\n\n* DR - Diabetic retinopathy\n* ARMD - Age-related macular degeneration \n* MH - Media haze\n* DN - Drusen\n* MYA - Myopia\n* BRVO - Branch retinal vein occlusion\n* TSLN - Tessellation \n* ERM - Epiretinal membrane \n* LS - Laser scars \n* MS - Macular scars \n* CSR - Central serous retinopathy \n* ODC - Optic disc cupping \n* CRVO - Central retinal vein occlusion \n* TV - Tortuous vessels\n* AH - Asteroid hyalosis \n* ODP - Optic disc pallor\n* ODE - Optic disc edema\n* ST - Optociliary shunt\n* AION - Anterior ischemic optic neuropathy\n* PT - Parafoveal telangiectasia\n* RT - Retinal traction\n* RS - Retinitis\n* CRS - Chorioretinitis\n* EDN - Exudation\n* RPEC - Retinal pigment epithelium changes\n* MHL - Macular hole\n* RP - Retinitis pigmentosa\n* CWS - Cotton-wool spots\n* CB - Coloboma\n* ODPM - Optic disc pit maculopathy\n* PRH - Preretinal hemorrhage\n* MNF - Myelinated nerve fibers\n* HR - Hemorrhagic retinopathy\n* CRAO - Central retinal artery occlusion\n* TD - Tilted disc\n* CME -Cystoid macular edema\n* PTCR - Post-traumatic choroidal rupture\n* CF - Choroidal folds\n* VH - Vitreous hemorrhage\n* MCA - Macroaneurysm\n* VS - Vasculitis\n* BRAO - Branch retinal artery occlusion\n* PLQ - Plaque\n* HPED - Hemorrhagic pigment epithelial detachment\n* CL - Collateral\n","metadata":{}}]}