{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook I will use the dataset 'adult income', containing information determining people's salary. The main objective is to succeed in predicting potential \"high salary\", which are obviously in the minority compared to the total population.","metadata":{}},{"cell_type":"markdown","source":"# Step 1. Import the packages and dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.metrics import classification_report_imbalanced, geometric_mean_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.svm import SVC\n\ndata_train = pd.read_csv('/kaggle/input/income-adult/adult_data.csv')\ndata_test = pd.read_csv('/kaggle/input/income-adult/adult_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2. Interpret the data","metadata":{}},{"cell_type":"code","source":"data_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Note that there is a '.' in column 'salary'.","metadata":{}},{"cell_type":"code","source":"data_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that there is a space ' ' in all columns' title except column 'age'. We are glad to see that there is no missing values.\nThe \"fnlwgt\"= \"final weight\" which means the number of people who are in the same situation(age, race, education background...etc.). So it seems useless since there are the other columns who say the same thing.\nThe same problem for the \"education\" column because of the \"education-num\".\nFinally, we are in a racist society (at least I hope so ahah)  we would like to be able to make predictions about the population regardless of their country of origin. so we can get rid of the \"race\" and \"native-country\" columns.","metadata":{}},{"cell_type":"markdown","source":"# Step 3. Data cleaning and processing","metadata":{}},{"cell_type":"code","source":"data_train.drop([\" fnlwgt\", \" education\", \" race\", \" native-country\"], axis = 1, inplace= True)\ndata_test.drop([\" fnlwgt\", \" education\", \" race\", \" native-country\"], axis = 1, inplace= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data viz of 'salary' column\n\nplt.figure(figsize=(15,8))\nsns.countplot(x=data_train[' salary'])\nplt.title(\"Proportion salary\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It prove again the high salary is the minority.\n","metadata":{}},{"cell_type":"code","source":"# replace the values in \"salary\" columns by 0 and 1.\ndata_train[' salary'].replace({\" <=50K\": 0, \" >50K\": 1}, inplace=True)\ndata_test[' salary'].replace({\" <=50K.\": 0, \" >50K.\": 1}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data_train to y_train and X_train.\ny_train=data_train[' salary']\nX_train=data_train.drop(' salary', axis=1)\n\n# split the data_test to y_train and X_train.\ny_test=data_test[' salary']\nX_test=data_test.drop(' salary', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts(normalize = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standardize the numerical variables in data_train.\n\nnum_train = X_train.dtypes[X_train.dtypes!= 'object'].index\n\nX_train[num_train] = pd.DataFrame(StandardScaler().fit_transform(X_train[num_train]))\n\n# Transform each categorical variable into indicator variables.\nX_train = pd.get_dummies(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standardize the numerical variables in data_test.\n\nnum_test = X_test.dtypes[data_test.dtypes!= 'object'].index\n\nX_test[num_test] = pd.DataFrame(StandardScaler().fit_transform(X_test[num_test]))\n\n# Transform each categorical variable in data_test into indicator variables.\nX_test = pd.get_dummies(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4. Creat and evaluate classification model SVM","metadata":{}},{"cell_type":"code","source":"svm = SVC(gamma = 'scale')\nsvm.fit(X_train, y_train)\n\nprint('Score sur ensemble test', svm.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = svm.predict(X_test)\n\nprint(pd.crosstab(y_test, y_pred, colnames= ['Predictions']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report_imbalanced(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The recall and f1_score for 1 are not too bad but we can make it better.","metadata":{}},{"cell_type":"markdown","source":"To go further, I use **Undersampling** methods who work by reducing the number of observations of the majority class in order to arrive at a satisfactory minority class / majority class ratio. What's more, this methode can make our training faster.","metadata":{}},{"cell_type":"code","source":"# Apply the methode randomUnderSempler.\nrUs = RandomUnderSampler()\nX_ru, y_ru = rUs.fit_resample(X_train, y_train)\n\nprint(\"Classes Ã©chantillon undersampled :\", dict(pd.Series(y_ru).value_counts()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = SVC(gamma='scale')\nsvm.fit(X_ru, y_ru)\n\ny_pred = svm.predict(X_test)\nprint(pd.crosstab(y_test, y_pred))\nprint(classification_report_imbalanced(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I try also with **'probability'**, however it may slowdown the training.","metadata":{}},{"cell_type":"code","source":"svm = SVC(probability= True, gamma ='scale') \nsvm.fit(X_ru, y_ru)                         \n\nthreshold = 0.5 # give a try with 0.4, 0.6, ...\n\nprobs = svm.predict_proba(X_test)\npred_class =  (probs[:,1] >= threshold).astype('int')\n\nprint(pd.crosstab(y_test, pred_class))\nprint(classification_report_imbalanced(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One more methode: **BalancedRandonForestClassifier**","metadata":{}},{"cell_type":"code","source":"from imblearn.ensemble import BalancedRandomForestClassifier\n\nbclf = BalancedRandomForestClassifier()\nbclf.fit(X_train, y_train) \ny_pred = bclf.predict(X_test)\nprint(pd.crosstab(y_test, y_pred))\nprint(classification_report_imbalanced(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"All latest trained models perform better than first one who use the initial dataset.\n\nIn fact, classification on unbalanced data is a classification problem where the training sample contains a strong disparity between the classes to be predicted.\n\nIt is important to remember that the greater the imbalance between the classes, the less successful the classical models will be in predicting the minority class. In many cases, the actual data is affected by an imbalance problem, so it will be necessary to use or even combine some of the methods presented in the notebook.\n\nThank you for your reading.","metadata":{}}]}