{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predict students grades\n\nHere [Student Performance Data Set](https://www.kaggle.com/larsen0966/student-performance-data-set) dataset by [Data-Science Sean](https://www.kaggle.com/larsen0966) is used to perform `EDA` and create a `machine learning model` that can predict student's final grades i.e. Tthe goal is to predict `G3` using `G1` and `G2`.\n\n![](https://media.giphy.com/media/IPbS5R4fSUl5S/giphy.gif)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import linear_model, preprocessing\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import KFold, learning_curve, cross_val_score, train_test_split\n\nfrom joblib import dump","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the dataset\ndf = pd.read_csv('/kaggle/input/student-performance-data-set/student-por.csv')\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 🧬 Attribute Information:\n\n1. `school` - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n2. `sex` - student's sex (binary: 'F' - female or 'M' - male)\n3. `age` - student's age (numeric: from 15 to 22)\n4. `address` - student's home address type (binary: 'U' - urban or 'R' - rural)\n5. `famsize` - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n6. `Pstatus` - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n7. `Medu` - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n8. `Fedu` - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 â€“ 5th to 9th grade, 3 â€“ secondary education or 4 â€“ higher education)\n9. `Mjob` - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n10. `Fjob` - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n11. `reason` - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n12. `guardian` - student's guardian (nominal: 'mother', 'father' or 'other')\n13. `traveltime` - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n14. `studytime` - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n15. `failures` - number of past class failures (numeric: n if 1<=n<3, else 4)\n16. `schoolsup` - extra educational support (binary: yes or no)\n17. `famsup` - family educational support (binary: yes or no)\n18. `paid` - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n19. `activities` - extra-curricular activities (binary: yes or no)\n20. `nursery` - attended nursery school (binary: yes or no)\n21. `higher` - wants to take higher education (binary: yes or no)\n22. `internet` - Internet access at home (binary: yes or no)\n23. `romantic` - with a romantic relationship (binary: yes or no)\n24. `famrel` - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n25. `freetime` - free time after school (numeric: from 1 - very low to 5 - very high)\n26. `goout` - going out with friends (numeric: from 1 - very low to 5 - very high)\n27. `Dalc` - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n28. `Walc` - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n29. `health` - current health status (numeric: from 1 - very bad to 5 - very good)\n30. `absences` - number of school absences (numeric: from 0 to 93)\n31. `G1` - first period grade (numeric: from 0 to 20)\n32. `G2` - second period grade (numeric: from 0 to 20)\n33. `G3` - final grade (numeric: from 0 to 20, output target)"},{"metadata":{},"cell_type":"markdown","source":"## ⛄️ Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the average of the grades\ndf['Average Grades'] = df[['G1', 'G2', 'G3']].mean(axis='columns')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing data"},{"metadata":{},"cell_type":"markdown","source":"## 🏄‍♀️ Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"**Helper plotting functions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_corr(df, annot=True):\n    _, ax = plt.subplots(figsize=(16, 12))\n    sns.heatmap(\n        df.corr(),\n        annot=annot,\n        cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True),\n        ax=ax\n    )\n\n\ndef plot_histplot(column):\n    sns.histplot(x=column, color='#65b87b', alpha=.7) \n    \n    \ndef plot_countplot(df, column_name, ax=None):\n    _df = df[[column_name]].copy()\n    if len(_df[_df[column_name].isnull()]):\n        _df.fillna('NaN', inplace=True)\n    \n    color = '#42b0f5' if ax != None else '#7661ff'\n    sns.countplot(x=column_name, data=_df, color=color, alpha=.7, ax=ax)\n    del _df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_histplot(df['Average Grades'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pearson correlation coefficient significance** \n![Pearson correlation coefficient significance](https://miro.medium.com/max/466/1*Qz_gwy4ZaSZuOpl3IyO2HA.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_corr(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> `age` has low positive correlation with `failure`\n>\n> `Medu` & `Fedu` has moderate positive correlation & they both have low positive correlation with `grades`\n>\n> `studytime` & `grades` have a low positive correlation\n>\n> `failure` has low negative correlation with `grades`\n>\n> `freetime` has low positive correlation with `goout`\n>\n> `goout` has low positive correlation with `Walc`\n>\n> `Walc` has moderate positive correlation with `Dalc` and they both have negligible negative correlation "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_base_relation(df, figsize=(20, 60)):\n    columns = df.columns.tolist()\n    _, axs = plt.subplots(len(columns), 3, figsize=figsize)\n    \n    for idx, column in enumerate(columns):\n        # To get distribution of data\n        sns.histplot(\n            x=df[column],\n            kde=False,\n            color='#65b87b', alpha=.7,\n            ax=axs[idx][0]\n        )\n\n        # To get knowledge about outliers\n        sns.boxplot(\n            x=df[column],\n            color='#6fb9bd',\n            ax=axs[idx][1]\n        )\n\n        # To get its realtion with Average Grades\n        sns.scatterplot(\n            x=column, y='Average Grades', data=df,\n            color='#706dbd', alpha=.7, s=80,\n            ax=axs[idx][2]\n        )\n        \n        \nplot_base_relation(df.select_dtypes(include=[int, float]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we won't be removing outliers since the dataset size is small"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_base_categorical_relation(df, figsize=(20, 60)):\n    columns = df.columns.tolist()\n    _, axs = plt.subplots(len(columns), 3, figsize=figsize)\n    \n    for idx, column in enumerate(columns):\n        try:\n            # To get knowledge about outliers & distribution\n            sns.boxplot(x=df[column], y=df['Average Grades'], ax=axs[idx][0])\n\n            # To get its realtion with Average Grades\n            sns.stripplot(\n                x=column, y='Average Grades', data=df,\n                color='#706dbd', alpha=.7, jitter=.1,\n                ax=axs[idx][1]\n            )\n\n            # To get count plot for `column` (considering NaN, so we can know \n            # how much of data is missing)\n            plot_countplot(df, column, axs[idx][2])\n        except ValueError:\n            # ValueError: min() arg is an empty sequence\n            # \n            # The above error happens while creating plot for some columns (maybe \n            # because it has NaN value)\n            print(f'{column} cannot be plotted')\n        \n        \nplot_base_categorical_relation(\n    pd.concat(\n        [df.select_dtypes(include=['object']), df[['Average Grades']]],\n        axis='columns'\n    )\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the number of samples and categories in categorical columns are less, therefore doing `one hot encoding`"},{"metadata":{"trusted":true},"cell_type":"code","source":"ohe_df = pd.get_dummies(df.select_dtypes('object'))\nohe_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing one column after doing one hot encoding to avoid multi-collinearity issues\nohe_df.drop(['romantic_yes'], axis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the categorical columns and adding one hot encoded df\n\n# Removing\ncategorical_columns = df.select_dtypes('object').columns.tolist()\ndf.drop(categorical_columns, axis='columns', inplace=True)\n\n# Adding\ndf = pd.concat([df, ohe_df], axis='columns')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since is collinear to G1, G2 & G3\ndf.drop(['Average Grades'], axis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 🎸 Modelling\n\nCreating a regression model that can predict student's final grades."},{"metadata":{"trusted":true},"cell_type":"code","source":"# KFold for cross validation\nkf = KFold(n_splits=10, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffling the dataset\ndf = df.sample(frac=1, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting features by analysing which features are collinear to `G3` and collinear \n# to the selected columns\nfeatures = ['failures', 'Medu', 'studytime', 'absences', 'G1', 'G2', 'higher_no', 'higher_yes']\ntarget = 'G3'\n\nx_train, x_test, y_train, y_test = train_test_split(\n    df[features], df[target], test_size=0.3, random_state=0\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling the dataset\n\nscaler = StandardScaler()\n\nx_train = scaler.fit_transform(np.asanyarray(x_train))\ny_train = np.asanyarray(y_train)\n\nx_test = scaler.fit_transform(np.asanyarray(x_test))\ny_test = np.asanyarray(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation\nscoring = 'r2'\nscore = cross_val_score(linear_model.LinearRegression(), x_train, y_train, cv=4, scoring=scoring)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting learning curve\n_sizes = [i for i in range(1, 408, 10)]\ntrain_sizes = np.array([_sizes])  # Relative sizes\nscoring = 'neg_mean_squared_error'\n\nlr = linear_model.LinearRegression()\ntrain_sizes_abs, train_scores, cv_scores = learning_curve(\n    lr, x_train, y_train, train_sizes=train_sizes, cv=10, scoring=scoring\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores_mean = []\nfor row in train_scores:\n    _mean = row.mean()\n    train_scores_mean.append(_mean)\n    \ncv_scores_mean = []\nfor row in cv_scores:\n    _mean = row.mean()\n    cv_scores_mean.append(_mean)    \n    \ntrain_scores_mean = -np.array(train_scores_mean)\ncv_scores_mean = -np.array(cv_scores_mean)\n    \nprint(train_scores_mean)\nprint()\nprint(cv_scores_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_sizes_abs, train_scores_mean, label='Train')\nplt.plot(train_sizes_abs, cv_scores_mean, label='Cross Validation')\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model\nmodel = lr.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimal parameter\ncoefficients = model.coef_\nintercept = model.intercept_\n\nprint(\"Coefficients: \", coefficients)\nprint(\"Intercept: \", model.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ⛱ Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To see how our model performs on data that model has NOT seen\n\nrms_error = mean_squared_error(y_test, y_test_pred, squared=False)\nr2_score_value = r2_score(y_test, y_test_pred)\n\nprint(f\"Root mean squared error: {rms_error}\")\nprint(f\"R2-score: {r2_score_value}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating a pipeline**"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaling = ('scale', StandardScaler())\nmodel = ('model', linear_model.LinearRegression())\n\n# Steps in the pipeline\nsteps = [scaling, model]\n\npipe = Pipeline(steps=steps)\n\n# Fiitting the model\nmodel = pipe.fit(x_train, y_train)\n\n# Out-Of-Sample Forecast\ny_test_pred = model.predict(x_test)\n\n# Evaluation\nrms_error = mean_squared_error(y_test, y_test_pred, squared=False)\nr2_score_value = r2_score(y_test, y_test_pred)\n\nprint(f\"Root mean squared error: {rms_error}\")\nprint(f\"R2-score: {r2_score_value}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the model\ndump(model, 'model.joblib')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Visualizing` our prediction against actual values."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n\nax1.plot(np.arange(len(y_test)), y_test, label='Actual')\nax2.plot(np.arange(len(y_test_pred)), y_test_pred, label='Prediction')\n\nax1.legend()\nax2.legend()\n\nf, ax3 = plt.subplots(nrows=1, ncols=1, figsize=(13, 5))\n\nax3.plot(np.arange(len(y_test)), y_test, label='Actual')\nax3.plot(np.arange(len(y_test_pred)), y_test_pred, label='Prediction')\n\nax3.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\nI'll wrap things up there. If you want to find some other answers then go ahead `edit` this kernel. If you have any `questions` then do let me know.\n\nIf this kernel helped you then don't forget to 🔼 `upvote` and share your 🎙 `feedback` on improvements of the kernel.\n\n![](https://media.giphy.com/media/ny7UCd6JETnmE/giphy.gif)\n\n---"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}