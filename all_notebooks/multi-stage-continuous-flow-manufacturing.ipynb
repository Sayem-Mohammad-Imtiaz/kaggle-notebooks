{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nimport csv\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import make_pipeline\nimport time\nimport warnings\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=pd.read_csv(\"../input/multistage-continuous-flow-manufacturing/X.csv\")\n\nY=pd.read_csv(\"../input/multistage-continuous-flow-manufacturing/Y.csv\")\n\nX2=pd.read_csv(\"../input/multistage-continuous-flow-manufacturing/X2.csv\")\nY2=pd.read_csv(\"../input/multistage-continuous-flow-manufacturing/Y2.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range (len(Y.columns[:])):\n    YZ=Y.values[:,i]\n    YZN=(((np.count_nonzero(YZ==0))/14088))\n    if (YZN>0.2):\n        YDROP=(Y.columns[i])\n        print (\"    Columns No  \", i, \"Name  \", YDROP, \"   Value =\", \"{:,.2f}\".format(YZN))\n        \n#----- droping the columns with more than 30% zeros\nDROP_Y=[1,5,6,7,11,14]\nDROP_Y_N=list(Y.columns[DROP_Y])\nY=Y.drop(columns=DROP_Y_N, axis=1)\n\n#for i in range (len(X2.columns[:])):\n#    X2Z=X2.values[:,i]\n#    X2ZN=(((np.count_nonzero(X2Z==0))/14088))\n#    if (X2ZN>0.3):\n#        X2DROP=(X2.columns[i])\n#        print (\"    Columns No  \", i, \"Name  \", X2DROP, \"   Value =\", \"{:,.2f}\".format(X2ZN))\n\n\nfor i in range (len(Y2.columns[:])):\n    Y2Z=Y2.values[:,i]\n    Y2ZN=(((np.count_nonzero(Y2Z==0))/14088))\n    if (Y2ZN>0.3):\n        Y2DROP=(Y2.columns[i])\n        print (\"    Columns No  \", i, \"Name  \", Y2DROP, \"   Value =\", \"{:,.2f}\".format(Y2ZN))\n        \nDROP_Y2=[4]\nDROP_Y2_N=list(Y2.columns[DROP_Y2])\nY2=Y2.drop(columns=DROP_Y2_N, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_X=X.values[:,:]\ninput_XC=X.columns[:]\ninput_XX=pd.DataFrame(data=input_X, columns=input_XC)\ninput_XXD=pd.DataFrame(data=input_X)\n\noutput_Y=Y.values[:,:]\noutput_YC=Y.columns[:]\noutput_YY=pd.DataFrame(data=output_Y, columns=output_YC)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"For the 1st Stage\")\n\nfor i in range (len(output_YC)):\n    Yi=output_YY.values [:,i];\n    columns=list(input_XXD.columns)\n    pmax=1\n    while (len(columns)>0):\n        pvalue=[]\n        X_1=input_XXD[columns]\n        X_1=sm.add_constant(X_1)\n        model=sm.OLS(Yi, X_1).fit()\n        pvalue=pd.Series(model.pvalues.values[1:], index=columns)\n        pmax=max(pvalue)\n        X_with_pmax=pvalue.idxmax()\n        if (pmax>0.05):\n            columns.remove(X_with_pmax)\n        else:\n                break\n        selected_X=columns\n        \n\n    X_selected=input_XX.values[:, selected_X]\n\n    X_train, X_test, Y_train, Y_test= train_test_split(X_selected, Yi, test_size=0.2)\n\n\n#----- Implementing SVM-POLY\n\n    svr_poly = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2, kernel='poly', degree=3))\n    svr_poly = svr_poly.fit(X_train, Y_train)\n    svr_poly = abs(svr_poly.score(X_test, Y_test))\n    svr_poly = \"{:.2f}\".format(svr_poly * 100)\n\n    print(svr_poly)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"For the 2nd Stage\")\n\n\ninput_X2=X2.values[:,:]\ninput_XC2=X2.columns[:]\ninput_XX2=pd.DataFrame(data=input_X2, columns=input_XC2)\ninput_XXD2=pd.DataFrame(data=input_X2)\n\noutput_Y2=Y2.values[:,:]\noutput_YC2=Y2.columns[:]\noutput_YY2=pd.DataFrame(data=output_Y2, columns=output_YC2)\n\n\nfor i in range (len(output_YC2)):\n    Yi2=output_YY2.values [:,i];\n    columns2=list(input_XXD2.columns)\n    pmax2=1\n    while (len(columns2)>0):\n        pvalue2=[]\n        X_12=input_XXD2[columns2]\n        X_12=sm.add_constant(X_12)\n        model=sm.OLS(Yi2, X_12).fit()\n        pvalue2=pd.Series(model.pvalues.values[1:], index=columns2)\n        pmax2=max(pvalue2)\n        X_with_pmax2=pvalue2.idxmax()\n        if (pmax2>0.05):\n            columns2.remove(X_with_pmax2)\n        else:\n                break\n        selected_X2=columns2\n        \n\n    X_selected2=input_XX2.values[:, selected_X2]\n\n    X_train2, X_test2, Y_train2, Y_test2= train_test_split(X_selected2, Yi2, test_size=0.2)\n\n\n#----- Implementing SVM-POLY for the second stage\n\n    svr_poly = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2, kernel='poly', degree=3))\n    svr_poly = svr_poly.fit(X_train2, Y_train2)\n    svr_poly = abs(svr_poly.score(X_test2, Y_test2))\n    svr_poly = \"{:.2f}\".format(svr_poly * 100)\n\n    print(svr_poly)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}