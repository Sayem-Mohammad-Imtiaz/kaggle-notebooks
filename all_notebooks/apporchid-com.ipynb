{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('../input/apporchid'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"826cc0d9-b33a-4614-bbd5-4815f4f6e62a","_cell_guid":"806a5216-916b-4912-8111-822775c98747","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/apporchid/training.csv').set_index('RefId')\ntest = pd.read_csv('../input/apporchid/test.csv').set_index('RefId')\n\ntrain['kind'] = 'train'\ntest['kind'] = 'test'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.concat([train, test])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info()\n\n# PurchDate dtype is object","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.IsBadBuy.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This is a imbalanced Dataset, we can try out SMOTE , RF for working with such data.","metadata":{}},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = dataset.corr()\nimport matplotlib.pyplot as plt\n\nplt.matshow(dataset.corr())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr.style.background_gradient(cmap='coolwarm').set_precision(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = dataset.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that MMRA columns have high coorelation, We will deal with them later.\n### Vehicle Year ---------VehicleAge \n### VehicleAge with MMRA Columns\n### Also there is not much coorelation between Dependent variable and independent variable. ","metadata":{}},{"cell_type":"code","source":"# List of column with Object dtyoe for Lable Encoding\ndataset.columns.to_series().groupby(dataset.dtypes).groups","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_boxplot = dataset[['VehYear', 'VehicleAge', 'VehOdo', 'BYRNO', 'VNZIP1', 'IsOnlineSale', 'WarrantyCost', 'MMRAcquisitionAuctionAveragePrice', \n           'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionAveragePrice', \n           'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', 'VehBCost']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pairplot = dataset[['VehYear', 'VehicleAge', 'VehOdo', 'BYRNO', 'VNZIP1', 'IsOnlineSale', 'WarrantyCost', 'MMRAcquisitionAuctionAveragePrice', 'VehBCost']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Univaritata analysis for the Numeric data\n\nfor column in df_boxplot:\n    plt.figure()\n    df_boxplot.boxplot([column])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clearly there are outliers in the dataset, they have to be treated before data modelling.\n\n### Checking for the distribution of the dataset","metadata":{}},{"cell_type":"code","source":"# Bivariate Analysis\nsns.pairplot(df_pairplot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping columns with missing values\n\ndataset = dataset.drop(['PRIMEUNIT', 'AUCGUART'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.PurchDate = pd.to_datetime(dataset.PurchDate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['year'] = dataset['PurchDate'].dt.year\ndataset['month'] = dataset['PurchDate'].dt.month\ndataset['day'] = dataset['PurchDate'].dt.day","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the date columns\n\ndataset = dataset.drop(['PurchDate'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj_dtype = ['Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color', 'Transmission', 'WheelType', 'Nationality', 'Size', 'TopThreeAmericanName', 'VNST']\n\nfor col in obj_dtype:\n    dataset[col] = le.fit_transform(dataset[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling missing values","metadata":{}},{"cell_type":"code","source":"dataset.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### replacing NAN by mode of the columns","metadata":{}},{"cell_type":"code","source":"dataset = dataset.fillna(dataset.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.kind.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = dataset[dataset['kind'] == 'train']\ntest_df = dataset[dataset['kind'] == 'test']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_df = train_df.drop(['kind'], axis=1)\ntest_df = test_df.drop(['kind', 'IsBadBuy'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.iloc[:,1:]\ny = train_df['IsBadBuy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating BaseLine Model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.70)\n\nclf = RandomForestClassifier(max_depth=5, n_estimators = 100, random_state=0)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating F1 Score for the BaseLine Model\nfrom sklearn.metrics import f1_score\n\n# using metrics module for accuracy calculation\nprint(\"F1 Score OF THE MODEL: \", f1_score(y_test, y_pred, average='weighted'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### F1 Score of BASELINE MODEL:  0.851619507920779","metadata":{}},{"cell_type":"code","source":"# Dropping the coorelaed columns which are mentioned below\n#1. MMRA columns.\n#2. Vehicle Year & VehicleAge \n#3. VehicleAge & MMRA Columns\n\n# Dropping VehicleAge, MMRA columns \ndataset = dataset.drop(['MMRAcquisitionAuctionCleanPrice', 'VehicleAge',\n       'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n       'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\n       'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice'], axis=1)\n\ntrain_df = dataset[dataset['kind'] == 'train']\ntest_df = dataset[dataset['kind'] == 'test']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['kind'], axis=1)\ntest_df = test_df.drop(['kind', 'IsBadBuy'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.iloc[:,1:]\ny = train_df['IsBadBuy']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.70)\n\nclf = RandomForestClassifier(max_depth=5, n_estimators = 100, random_state=0)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nprint(\"F1 Score OF THE MODEL: \", f1_score(y_test, y_pred, average='weighted'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### F1 Score OF THE MODEL:  0.8663583122603433","metadata":{}},{"cell_type":"markdown","source":"### The F1 score of the model has increased from 0.852 to 0.864\n\n### We can try following other techniques for increasing the score\n1. Hyperparameter tuning of the Random Forest\n2. Treatment of Imbalanced dataset\n3. Check if the features follow parametric distribution and change them if needed. \n4. Try boosting techniques such as XGBoost, CatBoost.\n5. Trying Stacking the model at the end to check if the scores improve.","metadata":{}},{"cell_type":"code","source":"## Treating the imbalanced dataset\n\nX = train_df.iloc[:,1:]\ny = train_df['IsBadBuy']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.70)\n\nclf = RandomForestClassifier(max_depth=10, n_estimators = 100, random_state=0, class_weight='balanced')\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nprint(\"F1 Score OF THE MODEL: \", f1_score(y_test, y_pred, average='weighted'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The F1 score has decreased when I tried to treat the imbalanced dataset, this may","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}