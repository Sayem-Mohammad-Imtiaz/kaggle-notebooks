{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exercice : appliquer les méthodes sur le dataset Indian Diabete"},{"metadata":{},"cell_type":"markdown","source":"Importation des bibbliothèques de bases utilisées :"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Pandas : librairie de manipulation de données\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avancés\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importation des données dans un tableau :"},{"metadata":{"trusted":true},"cell_type":"code","source":"t = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Affichage des 10 premiers éléments du tableau\nt.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remarque que certaines données dans le tableau sont erronnées dans le tableau car elles sont à 0 ce qui n'est pas normal.  \nA l'aide d'une fonction replace_0, on remplace les 0 par une valeur aléatoire suivant la loi normale déterminé avec les valeurs de la moyenne et de l'écart-type."},{"metadata":{"trusted":true},"cell_type":"code","source":"t = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\n# créer une valeur aléatoire suivant la loi normale et les valeurs de la moyenne et de l'écart-type\ndef replace_0(df,col) :\n    df1 = df.copy()\n    df1[col] = df[col].replace(0,np.random.normal(df[col].mean(),df[col].std()))\n    return df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remplace les 0 par ne valeur aléatoire suivant la loi normale :"},{"metadata":{"trusted":true},"cell_type":"code","source":"t = replace_0(t,'Glucose')\nt = replace_0(t,'BloodPressure')\nt = replace_0(t,'SkinThickness')\nt = replace_0(t,'Insulin')\nt = replace_0(t,'BMI')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On vérifie qu'il n'y a bien plus de 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"t[t.Glucose==0]\nt[t.BloodPressure==0]\nt[t.SkinThickness==0]\nt[t.Insulin==0]\nt[t.BMI==0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le remplacement a bien fonctionné.  \nCréation de l'apprentissage :"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Caractéristiques\nX = t.drop(['Outcome'], axis=1)\n#Résultats\ny = t.Outcome","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importation de méthode pour la séparation des ensembles\nfrom sklearn.model_selection import train_test_split\n#Séparation\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vérification du bon fonctionnement séparation entre l'apprentissage et le test\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Méthode de régression logistique"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importation de la méthode de régression logistique\nfrom sklearn.linear_model import LogisticRegression\n#Entrainement\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\n#Prédiction\ny_lr = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importation des méthodes de mesure de performances\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calcul du score\nrf_score = accuracy_score(y_test, y_lr)\nprint(rf_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Matrice de confusion\nprint(confusion_matrix(y_test,y_lr))\npd.crosstab(y_test, y_lr, rownames=['Reel'], colnames=['Prediction'], margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_lr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remarque une différence entre la qualité de prédiction des 0 (Pas de diabète) et la qualité de prédiction des 1 (diabète)."},{"metadata":{"trusted":true},"cell_type":"code","source":"t.Outcome.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remarque que cela est dû à un désiquilibre entre les valeurs 0 et 1 de la colonne Outcome dans la base de données."},{"metadata":{},"cell_type":"markdown","source":"# Méthode de Random Forests"},{"metadata":{},"cell_type":"markdown","source":"Calcul du score de précision avec la méthode Random Forests.  \nDans cette partie nous utilisons à présent le tableau modifier sans les valeurs de BloodPressur à 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importation de la méthode randon forests\nfrom sklearn import ensemble\n#Entrainement\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\n#Prédiction\ny_rf = rf.predict(X_test)\n#Calcul du score\nrf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Matrice de confusion\ncm = confusion_matrix(y_test, y_rf)\nprint(cm)\npd.crosstab(y_test, y_rf, rownames=['Reel'], colnames=['Prediction'], margins=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On obtient un score de variable entre 76% et 82% qui est peut correcte et meilleur que la méthode de régression logistique vu précédemment selon la sélection aléatoire choisis."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comparé à la méthode précédente, on remarque que la différence entre la qualité de prédiction des 0 et des 1 est réduite."},{"metadata":{},"cell_type":"markdown","source":"Utilisation d'hyperparamètres :"},{"metadata":{},"cell_type":"markdown","source":"Parmi les hyperparamètres de l'algorithme qui peuvent avoir un impact sur les performances, on a :\n\n* n_estimators : le nombre d'arbres de décision de la forêt aléatoire\n* min_samples_leaf : le nombre d'échantillons minimum dans une feuille de chaque arbre\n* max_features : le nombre de caractéristiques à prendre en compte lors de chaque split"},{"metadata":{},"cell_type":"markdown","source":"On va tester plusieurs combianaisons de paramètre pour obtenir la meilleur possible."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nparam_grid = {\n              'n_estimators': [10, 100, 500],\n              'min_samples_leaf': [1, 20, 50],\n              'max_features': [1, 2, 4, 8]\n             }\nestimator = ensemble.RandomForestClassifier()\nrf_gs = model_selection.GridSearchCV(estimator, param_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Détermination du meilleur groupe de paramètres\nrf_gs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Affichage du meilleur groupe de paramètre\nprint(rf_gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf2 = rf_gs.best_estimator_\ny_rf2 = rf2.predict(X_test)\nrf_score = accuracy_score(y_test, y_rf2)\nprint(rf_score)\nprint(classification_report(y_test, y_rf2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{},"cell_type":"markdown","source":"Calcul du score de précision avec la méthode XGBoost."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sous Jupyter, si xgboost n'est pas déjà installé\n!pip install xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importation de la méthode\nimport xgboost as XGB\n#Entrainement\nxgb  = XGB.XGBClassifier()\nxgb.fit(X_train, y_train)\n#Prédiction\ny_xgb = xgb.predict(X_test)\n#Calcul du score\nrf_score = accuracy_score(y_test, y_xgb)\nprint(rf_score)\n#Matrice de confusion \ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)\n#Classification report\nprint(classification_report(y_test, y_xgb))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On obtient un score de précision de 75.32% ce qui est moins bien quz les scores précédents."},{"metadata":{},"cell_type":"markdown","source":"Analyse de l'importance des caractéristiques :"},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf2.feature_importances_\nindices = np.argsort(importances)\nplt.figure(figsize=(8,5))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), X_train.columns[indices])\nplt.title('Importance des caracteristiques')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grâce à l'importance des caractèristiques, on remarque que le glucose joue un rôle très important dans l'identification d'un diabète."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}