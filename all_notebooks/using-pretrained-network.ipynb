{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/fizyr/keras-retinanet.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd keras-retinanet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python setup.py build_ext --inplace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\nfrom sklearn.model_selection import train_test_split\nimport urllib\nimport os\nimport csv\nimport cv2\nfrom PIL import Image\n\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nregister_matplotlib_converters()\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 22, 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nf = open('../input/face-mask-detection-dataset/Medical mask/Medical mask/meta.json')\nclasses_colors = json.load(f)\n#print(len(classes_colors[\"classes\"]))\n\nz = []\nfor i in range(len(classes_colors[\"classes\"])):\n    z.append([classes_colors[\"classes\"][i][\"title\"],i+1,classes_colors[\"classes\"][i][\"color\"]])\n#print(z)\n\nfrom pandas import DataFrame\nclass_color_df = DataFrame(z,columns=['classname','id','color'])\nclass_map_df = class_color_df[['classname','id']]\nclass_map_df=pd.DataFrame.from_records(class_map_df.values)\nclass_map_df.to_csv(r'train_class.csv',index=False)\n\nclass_color_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/face-mask-detection-dataset/train.csv\",header= None)\ndf[0] = \"../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/\"+df[0].astype(str)\ndf=df[1:]\ndf=df.drop([8132], axis=0)\ndf.to_csv(r'train_new.csv',index=False,header=None)\ndf.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!retinanet-debug csv train_new.csv train_class.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_objects(record_image):\n\n    path = record_image[0]\n    box = [record_image[1], record_image[2], record_image[3], record_image[4]]\n    class_n = record_image[5]\n    image = read_image_bgr(path)\n    \n    colours = ((class_color_df[class_color_df.classname == class_n].color).iloc[0]).lstrip('#')\n    colours1 = tuple(int(colours[i:i+2], 16) for i in (0, 2, 4))\n\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    draw_box(draw, box, color = colours1)\n    plt.imshow(draw)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_objects(df.iloc[119])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.15, shuffle=False)\ndf_train.to_csv(r'train_data.csv', index = False, header=None)\ndf_test.to_csv(r'test_data.csv', index = False, header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PRETRAINED_MODEL = 'pretrained_model.h5'\n\nURL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\nurllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ANNOTATIONS_FILE = 'train_data.csv'\nCLASSES_FILE = 'train_class.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!keras-retinanet/keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 8 --steps 500 --epochs 10 csv train_data.csv train_class.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls snapshots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\nprint(model_path)\n\nmodel = models.load_model(model_path, backbone_name='resnet50')\nmodel = models.convert_model(model)\n\nlabels_to_names = pd.read_csv(CLASSES_FILE, header=None).T.loc[0].to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfile_name = 'model_raw.sav'\npickle.dump(model, open(file_name, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"model_weights.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(image):\n    image = preprocess_image(image.copy())\n    image, scale = resize_image(image)\n\n    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n\n    boxes /= scale\n\n    return boxes, scores, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"THRES_SCORE = 0.5\n\ndef draw_detections(image, boxes, scores, labels):\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n        if score < THRES_SCORE:\n            break\n\n        color = label_color(label)\n\n        b = box.astype(int)\n        draw_box(image, b, color=color)\n\n        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n        draw_caption(image, b, caption)\n        print(box,score,caption)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_detected_objects(image_row):\n    img_path = image_row[\"name\"]\n\n    image = read_image_bgr(img_path)\n\n    boxes, scores, labels = predict(image)\n\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    true_box = [\n    image_row[\"x1\"], image_row[\"x2\"], image_row[\"y1\"], image_row[\"y2\"]\n    ]\n    draw_box(draw, true_box, color=(255, 255, 0))\n\n    draw_detections(draw, boxes, scores, labels)\n\n    plt.imshow(draw)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.columns = ['name', 'x1', 'x2', 'y1','y2','classname']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects(df_test.iloc[27])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects(df_test.iloc[49])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects(df_test.iloc[30])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects(df_test.iloc[39])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit=pd.read_csv(\"../input/face-mask-detection-dataset/submission.csv\")\nsubmit = submit.drop_duplicates()\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_detected_objects_new(image_row):\n    img_path = image_row[\"name\"]\n    img_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n    img_path=os.path.join(img_dir, img_path)\n\n    image = read_image_bgr(img_path)\n\n    boxes, scores, labels = predict(image)\n\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    draw_detections(draw, boxes, scores, labels)\n  \n    plt.axis('off')\n    plt.imshow(draw)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects_new(submit.iloc[12])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects_new(submit.iloc[34])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects_new(submit.iloc[13])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(image):\n    image = preprocess_image(image.copy())\n    image, scale = resize_image(image)\n\n    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n\n    boxes /= scale\n\n    return boxes, scores, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"THRES_SCORE = 0.5\n\ndef draw_detections(image, boxes, scores, labels):\n    dimension=[]\n    classify=[]\n\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n\n        if score < THRES_SCORE:\n            break\n\n        color = label_color(label)\n\n        b = box.astype(int)\n        draw_box(image, b, color=color)\n\n        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n        draw_caption(image, b, caption)\n   \n        classify.append(labels_to_names[label])\n        dimension.append(box)\n    \n    return dimension,classify","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_detected_objects_fin(image_row):\n    img_path = image_row[\"name\"]\n    img_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n    img_path=os.path.join(img_dir, img_path)\n\n    image = read_image_bgr(img_path)\n\n    boxes, scores, labels = predict(image)\n\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    draw_detections(draw, boxes, scores, labels)\n  \n    #plt.axis('off')\n    #plt.imshow(draw)\n    #plt.show()  \n\n    dimension, classify = draw_detections(draw, boxes, scores, labels)\n\n    dfObj = pd.DataFrame(dimension,columns = ['x1' , 'x2', 'y1', 'y2'])\n    dfObj['label'] = classify\n    dfObj['name'] = image_row[\"name\"]\n    dfObj = dfObj[['name','x1' , 'x2', 'y1', 'y2','label']]\n    return dfObj","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final=pd.DataFrame(columns=['name','x1' , 'x2', 'y1', 'y2','label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(submit)):\n    b=show_detected_objects_fin(submit.iloc[i])\n    final=final.append(b,ignore_index = True)\nfinal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nt = final.to_csv(r'submit_1.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}