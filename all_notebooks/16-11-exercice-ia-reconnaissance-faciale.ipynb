{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# On installe open cv pour pouvoir par la suite classifier les visages, les yeux... etc\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# On intalle le fichier de classification haarcascade_frontalface_default\nface_cascade = cv2.CascadeClassifier('../input/haarcascade-face/haarcascade_frontalface_default.xml')\n\nface_cascade","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# On boucle sur le fichier d'images\nfrom os import listdir\nfrom os.path import isfile, join\n\nimages_path = '../input/celeba-dataset/img_align_celeba/img_align_celeba/'\n\nimages = []\n\nlist_images = listdir(images_path)\n\n# On ne charge que 13 000 images pour éviter une erreur de mémoire avec kaggle\nfor i in range(0,13000):\n        f = list_images[i]\n        if isfile(join(images_path, f)):\n            images.append(images_path + f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# On lit l'image d'entrée\nmodifImg = []\nallCroped = []\nallGray = []\nfor img in images:\n    img = cv2.imread(img)\n    # On convertit en niveaux de gris car cette méthode ne fonctionne que sur les images en niveaux de gris\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    allGray.append(gray)\n\n    allFaces = [] \n    # On cherche à detecter les visages qui se ressemblent\n    # le premier argument qu'on envoie est l'image en niveaux de gris\n    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n    allFaces.append(faces)\n\n    for id1, faces in enumerate(allFaces):\n        for id2, (x, y, w, h) in enumerate(faces):\n\n            # On recadre l'image\n            crop_img = img[y:y+h, x:x+w]\n            dsize = (100, 100)\n            # On redimensionne l'image\n            crop_img = cv2.resize(crop_img, dsize)\n            allCroped.append(crop_img)\n            print(len(allCroped))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# Petit test pour voir ce que donne la dernière image stockée dans gray\n\nplt.imshow(gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nlist_img = []\nfor i,img_info in enumerate(allCroped):\n    print (i, ' / ', len(allCroped))\n    img_array = img_to_array(img_info)\n    list_img.append(img_array)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import InceptionResNetV2\nfrom keras.applications.inception_resnet_v2 import preprocess_input\nmodel = InceptionResNetV2(pooling='avg',include_top=False, weights='imagenet', input_shape=(100,100,3))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nX = np.array(list_img)\nX = preprocess_input(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_finale = []\nfor index in range(0, len(list_img)):\n    print (index, ' / ', len(list_img))\n    ret_vec = model.predict(X[index].reshape(1,100,100,3))\n    list_finale.append({'vec':ret_vec.reshape(-1),'original':list_img[index], 'index':index})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import array_to_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_find = 1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\nplt.imshow(array_to_img(list_finale[to_find]['original']))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from scipy import spatial\ncosine_list = []\nfor index_image,xt in enumerate(list_finale):\n    print (index_image, ' / ', len(list_finale))\n    result = 1 - spatial.distance.cosine(list_finale[to_find]['vec'].reshape(-1), xt['vec'])\n    cosine_list.append(dict({'res':result, 'i':list_finale[index_image]['index']}))\nfrom operator import itemgetter\ncosine_list.sort(key=itemgetter('res'), reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=1, ncols=10,figsize=(20, 4))\nplt.gray()\nfor indice, row in enumerate(ax):\n    print (cosine_list[indice]['i'])\n    row.imshow(array_to_img(list_finale[cosine_list[indice]['i']]['original']))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cosine_list","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}