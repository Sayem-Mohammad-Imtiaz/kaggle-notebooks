{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loan Prediction"},{"metadata":{},"cell_type":"markdown","source":"## 0. Import Packages and Settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Prepare Data and Make Some Explorations"},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_train = pd.read_csv(\"/kaggle/input/loanprediction/train_ctrUa4K.csv\")\nprint(\"Print the first 5 records in the dataset:\")\nprint(loan_train.head())\nprint()\nprint(\"Basic descriptive statistics of all the variables:\")\nprint(loan_train.describe())\nprint()\nprint(\"Present the feature attributes:\")\nprint(loan_train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count the null columns\nnull_columns = loan_train.columns[loan_train.isnull().any()]\nloan_train[null_columns].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We find that some of the features get missing value, and we need to drop of input some value of them.\nWe find there are seven features have this situation: Gender, Married, Dependents, Self_Employed, LoanAmount, Loan_Amount_Term, and Credit_History.\nWe make a quick guess before we check the distribution of the variables:\n1. Loan_ID is not relevent.\n2. Gender should not be relevent in ideal.\n3. Married 'Yes' will have more chance to be approved.\n4. Dependents 'With Dependents' will have more chance to get loan, too.\n5. Education Higher will be better.\n6. Self_Employed not sure.\n7. ApplicantIncome Higher will be better.\n8. CoapplicantIncome Higher will be better.\n9. LoanAmount not sure.\n10. Loan_Amount_Term not sure.\n11. Credit_History 'With credit history' will be better.\n12. Property_Area 'Urban' will be better."},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_train.hist(bins=50, figsize=(15, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_obj = loan_train.select_dtypes(include='object')\n\nfor col in df_obj.iloc[:, 1:].columns:\n    print(sns.countplot(x=col, data=df_obj))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the distribution of each variable between Loan_Status = 'Y' v.s. 'N'."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_approved = loan_train[loan_train['Loan_Status'] == 'Y']\ndf_rejected = loan_train[loan_train['Loan_Status'] == 'N']\n\nnon_object_variables = ['ApplicantIncome', 'CoapplicantIncome', \n                        'Credit_History', 'LoanAmount', 'Loan_Amount_Term']\n\nfor obj in non_object_variables:\n    sns.distplot(df_approved[obj][df_approved[obj].isnull() == False], label = 'Loan_Status == Y')\n    sns.distplot(df_rejected[obj][df_rejected[obj].isnull() == False], label = 'Loan_Status == N')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_variables = ['Gender', 'Married', 'Dependents', \n                   'Self_Employed', 'Property_Area']\n\nfor obj in object_variables:\n    print(sns.countplot(x=obj, data=df_obj, hue='Loan_Status'))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We conclude that the higher Y/N ratio, the higher possibility to get loan approved."},{"metadata":{},"cell_type":"markdown","source":"## 2. Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Fill the Missing Value with mode() (the value appear the most often)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_with_mode(df, x):\n    df[x].fillna(df[x].mode()[0], inplace=True)\n    \nhas_null_objects = ['Gender', 'Married', 'Dependents',\n                    'Self_Employed', 'LoanAmount', 'Loan_Amount_Term',\n                    'Credit_History']\n\nfor obj in has_null_objects:\n    fill_with_mode(loan_train, obj)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make sure all null value has bee filled\nfor col in loan_train.columns:\n    print('Variable', col, 'has missing entry:', sum(loan_train[col].isnull()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = loan_train.iloc[:, 1:-1]\ny = loan_train.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 One Hot Encoding to Categorical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# these four columns need to be onehotted\nonehot_targets = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', \n                  'Property_Area']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for target in onehot_targets:\n    onehot_temp = pd.get_dummies(X[target])\n    X = X.drop(target, axis=1)\n    X = pd.concat([onehot_temp, X], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Label Encoding to Predicted Value"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = le.transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare train and validation data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Prepare Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\nscores = cross_val_score(clf, X, y, cv=5)\nprint(\"Random forest Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Hyperparameter Searching with RandomSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=10, stop=700, num=10)]\n# number of features to consider in every split\nmax_features = ['auto', 'sqrt']\n# maximum level in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num=11)]\nmax_depth.append(None)\n# minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# method of selecting samples of training each tree\nbootstrap = [True, False]\n\n# create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# start hyperparameter searching\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100,\n                              cv=5, verbose=2, random_state=42, n_jobs=-1)\nrf_random.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the best hyperparameters\nrf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Train and Evaulate Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"clrf_grid = RandomForestClassifier(n_estimators=546, min_samples_split=2, min_samples_leaf=4,\n                                  max_features='sqrt', max_depth=10, bootstrap=True)\nscores = cross_val_score(clrf_grid, X, y, cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Grid Random Forst Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Work on Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_test = pd.read_csv('/kaggle/input/loanprediction/test_lAUu6dG.csv')\n    \nX_test = loan_test.iloc[:, 1:]\n    \nfor feature in has_null_objects:\n    fill_with_mode(X_test, feature)\n    \n# make sure all null value has bee filled\nfor col in X_test.columns:\n    print('Variable', col, 'has missing entry:', sum(X_test[col].isnull()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# onehot encoding to test data specific features\nfor target in onehot_targets:\n    onehot_temp = pd.get_dummies(X_test[target])\n    X_test = X_test.drop(target, axis=1)\n    X_test = pd.concat([onehot_temp, X_test], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clrf_grid.fit(X, y)\n\nresults = clrf_grid.predict(X_test)\nSJ_submit = pd.DataFrame({\"Loan_ID\": loan_test['Loan_ID'], \"Loan_Status\": results})\nprint(SJ_submit.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(SJ_submit).to_csv(\"submit_CudaChen.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}