{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/3o85xBiolEFwFtOw3C/giphy.gif\" width=\"800\" height=\"300\">"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import Important libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nimport plotly.express as px\nfrom fbprophet.plot import plot_plotly, plot_components_plotly\nfrom fbprophet import Prophet\nfrom statsmodels.tsa.seasonal import seasonal_decompose as sd\nimport plotly.graph_objects as go\nimport statsmodels.api as sm\nimport statsmodels.tsa.api as smt\nimport missingno as msno\nfrom sklearn.model_selection import TimeSeriesSplit, train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom datetime import timedelta\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load our data\n\nfeatures = pd.read_csv(\"../input/walmart-sales-prediction/features.csv\", parse_dates=['Date'])\nstores = pd.read_csv(\"../input/walmart-sales-prediction/stores.csv\")\ntrain = pd.read_csv(\"../input/walmart-sales-prediction/train.csv\", parse_dates=['Date'])\ntest = pd.read_csv(\"../input/walmart-sales-prediction/test.csv\", parse_dates=['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the first 3 rows\n\nprint(features.head(3))\nprint('\\n')\nprint(stores.head(3))\nprint('\\n')\nprint(train.head(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the dataset shape\n\nprint(features.shape)\nprint(stores.shape)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will merge our datasets\n\ntdf = train.merge(features, 'left').merge(stores, 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merged data head\n\ntdf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display general information\n\ntdf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Description\n\ntdf.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage of missing Values\n\ntdf.isna().sum()/len(tdf)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize our missing data\n\nmsno.bar(tdf, color=\"dodgerblue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IMPUTING MISSING DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing data is for Markdowns only (Quantitative veriables). We can imput the missing data \n# using a 0, which indicates that there is no markdown.\n\ntdf= tdf.fillna(0)\n# DISPLAY MISSING DATA\nmsno.bar(tdf, color=\"dodgerblue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix\n\nplt.figure(figsize= (15,10))\nsns.heatmap(tdf.corr(), annot= True, cmap= 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DISTRIBUTION OF THE DEPENDENT VARIABLE\n\nplt.figure(figsize=(20,5))\nsns.distplot(tdf['Weekly_Sales'], bins=40, kde=True, color='red')\nplt.title('Weekly_Sales distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales by different variables\n\nfig, ax = plt.subplots(2, 2, figsize= (10,10))\nax[0,0].scatter(tdf['Temperature'], tdf['Weekly_Sales'])\nax[0,0].set_title('Weekly_Sales by tempreture')\nax[0,1].scatter(tdf['Fuel_Price'], tdf['Weekly_Sales'])\nax[0,1].set_title('Weekly_Sales by fuel price')\nax[1,0].scatter(tdf['CPI'], tdf['Weekly_Sales'])\nax[1,0].set_title('Weekly_Sales by CPI')\nax[1,1].scatter(tdf['IsHoliday'], tdf['Weekly_Sales'])\nax[1,1].set_title('Weekly_Sales in holidays and not holidays')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Modeling"},{"metadata":{},"cell_type":"markdown","source":"## Decomposing Time Series Data into Trend and Seasonality\nA Series is an aggregate or combination of 4 components. All series have a level and noise. The trend and seasonality components are optional.\n* Level: The average value in the series.\n* Trend: The increasing or decreasing value in the series.\n* Seasonality: The repeating short-term cycle in the series.\n* Noise: The random variation in the series."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=train.groupby(\"Date\")[\"Weekly_Sales\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize Residuals, Seasonal, Trend, and level\n\nres = sm.tsa.seasonal_decompose(ts.values,period=52,model=\"multiplicative\")\nres.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here we can see a very small increasing trend and an obvious seasonality."},{"metadata":{},"cell_type":"markdown","source":"# Model 1: Prophet"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the top rows in ts\nts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the weekly sales by year\nfig = go.Figure()\nyears = pd.date_range(\"2010-01-01\",\"2013-01-01\", freq=\"AS\").tolist() # range dates by year\nfor i in range(len(years)-1):\n    ts_year = ts[years[i]:years[i+1]]\n    fig.add_trace(\n        go.Scatter(\n            y=ts_year.values,\n            x=ts_year.index.week,\n            name=years[i].year,\n        ))\n\nfig.update_layout(\n    title=\"weekly sales by year\",\n    xaxis_title=\"weeks\",\n    yaxis_title=\"sales\",\n    legend_title=\"year\",\n    yaxis_tickprefix = '$',\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"RebeccaPurple\"\n    ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reset index\np_ts = ts.reset_index()\np_ts.columns = [\"ds\",\"y\"]\np_ts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Prophet Model\nm = Prophet(yearly_seasonality = True)\nm.fit(p_ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the future data (26 weeks)\nfuture = m.make_future_dataframe(periods=26, freq='W')\nfuture.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict future sales\nforecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the forcasted sales\nplot_plotly(m, forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the components\nplot_components_plotly(m, forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 2: SARIMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsplot(ts, lags):\n    with plt.style.context(\"bmh\"):    \n        fig = plt.figure(figsize=(12, 7))\n        ts_ax = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid((2, 2), (1, 0))\n        pacf_ax = plt.subplot2grid((2, 2), (1, 1))\n        ts.plot(ax=ts_ax)\n        p_value = sm.tsa.stattools.adfuller(ts)[1]\n        ts_ax.set_title('Dickey-Fuller: p={0:.5f}'.format(p_value))\n        smt.graphics.plot_acf(ts, lags=lags, ax=acf_ax)\n        smt.graphics.plot_pacf(ts, lags=lags, ax=pacf_ax)\n        plt.tight_layout()\n        \ntsplot(ts, 26)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_diff = ts - ts.shift(52)\ntsplot(ts_diff[52:], 26)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_diff = ts_diff - ts_diff.shift(1)\ntsplot(ts_diff[52+1:], 40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify SARIMA Components & fit the model\np = 2\nd=1 \nq = 3\nP = 2\nD=1 \nQ = 3\ns = 52\nmodel=sm.tsa.statespace.SARIMAX(ts, order=(p, d, q), seasonal_order=(P, D, Q, s)).fit(disp=-1)\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsplot(model.resid[24+1:], lags=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Culaculate MAE\ndef mean_absolute_percentage_error(y_true, y_pred): \n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize MAE\n\ndef plotSARIMA(ts, model, n_steps):\n    data = pd.DataFrame(ts)\n    data.columns = ['actual']\n    data['model'] = model.fittedvalues\n    data['model'][:s+d] = np.NaN\n    \n    forecast = model.predict(start = data.shape[0], end = data.shape[0]+n_steps)\n    forecast = data.model.append(forecast)\n    error = mean_absolute_percentage_error(data['actual'][s+d:], data['model'][s+d:])\n\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=data.index,\n            y=data[\"actual\"],\n            name=\"Actual\",\n        ))\n    fig.add_trace(\n        go.Scatter(\n            x=forecast.index,\n            y=forecast,\n            name=\"Model\",\n    ))\n    fig.add_vrect(\n    x0=data.index[-1], x1=forecast.index[-1],\n    fillcolor=\"LightSalmon\", opacity=0.5,\n    layer=\"below\", line_width=0)\n    \n    fig.update_layout(\n        title=f\"Mean Absolute Percentage Error: {error:.2f}%\",\n        xaxis_title=\"weeks\",\n        yaxis_title=\"sales\",\n        yaxis_tickprefix = '$',\n        font=dict(\n            family=\"Courier New, monospace\",\n            size=18,\n            color=\"RebeccaPurple\"\n        ))\n    fig.update_xaxes(rangeslider_visible=True)\n    fig.show()\n    \nplotSARIMA(ts, model, 26)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 3: Linear Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding lags\nl_ts = pd.DataFrame(ts)\nl_ts.columns = [\"y\"]\n\nfor i in range(26, 54):\n    l_ts[f\"l{i}\"] = l_ts.y.shift(i)\n    \nmsno.bar(l_ts,color=\"lightgreen\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop NANs\nl_ts.dropna(inplace=True)\nmsno.bar(l_ts,color=\"lightgreen\");\nl_ts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #  5 folds cross-validation\ntscv = TimeSeriesSplit(n_splits=5)\n\ndef ts_train_test_split(X, y, test_size):\n    index = int(test_size*len(X))+1\n    \n    X_train = X.iloc[:-index]\n    y_train = y.iloc[:-index]\n    X_test = X.iloc[-index:]\n    y_test = y.iloc[-index:]\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the Mean Absolute error\ndef plotLMResults(model, X_train, X_test):\n    pred = model.predict(X_test)\n    \n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=X.index,\n            y=y,\n            name=\"Actual\",\n        ))\n    fig.add_trace(\n        go.Scatter(\n            x=X_test.index,\n            y=pred,\n            name=\"Model\",\n        ))\n\n    cv = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\"neg_mean_squared_error\")\n    \n    deviation = np.sqrt(cv.std())\n    lower = pred - (1.5 * deviation)\n    upper = pred + (1.5 * deviation)\n    \n    fig.add_trace(\n        go.Scatter(\n            x=X_test.index,\n            y=lower,\n            name=\"lower bond\",\n            line = dict(shape = 'linear', color = 'rgb(255, 12, 24)', width=0.7, dash = 'dash')\n        ))\n    fig.add_trace(\n        go.Scatter(\n            x=X_test.index,\n            y=upper,\n            name=\"upper bond\",\n            line = dict(shape = 'linear', color = 'rgb(255, 12, 24)', width=0.7, dash = 'dash')\n        ))\n    \n    error = mean_absolute_percentage_error(pred, y_test)\n    fig.update_layout(\n        title=f\"Mean Absolute Percentage Error: {error:.2f}%\",\n        xaxis_title=\"weeks\",\n        yaxis_title=\"sales\",\n        yaxis_tickprefix = '$',\n        font=dict(\n            family=\"Courier New, monospace\",\n            size=18,\n            color=\"RebeccaPurple\"\n        ))\n    fig.update_xaxes(rangeslider_visible=True)\n    fig.show()\n    \ndef plotCoefs(model):\n    coefs = pd.DataFrame(model.coef_, X_train.columns)\n    coefs.columns = [\"coef\"]\n    coefs[\"abs\"] = coefs.coef.apply(np.abs)\n    coefs = coefs.sort_values(by=\"abs\", ascending=False).drop([\"abs\"], axis=1)\n    \n    fig = px.bar(coefs.coef)\n    fig.update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='gold')\n    fig.show()\n    \n\ny = l_ts.y\nX = l_ts.drop(['y'], axis=1)\n\nX_train, X_test, y_train, y_test = ts_train_test_split(X, y, test_size=0.3)\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n\nplotLMResults(lr, X_train, X_test)\nplotCoefs(lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"with only adding a few lags to our linear model, we can get almost the same results as the SARIMA model. "},{"metadata":{},"cell_type":"markdown","source":"# Model 4: XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"holidays = train.groupby([\"Date\"])[\"IsHoliday\"].agg(lambda x: bool(any(x))).sort_index()\nfig = px.line(ts, title='Holidays')\n# fig.add_vrect(\n#     x0=data.index[-1], x1=forecast.index[-1],\n#     fillcolor=\"LightSalmon\", opacity=0.5,\n#     layer=\"below\", line_width=0)\n# timedelta(weeks=i)\nfor holiday in holidays[holidays].index:\n    fig.add_vrect(\n        x0=holiday- timedelta(weeks=1) , x1=holiday,\n        fillcolor=\"LightSalmon\", opacity=0.7,\n        layer=\"below\", line_width=0)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tempreture by date\ntemperature = features.groupby([\"Date\"])[\"Temperature\"].mean().sort_index()\nfig = px.scatter(ts, title='Temperature', color=ts.index.map(lambda x: round(temperature[x])),\n                 color_continuous_scale=[\"blue\", \"yellow\", \"red\"], labels={\"color\":\"Temperature\",\"value\":\"total sales\"})\nfig.update_traces(mode='lines+markers')\nfig.update_yaxes(tickprefix=\"$\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fuel prices by date\nfuel_price = features.groupby([\"Date\"])[\"Fuel_Price\"].mean().sort_index()\nfig = px.scatter(ts, title='Fuel Price', color=ts.index.map(lambda x: round(fuel_price[x],2)),\n                 labels={\"color\":\"Fuel Price\",\"value\":\"total sales\"})\nfig.update_traces(mode='lines+markers')\nfig.update_yaxes(tickprefix=\"$\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.index[0], ts.index[0]-timedelta(weeks=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lxgb_ts = l_ts.copy()\nfor i in range(0,8):\n    lxgb_ts[f\"h{i}\"] = lxgb_ts.index.map(lambda x: holidays[x-timedelta(weeks=i)])\n    lxgb_ts[f\"t{i}\"] = lxgb_ts.index.map(lambda x: temperature[x-timedelta(weeks=i)])\n    lxgb_ts[f\"f{i}\"] = lxgb_ts.index.map(lambda x: fuel_price[x-timedelta(weeks=i)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler = StandardScaler()\n\ny = lxgb_ts.y\nX = lxgb_ts.drop(['y'], axis=1)\n\nX_train, X_test, y_train, y_test = ts_train_test_split(X, y, test_size=0.3)\n\nX_train_standard = pd.DataFrame(standard_scaler.fit_transform(X_train)).set_index(X_train.index)\nX_test_standard =  pd.DataFrame(standard_scaler.transform(X_test)).set_index(X_test.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor \n\nxgb = XGBRegressor()\nxgb.fit(X_train_standard, y_train)\n\nplotLMResults(xgb, X_train_standard, X_test_standard)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# stores"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stores Time series\nsts = train.groupby([\"Store\",\"Date\"])[\"Weekly_Sales\"].sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display top rows\nsts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vsts = sts.groupby([\"Store\"])[\"Weekly_Sales\"].agg([\"sum\",\"mean\"]).reset_index()\nfig = px.bar(vsts, x='Store', y='sum',\n             hover_data=['Store', 'sum', 'mean'], color='mean',\n             labels={'sum':'Weekly Sales'}, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Walmart weekly sales by Store and Date(Using Plotly)\nfig = go.Figure()\nfor s in sts.Store.unique():\n    fig.add_trace(\n        go.Scatter(\n            x=sts[sts.Store==s].Date,\n            y=sts[sts.Store==s].Weekly_Sales,\n            name=\"Store_\"+str(s)\n        ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The highest sales were on Dec/24 and Dec/23, these are thanksgiving holidays."},{"metadata":{"trusted":true},"cell_type":"code","source":"l_sts = pd.DataFrame()\nfor s in sts.Store.unique():\n    df = pd.DataFrame(sts[sts.Store==s])\n    for i in range(26, 54):\n        df[f\"l{i}\"] = df.Weekly_Sales.shift(i)\n    df.dropna(inplace=True)    \n    l_sts = l_sts.append(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l_sts = l_sts.set_index(\"Date\")\nl_sts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sts_train_test_split(l_sts, test_size):\n    train_set = pd.concat([l_sts[l_sts.Store==s].iloc[:-int(test_size*len(l_sts[l_sts.Store==1]))+1] for s in l_sts.Store.unique()])\n    test_set = pd.concat([l_sts[l_sts.Store==s].iloc[-int(test_size*len(l_sts[l_sts.Store==1]))+1:] for s in l_sts.Store.unique()])\n    \n    y_train = train_set.Weekly_Sales\n    X_train = train_set.drop(['Weekly_Sales'], axis=1)\n    \n    y_test = test_set.Weekly_Sales\n    X_test = test_set.drop(['Weekly_Sales'], axis=1)\n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = sts_train_test_split(l_sts, test_size=0.2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler = StandardScaler()\nX_train_standard = pd.DataFrame(standard_scaler.fit_transform(X_train)).set_index(X_train.index)\nX_test_standard =  pd.DataFrame(standard_scaler.transform(X_test)).set_index(X_test.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor()\nxgb.fit(X_train_standard, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = xgb.predict(X_test_standard)\nmatest = X_test.copy()\nmatest[\"Pred_Sales\"] = pred\nmatest[\"Actual_Sales\"] = y_test\nmatest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfor s in range(1,5):\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Pred_Sales,\n            name=\"Store_\"+str(s)+\"_pred\"\n        ))\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Actual_Sales,\n            name=\"Store_\"+str(s)+\"_actual\",\n            line = dict(shape = 'linear', color = 'rgb(255, 12, 24)', width=0.7, dash = 'dash')\n        ))\nerror = mean_absolute_percentage_error(pred, y_test)\nfig.update_layout(\n    title=f\"Mean Absolute Percentage Error: {error:.2f}%\",\n    xaxis_title=\"weeks\",\n    yaxis_title=\"sales\",\n    yaxis_tickprefix = '$',\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"RebeccaPurple\"\n    ))\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store = tdf.groupby([\"Store\",\"Size\",\"Type\"])[\"Weekly_Sales\"].sum().reset_index()\n\n\nfig = px.bar(store, x='Store', y=\"Weekly_Sales\",\n             hover_data=['Store', 'Weekly_Sales'], color='Type',height=400, title=\"Weekly_Sales by Store Type\")\nfig.show()\n\n\nfig = px.bar(store, x='Store', y=\"Weekly_Sales\",\n             hover_data=['Store', 'Size'], color='Size', height=400, title=\"Weekly_Sales by Store Size\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lxgb_sts = pd.DataFrame()\nfor s in sts.Store.unique():\n    df = pd.DataFrame(sts[sts.Store==s]).set_index(\"Date\")\n    for i in range(26, 54):\n        df[f\"l{i}\"] = df.Weekly_Sales.shift(i)\n    \n    df.dropna(inplace=True)    \n    lxgb_sts = lxgb_sts.append(df)\n    \nfor i in range(0,12):\n        lxgb_sts[f\"h{i}\"] = lxgb_sts.index.map(lambda x: holidays[x-timedelta(weeks=i)])\n        lxgb_sts[f\"t{i}\"] = lxgb_sts.index.map(lambda x: temperature[x-timedelta(weeks=i)])\n        lxgb_sts[f\"f{i}\"] = lxgb_sts.index.map(lambda x: fuel_price[x-timedelta(weeks=i)])\n        \nlxgb_sts[\"Size\"] = lxgb_sts.Store.map(lambda x: store[store.Store==x][\"Size\"].item())\nlxgb_sts[\"Type\"] = lxgb_sts.Store.map(lambda x: store[store.Store==x][\"Type\"].item()).astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = sts_train_test_split(lxgb_sts, test_size=0.2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler = StandardScaler()\nX_train_standard = pd.DataFrame(standard_scaler.fit_transform(X_train)).set_index(X_train.index)\nX_test_standard =  pd.DataFrame(standard_scaler.transform(X_test)).set_index(X_test.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor()\nxgb.fit(X_train_standard, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = xgb.predict(X_test_standard)\nmatest = X_test.copy()\nmatest[\"Pred_Sales\"] = pred\nmatest[\"Actual_Sales\"] = y_test\nmatest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfor s in range(1,5):\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Pred_Sales,\n            name=\"Store_\"+str(s)+\"_pred\"\n        ))\n    fig.add_trace(\n        go.Scatter(\n            x=matest[matest.Store==s].index,\n            y=matest[matest.Store==s].Actual_Sales,\n            name=\"Store_\"+str(s)+\"_actual\",\n            line = dict(shape = 'linear', color = 'rgb(255, 12, 24)', width=0.7, dash = 'dash')\n        ))\nerror = mean_absolute_percentage_error(pred, y_test)\nfig.update_layout(\n    title=f\"Mean Absolute Percentage Error: {error:.2f}%\",\n    xaxis_title=\"weeks\",\n    yaxis_title=\"sales\",\n    yaxis_tickprefix = '$',\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"RebeccaPurple\"\n    ))\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}