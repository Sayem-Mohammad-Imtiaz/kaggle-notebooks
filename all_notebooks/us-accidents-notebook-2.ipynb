{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Imports\nimport matplotlib.pyplot as plt\nimport time\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc\n\n\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Datensatzaufbereitung"},{"metadata":{"trusted":true},"cell_type":"code","source":"###Auslesen des Datasets in Dataframe df_origin\ndf_origin = pd.read_csv(\"../input/us-accidents/US_Accidents_Dec19.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Analyse des originären Dataframes\n#Grafische Darstellung des Dataframes als Tabelle\n#df_origin.head()\n\n#Ausgabe von Länge und Breite\n#df_origin.shape\n\n#Ausgabe der Datentypen nach Attributen\n#df_origin.dtypes\n\n#Summierung von fehlenden Values nach Attributen\n#print(df_origin.isnull().sum().sort_values(ascending=False))\n\n#Bestimmung des Wertverhältnisses NaN zu Gesamtanzahl Werte\n#print((df_origin.isnull().sum() / df_origin.shape[0]).sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Analyse des originären Dataframes auf potenziell verwertbare Korrelationen\n#plt.subplots(figsize=(20,20))\n#corrHeatmap = sns.heatmap(df_origin.corr(method='pearson'), annot=True, square=True)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Datenbereinigung\n# Bereinigung des originären Dataframes um nicht-verwertbare Attribute mit zu vielen n/a-Values\ndf_removedColumns = df_origin.drop(df_origin.columns[df_origin.apply(lambda col: col.isnull().sum() > 300000)], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Entfernen aller Attribute ohne plausible Hypothese, mit Obsoleszenz oder mit komplexer Wertausprägung\ndf_numericalValuesOnly = df_removedColumns.drop(['ID',#ausschließlich unique, daher keine Korrelation gegeben\n                                                 'Source',#keine plausible Hypothese\n                                                 'Description',#komplexe Ausprägung erfordert Preprocessing mit Textanalyse\n                                                 'Street',#obsolet\n                                                 'Side',#obsolet\n                                                 'City',#obsolet\n                                                 'County',#obsolet\n                                                 'State',#obsolet\n                                                 'Zipcode',#obsolet\n                                                 'Country',#obsolet\n                                                 'Timezone',#obsolet\n                                                 'Airport_Code',#keine plausible Hypothese\n                                                 'Weather_Timestamp',#keine plausible Hypothese\n                                                 'Wind_Direction',#keine plausible Hypothese\n                                                 'Weather_Condition',#komplexe Ausprägung erfordert Preprocessing mit Textanalyse\n                                                 'Civil_Twilight',#obsolet\n                                                 'Nautical_Twilight',#obsolet\n                                                 'Astronomical_Twilight'#obsolet\n                                                ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Datenkonvertierung\n# Konvertierung von Boolean-Werten zu Integer-Werten\nfor col in df_numericalValuesOnly:\n    if df_numericalValuesOnly[col].dtype==np.bool:\n        df_numericalValuesOnly[col] = df_numericalValuesOnly[col].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Berechnung der Dauer eines Unfalls\ndf_numericalValuesOnly['Start_Time'] = pd.to_datetime(df_numericalValuesOnly['Start_Time'], errors='coerce')\ndf_numericalValuesOnly['Start'] = df_numericalValuesOnly['Start_Time'].dt.hour\ndf_numericalValuesOnly = df_numericalValuesOnly.drop(['Start_Time'], axis=1)\ndf_numericalValuesOnly['End_Time'] = pd.to_datetime(df_numericalValuesOnly['End_Time'], errors='coerce')\ndf_numericalValuesOnly['End'] = df_numericalValuesOnly['End_Time'].dt.hour\ndf_numericalValuesOnly = df_numericalValuesOnly.drop(['End_Time'], axis=1)\ndf_numericalValuesOnly['Duration'] = (df_numericalValuesOnly['End']-df_numericalValuesOnly['Start'])\ndf_numericalValuesOnly = df_numericalValuesOnly.drop(['Start','End'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hot Encoding des Attributs \"Sunrise_Sunset\"\ndf_Sunrise_SunsetEncoding = pd.get_dummies(df_numericalValuesOnly.Sunrise_Sunset)\ndf_numericalValuesOnly = pd.concat([df_numericalValuesOnly, df_Sunrise_SunsetEncoding], axis=1)\ndf_numericalValuesOnly = df_numericalValuesOnly.drop(['Sunrise_Sunset'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Analyse von Korrelationen auf die Zielvariable \"Severity\"\n# Erzeugung eines Dataframes mit allen Korrelationskoeefizienten der Attribute auf die Zielvariable\ndf_featureTargetCorrelations = df_numericalValuesOnly.corrwith(df_numericalValuesOnly['Severity'])\n\n#Darstellung der Korrelationskoeffizienten auf die Zielvariable in einer Heatmap\n#plt.subplots(figsize=(20,20))\n#corrHeatmap = sns.heatmap(df_featureTargetCorrelations.corr(method='pearson'), annot=True, square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Entfernen aller Attribute, deren Korrelationskoeffizient auf die Zielvariable kleiner als +/- 0,045 ist\ndf_importantCorrelationsOnly = df_numericalValuesOnly.drop(['Temperature(F)',\n                                                            'Humidity(%)',\n                                                            'Pressure(in)',\n                                                            'Visibility(mi)',\n                                                            'Bump',\n                                                            'Give_Way',\n                                                            'No_Exit',\n                                                            'Railway',\n                                                            'Roundabout',\n                                                            'Traffic_Calming',\n                                                            'Turning_Loop',\n                                                           ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Überschreiben des Dataframes mit ausschließlich signifikanten Korrelationskoeffizienten auf die Zielvariable\ndf_featureTargetCorrelations = df_importantCorrelationsOnly.corrwith(df_importantCorrelationsOnly['Severity']).drop(['Severity'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Darstellung der Korrelationskoeffizienten auf die Zielvariable in einer Heatmap\n#plt.subplots(figsize=(20,20))\n#corrHeatmap = sns.heatmap(df_featureTargetCorrelations.corr(method='pearson'), annot=True, square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing und Staging des Dataframes als Input\ndf_training = df_importantCorrelationsOnly.drop([#'Severity',\n                                                  'Start_Lat',\n                                                  #'Start_Lng',\n                                                  #'Distance(mi)',\n                                                  'Amenity',\n                                                  #'Crossing',\n                                                  #'Junction',\n                                                  #'Station',\n                                                  #'Stop',\n                                                  #'Traffic_Signal',\n                                                  'Duration'\n                                                  #'Day',\n                                                  #'Night',\n                                                 ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_training.Severity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_training.drop(['Severity'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{},"cell_type":"markdown","source":"## Erstes Modell"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(classification_report(predictions, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optimierung der Hyperparameter"},{"metadata":{},"cell_type":"markdown","source":"### RandomizedSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"### RandomizedSeachCV auf DecisionTreeClassifier\n\n### aufgrund extrem langer Laufzeit auskommentiert\n\n#param_dist = {\"max_depth\": [65, 80, 95, None],\n              #\"max_features\": [5, 9, 12],\n              #\"min_samples_leaf\": [1, 2, 4],\n              #\"min_samples_split\": [8, 10, 12],\n              #\"criterion\": [\"gini\", \"entropy\"]\n             #}\n\n#rscv = RandomizedSearchCV(DecisionTreeClassifier(random_state=0), param_distributions=param_dist, scoring='accuracy', cv=5, verbose=0, n_jobs=-1)\n#rscv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rscv.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"### GridSearchCV auf DecisionTreeClassifier\n\n### aufgrund extrem langer Laufzeit auskommentiert\n\n#param_grid = {\"max_depth\": [65, 80, 95, None],\n              #\"max_features\": [7, 9, 11],\n              #\"min_samples_leaf\": [1, 2, 4],\n              #\"min_samples_split\": [8, 10, 12],\n              #\"criterion\": [\"gini\", \"entropy\"]\n             #}\n\n#gscv = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid=param_grid, scoring='accuracy', cv=5, verbose=0, n_jobs=-1)\n#gscv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gscv.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kreuvalidierung mit optimiertem DecisionTreeClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Optimierter Decision Tree\nclf = DecisionTreeClassifier(criterion='gini', max_depth=None, max_features=9, min_samples_leaf=2, min_samples_split=10)\n\nstart = time.time()\nclf.fit(X_train, y_train)\nend = time.time()\nduration = end-start\nprint(\"Trainingsdauer:\", duration, \"s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(X_test)\nprob = clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\", accuracy_score(y_test, predictions))\nprint(\"Macro ROC_AUC Score:\", roc_auc_score(y_test, prob, average='macro', multi_class='ovr'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Kreuzvalidierung\n\nkf = KFold(n_splits=5, shuffle=True)\n\nresults = cross_val_score(clf, X, y, scoring='accuracy', cv=kf)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OneVsRestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Binarize the output\ny_binarized = label_binarize(y, classes=[1, 2, 3, 4])\nn_classes = 4\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_binarized, test_size=0.2, random_state=0)\n\nclassifier = OneVsRestClassifier(clf)\nstart = time.time()\nclassifier.fit(X_train, y_train)\nend = time.time()\nduration = end-start\nprint(\"Trainingsdauer:\", duration, \"s\")\n\ny_score = classifier.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Micro-ROC-AUC-Score:\", roc_auc_score(y_test, y_score, average='micro'))\nprint(\"Macro-ROC-AUC-Score:\", roc_auc_score(y_test, y_score, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC-Kurven"},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n#colors = cycle(['blue', 'red', 'green', 'yellow'])\n#for i, color in zip(range(n_classes), colors):\nplt.figure(figsize=(10,10))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i],\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i+1, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-AUC-Metrics for DecisionTree on Dataset \"US-Accidents\"')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{},"cell_type":"markdown","source":"## Erstes Modell"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint(classification_report(predictions, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optimierung der Hyperparameter"},{"metadata":{},"cell_type":"markdown","source":"### RandomizedSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"### RandomizedSearchCV auf RandomForest\n\n### aufgrund extrem langer Laufzeit auskommentiert\n\n#from sklearn.model_selection import RandomizedSearchCV\n\n#clf = RandomForestClassifier(random_state = 42, n_estimators = 20, max_features = 'sqrt', max_depth=60, criterion='entropy', min_samples_leaf=2, min_samples_split=10, verbose = 1, n_jobs = -1)\n\n#param_dist = {\n    #'n_estimators': [100, 500, 1000],\n    #'max_depth': [40, 60, 100, None],\n    #'criterion': ['gini', 'entropy'],\n    #'max_features': ['auto', 'sqrt'],\n    #'min_samples_split': [5, 10, 20, 40],\n    #'min_samples_leaf': [2, 4, 8, 16]\n#}\n\n#rscv = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, scoring='accuracy', cv=3, n_iter=10, verbose=1)\n#rscv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rscv.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"### GridSearchCV auf RandomForest\n\n### aufgrund extrem langer Laufzeit auskommentiert\n\n#from sklearn.model_selection import GridSearchCV\n\n#clf = RandomForestClassifier(random_state = 42, n_estimators = 20, max_features = 'sqrt', max_depth=60, criterion='entropy', min_samples_leaf=2, min_samples_split=10, verbose = 1, n_jobs = -1)\n\n#param_grid = {\n    #'n_estimators': [50, 100, 200, 500],\n    #'max_features': ['auto', 'sqrt'],\n    #'max_depth': [50, 60, 80, 100]\n    #'min_samples_split':\n    #'min_samples_leaf':\n#}\n\n#gscv = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1)\n#gscv.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gscv_clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kreuvalidierung mit optimiertem Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Optimierter Random Forest\nclf = RandomForestClassifier(random_state=0, n_estimators=50, max_features='auto', max_depth=100, criterion='entropy', min_samples_leaf=2, min_samples_split=10, verbose=0, n_jobs=-1)\n\nstart = time.time()\nclf.fit(X_train, y_train)\nend = time.time()\nduration = end-start\nprint(\"Trainingsdauer:\", duration, \"s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(X_test)\nprob = clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\", accuracy_score(y_test, predictions))\nprint(\"Macro ROC_AUC Score:\", roc_auc_score(y_test, prob, average='macro', multi_class='ovr'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Kreuzvalidierung\n\nclf = RandomForestClassifier(random_state=0, n_estimators=50, max_features='auto', max_depth=100, criterion='entropy', min_samples_leaf=2, min_samples_split=10, verbose=0, n_jobs=1) #Anpassung der n_jobs=1, damit keine Parallelisierung, gab ansonsten Probleme\n\nkf = KFold(n_splits=5, shuffle=True)\n\nresults = cross_val_score(clf, X, y, scoring='accuracy', cv=kf)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Konfusionsmatrix\n\n#from sklearn.metrics import confusion_matrix\n\n#confusion_matrix(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OneVsRestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Binarize the output\ny_binarized = label_binarize(y, classes=[1, 2, 3, 4])\nn_classes = 4\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_binarized, test_size=0.2, random_state=0)\n\nclf = RandomForestClassifier(random_state=0, n_estimators=50, max_features='auto', max_depth=100, criterion='entropy', min_samples_leaf=2, min_samples_split=10, verbose=0, n_jobs=-1)\n\nclassifier = OneVsRestClassifier(clf)\nstart = time.time()\nclassifier.fit(X_train, y_train)\nend = time.time()\nduration = end-start\nprint(\"Trainingsdauer:\", duration, \"s\")\n\ny_score = classifier.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Micro-ROC-AUC-Score:\", roc_auc_score(y_test, y_score, average='micro'))\nprint(\"Macro-ROC-AUC-Score:\", roc_auc_score(y_test, y_score, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC-Kurven"},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\nplt.figure(figsize=(10,10))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i],\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i+1, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-AUC-Metrics for RandomForest on Dataset \"US-Accidents\"')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3.7.1 64-bit","name":"python37164bit6b3e17da3e9a42658744a09d7d0f778f"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.7.1-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}