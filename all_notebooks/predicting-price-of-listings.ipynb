{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"023975c1-6602-9ee4-ee8a-bf4c071b859d"},"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"c92a9fd2-28a9-7cbd-b3f8-f1961118993c"},"source":"### Predicting Price of Listings\n\nAuthor: Alexandru Papiu"},{"cell_type":"markdown","metadata":{"_cell_guid":"73c35ce7-426d-94cc-3f07-5757b0c2413c"},"source":"Let's try to take a look at the Airbnb listings and see if we can accurately predict the prices asked based on the information in the listing:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"affb6bcb-e2cd-cf05-2d3a-2cfbacdb76d2"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import Ridge, RidgeCV, Lasso\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score, train_test_split\nimport xgboost as xgb\n\n\n\n%config InlineBackend.figure_format = 'png'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a97eb82-9d2d-e45e-2c02-e05530243424"},"outputs":[],"source":"train = pd.read_csv(\"../input/listings.csv\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"79296857-c87b-9134-0f45-40dec0ddc5e3"},"source":"Let's just keep some columns since there are so many of them:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"399998e2-ec10-f8f6-6785-d90565d67d56"},"outputs":[],"source":"columns_to_keep = [\"price\", \"neighbourhood_cleansed\", \"bedrooms\",\n                   \"property_type\", \"room_type\", \"name\", \"summary\",\n                   \"amenities\", \"latitude\", \"longitude\", \"number_of_reviews\",\n                   \"require_guest_phone_verification\", \"minimum_nights\"]\n\ntrain = train[columns_to_keep]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8a0a4be-9734-e157-9659-388af0ecf099"},"outputs":[],"source":"train.head(3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"0e9571e0-cecd-e904-9aad-0b8abe75137e"},"source":"Let's clean up the data a bit. We will define a function called clean that tidies up some of the columns:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"165e53af-f772-1ff1-41f3-08e4fb306254"},"outputs":[],"source":"def clean(train):\n\n    train[\"bedrooms\"] = train[\"bedrooms\"].fillna(0.5) #these are studios\n    train[\"summary\"] = train[\"summary\"].fillna(\"\")\n    train[\"bedrooms\"] = train[\"bedrooms\"].astype(\"str\")\n\n    #replace unpopular types with other \n    popular_types = train[\"property_type\"].value_counts().head(6).index.values\n    train.loc[~train.property_type.isin(popular_types), \"property_type\"] = \"Other\"\n\n    #make price numeric:\n    train[\"price\"] = train[\"price\"].str.replace(\"[$,]\", \"\").astype(\"float\")\n    #eliminate crazy prices:\n    train = train[train[\"price\"] < 600]\n    \n    return train"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e560a85c-0f2c-b547-fa26-4411d0ca349b"},"outputs":[],"source":"train = clean(train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c31c4b51-0f4c-cec2-bc0d-fbbda84eafb8"},"source":"### EDA:"},{"cell_type":"markdown","metadata":{"_cell_guid":"28f69a6d-adac-3b31-e9de-c304a507641f"},"source":"Let's look at the distribution of prices:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7478e7fc-701e-566e-38f1-48b58ab4ad29"},"outputs":[],"source":"train[\"price\"].hist(bins = 30)\ntrain[\"price\"].std()"},{"cell_type":"markdown","metadata":{"_cell_guid":"1849f3f5-a7bd-a089-bdb5-a2193a16f94c"},"source":"### Price by number of bedrooms:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b3517d5-89ad-f6f3-d99e-14a103f1d59f"},"outputs":[],"source":"(train.pivot(columns = \"bedrooms\", values = \"price\")\n         .plot.hist(bins = 30, stacked = True))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e02f9ca7-f850-f0d5-17d7-24ef35b77d6c"},"outputs":[],"source":"sns.barplot(x = \"bedrooms\", y = \"price\", data = train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"76423d2a-3ad1-5421-5453-8366dc5024da"},"source":"### Price by room_type:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a0b5f36-9af4-e1e1-0920-7ca645ba3daa"},"outputs":[],"source":"(train.pivot(columns = \"room_type\", values = \"price\")\n         .plot.hist(bins = 30, stacked = False, alpha = 0.8))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"036ddc93-decd-2ed5-1fc9-f3d3fc028da9"},"outputs":[],"source":"train.groupby(\"room_type\")[\"price\"].mean()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cdf22ccd-ce8a-4ab6-514e-6e51128c8a10"},"source":"As was expected the room type matters a lot - while private rooms average around 92$, entire homes average around $213. "},{"cell_type":"markdown","metadata":{"_cell_guid":"7e9c97c6-fca9-a6d4-9f60-342b2fab2bed"},"source":"###  Pre-Processing:"},{"cell_type":"markdown","metadata":{"_cell_guid":"b283ba69-7970-a3cb-efe4-da9bec1d3053"},"source":"This is a pretty interesting dataset since it contains very \"diverse\" data classes: looks like we have numerical, categorical and text data.  Let's split them up in two group since text data needs to be processed differently:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5c8c845-658a-a426-aadd-4e45acc07834"},"outputs":[],"source":"y = train[\"price\"]\ntrain_num_cat = train[[\"neighbourhood_cleansed\", \"bedrooms\",\n                   \"property_type\", \"room_type\", \"latitude\", \"longitude\",\n                   \"number_of_reviews\", \"require_guest_phone_verification\",\n                    \"minimum_nights\"]]\n\ntrain_text = train[[\"name\", \"summary\", \"amenities\"]]"},{"cell_type":"markdown","metadata":{"_cell_guid":"0a4c4c83-64f9-bb85-ee2e-32c4d33a4fcb"},"source":"Now let's one hot encode the categorical data:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"487c5be3-1eb5-e5b5-d771-4adc190cd3f7"},"outputs":[],"source":"X_num = pd.get_dummies(train_num_cat)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c34b0c5-e58e-c874-6ec6-85a3cf46f114"},"outputs":[],"source":"train_text.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"577b7276-477d-9f2b-189d-ec0e8e73899a"},"outputs":[],"source":"train.amenities = train.amenities.str.replace(\"[{}]\", \"\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a02e78d1-aa37-3447-b05f-637263303a46"},"outputs":[],"source":"amenity_ohe = train.amenities.str.get_dummies(sep = \",\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"29d657c3-dea4-ded1-6654-37b527d8b6d6"},"source":"Amenities are interesting. I will follow the same idea as in a previous script [here](https://www.kaggle.com/residentmario/d/airbnb/boston/modeling-prices) and one-hot encode the amenities. Turns you can do this with one line of pandas, sweet!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a69a5ae5-b4a6-80d6-75ef-057073a399cd"},"outputs":[],"source":"train.amenities = train.amenities.str.replace(\"[{}]\", \"\")\namenity_ohe = train.amenities.str.get_dummies(sep = \",\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25c6792e-0c04-91fa-fd11-a3ed078c4bd1"},"outputs":[],"source":"amenity_ohe.head(3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"5a7bafe3-4718-125c-0dea-5e9745f6bfb2"},"source":"What shall we do with the name and summary data? Let's just concatenate the two and then create a bag of words from them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b95b5566-fce2-f435-686c-82d5ba42ed6b"},"outputs":[],"source":"train[\"text\"] = train[\"name\"].str.cat(train[\"summary\"], sep = \" \")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b552a7b3-5d2c-7b0d-d9d1-d65fb9459714"},"outputs":[],"source":"vect = CountVectorizer(stop_words = \"english\", min_df = 10)\nX_text = vect.fit_transform(train[\"text\"])"},{"cell_type":"markdown","metadata":{"_cell_guid":"5f356109-55d3-a344-8303-b242cc8b5218"},"source":"### Models:"},{"cell_type":"markdown","metadata":{"_cell_guid":"0d30c586-976f-02ba-85c9-69778009cc68"},"source":"Now let's build some models! But first let's define some helper functions:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71052f96-a1ba-19d4-2008-0fc4a5e19a7b"},"outputs":[],"source":"#metric:\ndef rmse(y_true, y_pred):\n    return(np.sqrt(metrics.mean_squared_error(y_true, y_pred)))\n\n#evaluates rmse on a validation set:\ndef eval_model(model, X, y, state = 3):\n    X_tr, X_val, y_tr, y_val = train_test_split(X, y, random_state = state)\n    preds = model.fit(X_tr, y_tr).predict(X_val)\n    return rmse(y_val, preds)"},{"cell_type":"markdown","metadata":{"_cell_guid":"060bc6e0-2bf8-274d-5569-58d894a35d91"},"source":"Ok so we have three different matrices: "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b74d349f-9cd4-4d70-aaac-74d1d279baa3"},"outputs":[],"source":"(X_num.shape, X_text.shape, amenity_ohe.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc3021b3-ace2-b5c0-d248-42b7436389b9"},"outputs":[],"source":"#this is numeric + amenities:\nX = np.hstack((X_num, amenity_ohe))\n\n#this is all of them:\nX_full = np.hstack((X_num, amenity_ohe, X_text.toarray()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd396b10-3557-384d-61be-2fa7926f0c5e"},"outputs":[],"source":"models_rmse = [eval_model(xgb.XGBRegressor(), X_num, y),\n eval_model(xgb.XGBRegressor(), X, y),\n eval_model(Ridge(), X_num, y),\n eval_model(Ridge(), X, y)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f21234a3-4db4-fe2f-5e6d-c2c61f8346f7"},"outputs":[],"source":"models_rmse = pd.Series(models_rmse, index = [\"xgb_num\", \"xgb_ame\", \"ridge\", \"ridge_ame\"] )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93048da1-cc50-7a3e-dbe8-46f394fe49d7"},"outputs":[],"source":"models_rmse"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57d87552-a907-0707-8139-6e5128a98066"},"outputs":[],"source":"models_rmse.plot(kind = \"barh\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"88e1b244-c7ea-87c4-5440-7cf0c0610948"},"source":"Ok so it looks like xgboost is doing a little bit better than ridge and adding the amenities helps a bit ( around -1 rmse). This is however only on one validation set."},{"cell_type":"markdown","metadata":{"_cell_guid":"ea134718-630f-add5-bd6e-e21c90c8a511"},"source":"To test our different models more in depth, we will do repeated train-validation split (note this is not exactly cross validation) and then see how our errors are distributed. We also add a baseline model that always predicts the mean."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea2167f1-f333-9a6d-7639-8ba3317f86b5"},"outputs":[],"source":"results = []\nfor i in range(30):\n    X_tr, X_val, y_tr, y_val = train_test_split(X_num, y)\n    y_baseline = [np.mean(y_tr)]*len(y_val)\n\n    model = Ridge(alpha = 5)\n    preds_logit = model.fit(X_tr, y_tr).predict(X_val)\n\n\n    model = xgb.XGBRegressor()  \n    preds_xgb = model.fit(X_tr, y_tr).predict(X_val)\n    \n    results.append((rmse(y_baseline, y_val),\n                    rmse(preds_logit, y_val),\n                    rmse(preds_xgb, y_val)\n                    ))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76e7c420-af31-fa2e-9461-0b5425220a66"},"outputs":[],"source":"results = pd.DataFrame(results, columns = [\"baseline\", \"ridge\", \"xgb\"])\nresults.plot.hist(bins = 15, alpha = 0.5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9af9ec5-c205-104f-4e35-6df382dab475"},"outputs":[],"source":"pd.DataFrame([results.mean(), results.std()])"},{"cell_type":"markdown","metadata":{"_cell_guid":"1c6923a8-46b8-fc58-c8ce-89f8e6594bae"},"source":"Clearly both ridge and xgboost beat the baseline performance by a decent margin. Also it looks like the xgboost model is performing slightly better than the Ridge Regression, good to know! If we wanted to see if the difference in rmse is statistically significant we could do a permutation test or a t-test but I'll skip that for now."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"87306495-aaf6-cbb0-62a7-470600e0be3d"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}