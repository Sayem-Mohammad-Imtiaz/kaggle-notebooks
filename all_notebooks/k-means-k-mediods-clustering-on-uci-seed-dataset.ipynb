{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Introduction**\n\n**Abstract:** Measurements of geometrical properties of kernels belonging to three different varieties of wheat. A soft X-ray technique and GRAINS package were used to construct all seven, real-valued attributes.\n\nClasses - Kama (0), Rosa (1) and Canadian (2)\n\nLink to dataset : https://archive.ics.uci.edu/ml/datasets/seeds\n\n![](https://uci-seed-dataset.s3.ap-south-1.amazonaws.com/Dataset.PNG)\n\n> You will learn following things by reading this kernel.\n1. [Elbow](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html) method to find optimal k (number of clusters)\n2. k-means clustering with k value found.\n3. Calculate silhouette coefficient to measure clustering quality.\n4. Calculate purity to measure clustering quality.\n5. k-mediods clutering with k value found.\n6. Conclusions on methods used.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Workspace setting and loading dataset**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn import metrics\n\ndataset = pd.read_csv('../input/seed-from-uci/Seed_Data.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe(include = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[](http://)**[Elbow](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html) method to find optimal k (number of clusters)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dataset.iloc[:, 0:7]\ntarget = dataset.iloc[:, -1]\n\nmodel = KMeans()\nvisualizer = KElbowVisualizer(model, k=(1,10))\n\nvisualizer.fit(features)    # Fit the data to the visualizer\nvisualizer.poof()    # Draw/show/poof the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The lowest distortion, which is sum of square distances from each point to its assigned cluster, is found at k = 3 hence this clustering is optimal when 3 clusters are used. We used k-means and k-mediods with k = 3 in following clustering experiments.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Apply k-means clustering with k=3**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=3)\nkmeans.fit(features)\ncluster_labels = kmeans.fit_predict(features)\n\nkmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate silhouette coefficient for above clustering**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"silhouette_avg = metrics.silhouette_score(features, cluster_labels)\nprint ('silhouette coefficient for the above clutering = ', silhouette_avg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"o.47 would be an average value for silhouette coeffiencit. -1 is the worst and +1 is the optimal.\nRead more about silhouette coeffient at wikipedia article. And read the paper [here](https://www.sciencedirect.com/science/article/pii/0377042787901257).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Calculate Purity of the above clustering**\n\nYou can use [this](https://pml.readthedocs.io/en/latest/clustering.html) library as well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def purity_score(y_true, y_pred):\n    # compute contingency matrix (also called confusion matrix)\n    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n\npurity = purity_score(target, cluster_labels)\nprint ('Purity for the above clutering = ', purity)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Install [pyclustering](https://pypi.org/project/pyclustering/) on kernel**\n\nEnable internet setting for the kernel and run the following command to install custom python packge.\nRefer documentation for the package [here](https://codedocs.xyz/annoviko/pyclustering/classpyclustering_1_1cluster_1_1kmedoids_1_1kmedoids.html#a368ecae21ba8fabc43487d5d72fcc97e).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyclustering\n\nfrom pyclustering.cluster.kmedoids import kmedoids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Apply k-mediods clustering with k=3**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Randomly pick 3 indexs from the original sample as the mediods\ninitial_medoids = [1, 50, 170]\n\n# Create instance of K-Medoids algorithm with prepared centers.\nkmedoids_instance = kmedoids(features.values.tolist(), initial_medoids)\n\n# Run cluster analysis.\nkmedoids_instance.process()\n\n# predict function is not availble in the release branch yet.\n# cluster_labels = kmedoids_instance.predict(features.values)\n\nclusters = kmedoids_instance.get_clusters()\n\n# Prepare cluster labels\ncluster_labels = np.zeros([210], dtype=int)\nfor x in np.nditer(np.asarray(clusters[1])):\n   cluster_labels[x] = 1\nfor x in np.nditer(np.asarray(clusters[2])):\n   cluster_labels[x] = 2\n\ncluster_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mediods found in above clustering, indexes are shouwn below.\nkmedoids_instance.get_medoids()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate silhouette coefficient for above clustering**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"silhouette_avg = metrics.silhouette_score(features, cluster_labels)\nprint ('silhouette coefficient for the above clutering = ', silhouette_avg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate Purity of the above clustering**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"purity = purity_score(target, cluster_labels)\nprint ('Purity for the above clutering = ', purity)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\n1. Both silhouette coefficient and purity values are very close, hence both clustering are done similarity. K-means is slightly better in both measures.\n2. K-mediods results are sensitive to the initial mediods selected.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}