{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import the necessary packages\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import Sequential\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nimport ast \nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport random\nfrom imutils import paths\nfrom sklearn.preprocessing import LabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"burada klasörden görüntülerin isimlerini liste halinde çekiyoruz"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = list(map(lambda x: x, os.listdir('../input/illinois-doc-labeled-faces-dataset/front/front/')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"çektiğimiz isimlerle dataframe oluşturuyoruz"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data = img_name, index =None, columns = ['filename'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dataframe de yeni kolon açarak görüntülere suçlu etiketi ekleniyor."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.insert(1,\"criminal\",\"suclu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\nlabels = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"burada klasörden görüntülerin yollarını çekiyoruz daha sonra bu yollar resimleri klasörden okumamıza yarayacak"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] loading images...\")\nimagePaths = sorted(list(paths.list_images('../input/illinois-doc-labeled-faces-dataset/front/front/')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"çekilen dosyanın ne kadar veri içerdiğine baklıyor"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(imagePaths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagePaths[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_DIMS = (224, 224, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"burada görüntüler çekilerek ileride eğitebilmek için özelik ve giriş değerleri belirleniyor."},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# loop over the input images\nfor i in random.sample(range(len(imagePaths)),5000):\n\t# load the image, pre-process it, and store it in the data list\n    img=imagePaths[i]\n    image = cv2.imread(f\"{img}\")\n    image1 = cv2.resize(image,(224,224))\n    image1 = img_to_array(image1)\n    data.append(image1)\n    \n\n\t# extract the class label from the image path and update the\n\t# labels list\n\t# sınıf etiketini görüntü yolundan çıkarın ve etiket listesini güncelleyin\n    label = \"suclu\"\n    labels.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels[0:8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale the raw pixel intensities to the range [0, 1]\n# ham piksel yoğunluklarını [0, 1] aralığına ölçeklendirin\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# binarize the labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(lb.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n#% 80'i kullanarak verileri eğitim ve test bölümlerine ayırın\n# eğitim verileri ve kalan% 20 test için\n(trainX, testX, trainY, testY) = train_test_split(data,\n\tlabels, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct the image generator for data augmentation\n# Veri büyütme için görüntü oluşturucuyu oluşturun\naug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n\thorizontal_flip=True, fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam, Nadam\nfrom tensorflow.keras.regularizers import l1, l2, L1L2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the VGG16 network, ensuring the head FC layers are left off\nvgg = VGG16(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))\n# freeze all VGG layers so they will *not* be updated during the\n# training process\nvgg.trainable = False\n# flatten the max-pooling output of VGG\nflatten = vgg.output\nflatten = Flatten()(flatten)\n# construct a fully-connected layer header to output the predicted\n# bounding box coordinates\nsoftmaxHead = Dense(512, activation=\"relu\")(flatten)\nsoftmaxHead = Dropout(0.5)(softmaxHead)\nsoftmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\nsoftmaxHead = Dropout(0.3)(softmaxHead)\nsoftmaxHead = Dense(len(lb.classes_), activation=\"sigmoid\")(softmaxHead)\n# construct the model we will fine-tune for bounding box regression\nmodel = Model(inputs=vgg.input, outputs=softmaxHead)\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 20\nINIT_LR =1e-3\nBS = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"mse\", optimizer=opt,metrics=[\"accuracy\"])\n# train the network for bounding box regression\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nprint(\"[INFO] training bounding box regressor...\")\nH = model.fit(\n\tx=aug.flow(trainX, trainY, batch_size=BS),\n\tvalidation_data=(testX, testY),\n\tsteps_per_epoch=len(trainX) // BS,\n\tepochs=EPOCHS, verbose=1, callbacks = [es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_OUTPUT = '../working/'\nMODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"detector1.h5\"])\n# serialize the model to disk\nprint(\"[INFO] saving object detector model...\")\nmodel.save(MODEL_PATH, save_format=\"h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x=testX,y=testY,batch_size=BS)\nscore\nprint('Score Accuracy : {:.2f}%'.format(score[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_Y = model.predict(testX, batch_size = BS, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nconfusion_matrix=(confusion_matrix(np.argmax(testY,-1), pred_Y_cat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb.classes_[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nLABELS=['suclu']\nplt.figure(figsize=(10,8))\nsns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt = 'd')\nplt.title('Confusion Matrix')\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the necessary packages\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.models import load_model\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport mimetypes\nimport argparse\nimport imutils\nimport cv2\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[INFO] loading object detector...\")\nmodel = load_model('./detector1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(imagePath):\n    # load the input image (in Keras format) from disk and preprocess\n    # it, scaling the pixel intensities to the range [0, 1]\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    output = image.copy()\n    image = cv2.resize(image, (224, 224))\n    image = image.astype(\"float\") / 255.0\n    image = img_to_array(image)\n    image = np.expand_dims(image, axis=0)\n    # make bounding box predictions on the input image\n    proba = model.predict(image)[0]\n    idx = np.argmax(proba)\n    label = lb.classes_[idx]\n    label = \"{} olma ihtimali: {:.2f}% \".format(label, proba[idx] * 100)\n    cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n        0.7, (255, 0, 0), 2)\n        \n    # show the output image\n    fig=plt.figure(figsize=(10,10))\n    plt.grid(b=None)\n    plt.axis('off')\n    return plt.imshow(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagePath = \"../input/illinois-doc-labeled-faces-dataset/front/front/A00147.jpg\"\npredict(imagePath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagePath = \"../input/illinois-doc-labeled-faces-dataset/front/front/A01181.jpg\"\npredict(imagePath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagePath = \"../input/illinois-doc-labeled-faces-dataset/front/front/A01759.jpg\"\npredict(imagePath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}