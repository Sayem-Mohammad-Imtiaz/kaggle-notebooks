{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, cv2, random, json, itertools\n\nfrom IPython.display import SVG\nfrom tensorflow.keras.utils import plot_model, model_to_dot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.utils import to_categorical\nfrom tqdm import tqdm\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import (Add, Input, Conv2D, Dropout, Activation, BatchNormalization, \n                                    MaxPooling2D, ZeroPadding2D, AveragePooling2D, Flatten, Dense)\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, Callback\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.initializers import *\n\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_final_history(history):\n    \n    plt.style.use(\"ggplot\")\n    fig, ax = plt.subplots(1,2,figsize=(15,5))\n    \n    ax[0].set_title('Loss')\n    ax[1].set_title('Accuracy')\n    \n    ax[0].plot(history.history['loss'], label=\"Training Loss\")\n    ax[0].plot(history.history['val_loss'], label=\"Validation Loss\")\n    ax[1].plot(history.history['accuracy'], label=\"Training Accuracy\")\n    ax[1].plot(history.history['val_accuracy'], label=\"Validation Accuracy\")\n    \n    ax[0].legend(loc='upper right')\n    ax[1].legend(loc='lower right')\n    \n    plt.show();\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n    \n    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n    plt.figure(figsize=(20,20))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes,rotation=90)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f'\n    thresh = cm.max()/2.0\n    \n    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        \n        plt.text(j,i, format(cm[i,j], fmt),\n                horizontalalignment = \"center\",\n                color = \"white\" if cm[i,j] > thresh else \"black\")\n        pass\n    \n    plt.ylabel(\"True Label\")\n    plt.xlabel(\"Predicted Label\")\n    plt.grid(None);\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = \"../input/landuse-scene-classification/images\"\n\nwith open(\"../input/landuse-scene-classification/label_map.json\",\"r\") as file:\n    class_name_binarized = json.load(file)\n\nnum_classes = len(class_name_binarized)\nclass_names = list(class_name_binarized.keys())\nclass_name_binarized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(csv_file):\n    images, labels = [], []\n    \n    data = pd.read_csv(csv_file,index_col=\"Unnamed: 0\")\n    \n    for i in tqdm(range(data.shape[0])):\n        \n        img_name = data.loc[i,'Filename']\n        img = load_img(os.path.join(dataset_path,img_name),target_size=(224,224))\n        img = img_to_array(img)\n        \n        img = preprocess_input(img)\n        label = data.loc[i,'Label']\n        \n        images.append(img)\n        labels.append(label)\n        pass\n    \n    images = np.array(images)\n    labels = np.array(labels)\n    return images, labels\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images, train_labels = load_data(\"../input/landuse-scene-classification/train.csv\")\nval_images, val_labels = load_data(\"../input/landuse-scene-classification/validation.csv\")\n\ntrain_images.shape, train_labels.shape, val_images.shape, val_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = to_categorical(train_labels)\nval_labels = to_categorical(val_labels)\n\ntrain_labels.shape, val_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_block(X,k,filters,stage,block,s=2):\n    \n    conv_base_name = 'conv_' + str(stage) + block + '_branch'\n    bn_base_name = 'bn_' + str(stage) + block + '_branch'\n    ac_base_name = 'ac_' + str(stage) + block + '_branch'\n    \n    F1 = filters\n    \n    X = Conv2D(filters=F1, kernel_size=(k,k), strides=(s,s),\n              padding='same', name=conv_base_name+'2a')(X)\n    X = BatchNormalization(name=bn_base_name+'2a')(X)\n    X = Activation(\"relu\", name=ac_base_name+'2a')(X)\n    \n    return X\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_model(input_shape, classes):\n    \n    X_input = Input(input_shape)\n    \n    X = ZeroPadding2D((5,5),name=\"zero_padding_1\")(X_input)\n    \n    X = Conv2D(16,(3,3), strides=(2,2), name='conv1', padding=\"same\")(X)\n    X = BatchNormalization(name=\"bn_conv1\")(X)\n    \n    X = conv_block(X,3,32,2,block='A',s=1)\n    X = MaxPooling2D((2,2), name=\"max_pooling_2\")(X)\n    X = Dropout(0.25, name=\"dropout_2\")(X)\n    \n    X = conv_block(X,5,32,3,block='A',s=2)\n    X = MaxPooling2D((2,2), name=\"max_pooling_3\")(X)\n    X = Dropout(0.25, name=\"dropout_3\")(X)\n    \n    X = conv_block(X,3,64,4,block='A',s=1)\n    X = MaxPooling2D((2,2), name=\"max_pooling_4\")(X)\n    X = Dropout(0.25, name=\"dropout_4\")(X)\n    \n    X = Flatten(name=\"flatten_1\")(X)\n    X = Dense(64,name=\"dense_1\")(X)\n    X = Activation(\"relu\",name=\"dense_relu_1\")(X)\n    \n    X = Dense(128,name=\"dense_2\")(X)\n    X = Activation(\"relu\", name=\"dense_relu_2\")(X)\n    \n    X = Dense(classes,activation=\"softmax\",name=\"fc\"+str(classes))(X)\n    \n    model = Model(inputs=X_input, outputs=X, name=\"Basic_Conv_model\")\n    \n    return model\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = conv_model(input_shape=(224,224,3),classes=num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model,to_file='basic_conv_model.png',show_shapes=True,show_layer_names=True)\nSVG(model_to_dot(model).create(prog='dot',format='svg'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(lr=1e-3)\nmodel.compile(optimizer=opt, loss=\"categorical_crossentropy\",metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\nlogs = TensorBoard(\"logs\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\nbatch_size = 10\n\nhistory = model.fit(train_images, train_labels,\n                   steps_per_epoch=len(train_images)//batch_size,\n                   epochs=epochs,\n                   verbose=1,\n                   validation_data=(val_images, val_labels),\n                   validation_steps=len(val_images)//batch_size,\n                   callbacks=[checkpoint, logs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_final_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pred = model.predict(val_images)\nval_pred = np.argmax(val_pred, axis=1)\nval_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_actual = np.argmax(val_labels, axis=1)\n\ncnf_mat = confusion_matrix(val_actual, val_pred)\nnp.set_printoptions(precision=2)\n\nplt.figure()\nplot_confusion_matrix(cnf_mat, classes=class_names)\nplt.grid(None)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/landuse-scene-classification/images_train_test_val/train\"\nval_dir = \"../input/landuse-scene-classification/images_train_test_val/validation\"\n\nbatchSize = 10\n\nIGD = ImageDataGenerator(rescale=1./255.)\n\ntrain_generator = IGD.flow_from_directory(train_dir,\n                                         target_size=(224,224),\n                                         color_mode='rgb',\n                                         batch_size=batchSize,\n                                         class_mode='categorical',\n                                         shuffle=True,\n                                         seed=42)\n\nval_generator = IGD.flow_from_directory(val_dir,\n                                        target_size=(224,224),\n                                        color_mode='rgb',\n                                        batch_size=batchSize,\n                                        class_mode='categorical',\n                                        shuffle=True,\n                                        seed=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1 = MobileNet(weights=\"imagenet\",include_top=False,input_shape=(224,224,3))\n\nfor layer in model_1.layers:\n    layer.trainable = False\n\nmodel_1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"headModel = model_1.output\nheadModel = AveragePooling2D(pool_size=(7,7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128,activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(num_classes, activation=\"softmax\")(headModel)\n\nmodel_2 = Model(inputs=model_1.input, outputs=headModel)\n\nmodel_2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt_2 = Adam(lr=1e-3)\nmodel_2.compile(loss=\"categorical_crossentropy\",optimizer=opt_2,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model_2,to_file='MobileNet_transfer_model.png',show_shapes=True,show_layer_names=True)\nSVG(model_to_dot(model_2).create(prog='dot',format='svg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MobileNet_checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\nMobileNet_logs = TensorBoard(\"MobileNet-transfer-logs\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30\nbatchSize = 10\n\nhistory = model_2.fit(train_images, train_labels,\n                      steps_per_epoch=len(train_images)//batchSize,\n                      epochs=epochs,\n                      verbose=1,\n                      validation_data=(val_images,val_labels),\n                      validation_steps=len(val_images)//batchSize,\n                      callbacks=[MobileNet_checkpoint, MobileNet_logs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_final_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pred = model_2.predict(val_images)\nval_pred = np.argmax(val_pred, axis=1)\nval_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_actual = val_generator.classes\n# val_actual.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_actual = np.argmax(val_labels, axis=1)\n\ncnf_mat = confusion_matrix(val_actual, val_pred)\nnp.set_printoptions(precision=2)\n\nplt.figure()\nplot_confusion_matrix(cnf_mat, classes=class_names)\nplt.grid(None)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.save(\"MobileNet_transfer_model.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}