{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Contents  \n### * Check Data\n### * EDA\n### * Feature Engineering\n### * Comparing some Classification Methods"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nfrom sklearn.preprocessing import power_transform\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/health-insurance-cross-sell-prediction/train.csv').set_index('id')\ntest = pd.read_csv('../input/health-insurance-cross-sell-prediction/test.csv').set_index('id')\nprint('train :\\t',train.shape)\nprint('test :\\t',test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df = pd.DataFrame(columns=['train_nunique','test_nunique','n_values_only_in_test'])\ncat_col = ['Gender','Region_Code','Vehicle_Age','Policy_Sales_Channel']\n\nfor c in cat_col:\n    cat_df.at[c,'train_nunique'] = train[c].nunique()\n    cat_df.at[c,'test_nunique'] = test[c].nunique()\n    cat_df.at[c, 'n_values_only_in_test'] = len(\n        [v for v in test[c].unique() if v not in train[c].unique()])\n\ncat_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_cat(col,height,orderlist=None):\n    fig,ax = plt.subplots(1,2,sharey=True,figsize=(14,height))\n    sns.countplot(y=train[col],orient='h',order=orderlist,ax=ax[0])\n    sns.pointplot(y=col,x='Response',data=train,orient='h',ax=ax[1])\n    ax[1].set_xlim((0,0.3));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_cat('Gender',2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_cat('Driving_License',2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_cat('Previously_Insured',2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_cat('Vehicle_Age',3,orderlist=['< 1 Year','1-2 Year','> 2 Years'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cat('Vehicle_Damage',2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(3,2,figsize=(14,12))\nsns.distplot(train['Age'],kde=False,ax=ax[0,0])\nsns.violinplot(x='Age',y='Response',data=train,orient='h',ax=ax[0,1])\nsns.distplot(train['Vintage'],kde=False,ax=ax[1,0])\nsns.violinplot(x='Vintage',y='Response',data=train,orient='h',ax=ax[1,1])\nsns.distplot(train['Annual_Premium'],kde=False,ax=ax[2,0])\nsns.violinplot(x='Annual_Premium',y='Response',data=train,orient='h',ax=ax[2,1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['Response']\n\ntrain1 = train.drop('Response', axis=1)\ntest1 =test.copy()\ntrain1['status'], test1['status'] = 'train', 'test'\nallx = pd.concat([train1, test1])\n\nallx['sex'] = allx['Gender'].map({'Male':0, 'Female':1})\nallx['vehicle_age'] = allx['Vehicle_Age'].map({'< 1 Year':0, '1-2 Year':1, '> 2 Years':2})\nallx['vegicle_damage'] = allx['Vehicle_Damage'].map({'No':0, 'Yes':1})\n\n# Age, Annual_Premium -> Box-Cox transform\nallx['age'], allx['premium'] = 0, 0\nallx[['age', 'premium']] = power_transform(allx[['Age', 'Annual_Premium']], method='box-cox')\n\n# Region_Code, Policy_Sales_Channel -> Count Encoding\nregion_dic = allx['Region_Code'].value_counts().to_dict()\nmax_region = allx['Region_Code'].value_counts().max()\nallx['region'] = allx['Region_Code'].map(region_dic) / max_region\n\nchannel_dic = allx['Policy_Sales_Channel'].value_counts().to_dict()\nmax_channel = allx['Policy_Sales_Channel'].value_counts().max()\nallx['channel'] = allx['Policy_Sales_Channel'].map(channel_dic) / max_channel\n\nallx.drop(['Gender','Age','Region_Code','Vehicle_Age','Vehicle_Damage','Annual_Premium',\n           'Policy_Sales_Channel','Vintage'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = allx[allx['status']=='train'].drop('status', axis=1)\ntest_x = allx[allx['status']=='test'].drop('status', axis=1)\n\nx_train, x_valid, y_train, y_valid = train_test_split(x,y,test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparing some Classification Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"def auc_validation(clf):\n    return roc_auc_score(y_valid, clf.fit(x_train, y_train).predict_proba(x_valid)[:,1])\n\nLRC = LogisticRegression()\nRFC = RandomForestClassifier(random_state=0)\nGBC = GradientBoostingClassifier(random_state=0)\nXGB = XGBClassifier(random_state=0)\nLGB = LGBMClassifier(random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient Boosting methods work well"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LRC:\\t', auc_validation(LRC))\nprint('RFC:\\t', auc_validation(RFC))\nprint('GBC:\\t', auc_validation(GBC))\nprint('XGB:\\t', auc_validation(XGB))\nprint('LGB:\\t', auc_validation(LGB))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be continued..."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}