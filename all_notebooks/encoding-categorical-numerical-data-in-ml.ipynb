{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 15px;\n              color:white;\">\n            <b> Encoding Categorical and Numerical Data </b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    In this notebook I will be showing you how to encode categorical and numerical columns in python. \n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://2ubrsn5y54ao0ufa2mpsbmg3-wpengine.netdna-ssl.com/wp-content/uploads/2021/02/Hedof-x-Youtube_10-750x371.jpg)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#EEB03B;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 15px;\n              color:white;\">\n            <b> 1. Encoding Categorical Data </b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    There are two main types of data, Numerical and Categorical. For now we will be learning how to handle categorical columns in your dataset. As our machine learning model will not be able to read text data and make a model out of it, say, linear regression, we will always need to convert it into some kind of numerical data. Suppose we have a Sex Column with Male and Female. We can turn the single Sex column to 2 columns of Male and Female. When Male is true, we make the value 1 and when Male is false the value is 0. Vice versa for Female Column. This is how to encode them. We we learn some ways to do the same, below. \n</div>","metadata":{}},{"cell_type":"markdown","source":"***\n## Types of Categorical Data :\n   * **Ordinal Categorical** : This data will stay in order. Suppose you have a column of education degrees, school, undergraduate, graduate and so on. Here, there is an order between the two. If you change school to 1, undergraduate to 2 and graduate to , then you will maintain the order between them. \n       - **One Hot Encoder** : pd.dummies can also be used in place of onehot but as everytime you run pd.dummies the categories will change position in the output, for machine learning, it is best if you use OneHotEncoder. \n       \n   \n   * **Cardinal Categorical** : This data is not in order. Hence, cardinal. For example, gender column of Male and Female. They do not have any order in them. Female is not better or worse than Male, you cannot fit them in an order. In these cases, you cannot categorize them in an order like 1, 2, 3. As 3 is always more than 2 and 2 is more than 1. You have to change every category to a new column and make it a boolean binary value of 1 and 0. \n       - **Ordinal Encoder** : Used only for input or X columns. \n       - **Label Encoder** : Used only for output or Y columns.\n***\n## **Dummie Variable Trap :**\n\nWhen you are using One Hot Encoder, always get rid of 1 category. Suppose you have K categories in the column, always, after encoding them into K number of columns, get rid of any 1. Total number of columns after encoding should be (K - 1). This is the reasin why this is also called **K - 1 Encoding**.\n\n\n***","metadata":{}},{"cell_type":"code","source":"# importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_theme(style=\"dark\")\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:57.37813Z","iopub.execute_input":"2021-08-10T04:01:57.378516Z","iopub.status.idle":"2021-08-10T04:01:57.385246Z","shell.execute_reply.started":"2021-08-10T04:01:57.378477Z","shell.execute_reply":"2021-08-10T04:01:57.38416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cx = pd.read_csv(\"../input/customer/customer.csv\", index_col=None)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:57.386731Z","iopub.execute_input":"2021-08-10T04:01:57.387148Z","iopub.status.idle":"2021-08-10T04:01:57.401503Z","shell.execute_reply.started":"2021-08-10T04:01:57.387106Z","shell.execute_reply":"2021-08-10T04:01:57.400333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cx.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-08-10T04:01:57.402697Z","iopub.execute_input":"2021-08-10T04:01:57.403048Z","iopub.status.idle":"2021-08-10T04:01:57.421593Z","shell.execute_reply.started":"2021-08-10T04:01:57.403021Z","shell.execute_reply":"2021-08-10T04:01:57.420507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,6), facecolor='#f6f5f5')\ncols = list(enumerate(df_cx.columns[1:]))\nplt.suptitle(\"Categorical Columns\", fontsize=17)\nfor i in cols:\n    plt.subplot(1,4,i[0]+1)\n    sns.countplot(data = df_cx, x = i[1], palette = \"rainbow\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:57.42387Z","iopub.execute_input":"2021-08-10T04:01:57.424246Z","iopub.status.idle":"2021-08-10T04:01:58.029631Z","shell.execute_reply.started":"2021-08-10T04:01:57.424215Z","shell.execute_reply":"2021-08-10T04:01:58.028612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ^^^^^ <br>\nHere, you can see that we have only 1 cardinal column, that is gender.<br>\nRest 4 are ordinal columns. So we will use OneHotEncoding for only gender and in rest, we will be using Ordinal Encoder for only X and Label encoder for Y. Purchase column is the output or Y here and we only use Label Encoder for Y columns or dependent variables.**\n***","metadata":{}},{"cell_type":"code","source":"# X_train and Y_train\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train , y_test = train_test_split(df_cx.iloc[:,0:4], df_cx.iloc[:,4], test_size = 0.2, random_state = 2)\nprint(X_train.shape, y_train.shape)\nprint( X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.030909Z","iopub.execute_input":"2021-08-10T04:01:58.031227Z","iopub.status.idle":"2021-08-10T04:01:58.03949Z","shell.execute_reply.started":"2021-08-10T04:01:58.031193Z","shell.execute_reply":"2021-08-10T04:01:58.038669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    One Hot Encoding for Gender Column. <br>\n    Ordinal Encoding for columns of X or Review and Education column.\n</div>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\n\n\nCatEncod = ColumnTransformer(transformers=[\n    (\"genderEncod\", OneHotEncoder(drop=\"first\", sparse=False), [1]), #drop first will remove 1 col for dummie var trap\n    (\"Xordinal\", OrdinalEncoder(), [2,3]) # here [2,3] is the index of columns \n], remainder=\"passthrough\")","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.040595Z","iopub.execute_input":"2021-08-10T04:01:58.041008Z","iopub.status.idle":"2021-08-10T04:01:58.054327Z","shell.execute_reply.started":"2021-08-10T04:01:58.040977Z","shell.execute_reply":"2021-08-10T04:01:58.053288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CatEncod.fit_transform(X_train)\nCatEncod.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.055504Z","iopub.execute_input":"2021-08-10T04:01:58.055952Z","iopub.status.idle":"2021-08-10T04:01:58.082903Z","shell.execute_reply.started":"2021-08-10T04:01:58.055921Z","shell.execute_reply":"2021-08-10T04:01:58.082119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    Label Encoding for Purchase column as this is the dependent variable and is ordinal.\n</div>","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\n\nle.fit_transform(y_train)\nle.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.084093Z","iopub.execute_input":"2021-08-10T04:01:58.084483Z","iopub.status.idle":"2021-08-10T04:01:58.099494Z","shell.execute_reply.started":"2021-08-10T04:01:58.084455Z","shell.execute_reply":"2021-08-10T04:01:58.098489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#EEB03B;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 15px;\n              color:white;\">\n            <b> 2. Encoding Numerical Data </b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    We have learned how to encode categorical columns. Now, we will lean how to do the same for Numerical columns. Below we will discuss the types of encoding numerical columns. \n</div>","metadata":{}},{"cell_type":"markdown","source":"![binning.PNG](https://cdn.discordapp.com/attachments/517815672613503006/873213661605400666/binning.PNG)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#0F6395;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding:15px;\n              color:white;\">\n            <b> a. Equal Width Binning (Uniform Binning)</b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    This divides the numerical column into equal widths according to the number of bins in the parameter.\n</div>","metadata":{}},{"cell_type":"code","source":"# this is the only class that we will need for all the encoding that we will do for numerical columns\nfrom sklearn.preprocessing import KBinsDiscretizer","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.100838Z","iopub.execute_input":"2021-08-10T04:01:58.101231Z","iopub.status.idle":"2021-08-10T04:01:58.109689Z","shell.execute_reply.started":"2021-08-10T04:01:58.1012Z","shell.execute_reply":"2021-08-10T04:01:58.108627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def AutoEncodePlot(strat, numbin, pal):\n    NumEncod = ColumnTransformer(transformers = [\n        (\"equalwidth\", KBinsDiscretizer(strategy = strat, n_bins=numbin, encode = \"ordinal\"), [0])\n    ])\n    background_color = \"#f6f5f5\"\n    \n    plt.figure(figsize=(10,6), facecolor='#f6f5f5')\n\n    plt.subplot(1,2,1)\n    sns.histplot(data = X_train[\"age\"], color=\"#D6265D\", legend=False)\n    plt.xlabel(\"AGE\")\n    plt.ylabel(\"\")\n    plt.title(\"Before Binnning\")\n\n    plt.subplot(1,2,2)\n    sns.histplot(data = NumEncod.fit_transform(X_train), palette=pal, legend=False)\n    plt.xlabel(\"AGE\")\n    plt.ylabel(\"\")\n    plt.title(\"After Binning\")\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.113513Z","iopub.execute_input":"2021-08-10T04:01:58.113859Z","iopub.status.idle":"2021-08-10T04:01:58.122971Z","shell.execute_reply.started":"2021-08-10T04:01:58.113819Z","shell.execute_reply":"2021-08-10T04:01:58.121976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AutoEncodePlot(\"uniform\", 4, \"YlOrBr\") #uniform category of 4 age groups","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#D6265D;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding:15px;\n              color:white;\">\n            <b> b. Equal Frequency Binning (Quantile Binning) </b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    This will create bins of equal frequency. So the data distribution will be equal. Suppose you have 10 bins, then there will be equal frequency of ages in each bin. For example, in total 100 age values, 10 age will be in each bin as in total there are 10 bins in the parameter. \n</div>","metadata":{}},{"cell_type":"code","source":"AutoEncodePlot(\"quantile\", 5, \"cool\") #quantile binning of 5 bins","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.124508Z","iopub.execute_input":"2021-08-10T04:01:58.124833Z","iopub.status.idle":"2021-08-10T04:01:58.523174Z","shell.execute_reply.started":"2021-08-10T04:01:58.124805Z","shell.execute_reply":"2021-08-10T04:01:58.521874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#7768F8;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding:15px;\n              color:white;\">\n            <b> c. K - Means Binning </b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    This uses K - Means Clustering in order to find out the best frequency for a certain bin. Total number of bins is according to the input parameter. \n</div>","metadata":{}},{"cell_type":"code","source":"AutoEncodePlot(\"kmeans\", 3, \"viridis\") #3 bins using k-means binning","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.524662Z","iopub.execute_input":"2021-08-10T04:01:58.525126Z","iopub.status.idle":"2021-08-10T04:01:58.918433Z","shell.execute_reply.started":"2021-08-10T04:01:58.525042Z","shell.execute_reply":"2021-08-10T04:01:58.917345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#EEB03B;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 15px;\n              color:white;\">\n            <b> 3. Binarization </b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    This is the simplest form of encoding numerical columns. You keep a threshold. Suppose, any age that is greater than 50 will be in category 1 and age below 50 will be in category 0. It will be a binary category, hence the name.\n</div>","metadata":{}},{"cell_type":"code","source":"#importing binarizing class\nfrom sklearn.preprocessing import Binarizer","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.919676Z","iopub.execute_input":"2021-08-10T04:01:58.91994Z","iopub.status.idle":"2021-08-10T04:01:58.924484Z","shell.execute_reply.started":"2021-08-10T04:01:58.919913Z","shell.execute_reply":"2021-08-10T04:01:58.92352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BinarCol = ColumnTransformer(transformers = [\n    (\"agebin\", Binarizer(threshold=50, copy=False), [0]) #copy false as the output col will not be a new column\n]\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.926534Z","iopub.execute_input":"2021-08-10T04:01:58.92705Z","iopub.status.idle":"2021-08-10T04:01:58.937191Z","shell.execute_reply.started":"2021-08-10T04:01:58.927003Z","shell.execute_reply":"2021-08-10T04:01:58.935895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = {\"AgeCat\":BinarCol.fit_transform(X_train).reshape(40,),\n\"Age\": X_train[\"age\"]}\npd.DataFrame(X).head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T04:01:58.9389Z","iopub.execute_input":"2021-08-10T04:01:58.939337Z","iopub.status.idle":"2021-08-10T04:01:58.961548Z","shell.execute_reply.started":"2021-08-10T04:01:58.939293Z","shell.execute_reply":"2021-08-10T04:01:58.96028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    See how the numerical column has been categorized to a binary column. Any age above 50 will be 1 and below 50 will be 0. It is very easy. Try these yourself. <br>\n</div>","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#EEB03B;\n           font-size:220%;\n           font-family:Nexa;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 15px;\n              color:white;\">\n            <b> Conclusion </b>\n        </p>\n</div>\n<div class=\"alert alert-block alert-info\" style=\"font-size:16px; font-family:Nexa;\">\n    Binning rarely helps with your accuracy of model. Most of the models categorize the numerical columns by itself however they have their own ways of doing that. Most of the times, the best outcome is visualization and you can gain intuitive understanding of data by simply categorizing the numerical columns. However, try these techniques for yourself and see if your model is improving in any way. It might improve if the number of bins is low and accurately divides the total distribution but for that you will need domain knowledge. A big part of feature engineering is domain knowledge. If you have a data where you know, every 1000 points change will have similar effects on the outcome, then you know what to do. Bin the whole dataset into equal frequencies of 1000 per bin. Simple. That will hugely benefit your hypothesis. <br>\n    However, I will suggest you to use trail and error again. You never know what will increase the accuracy and give your model the edge you need. Happy kaggling!\n</div>","metadata":{}}]}