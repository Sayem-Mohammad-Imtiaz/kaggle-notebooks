{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import necessary libraries\nimport pandas as pd \nimport numpy as np\nimport seaborn as sbn\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\ntitanic2 = pd.read_csv(\"../input/titanic/train_and_test2.csv\").dropna()\n\ndata = titanic2[['Age', 'Fare', 'Sex', 'sibsp','Parch','Pclass','Embarked','2urvived']]\nX = titanic2[['Age', 'Fare', 'Sex', 'sibsp','Parch','Pclass','Embarked']]\ny = titanic2['2urvived']\n#There were two incomplete rows in the original dataset. dropna() should remove them.\nX[X.isnull().any(axis=1)]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il dataset in input ha ricevuto alcune operazioni di preprocessing rispetto a quello del contest originale:\n\n1. I set di test e train sono stati riuniti\n2. Gli elementi testuali come il sesso sono gia stati convertiti in indici numerici in base al loro label.\n3. Alcune categorie poco attinenti (come il nome della persona) sono state escluse.\n\nMostriamo innanzitutto la correlazione tra le colonne di X e il risultato, e l'autocorrelazione tra gli elementi di X.\nL'operazione viene svolta tramite il preset \"heatmap\" di seaborn"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verify correlation with 'Survived' and within X\nplt.figure(figsize=(12,10))\ncor = data.corr()\nsbn.heatmap(cor, annot=True, cmap=plt.cm.Spectral)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Non è sorprendente vedere uno sbilanciamento in correlazione tra il sesso del passeggero e la sua capacita di sopravvivenza.\nCirca il 70% delle donne a bordo sopravvissero il naufragio, contro il 20% degli uomini.\n\nDal grafico si possono estrarre anche informazioni di autocorrelazione da cui migliorare l'input al modello naive Bayes, che si aspetta \nvariabili relativamente indipendenti. La più evidente è Fare/Pclass: il costo del biglietto e la classe a bordo sono ovviamente fortemente correlati.\nTestando quale delle due classi genera un risultato migliore, si puo vedere che Pclass fornisce informazioni più utili alla classificazione corretta se unita alle altre colonne rimanenti."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unsurprisingly, boarding class and fare are strongly correlated. \n# Less correlated but still quite high are Age/Class and Siblings+Spouses/Parents+children\n# Fare might give us more granular information between the two.\n# On the other hand, information about the actual class has stronger implication on the person's location within the ship.\n# The model seems to perform much better with 'Fare' dropped.\n\n#X =X.drop(['Pclass'], axis=1)\nX = X.drop('Fare', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into training and test with a fixed random state.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n\ndef evaluate(y_test, y_pred):\n        print(\"accuracy:\", accuracy_score(y_test, y_pred))\n        print(\"precision:\", precision_score(y_test, y_pred))\n        print(\"recall:\", recall_score(y_test, y_pred))\n        #print(\"AUC:\", roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applichiamo sullo stesso split due modelli separati:\n* Un modello generico di GaussianNB, che scala e tratta i dati assumendo che siano generalmente distribuiti secondo una distribuzione normale\n* Un modello ComplementNB, che sklearn dichiara empiricamente più adatto a trattare dati sbilanciati (come nel caso del titanic, contro i sopravvissuti)\n\nStampiamo anche le matrici di confusione e le metriche corrispondenti delle predizioni per dimostrare gli effetti dei modelli individuali."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply scikit-learn's GaussianNB model.\nfrom sklearn.naive_bayes import GaussianNB\n\n# No need to preprocess data since GaussianNB will by default rescale and fit the input on its own.\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\n\nevaluate(y_test, y_pred)\n\n# Plot the confusion matrix for the test sample [0 for died, 1 for survived].\n\nerrors = confusion_matrix(y_test,y_pred)\nprint(errors)\nsbn.heatmap(errors, annot=True, fmt=\"d\", cmap=plt.cm.Reds)\n\ny_gauss = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The total accuracy is decent (especially considering the original titanic contest winners' was also quite low)\n# But recall and precision could be better. It may be because the dataset is imbalanced against survivors (at about 70%)\n# Let's try out Complement Naive Bayes, since sklearn's docs say \n# 'CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets. '\n\nfrom sklearn.naive_bayes import ComplementNB\n\ncnb = ComplementNB() # No particular default parameter tweaking needed.\ncnb.fit(X_train, y_train)\ny_pred = cnb.predict(X_test)\n\nevaluate(y_test, y_pred)\n\nerrors = confusion_matrix(y_test,y_pred)\nprint(errors)\nsbn.heatmap(errors, annot=True, fmt=\"d\", cmap=plt.cm.Reds)\n\ny_compl = y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Possiamo notare che nonostante l'accuratezza del modello GaussianNB sia relativamente alta, genera più falsi negativi che positivi veri.\nQuesto viene evidenziato dal punteggio di recall molto basso.\n\nIl risultato del modello ComplementNB perde leggermente nell'accuratezza totale ma discrimina in maniera molto più accurata tra i sopravvissuti.\nCiò può indicare che l'errore di bias verso una direzione nelle predizioni del modello gaussiano fosse effettivamente generato dallo squilibrio del dataset.\n\nLa metrica di F-measure supporta tale conclusione; il risultato del modello ComplementNB genera un punteggio più vicino a 1 rispetto a GaussianNB."},{"metadata":{"trusted":true},"cell_type":"code","source":"# F-Measure for both classifiers. We expect ComplementNB's score to be higher.\nfrom sklearn.metrics import f1_score\n\nprint(\"Gaussian: {}\".format(f1_score(y_test, y_gauss)))\nprint(\"Complement: {}\".format(f1_score(y_test, y_compl)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}