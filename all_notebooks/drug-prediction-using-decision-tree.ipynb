{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook I will use this classification algorithm to build a model from historical data of patients, and their response to different medications. I use the trained decision tree to predict the class of a unknown patient, or to find a proper drug for a new patient.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/drugsets/drug200.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let see the shape of the data\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we can see that we are dealing with categorical data so we have to transform them because machine learning algorithms work only with numerical data for now let import the important package\n# we are going to use \nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pre-processing\nUsing my_data as the Drug.csv data read by pandas, declare the following variables:\n\nX as the Feature Matrix (data of my_data)\ny as the response vector (target)\nRemove the column containing the target name since it doesn't contain numeric values.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\ndf['Sex'] = encoder.fit_transform(df['Sex'])\ndf['BP'] = encoder.fit_transform(df['BP'])\ndf['Cholesterol'] = encoder.fit_transform(df['Cholesterol'])\ndf['Na_to_K'] = encoder.fit_transform(df['Na_to_K'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,[1,2,3,4]]\ny = df.iloc[:,5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[:5] ,y[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting up the Decision Tree\nWe will be using train/test split on our decision tree. Let's import train_test_split from sklearn.model_selection.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now train_test_split will return 4 different parameters. We will name them:\nX_trainset, X_testset, y_trainset, y_testset\n\nThe train_test_split will need the parameters:\nX, y, test_size=0.3, and random_state=3.\n\nThe X and y are the arrays required before the split, the test_size represents the ratio of the testing dataset, and the random_state ensures that we obtain the same splits.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =.3,random_state =3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now let see the shape of train and test set\nX_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape , y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Modeling\nWe will first create an instance of the DecisionTreeClassifier called drugTree.\nInside of the classifier, specify criterion=\"entropy\" so we can see the information gain of each node.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifer = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifer.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y pred variable \ny_pred = classifer.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#You can print out y_pred and y_test if you want to visually compare the prediction to the actual values.\nprint(y_pred[:5])\nprint(y_test[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluation\nNext, let's import metrics from sklearn and check the accuracy of our model.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nimport matplotlib.pyplot as plt\nprint(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy classification score computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\n\nIn multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0\nI our case here we have done a great job we get 0.93% means 93% we can trust our model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.externals.six import StringIO\n# import pydotplus\nimport matplotlib.image as mpimg\nfrom sklearn import tree\n%matplotlib inline ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}