{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task : The most min temp"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Minimum Temperature   \"+str(df['MinTemp'].min()))\ndf.groupby('Location',sort = False)['MinTemp'].min().nsmallest()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task : Most max temp"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Maximum Temperature   \"+str(df['MaxTemp'].max()))\ndf.groupby('Location',sort = False)['MaxTemp'].max().nlargest()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task : Largest amount of rainfall"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Highest Rainfall      \"+str(df['Rainfall'].max()))\ndf.groupby('Location',sort = False)['Rainfall'].max().nlargest()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see % of missing values\n\ndf.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values % in the features Evaporation=43%, Sunshine 48%, Cloud9am=38%, Cloud3pm=40% \n# This are to much missing value, I'm dropping this features.\n\ndf=df.drop(['Evaporation','Sunshine','Cloud9am','Cloud3pm'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let seperate Categories and numerical features\n\ndf_cat=df[['WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow','Date','Location']]\n\ndf_num=df.drop(['WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow','Date','Location'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Every location has different windspeed, direction, Temperature and Pressure  \n# Replacing Categories features with most frequent value based on location \n\nfor col in df_cat.columns.values:\n    if df[col].isnull().sum() == 0:\n        continue\n    df_cat[col] = df.groupby(['Location'])[col].apply(lambda x: x.fillna(x.mode().max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Still we have missing value for WindGustDir because for few locations we have no values \n\ndf_cat.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We replace this values with the mode of complete dataset\n\ndf_cat['WindGustDir']=df['WindGustDir'].fillna(df['WindGustDir'].mode().max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing Numerical features with mean value based on location same as Categories\n\nfor col in df_num.columns.values:\n    if df[col].isnull().sum() == 0:\n        continue\n    df_num[col] = df.groupby(['Location'])[col].apply(lambda x: x.fillna(x.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This has same problem as df_cat, We will replace is mean value of dataset\n\ndf_num['WindGustSpeed']=df_num['WindGustSpeed'].fillna(df['WindGustSpeed'].mean())\ndf_num['Pressure9am']=df_num['Pressure9am'].fillna(df['Pressure9am'].mean())\ndf_num['Pressure3pm']=df_num['Pressure3pm'].fillna(df['Pressure3pm'].mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d={'Yes':1,'No':0}\ndf_cat['RainTomorrow']=df_cat['RainTomorrow'].map(d)\ndf_cat['RainToday']=df_cat['RainToday'].map(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat2=df_cat[['WindGustDir','WindDir9am','WindDir3pm','Location']]\n\n#Replacing Categories value with value counts\n\ndf_cat2['Location']=df_cat2['Location'].map(df_cat2['Location'].value_counts())\ndf_cat2['WindGustDir']=df_cat2['WindGustDir'].map(df_cat2['WindGustDir'].value_counts())\ndf_cat2['WindDir9am']=df_cat2['WindDir9am'].map(df_cat2['WindDir9am'].value_counts())\ndf_cat2['WindDir3pm']=df_cat2['WindDir3pm'].map(df_cat2['WindDir3pm'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_n=pd.merge(df_num, df_cat2, left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Standar Scaler to scaled\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df_n)\ndf_scaled = pd.DataFrame(scaler.fit_transform(df_n),columns = df_n.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_x=pd.merge(df_scaled, df_cat['RainToday'],left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_x.hist(bins=50, figsize=(20, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let see the correlation\n\nplt.figure(figsize=(20,10))\nheatmap = sns.heatmap(df_x.corr(), vmin=-1, vmax=1, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Teamp9am(89%) and Temp3pm(98%) has high correlation with MaxTemp\n\ndf_x.drop('Temp9am',axis=1,inplace=True)\ndf_x.drop('Temp3pm',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(df_x, df_cat['RainTomorrow'], test_size=0.2, random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we can see we are dealing with big imbalance dataset, We need to perform oversampling\n\ndf_cat['RainTomorrow'].value_counts().plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Oversampled\n\nfrom imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state = 37) \nX_train_res, y_train_res = sm.fit_resample(X_train, y_train)\nfrom collections import Counter\n\nprint(\"Before {}\".format(Counter(y_train)))\nprint(\"After {}\".format(Counter(y_train_res)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost\n\nfrom sklearn import datasets, linear_model, metrics \nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score\nfrom xgboost import XGBClassifier\n\nmodel = XGBClassifier(max_depth=10,random_state = 37)\nmodel.fit(X_train_res, y_train_res)\nmodel.score(X_train_res, y_train_res)\n\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Confusion matrix \\n {}'.format(confusion_matrix(y_test,y_pred)))\nprint('Accuracy score {:.2f}'.format(accuracy_score(y_test,y_pred)*100))\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task : Update data up to 2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n\nm = Prophet()\n\ndf_for=df[['Date','Rainfall']]\ndf_for['Date']=pd.to_datetime(df_for['Date'])\ndf_for.rename(columns = {'Date':'ds'}, inplace = True)\ndf_for.rename(columns = {'Rainfall':'y'}, inplace = True)\nm.fit(df_for)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future = m.make_future_dataframe(periods=1285)\nfuture.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import add_changepoints_to_plot\nfig = m.plot(forecast)\na = add_changepoints_to_plot(fig.gca(), m, forecast)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}