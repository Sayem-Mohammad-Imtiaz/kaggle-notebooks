{"cells":[{"metadata":{"_uuid":"3f6c2bfe6b2e26c92357e896a1511195d836956e"},"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n    \n## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \nAuthor: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."},{"metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"},"cell_type":"markdown","source":"## <center> Assignment 4. Sarcasm detection with logistic regression\n    \nWe'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />"},{"metadata":{"trusted":true,"_uuid":"23a833b42b3c214b5191dfdc2482f2f901118247"},"cell_type":"code","source":"!ls ../input/sarcasm/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4"},"cell_type":"code","source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nsns.set()\nfrom matplotlib import pyplot as plt\n\n%config InlineBackend.figure_format = 'svg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856"},"cell_type":"code","source":"train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78"},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c"},"cell_type":"markdown","source":"Some comments are missing, so we drop the corresponding rows."},{"metadata":{"trusted":true,"_uuid":"97b2d85627fcde52a506dbdd55d4d6e4c87d3f08"},"cell_type":"code","source":"train_df.dropna(subset=['comment'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"},"cell_type":"markdown","source":"We notice that the dataset is indeed balanced"},{"metadata":{"trusted":true,"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11"},"cell_type":"code","source":"train_df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b836574e5093c5eb2e9063fefe1c8d198dcba79"},"cell_type":"markdown","source":"We split data into training and validation parts."},{"metadata":{"trusted":false,"_uuid":"7f0f47b98e49a185cd5cffe19fcbe28409bf00c0"},"cell_type":"markdown","source":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n\n## Links:\n  - Machine learning library [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n  - Kernels on [logistic regression](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) and its applications to [text classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), also a [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection) on feature engineering and feature selection\n  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approaching (Almost) Any NLP Problem on Kaggle\"\n  - [ELI5](https://github.com/TeamHG-Memex/eli5) to explain model predictions"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"79927a6f0857ec0c1a9dd1bb9ef0fdd6f83fe754"},"cell_type":"code","source":"# plt.figure(figsize=(10,4))\ntrain_df.loc[train_df['label'] == 1, 'comment'].str.len().apply(np.log1p).hist(alpha=.5, label='sarcastic')\ntrain_df.loc[train_df['label'] == 0, 'comment'].str.len().apply(np.log1p).hist(alpha=.5, label='normal')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87e9c0d06fe89991b6d2a66e3c0481289d12c4c7"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2126c13c6a34a0ddea61ce3b94da93558b8c3af4"},"cell_type":"code","source":"sub_label = train_df.groupby(\"subreddit\")['label'].agg([np.mean, np.sum, np.size])\nsub_label.sort_values(by='sum', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef37f9234df462bd058cc470e1c5f78193526d7d"},"cell_type":"code","source":"sub_label[sub_label['size'] > 1000].sort_values(by='mean', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f674df96326d206a06642dde1cdf386016ce84a6"},"cell_type":"markdown","source":"for authors"},{"metadata":{"trusted":true,"_uuid":"d969314dc9eb3737cd2daf2f427f5b8265073942"},"cell_type":"code","source":"author_label = train_df.groupby(\"author\")['label'].agg([np.mean, np.sum, np.size])\nauthor_label.sort_values(by='sum', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"41e93ba365156cf5c4724d2969a78ca51163ed38"},"cell_type":"code","source":"author_label[author_label['size'] > 400].sort_values(by='mean', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05ac4bed69377c042661c1e76da9ce4094eaae2e"},"cell_type":"markdown","source":"for scores"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7f9f0d519a7f7aabdfa19ea9a172acd5bc01b948"},"cell_type":"code","source":"score_label = train_df[train_df['score'] >= 0].groupby('score')['label'].agg([np.mean, np.sum, np.size])\nscore_label[score_label['size'] > 400].sort_values(by='mean', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e83e3826175dd2fabbe0400f5acbd7d01508a87d"},"cell_type":"markdown","source":"scores less than zero"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"33c74fe1d3cc5c64f8f871e350866ff817b22657"},"cell_type":"code","source":"score_label2 = train_df[train_df['score'] < 0].groupby('score')['label'].agg([np.mean, np.sum, np.size])\n# score_label2.head(10)\nscore_label2[score_label2['size'] > 400].sort_values(by='mean', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d03ea1ac99c9edbe7db23e00d308e0a886d1fbf3"},"cell_type":"code","source":"print('Maximum score: ', train_df['score'].max(), '\\n')\nprint('Minimum score: ', train_df['score'].min(), '\\n')\nprint('Mean score: ', train_df['score'].mean(), '\\n')\nprint('Standard Deviation score: ', train_df['score'].std(), '\\n')\nprint('Median score: ', train_df['score'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"162ef0142053ac4a7b5dbd003dcdfa2537865d5d"},"cell_type":"code","source":"max_score = train_df['score'].max()\nmin_score = train_df['score'].min()\n\nparent_comment_max_score = train_df.loc[train_df['score'] == max_score, 'parent_comment'].iloc[0]\nparent_comment_min_score = train_df.loc[train_df['score'] == min_score, 'parent_comment'].iloc[0]\n\ncomment_max_score = train_df.loc[train_df['score'] == max_score, 'comment'].iloc[0]\ncomment_min_score = train_df.loc[train_df['score'] == min_score, 'comment'].iloc[0]\n\nsarcasm_max_score = train_df.loc[train_df['score'] == max_score, 'label'].iloc[0]\nsarcasm_max_score = (sarcasm_max_score == 1)\n\nsarcasm_min_score = train_df.loc[train_df['score'] == min_score, 'label'].iloc[0]\nsarcasm_min_score = (sarcasm_min_score == 1)\n\nprint('The comment \"{}\", scored the highest at {}, had a parent comment of \"{}\" and it is labelled as sarcastic: {}'\n      .format(comment_max_score, max_score, parent_comment_max_score, sarcasm_max_score), '\\n')\n\nprint('The comment \"{}\", scored the lowest at {}, had a parent comment of \"{}\" and it is labelled as sarcastic: {}'\n      .format(comment_min_score, min_score, parent_comment_min_score, sarcasm_min_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66931a54766ea0a0ae7b7ebf61ca8f89524cacc4"},"cell_type":"code","source":"train_df['date'] = pd.to_datetime(train_df['date'], yearfirst=True)\ntrain_df['year'] = train_df['date'].apply(lambda d: d.year)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4c8c789a49eb320acc03f8dfc2fa532d2cd19ec"},"cell_type":"code","source":"year_comments = train_df.groupby('year')['label'].agg([np.mean, np.size, np.sum])\nyear_comments.sort_values(by='sum', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1c1d25ab49f304b56b06f39aa601962828768d0","scrolled":true},"cell_type":"code","source":"# plt.figure(figsize=(10,6))\nyear_comments['mean'].plot(kind='line')\nplt.title('Rate of Sarcastic Comments by Year')\nplt.ylabel('Mean Sarcastic Comments by Year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e9e9aa425ce692bb89b39317458f0a4cdc039db"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2602bfbfc540b279021cfe51219ab608a73abdca"},"cell_type":"code","source":"X = train_df['comment']\ny = train_df['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f02e37b04f32016d8ac60b584f84e604d7e2e8e0"},"cell_type":"code","source":"tf_idf = TfidfVectorizer(ngram_range=(1,2), max_features=60000, min_df=2)\nlogist = LogisticRegression(n_jobs=4, solver='lbfgs', random_state=17, verbose=1)\ntf_idf_logist_pipeline = Pipeline([('tf_idf', tf_idf),\n                                  ('logist', logist)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f477c03c92936c485f6f5b9d4a0f9e40e9266d76"},"cell_type":"code","source":"# fit\ntf_idf_logist_pipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db531504aaca8e4056faf9f9d109424ad839912d"},"cell_type":"code","source":"# predict\npred = tf_idf_logist_pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5cf31c748ae78f3ccef5b84d6e43ac87ddaff73","scrolled":true},"cell_type":"code","source":"# accuracy\naccuracy_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df3b8f76a86e3f6ecb46b0ac4cf3568185608d61"},"cell_type":"code","source":"print('Accuracy score is: {:.2%}'.format(accuracy_score(y_test, pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05f0bd20aeea486500b4f236161d2fc3985fcc98"},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba4eb7c452da1bc2fa9c7094a613337243f777d7"},"cell_type":"code","source":"classification_report(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efcd32948e39e760283ebe9e2f57530bf16e5ad2","scrolled":true},"cell_type":"code","source":"confusion_matrix(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5ea3c4281d3a2ac0b8d821ba15c83b9177bae53"},"cell_type":"code","source":"# plot confusion matrix\nplt.figure(figsize=(10, 6))\n\nconmat = pd.DataFrame(confusion_matrix(y_test, pred), index=['Not Sarcastic', 'Sarcastic'], \n                      columns=['Not Sarcastic', 'Sarcastic'])\n\nax = sns.heatmap(conmat, annot=True, cbar=False, cmap='viridis', linewidths=0.5, fmt='.0f')\nax.set_title('Confusion Matrix for Sarcasm Detection', fontsize=18, y=1.05)\nax.set_ylabel('Real', fontsize=12)\nax.set_xlabel('Predicted', fontsize=12)\nax.xaxis.set_ticks_position('bottom')\nax.yaxis.set_ticks_position('left')\n# ax.xaxis.set_label_position('bottom')\nax.tick_params(labelsize=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25493c542332624d11f024a440e189f9eac19280"},"cell_type":"code","source":"import eli5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5fd09ffe1837bc88cb50f8b6ecf204e4544fad4"},"cell_type":"code","source":"eli5.show_weights(estimator=tf_idf_logist_pipeline.named_steps['logist'], \n                  vec=tf_idf_logist_pipeline.named_steps['tf_idf'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ff5ec6638011573b186ae389c014bde8911dc39"},"cell_type":"code","source":"# using grid cv\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2a7dccc70e44349779cd6c5670903db809adc15"},"cell_type":"code","source":"model = Pipeline([('tfidf',TfidfVectorizer(min_df=2)),\n                    ('logit',LogisticRegression(solver='lbfgs', max_iter=3000))])\nparams = {'tfidf__ngram_range':[(1,1),(1,2)],'tfidf__use_idf':(True,False)}\ngrid = GridSearchCV(estimator=model, param_grid=params, verbose=1, n_jobs=-1, cv=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c984df3c8e85c6ef1aa8f096312349e1cf2be16f","scrolled":true},"cell_type":"code","source":"grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"aa079f85119033be1b1086881492a46f4a26015b"},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19ab2d5169b772652ef1a48c524a62ffff30ba3b"},"cell_type":"code","source":"better_model = Pipeline([('tfidf',TfidfVectorizer(min_df=2, ngram_range=(1,2), use_idf=True)),\n                    ('logit',LogisticRegression(solver='lbfgs', max_iter=3000))])\nbetter_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7aaef00d3ecf7becd423b4bde214e4eed99c61c"},"cell_type":"code","source":"better_pred = better_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97adf3ce8ef1da3b2146509c9aa90150d8a5c1a8"},"cell_type":"code","source":"accuracy_score(y_test, better_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9160557852c0e491bea1efa23337e0f6daa2a072"},"cell_type":"code","source":"print('Accuracy score is: {:.2%}'.format(accuracy_score(y_test, better_pred)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a95b5faf0c68dc1222a11d7d80bf584593652544"},"cell_type":"markdown","source":"> **slightly better accuracy**"},{"metadata":{"trusted":true,"_uuid":"5fbdd9d091899418d7dbde093803bcc50a54e65e"},"cell_type":"code","source":"confusion_matrix(y_test, better_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be5716e15f565daa11c7b5fdba8f0bbca16277a4"},"cell_type":"code","source":"# plot confusion matrix again\nplt.figure(figsize=(10, 6))\n\nconmat = pd.DataFrame(confusion_matrix(y_test, better_pred), index=['Not Sarcastic', 'Sarcastic'], \n                      columns=['Not Sarcastic', 'Sarcastic'])\n\nax = sns.heatmap(conmat, annot=True, cbar=False, cmap='viridis', linewidths=0.5, fmt='.0f')\nax.set_title('Confusion Matrix for Sarcasm Detection', fontsize=18, y=1.05)\nax.set_ylabel('Real', fontsize=12)\nax.set_xlabel('Predicted', fontsize=12)\nax.xaxis.set_ticks_position('bottom')\nax.yaxis.set_ticks_position('left')\nax.tick_params(labelsize=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afafb94ffb56c3af7de546832c5f732244a0dab5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}