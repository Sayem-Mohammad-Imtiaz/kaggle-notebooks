{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.decomposition import NMF;\nfrom sklearn.preprocessing import normalize;\nimport pickle\nimport re, string\n%matplotlib notebook","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:41.040538Z","iopub.execute_input":"2021-05-20T21:02:41.04103Z","iopub.status.idle":"2021-05-20T21:02:42.674299Z","shell.execute_reply.started":"2021-05-20T21:02:41.040913Z","shell.execute_reply":"2021-05-20T21:02:42.673411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-20T21:02:42.675522Z","iopub.execute_input":"2021-05-20T21:02:42.675796Z","iopub.status.idle":"2021-05-20T21:02:42.688993Z","shell.execute_reply.started":"2021-05-20T21:02:42.675769Z","shell.execute_reply":"2021-05-20T21:02:42.688017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/web-log-dataset/weblog.csv')\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:42.691022Z","iopub.execute_input":"2021-05-20T21:02:42.691498Z","iopub.status.idle":"2021-05-20T21:02:42.764585Z","shell.execute_reply.started":"2021-05-20T21:02:42.691451Z","shell.execute_reply":"2021-05-20T21:02:42.763716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    \n    PUNCTUATION = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"    \n\n    text = \" \".join([c for c in text if c not in PUNCTUATION])\n    \n    text = re.sub(r\"/\",\" \",text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:42.765997Z","iopub.execute_input":"2021-05-20T21:02:42.766434Z","iopub.status.idle":"2021-05-20T21:02:42.771422Z","shell.execute_reply.started":"2021-05-20T21:02:42.766403Z","shell.execute_reply":"2021-05-20T21:02:42.770523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\ndf['URL'] = df['URL'].apply(word_tokenize)\ndf['text'] = df['URL'].apply(clean_text)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:42.772691Z","iopub.execute_input":"2021-05-20T21:02:42.773094Z","iopub.status.idle":"2021-05-20T21:02:45.151893Z","shell.execute_reply.started":"2021-05-20T21:02:42.773053Z","shell.execute_reply":"2021-05-20T21:02:45.151181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = [''.join(text) for text in df['text']]","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:45.153156Z","iopub.execute_input":"2021-05-20T21:02:45.153439Z","iopub.status.idle":"2021-05-20T21:02:45.177118Z","shell.execute_reply.started":"2021-05-20T21:02:45.153411Z","shell.execute_reply":"2021-05-20T21:02:45.176053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer(analyzer='word', max_features=1000)\nx_counts = vectorizer.fit_transform(sentences)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:45.178299Z","iopub.execute_input":"2021-05-20T21:02:45.178602Z","iopub.status.idle":"2021-05-20T21:02:45.351329Z","shell.execute_reply.started":"2021-05-20T21:02:45.17857Z","shell.execute_reply":"2021-05-20T21:02:45.350351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_counts","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:45.355468Z","iopub.execute_input":"2021-05-20T21:02:45.355782Z","iopub.status.idle":"2021-05-20T21:02:45.361374Z","shell.execute_reply.started":"2021-05-20T21:02:45.355752Z","shell.execute_reply":"2021-05-20T21:02:45.360386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = TfidfTransformer(smooth_idf=False);\nx_tfidf = transformer.fit_transform(x_counts);","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:45.362802Z","iopub.execute_input":"2021-05-20T21:02:45.363089Z","iopub.status.idle":"2021-05-20T21:02:45.384095Z","shell.execute_reply.started":"2021-05-20T21:02:45.363046Z","shell.execute_reply":"2021-05-20T21:02:45.383093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtfidf_norm = normalize(x_tfidf, norm='l1', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:45.385546Z","iopub.execute_input":"2021-05-20T21:02:45.385977Z","iopub.status.idle":"2021-05-20T21:02:45.392604Z","shell.execute_reply.started":"2021-05-20T21:02:45.385931Z","shell.execute_reply":"2021-05-20T21:02:45.391493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#number of topics\nnum_topics=5\n#obtain a NMF model.\nmodel = NMF(n_components=num_topics, init='nndsvd');\n#fit the model\nmodel.fit(xtfidf_norm)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:45.394282Z","iopub.execute_input":"2021-05-20T21:02:45.394682Z","iopub.status.idle":"2021-05-20T21:02:46.174402Z","shell.execute_reply.started":"2021-05-20T21:02:45.394639Z","shell.execute_reply":"2021-05-20T21:02:46.173334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nmf_topics(model, n_top_words):\n    \n    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n    feat_names = vectorizer.get_feature_names()\n    \n    word_dict = {};\n    for i in range(num_topics):\n        \n        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n        words_ids = model.components_[i].argsort()[:-n_top_words - 1:-1]\n        words = [feat_names[key] for key in words_ids]\n        word_dict['Tarea # ' + '{:02d}'.format(i+1)] = words;\n    \n    return pd.DataFrame(word_dict)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:46.176116Z","iopub.execute_input":"2021-05-20T21:02:46.176518Z","iopub.status.idle":"2021-05-20T21:02:46.185585Z","shell.execute_reply.started":"2021-05-20T21:02:46.176474Z","shell.execute_reply":"2021-05-20T21:02:46.184161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_nmf_topics(model, 10)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:02:46.187378Z","iopub.execute_input":"2021-05-20T21:02:46.187895Z","iopub.status.idle":"2021-05-20T21:02:46.220131Z","shell.execute_reply.started":"2021-05-20T21:02:46.187853Z","shell.execute_reply":"2021-05-20T21:02:46.218578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}