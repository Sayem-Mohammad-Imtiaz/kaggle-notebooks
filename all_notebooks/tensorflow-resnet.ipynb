{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TensorFlow ResNet50 - Transfer Learning\n### Experiment with - \n* #### Transfer Learning\n* #### TF.Data\n* #### TF.GradientTape - Custom training loop","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport skimage.io as sk\nimport pathlib\nimport matplotlib.pyplot as plt\n\nimport os\nimport time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Data\nusing dataset - https://www.kaggle.com/olgabelitskaya/flower-color-images\n> The content is very simple: 210 images (128x128x3) with 10 species of flowering plants and the file with labels flower-labels.csv. Photo files are in the .png format and the labels are the integers.\n>\n> Label => Name\n0 => phlox; 1 => rose; 2 => calendula; 3 => iris; 4 => leucanthemum maximum;\n5 => bellflower; 6 => viola; 7 => rudbeckia laciniata (Goldquelle); 8 => peony; 9 => aquilegia.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_FOLDER=pathlib.Path(\"/kaggle/input/flower-color-images/flower_images/flower_images\")\ndata_set = pd.read_csv(\"/kaggle/input/flower-color-images/flower_images/flower_images/flower_labels.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Hyperparameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 30\nBS = 15\nINIT_LR = 1e-3\nTOT_IMG = data_set.count()[0]\nTOT_BATCH = int(TOT_IMG/BS)\nCLASSES = {0:'phlox',1:'rose',2:'calendula',3:'iris',4:'leucanthemum maximum', 5:'bellflower',6:'viola',7:'rudbeckia laciniata (Goldquelle)',\n          8:'peony',9:'aquilegia'}\nCLASS_ARR = [0,1,2,3,4,5,6,7,8,9]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(sk.imread('/kaggle/input/flower-color-images/flower_images/flower_images/0172.png').shape)\nsk.imshow('/kaggle/input/flower-color-images/flower_images/flower_images/0172.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preprocessing\nFirst defining below helper functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#decoding Image using TF helper functions.\ndef decode_img(img):\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_png(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img,[224,224])\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Label from the image and dataset\ndef get_label(img_name):\n    lab = (data_set.loc[data_set['file']==img_name]['label']).to_string(index=False)\n    ilab= np.array([lab]).astype(np.int32)\n    ret =np.equal(ilab,CLASS_ARR)\n    return ret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.tensorflow.org/tutorials/load_data/images\n# \ndef process_image(image_path):\n    parts = tf.strings.split(image_path, os.path.sep)    \n    image_name = parts[-1]\n    label = tf.py_function(func=get_label,inp=[image_name], Tout=tf.bool)\n    img = tf.io.read_file(image_path)\n    img = decode_img(img)\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image Pre-Processing with tf.Dataset\nUsing process_image() function defined above","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using tf.Data to process dataset for this experiment.\nlist_ds= tf.data.Dataset.list_files(str(DATA_FOLDER/'*.png'))\nlabeled_ds = list_ds.map(process_image,num_parallel_calls=tf.data.experimental.AUTOTUNE)\nds = labeled_ds.shuffle(buffer_size=TOT_IMG)\nds = ds.batch(BS)\nds = ds.repeat()\n#image_batch, label_batch = next(iter(ds))\n\n#for img,label in labeled_ds.take(1):\n#    tf.print(\"IMAGE:\", img.numpy().shape)\n#    tf.print(\"LABEL:\",label.numpy())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image_batch(image_batch, image_label):\n    plt.figure(figsize=(10,10))\n    for n in range(BS):\n        ax = plt.subplot(3,5,n+1)\n        plt.imshow(image_batch[n])\n        #print(CLASSES[(np.where(image_label[n])[0][0])])\n        plt.title(CLASSES[(np.where(image_label[n])[0][0])])\n        plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, label_batch = next(iter(ds))\nshow_image_batch(image_batch.numpy(), label_batch.numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ResNet Implementation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Input, AveragePooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\nrsntBase = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n#rsntBase.summary()\n\n# define a custom model based on ResNet50\nmodel = rsntBase.output\nmodel = AveragePooling2D(pool_size=(7,7))(model)\nmodel = Flatten(name=\"flatten\")(model)\nmodel = Dense(1024,activation='relu')(model)\nmodel = Dropout(0.5)(model)\nmodel = Dense(1024,activation='relu')(model)\nmodel = Dropout(0.5)(model)\nmodel = Dense(len(CLASS_ARR), activation='softmax')(model)\n\nclfModel = Model(inputs=rsntBase.input, outputs=model)\n\n# freezing all layers except for last Conv block (Conv5)\nfor _ in rsntBase.layers:\n    if not _.name.startswith('conv5_'):\n        _.trainable=False\n    \nclfModel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define Optimizer\noptimizer = tf.keras.optimizers.Adam(lr=INIT_LR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define training Loss\nfrom tensorflow.keras.losses import categorical_crossentropy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Implementing TensorFlow Gradient Tape for custom training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef step_function(X,y):\n    with tf.GradientTape() as tape:\n        pred = clfModel(X)\n        loss = categorical_crossentropy(y, pred,from_logits=True)\n        \n    grads = tape.gradient(loss, clfModel.trainable_variables)\n    optimizer.apply_gradients(zip(grads,clfModel.trainable_variables))\n    return loss    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training using step_function() - Gradient Tape","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_loss = []\ntrain_accuracy = []\ndef train(datasetx, epochs):\n    for epoch in range(0, epochs):\n        start = time.time()\n        epoch_avg_loss = tf.keras.metrics.Mean()\n        epoch_accuracy = tf.keras.metrics.CategoricalCrossentropy()\n        tds = iter(datasetx)\n        for i in range(TOT_BATCH):\n            image_batch, label_batch = next(tds)\n            loss = step_function(image_batch,label_batch)\n            epoch_avg_loss.update_state(loss)\n            epoch_accuracy.update_state(label_batch,clfModel(image_batch, training=True))\n        all_loss.append(epoch_avg_loss.result().numpy())\n        train_accuracy.append(epoch_accuracy.result().numpy())\n        if epoch % 2 == 0:\n            print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start), epoch_avg_loss.result().numpy(),epoch_accuracy.result().numpy())            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(ds, EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy Plot - \n**Issue is that the resnet is Only able to predict one class - **\nHence the Accuracy is only ~14%\n\n# Question - How to solve this ResNet50 training problem??","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\nfig.suptitle('Training Metrics')\n\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].plot(all_loss)\n\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(train_accuracy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img,label in ds.take(1):\n    plt.figure(figsize=(20,20))\n    pred_logits = clfModel(img.numpy(), training=False)\n    pred = tf.argmax(pred_logits, axis=1, output_type=tf.int32).numpy()\n    print(pred)\n    for n in range(BS):\n        ax = plt.subplot(3,5,n+1)\n        plt.imshow(img[n].numpy())\n        plt.title(\"Actual: {}\\nPredicted: {}\".format(CLASSES[(np.where(label[n])[0][0])],CLASSES[pred[n]]))\n        plt.axis('off')\n        \n    #tf.print(\"IMAGE:\", img.numpy().shape)\n    #tf.print(\"LABEL:\",label.numpy())\n    #clfModel(img.numpy(), training=False)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}