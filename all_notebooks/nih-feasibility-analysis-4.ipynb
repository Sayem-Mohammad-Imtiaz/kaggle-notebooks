{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import required packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re # for pattern matching, like grep in r\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read data\n## Data Entry\n\nFirst is data entry with patient IDs, findings and demographics information. \nThen create a subset with interested columns only."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_entry = pd.read_csv('../input/nihdata/Data_Entry_2017.csv')\ndata_entry.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_entry_subset = data_entry.loc[:, 'Image Index':'Finding Labels']\ndata_entry_subset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Remark:** From `Finding Labels`, we can tell this is a multi-labelled classification instead of binary. Spliting the column and getting the unique values are required."},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"split = pd.DataFrame(data_entry_subset['Finding Labels'].str.split('|').tolist())\n\ntemp = []\nfor i in split:\n    temp.append(split[i].unique())\n\nflatten = pd.DataFrame(temp).values.flatten()\n\nunique = []\nfor x in flatten:\n    if x not in unique:\n        unique.append(x)\n\nlabels = list(filter(None, unique))\nlabels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 15 disease condition including *No Finding*. Note that *Cardiomegaly* etc are not our sole interested point of prediction. *Finding Labels* will be manipulated that split all the different disease tags."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_entry_subset[\"Finding Labels\"] = data_entry_subset[\"Finding Labels\"].apply(lambda x:x.split(\"|\"))\ndata_entry_subset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have a look at the class distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nlabels_count = Counter(label for lbs in data_entry_subset[\"Finding Labels\"] for label in lbs)\n\nlabels_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the frequency table, we found out that there are two types of imbalances:\n1. Imbalance across different classes\n2. Imbalance between positive and negative in some classes\n\nWe will have to derive a `class_weights` to adjust the imbalance distribution later which will be used to fit into the `fit` function."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_count = sum(labels_count.values())\nclass_weights = {cls: total_count / count for cls, count in labels_count.items()}\n\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Images\n\n`f, l` are dummy variables representing two columns of *data_entry_subset*."},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l in data_entry_subset[:9].values:\n    img = cv2.imread('../input/nihdata/images_001/images/{}'.format(f))\n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n    i += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data frame pre-processing\nThis session is to process the images (unstructed data) to machine learnable format (to let the computer understands the images in its way).\n\nWe would also split the entire dataset into training set and validation set for model developement and model validation respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,  \n    zoom_range=0.2,        \n    horizontal_flip=True,\n    validation_split=0.2) \n\ndef get_flow_from_dataframe(generator, \n                            dataframe, \n                            subset,\n                            image_shape=(150, 150),\n                            batch_size=32):\n    \n    train_generator_1 = generator.flow_from_dataframe(dataframe, target_size=image_shape,\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '../input/nihdata/images_001/images',\n                                                      batch_size=batch_size,\n                                                      classes = labels,\n                                                      subset=subset)\n\n    train_generator_2 = generator.flow_from_dataframe(dataframe, target_size=image_shape,\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '../input/nihdata/images_002/images',\n                                                      batch_size=batch_size,\n                                                      classes = labels,\n                                                      subset=subset)\n    \n    train_generator_3 = generator.flow_from_dataframe(dataframe, target_size=image_shape,\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '../input/nihdata/images_003/images',\n                                                      batch_size=batch_size,\n                                                      classes = labels,\n                                                      subset=subset)\n    \n    while True:\n        x_1 = train_generator_1.next()\n        x_2 = train_generator_2.next()\n        x_3 = train_generator_3.next()\n        \n        yield np.concatenate((x_1[0], x_2[0], x_3[0]), axis = 0), np.concatenate((x_1[1], x_2[1], x_3[1]), axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = get_flow_from_dataframe(generator=datagen, \n                                    dataframe=data_entry_subset, \n                                    subset = 'training',\n                                    image_shape=(150, 150),\n                                    batch_size=32)\n\nval_gen = get_flow_from_dataframe(generator=datagen, \n                                    dataframe=data_entry_subset, \n                                    subset = 'validation',\n                                    image_shape=(150, 150),\n                                    batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define `class_weights_index` based on `class_weights` derived. "},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = datagen.flow_from_dataframe(data_entry_subset, target_size=(150,150),\n                                                      x_col='Image Index',\n                                                      y_col='Finding Labels',\n                                                      class_mode='categorical',\n                                                      directory = '../input/nihdata/images_001/images',\n                                                      batch_size=32,\n                                                      classes = labels)\n\ngenerator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights_index = {\n 1: 50.985951008645536,\n 5: 56.25476947535771,\n 4: 10.628294660959675,\n 10: 2.3448418680936367,\n 7: 623.5110132158591,\n 8: 7.114557152910425,\n 9: 24.478900034590108,\n 11: 22.356183857210553,\n 0: 12.244744355048015,\n 14: 26.695020746887966,\n 12: 41.81299852289513,\n 13: 98.9077568134172,\n 6: 83.94839857651246,\n 3: 61.45766391663048,\n 2: 30.327190914934647\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Development\nThis session is to build a deep learning model that can perform classification in later application."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), padding = 'same',\n                        activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(15, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Alternative: Transfer learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = 150\ncols = 150\n\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom keras import optimizers, losses, activations, models\nfrom keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\nfrom keras import applications\ninput_shape = (rows, cols, 3)\n\nweights_path = '../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = applications.VGG19(weights= weights_path, \n                                include_top=False, \n                                input_shape=(rows, cols, 3))\nbase_model.trainable = False\n\nadd_model = Sequential()\nadd_model.add(base_model)\nadd_model.add(GlobalAveragePooling2D())\nadd_model.add(Dropout(0.5))\nadd_model.add(Dense(15, \n                    activation='sigmoid'))\nmodel_vgg15 = add_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Optimization\nThis is to instruct the model to improve its performance (accuracy) by learning from its own mistake."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"step_per_train = 20000//32\nstep_per_val = 4999//32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    train_gen, \n    steps_per_epoch  = step_per_train, \n    validation_data  = val_gen,\n    validation_steps = step_per_val,\n    class_weight = class_weights_index,\n    use_multiprocessing = True,\n    epochs = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\nfig = plt.figure(figsize=(16,9))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('multi_label.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Demo\nUsers can change index no of `data_entry_subset.iloc[[]]` to predict different image, same goes to second cell below. Future work need to be done to automate this manual key in process."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nfrom keras.preprocessing import image\n\nmodel = load_model('multi_label.h5')\n\ngenerator.reset()\n\npred = model.predict_generator(generator, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\npred_threshold = (pred > 0.15)\nclass_indices = generator.class_indices\nclass_indices = dict((v, k) for k, v in class_indices.items())\n\nfor i in pred_threshold:\n    outcome = []\n    for index, cls in enumerate(i):\n        if cls:\n            outcome.append(class_indices[index])\n    predictions.append(\",\".join(outcome))\n\npatient_id = generator.filenames\nresults = pd.DataFrame({\"Filename\": patient_id,\n                       \"Classifications\": predictions})\n\nresults.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n\nfor f, l in data_entry_subset.iloc[[0]].values:\n    img = cv2.imread('../input/nihdata/images_001/images/{}'.format(f))\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.title(('{} - {}'.format(f, l)))\n    \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}