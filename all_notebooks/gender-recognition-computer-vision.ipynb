{"cells":[{"metadata":{},"cell_type":"markdown","source":"## OVERVIEW\n---\n* Feature Selection & Data Sampling\n* Image Processing\n* Data Augmentation\n* Transfer Learning with Keras Xception\n* Bottleneck Feature Ectraction\n* Deep Learning","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime as dt\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style('darkgrid')\n\n\nimport os\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nimport cv2\nfrom scipy.stats import uniform\n\nfrom tqdm import tqdm\nfrom IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n\nimport keras\nfrom keras.models import Model, Sequential\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Masking,GlobalAveragePooling1D\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\n\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DATA UTILITIES","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#copying the pretrained models to the cache directory\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n\n#copy the Xception models\n!cp ../input/keras-pretrained-models/xception* ~/.keras/models/\n#show\n!ls ~/.keras/models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_folder = '../input/celeba-dataset'\ndata_folder = '../input/celeba-dataset/img_align_celeba'\nimage_folder = '../input/celeba-dataset/img_align_celeba/img_align_celeba'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read the image attributes csv file\ndf = pd.read_csv('../input/celeba-dataset/list_attr_celeba.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.columns)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FEATURE SELECTION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df = df[['image_id', 'Male']]\n#replace -1 to 0\ndf.replace(to_replace=-1, value=0, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add a class feature\ndef to_labels(x):\n    if x == 0:\n        return 'female'\n    else:\n        return 'male'\n\ndf['class'] = df.Male.apply(to_labels)\ndf.columns = ['filename', 'label', 'class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show new dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### COUNTPLOT PER GENDER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.countplot(df.label);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DATA SAMPLING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SAMPLES = 300\ntrain_data = pd.concat([df[df['label']== i][:SAMPLES] for i in range(0,2)])\nprint('TRAIN DATA SHAPE: ', train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SHOW SAMPLE IMAGES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to get an image\ndef read_img(filename, size):\n    img = image.load_img(os.path.join(image_folder, filename), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img) / 255\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_rows = 3\nnb_cols = 5\nfig, axs = plt.subplots(nb_rows, nb_cols, figsize=(10, 5));\nplt.suptitle('SAMPLE IMAGES');\nfor i in range(0, nb_rows):\n    for j in range(0, nb_cols):\n        axs[i, j].xaxis.set_ticklabels([]);\n        axs[i, j].yaxis.set_ticklabels([]);\n        axs[i, j].imshow((read_img(train_data['filename'].iloc[np.random.randint(500)], (255,255))));\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DATA AUGMENTATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a imagegenerator for for augmentation\ndatagen =  ImageDataGenerator(\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = read_img(train_data['filename'].iloc[546], (255,255))\nplt.title('ORIG IMAGE')\nplt.imshow(img);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### SHOW SAMPLE AUGMENTED IMAGE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape image to 4 dimentional\nimg = img.reshape((1,) + img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.suptitle('Data Augmentation', fontsize=28)\n\n\ni = 0\n\nfor batch in datagen.flow(img, batch_size=32):\n    plt.subplot(3, 5, i+1)\n    plt.grid(False)\n    plt.imshow(batch.reshape(255, 255, 3));\n    \n    if i == 9:\n        break\n    i += 1\n    \nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the data\nX = train_data.drop(['label', 'class'], axis=1)\ny = train_data['label']\n\ntrain_x, train_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### IMAGE PROCESSING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to get an image\ndef read_img(filename, size):\n    img = image.load_img(os.path.join(image_folder, filename), target_size=size)\n    #convert image to array\n    img = image.img_to_array(img) / 255\n    img = img.reshape((1,) + img.shape)\n    return img\n\n\narray_img = []\nlabel_img = []\n\nfor i, file in tqdm(enumerate(train_x['filename'])):\n    img = read_img(file, (255,255))\n    label = y_train.iloc[i]\n    num = 0\n    for batch in datagen.flow(img, batch_size=32):\n        batch = batch.reshape(255,255,3)\n        array_img.append(batch)\n        label_img.append(label)\n        if num == 4:\n            break\n        num=num+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XCEPTION INPUT PREPROCESSING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocess train\nINPUT_SIZE = 255\n\n\nX_train = np.zeros((len(array_img), INPUT_SIZE, INPUT_SIZE, 3), dtype='float')\ni=0\nfor file in tqdm(array_img):\n    X_train[i] = xception.preprocess_input(np.expand_dims(file.copy(), axis=0))\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocess validation\n\nX_val = np.zeros((len(train_val), INPUT_SIZE, INPUT_SIZE, 3), dtype='float')\nfor i, file in tqdm(enumerate(train_val['filename'])):\n    img = read_img(file, (255,255))\n    X_val[i] = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### BOTTLENECK FEATURE EXTRACTION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xception_bf = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\nbf_train_x = xception_bf.predict(X_train, batch_size=32, verbose=1)\nbf_train_val = xception_bf.predict(X_val, batch_size=32, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print shape of feature and size\nprint('Train Shape: ', bf_train_x.shape)\nprint('Train Size: ', bf_train_x.size)\n\nprint('Validation Shape: ', bf_train_val.shape)\nprint('Validation Size: ', bf_train_val.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MODELLING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#keras model\nmodel = Sequential()\nmodel.add(Dense(units = 512 , activation = 'relu', input_dim=bf_train_x.shape[1]))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 64 , activation = 'relu'))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\nmodel.compile(optimizer ='adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#set callbacks\ncallbacks = [EarlyStopping(monitor='val_loss', patience=2),\n         ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n\n#fit the data\nhistory = model.fit(bf_train_x, np.array(label_img), batch_size=32, epochs=100, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LOSS AND ACCURACY","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(14,5))\nax[0].set_title('TRAINING LOSS');\nax[1].set_title('TRAINING ACCURACY');\n\n\nax[0].plot(history.history['loss'], color= 'salmon',lw=2);\nax[1].plot(history.history['accuracy'], color= 'steelblue',lw=2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the validation data\npredictions = model.predict_classes(bf_train_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CLASSIFICATION REPORT","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_val, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CONFUSION MATRIX","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"con_mat = confusion_matrix(y_val, predictions)\nplt.figure(figsize=(5,5))\n\nsns.heatmap(con_mat, annot=True, square=True);\nplt.xlabel('Y_TRUE');\nplt.ylabel('PREDICTIONS');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}