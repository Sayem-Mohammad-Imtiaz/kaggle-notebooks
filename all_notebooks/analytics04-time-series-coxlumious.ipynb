{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Time Series and Forecasting\nThis section will walk through simple time series analysis and forecasting. It uses Pandas, NumPy, and a forecasting library developed by Facebook called Prophet.\n\n* Forecasting is about predicting the future based on data from the past (time-series)\n  - Traditional forecasting methods use classifical statistical methods: linear regression analysis, logistic regression analysis, clustering, factor analysis, and time-series.\n\n* Forecasting is important in many contexts\n  - Organizational operations: allows for efficient allocation of scarce resources and for setting goals based on evidence\n  - Policy: understanding macro trends in environment and climate\n\n* Difficulties in forecasting:\n  - Comletely automatic forecasting techniques are brittle and inflexible\n  - Analysts who can produce high quality forecasts are rare because forecasting is a specialized skill, as much art as science\n\n* Libraries such as Prophet help with many of the \"artsy\" components of forecasting\n  - Helping to determine how much data to incorporate. Prophet works best with hourly, daily, or weekly observations with at least a few months (preferably more than year) of history\n  - It includes multuiple \"human-scale\" seasonalities such as day of week and time of year to help with variations in trends across weekends and other complexities.\n  - It can help track holidays that occur at irregular intervals that are known in advance (such as the Super Bowl)\n  - It provides ways to gauge historical trend changes, such as due to a product change or a modification in operational data collection (such as how logs are accumulated)\n\n* Sophisticated time series forecasting combines multiple types of analysis\n\n#### Methods for Producing Forecasts (via Prophet)\nWhile there are many methods to create forecasts, we will focus on the mechanism used by Prophet: [additive regression models](https://en.wikipedia.org/wiki/Additive_model). \n\n* _An additive model is a class of nonparametric regression._\n  - _In non-parametric regression, predictors are constructed according to information derived from the data._\n  - _Nonparametric regression require larger sample sizes than traditional regression methods as the data must supply the model structure as well as model estimates._\n\n* Prophet forecasta are composed of:\n  - Piecewise linear or logistic growth curve trend. Prophet automatically determines this by selecting changepoints from the data.\n  - Yearly season component modeled using Fourier series.\n  - Weekly seasonal component which uses dummy encoding of variables. _Dummy encoded variables are true/false (binary) encodings of categorical information. It usually specifies whether an observation is a member of a specific category: for example, whether a patient has a given disease; or if a patient was exposed to a particular type of drug. This type of encoding can be given to a classifier such as a regressor without implying directionality._\n  - Prophet can also take into account holidays\n\n\n### Import Dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Python Dependencies\nfrom fbprophet import Prophet     # Prophet is a forecasting library developed by Facebook\nimport numpy as np\nimport pandas as pd\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resample and Prepare Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# Resampling data from minute interval to day\nbit_df = pd.read_csv('../input/coinbase/coinbaseUSD_1-min_data_2014-12-01_to_2018-01-08.csv',\n  low_memory=False, error_bad_lines=False)\nbit_df['Timestamp'] = bit_df.Timestamp.astype('int', errors='ignore')\n\n\n# Convert unix time to datetime\nbit_df['date'] = pd.to_datetime(bit_df.Timestamp, unit='s', errors='coerce')\n\n# Reset index\nbit_df = bit_df.set_index('date')\n\n# Ensure that all data has been coerced\nbit_df['Open'] = pd.to_numeric(bit_df['Open'], errors='coerce')\nbit_df['Close'] = pd.to_numeric(bit_df['Close'], errors='coerce')\nbit_df['High'] = pd.to_numeric(bit_df['High'], errors='coerce')\nbit_df['Low'] = pd.to_numeric(bit_df['Low'], errors='coerce')\n\n# Rename columns so easier to code\nbit_df = bit_df.rename(columns={'Open':'open', 'High': 'hi', 'Low': 'lo',\n  'Close': 'close', 'Volume_(BTC)': 'vol_btc',\n  'Volume_(Currency)': 'vol_cur',\n  'Weighted_Price': 'wp', 'Timestamp': 'ts'})\n\n# Resample and only use recent samples that aren't missing\nbit_df = bit_df.resample('d').agg({'open': 'mean', 'hi': 'mean',\n  'lo': 'mean', 'close': 'mean', 'vol_btc': 'sum',\n  'vol_cur': 'sum', 'wp': 'mean', 'ts': 'min'}).iloc[-1000:]\n\n# drop last row as it is not complete\nbit_df = bit_df.iloc[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# needs ds and y columns\nts = (bit_df\n    .reset_index()\n    .rename(columns={'date': 'ds', 'close': 'y'})\n[['ds', 'y']]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"View date types:"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set index of the datset to be the date `ds` (in order to visualize the relationship):"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ts.set_index('ds').plot(figsize=(14,10))\nts.set_index('ds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = Prophet(daily_seasonality=True)\nm.fit(ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use prophet to create forecasts from the historical data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a future object and predict into it\nfuture = m.make_future_dataframe(periods=24)\nforecast = m.predict(future)\nforecast","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"invert the dataframe to look at the structure of the forecast:"},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the prediction, including the uncertainty lines:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the prediction, include the uncertainty lines\nax = m.plot(forecast, uncertainty=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inspect the component trends:\n\n* how data trends summarized over an adjusted period"},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the trend, yearly, weekly and daily componentsb\nax = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exercise: Snow Data\nThis exercise looks at forecasting using snow data.\n\n* Use prophet to predict 100 days in the future of Snow Depth (SNWD)\n* What month has the most snow\n\n\n#### Try Using Log of Data\nPredictions may work better if we tweak the data. In this case let's try taking the log of the bitcoin price. _Most predictive and analytic techniques work best when they can find a meaningful separation. For some types of data, this can be difficult because of how spread out or compact it is. Applying a transform, such as taking the `log` gives the model a better chance of finding a meaningful pattern._"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts2 = ts.assign(y=lambda x: np.log(x.y))\n# ts2.set_index('ds').plot()\nts2.set_index('ds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m2 = Prophet() #dont need daily_seasonality=True)\nm2.fit(ts2)\nfuture2 = m2.make_future_dataframe(periods=24)\nforecast2 = m2.predict(future2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the prediction, include the uncertainty lines\nax = m2.plot(forecast2, uncertainty=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = m2.plot_components(forecast2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exercise: Log of Time Series\nThis exercise looks at forecasting using snow data.\n\n* Run the snow calculation using the log of the snow depth. Does it track better? _Hint: might need to add 1 before logging_"}],"metadata":{},"nbformat":4,"nbformat_minor":4}