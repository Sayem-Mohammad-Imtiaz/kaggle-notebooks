{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is Intent Classification\n\nIntents are general traits that map the user’s message to the corresponding bot action (prediction workflow). For example, the phrase “What is the weather today?” will map to ‘weather_inquiry’ intent by its entire wording, and not some particular part.\n\nA restaurant_search can be expressed in many different ways:-\n\nI'm hungry. Show me good pizza spots. I want to take my boyfriend out for sushi\n\nThis can also be request_booking\n\n\n","attachments":{}},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data from ATIS Dataset\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import spacy\nimport csv\n\ndef read_data(path):\n    with open(path, 'r') as csvfile:\n        readCSV = csv.reader(csvfile, delimiter=',')\n        labels = []\n        sentences = []\n        for row in readCSV:\n            label = row[0]\n            sentence = row[1]\n            labels.append(label)\n            sentences.append(sentence)\n    return sentences, labels\n\n# Loading Test Data\n\nsentences_test,labels_test = read_data('../input/atis-airlinetravelinformationsystem/atis_intents_test.csv')\nprint(sentences_test[:3],'\\n')\nprint(labels_test[:3])\n\n# Loading Training Data\n\nsentences_train,labels_train = read_data('../input/atis-airlinetravelinformationsystem/atis_intents_train.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spacy Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m spacy download en_vectors_web_lg\n!python -m spacy link en_vectors_web_lg en_vectors_web_lg\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading spaCy model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport spacy\nimport numpy as np\n\n# Load the spacy model: nlp\nnlp = spacy.load('en_vectors_web_lg')\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the dimensionality of nlp\nembedding_dim = nlp.vocab.vectors_length\n\nprint(embedding_dim)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding Sentences Using spaCy NLP Model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef encode_sentences(sentences):\n    # Calculate number of sentences\n    n_sentences = len(sentences)\n\n    print('Length :-',n_sentences)\n\n    X = np.zeros((n_sentences, embedding_dim))\n    #y = np.zeros((n_sentences, embedding_dim))\n\n    # Iterate over the sentences\n    for idx, sentence in enumerate(sentences):\n        # Pass each sentence to the nlp object to create a document\n        doc = nlp(sentence)\n        # Save the document's .vector attribute to the corresponding row in     \n        # X\n        X[idx, :] = doc.vector\n    return X\n\ntrain_X = encode_sentences(sentences_train)\ntest_X = encode_sentences(sentences_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_encoding(labels):\n    # Calculate the length of labels\n\n    n_labels = len(labels)\n    print('Number of labels :-',n_labels)\n\n\n    # import labelencoder\n    from sklearn.preprocessing import LabelEncoder\n    # instantiate labelencoder object\n    le = LabelEncoder()\n    y =le.fit_transform(labels)\n    print(y[:100])\n    print('Length of y :- ',y.shape)\n    return y\n\ntrain_y = label_encoding(labels_train)\ntest_y = label_encoding(labels_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/atis-airlinetravelinformationsystem/atis_intents_train.csv', delimiter=',')\ndf1.dataframeName = 'atis_intents_train.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# matplotlib histogram\nplt.hist(train_y)\n\n# Add labels\nplt.title('Histogram of Intent Lables')\nplt.xlabel('Intent Types')\nplt.ylabel('Frequency')\n#df1['atis_flight'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Intent classification with SVM | Training Step"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import SVC\nfrom sklearn.svm import SVC\n# X_train and y_train was given.\ndef svc_training(X,y):\n    # Create a support vector classifier\n    clf = SVC(C=1)\n\n    # Fit the classifier using the training data\n    clf.fit(X, y)\n    return clf\n\nmodel = svc_training(train_X,train_y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validation Step\n\ndef svc_validation(model,X,y):\n    # Predict the labels of the test set\n    y_pred = model.predict(X)\n\n    # Count the number of correct predictions\n    n_correct = 0\n    for i in range(len(y)):\n        if y_pred[i] == y[i]:\n            n_correct += 1\n\n    print(\"Predicted {0} correctly out of {1} training examples\".format(n_correct, len(y)))\n\n\nsvc_validation(model,train_X,train_y)\nsvc_validation(model,test_X,test_y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_true, y_pred = test_y, model.predict(test_X)\nprint(classification_report(y_true, y_pred))\n   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nThis is an imbalanced dataset with some of the classes having small number of samples. The resulting poor classification accuracy can be seen in the results."},{"metadata":{},"cell_type":"markdown","source":"## Note\nPlease share, upvote and comment to help me create and share more content for the community.\nThank you all."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}