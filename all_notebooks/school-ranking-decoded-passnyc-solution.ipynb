{"cells":[{"metadata":{"_uuid":"94725a28bdc925660d2eb50111dd1b746a1d610b"},"cell_type":"markdown","source":"### **Objective:** \"Which schools have students that would benefit from outreach services and lead to a more diverse group of students taking the SHSAT and being accepted into New York City's Specialized High Schools.\""},{"metadata":{"_uuid":"4ee33850a941c5a9bd16a58988435aba8ecd1400"},"cell_type":"markdown","source":">**Background :** The Specialized High Schools Admissions Test (SHSAT) is an examination administered to eighth and ninth grade students residing in New York City and used to determine admission to all but one of the city's nine Specialized High Schools. In 2008, about 29,000 students took the test, and 6,108 students were offered admission to one of the high schools based on the results. On average, 30,000 students take this exam annually. The test is given each year in October and November, and students are informed of their results the following March. Those who receive offers decide by the middle of March whether to attend the school the following September. The test is independently produced and graded by American Guidance Service, a subsidiary of Pearson Education, under contract to the New York City Department of Education."},{"metadata":{"_uuid":"d8dee9ec6d5828a8adf36f7aeb9998c320b4c735"},"cell_type":"markdown","source":"* **If we can rank order schools and be granular about it or show schools on a map and take into account diversity, language, poverty, weather, public transit, whatever, then that's probably a good way to go about it.**"},{"metadata":{"_uuid":"c92449ee62f2a87cde65bb552ee133974982292e"},"cell_type":"markdown","source":">* **Our efforts should be directed at :**  \n>1) Increase in SHSAT registration (Year 2013-2016)  \n>2) Increase in SHSAT participation (Year 2013-2016)    \n>3) Participation to registration ratio (Year 2016)   \n>4) Participation to enrollment ratio (Year 2016)   "},{"metadata":{"_uuid":"18185d732242036186e91d461c85c0df911b0b7d"},"cell_type":"markdown","source":">**Datasets used :**     \n(1) 2016 School Explorer.csv      \n(2) D5 SHSAT Registrations and Testers.csv     \n(3) ged-plus-locations.csv     \n(4) 2010-2016-school-safety-report.csv     "},{"metadata":{"_uuid":"5f1f24ff8490637d18d452a83dd55a7fd91431db"},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"_uuid":"1f960a5a4a31f76e9114e8d9afbbd5181a121503"},"cell_type":"markdown","source":"In my previous kernel on PASSNYC, I performed an in-depth exploration in order to understand the dataset which included geography analysis, time series trends, distributions of important variables of the dataset, analysis, and comparisons.\n"},{"metadata":{"trusted":true,"_uuid":"4005a05c88c7002a2c491b0b1d73a1efc5055a4a","collapsed":true},"cell_type":"code","source":"from IPython.core.display import display, HTML\ndisplay(\"https://www.kaggle.com/rishih/present-sir\")\n#Link: [https://www.kaggle.com/rishih/present-sir](https://www.kaggle.com/rishih/present-sir)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d31b068b4b133b961ac0d6f9413c46827421c579"},"cell_type":"markdown","source":"## [Table of Content :](#as)    \n\n### [1. Preprocessing](#asd)   \n### [2. Hierarchial Clustering](#asd)   \n### [3. PFA : Principal Feature Analysis](#asd)   \n### [4. Regression : Gradient Boosting & Random Forest](#asd)   \n### [5. Obtaining most important features](#asdf)   \n### [6. Obtaining feature weights using SHST dataset](#asdf)   \n### [7. School ranking](#df)  \n"},{"metadata":{"_uuid":"183131aa0d209b176beff2b7908a3b7f26b74134"},"cell_type":"markdown","source":"## 0. Pre-processing"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"fbfe43fb31cb2f38b94007ac6e5ed1528d5a0be7"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"6a050d5c14ccc5407940da31d14c58d26c7f1f96"},"cell_type":"code","source":"import pandas as pd\nged=pd.read_csv('../input/ny-ged-plus-locations/ged-plus-locations.csv')\nschools=pd.read_csv('../input/data-science-for-good/2016 School Explorer.csv')\nsecure=pd.read_csv('../input/ny-2010-2016-school-safety-report/2010-2016-school-safety-report.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"acb8b1c60b82cae89f8288f72a717af98f9da82a"},"cell_type":"code","source":"ged.apply(lambda x:sum(x.isnull()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22d45fd3b7d91d721f9f2818ae316555f508b1ea"},"cell_type":"markdown","source":"Since we won't be using 'Notes' column, we donot preprocess NaN values in ged"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a3d8822d571cd1323a28d1750cd48662d541c850"},"cell_type":"code","source":"ged.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2eff062760ea67d9152e182d151f8d66e89d2acd"},"cell_type":"code","source":"schools.groupby(['Student Achievement Rating']).agg(np.mean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c266680e725b2dfabb13955e81eff15218903a21"},"cell_type":"markdown","source":"* As is evident from the above dataframe, **Exceeding Target and Meeting Target** fare better in terms of proficiency in **Maths and English.** Also, majority of students in schools with rating of Exceeding Target and Meeting Target are either **White or Asian.**"},{"metadata":{"_uuid":"c38814866b5f80a310e6b397d4ccca99cd8c82b7"},"cell_type":"markdown","source":"* In the course of this analysis, I shall proceed with the schools which have ratings: **Approaching Target** or **Not Meeting Target**."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a9aa6e60cc2cd7c1a6bf8e3a9eebc3b2896b4fdf"},"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \na=schools['Address (Full)'].replace({'NEW YORK':'NewYork','CAMBRIA HEIGHTS':'CambriaHeights','SPRINGFIELD GARDENS':'SpringfieldGardens','REGO PARK':'RegoPark','FOREST HILLS':'ForestHills','ROCKAWAY PARK':'ROCKAWAY','HOWARD BEACH':'HowardBeach','QUEENS VILLAGE':'QueensVillage','COLLEGE POINT':'CollegePoint','RICHMOND HILL':'RichmondHill','FLORAL PARK':'FloralPark','OZONE PARK':'OzonePark','LITTLE NECK':'LittleNeck','LONG ISLAND CITY':'LongIslandCity','MIDDLE VILLAGE':'MiddleVillage','ROOSEVELT ISLAND':'RooseveltIsland','STATEN ISLAND':'StatenIsland','JACKSON HEIGHTS':'JacksonHeights','GREENWICH VILLAGE':'GreenwichVillage','GREAT NECK':'GreatNeck','BROAD CHANNEL':'BroadChannel','BRIGHTON BEACH':'BrightonBeach','MANHATTAN BEACH':'ManhattanBeach','ROCKAWAY BEACH':'RockawayBeach','GRAMERCY PARK':'GramercyPark','PABLEO POINT':'PabloPoint','CARROLL GARDENS':'CarrollGardens','KEW GARDENS':'KewGardens'},regex=True)\ndivision=[None]*len(a)\nfor i in range(len(a)):\n    division[i]=str(a[i]).split(\",\",2)[0].split()[-1]\nschools['neighbourhood']=division\ndf=schools[(schools['Economic Need Index']>0.6) | (schools['Rigorous Instruction Rating']=='Approaching Target') | (schools['Rigorous Instruction Rating']=='Not Meeting Target') | (schools['Collaborative Teachers Rating']=='Not Meeting Target') | (schools['Collaborative Teachers Rating']=='Approaching Target') | (schools['Supportive Environment Rating']=='Not Meeting Target') | (schools['Supportive Environment Rating']=='Approaching Target') | (schools['Effective School Leadership Rating']=='Not Meeting Target')| (schools['Effective School Leadership Rating']=='Approaching Target') | (schools['Strong Family-Community Ties Rating']=='Not Meeting Target') | (schools['Strong Family-Community Ties Rating']=='Approaching Target') | (schools['Trust Rating']=='Not Meeting Target') | (schools['Trust Rating']=='Approaching Target') | (schools['Student Achievement Rating']=='Not Meeting Target') | (schools['Student Achievement Rating']=='Approaching Target')]\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe531a33c102d29f9b096c716dcefe00bccc7b6c"},"cell_type":"markdown","source":"**Since grade 8 and grade 9 students can only take the SHSAT, we remove all schools which has neither of the grades (upper grade<8 or lower grade>9).**\n"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0acf5fcce8cd600922731cde46d050a03a9585e8"},"cell_type":"code","source":"df=df[(df['Grade Low']<='09') | (df['Grade High']>='08')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9cc1939f9a2fe607537e4f3f46b7b6bb00f9d93f"},"cell_type":"code","source":"# Since we donot need the performance for other grades, we dump those columns\ndf=df.drop(df.columns[41:141], axis=1) \ndf=df.drop(df.columns[[0,1,2,4]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"bb8f57982cf01b1e90ed65cc3f3fbc40629aa2e3"},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fd38984555e7196da57fd7b3afa62e9d577431f"},"cell_type":"markdown","source":"### > Looking at null values"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"15842f04bdce398d42f199c415093bb9c6385187"},"cell_type":"code","source":"df.apply(lambda x:sum(x.isnull()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a6796a336cc03936ca444aa510018a3316c09792"},"cell_type":"code","source":"df['School Income Estimate']=df['School Income Estimate'].replace({'\\$':'', ',':''},regex=True).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc894d1a420b7dc9000a12aacff196b34ed79600"},"cell_type":"markdown","source":"* **Replacing School Income Estimate nan values of Community Schools with the Community School average.**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"87c685b63ee2567355ef02ce240ae95ca3064172"},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2cf94ee6960c5ced25cfaa6f41d079af4417fac9"},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(211)\nsns.set(rc={'figure.facecolor':'lightgray'})\nsns.boxplot(y=df['School Income Estimate'],x=df[\"Community School?\"])\nplt.title('School Income Estimate vs Community School?')\nplt.subplot(212)\nsns.set(rc={'figure.facecolor':'lightgray'})\nsns.boxplot(y=df['School Income Estimate'],x=df[\"District\"])\nplt.title('School Income Estimate vs District')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10ccafefe00565450b3b8d1f29b3cd16ee575520"},"cell_type":"markdown","source":"* **Replacing the NaN values with average of schools which are not Community Schools.**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"32817bafbe623a3958627a771c7561c23ad55188"},"cell_type":"code","source":"a=df[df['Community School?']=='Yes']['School Income Estimate'].mean()\nnull_index= df[df['Community School?']=='Yes']['School Income Estimate'].isnull().index.tolist()\nfor i in null_index:\n    df.at[i,'School Income Estimate']= a","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05149b86cc6888f41dadf37d7246a312cb048a65"},"cell_type":"markdown","source":"* **Replacing the remaining NaN values with district average of certain districts (which have a low variance)**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c717d105040f24342ee0e67f5d10fd9e645c3f9b"},"cell_type":"code","source":"import numpy as np\ngrouped=df.groupby('District')\na=grouped['School Income Estimate'].agg(np.mean)\nnull_index=(df['District'].loc[df['School Income Estimate'].isnull().tolist()]== 4|5|6|7|9|12|16|17|18|19|23|26|32).index.tolist()\n\nfor i in null_index:\n    df.at[i,'School Income Estimate']= a[df['District'][i]]     ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9da119d086b6f5bb9f6073a9ff115908ba6182b8"},"cell_type":"markdown","source":"* Now what do we do with the ramaining NaN values in these columns ?\n* We drop columns with NaN values in these columns as all districts have Exceeding Target and Meeting Target as their majority."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3e2c630b762bf5d792572f9dde24de23d040e690"},"cell_type":"code","source":"schools[['Supportive Environment Rating','Rigorous Instruction Rating','Collaborative Teachers Rating','Student Achievement Rating','Trust Rating','Effective School Leadership Rating','Strong Family-Community Ties Rating','District']].groupby(['District'],as_index=False)[['Supportive Environment Rating','Rigorous Instruction Rating','Collaborative Teachers Rating','Student Achievement Rating','Trust Rating','Effective School Leadership Rating','Strong Family-Community Ties Rating']].agg(lambda x: x.value_counts().index[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7858e08e9973b3a4183d854da93414361027e7fd"},"cell_type":"code","source":"# remove the rows with remaining NaN values\ndf=df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"da610c249f0be7047ee88d81fd53ca54aa237943"},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3253bc88814c02cee0c16d6f4dee5436ac8f1f02"},"cell_type":"markdown","source":"The term **'community school'** refers to a type of publicly funded school in the United States that serves as **both an educational institution and a centre of community life.** A community school is both a place and a set of partnerships between the school and other community resources. Its integrated focus on academics, youth development, family support, health and social services and community development leads to improved student learning, stronger families and healthier communities. Using public schools as hubs, community schools bring together many partners to offer a range of support and opportunities to children, youth, families and communities—before, during and after school, and on weekends.   \n\n\n<font color='darkgray'>@ Wikipedia</font>"},{"metadata":{"_uuid":"5194cda6d317e89d8c32e04e83b557e2158597a8"},"cell_type":"markdown","source":"### > How many of them are not community schools?"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f3d02641a7333a8f3d8346e96b4636599e702f71"},"cell_type":"code","source":"len(df[df['Community School?']=='No'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a178aea713cbb6316521be33e6d80e3d57f25c6"},"cell_type":"markdown","source":"### > Where are these schools located?"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"79b583892a5c9c0e7fa76a3cd34874c48e37a112"},"cell_type":"code","source":"from collections import Counter\nCounter(df['neighbourhood']).most_common(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56787f57f985a2c1ea90b18d5ebd61d8971e8342"},"cell_type":"markdown","source":"* **Most Schools are located in Brooklyn and Bronx where the percentage of Black and Hispanic are high.**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9407ed84a51e5b41b8c6a23163b3052697b78913"},"cell_type":"code","source":"df['Percent of Students Chronically Absent']=df['Percent of Students Chronically Absent'].replace({'\\%':''},regex=True).astype(float)\ndf['Rigorous Instruction %']=df['Rigorous Instruction %'].replace({'\\%':''},regex=True).astype(float)\ndf['Collaborative Teachers %']=df['Collaborative Teachers %'].replace({'\\%':''},regex=True).astype(float)\ndf['Supportive Environment %']=df['Supportive Environment %'].replace({'\\%':''},regex=True).astype(float)\ndf['Effective School Leadership %']=df['Effective School Leadership %'].replace({'\\%':''},regex=True).astype(float)\ndf['Strong Family-Community Ties %']=df['Strong Family-Community Ties %'].replace({'\\%':''},regex=True).astype(float)\ndf['Trust %']=df['Trust %'].replace({'\\%':''},regex=True).astype(float)\ndf['Student Attendance Rate']=df['Student Attendance Rate'].replace({'\\%':''},regex=True).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"242c440716fb9ad1fdf4deb59512a5ed4f691dc3"},"cell_type":"markdown","source":"### > Taking a look at the neighbourhood in our dataframe"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"eb347fe59aa22d48965fdf55d3edb4921b297523"},"cell_type":"code","source":"import numpy as np\ndf['Percent Black']=df['Percent Black'].replace({'%':''},regex=True).astype(float)\ndf['Percent Asian']=df['Percent Asian'].replace({'%':''},regex=True).astype(float)\ndf['Percent Hispanic']=df['Percent Hispanic'].replace({'%':''},regex=True).astype(float)\ndf['Percent White']=df['Percent White'].replace({'%':''},regex=True).astype(float)\ndf.groupby(['neighbourhood'],as_index=False)[['Percent Black','Percent Hispanic','Percent White','Percent Asian']].agg(np.mean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da2fa123f71a1760a0f7e4ae0229744c860b4f57"},"cell_type":"markdown","source":"### > Null values of secure dataset"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4f3defe626bd43ac556a328e765886d5a36a0169"},"cell_type":"code","source":"secure.apply(lambda x:sum(x.isnull()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c023ceaf389cfad37be7fb6729c4b164c091f199"},"cell_type":"markdown","source":"### > Finding the closest GED centres to these schools"},{"metadata":{"_uuid":"e2d1b166d9c926744fa48a2d270af911008243e9"},"cell_type":"markdown","source":"The **GED, General Educational Diploma**, is for those without a High School Diploma. Study and take a battery of tests to certify your aptitude, knowledge and skills. It is designed for those that never finished high school. Find a local test center near you. The GED, which stands for General Educational Development but is also referred to as a General Education Diploma, is a set of tests that when passed certify the test taker (American or Canadian) has met high-school level academic skills."},{"metadata":{"_uuid":"06d6bc18cb8e1fcd998562331fbd81504615de1d"},"cell_type":"markdown","source":"> * The GED Tests include five subject area tests: **Language Arts/Writing, Language Arts/Reading, Social Studies, Science, and Mathematics.**\n>\n>* In addition to **English**, the GED tests are available in **Spanish, French, large print, audiocassette and Braille.**\n>\n>* The GED credential itself is issued by the state, province or territory in which the test taker lives.\n>\n>* Many government institutions and universities regard the GED as the same as a high school diploma with respect to program eligibility and as a prerequisite for admissions."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"247475c4bf16625c9e32853cd9c85c1e486ad34f"},"cell_type":"code","source":"from math import cos, asin, sqrt\n\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295\n    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n    return 12742 * asin(sqrt(a))\n\ndef closest(data, v):\n    minimum=100000\n    ind=0\n    for index,row in data.iterrows():\n            dist=distance(v['Latitude'],v['Longitude'],row['Latitude'],row['Longitude'])\n            #print(minimum)\n            if minimum > dist:\n                          minimum=dist\n                          ind=index                        \n    return(data['Program Site name'][ind], data['Postcode'][ind],minimum)  \n\n#closest(ged, df[['Latitude','Longitude']].loc[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"62184ad28e4a3e081434595112905920faa11ea9"},"cell_type":"code","source":"a=[]\nb=[]\ne=[]\nfor index,row in df.iterrows():\n    c,f,d=closest(ged, df[['Latitude','Longitude']].loc[index])\n    a.append(c)\n    e.append(f)\n    b.append(d)\ndf['Closest GED Center']=a\ndf['Distance']=b\ndf['Postcode']=e","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc7da1ab106a6581ce6bfb9d86caeea07fb2bfe6"},"cell_type":"markdown","source":"### > Crime Index"},{"metadata":{"_uuid":"11517e9ca9b299c348b6170cf2fc0ae9367225e1"},"cell_type":"markdown","source":"* Since, I am going to use the crime columns only **(Major N, Oth N, Prop N, NoCrim N, Vio N)**, I'll try and remove the NaN values from the dataset using the mean value of the districts."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4e5705eeeda3530b6f88e811c14b2dccfc496a06"},"cell_type":"code","source":"secure=secure.dropna(subset=['Geographical District Code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5d370ebbe50c233921a84e7087d19d9cb3c62984"},"cell_type":"code","source":"plt.figure(figsize=(20,6))\nsns.set(rc={'figure.facecolor':'lightgray'})\nsns.boxplot(y=secure['NoCrim N'],x=secure['Geographical District Code'])\nplt.title('District vs NoCrim N', size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"eac1f985bf5f0100a4ce93adccd0f070371abe27"},"cell_type":"code","source":"grouped=secure.groupby('Geographical District Code')\nz=grouped[['Major N','Vio N','Prop N','NoCrim N','Oth N']].agg(np.mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8d07dfe505b128ff0c5792693e5808904e9d48ae"},"cell_type":"code","source":"null_index=secure[secure['Major N'].isnull()].index.tolist()\nfor i in null_index:\n    secure.at[i,'Major N'],secure.at[i,'Vio N'],secure.at[i,'Prop N'],secure.at[i,'NoCrim N'],secure.at[i,'Oth N']=z['Major N'][secure['Geographical District Code'][i]],z['Vio N'][secure['Geographical District Code'][i]],z['Prop N'][secure['Geographical District Code'][i]],z['NoCrim N'][secure['Geographical District Code'][i]],z['Oth N'][secure['Geographical District Code'][i]]    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85068889201bddada7d7d249492c575a5ade9532"},"cell_type":"markdown","source":"* **We create a common index called a Security index from all types of crimes committed (which includes Major crimes, Violent crimes, Property crimes, Non criminal crimes and other crimes).**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b8d8b7422b74156c5052fad90d0f4f2d791c32fd"},"cell_type":"code","source":"secure['crime index']=secure['Major N']*0.55 + secure['Vio N']*0.25 + secure['Prop N']*0.1 + secure['NoCrim N']*0.05 + secure['Oth N']*0.05","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"084b306073804461c6b68a9d24eb0667a11a279e"},"cell_type":"code","source":"# obtaining the crime index of each location\ngrouped=secure.groupby(['Postcode'],as_index=False)['crime index'].agg(np.mean)\n\nfor code in grouped['Postcode'].tolist():\n    df.at[df[df['Postcode']==code].index.tolist(),'crime index']=grouped[grouped['Postcode']==code]['crime index'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"609528adad0c325c018f22862122ebcee0a966c4"},"cell_type":"markdown","source":"### > Binarizing the 'Community School?' column"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b4e285cc321966d0a5deb8f36404e5a96b31e835"},"cell_type":"code","source":"df.at[df[df['Community School?']=='Yes'].index,'Community School?']=1\ndf.at[df[df['Community School?']=='No'].index,'Community School?']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"30e9422915ebd0cbb9703077b2715ae44e3a2fa0"},"cell_type":"code","source":"df3=df[['Economic Need Index', 'School Income Estimate','Community School?','Percent Asian', 'Percent Black', 'Percent Hispanic','Percent White', 'Student Attendance Rate',\n       'Percent of Students Chronically Absent', 'Rigorous Instruction %','Collaborative Teachers %','Supportive Environment %', 'Effective School Leadership %',\n            'Strong Family-Community Ties %','Trust %','Average ELA Proficiency',\n       'Average Math Proficiency', 'Distance', 'crime index']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"19e182aeee5521621b3ce892f930cebe403cf143"},"cell_type":"code","source":"df3.apply(lambda x:sum(x.isnull()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7502cb74a7f382eb4a2006dfe820405bba708d89"},"cell_type":"code","source":"df3.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3637ba15d09ca4267ea091b199c32a4124b0119a"},"cell_type":"markdown","source":"# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"634e69059e98de841d7bac2cec892008407f418b"},"cell_type":"markdown","source":"## 1. Perform the Hierarchical Clustering\nNow that we have some very simple sample data, let's do the actual clustering on it:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c3f1f6f85348dec7501b3d134bb8de4ad9930371"},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom scipy.cluster.hierarchy import dendrogram, linkage","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5916ddcd727115b42f63148be90f14f79a79d917"},"cell_type":"code","source":"%matplotlib inline\nnp.set_printoptions(precision=5, suppress=True) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7dd5435fbb6f48807aacb40a501f60666106db7"},"cell_type":"markdown","source":"### > Cophenetic Correlation Coefficient\nWith help of the cophenet() function. This compares (correlates) the actual pairwise distances of all our samples to those implied by the hierarchical clustering. The closer the value is to 1, the better the clustering preserves the original distances."},{"metadata":{"_uuid":"e2cbac71351a465587d4e0dce1e9294f7ef98873"},"cell_type":"markdown","source":"* I use the **euclidean distance metric** as this produces the **highest Cophenetic Correlation Coefficient.**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ecb172ddaad6870c36cd058ec2a459caca0a0e42"},"cell_type":"code","source":"# generate the linkage matrix\nZ = linkage(df3,'complete')\nfrom scipy.cluster.hierarchy import cophenet\nfrom scipy.spatial.distance import pdist\n\nc, coph_dists = cophenet(Z, pdist(df3))\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0cc40d27987721d6207bb5a78c76cf28bf716e4d"},"cell_type":"code","source":"plt.figure(figsize=(25, 10))\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('sample index')\nplt.ylabel('distance')\ndendrogram(\n    Z,\n    leaf_rotation=90.,  # rotates the x axis labels\n    leaf_font_size=8.,  # font size for the x axis labels\n)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b883de1a6a1826bbe236e9ebd55c4865992e1858"},"cell_type":"markdown","source":"Let's take apart the dendogram....\n\n* On the x axis you see labels. If you don't specify anything else they are the indices of your samples in X.\n* On the y axis you see the distances (of the 'ward' method in our case).\n\nStarting from each label at the bottom, you can see a vertical line up to a horizontal line. The height of that horizontal line tells you about the distance at which this label was merged into another label or cluster.\n\nLet's have a look at the distances of the last 10 merges:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"537f40739c05dc6043f4a6901be0ad7ad97a29cc"},"cell_type":"code","source":"Z[-10:,2]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd159f2144282a11de33ef76c91eca1137a1ac86"},"cell_type":"markdown","source":"We can also see that from distances > 21080 up there's a huge jump of the distance to the final merge at a distance of approx 61352. Such distance jumps / gaps in the dendrogram are pretty interesting for us. They indicate that something is merged here, that maybe just shouldn't be merged. In other words: maybe the things that were merged here really don't belong to the same cluster, telling us that maybe there's just 4 clusters here."},{"metadata":{"_uuid":"cdc99148225da0e51641ed418dd44428d905f066"},"cell_type":"markdown","source":"### > Eye Candy\nEven though this already makes for quite a nice visualization, we can pimp it even more by also annotating the distances inside the dendrogram by using some of the useful return values dendrogram():"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ece9f6e7929666c0a3dbb89dc1000ff499c0b823"},"cell_type":"code","source":"plt.figure(figsize=(25, 10))\ndef fancy_dendrogram(*args, **kwargs):\n    max_d = kwargs.pop('max_d', None)\n    if max_d and 'color_threshold' not in kwargs:\n        kwargs['color_threshold'] = max_d\n    annotate_above = kwargs.pop('annotate_above', 0)\n\n    ddata = dendrogram(*args, **kwargs)\n    \n    if not kwargs.get('no_plot', False):\n        plt.title('Hierarchical Clustering Dendrogram (truncated)')\n        plt.xlabel('sample index or (cluster size)')\n        plt.ylabel('distance')\n        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n            x = 0.5 * sum(i[1:3])\n            y = d[1]\n            if y > annotate_above:\n                plt.plot(x, y, 'o', c=c)\n                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n                             textcoords='offset points',\n                             va='top', ha='center')\n        if max_d:\n            plt.axhline(y=max_d, c='k')\n    return ddata\n\nfancy_dendrogram(\n    Z,\n    truncate_mode='lastp',\n    p=100,\n    leaf_rotation=90.,\n    leaf_font_size=12.,\n    show_contracted=True,\n    annotate_above=10,  # useful in small plots so annotations don't overlap\n)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70d1a6f8c91dec3e4abf44b0d3ca74296375cf10"},"cell_type":"markdown","source":"The above shows a truncated dendrogram, which only shows the last p=100."},{"metadata":{"_uuid":"cc536dcae9a29204be823a2113ab347485c93aaf"},"cell_type":"markdown","source":"### > Selecting a Distance Cut-Off aka Determining the Number of Clusters\nAs explained above already, a huge jump in distance is typically what we're interested in if we want to argue for a certain number of clusters. If we have the chance to do this manually, i would always opt for that, as it allows us to gain some insights into the data and to perform some sanity checks on the edge cases. In our case, I would say that the cutoff is 1260 as the jump is prety obvious."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"87a8bfc46b03627f434b4123d8b063d60d3e951e"},"cell_type":"code","source":"# set cut-off to 21080 \nmax_d = 23000   # max_d as in max_distance","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e93b5a8eb18582ba790ffee6e06b26e951c17d7c"},"cell_type":"markdown","source":"Let's visualize this in the dendrogram as a cut-off line:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c51fe614397db09fa3a43573a28c641316a75eba"},"cell_type":"code","source":"plt.figure(figsize=(25, 10))\nfancy_dendrogram(\n    Z,\n    truncate_mode='lastp',\n    p=100,\n    leaf_rotation=90.,\n    leaf_font_size=12.,\n    show_contracted=True,\n    annotate_above=100,\n    max_d=max_d,  # plot a horizontal cut-off line\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b42a04438677b732228fca42604096692ca6df4"},"cell_type":"markdown","source":"### > Automated Cut-Off Selection"},{"metadata":{"_uuid":"17a569edaf8d466aea34dba07dfd71c757634a31"},"cell_type":"markdown","source":"Now while this manual selection of a cut-off value offers a lot of benefits when it comes to checking for a meaningful clustering and cut-off, there are cases in which we can automate this."},{"metadata":{"_uuid":"2f95676b32f4304fd9e8248f19987a5b4e8fd17d"},"cell_type":"markdown","source":"### > Elbow Method\nIt tries to find the clustering step where the acceleration of distance growth is the biggest (the \"strongest elbow\" of the blue line graph below, which is the highest value of the green graph below):"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"701ffad70883082d7a5984cfa6a4d741e982af43"},"cell_type":"code","source":"last = Z[-10:, 2]\nlast_rev = last[::-1]\nidxs = np.arange(1, len(last) + 1)\nplt.figure(figsize=(20,8))\nplt.plot(idxs, last_rev)\n\nacceleration = np.diff(last, 2)  # 2nd derivative of the distances\nacceleration_rev = acceleration[::-1]\nplt.plot(idxs[:-2] + 1, acceleration_rev)\nplt.show()\nk = acceleration_rev.argmax() + 2  # if idx 0 is the max of this we want 2 clusters\nprint(\"clusters:\", k)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8deb355c0623d4cec7cd58166d4071a0518bbb08"},"cell_type":"markdown","source":"### > Retrieve the Clusters\n**Now, let's finally have a look at how to retrieve the clusters, for different ways of determining k. We can use the fcluster function.**"},{"metadata":{"_uuid":"bae41a90d67f104762ef2082f24f6834d5827f69"},"cell_type":"markdown","source":"**1. Knowing max_d:\nLet's say we determined the max distance with help of a dendrogram, then we can do the following to get the cluster id for each of our samples:**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3aa2e6ad8c515f1895f141452ab40c5e96535234"},"cell_type":"code","source":"from scipy.cluster.hierarchy import fcluster\nmax_d = 23000\nclusters = fcluster(Z, max_d, criterion='distance')\nclusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8d4afa77a32b69f9f2173457ba3b8de6c1e48772"},"cell_type":"code","source":"Counter(clusters)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d5b8b07616a7af0f264abef40fa43428a541106"},"cell_type":"markdown","source":"**2. Knowing k:\nAnother way starting from the dendrogram is to say \"i can see i have k=2\" clusters. We can then use:**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7529dacacfabf50e12ac0c9ce2b0bd81f822580e"},"cell_type":"code","source":"k=2\ncluster=fcluster(Z, k, criterion='maxclust')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"00f452bbd4a78ae100de1bbafa70d70cfccf88d9"},"cell_type":"code","source":"fcluster(Z, k, criterion='maxclust')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8ad0ffc432a23e6328d2840361c1f11d5f5a75e"},"cell_type":"markdown","source":"** I am going to use the hierarchial clustering. **"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7ca5bede08778f8673763933e613f2640bd1b2ac"},"cell_type":"code","source":"z=ged[['Program Site name','Latitude','Longitude','Borough']].dropna()\n\nimport branca.colormap as cm\nimport folium\nfrom folium import plugins\n\nstep = cm.StepColormap(\n    ['aqua','yellow','red'],\n    vmin=0.5, vmax=3.5,\n    index=[0.5,1.5,2.5],\n    caption='step'\n)\n    \nstep","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b71c2eb09347b0fbc788fac78fe7736c3b5d14ef"},"cell_type":"markdown","source":"* **Blue: CLuster 1**\n* **Yellow: Cluster 2**\n* **Red: Cluster 3**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"de77b536dc8bae2ac1b0094ddf01821e6be55741"},"cell_type":"code","source":"df['Cluster']=fcluster(Z, max_d, criterion='distance')\ndf = df.reset_index(drop=True)\ndf3 = df3.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8465f23002cf9adcf293d6af7b7363f64846790f"},"cell_type":"code","source":"m = folium.Map([df['Latitude'][0], df['Longitude'][0]], zoom_start=9.5,tiles='cartodbdark_matter')\n\ni=0\nfor lat, lon in zip(df['Latitude'], df['Longitude']):\n    folium.CircleMarker([lat, lon], color=step(df['Cluster'][i]), fill=True, radius=0.9).add_to(m)    \n    i+=1\nm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"12829c3bbc0330c35be73f6479e4f13dd112211f"},"cell_type":"code","source":"grouped=df.groupby(['Cluster']).agg(np.mean)\ngrouped.drop(grouped.columns[1:6], axis=1)\n#grouped","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d61d45d7b6ce9e5aeeac7371efe6c3261577efe"},"cell_type":"markdown","source":"* **Let's neglect the cluster 4. On careful observation, we can see that Cluster 2 has the highest Percentage of Black and Hispanic students = 40.8% and 50%. Cluster 1 has the highest percentage of Asian = 20.5% and cluster 3 has the highest percentage of White = 29.25%.  **   \n\n* **This explains the high Economic Index of cluster 2 and low Economic Index for cluster 3. Moreover, the crime index is higher in the areas of cluster 2 = 1.06. It's lowest in cluster 1 = 0.88.**   \n\n* **The Distance of the closest GED centres is more in case of cluster 3 = 4.19.**\n\n* **Student Attendance Rate seems to lowest for Cluster 2 = 91.34% with a higher percentage of students chronically absent = 25.77%.**\n\n* **Average ELA and Math Proficiency are lowest for cluster 2.**\n\n* **Fewer students have score 4 in Grade 8 in cluster 2.**     \n\n> This gives us a rough idea of the important features coming into play.\n\n"},{"metadata":{"_uuid":"1aa1f346bd2364ae44b8a12da10d14ee70e65c9e"},"cell_type":"markdown","source":"### > Let's look at the schools in each cluster"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"cf1d86397523059abf9da631242e87e717b8be1d"},"cell_type":"code","source":"grouped=df[['School Name','Cluster']].groupby(['School Name'],as_index=False).agg(lambda x:x.value_counts().index[0]).groupby(['Cluster'])\naug=grouped['School Name'].apply(lambda x: sorted(set(x)))[1]\nnov=grouped['School Name'].apply(lambda x: sorted(set(x)))[2]\napr=grouped['School Name'].apply(lambda x: sorted(set(x)))[3]\n\nz={'School Name':[aug,nov,apr], 'Cluster': [1,2,3]}\nz=pd.DataFrame(z)\nz.style.set_properties(**{'background-color': 'black',\n                           'color': 'gold','border-color': 'white'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de79924b4ab4c3c0b4f4c311710f4eeb64b69809"},"cell_type":"markdown","source":"# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"bf37191e1cd8ae8b382b646c73030e26eb943def"},"cell_type":"markdown","source":"## 2. PFA (Principal Feature Analysis) "},{"metadata":{"_uuid":"9f414d0f7923b44cbc8ad62f2ba1c13ea0e4e14d"},"cell_type":"markdown","source":">PCA has the disadvantage that measurements from all the original features are used in the projection to the lower dimensional space. PFA, on the other hand performs dimensionality reduction of a feature set by choosing a subset of the original features that contains most of the essential information, using the same criteria as PCA."},{"metadata":{"_uuid":"90aab2c6deed9e26f604d67e5886a983b3968147"},"cell_type":"markdown","source":"### > Standardizing"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ee525e8021a50a3ba408a67fa1c0bb890a1787cc"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX_std = StandardScaler().fit_transform(df3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"021cd61856aac6cd63844d56bfa2e6f16bb5ebab"},"cell_type":"markdown","source":"### > Obtaining the most important features "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1786a86652802ad4e07ca84dc08ee69ac80e7f6d"},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom collections import defaultdict\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn.preprocessing import StandardScaler\n\nclass PFA(object):\n    def __init__(self, n_features, q=None):\n        self.q = q\n        self.n_features = n_features\n\n    def fit(self, X):\n        if not self.q:\n            self.q = X.shape[1]\n\n        sc = StandardScaler()\n        X = sc.fit_transform(X)\n\n        pca = PCA(n_components=self.q).fit(X)\n        A_q = pca.components_.T\n\n        kmeans = KMeans(n_clusters=self.n_features).fit(A_q)\n        clusters = kmeans.predict(A_q)\n        cluster_centers = kmeans.cluster_centers_\n\n        dists = defaultdict(list)\n        for i, c in enumerate(clusters):\n            dist = euclidean_distances([A_q[i, :]], [cluster_centers[c, :]])[0][0]\n            dists[c].append((i, dist))\n\n        self.indices_ = [sorted(f, key=lambda x: x[1])[0][0] for f in dists.values()]\n        self.features_ = X[:, self.indices_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"84989f1b8292c062b7a97804e9c57c8a931f1366"},"cell_type":"code","source":"import numpy as np\n\npfa = PFA(n_features=10)\npfa.fit(X_std)\n\n# To get the transformed matrix\nX_transformed = pfa.features_\n\n# To get the column indices of the kept features\ncolumn_indices = pfa.indices_\ncolumn_indices","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcb0d6109816c8129f5440e048971cafa6208fd3"},"cell_type":"markdown","source":"### > Most important features"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e8d7dedbda9321686350a0fb39d3f8a02094d4c6"},"cell_type":"code","source":"df3.columns[column_indices].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85320713a2535547f085913da47b499f940070a7"},"cell_type":"markdown","source":"# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"1cd126a9a85e0422b2d0a875738ebc1a63ba1089"},"cell_type":"markdown","source":"## 3. Merging with th SHSAT data of District 5"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"562dc80394849d8bec596b89889b8017af849584"},"cell_type":"code","source":"shst=pd.read_csv('../input/data-science-for-good/D5 SHSAT Registrations and Testers.csv')\nshst=shst.rename(columns={'DBN':'Location Code'})\nshst=shst.drop(shst.columns[1],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"91752665487590b00aae4b400203f0cd43d29d6c"},"cell_type":"code","source":"shst.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9c313f3d12e8ba2a7064bdcdc0c71f10c333b913"},"cell_type":"code","source":"# ratio of number of students who are enrolled till end of October and who actually take the test\n# participation to enrollment ratio\nshst['PEratio']=shst['Number of students who took the SHSAT']/shst['Enrollment on 10/31']\n# registration to enrollment ratio\nshst['REratio']=shst['Number of students who registered for the SHSAT']/shst['Enrollment on 10/31']\n# participation to registration ratio\nshst['PRratio']=shst['Number of students who took the SHSAT']/shst['Number of students who registered for the SHSAT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"617f094500f844915aa232c3217763f6e92c7bb0"},"cell_type":"code","source":"ged_secure=pd.merge(df,shst,on='Location Code')\nged_secure.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9e660fc4189280b1bd5f7ee3d6947cbc8f10f3c4"},"cell_type":"code","source":"ged_secure.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"fefba0b7a6efa9d5277a2030f412c4e9482c59ea"},"cell_type":"code","source":"ged_secure.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7e97b2f1daee18c989b823ca30a3923c0f96c41"},"cell_type":"markdown","source":"### > NaN values in the ratio"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b08a51789432615ce8fcc0a02ac16cf9d6a91597"},"cell_type":"code","source":"ged_secure[['PEratio','REratio','PRratio']].apply(lambda x:sum(x.isnull()))  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89c7ca04b2b1c3315b6ce2c611e1dc02ad92abfa"},"cell_type":"markdown","source":"**Replacing the NaN values in PRratio by the mean value of the PRratio of Zip**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e051a1cd1bfb3d12b239b9cedf2016492e6bb7e7"},"cell_type":"code","source":"sns.set(rc={'figure.facecolor':'lightgray'})\nsns.boxplot(y=ged_secure['PRratio'],x=ged_secure['Zip'])\nplt.title('PRratio vs Zip')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"6232e87bc92b4b5e0d990dfcd26132a332619da0"},"cell_type":"code","source":"import numpy as np\ngrouped=ged_secure.groupby('Zip')\na=grouped['PRratio'].agg(np.mean)\nnull_index=ged_secure[ged_secure['PRratio'].isnull()].index.tolist()\n\nfor i in null_index:\n    ged_secure.at[i,'PRratio']= a[ged_secure['Zip'][i]]     ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38c0c00d7bb5b03fa0f43b9166c5bfae119f0ea1"},"cell_type":"markdown","source":"## 3.1 Hierarchial Clustering"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0a71b3232d319c804b1927f4ce292de42684f9ee"},"cell_type":"code","source":"df3=ged_secure[['Economic Need Index', 'School Income Estimate','Community School?','Percent Asian', 'Percent Black', 'Percent Hispanic','Percent White', 'Student Attendance Rate',\n       'Percent of Students Chronically Absent', 'Rigorous Instruction %','Collaborative Teachers %','Supportive Environment %', 'Effective School Leadership %',\n            'Strong Family-Community Ties %', 'Trust %','Average ELA Proficiency',\n       'Average Math Proficiency', 'Distance', 'crime index','Enrollment on 10/31',\n       'Number of students who registered for the SHSAT',\n       'Number of students who took the SHSAT']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"968ad8044e7b7ce7aa476923dd60210d4b2b0a82"},"cell_type":"code","source":"# generate the linkage matrix\nZ = linkage(df3)\nfrom scipy.cluster.hierarchy import cophenet\nfrom scipy.spatial.distance import pdist\n\nc, coph_dists = cophenet(Z, pdist(df3))\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a2a69a4f850c610ff9fd85149b231db2dada3a2c"},"cell_type":"code","source":"plt.figure(figsize=(25, 10))\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('sample index')\nplt.ylabel('distance')\ndendrogram(\n    Z,\n    leaf_rotation=90.,  # rotates the x axis labels\n    leaf_font_size=8.,  # font size for the x axis labels\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ee2b48f6ba30f525bb7fa8ed0c95feff11641ad0"},"cell_type":"code","source":"Z[-10:,2]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d3e47f68ffc932600fe5d1bd65be6a1ca3b666b"},"cell_type":"markdown","source":"* **Huge jump after distance=357**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c436b805d206931ccb8d3f85d3588683ddfc6cc0"},"cell_type":"code","source":"max_d=400\nplt.figure(figsize=(25, 10))\nfancy_dendrogram(\n    Z,\n    truncate_mode='lastp',\n    p=100,\n    leaf_rotation=90.,\n    leaf_font_size=12.,\n    show_contracted=True,\n    annotate_above=100,\n    max_d=max_d,  # plot a horizontal cut-off line\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"062033d81db3d51d27d852df4e5db9d26ce43a72"},"cell_type":"markdown","source":"* This shows that there should be 6 clusters."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"d4a5d94bc55f1a9e794fe5a1a96cc983f0360c19"},"cell_type":"code","source":"last = Z[-10:, 2]\nlast_rev = last[::-1]\nidxs = np.arange(1, len(last) + 1)\nplt.figure(figsize=(20,8))\nplt.plot(idxs, last_rev)\n\nacceleration = np.diff(last, 2)  # 2nd derivative of the distances\nacceleration_rev = acceleration[::-1]\nplt.plot(idxs[:-2] + 1, acceleration_rev)\nplt.show()\nk = acceleration_rev.argmax() + 2  # if idx 0 is the max of this we want 2 clusters\nprint(\"clusters:\", k)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88db02966d38ce6cd33c5e581404f30fe908c4c1"},"cell_type":"markdown","source":"### > Generate the clusters"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9a2f13a15f73ba5bf69f24fdeea23ab1d38b3e00"},"cell_type":"code","source":"from scipy.cluster.hierarchy import fcluster\nmax_d = 400\nclusters = fcluster(Z, max_d, criterion='distance')\nclusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"40c6477a4fd318ab9a3114615314aafea9688dc1"},"cell_type":"code","source":"Counter(clusters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5e63efcc55615b439e50dfd33b47ec64a6ae1d38"},"cell_type":"code","source":"ged_secure['Cluster']=fcluster(Z, max_d, criterion='distance')\nged_secure = ged_secure.reset_index(drop=True)\ndf3 = df3.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3c349b07c5df16ca83aa86028c4a4c8ad9a45379"},"cell_type":"code","source":"grouped=ged_secure.groupby(['Cluster']).agg(np.mean)\ngrouped.drop(grouped.columns[1:6], axis=1)\n#grouped","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b2fde42ec86b4e5732f8e59385c9aea8d0b2404"},"cell_type":"markdown","source":"### > Let's look at the schools in each cluster"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"d52f38473375f95d30e07714b1e32ef83c9465e8"},"cell_type":"code","source":"grouped=ged_secure[['School Name','Cluster']].groupby(['School Name'],as_index=False).agg(lambda x:x.value_counts().index[0]).groupby(['Cluster'])\naug=grouped['School Name'].apply(lambda x: sorted(set(x)))[1]\nnov=grouped['School Name'].apply(lambda x: sorted(set(x)))[2]\napr=grouped['School Name'].apply(lambda x: sorted(set(x)))[3]\nmar=grouped['School Name'].apply(lambda x: sorted(set(x)))[4]\n#Oct=grouped['School State'].apply(lambda x: sorted(set(x)))['Oct']\nSep=grouped['School Name'].apply(lambda x: sorted(set(x)))[5]\n\nz={'School Name':[aug,nov,apr,mar,Sep], 'Cluster': [1,2,3,4,5]}\nz=pd.DataFrame(z)\nz.style.set_properties(**{'background-color': 'black',\n                           'color': 'lawngreen','border-color': 'white'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fba7894ef1dc46dc5c6b5ce259346103fd0fa7cf"},"cell_type":"markdown","source":"## 3.2 PCA"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7f2c9e64b6e6472d7954433b5a8475ad1401f291"},"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nx = StandardScaler().fit_transform(df3)\nprint('Covariance matrix \\n%s' %x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1d44de83585d79827642d48491b4b28421fce04e"},"cell_type":"code","source":"cov_mat = np.cov(x.T)\n\neig_vals, eig_vecs = np.linalg.eig(cov_mat)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ebb637991d7a0e14e92661c8a9b4be4a1d19c0b6"},"cell_type":"code","source":"# Make a list of (eigenvalue, eigenvector) tuples\neig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n\n# Sort the (eigenvalue, eigenvector) tuples from high to low\neig_pairs.sort()\neig_pairs.reverse()\n\n# Visually confirm that the list is correctly sorted by decreasing eigenvalues\nprint('Eigenvalues in descending order:')\nfor i in eig_pairs:\n    print(i[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"506b267c04195c716043881cc575055432e1bc45"},"cell_type":"code","source":"import  plotly\nplotly.tools.set_credentials_file(username='RishiHazra', api_key='3WYShX1Rc0UlKTzCVggk')\nimport plotly.offline as py\nfrom plotly import tools\nfrom plotly.graph_objs import *\npy.init_notebook_mode(connected=True)\n\ntot = sum(eig_vals)\nvar_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\ncum_var_exp = np.cumsum(var_exp)\n\ntrace1 = Bar(\n        x=['PC %s' %i for i in range(1,16)],\n        y=var_exp,\n        showlegend=False)\n\ntrace2 = Scatter(\n        x=['PC %s' %i for i in range(1,16)], \n        y=cum_var_exp,\n        name='cumulative explained variance')\n\ndata = Data([trace1, trace2])\n\nlayout=Layout(\n        yaxis=YAxis(title='Explained variance in percent'),\n        title='Explained variance by different principal components')\n\nfig = Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a62bc28f35a10bddc9fcde17245b2792a0f115b"},"cell_type":"markdown","source":"** A total of 15 dimensions account for more than 98% of the data. **"},{"metadata":{"_uuid":"a619a1ea9875e1ab17bd6f4b525efb21d0537d64"},"cell_type":"markdown","source":"### > PFA (Principal Feature Analysis): Obtaining the most important features "},{"metadata":{"_uuid":"dac87db8b0c4f1e25dfeec46e2d18489203e17fe"},"cell_type":"markdown","source":"> PCA has the disadvantage that measurements from all the original features are used in the projection to the lower dimensional space. PFA, on the other hand performs dimensionality reduction of a feature set by choosing a subset of the original features that contains most of the essential information, using the same criteria as PCA. "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ad560e90609c8b113215799ea7067f119cd6a2b7"},"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import StandardScaler\nx = StandardScaler().fit_transform(df3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a59a285934719d7539c86af632b8efac49656423"},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom collections import defaultdict\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn.preprocessing import StandardScaler\n\nclass PFA(object):\n    def __init__(self, n_features, q=None):\n        self.q = q\n        self.n_features = n_features\n\n    def fit(self, X):\n        if not self.q:\n            self.q = X.shape[1]\n\n        sc = StandardScaler()\n        X = sc.fit_transform(X)\n\n        pca = PCA(n_components=self.q).fit(X)\n        A_q = pca.components_.T\n\n        kmeans = KMeans(n_clusters=self.n_features).fit(A_q)\n        clusters = kmeans.predict(A_q)\n        cluster_centers = kmeans.cluster_centers_\n\n        dists = defaultdict(list)\n        for i, c in enumerate(clusters):\n            dist = euclidean_distances([A_q[i, :]], [cluster_centers[c, :]])[0][0]\n            dists[c].append((i, dist))\n\n        self.indices_ = [sorted(f, key=lambda x: x[1])[0][0] for f in dists.values()]\n        self.features_ = X[:, self.indices_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"39efe934d311df37ba807b35e1224072bb977bc4"},"cell_type":"code","source":"import numpy as np\n\n\npfa = PFA(n_features=15)\npfa.fit(x)\n\n# To get the transformed matrix\nX = pfa.features_\n\n# To get the column indices of the kept features\ncolumn_indices = pfa.indices_\ncolumn_indices","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"334efb8a594edc8d95c3f38013391b14d2108ee5"},"cell_type":"markdown","source":"### > Most important features"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"230a2f82ec4182597f480efa0bcafc2856ae3f0a"},"cell_type":"code","source":"df3.columns[column_indices].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b20ed83f3d70ecaccda636e281133b315e28c7bb"},"cell_type":"markdown","source":"# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"697e07556c8f12c49a9050431fcf649ea0c9a418"},"cell_type":"markdown","source":"## 4. Obtaining the feature importance from training"},{"metadata":{"_uuid":"3c71b1051268ecf9f05acbb8342e1affc7f740cc"},"cell_type":"markdown","source":"* Let us formulate a few basic assumptions based on our objective. We are to rank schools in order to encourage more paricipation among students so that the ones on the top benefit from the outreach services. \n\n* Henceforth, we shall consider the following as our target(Y)- values. The other features are our X-values."},{"metadata":{"_uuid":"48b1f2ddac0b15b6c61885f59bc085cd6c21e6be"},"cell_type":"markdown","source":"* Year 2016 Ratio of number of students who appear for the test to the number of students who are enrolled \n* Year 2016 Ratio of number of students who register for the test to the number of students who are enrolled\n* Year 2016 Ratio of number of students who appear for the test to the number of students who have registered\n* Difference in ratio of number of students who appear for the test to the number of students who are enrolled (2013-2016)\n* Difference in the ratio of number of students who register for the test to the number of students who are enrolled (2013-2016)\n* Difference in ratio of number of students who appear for the test to the number of students who registered for the test (2013-2016)"},{"metadata":{"_uuid":"7ff59246e2d971d31b82631e15e8b6c8ab3f89d8"},"cell_type":"markdown","source":"I will be using two methods to rank the features.   \n1) Using F-Regression   \n2) Using Gradient Boosting and/or Random Forest Regressor   "},{"metadata":{"_uuid":"5dc57feea1b2470e44f5ab79208e2dc1b4ba89a4"},"cell_type":"markdown","source":"### 4.1 Year 2016 Ratio of number of students who appear for the test to the number of students who are enrolled "},{"metadata":{"_uuid":"f3921bf90b24454b1469808665832d3d69ac70b0"},"cell_type":"markdown","source":"### > train-test split"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"117ce62de405e64ba5cce4467fcac78d41aa37ac"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfeatures = ged_secure[\n    ['Economic Need Index','School Income Estimate','Community School?','Percent Asian', 'Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Percent of Students Chronically Absent', 'Rigorous Instruction %','Collaborative Teachers %','Supportive Environment %', 'Effective School Leadership %',\n     'Strong Family-Community Ties %','Trust %','Average ELA Proficiency','Average Math Proficiency', 'Distance', 'crime index']].values\ntargets = ged_secure['PEratio'].values\n\nX_train1, X_test1, y_train1, y_test1 =train_test_split(features, targets, test_size=0.1, random_state=1)\nX_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fadee9a65d4e29bd96b0f980c0dca9d1fe01cf0"},"cell_type":"markdown","source":"### > Using F-Regression: \n\nF-regression does the following:\n\n* Start with a constant model, M0\n* Try all models M1 consisting of just one feature and pick the best according to the F statistic\n* Try all models M2 consisting of M1 plus one other feature and pick the best ..."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4cb6b20812be051d3d186d4d6f2d8370a962510a"},"cell_type":"code","source":"from sklearn.feature_selection import f_regression\nf_regression(X_train1, y_train1, center=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"09a1aa05918904482ad9e4b55bf12d8195e21a4e"},"cell_type":"code","source":"a=f_regression(X_train1, y_train1, center=True)[0]\nplt.figure(figsize=[15,5])\nplt.bar(range(len(a)), a,width=0.5)\n\nimport math\nxint = range(0, len(a))\nplt.xticks(xint)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"392ef2a280dd9df144a6785ece3c5cb80d5feb6e"},"cell_type":"markdown","source":"**Thus, we see that the following features (which have a high F-score) are most important estimators of our target variable.     \nIn the order of precedence.......  **\n\n**1) School Attendance Rate  **    \n**2) Strong Family-Community Ties %   **    \n**3) Percent of Students Chronically Absent  **    \n**4) crime index    **    \n**5) Economic Need Index   **    \n**6) Percent Black   **        \n**7) Percent Hispanic  **     \n**8) School Income Estimate **  \n\n"},{"metadata":{"_uuid":"0367dd3f9522fe711bf97429c9bab6d2aea9b073"},"cell_type":"markdown","source":"### > Using Gradient Boosting and/or Random Forest Regressor\n\nImportance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity used to select the split points or another more specific error function. The feature importances are then averaged across all of the the decision trees within the model.\n\nRandom forest consists of a number of decision trees. Every node in the decision trees is a condition on a single feature, designed to split the dataset into two so that similar response values end up in the same set."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4774c439970ebc71b2235c5bacb8e34badfb44e0"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_error\nfrom sklearn.metrics import r2_score, explained_variance_score\n\ndef regression(regressor, x_train, x_test, y_train):\n    reg = regressor\n    reg.fit(x_train, y_train)\n    \n    y_train_reg = reg.predict(x_train)\n    y_test_reg = reg.predict(x_test)\n    \n    return y_train_reg, y_test_reg\n\ndef scores(regressor, y_train, y_test, y_train_reg, y_test_reg):\n    print(\"_______________________________________\")\n    print(regressor)\n    print(\"_______________________________________\")\n    print(\"R2 score. Train: \", r2_score(y_train, y_train_reg))\n    print(\"R2 score. Test: \", r2_score(y_test, y_test_reg))\n    print(\"---------\")\n    print(\"MSE (Train): \", mean_squared_error(y_train, y_train_reg))\n    print(\"MSE Test: \", mean_squared_error(y_test, y_test_reg))\n    print(\"---------\")\n    print(\"MAE (Train): \", mean_absolute_error(y_train, y_train_reg))\n    print(\"MAE (Test): \", mean_absolute_error(y_test, y_test_reg))\n    print(\"_______________________________________\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7ec97802178a576a4b00f08eda5feb36f8ee1d51"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n#n_estimators=The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\ny_train_gbr1, y_test_gbr1 =regression(GradientBoostingRegressor(max_depth=10, n_estimators=100), \n           X_train1, X_test1, y_train1)\n\nscores('Gradient Boosting Regressor \\nratio of no. of students who are enrolled to the no. of students who take the test', \n       y_train1, y_test1, y_train_gbr1, y_test_gbr1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"d2c5be07fb06e6bcc4507b48646115446ba19e92"},"cell_type":"code","source":"# n_estimators=The number of trees in the forest\ny_train_rfr1, y_test_rfr1 =regression(RandomForestRegressor(n_estimators=22), X_train1, X_test1, y_train1)\n\nscores('Random Forest Regressor \\nratio',y_train1, y_test1, y_train_rfr1, y_test_rfr1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"103f51f6e68f009d967fbac15ec035d99827c23d"},"cell_type":"code","source":"# plot feature importances\nmodel1=GradientBoostingRegressor(max_depth=7, n_estimators=100).fit(X_train1, y_train1)\nmodel2=RandomForestRegressor(n_estimators=22).fit(X_train1, y_train1)\nplt.figure(figsize=[15,5])\nplt.bar(range(len(model1.feature_importances_)), model1.feature_importances_, width=0.5)\nplt.bar(range(len(model2.feature_importances_)), -model2.feature_importances_, width=0.5)\n\nimport math\nimport matplotlib.patches as mpatches\nxint = range(0, len(model1.feature_importances_))\nplt.xticks(xint)\nblue_patch = mpatches.Patch(color='b', label='Gradient Boosting')\ngreen_patch = mpatches.Patch(color='g', label='Random Forest')\nplt.legend(handles=[blue_patch,green_patch])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06790c21beae6732c414a05161aebd01948dbb8b"},"cell_type":"markdown","source":"Thus, we see that the following features (which have high importance in either of the methods) are most important estimators of our target variable.\n**'School Attendance Rate','Percent of Students Chronically Absent','Percent White','Economic Need Index','Distance','crime index','Average ELA Proficiency','Percent Black','Percent Hispanic'**.\n"},{"metadata":{"_uuid":"0a742e507b74f7fac6a955accbdb38d2b8da831d"},"cell_type":"markdown","source":"### 4.2 Year 2016 Ratio of number of students who register for the test to the number of students  who are enrolled "},{"metadata":{"_uuid":"1c2bbe56e4da6ee4dec670c2a6dbb002f1bd91f6"},"cell_type":"markdown","source":"### > train-test split"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ad50133b75c60424a7a4890b78a8f3d0801d5c98"},"cell_type":"code","source":"targets = ged_secure['REratio'].values\nfeatures = ged_secure[\n    ['Economic Need Index','School Income Estimate','Community School?','Percent Asian', 'Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Percent of Students Chronically Absent', 'Rigorous Instruction %','Collaborative Teachers %','Supportive Environment %', 'Effective School Leadership %',\n     'Strong Family-Community Ties %','Trust %','Average ELA Proficiency','Average Math Proficiency', 'Distance', 'crime index']].values\nX_train1, X_test1, y_train1, y_test1 =train_test_split(features, targets, test_size=0.1, random_state=1)\nX_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc081f30fe6d9fafb67c88daefeb498b1a86eb04"},"cell_type":"markdown","source":"### > Using F-Regression:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b3245ddf00f8fc405262d134c33ad397dda9819e"},"cell_type":"code","source":"from sklearn.feature_selection import f_regression\nf_regression(X_train1, y_train1, center=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"478102b4a0118203c43532f2534cc29d7e975c14"},"cell_type":"code","source":"a=f_regression(X_train1, y_train1, center=True)[0]\nplt.figure(figsize=[15,5])\nplt.bar(range(len(a)), a,width=0.5)\n\nimport math\nxint = range(0, len(a))\nplt.xticks(xint)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0cbccb472e8c0a51eb432b8d329b6c4b17bdc74"},"cell_type":"markdown","source":"**Thus, we see that the following features (which have a high F-score) are most important estimators of our target variable.     \nIn the order of precedence.......  **\n\n**1) Distance  **    \n**2) Percent Hispanic   **    \n**3) Percent Black  **    \n**4) Supportive Environment %   **    \n**5) Economic Need Index   **    \n**6) Collaborative Teachers %   **        \n**7) Student Attendance Rate  **     \n**8) crime index **   \n**9) Percent White **"},{"metadata":{"_uuid":"b0119d14e5854fc5652961e818e38e2939bc2f03"},"cell_type":"markdown","source":"### > Using Gradient Boosting and/or Random Forest Regressor\nImportance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity used to select the split points or another more specific error function. The feature importances are then averaged across all of the the decision trees within the model.\n\nRandom forest consists of a number of decision trees. Every node in the decision trees is a condition on a single feature, designed to split the dataset into two so that similar response values end up in the same set."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"d8367ecb131402ee132360419080a5cd896ae2b9"},"cell_type":"code","source":"y_train_gbr1, y_test_gbr1 =regression(GradientBoostingRegressor(max_depth=5, n_estimators=100), \n           X_train1, X_test1, y_train1)\n\nscores('Gradient Boosting Regressor \\nratio of no. of students who are enrolled to the no. of students who take the test', \n       y_train1, y_test1, y_train_gbr1, y_test_gbr1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"efb793ec2aaa9009e66dd8c16d78aad2d9adf190"},"cell_type":"code","source":"# n_estimators=The number of trees in the forest\ny_train_rfr1, y_test_rfr1 =regression(RandomForestRegressor(n_estimators=25), \n           X_train1, X_test1, y_train1)\n\nscores('Random Forest Regressor \\nratio',y_train1, y_test1, y_train_rfr1, y_test_rfr1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a8269564e3e0144c9d3a72ee66527f9e2e598ccd"},"cell_type":"code","source":"# plot feature importances\n\nmodel1=GradientBoostingRegressor(max_depth=7, n_estimators=100).fit(X_train1, y_train1)\nmodel2=RandomForestRegressor(n_estimators=22).fit(X_train1, y_train1)\nplt.figure(figsize=[15,5])\nplt.bar(range(len(model1.feature_importances_)), model1.feature_importances_, width=0.5)\nplt.bar(range(len(model2.feature_importances_)), -model2.feature_importances_, width=0.5)\n\nimport math\nxint = range(0, len(model1.feature_importances_))\nplt.xticks(xint)\nblue_patch = mpatches.Patch(color='b', label='Gradient Boosting')\ngreen_patch = mpatches.Patch(color='g', label='Random Forest')\nplt.legend(handles=[blue_patch,green_patch])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad62fabb51889c27072a12f1e834e3523ca9a826"},"cell_type":"markdown","source":"Thus, we see that the following features (which have high importance in either of the methods) are most important estimators of our target variable.\n**'Distance','Percent Black','Percent Hispanic','Economic Need Index','Distance','Strong Family-Community Ties %','Trust %',**"},{"metadata":{"_uuid":"05079a86721dddb26a9d143bf8ab1a026e47586a"},"cell_type":"markdown","source":"### 4.3 Year 2016 Ratio of number of students who appear for the to the number of students who are registered for the test"},{"metadata":{"_uuid":"55420a564fb9b53eb10c5831151f5e822210ab5e"},"cell_type":"markdown","source":"### > train-test split"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4ffde37c62334ad2eb8bd71f537f3cd0114901d6"},"cell_type":"code","source":"ged_secure1=ged_secure.dropna()\ntargets = ged_secure1['PRratio'].values\nfeatures = ged_secure1[\n    ['Economic Need Index','School Income Estimate','Community School?','Percent Asian', 'Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Percent of Students Chronically Absent', 'Rigorous Instruction %','Collaborative Teachers %','Supportive Environment %', 'Effective School Leadership %',\n     'Strong Family-Community Ties %','Trust %','Average ELA Proficiency','Average Math Proficiency', 'Distance', 'crime index']].values\nX_train1, X_test1, y_train1, y_test1 =train_test_split(features, targets, test_size=0.1, random_state=1)\nX_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7bf6a4f17e50bd06e59c2cb656346f7d509dbdb"},"cell_type":"markdown","source":"### > Using F-Regression:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e21af254ad177b6602af02ab73dc344d965df632"},"cell_type":"code","source":"from sklearn.feature_selection import f_regression\nf_regression(X_train1, y_train1, center=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5997f91168793c84608e47858314eab764329d78"},"cell_type":"code","source":"a=f_regression(X_train1, y_train1, center=True)[0]\nplt.figure(figsize=[15,5])\nplt.bar(range(len(a)), a,width=0.5)\n\nimport math\nxint = range(0, len(a))\nplt.xticks(xint)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b07368a5c5ed507b75728d635de49e81f7c07749"},"cell_type":"markdown","source":"**Thus, we see that the following features (which have a high F-score) are most important estimators of our target variable.     \nIn the order of precedence.......  **\n\n**1) Distance  **    \n**2) Percent Hispanic   **    \n**3) Percent Black  **    \n**4) Economic Need Index   **    \n**5) Average Math Proficiency   **   "},{"metadata":{"_uuid":"90411599103f0d744cbe76bb551bbda7aea23ad8"},"cell_type":"markdown","source":"### > Using Gradient Boosting and/or Random Forest Regressor\nImportance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity used to select the split points or another more specific error function. The feature importances are then averaged across all of the the decision trees within the model.\n\nRandom forest consists of a number of decision trees. Every node in the decision trees is a condition on a single feature, designed to split the dataset into two so that similar response values end up in the same set.\n"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b8ac571d50d6f7b85dfd736747de20152f6e2f13"},"cell_type":"code","source":"y_train_gbr1, y_test_gbr1 =regression(GradientBoostingRegressor(max_depth=5, n_estimators=100), \n           X_train1, X_test1, y_train1)\n\nscores('Gradient Boosting Regressor \\nratio of no. of students who are enrolled to the no. of students who take the test', \n       y_train1, y_test1, y_train_gbr1, y_test_gbr1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ece6fdc59be6f25c3aab116d6d5c6638ac2a5b2c"},"cell_type":"code","source":"# n_estimators=The number of trees in the forest\ny_train_rfr1, y_test_rfr1 =regression(RandomForestRegressor(n_estimators=25), \n           X_train1, X_test1, y_train1)\n\nscores('Random Forest Regressor \\nratio', \n       y_train1, y_test1, y_train_rfr1, y_test_rfr1)\n\n# plot feature importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5608eadcdcf98218df58fa713bacff9a8086a2be"},"cell_type":"code","source":"model1=GradientBoostingRegressor(max_depth=7, n_estimators=100).fit(X_train1, y_train1)\nmodel2=RandomForestRegressor(n_estimators=22).fit(X_train1, y_train1)\nplt.figure(figsize=[15,5])\nplt.bar(range(len(model1.feature_importances_)), model1.feature_importances_, width=0.5)\nplt.bar(range(len(model2.feature_importances_)), -model2.feature_importances_, width=0.5)\n\nimport math\nxint = range(0, len(model1.feature_importances_))\nplt.xticks(xint)\nimport matplotlib.patches as mpatches\n\nblue_patch = mpatches.Patch(color='b', label='Gradient Boosting')\ngreen_patch = mpatches.Patch(color='g', label='Random Forest')\nplt.legend(handles=[blue_patch,green_patch])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19eea31b1a570acbca2386c85630e9055ab099d0"},"cell_type":"markdown","source":"Thus, we see that the following features (which have high importance in either of the methods) are most important estimators of our target variable. **Economic Need Index , Percent Hispanic, Percent Black, Distance**.\n"},{"metadata":{"_uuid":"2e3c77b2a4bb6dee112caafc79776e3c6a6fd7d5"},"cell_type":"markdown","source":"### > From the above methods, we conclude that the most important features are as follows:\n\n* **Economic Need Index**\n* **School Attendance Rate**\n* **Distance**\n* **crime index**\n* **Percent Black**\n* **Percent Hispanic**\n* **Percent White (plays a major role as minority)**"},{"metadata":{"_uuid":"c0e47afbdf216a4302cb642b180d6ab2d03ceded"},"cell_type":"markdown","source":"# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"df3b787ba6a4927d94c338f69090abc563dcae84"},"cell_type":"markdown","source":"## 5. Obtaining feature weights"},{"metadata":{"_uuid":"c16c634bda4e3047cf525c5e9aa8be4e45c83344"},"cell_type":"markdown","source":">Before proceeding further, I'll normalize all features and bring them on the same scale so that none of the features acts to overpower the others. I'll be dividing all the features by their max values."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0b98207a3089603e3b656a203c93521ef1d70d08"},"cell_type":"code","source":"features = ged_secure1[\n    ['Economic Need Index','Community School?','Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Distance', 'crime index']]\nmin_vec=features.min(axis=0)\nmax_vec=features.max(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2bf6c086c15e55833ab4c058ec50694de65e8b4a"},"cell_type":"code","source":"features_normalized=(features.sub(features.mean(axis=0), axis=1))/ features.std(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"958b7a1bdaabfc2c72de0b77fb94036ae4ad72b2"},"cell_type":"code","source":"targets = ged_secure1['PEratio'].values\na=f_regression(features_normalized.values,targets, center=True)[0]\nf_regression(features_normalized.values,targets, center=True)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1ddd4caf06870753abd14d5e2a40487110ae4361"},"cell_type":"code","source":"targets = ged_secure1['PRratio'].values\nb=f_regression(features_normalized.values,targets, center=True)[0]\nf_regression(features_normalized.values,targets, center=True)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"83f88be7a99a252cc7de98bbc2a062bbc18440b0"},"cell_type":"code","source":"targets = ged_secure1['REratio'].values\nc=f_regression(features_normalized.values,targets, center=True)[0]\nf_regression(features_normalized.values,targets, center=True)[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b41548f0dfcfaed43d1c4c58dfc40029b10ab2f"},"cell_type":"markdown","source":"### > I shall consider the average of all the F-scores as weights of the features."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"933ae9121f3a1b4c7826dfed2d1b992e29ff40eb"},"cell_type":"code","source":"weights=(a+b+c)/3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d81ce3f5afa1aa9a4e8477e471ce71cc570c8383"},"cell_type":"markdown","source":"# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"733417a1dbd37061fc21f2c88a2ac464ab524fbc"},"cell_type":"markdown","source":"## 6. Ranking the schools"},{"metadata":{"_uuid":"4dca5b4a5ed8b56e31b55770502456a1f3aa8f84"},"cell_type":"markdown","source":"### > Normalizing the whole dataset"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"6d232c17422280f978f6f0f5fe5e122a2f4bd722"},"cell_type":"code","source":"features = df[['School Name', 'Location Code', 'District', 'Latitude', 'Longitude',\n       'Address (Full)', 'City', 'Zip','Economic Need Index','Community School?','Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Distance', 'crime index']]\nmin_vec=features[['Economic Need Index','Community School?','Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Distance', 'crime index']].min(axis=0)\nmax_vec=features[['Economic Need Index','Community School?','Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Distance', 'crime index']].max(axis=0)\n\nfeatures_normalized=(features[['Economic Need Index','Community School?','Percent Black', 'Percent Hispanic','Percent White', \n     'Student Attendance Rate','Distance', 'crime index']].sub(min_vec, axis=1))/ (max_vec-min_vec)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04ced2a5605450223fbb5dcd695c00c351e64807"},"cell_type":"markdown","source":"### > Weighed sum of features"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"fe38f729d7010c287801beb5f77a187e1b09287e"},"cell_type":"code","source":"weighed_features=features_normalized*weights\nfeatures['Score']=weighed_features.sum(axis=1)\nfeatures=features.sort_values('Score', ascending=False).drop_duplicates('School Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2ad74c712a7dadb6b3ddfca946c4dcfe77f62258"},"cell_type":"code","source":"features1=features[:10]\nfeatures1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c05ba192fb02001086c9bed4632450ba3d1094d0"},"cell_type":"markdown","source":"### > Top 10 Schools which require intervention"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5d6bd9087377bfe22076643b7bfc8513c3fd89a9"},"cell_type":"code","source":"map_1 = folium.Map(location=[40.755048, -73.926963],\n                   zoom_start=9.5,\n                   tiles='cartodbdark_matter')\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[0], popup=features1.reset_index(drop=False)['School Name'].loc[0]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[1], popup=features1.reset_index(drop=False)['School Name'].loc[1]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[2], popup=features1.reset_index(drop=False)['School Name'].loc[2]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[3], popup=features1.reset_index(drop=False)['School Name'].loc[3]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[4], popup=features1.reset_index(drop=False)['School Name'].loc[4]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[5], popup=features1.reset_index(drop=False)['School Name'].loc[5]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[6], popup=features1.reset_index(drop=False)['School Name'].loc[6]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[7], popup=features1.reset_index(drop=False)['School Name'].loc[7]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[8], popup=features1.reset_index(drop=False)['School Name'].loc[8]).add_to(map_1)\nfolium.Marker(features1.reset_index(drop=False)[['Latitude','Longitude']].loc[9], popup=features1.reset_index(drop=False)['School Name'].loc[9]).add_to(map_1)\n\n\ni=0\nfor lat, lon in zip(df['Latitude'], df['Longitude']):\n    folium.CircleMarker([lat, lon], color=step(df['Cluster'][i]), fill=True, radius=0.9).add_to(map_1)    \n    i+=1\n\nmap_1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8a7451473dc8f16efc8c1438ae4104083bac4a3"},"cell_type":"markdown","source":"**The top 10 schools represented along with the previous grouping generated by hierarchial clustering.**   \n\n**Click on the marker to the know the name of the Schools.**"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7dde823b917253bede6e55665f1f247a6d420e4a"},"cell_type":"code","source":"z=ged[['Program Site name','Latitude','Longitude','Borough']].dropna()\n\nimport branca.colormap as cm\nimport folium\nfrom folium import plugins\n\nstep = cm.StepColormap(\n    ['aqua','yellow','red'],\n    vmin=0.5, vmax=3.5,\n    index=[0.5,1.5,2.5],\n    caption='step'\n)\n    \nstep","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cf967c1949166085afbf262d76ca3b2021d751c"},"cell_type":"markdown","source":"* **Blue: CLuster 1**\n* **Yellow: Cluster 2**\n* **Red: Cluster 3**"},{"metadata":{"_uuid":"9336b05f6e77eaf3fd80546fe4489b8b4587c4e2"},"cell_type":"markdown","source":"# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"012bbef5412d2af6fc231611d994eaac2259d838"},"cell_type":"markdown","source":"## 7. Conclusion:\nAs is evident from the mapping, most of the schools belong to Cluster 2 which has the highest Percentage of Black and Hispanic students = 40.8% and 50% (as deduced earlier). Moreover, the crime index is higher in the areas of cluster 2 = 1.06. Student Attendance Rate seems to lowest for Cluster 2 = 91.34% with a higher percentage of students chronically absent = 25.77%. Average ELA and Math Proficiency are lowest for cluster 2. ewer students have score 4 in Grade 8 in cluster 2. Also, cluster 2 has the highest Economic Index.    \n\nThus this is consistent with our clustering results."},{"metadata":{"_uuid":"bdfb4ce24736919f16bcd56a905cd387842b101a"},"cell_type":"markdown","source":"# ............................................................................................................................"},{"metadata":{"_uuid":"46627c8d95f2d171f865915aac6b02e1a6e980db"},"cell_type":"markdown","source":"# This kernel is still in development process. Feel free to post your suggestions. Thank You."},{"metadata":{"_uuid":"fcddbb4d9e4702493e0e98515d73588a88db4892"},"cell_type":"markdown","source":"# ................................................................................................................................"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"69ff50e7eadce7dec26b7ad76a33d30db2dbfaa9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}