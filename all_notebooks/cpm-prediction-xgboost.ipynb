{"cells":[{"metadata":{"id":"VihEAU9sTKmI"},"cell_type":"markdown","source":"# 1. Importing Libraries"},{"metadata":{"id":"CQR5YHghTKmm","trusted":true},"cell_type":"code","source":"# Add required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n#from sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error,accuracy_score\n\nimport optuna\nseed =42 # for repeatability\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"W9mMp39-TKmr"},"cell_type":"markdown","source":"\n# 2. Getting Data"},{"metadata":{"id":"LMWabNo-TKmu","trusted":true},"cell_type":"code","source":"# Load data set\n# Add path for the data set\npath = \"../input/real-time-advertisers-auction/Dataset.csv\"\ndf = pd.read_csv(path)\nXact = df","execution_count":null,"outputs":[]},{"metadata":{"id":"aJ-xOKKxTKmv"},"cell_type":"markdown","source":"# 3. Understanding Data"},{"metadata":{"id":"LND6yz7LTKmx","outputId":"f04cf7e1-f239-40f8-ba06-f717b1600d56","trusted":true},"cell_type":"code","source":"df.head() ","execution_count":null,"outputs":[]},{"metadata":{"id":"WZQnfSbCTKm1","outputId":"8e63a3f7-be2a-444e-8edd-fa9cb2111024","trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"XjPxQdfxTKm2","trusted":true},"cell_type":"code","source":"# converting date column to datetime \ndf['date'] = pd.to_datetime(df['date'],errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data cleaning"},{"metadata":{"id":"BAuon4TdTKm5","outputId":"a1a7f696-15ee-4ac5-bb1f-02f7874a8ed2","trusted":true},"cell_type":"code","source":" df.isnull().sum() # Check the missing elements","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Data analysis"},{"metadata":{"id":"zdw-BCZvTKm7","outputId":"874b8c8f-ec1e-4e04-b61f-e8ec051db04b","trusted":true},"cell_type":"code","source":"df.info() # Check the data type of the variables","execution_count":null,"outputs":[]},{"metadata":{"id":"RlCYtbkN6lUT","trusted":true},"cell_type":"code","source":"# checking for duplicate rows\nprint(df.shape[0])\nprint(f'Number of duplicated rows: {df.shape[0] - df.drop_duplicates().shape[0]}')\nprint('dropping duplicates')\ndf = df.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"id":"4-c2drWZ6qFQ","outputId":"a01297a0-178c-4a28-bbcb-ddbf942e241c","trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"4upm5SBxoxO3","trusted":true},"cell_type":"code","source":"# Add varibles\ndf['weekday'] = df['date'].apply(lambda x:x.weekday())\ndf['View_perc'] = np.where(df['measurable_impressions']!=0,\n                           df['viewable_impressions']/df['measurable_impressions'],0)","execution_count":null,"outputs":[]},{"metadata":{"id":"O3MHoL02TKnA","outputId":"3a27b1dd-64d3-4b0a-beac-7c063bf4f4f0","scrolled":true,"trusted":true},"cell_type":"code","source":"df.nunique() # Count Distinct Values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Features selection"},{"metadata":{"id":"p_qtef1VTKnD","trusted":true},"cell_type":"code","source":"# We can infer from above that these columns only have one unqique value\n# so dropping it\ndf = df.drop(['integration_type_id','revenue_share_percent'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since it is mentioned in the problem description dropping columns as below\ndf = df.drop(['order_id', 'line_item_type_id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking if there are any categorical/object column?\n# All are either float or ints\nprint(df.select_dtypes(['object']).columns)","execution_count":null,"outputs":[]},{"metadata":{"id":"MZRdKp8MQR74"},"cell_type":"markdown","source":"Above analysis explained:\n1. order_id and line_item_type_id are dropped as mentioned in problem formulation\n\n2. integration_type_id and revenue_share_percent are dropped since both have only one unique category\n\n3. Catagorical variables (Which have unique values less than 12): \n\n    site_id, ad_type_id, device_category_id,       line_item_type_id,os_id, integration_type_id,monetization_channel_id, revenue_share_percent.\n\n4. Data types in the data set are 'Object', 'integer' and 'float'\n\n5. No missing values in the given features "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CPM (Cost per thousand impressions) calculation \n+ CPM = (revenue/impressions)*1000"},{"metadata":{"id":"0KsBEjaQ7DiF","trusted":true},"cell_type":"code","source":"df['CPM'] = np.where(df['measurable_impressions']!=0, (df['total_revenue']*100/df['measurable_impressions'])*1000,0)\ndf_corr = df # df for correlation analysis","execution_count":null,"outputs":[]},{"metadata":{"id":"IiK8K8tKKXnM","outputId":"0554dc84-7b9b-4986-893a-72851cb17206","trusted":true},"cell_type":"code","source":"df['CPM'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since we used 'total_revenue' and 'measurable inpressions' to calculate 'CPM' \n# we need to drop any one the feature\n# so dropping total_revenue\ndf = df.drop(['total_revenue'],axis=1)\ndf_fortest = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"e59ra7RHKd1y"},"cell_type":"markdown","source":"# 7. Modelling"},{"metadata":{},"cell_type":"markdown","source":"7.1 Approach 1 : ML model - XGBoost\n    * Modelling without removing outliers"},{"metadata":{"id":"RJwJHKowTKnH","trusted":true},"cell_type":"code","source":"# Modelling - Iteration 1\n# ML model\n\ny = df['CPM']\nX = df.drop(columns=['date',\"CPM\"]) # For modelling\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and testing data selection\n    * Selection based on date 06-22-2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = X.loc[df.date < pd.Timestamp('06-22-2019')]\nval_X = X.loc[df.date >= pd.Timestamp('06-22-2019')]\ntrain_y = y.loc[df.date < pd.Timestamp('06-22-2019')]\nval_y = y.loc[df.date >= pd.Timestamp('06-22-2019')]","execution_count":null,"outputs":[]},{"metadata":{"id":"GGD5X26w0EW7","outputId":"f901befb-3c93-43e2-e016-8f27a2ae7727","trusted":true},"cell_type":"code","source":"train_X.shape, train_y.shape, val_X.shape, val_y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost model fitting"},{"metadata":{"id":"ULmecGiTTKnI","outputId":"b3deeef1-4b53-4089-81fe-0b27b738cff6","scrolled":true,"trusted":true},"cell_type":"code","source":"model_xgb1 = xgb.XGBRegressor()\nmodel_xgb1.fit(train_X, train_y)\nxgb_preds = model_xgb1.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Error metric evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE:\", mean_absolute_error(val_y, xgb_preds))\nprint(\"MSE:\", mean_squared_error(val_y, xgb_preds))\nprint(\"R2:\",r2_score(val_y,xgb_preds))","execution_count":null,"outputs":[]},{"metadata":{"id":"bcMGzuzELZXJ"},"cell_type":"markdown","source":"As it can be seen above metrics are bad, we need to explore more to understand what might be going wrong\n1. Lets look at the 'CPM' variable distribution"},{"metadata":{"id":"fm4l1s0wLXve","outputId":"b849f3a0-5882-42cb-f13b-586d4935bc3d","trusted":true},"cell_type":"code","source":"# Distribution of CPM\nsns.distplot(df['CPM'],bins=1000)\nplt.ylabel(\"Density\")\nplt.ylim((0,0.000001))","execution_count":null,"outputs":[]},{"metadata":{"id":"GECBXC5yL8BU","outputId":"44302a97-0f63-4562-e37e-5a2bc61c77a3","trusted":true},"cell_type":"code","source":"df['CPM'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"b-fe4uJlL6sL"},"cell_type":"markdown","source":"As it can be seen from above distribtuon plot and value counts,that there are plenty of zeros and as well as outliers as fars as till ~3k. Let us remove outlier first from data and see if metrics improves"},{"metadata":{},"cell_type":"markdown","source":"7.2 Approach 2 : ML model - XGBoost\\\n    * Model after removing outliers"},{"metadata":{},"cell_type":"markdown","source":"Outliers removel"},{"metadata":{"id":"xgCmd3vQMXyj","trusted":true},"cell_type":"code","source":"# Remove outliers \ndf_1 = df[df.CPM < df.CPM.quantile(.95)]\ndf_1 = df_1[df_1.CPM >= 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=sns.distplot(df_1['CPM'], kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"})\nplt.ylabel(\"Density\")\n#plt.ylim((0,0.000001))","execution_count":null,"outputs":[]},{"metadata":{"id":"IhSvv9XyMrYG","trusted":true},"cell_type":"code","source":"# For modelling\nX = df_1.drop(columns=['date',\"CPM\"]) \ny = df_1['CPM']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and testing points\n    * Selection based on date 06-22-2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = seed)\ntrain_X = X.loc[df_1.date < pd.Timestamp('06-22-2019')]\nval_X = X.loc[df_1.date >= pd.Timestamp('06-22-2019')]\ntrain_y = y.loc[df_1.date < pd.Timestamp('06-22-2019')]\nval_y_o = y.loc[df_1.date >= pd.Timestamp('06-22-2019')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost model fitting"},{"metadata":{"id":"qU8anTL5LP_O","outputId":"9af78f3d-8d79-4d0a-af19-fae7b80f8777","trusted":true},"cell_type":"code","source":"# Model fitting using XGBoost\nmodel_xgb2 = xgb.XGBRegressor()\nmodel_xgb2.fit(train_X, train_y)\nxgb_preds_noout = model_xgb2.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Error metric evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE:\", mean_absolute_error(val_y_o, xgb_preds_noout))\nprint(\"MSE:\", mean_squared_error(val_y_o, xgb_preds_noout))\nprint(\"R2:\",r2_score(val_y_o,xgb_preds_noout))","execution_count":null,"outputs":[]},{"metadata":{"id":"Wiw123rdNAdB"},"cell_type":"markdown","source":"Model performance did improve a bit, it seems that we need to deal with zeros first as it can be reason that heavy tail making our model biased towards it\n1. We are going to use two staged approach here\n2. Stage 1: Build model to classify if the CPM is zero or not\n3. Stage 2: regression model to regress for predicted non zero class\n4. Ensemble this to get final predictions"},{"metadata":{},"cell_type":"markdown","source":"7.3 Approach 3 : ML model - XGBoost\\\n    * Modelling after removing outliers\\\n    * Stage 1: Build model to classify if the CPM is zero or not\\\n    * Stage 2: regression model to regress for predicted non zero class\\\n    * Ensemble this to get final predictions\\"},{"metadata":{},"cell_type":"markdown","source":"Classifying CPM data"},{"metadata":{"id":"vEfD3YYSHDpC","trusted":true},"cell_type":"code","source":"df['CPM_cat'] = np.where(df[\"CPM\"]>0,1,0)","execution_count":null,"outputs":[]},{"metadata":{"id":"t-eKJyTqN7uT","outputId":"b2712181-73bc-4640-8b6a-4891652374fe","trusted":true},"cell_type":"code","source":"df['CPM_cat'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"TIY_Z4v3OBBc"},"cell_type":"markdown","source":"We can use accuracy as metric as it can be seen that the classes are nearly balanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_clf = df['CPM_cat']\nX_clf = df.drop(columns=['date',\"CPM\",'CPM_cat']) # For modelling","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and testing points\n    * Selection based on date 06-22-2019"},{"metadata":{"id":"BXXXH_27OYoN","trusted":true},"cell_type":"code","source":"train_X_clf = X_clf.loc[df.date < pd.Timestamp('06-22-2019')]\nval_X_clf = X_clf.loc[df.date >= pd.Timestamp('06-22-2019')]\ntrain_y_clf = y_clf.loc[df.date < pd.Timestamp('06-22-2019')]\nval_y_clf = y_clf.loc[df.date >= pd.Timestamp('06-22-2019')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost model fitting"},{"metadata":{"id":"V7azByTVMvkX","outputId":"03197161-572e-4195-dc58-375bedb338e8","trusted":true},"cell_type":"code","source":"model_xgb_clf = xgb.XGBClassifier()\nmodel_xgb_clf.fit(train_X_clf, train_y_clf)\nxgb_preds_clf = model_xgb_clf.predict(val_X_clf)\nprint('acc',accuracy_score(val_y_clf,xgb_preds_clf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyper parameter optimization\n     for classified CPM data"},{"metadata":{"id":"WKDH8qVFTbXA","trusted":true},"cell_type":"code","source":"# Function used in hyper parameter optimization with the parameters\n\ndef objective(trial):\n  \n\n    param = {\n        \"silent\": 1,\n        \"objective\": \"binary:logistic\",\n        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n        \"max_depth\":trial.suggest_int(\"max_depth\",4,10),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",.6,1.),\n        \"subsample\":trial.suggest_float(\"subsample\",.7,1.),\n\n    }\n\n    y_clf = df['CPM_cat']\n    X_clf = df.drop(columns=['date',\"CPM\",'CPM_cat']) # For modelling\n    \n    # train_X_clf, val_X_clf, train_y_clf, val_y_clf = train_test_split(X_clf, y_clf, random_state = seed)\n    train_X_clf = X_clf.loc[df.date < pd.Timestamp('06-22-2019')]\n    val_X_clf = X_clf.loc[df.date >= pd.Timestamp('06-22-2019')]\n    train_y_clf = y_clf.loc[df.date < pd.Timestamp('06-22-2019')]\n    val_y_clf = y_clf.loc[df.date >= pd.Timestamp('06-22-2019')]\n\n    model_xgb_clf = xgb.XGBClassifier(**param)\n    model_xgb_clf.fit(train_X_clf, train_y_clf)\n    xgb_preds_clf = model_xgb_clf.predict(val_X_clf)\n    print('acc',accuracy_score(val_y_clf,xgb_preds_clf))\n\n\n    return accuracy_score(val_y_clf,xgb_preds_clf)","execution_count":null,"outputs":[]},{"metadata":{"id":"ckbKr8S1UePV","outputId":"e403f621-b302-403f-d4ea-b2824ff2ce43","trusted":true},"cell_type":"code","source":"# Parameters after hyper parameter optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit model for classifier"},{"metadata":{"id":"UNUN57VNWfBq","trusted":true},"cell_type":"code","source":"model_xgb_clf = xgb.XGBClassifier(**study.best_params)\nmodel_xgb_clf.fit(train_X_clf, train_y_clf)\nxgb_preds_clf = model_xgb_clf.predict(val_X_clf)\nprint('acc',accuracy_score(val_y_clf,xgb_preds_clf))","execution_count":null,"outputs":[]},{"metadata":{"id":"LNixmTZCXZhZ","trusted":true},"cell_type":"code","source":"X.shape,df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oulier removal"},{"metadata":{"id":"pEcqoiDHPDWM","trusted":true},"cell_type":"code","source":"df = df[df['CPM']<np.percentile(df['CPM'],95)]\ndf = df[df['CPM']>=0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"jjBBNzcyO0I5","trusted":true},"cell_type":"code","source":"df['CPM_cat_pred'] = list(model_xgb_clf.predict(df[X.columns]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CPM_cat_pred'].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model fitting after hyper parameter optimization and outlier removal"},{"metadata":{"id":"lXYsY4g8O9v-","trusted":true},"cell_type":"code","source":"y_reg = df['CPM']\nX_reg = df.drop(columns=['date',\"CPM\",'CPM_cat']) # For modelling","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and testing points\n    * Selection based on date 06-22-2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X_reg = X_reg.loc[df.date < pd.Timestamp('06-22-2019')]\nval_X_reg = X_reg.loc[df.date >= pd.Timestamp('06-22-2019')]\ntrain_y_reg = y_reg.loc[df.date < pd.Timestamp('06-22-2019')]\nval_y_reg = y_reg.loc[df.date >= pd.Timestamp('06-22-2019')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and testing points\\\n    * Selection based on date 06-22-2019"},{"metadata":{},"cell_type":"markdown","source":"XGBoost model fitting"},{"metadata":{"id":"uNAszQfbPRQf","trusted":true},"cell_type":"code","source":"model_xgb_reg = xgb.XGBRegressor()\nmodel_xgb_reg.fit(train_X_reg, train_y_reg)\nxgb_preds_reg = model_xgb_reg.predict(val_X_reg)\n\nprint(\"MAE:\", mean_absolute_error(val_y_reg, xgb_preds_reg))\nprint(\"MSE:\", mean_squared_error(val_y_reg, xgb_preds_reg))\nprint(\"R2:\",r2_score(val_y_reg,xgb_preds_reg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"7.4 Approach 4\\\n     * Feature seletion based on correlation analysis "},{"metadata":{},"cell_type":"markdown","source":"Correlation analysis - using heatmap "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correalation between each variables \ndf_fortest = df_corr.drop(['total_revenue'],axis=1)\nplt.figure(figsize=(16,8))\nsns.heatmap(df_fortest.corr(),annot = True,cmap=\"YlGnBu\",fmt='.1g')\n\n# Inference\n# Total and viewable are are highly correlated(>0.85) with total impressions\n# Total and viewable are dropped from the data set\n\ndf_fortest = df_fortest.drop(['measurable_impressions','viewable_impressions'],axis=1)\ndf_fortest.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model selction"},{"metadata":{"id":"lXYsY4g8O9v-","trusted":true},"cell_type":"code","source":"y_reg_cor = df_fortest['CPM']\nX_reg_cor = df_fortest.drop(columns=['date','CPM']) # For modelling","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and testing points\n    * Selection based on date 06-22-2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X_reg_cor = X_reg_cor.loc[df_fortest.date < pd.Timestamp('06-22-2019')]\nval_X_reg_cor = X_reg_cor.loc[df_fortest.date >= pd.Timestamp('06-22-2019')]\ntrain_y_reg_cor = y_reg_cor.loc[df_fortest.date < pd.Timestamp('06-22-2019')]\nval_y_reg_cor = y_reg_cor.loc[df_fortest.date >= pd.Timestamp('06-22-2019')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost model fitting"},{"metadata":{"id":"uNAszQfbPRQf","trusted":true},"cell_type":"code","source":"model_xgb_reg_cor = xgb.XGBRegressor()\nmodel_xgb_reg_cor.fit(train_X_reg_cor, train_y_reg_cor)\nxgb_preds_reg_cor = model_xgb_reg_cor.predict(val_X_reg_cor)\n\nprint(\"MAE:\", mean_absolute_error(val_y_reg_cor, xgb_preds_reg_cor))\nprint(\"MSE:\", mean_squared_error(val_y_reg_cor, xgb_preds_reg_cor))\nprint(\"R2:\",r2_score(val_y_reg_cor,xgb_preds_reg_cor))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Further study is not required as mentioned in approach 2 (removal of outliers) and approach 3 ( Ensembling regression and classification after Hyper parameter optimization)\\\nSince this approach gives similar error metrics compared to approach 1. Upgrading this will provide outcomes similar to approach 2 and approach 3. So the further study is ignored."},{"metadata":{},"cell_type":"markdown","source":"# Model selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# R2 error comparison\nprint(\"R2_1:\",r2_score(val_y,xgb_preds))\nprint(\"R2_2:\",r2_score(val_y_o,xgb_preds_noout))\nprint(\"R2_3:\",r2_score(val_y_reg,xgb_preds_reg))\nprint(\"R2_4:\",r2_score(val_y_reg_cor,xgb_preds_reg_cor))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MSE error comparison\nprint(\"MSE_1:\", mean_squared_error(val_y, xgb_preds))\nprint(\"MSE_2:\", mean_squared_error(val_y_o, xgb_preds_noout))\nprint(\"MSE_3:\", mean_squared_error(val_y_reg, xgb_preds_reg))\nprint(\"MSE_4:\", mean_squared_error(val_y_reg_cor, xgb_preds_reg_cor))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE error\nprint(\"MAE_1:\", mean_absolute_error(val_y, xgb_preds))\nprint(\"MAE_2:\", mean_absolute_error(val_y_o, xgb_preds_noout))\nprint(\"MAE_3:\", mean_absolute_error(val_y_reg, xgb_preds_reg))\nprint(\"MAE_4:\", mean_absolute_error(val_y_reg_cor, xgb_preds_reg_cor))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the error metric model from approach 3 is choosed as best fit to the data.\nFor example, MAE error is reduced around 41%\\\nApporch 3 consists: \\\n    * Model bulit with XGBoost ML algorithm\\\n    * Outliers are not considered in CPM\\\n    * Hyper parameter optimization is carried out to identify the best parameter combinations for XGBoost\\\n    * Error metric comparison with approach 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_df= pd.DataFrame({})\nbest_df['CPM_actual']= val_y_reg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_df['Pred_CPM'] = xgb_preds_reg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Revenue calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"revenue_df = pd.DataFrame({'Actual_Impressions': val_X_reg['total_impressions'].values,  'CPM_actual': val_y_reg, \n                           'Pred_CPM': best_df['Pred_CPM'].values})\n\nrevenue_df['Pred_Rev'] = revenue_df['Pred_CPM'] * revenue_df['Actual_Impressions'] / (1000 * 100)\nrevenue_df['Pred_Rev'] = revenue_df['Pred_Rev'].clip(lower=0)\nrevenue_df.sample(n=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Questions"},{"metadata":{},"cell_type":"markdown","source":"1. What is the potential revenue range our publisher can make in July?"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Average revenue of june month:', np.round(Xact[\"total_revenue\"].mean(),2))\nP =np.round(revenue_df[\"Pred_Rev\"].mean(),2)\nprint('Predicted revenue range of july month:', P)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. What is the reserve prices that he/she can set ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Reserve price of june month:', np.round(best_df[\"CPM_actual\"].max(),2))\nprint('Predicted reserve price of july month:',np.round(best_df[\"Pred_CPM\"].max(),2))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}