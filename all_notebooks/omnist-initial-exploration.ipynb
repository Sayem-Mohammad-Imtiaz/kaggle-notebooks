{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n---\n# 1) Overhead-MNIST Initial Data Exploration\n* Purpose:\n> This notebook is intended to serve as a data familiarization starting point. It contains general statistics and insights regarding the overall population that can be used to inform subsequent model construction and optimization. There are no machine learning algorithms utilized; hence, an accelerator is not required.","metadata":{}},{"cell_type":"markdown","source":"---\n# 2) Installs & Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\n%matplotlib inline\n\nfrom skimage import io\n\n# Set global plot values for uniformity\nrcParams['figure.facecolor'] = 'lightgray'\nrcParams['figure.figsize'] = (13, 5)\n\n# Useful functions\ndef sp(int):\n    # Returns a string of blank spaces of length int\n    return ' ' * int","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 3) Load & Inspect Files","metadata":{}},{"cell_type":"code","source":"# Store useful paths\npath = '../input/overheadmnist/overhead/'\npath_tr = path + 'training'\npath_ts = path + 'testing'\n\n# Save files as dataframes\ntrain = pd.read_csv(path + 'train.csv')\ntest = pd.read_csv(path + 'test.csv')\nlabels = pd.read_csv(path + 'labels.csv')\nclasses = pd.read_csv(path + 'classes.csv')\n\nclasses2 = classes.drop(['class', 'label'], axis = 1)\nclasses2.index = classes['class']\n\n# Store names and frames\ndf_lst = ['train', 'test', 'classes', 'classes2', 'labels']\ndf_lst2 = [train, test, classes, classes2, labels]\n\n# View dataframes\nprint(sp(25) + 'DataFrames\\n')\nfor i, df in enumerate(df_lst2):\n    print('{}:\\n{}\\n\\n'\n          .format(df_lst[i], df.head().iloc[:, :8]), \n          end = '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 4) Data Exploration","metadata":{}},{"cell_type":"markdown","source":"## Basic Information & Descriptions","metadata":{}},{"cell_type":"code","source":"# View info\nprint(sp(25) + 'DataFrame Info\\n')\nfor i, df in enumerate(df_lst2):\n    print(df_lst[i] + ':')\n    print('{}\\n\\n'\n          .format(df.info()), \n          end = '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View statistics\nprint(sp(25) + 'Descriptive Statistics\\n')\nfor i, df in enumerate(df_lst2):\n    print('{}:\\n{}\\n\\n'\n          .format(df_lst[i], df.describe().iloc[:, :5]), end = '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save useful values\ntot_tr = len(train)\ntot_ts = len(test)\ntot_pics = tot_tr + tot_ts\nnum_classes = len(classes)\nclss_lst = classes['class'].values\n\nts_tr_ratio = round(tot_ts / tot_tr, 3)\n\n# Display pertinent data\nprint('Total pics: {}    Classes: {}    Training: {}    Test: {}'\n     .format(tot_pics, num_classes, tot_tr, tot_ts))\nprint('\\nTest/Training ratio: {}\\n\\nClasses: \\n{}'\n     .format(ts_tr_ratio, clss_lst))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remarks\nThere are a total of 9584 images in the entire set. The train and test splits contain 8519 and 1065 labeled examples, respectively. Each row in the dataframe represents a labeled, 28x28, grayscale satellite image with no missing values. For the interim, label fidelity is assumed to be above 95%.\n\nThere are 10 classes:\\\ncar, harbor, helicopter, oil_gas_field, parking_lot, plane, runway_mark, ship, stadium, and storage_tank.","metadata":{}},{"cell_type":"markdown","source":"## Distributions","metadata":{}},{"cell_type":"code","source":"# Bar chart\nplt.figure(tight_layout = True)\nclasses2.plot.bar(figsize = (12, 5), ec = 'k', stacked = True, \n                  rot = 90, title = 'Population Comparisons')\nplt.xlabel(None)\nplt.legend(loc = 'lower right')\nplt.show()\n\n# Pie chart\nplt.figure(tight_layout = True)\nclasses2.plot.pie(subplots = True, figsize = (12, 5), legend = False,  \n                  title = 'Population Distributions')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remarks\nThe training and test sets share the same population distribution, with each showing significantly fewer helicopter examples. The runway_mark and stadium categories also have slightly less than average representation. While notable, these differences are unlikely to impact initial training or evaluation.","metadata":{}},{"cell_type":"markdown","source":"## Class Size Comparisons","metadata":{}},{"cell_type":"code","source":"# Save and display pertinent variables\ndesc = classes.describe()\n\ntr_mean = int(round(desc.loc['mean', 'train_count']))\nts_mean = int(round(desc.loc['mean', 'test_count']))\n\ntr_least = classes['train_count'].min()\ntr_most = classes['train_count'].max()\n\nts_least = classes['test_count'].min()\nts_most = classes['test_count'].max()\n\nprint('Average samples per class - \\n{}Train: {}\\n{}Test: {}'\n     .format(sp(30), tr_mean, sp(30), ts_mean))\n\nprint('\\nMost represented classes - \\n{}\\n\\n{}\\n{}'\n      .format(sp(25) + 'harbor, plane, ship', \n              sp(30) + 'Train: ' + str(tr_most),\n              sp(30) + 'Test: ' + str(tr_least - 1)))\n\nprint('\\nLeast represented class - \\n{}\\n\\n{}\\n{}'\n      .format(sp(25) + 'helicopter', \n              sp(30) + 'Train: ' + str(tr_least),\n              sp(30) + 'Test: ' + str(classes['test_count'].min())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Ratios of pictures in each class compared to the total,' + \n      '\\nas well as the least and most populous classes:')\n\nfor i in range(num_classes):\n    clss = clss_lst[i]\n    tr, ts = classes.iloc[i, -2:].values\n    tr_frac = round(tr / tot_tr, 3)\n    ts_frac = round(ts / tot_ts, 3)\n    tr_sm = round(tr / tr_least, 3)\n    tr_lg = round(tr / tr_most, 3)\n    ts_sm = round(ts / ts_least, 3)\n    ts_lg = round(ts / ts_most, 3)\n    print('\\n{}{} -\\n{}ratio to tot -    Train: {}    Test: {}'\n          .format(sp(3), clss, sp(10), tr_frac, ts_frac) + \n          '\\n{}ratio to min -    Train: {}    Test: {}'\n          .format(sp(10), tr_sm, ts_sm) + \n          '\\n{}ratio to max -    Train: {}    Test: {}'\n          .format(sp(10), tr_lg, ts_lg))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 5) View Sample Images\n* Collected and displayed with scikit-image.","metadata":{}},{"cell_type":"code","source":"# Create multi-pic display\nprint(sp(40) + 'Training Examples')\n\n# Subplot placement indexer\nidx = 1\n\nplt.figure(figsize = (12, 12), tight_layout = True)\nfor clss in clss_lst:\n    ic = io.ImageCollection('../input/overheadmnist/overhead/training/' + clss + '/*.jpg')\n    for i in range(6):\n        plt.subplot(num_classes, 6, idx)\n        _ = io.imshow(ic[i])\n        plt.axis('off')\n        plt.title(clss)\n        idx += 1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Single pic examples\nidx = 1\n\nplt.figure(figsize = (15, 20), tight_layout = False)\nfor clss in clss_lst:\n    ic = io.ImageCollection('../input/overheadmnist/overhead/training/' + clss + '/*.jpg')\n    for i in range(1):\n        plt.subplot(num_classes, 5, idx)\n        _ = io.imshow(ic[i])\n        plt.axis('off')\n        plt.title(clss)\n        idx += 1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remarks\nEach picture contains object variants from mere edges to single, or multilple, instances of the indicated category. The sample images are accurately labeled, which bodes well for testing very basic models, and lends confidence to the assumption that labels are correct. \n\n*Note:*\\\nThe first plot omits title and picture in that same position regardless of the input. Manual inspection of the storage_tank pictures shows no problem with displaying the missing image and is likely due to rendering issues in this notebook. If the problem persists it could be an indication of some form of bug. ","metadata":{}},{"cell_type":"markdown","source":"---\n# 6) Conclusion\nThe Overhead-MNIST dataset is composed of 9584 grayscale image arrays of shape (1, 28, 28), four .csv files containing either flattened picture arrays or label mapping/summary data, and ubyte files. There are 784 pixels per picture, and the raw arrays are not normalized. The ratio of test to train data is .125, while both share matching internal class distributions. \n\nThe average train class size is 852, while the average test class size is 107. Helicopters bear the least representation with only 655 training and 82 test entries. \nThis accounts for approximately 7.7% of the data, while car, harbor, oil_gas_field, parking_lot, plane, ship, and storage_tank compose around 10.4% on average. The remaining two classes, runway_mark and stadium, comprise 9.4% and 9.9% of the training data respectively. \n\n*Model Creation, Training, & Validation:*\\\nDuring baseline establishment avoid hyperparameter adjustments. Raw data augmentation should be strictly limited to array normalization. The presence of dissimilar class sizes necessitates stratification when further splitting the training set into train and validation sets. The given test set will be held unseen and used for final model scoring.\n\n*Image Processing:*\\\nDetailed image processing is presently a low priority; it will become a focus only during performance optimization. In future explorations,  various techinques will be employed to augment the images. Model performance will then be compared and contrasted until optimum hyper-parameter settings are achieved. Normalization will take place during filtering and model ingestion preparation. Multiple filters can be applied for enhanced edge detection, contrast, and more. Model fine tuning could include determining a combination of size, filter applications, etc., that satisfies storage space and run time requirements at the cost of some yet unkown.\n","metadata":{}},{"cell_type":"markdown","source":"## Next Steps\n* Model comparison with Pycaret\n* Exploratory Data Analysis (EDA)\n---\n---","metadata":{}}]}