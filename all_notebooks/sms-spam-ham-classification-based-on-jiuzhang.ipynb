{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as plt\nimport re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"data_dir = '../input/'\ndf = pd.read_csv(data_dir + 'spam.csv', encoding='latin-1')\nprint(df.head()) # v1 (column 0) = labels, v2 (column 1) = email contents\nprint(df.shape) # (5572, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb5d9663683daa2608a640a3f1a3933c46dfbede"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndata_train, data_test, labels_train, labels_test = train_test_split(df.v2,\n                                                                    df.v1,\n                                                                   test_size=0.2,\n                                                                   random_state=0)\nprint(data_train.shape)\nprint(data_test.shape)\nprint(labels_train.shape)\nprint(labels_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3ce893e3cf35b72eab718c2f8fb7bf6614b2b2e"},"cell_type":"code","source":"def preprocessing_word(word):\n    word = word.lower() # lowercase\n#     word = re.sub(\"[^a-zA-Z0-9]\",\" \", word) # tokenization\n#     word = wordnet_lemmatizer.lemmatize(word) # lemmatization\n#     if word not in stopwords.words('english'): # remove stop words\n#         return word\n    return word\n\ndef generate_vocabulary(documents):\n    vocabulary = {}\n    for document in documents:\n        words = document.split()\n        for index, word in enumerate(words):\n            word = preprocessing_word(word)\n            if word not in vocabulary and word is not None:\n                vocabulary[word] = index\n    return vocabulary\n\nvocabulary = generate_vocabulary(data_train)\nprint(len(vocabulary.keys()))\nprint(list(vocabulary.items())[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09d8dc6b926e093f9fa6c7e6145a4f6417558250"},"cell_type":"code","source":"def document_2_vector(vocabulary, document):\n    document_vector = np.zeros(len(vocabulary.keys()))\n    words = document.split()\n#     new_words = []\n    for word in words:\n        word = preprocessing_word(word)\n        if word in vocabulary and word is not None:\n            document_vector[vocabulary[word]] += 1\n#         elif word is not None:\n#             print(word)\n#             new_words.append(word)\n#     return document_vector, new_words\n    return document_vector\n\ndef documents_2_matrix(vocabulary, documents):\n    train_matrix = []\n#     new_words_matrix = []\n    for document in documents:\n#         document_vector, new_words = document_2_vector(vocabulary, document)\n        document_vector = document_2_vector(vocabulary, document)\n        train_matrix.append(document_vector)\n    return train_matrix\n\n# example = document_2_vector(vocabulary, \"we are good good student students hfsdkjhiuhe\")\n# print(example)\n# print(example[vocabulary['good']], example[vocabulary['student']])\n\ntrain_matrix = documents_2_matrix(vocabulary, data_train.values)\nprint(len(train_matrix))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"077edcc4d26d8f76e59efaa37c8ee6668e011411"},"cell_type":"code","source":"def naive_bayes_train(train_matrix, labels_train):\n    num_docs = len(train_matrix)\n    num_words = len(train_matrix[0])\n    \n    # 1darray, each cell represents the occurrence of each word as spam/ham\n    spam_word_counter = np.ones(num_words)\n    ham_word_counter = np.ones(num_words)\n    \n    # total number of spam/ham words\n    spam_total_count = 0\n    ham_total_count = 0\n    \n    # num of spam/ham docs\n    spam_count = 0\n    ham_count = 0\n    \n    for i in range(num_docs):\n        if labels_train[i] == 'ham':\n            ham_word_counter += train_matrix[i]\n            ham_total_count += sum(train_matrix[i])\n            ham_count += 1\n        else:\n            spam_word_counter += train_matrix[i]\n            spam_total_count += sum(train_matrix[i])\n            spam_count += 1\n    \n    # spam/ham probability for each word with Laplace Smoothing\n    p_spam_vector = np.log(spam_word_counter / (spam_total_count + num_words))\n    p_ham_vector = np.log(ham_word_counter / (ham_total_count + num_words))\n    \n    p_spam = np.log(spam_count / num_docs)\n    p_ham = np.log(ham_count / num_docs)\n    \n    return p_spam_vector, p_spam, p_ham_vector, p_ham\n\np_spam_vector, p_spam, p_ham_vector, p_ham = naive_bayes_train(train_matrix, labels_train.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ce495569d81bfee09d1a9808d3f4259f115ed57"},"cell_type":"code","source":"def predict(test_word_vector, p_spam_vector, p_spam, p_ham_vector, p_ham):\n    spam = sum(test_word_vector * p_spam_vector) + p_spam\n    ham = sum(test_word_vector * p_ham_vector) + p_ham\n    return 'spam' if spam > ham else 'ham'\n\npredictions = []\nfor document in data_test.values:\n    test_word_vector = document_2_vector(vocabulary, document)\n    ans = predict(test_word_vector, p_spam_vector, p_spam, p_ham_vector, p_ham)\n    predictions.append(ans)\n\nprint(len(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d126e3ecfca5739264f2db37fca0318cf9dc1074"},"cell_type":"code","source":"print(accuracy_score(labels_test, predictions))\nprint(classification_report(labels_test, predictions))\nprint(confusion_matrix(labels_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba976e3255e617c33a795d199195f1f3c64da72b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}