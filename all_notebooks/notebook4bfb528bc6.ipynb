{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hello, this is my final project for the course Intro to AI. I will try to use AI in order to predict the evolution of Bitcoin."},{"metadata":{},"cell_type":"markdown","source":"### Set Up"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#usefull when cells take time\ndef progressBar(current, total, barLength = 20):\n    percent = float(current) * 100 / total\n    arrow   = '-' * int(percent/100 * barLength - 1) + '>'\n    spaces  = ' ' * (barLength - len(arrow))\n\n    print('Progress: [%s%s] %d %%' % (arrow, spaces, percent), end='\\r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### My simple database"},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin = pd.read_csv('Bitcoin_data.csv')\nbitcoin\n#evolution of bitcoin per hours, with 28587 hours","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin = bitcoin.reindex(index=bitcoin.index[::-1])\nbitcoin.reset_index(inplace=True, drop=True)\nbitcoin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Result_BTC is the pourcentage of the increased value of bitcoin for the next hour. Classification is 1 if the value increased the next hour, 0 if it stagnates and -1 if it descreases.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = bitcoin.iloc[:28000, :]\ntest_set = bitcoin.iloc[28001:, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = train_set.corr()\ncorr_matrix[\"Classification\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix[\"Result\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlations are not very good, but later I will find interesting results nonetheless."},{"metadata":{},"cell_type":"markdown","source":"## Preparation for machine learning"},{"metadata":{},"cell_type":"markdown","source":"### Trying to predict the exact result"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_set[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_test = test_set[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_train\n#after several try, I decided to keep only these features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_set[\"Result\"].values\ny_test = test_set[\"Result\"].values\n\ny_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\n\nbitcoin_train_predictions = lin_reg.predict(X_train)\nbitcoin_train_predictions\n\nfrom sklearn.metrics import mean_squared_error\n\nlin_mse = mean_squared_error(y_train, bitcoin_train_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CROSS VALIDATION\nfrom sklearn.model_selection import cross_val_score\n\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n    \nlin_scores = cross_val_score(lin_reg, X_train, y_train,\n                             scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error is to large"},{"metadata":{},"cell_type":"markdown","source":"### Decision tree regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = bitcoin[[\"Open\",\"High\",\"Low\",\"Close\"]], bitcoin['Result']\nx_train = X_train\nx_valid = X_test\ny_valid = y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape, y_train.shape, x_valid.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor()\nmodel.fit(x_train,y_train)\nmodel.score(x_train,y_train), model.score(x_valid,y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model seems to overfit the data. Let's try to regularize it."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat = model.predict(x_valid)\ny_m = y_valid.mean()\n\nss_res = ((y_valid - y_hat)**2).sum()\nss_tot = ((y_valid - y_m)**2).sum()\nr_squared = 1 - ss_res/ss_tot\nr_squared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_train, score_valid = [],[]\nmsl = [i for i in range(1,15)]\nfor m in msl:\n    model = DecisionTreeRegressor(min_samples_leaf=m)\n    model.fit(x_train,y_train)\n    print(m, model.score(x_train,y_train), model.score(x_valid,y_valid))\n    score_train.append(model.score(x_train,y_train))\n    score_valid.append(model.score(x_valid,y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(msl, score_train)\nplt.plot(msl, score_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CROSS VALIDATION\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X_train, y_train,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)\n\n\ndisplay_scores(tree_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model perform poorly, even regularized."},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor(random_state=42)\nforest_reg.fit(X_train, y_train)\nbitcoin_train_predictions = forest_reg.predict(X_train)\nforest_mse = mean_squared_error(y_train, bitcoin_train_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CROSS VALIDATION\n\n#from sklearn.model_selection import cross_val_score\n\n#forest_scores = cross_val_score(forest_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n#forest_rmse_scores = np.sqrt(-forest_scores)\n#display_scores(forest_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uncomment to execute this cross validation, but it takes a lot of time and the error is still to important"},{"metadata":{},"cell_type":"markdown","source":"## In this part we will use classification models in order to try to predict if the bitcoin will increase (True) or not (False)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bitcoin['Increase'] = np.where(bitcoin['Result']>0.0, True, False)\nbitcoin.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(bitcoin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = bitcoin.iloc[24586:24986]\ntest_set_1 = bitcoin.iloc[24987:25706]\ntest_set_2 = bitcoin.iloc[25707:26426]\ntest_set_3 = bitcoin.iloc[26427:27146]\ntest_set_4 = bitcoin.iloc[27147:27866]\ntest_set_5 = bitcoin.iloc[27867:, :]\n#5 last months for testing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train = train_set[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_set[\"Increase\"].values\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_1 = test_set_1[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_test_2 = test_set_2[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_test_3 = test_set_3[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_test_4 = test_set_4[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_test_5 = test_set_5[[\"Open\",\"High\",\"Low\",\"Close\"]].values\nX_test_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_1 = test_set_1[\"Increase\"].values\ny_test_result_1 = test_set_1[\"Result\"].values\ny_test_2 = test_set_2[\"Increase\"].values\ny_test_result_2 = test_set_2[\"Result\"].values\ny_test_3 = test_set_3[\"Increase\"].values\ny_test_result_3 = test_set_3[\"Result\"].values\ny_test_4 = test_set_4[\"Increase\"].values\ny_test_result_4 = test_set_4[\"Result\"].values\ny_test_5 = test_set_5[\"Increase\"].values\ny_test_result_5 = test_set_5[\"Result\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nwhile i < len(y_train):\n    print(y_test_result_1[i], y_test_1[i])\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simulation building"},{"metadata":{},"cell_type":"markdown","source":"In this part, we will build a simulation method, where we invest every hour based on our predictions. We can invest on the increase or the decrease of the stock, and we fix a stop loss below which we sell, and a take profit when we sell also."},{"metadata":{"trusted":true},"cell_type":"code","source":"def simulation(X_test, y_test_result, starting_wallet, stop_loss, take_profit, clf):\n    i=0\n    tendance = 0\n    y_result = y_test_result\n    total = starting_wallet\n    while i < len(y_result):\n        \n        #si l'ia nous dit de miser la hausse, qu'on mise la hausse et que le cours augmente\n        #if the model tells us that the stock will increase and it's true\n        if clf.predict(X_test)[i] == True and y_result[i] > 0:\n            tendance = 1\n            if y_result[i] > (take_profit):\n                total =  (tendance * ((1 + (take_profit/100)) * total))\n                commission = 0.0004 * total\n                total = total - commission\n            else:\n                total =  (tendance * ((1 + (y_result[i]/100)) * total))\n                commission = 0.0004 * total\n                total = total - commission\n\n        #si l'ia nous dit de miser la hausse, qu'on mise la hausse et que le cours descend\n        #if the model tells us that the stock will increase and it's not true\n        elif clf.predict(X_test)[i] == True and y_result[i] < 0:\n            tendance = -1\n            if y_result[i] < (stop_loss):\n                total =  ((1 - (-stop_loss/100)) * total)\n                commission = 0.0004 * total\n                total = total - commission\n            else:\n                total =  ((1 - (-y_result[i]/100)) * total)\n                commission = 0.0004 * total\n                total = total - commission\n\n        #si l'ia nous dit de miser la baisse, qu'on mise le baisse et que le cours augmente\n        #if the model tells us that the stock will decrease and it's not true\n        elif clf.predict(X_test)[i] == False and y_result[i] > 0:\n            tendance = -1\n            if (-y_result[i]) < stop_loss:\n                total =  ((1 - (-stop_loss/100)) * total)\n                commission = 0.0004 * total\n                total = total - commission\n            else:\n                total =  ((1 - (y_result[i]/100)) * total)\n                commission = 0.0004 * total\n                total = total - commission\n\n        #si l'ia nous dit de miser la baisse, qu'on mise la baisse et que le cours descend\n        #if the model tells us that the stock will decrease and it's true, we decide to \"short\"\n        elif clf.predict(X_test)[i] == False and y_result[i] < 0:\n            tendance = 1\n            if y_result[i] < (-take_profit):\n                total =  (tendance * (1 + (take_profit/100)) * total)\n                commission = 0.0004 * total\n                total = total - commission\n            else:\n                total =  (tendance * ((1 + (-y_result[i]/100))) * total)\n                commission = 0.0004 * total\n                total = total - commission\n\n        i+=1\n    print('Wallet at the begining of the test simulation : ',starting_wallet)\n    print('Wallet at the end of the test simulation : ',round(total, 2))\n    print('---------------------------')\n    return round(total, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def detailed_simulation(X_test, y_test_result, starting_wallet, stop_loss, take_profit, clf):\n    i=0\n    tendance = 0\n    y_result = y_test_result\n    total = starting_wallet\n    print('Stop loss : ',stop_loss)\n    print('Take profit : ',take_profit)\n    print('---- BEGINNING SIMULATION ----')\n    while i < len(y_result):\n        print('Predicted : ', clf.predict(X_test)[i])\n        print('Reality : ', y_result[i])\n\n        #si l'ia nous dit de miser la hausse, qu'on mise la hausse et que le cours augmente\n        #if the model tells us that the stock will increase and it's true\n        if clf.predict(X_test)[i] == True and y_result[i] > 0:\n            tendance = 1\n            if y_result[i] > (take_profit):\n                print('Take profit : ', take_profit)\n                total =  (tendance * ((1 + (take_profit/100)) * total))\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n            else:\n                total =  (tendance * ((1 + (y_result[i]/100)) * total))\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n\n        #si l'ia nous dit de miser la hausse, qu'on mise la hausse et que le cours descend\n        #if the model tells us that the stock will increase and it's not true\n        elif clf.predict(X_test)[i] == True and y_result[i] < 0:\n            tendance = -1\n            if y_result[i] < (stop_loss):\n                print('Stop loss : ', stop_loss)\n                total =  ((1 - (-stop_loss/100)) * total)\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n            else:\n                total =  ((1 - (-y_result[i]/100)) * total)\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n\n        #si l'ia nous dit de miser la baisse, qu'on mise le baisse et que le cours augmente\n        #if the model tells us that the stock will decrease and it's not true\n        elif clf.predict(X_test)[i] == False and y_result[i] > 0:\n            tendance = -1\n            if (-y_result[i]) < stop_loss:\n                print('Stop loss : ', stop_loss)\n                total =  ((1 - (-stop_loss/100)) * total)\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n            else:\n                total =  ((1 - (y_result[i]/100)) * total)\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n\n        #si l'ia nous dit de miser la baisse, qu'on mise la baisse et que le cours descend\n        #if the model tells us that the stock will decrease and it's true, we decide to \"short\"\n        elif clf.predict(X_test)[i] == False and y_result[i] < 0:\n            tendance = 1\n            if y_result[i] < (-take_profit):\n                print('Take profit : ', take_profit)\n                total =  (tendance * (1 + (take_profit/100)) * total)\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n            else:\n                total =  (tendance * ((1 + (-y_result[i]/100))) * total)\n                print('Wallet before commission : ', total)\n                commission = 0.0004 * total\n                print('Commission : ', commission)\n                total = total - commission\n                print('Wallet after commission : ', total)\n\n        print('---------------------------')\n        i+=1\n        #progressBar(i, len(y_result))\n    print(\"\")\n    print('END OF SIMULATION')\n    print('Wallet at the begining of the test simulation : ',starting_wallet)\n    print('Wallet at the end of the test simulation : ',round(total, 2))\n    print('---------------------------')\n    return round(total, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stochastic Gradient Descent (SGD) classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier().fit(X_train, y_train)\ni = 0\ngood_predictions = 0\ntotal_predictions = len(X_train)\nwhile i < total_predictions:\n    #print(sgd_clf.predict([X_train[i]]), y_train[i])\n    if (sgd_clf.predict([X_train[i]]) == True and y_train[i] == 1):\n        good_predictions += 1\n    elif (sgd_clf.predict([X_train[i]]) == False and y_train[i] != 1):\n        good_predictions += 1\n    i += 1\naccuracy = good_predictions * 100 / total_predictions\nprint('number of good predictions = ', good_predictions)\nprint ('total predictions = ', total_predictions)\nprint ('accuracy = ', accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how the model perform on the 5 mounths"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nprint('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, sgd_clf.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's focus on the fourth mounth"},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 0\ncount_tp = 0\ncount_fp = 0 \ncount_fn = 0 \ncount_tn = 0\ncount_negative = 0\ncount_positive = 0 \nfor i in sgd_clf.predict(X_test_4):\n    if i == True:\n        if y_test_4[index] == True:\n            count_tp+=1\n        if y_test_4[index] == False:\n            count_fp+=1\n    if i == False:\n        if y_test_4[index] == True:\n            count_fn+=1\n        if y_test_4[index] == False:\n            count_tn+=1\n    index+=1\n\nfor i in y_test_4:\n    if i == True:\n        count_positive+=1\n    else:\n        count_negative+=1\n        \nprint('True positives :', count_tp)\nprint('False positives :', count_fp)\nprint('True negatives :', count_tn)\nprint('False negatives :', count_fn)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we run a detailed simulation on the second mounth, we can see what is going on step by step if we try this model in real life. We will use a stop loss of -1% and a take profit of 1.2%, with 10000USD."},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_simulation(X_test_2, y_test_result_2, 10000, -1, 1.2, sgd_clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that we loose money. Now let's try on the 5 last mounth : "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mounth 1')\ntotal_1 = simulation(X_test_1, y_test_result_1, 10000, -1, 1.2, sgd_clf)\nprint('Mounth 2')\ntotal_2 = simulation(X_test_2, y_test_result_2, total_1, -1, 1.2, sgd_clf)\nprint('Mounth 3')\ntotal_3 = simulation(X_test_3, y_test_result_3, total_2, -1, 1.2, sgd_clf)\nprint('Mounth 4')\ntotal_4 = simulation(X_test_4, y_test_result_4, total_3, -1, 1.2, sgd_clf)\nprint('Mounth 5')\ntotal_5 = simulation(X_test_5, y_test_result_5, total_4, -1, 1.2, sgd_clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to improve our simulation we should calculate also when during the hour, the stock reach the stop loss and end at a higher value. We will ignore this problem in this final project, for time. Nevertheless, it's very rare that the stock reach -1% and end at a higher value."},{"metadata":{},"cell_type":"markdown","source":"## KNN classifier\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_class = KNeighborsClassifier(n_neighbors=4, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\nknn_class.fit(X_train, y_train)\n\nprint('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, knn_class.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, knn_class.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, knn_class.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, knn_class.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, knn_class.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, knn_class.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, knn_class.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, knn_class.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, knn_class.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, knn_class.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, knn_class.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, knn_class.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, knn_class.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, knn_class.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, knn_class.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mounth 1')\ntotal_1 = simulation(X_test_1, y_test_result_1, 10000, -1, 1.2, knn_class)\nprint('Mounth 2')\ntotal_2 = simulation(X_test_2, y_test_result_2, total_1, -1, 1.2, knn_class)\nprint('Mounth 3')\ntotal_3 = simulation(X_test_3, y_test_result_3, total_2, -1, 1.2, knn_class)\nprint('Mounth 4')\ntotal_4 = simulation(X_test_4, y_test_result_4, total_3, -1, 1.2, knn_class)\nprint('Mounth 5')\ntotal_5 = simulation(X_test_5, y_test_result_5, total_4, -1, 1.2, knn_class)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, clf.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, clf.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, clf.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, clf.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, clf.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, clf.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, clf.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, clf.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, clf.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, clf.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, clf.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, clf.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, clf.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, clf.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, clf.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mounth 1')\ntotal_1 = simulation(X_test_1, y_test_result_1, 10000, -1, 1.2, clf)\nprint('Mounth 2')\ntotal_2 = simulation(X_test_2, y_test_result_2, total_1, -1, 1.2, clf)\nprint('Mounth 3')\ntotal_3 = simulation(X_test_3, y_test_result_3, total_2, -1, 1.2, clf)\nprint('Mounth 4')\ntotal_4 = simulation(X_test_4, y_test_result_4, total_3, -1, 1.2, clf)\nprint('Mounth 5')\ntotal_5 = simulation(X_test_5, y_test_result_5, total_4, -1, 1.2, clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fine tuning"},{"metadata":{},"cell_type":"markdown","source":"Based on previous simulations, the best model is the SGD and the accuracy of the model have the biggest impact on the simulation. So we'll try to fine tune based on the documentation : https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom time import time\nimport scipy.stats as stats\nfrom sklearn.utils.fixes import loguniform\nclf = SGDClassifier(loss='hinge', penalty='elasticnet', fit_intercept=True)\n\n# Utility function to report best scores\ndef report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n                  .format(results['mean_test_score'][candidate],\n                          results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\n\n# specify parameters and distributions to sample from\nparam_dist = {'average': [True, False],\n              'l1_ratio': stats.uniform(0, 1),\n              'alpha': loguniform(1e-4, 1e0)}\n\n# run randomized search\nn_iter_search = 20\nrandom_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n                                   n_iter=n_iter_search)\n\nstart = time()\nrandom_search.fit(X_train, y_train)\nprint(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n      \" parameter settings.\" % ((time() - start), n_iter_search))\nreport(random_search.cv_results_)\n\n# use a full grid over all parameters\nparam_grid = {'average': [True, False],\n              'l1_ratio': np.linspace(0, 1, num=10),\n              'alpha': np.power(10, np.arange(-4, 1, dtype=float))}\n\n# run grid search\ngrid_search = GridSearchCV(clf, param_grid=param_grid)\nstart = time()\ngrid_search.fit(X_train, y_train)\n\nprint(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n      % (time() - start, len(grid_search.cv_results_['params'])))\nreport(grid_search.cv_results_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(alpha=0.001, average=False, l1_ratio=0.2222222222222222).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, sgd_clf.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mounth 1')\ntotal_1 = simulation(X_test_1, y_test_result_1, 10000, -0.5, 1.2, sgd_clf)\nprint('Mounth 2')\ntotal_2 = simulation(X_test_2, y_test_result_2, total_1, -0.5, 1.2, sgd_clf)\nprint('Mounth 3')\ntotal_3 = simulation(X_test_3, y_test_result_3, total_2, -0.5, 1.2, sgd_clf)\nprint('Mounth 4')\ntotal_4 = simulation(X_test_4, y_test_result_4, total_3, -0.5, 1.2, sgd_clf)\nprint('Mounth 5')\ntotal_5 = simulation(X_test_5, y_test_result_5, total_4, -0.5, 1.2, sgd_clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we improve a lot the performance of our model with the fine tuning. But as we said earlier, the simulation is not perfect, and the performance seems very random."},{"metadata":{},"cell_type":"markdown","source":"### Features engineering"},{"metadata":{},"cell_type":"markdown","source":"I developed a new database with trading metrics and other crypto stocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin = pd.read_csv('bitcoin_fe.csv')\nbitcoin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to clean the database (remove the rows '-' and NaN)"},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin_to_remove = (bitcoin.loc[bitcoin['VolumeBTC'] == '-'])\nbitcoin = bitcoin[~bitcoin.index.isin(bitcoin_to_remove.index)]\nbitcoin_to_remove = (bitcoin.loc[bitcoin['VolumeUSDT_BTC'] == '-'])\nbitcoin = bitcoin[~bitcoin.index.isin(bitcoin_to_remove.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(bitcoin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin = bitcoin.apply (pd.to_numeric, errors='coerce')\nbitcoin = bitcoin.drop(['Date'], axis = 1)\nbitcoin = bitcoin.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(bitcoin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that our new database is clean, let's prepare our data for classifications models."},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin['Increase'] = np.where(bitcoin['Result_BTC']>0.0, True, False)\nbitcoin = bitcoin.drop(['Result_BTC'], axis = 1)\nbitcoin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(bitcoin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size = (len(bitcoin)-720)\n\ntest_set_5 = bitcoin.iloc[(size): len(bitcoin)]\nsize = size - 721\ntest_set_4 = bitcoin.iloc[(size+1):(size + 721)]\nsize = size - 721\ntest_set_3 = bitcoin.iloc[(size+1):(size + 721)]\nsize = size - 721\ntest_set_2 = bitcoin.iloc[(size+1):(size + 721)]\nsize = size - 721\ntest_set_1 = bitcoin.iloc[(size+1):(size + 721)]\nsize = size - 721\ntrain_set = bitcoin.iloc[0:(size + 722)]\n#5 last months for testing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set_5.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, I added a lot of features such as EMA (trading metric) and stocks of Etherium (another cryptocurrency)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_set.iloc[:,1:-2].values\nX_test_1 = test_set_1.iloc[:,1:-2].values\nX_test_2 = test_set_2.iloc[:,1:-2].values\nX_test_3 = test_set_3.iloc[:,1:-2].values\nX_test_4 = test_set_4.iloc[:,1:-2].values\nX_test_5 = test_set_5.iloc[:,1:-2].values\ny_train = train_set[\"Increase\"].values\ny_test_1 = test_set_1[\"Increase\"].values\ny_test_2 = test_set_2[\"Increase\"].values\ny_test_3 = test_set_3[\"Increase\"].values\ny_test_4 = test_set_4[\"Increase\"].values\ny_test_5 = test_set_5[\"Increase\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nprint('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, sgd_clf.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_class = KNeighborsClassifier(n_neighbors=4, weights='distance', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\nknn_class.fit(X_train, y_train)\n\nprint('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, knn_class.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, knn_class.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, knn_class.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, knn_class.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, knn_class.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, knn_class.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, knn_class.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, knn_class.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, knn_class.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, knn_class.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, knn_class.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, knn_class.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, knn_class.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, knn_class.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, knn_class.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\nprint('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, clf.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, clf.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, clf.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, clf.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, clf.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, clf.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, clf.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, clf.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, clf.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, clf.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, clf.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, clf.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, clf.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, clf.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, clf.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even with the fine tuning, the models seem to do randomly."},{"metadata":{},"cell_type":"markdown","source":"### Fine tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom time import time\nimport scipy.stats as stats\nfrom sklearn.utils.fixes import loguniform\nclf = SGDClassifier(loss='hinge', penalty='elasticnet', fit_intercept=True)\n\n# Utility function to report best scores\ndef report(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n                  .format(results['mean_test_score'][candidate],\n                          results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\n\n# specify parameters and distributions to sample from\nparam_dist = {'average': [True, False],\n              'l1_ratio': stats.uniform(0, 1),\n              'alpha': loguniform(1e-4, 1e0)}\n\n# run randomized search\nn_iter_search = 20\nrandom_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n                                   n_iter=n_iter_search)\n\nstart = time()\nrandom_search.fit(X_train, y_train)\nprint(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n      \" parameter settings.\" % ((time() - start), n_iter_search))\nreport(random_search.cv_results_)\n\n# use a full grid over all parameters\nparam_grid = {'average': [True, False],\n              'l1_ratio': np.linspace(0, 1, num=10),\n              'alpha': np.power(10, np.arange(-4, 1, dtype=float))}\n\n# run grid search\ngrid_search = GridSearchCV(clf, param_grid=param_grid)\nstart = time()\ngrid_search.fit(X_train, y_train)\n\nprint(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n      % (time() - start, len(grid_search.cv_results_['params'])))\nreport(grid_search.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(alpha=0.01, average=True, l1_ratio=0.5555555555555556).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mounth 1:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('Recall: ', (100 * recall_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('F1: ', (100 * f1_score(y_test_1, sgd_clf.predict(X_test_1))))\nprint('-----------------')\nprint('Mounth 2:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('Recall: ', (100 * recall_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('F1: ', (100 * f1_score(y_test_2, sgd_clf.predict(X_test_2))))\nprint('-----------------')\nprint('Mounth 3:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('Recall: ', (100 * recall_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('F1: ', (100 * f1_score(y_test_3, sgd_clf.predict(X_test_3))))\nprint('-----------------')\nprint('Mounth 4:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('Recall: ', (100 * recall_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('F1: ', (100 * f1_score(y_test_4, sgd_clf.predict(X_test_4))))\nprint('-----------------')\nprint('Mounth 5:')\nprint('Accuracy: ', (100 * accuracy_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('Recall: ', (100 * recall_score(y_test_5, sgd_clf.predict(X_test_5))))\nprint('F1: ', (100 * f1_score(y_test_5, sgd_clf.predict(X_test_5))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model is still doing poorly, even with all the features we added."},{"metadata":{},"cell_type":"markdown","source":"### To go further"},{"metadata":{},"cell_type":"markdown","source":"I did research on the web, and I found an interesting video that presents the LSTM (neural network) model. I do not recommand to launch these cells (I tested on google Collab, it lasted 8 hours, in order to save my computer) and I found interesting results : "},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\n#import pandas_datareader as pdd\nfrom sklearn.preprocessing import MinMaxScaler\n#from keras.models import Sequential\n#from keras.layers.core import Dense, Activation, Dropout\n#from keras.layers.recurrent import LSTM\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import io\nbitcoin_m = pd.read_csv('Bitcoin_1m_data.csv')\nbitcoin_m.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin_m.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoin_m = bitcoin_m.iloc[400000:16725692 :]\ndata = bitcoin_m.filter(['Close'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=data.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train = np.array(x_train), np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order for our model to work, we will create several windows of 60 closing prices in order to predict the number 61. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = scaled_data[0:training_data_len,:] \nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)-60):\n    x_train.append(train_data[i-60:i, 0])\n    #y_train.append(train_data[i+60, 0])\n    if (train_data[i+60, 0])>0:\n      y_train.append(True)\n    else:\n      y_train.append(False)\n    if i<= 60:\n        print(x_train)\n        print(y_train)\n        print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The lstm need a 3D x_train in order to work."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1],1)))\nmodel.add(LSTM(100, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=1, epochs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = scaled_data[training_data_len - 60: , :]\n\n#create data sests x_tesst and y \nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range (60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.array(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.reshape(x_test,(x_test.shape[0], x_test.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(np.mean(predictions - y_test)**2)\nrmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Last rmse obtained = 8.27602340010901"},{"metadata":{},"cell_type":"markdown","source":"Even though the rmse change everytime we launch the model, 8.28 error in the estimation of Close is very low, and it's maybe worth to deep into it. "},{"metadata":{},"cell_type":"markdown","source":"### Conclusion"},{"metadata":{},"cell_type":"markdown","source":"In this final project, I realize that trying to predict the stock of Bitcoin is very hard, and maybe beyond the scope of this course. Nevertheless, I tried to apply everything we learned and to interpret it, and why it's not working correctly. It's safe to assume that deep learning is a good lead to investigate for this prediction problem. Thank you."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}