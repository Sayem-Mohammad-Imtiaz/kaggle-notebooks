{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# load libs and dataset\n\n\nimport os\nimport re\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom numpy import asarray\nfrom numpy import zeros\n\nfrom keras.layers import LSTM, SimpleRNN\nfrom keras.layers.core import Dense\nfrom keras.layers.embeddings import Embedding\n\nfrom keras.models import Sequential\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\n\nfrom sklearn.model_selection import train_test_split\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nds = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\nds.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# clean dataset\n\ndef clean(sentence):\n    \n    # remove html tags\n    sentence = re.compile(r'<[^>]+>').sub('', sentence)\n\n    # remove punctuations and numbers\n    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n\n    # remove single characters\n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n\n    # remove multiple spaces\n    sentence = re.sub(r'\\s+', ' ', sentence)\n    \n    # lowercase sentence\n    sentence = sentence.lower()\n\n    return sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create x and y dimensions, x = sentences as string, y = ratings as binary\n\nx = []\nsentences = list(ds['review'])\nfor sentence in sentences:\n    x.append(clean(sentence))\n    \ny = ds['sentiment']\ny = np.array(list(map(lambda x: 1 if x == \"positive\" else 0, y)))\n\n#x\n#y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create train (80%) and test (20%) datasets\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create tokens (as a word-to-index dictionary) and pad sequences (maxlen 100)\n\ntokenizer = Tokenizer(num_words = 10000)\ntokenizer.fit_on_texts(x_train)\n\nx_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\n\nmaxlen = 100\n\nx_train = pad_sequences(x_train, padding = 'post', maxlen = maxlen)\nx_test = pad_sequences(x_test, padding = 'post', maxlen = maxlen)\n\nvocab_size = len(tokenizer.word_index) + 1 # adding 1 because of reserved 0 index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vocab_size\n#x_train\n#y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the feature matrix and provide a dense representation of words that capture something about their meaning\n# use Stanford's GloVe 100d word embeddings\n# source = https://nlp.stanford.edu/projects/glove/\n# info = https://www.kaggle.com/danielwillgeorge/glove6b100dtxt?select=glove.6B.100d.txt\n\nembeddings_dictionary = dict()\nglove_file = open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt', encoding=\"utf8\")\n\nfor line in glove_file:\n    records = line.split()\n    word = records[0]\n    vector_dimensions = asarray(records[1:], dtype = 'float32')\n    embeddings_dictionary [word] = vector_dimensions\nglove_file.close()\n\nembedding_matrix = zeros((vocab_size, 100))\nfor word, index in tokenizer.word_index.items():\n    embedding_vector = embeddings_dictionary.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[index] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######\n# RNN #\n#######\n\n# create RNN model, train and evaluate\n\nmodel = Sequential()\nembedding_layer = Embedding(vocab_size, 100, weights = [embedding_matrix], input_length = maxlen , trainable = False)\nmodel.add(embedding_layer)\nmodel.add(SimpleRNN(128))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n\nprint(model.summary())\n\nhistory = model.fit(x_train, y_train, batch_size = 128, epochs = 6, verbose = 1, validation_split = 0.2)\nscore = model.evaluate(x_test, y_test, verbose=1)\n\nprint(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot RNN model results\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('RNN Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('RNN Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########\n# LSTM #\n########\n\n# create LSTM model, train and evaluate\n\nmodel = Sequential()\nembedding_layer = Embedding(vocab_size, 100, weights = [embedding_matrix], input_length = maxlen , trainable = False)\nmodel.add(embedding_layer)\nmodel.add(LSTM(128))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n\nprint(model.summary())\n\nhistory = model.fit(x_train, y_train, batch_size = 128, epochs = 6, verbose = 1, validation_split = 0.2)\nscore = model.evaluate(x_test, y_test, verbose=1)\n\nprint(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot LSTM model results\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\nplt.title('LSTM Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('LSTM Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}