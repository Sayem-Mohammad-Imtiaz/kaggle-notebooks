{"cells":[{"metadata":{"_uuid":"3f6fbe8c783d9e11eaf8e56802b7fac8f1640347"},"cell_type":"markdown","source":"# Airline Sentiment Classification Based on the Passengers Tweets."},{"metadata":{"_uuid":"6fa1a840649cbf86d454d8a4cc419477486d8038"},"cell_type":"markdown","source":"First of All, Importing all libraries required for data analysis and data visualizations."},{"metadata":{"trusted":false,"_uuid":"0354944cd315e6293fcec2a5505070ba9947e81a"},"cell_type":"code","source":"import pandas as pandasInstance\nimport numpy as numpyInstance\nimport matplotlib.pyplot as matplotlibInstance\nimport seaborn as seabornInstance","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0e4c4e1894c11a99f0e65f8025e3b9044a2c74f"},"cell_type":"markdown","source":"Doing setting for inline data visualizations."},{"metadata":{"trusted":false,"_uuid":"00d79e21fbdabe0037c35d2a81d2c59d1970e828"},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f56cfbe5f37e5f30b942a5ee6a49efbf2fc3ab1a"},"cell_type":"markdown","source":"Now Importing the Data Related to Passangers Tweets."},{"metadata":{"trusted":false,"_uuid":"ab383add073c7b48c1212069f4c1966262ae6e3d"},"cell_type":"code","source":"tweets_Data = pandasInstance.read_csv('../input/Tweets.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"277705944f091159d8a9fea3bacb23c23a82ae1b"},"cell_type":"markdown","source":"Checking the Header of the Data Loaded."},{"metadata":{"trusted":false,"_uuid":"9ae0a9c3ba8472b166dc91481bcb721e66e21286"},"cell_type":"code","source":"tweets_Data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f4bb818f680392cfc9103eac9bf894f2f101326"},"cell_type":"markdown","source":"Now Checking the Information about all the Columns."},{"metadata":{"trusted":false,"_uuid":"7e94e8cdfa9133b6eed9cc51a372cc723b88bb7d"},"cell_type":"code","source":"tweets_Data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52152e47094c7cd996b6b5ffed222f1ddf622b04"},"cell_type":"markdown","source":"Getting Some Basic Statistical Data of The Tweets Data."},{"metadata":{"trusted":false,"_uuid":"3db4f851ecec65e2b25a8c684e2ebc99a92798ba"},"cell_type":"code","source":"tweets_Data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a7c0e29c3de57e2fa960be37ecc64bd940e366e"},"cell_type":"markdown","source":"## Part 1: Some Basic Data Exploration and Data Visualizations."},{"metadata":{"_uuid":"4c89a054960558fe5c690c3955c94ef930e75759"},"cell_type":"markdown","source":"Counting the Number of Different Airlines, present in the data."},{"metadata":{"trusted":false,"_uuid":"275cc116a83c3891c4f119f2c9e64c7915affa6b"},"cell_type":"code","source":"matplotlibInstance.figure(figsize=(20,10))\nmatplotlibInstance.tight_layout()\nseabornInstance.countplot(x='airline',data=tweets_Data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f02d1ff9be0832fd902dbcd8d9c60b614546d95"},"cell_type":"markdown","source":"##### From Above Count Plot We can Colclude that \"United\" Airline has Most Tweets."},{"metadata":{"_uuid":"ce596c4cfce1c74f58e1b79f1be2ad46f62c9c98"},"cell_type":"markdown","source":"Finding Out From Which Time Zone Most of The Passangers Have Made Tweets."},{"metadata":{"trusted":false,"_uuid":"7a1007af8eb3ba2733b20c3a3acb0e521d2f7dc0"},"cell_type":"code","source":"groupedByTimeZone = tweets_Data.groupby('user_timezone')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ff32c068488845811fa9078cf7ac5243e3d47c8a"},"cell_type":"code","source":"numberOfTweetsFromDifferentTiemZones = groupedByTimeZone['user_timezone'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4357411e1960884fe6ab9d8ada114cd9eef07dc5"},"cell_type":"code","source":"topFiveTimeZonesWithMostTweets = numberOfTweetsFromDifferentTiemZones.sort_values(ascending=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5c622bbee1a9238dd7ecce764f105355e8ba9324"},"cell_type":"code","source":"topFiveTimeZonesWithMostTweets","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a58980158850f87a2587e30c1a534722259ffc85"},"cell_type":"markdown","source":"##### Most Tweets from Passangers are from Eastern Time, Central Time, Pacific Time, Quito and Atlantic Time."},{"metadata":{"_uuid":"441a263b61d32e19018e2886b87685499b2fc30b"},"cell_type":"markdown","source":"Let's Check Where Most Of the Airline Sentiment Confidence Lies."},{"metadata":{"trusted":false,"_uuid":"a4151ef3fce144d86de27516b500b38b661ab0f6"},"cell_type":"code","source":"tweets_Data['airline_sentiment_confidence'].hist(color='green',figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb85a62f7932d43b234df521ac47714d72ab5582"},"cell_type":"markdown","source":"We Can See that Most Airline Sentiment Confidence is Between 0.7 to 1.0"},{"metadata":{"_uuid":"5d3cb83699026db1805e48f7846a8a951097e647"},"cell_type":"markdown","source":"Counting the Length of Each Tweet."},{"metadata":{"trusted":false,"_uuid":"448e08289945757d683cff21b869c56acd43b1c5"},"cell_type":"code","source":"tweets_Data['Tweet Length'] = tweets_Data['text'].apply(len)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77182f964bff5d602b4e13f95d67c6bb451d8106"},"cell_type":"markdown","source":"Grabbing the Information of the Most Length Tweet."},{"metadata":{"trusted":false,"_uuid":"5c833d85ff9f5f6c3d5c059d60ae5d8fa18cbfa7"},"cell_type":"code","source":"tweets_Data[tweets_Data['Tweet Length'] == 186]['text'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9ef36d2f4f0ca7afe56e8c0977a51afd82e20a26"},"cell_type":"code","source":"tweets_Data.hist(column='Tweet Length',by='airline_sentiment',figsize=(20,10),color='red',bins=100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bc1d72514c7c0b839f0a879b273870d916e9909"},"cell_type":"markdown","source":"##### From Above Histograms We can Conclude that tweets with Postiive Aspect has More Words on average and Neutral Too."},{"metadata":{"_uuid":"3d2afdd992b221ba7b57acae1efc02bb36276757"},"cell_type":"markdown","source":"## Part 2: Cleaning and Normalizing the Tweets Text."},{"metadata":{"_uuid":"a871e0caf641c28f538f025cf856aa6dbfe589d1"},"cell_type":"markdown","source":"Importing the NLTK for the Purpose of Removing the Stopping Words."},{"metadata":{"trusted":false,"_uuid":"0568ec7a0b1402f51af6a3c83cc8219fcdfc1432"},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3a76f55f2c2949f444ef3e6f4d979a5e47e52e2"},"cell_type":"markdown","source":"Importing the Strings Library in order to Remove the Punctuation Marks and Other Things."},{"metadata":{"trusted":false,"_uuid":"bf3060ff2ee552d46f074f56488be540f7bc649e"},"cell_type":"code","source":"import string","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03d8a3c788372a518a6cb935ab7adc0985da0c5e"},"cell_type":"markdown","source":"Now Grabbing the All Tweet's Text."},{"metadata":{"trusted":false,"_uuid":"3d7a6fb64bd664ae55f189f906549097c680ed7a"},"cell_type":"code","source":"tweets_text = tweets_Data['text']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20e2936f3d900dcd765ea6aaf8c3e375b781b0b0"},"cell_type":"markdown","source":"Removing the Punctuation Marks of the Text and also the Stopping words."},{"metadata":{"trusted":false,"_uuid":"19c3795d809307b0641161f753d14bc8d998b995"},"cell_type":"code","source":"def text_process(mess):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in mess if char not in string.punctuation]\n\n    # Join the characters again to form the string.\n    nopunc = ''.join(nopunc)\n    \n    # Now just remove any stopwords\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90a645c2580beb32b155225160b1d5acb6b52f74"},"cell_type":"markdown","source":"Now applying the Above Function to the Tweets Text"},{"metadata":{"trusted":false,"_uuid":"3aca7981e5074686b1537a59a3f0df077f6283b9"},"cell_type":"code","source":"withoutStopWordsandPunctuations = tweets_Data['text'].apply(text_process)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e68119c5bfa19d6d196f8597a02e4c1c80d8cb66"},"cell_type":"markdown","source":"Importing the CountVectorizer to Make the Bag of Words."},{"metadata":{"trusted":false,"_uuid":"91480f3c7188f18b47d59cee306ee4513a3bd276"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4c34dde2486b8460e79bb80e0dea31499951ffe1"},"cell_type":"code","source":"bow_transformer = CountVectorizer(analyzer=text_process).fit(tweets_Data['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b028ebc23d9d9dfa2e6e6015e12b37a466136214"},"cell_type":"code","source":"print(len(bow_transformer.vocabulary_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f07daad0e7e63bcfe0f301c98748ed2e95a331fa"},"cell_type":"code","source":"tweets_bow = bow_transformer.transform(tweets_Data['text'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"361859a17254b91a3042940a870c666970fb868e"},"cell_type":"markdown","source":"Looking at the Shape and Amount of Non Zero Occurances."},{"metadata":{"trusted":false,"_uuid":"34ba6022c1db309da4083affc2e1a1f1dd66b93a"},"cell_type":"code","source":"print('Shape of Sparse Matrix: ', tweets_bow.shape)\nprint('Amount of Non-Zero occurences: ', tweets_bow.nnz)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e2ec3d1049b63bbcd7861ca3dfa4e965550faeb"},"cell_type":"markdown","source":"Checking the Sparsity."},{"metadata":{"trusted":false,"_uuid":"16bc289767be3e2a5e543b7132a84030fdcd024e"},"cell_type":"code","source":"sparsity = (100.0 * tweets_bow.nnz / (tweets_bow.shape[0] * tweets_bow.shape[1]))\nprint('sparsity: {}'.format((sparsity)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4c265975aa08d33d918a00b60789ba6276a7481"},"cell_type":"markdown","source":"## Part 3: Using the TF-IDF."},{"metadata":{"trusted":false,"_uuid":"b48fb3de92bc60848c4ed403fbee0f64bef817e2"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf_transformer = TfidfTransformer().fit(tweets_bow)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfa3c82c7429c0017de46d92b3872a0362477fb0"},"cell_type":"markdown","source":"Transfering the Bag of Words into the TF-IDF at once."},{"metadata":{"trusted":false,"_uuid":"f436c1e2e6713fd2a18e5254067b86fd126262c9"},"cell_type":"code","source":"tweets_tfidf = tfidf_transformer.transform(tweets_bow)\nprint(tweets_tfidf.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13d4931230970b4d4e2d54c18e09015b81907a3a"},"cell_type":"markdown","source":"## Part 4: Training and Splitting the Model."},{"metadata":{"_uuid":"11a98cfbf0ff887f42148e615e072c19825e6cc1"},"cell_type":"markdown","source":"For this purpose we will use the Naive Bays Classifier Algorithm."},{"metadata":{"trusted":false,"_uuid":"8ad6c5eba4f575ed9cbfe950ff4d367b8cff8326"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(tweets_tfidf, tweets_Data['airline_sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dd3ca819383034c65f27672df4600431b477515"},"cell_type":"markdown","source":"## Part 5: Evaluation of the Model."},{"metadata":{"trusted":false,"_uuid":"7ee07ba04656f5c169eccd9724ef19ef7c734c4d"},"cell_type":"code","source":"all_predictions = spam_detect_model.predict(tweets_tfidf)\nprint(all_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3f6d4fbb6d670a884a475937edab0aa27c5636cf"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint (classification_report(tweets_Data['airline_sentiment'], all_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"42d5bf3a50cb9b88218869a404ed5f13e73bfc36"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}