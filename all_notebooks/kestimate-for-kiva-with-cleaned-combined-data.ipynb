{"cells":[{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"5c505146953da5b779b40c33eb88d64bcc8a80f8","_cell_guid":"fa89e9a0-a874-4e4c-ab51-915f28cf0889","trusted":false},"cell_type":"code","source":"print(\"Starting with a csv of joined data from the original data and additional snapshot, this notebook checks if rMPI can be predicted by a collection of socioeconomic statistics, then starts a PCA analysis that could help construct a Kiva estimate of need/poverty aka Kestimate. During merging and cleaning, regional and country-level socioeconomic stats were looked up using the region name or latitude and longitude. Missing data were decreased by assigning a rounded latitute and longitude when it was missing but could  region was known.\")\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"First will fix the count of male / female applicants, and sample 500k rows, about half the data, to save memory and training time\")\n#Reading in the data and fixing the counts of female/male loan applicants\nimport numpy as np \nimport pandas as pd \nimport random\n\ndata = pd.read_csv(\"../input/cleaned-combined-kiva/cleaned_combined_kiva.csv\")\n#Sampling 500k rows to save training time / memory\nsample = random.sample(range(len(data)), 500000)\ndata = data.iloc[sample, :]\n\n#Adjusting dtypes so they match\n#Some empty spaces causing type issues in PPP variables, and filling NaNs with empty strings for string variables.\ndata['rPPP90'] = pd.to_numeric(data['rPPP90'].replace(\" \",\"\"))\ndata['rPPP95'] = pd.to_numeric(data['rPPP95'].replace(\" \",\"\"))\ndata['rPPP00'] = pd.to_numeric(data['rPPP00'].replace(\" \",\"\"))\ndata['rPPP05'] = pd.to_numeric(data['rPPP05'].replace(\" \",\"\"))\ncols = data.columns.to_series().groupby(data.dtypes).groups\ncols = {k.name: v for k, v in cols.items()}\nfor col in cols['object']:\n    data[col] = data[col].fillna(\"\")\n\ndef parsegender(v):\n    genderlist = []\n    if isinstance(v['borrower_genders'], str):\n        genderlist = v['borrower_genders'].split(',')\n    numfemale = 0\n    nummale = 0\n    for gender in genderlist:\n        if len(gender.strip()) == 6:\n            numfemale += 1\n        if len(gender.strip()) == 4:\n            nummale += 1\n    return numfemale, nummale\n\n\ndf = data.apply(parsegender, axis=1)\ndata['femalec'] = df.apply(lambda x: x[0])\ndata['malec'] = df.apply(lambda x: x[1])\ndel data['borrower_genders']\ndel data['Unnamed: 0']\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d17970403086a2afe974ec820b362abbb63ea5a4","_cell_guid":"a9f07d18-82b0-4bde-bdb3-c0ed512d5468","trusted":false},"cell_type":"code","source":"print(data['femalec'].describe())\nprint(data['malec'].describe())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"#Borrowed this missing data check from another kernel\ndef mdata(data1):\n    mtotal = data1.isnull().sum().sort_values(ascending=False)\n    mpercent = (data1.isnull().sum() / data1.isnull().count()).sort_values(ascending=False)\n    return pd.concat([mtotal, mpercent], axis=1, keys=['Total', 'Percent'])\nprint(mdata(data))\n\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_kg_hide-output":true,"_uuid":"aa6946896adf019170d1a95cbd3ac2554a2c9cd0","_cell_guid":"c9ccd7cd-31a6-4dc4-8bf2-78b5d97a8b05","trusted":false},"cell_type":"code","source":"#A bit of a messy approach to improve location granularity by extracting region from town names.\n#It takes a long time to run so I am skipping it.\n'''\ndef addregionfromloc(v):\n    if (v['region'] == '' or not isinstance(v['region'], str)) and (\\\n                    isinstance(v['town_name'], str) and len(v['town_name']) > 1):\n    \n        temp = mpi_locations.fillna('zzz').apply(lambda x: x['region'] in v['town_name'], axis=1)\n        temp = temp[temp == True]\n        for item in temp.iteritems():\n        # Limit length problem with match to strings<5 like region 'Bo' or common word Centre\n            if len(mpi_locations.iloc[item[0], 3]) > 5 and (mpi_locations.iloc[item[0], 3] != \"Centre\") and (\\\n                    mpi_locations.iloc[item[0], 3] != \"Northern\") and (\\\n                    mpi_locations.iloc[item[0], 3] != \"Southern\") and (\\\n                    mpi_locations.iloc[item[0], 3] != \"Central\"):\n                print('ADDED region from town', mpi_locations.iloc[item[0], 3], ' from', v['town_name'])\n                return mpi_locations.iloc[item[0], 3]\n\n        return v['region']\n\ndata['region'] = data.apply(addregionfromloc, axis=1)\nprint(mdata(data))\n'''","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"bec7813f350c348d6e49f0f069594f5cdf8ce761","_cell_guid":"dbc1d454-8268-4dbb-b1f4-3d6d6a34d7c9","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"Switching to spark for ML\")\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark import SparkContext, SparkConf\n\nsc = (SparkSession.builder\n                  .appName('Kiva')\n                  .enableHiveSupport()\n                  .config(\"spark.executor.memory\", \"2G\")\n                  .config(\"spark.driver.memory\",\"17G\")\n                  .config(\"spark.executor.cores\",\"7\")\n                  .config(\"spark.python.worker.memory\",\"2G\")\n                  .config(\"spark.driver.maxResultSize\",\"0\")\n                  .config(\"spark.sql.crossJoin.enabled\", \"true\")\n                  .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n                  .config(\"spark.default.parallelism\",\"2\")\n                  .getOrCreate())\nsc.sparkContext.setLogLevel('INFO')\ndata = sc.createDataFrame(data)\ndata.printSchema()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"scrolled":true,"collapsed":true,"_uuid":"3e8366c7f458e80d69f53b8a610e212a62051492","_cell_guid":"5ac2129c-b48f-4559-83a4-746640bcd194","trusted":false},"cell_type":"code","source":"print(\"This cell shows that rMPI can be accurately predicted using the mix of country- and region-level stats in the data. This makes sense since rMPI is calculated using similar data. This random forest regression model could be very helpful to Kiva in estimating missing MPI values using existing data.\")\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.feature import VectorIndexer\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.mllib.util import MLUtils\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nkiva = data.na.drop(subset=[\"rMPI\",'cHDI','cLE','cEDavg','GNI','rPop05','rPPP05'])\nfeaturecolumns = ['cHDI','cLE','cEDavg','GNI','rPop05','rPPP05']\n(training, test) = kiva.randomSplit([0.7, 0.3])\n\nassembler = VectorAssembler(inputCols=featurecolumns, outputCol='features')\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol='rMPI', numTrees=12, featureSubsetStrategy=\"auto\", maxDepth=20)\n\npipeline = Pipeline(stages=[assembler, rf])\n\nmodel = pipeline.fit(training)\npredictions = model.transform(test)\n\npredictions.select(\"prediction\", \"rMPI\", \"features\").show(25)\n\nevaluator = RegressionEvaluator(\n    labelCol=\"rMPI\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"scrolled":true,"_uuid":"5b6d2df0f6e71e609c1a116ac4697522514e52b6","_cell_guid":"f2927bb4-e539-4568-b1a1-83571ecde7f9","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"Here we extract principal components from socioeconomic variables from the previous cell, plus loan and gender variables to meet Kiva's goal of incorporating those aspects into a metric.\\\n      So these 12 variables explain a lot about the loan, country- and regional poverty, and the number of applications + their gender. The PCA finds a way to capture 85% of all the variation across these traits in 5 components.\")\nfrom pyspark.ml.feature import PCA\nfrom pyspark.ml.feature import StandardScaler\n\nfeaturecolumns = ['femalec', 'malec', 'loan_amount', 'term_in_months', 'cHDI','cLE','cEDavg','cEDexp', 'GNI', 'rPop05', 'rPPP00', 'rPPP05']\nkiva = data.na.drop(subset=featurecolumns)\n\nassembler = VectorAssembler(inputCols=featurecolumns, outputCol='features')\nscaler = StandardScaler(inputCol='features', outputCol='zfeatures', withStd=True, withMean=True)\npca = PCA(k=5, inputCol=\"zfeatures\", outputCol=\"pcaFeatures\")\n\npcapipe = Pipeline(stages=[assembler, scaler, pca])\n\npcamodel = pcapipe.fit(kiva)\npcatrained = pcamodel.stages[2]\n\nprint('Explained variance: ', pcatrained.explainedVariance)\nprint('Total explained variance: ', sum(pcatrained.explainedVariance))\n\nprint('Principal components matrix:')\nprint(pcatrained.pc)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"dd0a8cb37a582f487c91a61fc7c23d7939aae4af","_cell_guid":"a93975b1-116c-4168-a560-cb0d1b054de6","trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"print('The PCA could be taken further in order to construct an MPI style metric that factors in data about the loan, gender, etc. -- which could be called the Kestimate')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}