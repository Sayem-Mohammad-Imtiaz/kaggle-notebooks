{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Retail](https://www.xpandretail.com/wp-content/uploads/2018/11/Screen-Shot-2018-11-26-at-2.10.07-PM.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<br>Content:\n* [Sneak Peek into the Data](#1)\n* [Analysis Datewise](#2)\n* [Analysis Storewise](#3)\n* [Analysis Departmentwise](#4)\n* [Analysis Store Type and Year/Month Wise](#5) \n* [Analysis of MarkDown](#6)\n* [Prediction on Date and Store](#7)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\ndf_store = pd.read_csv(\"/kaggle/input/retaildataset/stores data-set.csv\")\ndf_feature = pd.read_csv(\"/kaggle/input/retaildataset/Features data set.csv\",parse_dates=[\"Date\"])\ndf_sales = pd.read_csv(\"/kaggle/input/retaildataset/sales data-set.csv\",parse_dates=[\"Date\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# Sneak Peek into the Data\n\nLets see how the tables look and get some basic information. i.e \n* Data types\n* No of Data (rows and column)\n* Null Data\n* few rows to understand the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_store.info())\nprint(df_store.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_feature.info())\nprint(df_feature.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_sales.info())\nprint(df_sales.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"looking into the data I come to the conclusion that we can group data based on the time,store,department.\nAlso we can check how holiday,Temperature,Fuel Price,CPI,Unemployment,Type of Store affecting sales.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n# **Analysis Datewise**\n\nlet explore data based on the timeline\n\n* lets Merge Feature tables and sales tables based on the date \n* we will convert WeeklySales in Millions\n* we will modify column as the day is holiday or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_date = df_feature.groupby(\"Date\").agg({\"Temperature\":\"mean\"\n                                            ,\"Fuel_Price\":\"mean\"\n                                            ,\"IsHoliday\":\"sum\"\n                                            ,\"CPI\":\"mean\"\n                                           ,\"Unemployment\":\"mean\"})\ndata_date = data_date.sort_index()\ntemp_date_data = data_date[:'2012-12-10']\n\ndata_sales_date = df_sales.groupby(\"Date\").agg({\"Weekly_Sales\":\"sum\"})\ndata_sales_date.sort_index(inplace=True)\ndata_sales_date.Weekly_Sales = data_sales_date.Weekly_Sales/1000000\ndata_sales_date.Weekly_Sales = data_sales_date.Weekly_Sales.apply(int)\ndata = pd.merge(data_sales_date, temp_date_data, left_index=True,right_index=True, how='left')\ndata[\"IsHoliday\"] = data[\"IsHoliday\"].apply(lambda x: True if x == 45.0 else False )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\n#plt.figure(figsize=(15,4))\nfig, ax = plt.subplots(5,1,figsize=(15,10),sharex=True) \ndata[\"Weekly_Sales\"].plot(ax=ax[0],title=\"Weekly Sales/sales on Holiday\")\ndata[data.IsHoliday==True][\"Weekly_Sales\"].plot(marker=\"D\",ax=ax[0],legend=\"Holiday Week sale\")\ndata[\"Temperature\"].plot(ax=ax[1], title=\"Temperature\")\ndata[\"Fuel_Price\"].plot(ax=ax[2],title=\"Fuel_Price\")\ndata[\"CPI\"].plot(ax=ax[3],title=\"CPI\")\ndata[\"Unemployment\"].plot(ax=ax[4],title=\"Unemployment\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Nov- Dec shows spike in Weekly Sales.but over the year it is not increased. \n* weeks nearby holiday shows peak\n* Fuel Price and Consumer Price Index shown growth over the year.\n* Unemployment decreased year after year.\n* Temperature is showing a random walk\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Weekly sales doesnot show any high correlation with any other parameters.\n* CPI and Unemployment  shows negative correlation on other hand Fuel Price show positive correlation\n* Unemployment and Fuel price are also negatively correlated","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_sales_month = data.groupby(data.index.month).agg({\"Weekly_Sales\":\"sum\"})\nplt.figure(figsize=(10, 5))\nsns.barplot(x=data_sales_month.index,y=data_sales_month.Weekly_Sales)\nplt.title(\"Month wise Sales\")\nplt.xlabel(\"Month\")\nplt.ylabel(\"Sales\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It could be as Enough buying during offer and holidays (Black friday Sales,Chrismas,New year) and later sales go down and then again gaining momentum in some months.\n* In Nov also people show less buying can be waiting period for upcoming sales.\n* whole data for Dec-2013 I guess is not available so even after spike in Dec the sales are not gone very high.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_sales_year = data.groupby(data.index.year).agg({\"Weekly_Sales\":\"sum\"})\n\nsns.barplot(x=data_sales_year.index,y=data_sales_year.Weekly_Sales)\nplt.title(\"Year wise Sales\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Sales\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(data[\"Weekly_Sales\"], period=45) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nplt.plot(decomposition.trend)\nplt.plot(decomposition.seasonal)\nplt.plot(decomposition.resid)\nplt.legend([\"Trend\", \"Seasonal\",\"Resid\"], loc =\"upper right\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It shows a sideway trend","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n# **Analysis Storewise**\n\nlets explore the pattern in store for weekly sales data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_Store = df_feature.groupby(\"Store\").agg({\"Temperature\":\"mean\",\"Fuel_Price\":\"mean\",\"IsHoliday\":\"sum\"})\n\ntemp_store = df_sales.groupby(\"Store\").agg({\"Weekly_Sales\":\"sum\"})\ntemp_store.Weekly_Sales = temp_store.Weekly_Sales/1000000\ntemp_store.Weekly_Sales = temp_store.Weekly_Sales.apply(int)\ndata_Store.set_index(np.arange(0,45),inplace=True)\ndf_store[\"temp\"] = data_Store.Temperature\ndf_store[\"Fuel_Price\"] = data_Store.Fuel_Price\ndf_store[\"holiday\"] = data_Store.IsHoliday\ndf_store[\"Weekly_Sales\"] = temp_store.Weekly_Sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_store.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,3,figsize=(15, 4))\nsns.countplot(df_store.Type,ax=ax[0])\nsns.swarmplot(data = df_store,y=\"Size\",x=\"Type\",ax=ax[1])\n\nsns.boxplot(data = df_store,y=\"Weekly_Sales\",x=\"Type\",ax=ax[2])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Store Count is in the order of A, B and least is C \n* Size wise A store as most no of Item followed by B and than C\n* Even After less Count of Store and lesser Size B has more Weekly Sales than A and C at the least.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n# **Analysis Departmentwise**\n\nA little Invesigation on Department","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_sales[\"Dept\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"data_Dept = df_sales.groupby(\"Dept\").agg({\"Weekly_Sales\":\"sum\"})\ndata_Dept.Weekly_Sales = data_Dept.Weekly_Sales/10000\ndata_Dept.Weekly_Sales = data_Dept.Weekly_Sales.apply(int)\ndata_Dept.sort_values(by=\"Weekly_Sales\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1, ax1 = plt.subplots(figsize=(15, 4))\n#ordered_df = data_Dept.sort_values(by='Weekly_Sales')\nplt.vlines(x=data_Dept.index, ymin=0, ymax=data_Dept['Weekly_Sales'], color='skyblue')\nplt.plot(data_Dept.index,data_Dept['Weekly_Sales'], \"o\")\nplt.title(\"Departmentwise Sales\")\nplt.ylabel(\"Sales\")\nplt.xlabel(\"Department\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here  we can see department 1-15 as well as 90-95 has shown  higher weekly sales.\n* some department as 38,40,72 has shown higher weekly sales.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n# Analysis Store Type and Year/Month Wise ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_date_store = df_sales.groupby([\"Date\",\"Store\"]).agg({\"Weekly_Sales\":\"sum\"})\nsales_date_store.sort_index(inplace=True)\nsales_date_store.Weekly_Sales = sales_date_store.Weekly_Sales/10000\nsales_date_store.Weekly_Sales = sales_date_store.Weekly_Sales.apply(int)\ndata_table = pd.merge(df_feature,sales_date_store ,  how='left', on=[\"Date\",\"Store\"])\ndata_table = pd.merge(data_table,df_store[[\"Store\",\"Type\"]] ,  how='left', on=[\"Store\"])\ndata_table.head(20)\ndata_train = data_table[data_table.Weekly_Sales.notnull()]\ndata_test = data_table[data_table.Weekly_Sales.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.barplot(x=data_train.Date.dt.year, y=data_train.Weekly_Sales,hue=data_train.Type)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Store Type A & B has shown slight decrease year on basis in sales.\n* Store C has shown a slight increase in sales.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nsns.barplot(x=data_train.Date.dt.month, y=data_train.Weekly_Sales,hue=data_train.Type)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Type A & B store show spike in Nov Dec mostly due to holiday whereas jan has shown decrease in sale.\n* Type C is consistent over every month and doesnot show much deviation.\n   ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n# Analysis of MarkDown","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,4))\ntrain_markdown = data_table[data_table.MarkDown2.notnull()]\ntrain_markdown = train_markdown.groupby(\"Date\").agg({\"MarkDown1\":\"mean\",\"MarkDown2\":\"mean\",\"MarkDown3\":\"mean\",\"MarkDown4\":\"mean\",\"MarkDown5\":\"mean\"})\n\n\nplt.plot(train_markdown.index,train_markdown.MarkDown1)\nplt.plot(train_markdown.index,train_markdown.MarkDown2)\nplt.plot(train_markdown.index,train_markdown.MarkDown3)\nplt.plot(train_markdown.index,train_markdown.MarkDown4)\nplt.plot(train_markdown.index,train_markdown.MarkDown5)\nplt.title(\"Timeline Markdown\")\nplt.ylabel(\"Markdown\")\nplt.xlabel(\"Date\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_markdown.hist(figsize=(10,8),bins=6,color='Y')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_markdown_month = train_markdown.groupby(train_markdown.index.month).agg({\"MarkDown1\":\"mean\",\"MarkDown2\":\"mean\",\"MarkDown3\":\"mean\",\"MarkDown4\":\"mean\",\"MarkDown5\":\"mean\"})\n\ntrain_markdown_month.plot(kind='bar', stacked=True,figsize=(15,6))\nplt.title(\"Stacked Monthwise Morkdown\")\nplt.ylabel(\"Markdown\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_markdown_1 = data_table[data_table.MarkDown2.notnull()]\ntrain_markdown_type = train_markdown_1.groupby(\"Type\").agg({\"MarkDown1\":\"mean\",\"MarkDown2\":\"mean\",\"MarkDown3\":\"mean\",\"MarkDown4\":\"mean\",\"MarkDown5\":\"mean\"})\n\ntrain_markdown_type.plot(kind='bar', stacked=True,figsize=(10,4))\nplt.title(\"Stacked StoreType Wise\")\nplt.ylabel(\"Markdown\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n# **Prediction on Date and Store**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom fancyimpute import IterativeImputer\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.svm import SVR, LinearSVR, NuSVR\nfrom sklearn.linear_model import ElasticNet, Lasso, RidgeCV,LinearRegression\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,RandomForestRegressor\nimport xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Clean up and preprocessing**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def createdummies(data,cols):\n    for col in cols:\n        one_hot = pd.get_dummies(data[col],prefix=col)\n        data = data.join(one_hot)\n        data.drop(col,axis = 1,inplace=True)\n    \n    return data\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"\n# imputing the missing value\nitt = IterativeImputer()\ndf = itt.fit_transform(data_table[[\"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\"]]) \ndata_table.MarkDown1 = df[:,0]\ndata_table.MarkDown2 = df[:,1]\ndata_table.MarkDown3 = df[:,2]\ndata_table.MarkDown4 = df[:,3]\ndata_table.MarkDown5 = df[:,4]\n\ndata_table['CPI'].fillna((data_table['CPI'].mean()), inplace=True)\ndata_table['Unemployment'].fillna((data_table['Unemployment'].mean()), inplace=True)\ndata_table['IsHoliday'] = data_table['IsHoliday'].map({True:0,False:1})\n\n#create new column\ndata_table[\"Month\"] = data_table.Date.dt.month\ndata_table[\"Year\"] = data_table.Date.dt.year\ndata_table[\"WeekofYear\"] = data_table.Date.dt.weekofyear\ndata_table.drop(['Date'],axis=1,inplace=True)\n\n#create dummies out of categorical column\ndata_table = createdummies(data_table,[\"Type\",\"Month\",\"Year\",\"WeekofYear\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"data_table.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Split**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data_table[data_table.Weekly_Sales.notnull()]\ndata_test = data_table[data_table.Weekly_Sales.isnull()]\nX = data_train.drop('Weekly_Sales', axis=1)\ny = data_train['Weekly_Sales']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Basic Model Creation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\nclassifiers = [\n    LinearRegression(),\n    ElasticNet(),\n    RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]),\n    KernelRidge(alpha=0.6, kernel='polynomial', degree=3, coef0=2.5),\n    Lasso(alpha =16, random_state=100),\n    ElasticNet(alpha=0.8),\n    DecisionTreeRegressor(),\n    RandomForestRegressor(),\n    GradientBoostingRegressor(),\n    AdaBoostRegressor(),\n    SVR(), \n    LinearSVR(), \n    NuSVR(),\n    xgb.XGBRegressor(),\n    lgb.LGBMRegressor()\n    ]\n\nname = []\nscore = []\nmodels = []\nrmse = []\ni = 0\nfor classifier in classifiers:\n    classifier.fit(X_train, y_train)   \n    name.append(type(classifier).__name__)\n    score.append(classifier.score(X_test, y_test))\n    models.append(classifier)\n    rmse.append(np.sqrt(mean_squared_error(classifier.predict(X_test), y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparing Model Performance**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_score = pd.DataFrame(list(zip(name,rmse, score, models)),columns=['name','rmse','score',\"model\"])\ndf_score.set_index('name',inplace=True)\ndf_score.sort_values(by=['score'],inplace=True)\ndf_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = df_score.loc[\"XGBRegressor\",\"model\"]\ndata_test.drop(['Weekly_Sales'],axis=1,inplace=True)\npredict = model.predict(data_test)\npredict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Work In Progress\n\n**Thank you for Reading, Please Upvote ,Comment and Follow for motivating me for more such work**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Thanks](https://www.access2interpreters.com/wp-content/uploads/2016/01/thank-you.jpg)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}