{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Unsupervised Machine Learning on Wholesale Customers Data**","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T06:21:20.359128Z","iopub.execute_input":"2021-08-04T06:21:20.35965Z","iopub.status.idle":"2021-08-04T06:21:20.363857Z","shell.execute_reply.started":"2021-08-04T06:21:20.359618Z","shell.execute_reply":"2021-08-04T06:21:20.363134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:36:16.102584Z","iopub.execute_input":"2021-08-04T06:36:16.102928Z","iopub.status.idle":"2021-08-04T06:36:16.107449Z","shell.execute_reply.started":"2021-08-04T06:36:16.102899Z","shell.execute_reply":"2021-08-04T06:36:16.106269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading the CSV data file and creating the data frame**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nwholesale_data = pd.read_csv('../input/wholesale-customers-data-set/Wholesale customers data.csv')\n\n# just printing random observations and attributes.\nprint(wholesale_data.sample(5))\nprint(\"\\n\\n\")\n\n# dropping of the attributes 'Channel' and 'Region'\n# 'Channel' represents the hotel, cafe or retail store\n# 'Region' represents the customer region \n# dropping of the attributes 'Channel' & ' Region' won't affect the clustering, as we are trying to relate the customers to the products\n# they buy in order to maximize the business\nwholesale_data.drop(labels=['Channel', 'Region'], axis=1, inplace=True)\nprint(wholesale_data.head(5))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:25:19.814987Z","iopub.execute_input":"2021-08-04T06:25:19.815384Z","iopub.status.idle":"2021-08-04T06:25:19.836832Z","shell.execute_reply.started":"2021-08-04T06:25:19.815352Z","shell.execute_reply":"2021-08-04T06:25:19.835864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now to check for null values in the dataset**","metadata":{}},{"cell_type":"code","source":"# Gives us the basic analysis information of the wholesale customer dataset \nwholesale_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:22:19.137014Z","iopub.execute_input":"2021-08-04T06:22:19.137401Z","iopub.status.idle":"2021-08-04T06:22:19.155901Z","shell.execute_reply.started":"2021-08-04T06:22:19.13737Z","shell.execute_reply":"2021-08-04T06:22:19.154775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since the above attributes have non-null values we do not need to do null checks for the attributes**","metadata":{}},{"cell_type":"markdown","source":"**Let's take a look at the basic statisical data**","metadata":{}},{"cell_type":"code","source":"wholesale_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:22:25.057953Z","iopub.execute_input":"2021-08-04T06:22:25.058357Z","iopub.status.idle":"2021-08-04T06:22:25.099921Z","shell.execute_reply.started":"2021-08-04T06:22:25.058314Z","shell.execute_reply":"2021-08-04T06:22:25.099222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wholesale_data.describe().transpose()[['mean','50%','count']].plot.barh()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:56:26.940596Z","iopub.execute_input":"2021-08-04T06:56:26.940975Z","iopub.status.idle":"2021-08-04T06:56:27.230499Z","shell.execute_reply.started":"2021-08-04T06:56:26.940943Z","shell.execute_reply":"2021-08-04T06:56:27.22933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let us perform 'Standardization' and 'Decomposition'** **(Pre processing)**\n\nPreviously we saw the features 'Channel' & 'Region' removed. These values have a low magnitude, whereas the other features like fresh, milk, grocery, frozen, detergents_paper, delicassen seem to have a higher magnitude and it is very necessary to bring these data to the same magnitude, because K- means algorithm is distance based and can have adverse effect with magnitude. Hence similar magnitude is preferred.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nstandard_scaler = StandardScaler()\nscaled_data = standard_scaler.fit_transform(wholesale_data)\n\ntraining_PCA_data = PCA(2).fit_transform(scaled_data)\n\nprint(scaled_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:24:21.874446Z","iopub.execute_input":"2021-08-04T06:24:21.874941Z","iopub.status.idle":"2021-08-04T06:24:23.206808Z","shell.execute_reply.started":"2021-08-04T06:24:21.87491Z","shell.execute_reply":"2021-08-04T06:24:23.205483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(scaled_data).describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:24:25.295828Z","iopub.execute_input":"2021-08-04T06:24:25.296184Z","iopub.status.idle":"2021-08-04T06:24:25.337687Z","shell.execute_reply.started":"2021-08-04T06:24:25.296155Z","shell.execute_reply":"2021-08-04T06:24:25.336569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_PCA_DF = pd.DataFrame(training_PCA_data,columns=['d1','d2'])\ntraining_PCA_DF.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:28:21.626998Z","iopub.execute_input":"2021-08-04T06:28:21.627467Z","iopub.status.idle":"2021-08-04T06:28:21.63971Z","shell.execute_reply.started":"2021-08-04T06:28:21.62743Z","shell.execute_reply":"2021-08-04T06:28:21.638639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_PCA_DF.plot.scatter('d1','d2',s=50)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T07:02:20.486104Z","iopub.execute_input":"2021-08-04T07:02:20.486481Z","iopub.status.idle":"2021-08-04T07:02:20.689308Z","shell.execute_reply.started":"2021-08-04T07:02:20.486448Z","shell.execute_reply":"2021-08-04T07:02:20.68861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now to determine the number of clusters for the K-means algorithm, this can be calculated in 2 ways:**\n\n1. Elbow Method\n2. Silhouette Method","metadata":{}},{"cell_type":"markdown","source":"**Using Elbow Method**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Using elbow methods to determine the number of clusters for the K-Means algorithm\n# WCSS = Within Cluster Sum of Squares\nwcss = [] \nfor i in range(1, 25):\n    km = KMeans(n_clusters = i, init = 'k-means++', \n                max_iter = 300, n_init = 10, random_state = 0)\n    km.fit(training_PCA_DF)\n    wcss.append(km.inertia_)\nplt.plot(range(1, 25), wcss)\nplt.legend(['wcss'])\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('Number of Clusters')\nplt.ylabel('wcss')\nplt.figure(figsize = (10,5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:58:03.02576Z","iopub.execute_input":"2021-08-04T06:58:03.026296Z","iopub.status.idle":"2021-08-04T06:58:05.898455Z","shell.execute_reply.started":"2021-08-04T06:58:03.026245Z","shell.execute_reply":"2021-08-04T06:58:05.897421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using Silhouette Method**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import silhouette_score\n\n# Averaging the clusters with silhouette methods \nsil_avg=[]\ncluster_numbers = [4, 5, 6,7] \nprint(\"Average Silhouette Method\\n\")\nfor one_cluster in cluster_numbers: \n    cluster = KMeans(n_clusters = one_cluster) \n    cluster_labels = cluster.fit_predict(training_PCA_DF) \n    silhouette_avg = silhouette_score(training_PCA_DF, cluster_labels)\n    sil_avg.append([one_cluster,silhouette_avg])\n    print(f\"For clusters = {one_cluster}\")\n    print(f\"The average silhouette score for {one_cluster} is = {silhouette_avg}\")\nsil_avg=np.array(sil_avg)\nplt.plot(sil_avg[:,0],sil_avg[:,1],linestyle='dashed')\nplt.legend(['avg_sil'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:46:28.600019Z","iopub.execute_input":"2021-08-04T06:46:28.600598Z","iopub.status.idle":"2021-08-04T06:46:29.371594Z","shell.execute_reply.started":"2021-08-04T06:46:28.60055Z","shell.execute_reply":"2021-08-04T06:46:29.370609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we can from the above averages that most values are closer to 5, meaning that number of cluster are fixed to 5**","metadata":{}},{"cell_type":"markdown","source":"Now we perform the K-Means clustering and plot the results in a scatterplot","metadata":{}},{"cell_type":"code","source":"print(training_PCA_DF.sample(10))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:46:53.025964Z","iopub.execute_input":"2021-08-04T06:46:53.026472Z","iopub.status.idle":"2021-08-04T06:46:53.035637Z","shell.execute_reply.started":"2021-08-04T06:46:53.026423Z","shell.execute_reply":"2021-08-04T06:46:53.034644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclusters_K_Means = 5\nrandom_state_K_Means = 0\n\nkmean = KMeans(n_clusters=clusters_K_Means, random_state=random_state_K_Means).fit(training_PCA_DF)\nkmean_Y = kmean.predict(training_PCA_DF)\nlab = kmean.labels_\n\nplt.figure(figsize=(10,5))\nplt.title(f\"K- Means with cluster value = {clusters_K_Means}\",fontsize=15)\nplt.scatter(training_PCA_DF['d1'], training_PCA_DF['d2'],c = kmean_Y, s=105, \n        alpha=0.6,marker='o')\nplt.xlabel(\"X Axis\")\nplt.ylabel(\"Y Axis\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:47:55.822535Z","iopub.execute_input":"2021-08-04T06:47:55.822926Z","iopub.status.idle":"2021-08-04T06:47:56.088936Z","shell.execute_reply.started":"2021-08-04T06:47:55.82289Z","shell.execute_reply":"2021-08-04T06:47:56.087774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy.cluster.hierarchy as shc\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.cluster import AgglomerativeClustering\n\n#Agglomerative Clustering\n\nagglometric_clustering= AgglomerativeClustering(n_clusters=clusters_K_Means,affinity = 'euclidean',linkage = 'ward')\nagglometric_clustering_y = agglometric_clustering.fit_predict(training_PCA_DF)\nplt.figure(figsize =(10,5))\nplt.scatter(training_PCA_DF['d1'], training_PCA_DF['d2'],c = agglometric_clustering_y, s=80, alpha=0.6,marker='o')\nplt.title('Agglomerative Clustering',fontsize = 20)\nplt.show()\n\nplt.figure(figsize=(10,5))\nplt.title('Agglomerative Clustering : Dendrogram',fontsize = 20)\ndend=shc.dendrogram(shc.linkage(training_PCA_DF,method='ward') ,truncate_mode='level', p=4) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:49:07.23955Z","iopub.execute_input":"2021-08-04T06:49:07.239916Z","iopub.status.idle":"2021-08-04T06:49:07.758037Z","shell.execute_reply.started":"2021-08-04T06:49:07.239885Z","shell.execute_reply":"2021-08-04T06:49:07.757012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster=AgglomerativeClustering(n_clusters=clusters_K_Means,affinity='euclidean',linkage='ward')\ncluster.fit_predict(training_PCA_DF)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:49:25.317396Z","iopub.execute_input":"2021-08-04T06:49:25.317745Z","iopub.status.idle":"2021-08-04T06:49:25.333714Z","shell.execute_reply.started":"2021-08-04T06:49:25.317715Z","shell.execute_reply":"2021-08-04T06:49:25.332796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import Birch\n\n\n#birch clustering\nbirch_clustering = Birch(branching_factor=500, n_clusters=clusters_K_Means, threshold=1.5)\nbirch_clustering.fit(training_PCA_DF)\nlabels = birch_clustering.predict(training_PCA_DF)\n\nplt.title('Birch Clustering',fontsize = 20)\nplt.scatter(training_PCA_DF['d1'], training_PCA_DF['d2'], c=labels,alpha=0.6,marker='o',s=150)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:51:23.186612Z","iopub.execute_input":"2021-08-04T06:51:23.187001Z","iopub.status.idle":"2021-08-04T06:51:23.42604Z","shell.execute_reply.started":"2021-08-04T06:51:23.186962Z","shell.execute_reply":"2021-08-04T06:51:23.424953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans\n\n# mini batch clustering\n\nminibatch_clustering = MiniBatchKMeans(n_clusters=clusters_K_Means, random_state=random_state_K_Means)\nminibatch_clustering.fit(training_PCA_DF)\n\nlabels = minibatch_clustering.predict(training_PCA_DF)\nplt.title('MiniBatchKMeans clustering',fontsize = 20)\nplt.scatter(training_PCA_DF['d1'], training_PCA_DF['d2'], c=labels,alpha=0.6,marker='o',s=150)\nplt.figure(figsize=(20,15))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T06:51:51.451092Z","iopub.execute_input":"2021-08-04T06:51:51.451456Z","iopub.status.idle":"2021-08-04T06:51:51.661597Z","shell.execute_reply.started":"2021-08-04T06:51:51.451426Z","shell.execute_reply":"2021-08-04T06:51:51.660866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}