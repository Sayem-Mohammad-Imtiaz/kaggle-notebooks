{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorly\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:22.928563Z","iopub.execute_input":"2021-05-29T10:45:22.928958Z","iopub.status.idle":"2021-05-29T10:45:28.256258Z","shell.execute_reply.started":"2021-05-29T10:45:22.928924Z","shell.execute_reply":"2021-05-29T10:45:28.254711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom queue import PriorityQueue\nimport tensorly\nfrom tensorly.decomposition import parafac\nimport math\nfrom tensorly.metrics import regression\n\nimport random\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-29T10:45:28.259052Z","iopub.execute_input":"2021-05-29T10:45:28.259428Z","iopub.status.idle":"2021-05-29T10:45:28.27155Z","shell.execute_reply.started":"2021-05-29T10:45:28.259396Z","shell.execute_reply":"2021-05-29T10:45:28.270754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function that selecteds random samples from all three modes and returns them with their corresponding indices\ndef selectRandomSamples(A1slice,A2slice,A3slice,s1,s2,s3):\n\n    #moi along I:\n    pqI = PriorityQueue()\n    sum_weight = 0\n    for i in range(0,A1slice.shape[0]):\n        sum_weight = 0\n        for j in range(0,A1slice.shape[1]):\n            for k in range(0,A1slice.shape[2]):\n                #print(\"c:\",A1slice[i][j][k])\n                sum_weight += A1slice[i][j][k]\n        pqI.put((-sum_weight,i))\n\n\n\n    selectedI = np.zeros([s1,A1slice.shape[1],A1slice.shape[2]])\n    selectedindxI = np.zeros(s1)\n    i = 0\n    while not pqI.empty():\n        next_item = pqI.get()\n        if i < s1:\n            selectedI[i] = A1slice[next_item[1]]\n            selectedindxI[i] = next_item[1]\n        i += 1\n\n\n\n\n\n\n    #moi along J:\n    pqJ = PriorityQueue()\n    sum_weight = 0\n\n    for i in range(0,A2slice.shape[0]):\n        sum_weight = 0\n        for j in range(0,A2slice.shape[1]):\n            for k in range(0,A2slice.shape[2]):\n                #print(\"c:\",A1slice[i][j][k])\n                sum_weight += A2slice[i][j][k]\n        pqJ.put((-sum_weight,i))\n\n    selectedJ = np.zeros([s2,A2slice.shape[1],A2slice.shape[2]])\n    selectedindxJ = np.zeros(s2)\n    i = 0\n\n    while not pqJ.empty():\n        next_item = pqJ.get()\n        if i < s2:\n            selectedJ[i] = A2slice[next_item[1]]\n            selectedindxJ[i] = next_item[1]\n        i += 1\n\n\n\n    #moi along K:\n    pqK = PriorityQueue()\n    sum_weight = 0\n    for i in range(0,A3slice.shape[0]):\n        sum_weight = 0\n        for j in range(0,A3slice.shape[1]):\n            for k in range(0,A3slice.shape[2]):\n                #print(\"c:\",A1slice[i][j][k])\n                sum_weight += A3slice[i][j][k]\n        pqK.put((-sum_weight,i))\n\n    selectedK = np.zeros([s3,A3slice.shape[1],A3slice.shape[2]])\n    selectedindxK = np.zeros(s3)\n\n    i = 0\n\n    while not pqK.empty():\n        next_item = pqK.get()\n        if i < s3:\n            selectedK[i] = A3slice[next_item[1]]\n            selectedindxK[i] = next_item[1]\n        i += 1\n\n\n    return selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:28.272562Z","iopub.execute_input":"2021-05-29T10:45:28.272849Z","iopub.status.idle":"2021-05-29T10:45:28.298235Z","shell.execute_reply.started":"2021-05-29T10:45:28.272818Z","shell.execute_reply":"2021-05-29T10:45:28.294153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function that builds the Xs tensor\n#Xs tensor is made by combining all selected samples(from selectRandomSamples function) from all three slices\n#The F parameter is a tensor with new incoming data\n#F is set to None in the first iteration i.e for the initial tensor(before any new data has arrived)\n#If new data are sent as parameter during function call, it adds the new data slices to Xs along with the older randomly selected samples\ndef buildXs(selectedI,selectedJ,selectedK,F):\n    if F == None:\n        Xs = np.zeros([(selectedI.shape[0]+selectedJ.shape[0]+selectedK.shape[0]),max(selectedI.shape[1],selectedJ.shape[1],selectedK.shape[1]),max(selectedI.shape[2],selectedJ.shape[2],selectedK.shape[2])])\n    else:\n        fixed1 = F[0]\n        fixed2 = F[1]\n        fixed3 = F[2]\n        Xs = np.zeros([(selectedI.shape[0]+selectedJ.shape[0]+selectedK.shape[0]+fixed1.shape[0]+fixed2.shape[0]+fixed3.shape[0]),max(selectedI.shape[1],selectedJ.shape[1],selectedK.shape[1],fixed1.shape[1],fixed2.shape[1],fixed3.shape[1]),max(selectedI.shape[2],selectedJ.shape[2],selectedK.shape[2],fixed1.shape[2],fixed2.shape[2],fixed3.shape[2])])\n\n    l=0\n    m=0\n    n=0\n\n    for i in range(0,selectedI.shape[0]):\n        for j in range(0,selectedI.shape[1]):\n            for k in range(0,selectedI.shape[2]):\n                Xs[i][j][k] = selectedI[i][j][k]\n                l=i\n                m=j\n                n=k\n                \n    # Add new incoming slices\n    if F != None:\n        for i in range(0,fixed1.shape[0]):\n            l+=1\n            for j in range(0,fixed1.shape[1]):\n                for k in range(0,fixed1.shape[2]):\n                    Xs[l][j][k] = fixed1[i][j][k]\n\n    for i in range(0,selectedJ.shape[0]):\n        l+=1\n        for j in range(0,selectedJ.shape[1]):\n            for k in range(0,selectedJ.shape[2]):\n                Xs[l][j][k] = selectedJ[i][j][k]\n    \n    if F != None:\n        for i in range(0,fixed2.shape[0]):\n            l+=1\n            for j in range(0,fixed2.shape[1]):\n                for k in range(0,fixed2.shape[2]):\n                    Xs[l][j][k] = fixed2[i][j][k]\n\n    for i in range(0,selectedK.shape[0]):\n        l+=1\n        for j in range(0,selectedK.shape[1]):\n            for k in range(0,selectedK.shape[2]):\n                Xs[l][j][k] = selectedK[i][j][k]\n    if F != None:\n        for i in range(0,fixed3.shape[0]):\n            l+=1\n            for j in range(0,fixed3.shape[1]):\n                for k in range(0,fixed3.shape[2]):\n                    Xs[l][j][k] = fixed3[i][j][k]\n\n\n\n    return Xs\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:28.301673Z","iopub.execute_input":"2021-05-29T10:45:28.302241Z","iopub.status.idle":"2021-05-29T10:45:28.3268Z","shell.execute_reply.started":"2021-05-29T10:45:28.302202Z","shell.execute_reply":"2021-05-29T10:45:28.325478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This function returns a summary of the tensor A\n#Summary of a tensor is a tensor Xs which has all the randomly selected samples from all trhee modes\n#The summary may or may not include the new incoming data slices depending on whether it is the initial iteration or not\n\ndef summary(A,s,fixed = None):\n    #determine sample sizes\n    I = A.shape[0]\n    J = A.shape[1]\n    K = A.shape[2]\n    s1 = math.ceil(I/s[0])\n    s2 = math.ceil(J/s[1])\n    s3 = math.ceil(K/s[2])\n\n    \n    #Slice input matrix A along all dimensions\n    A1slice = np.array(tf.slice(A, [0, 0, 0], [tf.shape(A)[0],tf.shape(A)[1] , tf.shape(A)[2]]))\n    print(\"i mode slicing done\")\n    \n\n    A2slice = np.zeros([A.shape[1],A.shape[0],A.shape[2]])\n    for i in range(0,tf.shape(A)[1]):\n        col = tf.slice(A, [0, i, 0], [tf.shape(A)[0],1 , tf.shape(A)[2]])\n        A2slice[i] = col[:,0]\n    print(\"j mode slicing done\")\n    \n    A3slice = np.zeros([A.shape[2],A.shape[0],A.shape[1]])\n    for i in range(0,tf.shape(A)[2]):\n        col = tf.slice(A, [0, 0, i], [tf.shape(A)[0],tf.shape(A)[1] , 1])\n        A3slice[i] = col[:,:,0]\n    print(\"k mode slicing done\")\n    \n    \n    #Choose random samples along modes 1,2,3\n    selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK = selectRandomSamples(A1slice,A2slice,A3slice,s1,s2,s3)\n  \n    #Combine samples\n    if(fixed == None):\n        Xs = buildXs(selectedI,selectedJ,selectedK,F = None)\n    else:\n        Xs = buildXs(selectedI,selectedJ,selectedK,F = fixed)\n\n    \n    return Xs,selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:28.329953Z","iopub.execute_input":"2021-05-29T10:45:28.330288Z","iopub.status.idle":"2021-05-29T10:45:28.346466Z","shell.execute_reply.started":"2021-05-29T10:45:28.330259Z","shell.execute_reply":"2021-05-29T10:45:28.34516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Xnew is used in place of the original tensor when new incoming slices have come\n# When no incoming slices have come yet, and tensor A is at it's initial state, a set of randomly selected samples are selected and saved\n# When new incoming data has arrived, the prevous samples selected when input tensor was at it's initial state are passed as parameters to this function\n# Xnew is built by adding 2 things:\n#     1. Adding the previously selected samples one after another using buildXs to create tensor Xslices\n#     2. Adding the new incoming data slices.(Let use assume that the new data slices are only added along mode three for this code)\n# Xnew is then returned\ndef buildXnew(Xold,F,mode1,mode2,mode3):\n    #Xslices tensor shape:\n    m = mode1.shape[0] \n    n = mode2.shape[0] \n    p = mode3.shape[0]\n    \n    #Build Xslices tensor with mode1,2 and 3 selected slices from previoud tensor\n\n    \"\"\"for i in range(0,m):\n        for j in range(0,n):\n            for k in range(0,p):\n                Xslices[i][j][k] = Xold[int(mode1[i])][int(mode2[j])][int(mode3[k])]\"\"\"\n    \n    Xslices = buildXs(mode1,mode1,mode3,F = None)\n                \n    \n    \n    \n    \n    #Merge Xslices and new incoming slices\n    m = max(Xslices.shape[0],F.shape[0])\n    n = max(Xslices.shape[1],F.shape[1])\n    p = Xslices.shape[2] + F.shape[2]\n    # Here, only p is the added value of shape(2) of Xslices and F because the slices are added along the third dimension\n    new = 0\n    Xnew = np.zeros([m,n,p])\n\n    \n    for i in range(0,m):\n        for j in range(0,n):\n            for k in range(0,p):\n                if k < Xslices.shape[2] and i < Xslices.shape[0] and j < Xslices.shape[1]:\n                    Xnew[i][j][k] = Xslices[i][j][k]\n                elif k >= Xslices.shape[2] and new < F.shape[2] and i < F.shape[0] and j < F.shape[1]:\n                    Xnew[i][j][k] = F[i][j][new]\n                    new+=1\n            new = 0\n                \n        \n   \n    \n                \n                \n    return Xnew\n    \n                ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:28.350414Z","iopub.execute_input":"2021-05-29T10:45:28.350838Z","iopub.status.idle":"2021-05-29T10:45:28.367714Z","shell.execute_reply.started":"2021-05-29T10:45:28.35069Z","shell.execute_reply":"2021-05-29T10:45:28.36674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge(As,Bs,Cs,r, rank,selectedI,selectedJ, selectedK ,Aold=None,Bold=None,Cold=None):\n    usedA =[]\n    if r ==0:\n        A = As\n        B = Bs\n        C = Cs\n    else:\n        vA=np.zeros([Aold.shape[0],1])\n        vB=np.zeros([Bold.shape[0],1])\n        vC=np.zeros([Cold.shape[0],1])\n        \n        for i in range(0,rank):\n            for j in range(0,rank):\n                vA[j] = np.dot(Aold[:,i] , As[:,j])\n                vB[j] = np.dot(Bold[:,i] , Bs[:,j])\n                vC[j] = np.dot(Cold[:,i] , Cs[:,j])\n                \n            idx = np.argsort(vA)\n            idx = idx[::-1]\n            \n            ii=0\n            while(idx[ii] in usedA):\n                ii= ii+1\n            \n            Id = idx[ii]\n            usedA.append(Id)\n            \n            for k in range(0,As.shape[0]):\n                if As[k][Id] == 0:\n                    As[k][Id] = As[k][Id] + Aold[k][i]\n                    \n            for k in range(0,Bs.shape[0]):\n                if Bs[k][Id] == 0:\n                    Bs[k][Id] = Bs[k][Id] + Bold[k][i]\n                    \n            for k in range(0,Cs.shape[0]):\n                if Cs[k][Id] == 0:\n                    Cs[k][Id] = Cs[k][Id] + Cold[k][i]\n        \n        A = As\n        B = Bs\n        C = Cs\n    \n    return A, B, C\n        \n    \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:28.369252Z","iopub.execute_input":"2021-05-29T10:45:28.369537Z","iopub.status.idle":"2021-05-29T10:45:28.391338Z","shell.execute_reply.started":"2021-05-29T10:45:28.36951Z","shell.execute_reply":"2021-05-29T10:45:28.390052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/hotel-reviews/Datafiniti_Hotel_Reviews.csv', header = None, names = ['city', 'name', 'reviews.rating', 'reviews.userProvince'], usecols = [6,11,21,16])\n#df=df.iloc[:5000, :]\n#df['reviews.rating'] = pd.to_numeric(df[\"], downcast=\"float\")\n\nprint('Dataset 1 shape: {}'.format(df.shape))\nprint('-Dataset examples-')\nprint(df.iloc[:5000, :])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:28.392876Z","iopub.execute_input":"2021-05-29T10:45:28.39337Z","iopub.status.idle":"2021-05-29T10:45:29.054707Z","shell.execute_reply.started":"2021-05-29T10:45:28.393323Z","shell.execute_reply":"2021-05-29T10:45:29.049887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove null values\ndf = df[df['reviews.userProvince'].notna()]\n\nsamples = 100\n\ndf1=df.sample(n = samples)\nprint(df1.shape)\n\n\ndf1.head()\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:29.063156Z","iopub.execute_input":"2021-05-29T10:45:29.06441Z","iopub.status.idle":"2021-05-29T10:45:29.117852Z","shell.execute_reply.started":"2021-05-29T10:45:29.064245Z","shell.execute_reply":"2021-05-29T10:45:29.115722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build The Tensor\ndf1['city']=df1['city'].astype('category').cat.codes\ndf1['name']=df1['name'].astype('category').cat.codes\ndf1['reviews.userProvince']=df1['reviews.userProvince'].astype('category').cat.codes\ndf1['reviews.rating']=df1['reviews.rating'].astype('category').cat.codes\n\n\nl = list(df1['city'])\nm = list(df1['name'])\nn = list(df1['reviews.userProvince'])\n#print(n)\n\ncity = dict([(y,x) for x,y in enumerate(set(l))])\nname = dict([(y,x) for x,y in enumerate(set(m))])\nprovince = dict([(y,x) for x,y in enumerate(set(n))])\n\nall_values = city.values()\ncityNo = max(all_values)\n\nall_values = name.values()\nnameNo = max(all_values)\n\nall_values = province.values()\n#print(all_values)\nprovinceNo = max(all_values)\n#print(countryNo)\n\n\nindexlist = []\nvaluelist = []\n  \n\nex = np.zeros([cityNo+1,nameNo+1,provinceNo+1])\n\n\nfor i,j in df1.iterrows():\n    #print(j.Movie_Id)\n    x = city[df1['city'][i]]\n    y = name[df1['name'][i]]\n    z = province[int(df1['reviews.userProvince'][i])]\n\n    #print(str(x)+\" \"+str(y)+\" \"+str(z))\n    info = df1['reviews.rating'][i]\n    \n    #print(info)\n    #print(x,y,z)\n    ex[x][y][z] = info\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:29.120096Z","iopub.execute_input":"2021-05-29T10:45:29.120731Z","iopub.status.idle":"2021-05-29T10:45:29.158554Z","shell.execute_reply.started":"2021-05-29T10:45:29.120675Z","shell.execute_reply":"2021-05-29T10:45:29.157692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#initial inputs\n\n# s specifies the number of samples to be selected in the tensor summary\n# Higher the value of s, higher the accuracy\n# But if s is too high, it may result in overfitting\ns = [5,5,5]\nrank = 3\n\n# Parafac is applied on the initial tensor. This is the only time parafac is applied on the entire tensor\nA = tensorly.tensor(ex)\nfactors = parafac(A,rank = rank, verbose = 0,normalize_factors=False)\n\n\n\n\n# Selected random indices from mode 1,2 and 3 of initial tensor as the FIXED INDICES\n# These samples will be used to estimate the factors later on when new slices are added instead of the full tensor\nXs,selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK = summary(A,s)\n\nprint(\"mode i selected:\",selectedI.shape)\nprint(\"mode j selected:\",selectedJ.shape)\nprint(\"mode k selected:\",selectedK.shape)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:29.159972Z","iopub.execute_input":"2021-05-29T10:45:29.160224Z","iopub.status.idle":"2021-05-29T10:45:30.323341Z","shell.execute_reply.started":"2021-05-29T10:45:29.160199Z","shell.execute_reply":"2021-05-29T10:45:30.322231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The primary sambaten function\n# First, a summary of the tensor is obtained with the previously selected samples and the new incomning slices\n# Then this summary is factoriezed and the corresponding factors are used to estimate the original tensor\ndef SamBATen(X, rank, s, r):\n    for i in range(0,r):\n        if i==0:\n            Xs,selectedI,selectedJ, selectedK, indI,indJ,indK =summary(X,s)\n            fixed = []\n            fixed.append(selectedI) \n            fixed.append(selectedJ) \n            fixed.append(selectedK)\n            \n        else:\n            Xs,selectedI,selectedJ, selectedK, indI,indJ,indK =summary(X,s,fixed)\n            \n        factors = parafac(Xs,rank = rank, verbose = 0,normalize_factors=False)\n        \n        weights = factors[0]\n        '''\n        scaling_matrix = np.array(np.diag(weights**(1/3)))\n        As= np.matmul(np.array(factors[1][0]),scaling_matrix)\n        Bs= np.matmul(np.array(factors[1][1]),scaling_matrix)\n        Cs= np.matmul(np.array(factors[1][2]),scaling_matrix)'''\n        As= factors[1][0]\n        Bs= factors[1][1]\n        Cs= factors[1][2]\n        \n        \n        \n        if i ==0:\n            A, B, C = merge(As,Bs,Cs,i,rank,selectedI,selectedJ, selectedK)\n        else :\n            A, B, C = merge(As,Bs,Cs,i,rank,selectedI,selectedJ, selectedK,Aold,Bold,Cold)\n            \n        Aold = A\n        Bold = B\n        Cold = C\n    return A,B,C,weights\n            ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:30.32488Z","iopub.execute_input":"2021-05-29T10:45:30.325308Z","iopub.status.idle":"2021-05-29T10:45:30.335331Z","shell.execute_reply.started":"2021-05-29T10:45:30.325261Z","shell.execute_reply":"2021-05-29T10:45:30.334424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function creates a new tensor by merging the new slices with the intial tensor\ndef merge_oldnew(A,F):\n    m = A.shape[0]\n    n = A.shape[1]\n    p = A.shape[2]\n    \n    xx = F.shape[2]\n    \n    new = np.zeros(([m,n,p+xx]))\n    \n    fin = 0\n    \n    for i in range(0,m):\n        for j in range(0,n):\n            for k in range(0,new.shape[2]):\n                if k < p:\n                    new[i][j][k] = A[i][j][k]\n                else:\n                    new[i][j][k] = F[i][j][fin]\n                    fin += 1\n            fin = 0\n            \n    return new\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:30.336676Z","iopub.execute_input":"2021-05-29T10:45:30.336935Z","iopub.status.idle":"2021-05-29T10:45:30.354023Z","shell.execute_reply.started":"2021-05-29T10:45:30.336911Z","shell.execute_reply":"2021-05-29T10:45:30.353083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def insert_data(F,n):\n    for i in range(0,F.shape[0]):\n        for j in range(0,n):\n            col = random.randrange(0,85)\n            x = random.randrange(1,5)\n            F[i][col][0] = x\n    return F\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:30.355055Z","iopub.execute_input":"2021-05-29T10:45:30.355322Z","iopub.status.idle":"2021-05-29T10:45:30.36884Z","shell.execute_reply.started":"2021-05-29T10:45:30.355295Z","shell.execute_reply":"2021-05-29T10:45:30.367445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAMBATEN(original)\n# Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 20\nno_of_new_cols = 1\nsambaten_error = 0\nsambaten_fit = 0\n\n\n\nAtotal = A\n\nimport tensorflow\n\nr = 1\nfor i in range(0,additions_no):\n    #Generate a random data sample as new data along the 3rd dimension\n    F = 4*np.random.rand(Atotal.shape[0],Atotal.shape[1],no_of_new_cols)\n    F = np.around(F, decimals=0)\n    #print(X.shape)\n    # The latest incoming slice is added to the total tensor(Atotal contains old and all new data)\n    Atotal = merge_oldnew(Atotal,F)\n    # Anew contains the selected initial sample slices and the last 10 new incoming slices\n    Anew = buildXnew(Atotal,F,selectedI,selectedJ,selectedK)\n    # Anew is used to estimate the new tensor instead of the entire tensor\n    factor1,factor2,factor3,weights = SamBATen(Anew, rank, s, r)\n    #print(\"Components on iteration \",i+1,\":\")\n    #print(factor1,factor2,factor3)\n    factor_array = []\n    factor_array.append(factor1)\n    factor_array.append(factor2)\n    factor_array.append(factor3)\n    \n    #regenerated_tensor = regenerate(factors)\n    regenerated_tensor = tensorly.cp_to_tensor((weights,factor_array))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Atotal) - np.linalg.norm(regenerated_tensor)\n    fit = 1- ((residual) /np.linalg.norm(Atotal))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Atotal))\n    print(\"error\",error)\n    sambaten_error += error\n    sambaten_fit += fit\n    print(\"------------------------------------------------------------------\")\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:30.370921Z","iopub.execute_input":"2021-05-29T10:45:30.371363Z","iopub.status.idle":"2021-05-29T10:45:36.332049Z","shell.execute_reply.started":"2021-05-29T10:45:30.371329Z","shell.execute_reply":"2021-05-29T10:45:36.329825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the average error across all iterations\n\nprint(\"Original Sambaten error: \",(sambaten_error/additions_no)*100)\nprint(\"Original Sambaten fitness: \",(sambaten_fit/additions_no)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.333027Z","iopub.status.idle":"2021-05-29T10:45:36.333441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAMBATEN(modified)\n# Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 20\nno_of_new_cols = 1\nsambaten_error = 0\nsambaten_fit = 0\n\n\n\nAtotal = A\n\nimport tensorflow\n\nr = 1\nfor i in range(0,additions_no):\n    #Generate a random data sample as new data along the 3rd dimension\n    F = 4*np.random.rand(Atotal.shape[0],Atotal.shape[1],no_of_new_cols)\n    F = np.around(F, decimals=0)\n    #Depending on condition, we take the last 10 new incoming slices and merge them to our tensor summary\n    if(i == 0):\n        X = F\n    else:\n        X = merge_oldnew(X,F)\n    if i >= 10:\n        X = merge_oldnew(X,F)\n        X = X[:,:,X.shape[2]-10:X.shape[2]]\n    #print(X.shape)\n    # The latest incoming slice is added to the total tensor(Atotal contains old and all new data)\n    Atotal = merge_oldnew(Atotal,F)\n    print(\"Atotal shape before:\",Atotal.shape)\n    print(i,Atotal.shape[2])\n    Atotal = Atotal[:,:,1:Atotal.shape[2]]\n    print(\"Atotal shape after:\",Atotal.shape)\n    # Anew contains the selected initial sample slices and the last 10 new incoming slices\n    Anew = buildXnew(Atotal,X,selectedI,selectedJ,selectedK)\n    # Anew is used to estimate the new tensor instead of the entire tensor\n    factor1,factor2,factor3,weights = SamBATen(Anew, rank, s, r)\n    #print(\"Components on iteration \",i+1,\":\")\n    #print(factor1,factor2,factor3)\n    factor_array = []\n    factor_array.append(factor1)\n    factor_array.append(factor2)\n    factor_array.append(factor3)\n    \n    #regenerated_tensor = regenerate(factors)\n    regenerated_tensor = tensorly.cp_to_tensor((weights,factor_array))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Atotal) - np.linalg.norm(regenerated_tensor)\n    fit = 1- ((residual) /np.linalg.norm(Atotal))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Atotal))\n    print(\"error\",error)\n    sambaten_error += error\n    sambaten_fit += fit\n    print(\"------------------------------------------------------------------\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.334523Z","iopub.status.idle":"2021-05-29T10:45:36.334989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the average error across all iterations\n\nprint(\"Modified Sambaten error: \",(sambaten_error/additions_no)*100)\nprint(\"Modified Sambaten fitness: \",(sambaten_fit/additions_no)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.33605Z","iopub.status.idle":"2021-05-29T10:45:36.336695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAMBATEN(modified 2)\n# Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 60\nno_of_new_cols = 1\nsambaten_error = 0\nsambaten_fit = 0\n\n# parameter\nerror_limit = 0.1\nnewSliceNo = 30\n\n\n\nAtotal = A\n\nimport tensorflow\n\nr = 1\nfor i in range(0,additions_no):\n    #Generate a random data sample as new data along the 3rd dimension\n    F = 4*np.random.rand(Atotal.shape[0],Atotal.shape[1],no_of_new_cols)\n    F = np.around(F, decimals=0)\n    #Depending on condition, we take the last 10 new incoming slices and merge them to our tensor summary\n    if(i == 0):\n        X = F\n    elif i < 30:\n        X = merge_oldnew(X,F)\n    elif i >= 30:\n        X = merge_oldnew(X,F)\n        X = X[:,:,X.shape[2]-newSliceNo:X.shape[2]]\n    #print(X.shape)\n    # The latest incoming slice is added to the total tensor(Atotal contains old and all new data)\n    Atotal = merge_oldnew(Atotal,F)\n    print(\"Atotal shape before:\",Atotal.shape)\n    Atotal = Atotal[:,:,1:Atotal.shape[2]]\n    print(\"Atotal shape after:\",Atotal.shape)\n    Anew = buildXnew(Atotal,X,selectedI,selectedJ,selectedK)\n    # Anew is used to estimate the new tensor instead of the entire tensor\n    factor1,factor2,factor3,weights = SamBATen(Anew, rank, s, r)\n    #print(\"Components on iteration \",i+1,\":\")\n    #print(factor1,factor2,factor3)\n    factor_array = []\n    factor_array.append(factor1)\n    factor_array.append(factor2)\n    factor_array.append(factor3)\n    \n    #regenerated_tensor = regenerate(factors)\n    regenerated_tensor = tensorly.cp_to_tensor((weights,factor_array))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Atotal) - np.linalg.norm(regenerated_tensor)\n    fit = 1- ((residual) /np.linalg.norm(Atotal))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Atotal))\n    print(\"error\",error)\n    if error >= error_limit:\n        print(\"Recalculate summary\")\n        Xs,selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK = summary(Atotal,s)\n    sambaten_error += error\n    sambaten_fit += fit\n    print(\"------------------------------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:52.253431Z","iopub.execute_input":"2021-05-29T10:45:52.253794Z","iopub.status.idle":"2021-05-29T10:50:35.68882Z","shell.execute_reply.started":"2021-05-29T10:45:52.253763Z","shell.execute_reply":"2021-05-29T10:50:35.687634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the average error across all iterations\n\nprint(\"Modified 2 Sambaten error: \",(sambaten_error/additions_no)*100)\nprint(\"Modified 2 Sambaten fitness: \",(sambaten_fit/additions_no)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:50:35.690989Z","iopub.execute_input":"2021-05-29T10:50:35.691784Z","iopub.status.idle":"2021-05-29T10:50:35.7001Z","shell.execute_reply.started":"2021-05-29T10:50:35.691719Z","shell.execute_reply":"2021-05-29T10:50:35.698834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Online CP, Tucker decomposition and Matrix Product State method are applied in the following cells to demonstrate how our method SAMBATEN performs compared to the existing tensor decomposition methods","metadata":{}},{"cell_type":"markdown","source":"**Online CP**","metadata":{}},{"cell_type":"code","source":"# Online CP\n\nA = tensorly.tensor(ex)\n\nrank = 3\n\n\n\n#Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 30\nno_of_new_cols = 1\n\ncp_error = 0\ncp_fit = 0\n\nm = A.shape[0]\nn = A.shape[1]\np = A.shape[2]\nAnew = A\n\nr = 1\nfor i in range(0,additions_no):\n    F = 4*np.random.rand(Anew.shape[0],Anew.shape[1],no_of_new_cols)\n    F = np.around(F, decimals=0)\n    Anew = merge_oldnew(Anew,F)\n    cp_weight,cp_factors = parafac(Anew,rank = rank, verbose = 0,normalize_factors=False)\n    cp_regenerated = tensorly.cp_to_tensor((cp_weight,cp_factors))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Anew) - np.linalg.norm(cp_regenerated)\n    fit = 1- ((residual) /np.linalg.norm(Anew))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Anew))\n    print(\"error\",error)\n    cp_error += error\n    cp_fit += fit\n    print(\"------------------------------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.34201Z","iopub.status.idle":"2021-05-29T10:45:36.342673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Online cp error: \",(cp_error/additions_no)*100)\nprint(\"Online cp fitness: \",(cp_fit/additions_no)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.343962Z","iopub.status.idle":"2021-05-29T10:45:36.344599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Matrix Product State Method**","metadata":{}},{"cell_type":"code","source":"# Matrix Product State Method\nA3 = tensorly.tensor(ex)\n\nrank = 3\n\nfrom tensorly.decomposition import matrix_product_state\nfrom tensorly import tt_to_tensor\n\n\n\n#Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 30\nno_of_new_cols = 1\n\nmat_product_error = 0\nmat_product_fit = 0\n\nm = A3.shape[0]\nn = A3.shape[1]\np = A3.shape[2]\nAnew3 = A3\n\nr = 1\nfor i in range(0,additions_no):\n    F = 4*np.random.rand(Anew3.shape[0],Anew3.shape[1],no_of_new_cols)\n    Anew3 = merge_oldnew(Anew3,F)\n    factors = matrix_product_state(Anew3, rank=rank)\n    F = np.around(F, decimals=0)\n    cp_regenerated3 = np.round(tt_to_tensor(factors))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Anew3) - np.linalg.norm(cp_regenerated3)\n    fit = 1- ((residual) /np.linalg.norm(Anew3))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Anew3))\n    print(\"error\",error)\n    mat_product_error += error\n    mat_product_fit += fit","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.345863Z","iopub.status.idle":"2021-05-29T10:45:36.346489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Matrix Product State method error: \",(mat_product_error/additions_no)*100)\nprint(\"Matrix Product State method fitness: \",(mat_product_fit/additions_no)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.347772Z","iopub.status.idle":"2021-05-29T10:45:36.348401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tucker Decomposition**","metadata":{}},{"cell_type":"code","source":"# Tucker decomposition\n\nA5 = tensorly.tensor(ex)\n\nrank = 3\n\nfrom tensorly.decomposition import matrix_product_state\nfrom tensorly import tt_to_tensor\nfrom tensorly.decomposition import tucker\nfrom tensorly import tucker_to_tensor\n\n\n#Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 30\nno_of_new_cols = 1\n\ntucker_error = 0\ntucker_fit = 0\n\nm = A5.shape[0]\nn = A5.shape[1]\np = A5.shape[2]\nAnew5 = A5\n\nr = 1\nfor i in range(0,additions_no):\n    F = 4*np.random.rand(Anew5.shape[0],Anew5.shape[1],no_of_new_cols)\n    F = np.around(F, decimals=0)\n    Anew5 = merge_oldnew(Anew5,F)\n    \n    factors = tucker(Anew5, rank=3)\n    regenerated5 = tucker_to_tensor(factors)    \n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Anew5) - np.linalg.norm(regenerated5)\n    fit = 1- ((residual) /np.linalg.norm(Anew5))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Anew5))\n    print(\"error\",error)\n    tucker_error += error\n    tucker_fit += fit","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.349724Z","iopub.status.idle":"2021-05-29T10:45:36.350352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Tucker method error: \",(tucker_error/additions_no)*100)\nprint(\"Tucker method fitness: \",(tucker_fit/additions_no)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:45:36.351708Z","iopub.status.idle":"2021-05-29T10:45:36.352335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This we can see that all the other decomposition methods had much higher percentage of error and lower fitness percentage compared to SAMBATEN.","metadata":{}}]}