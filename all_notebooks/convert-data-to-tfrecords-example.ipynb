{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/tfrecords-gender/data/train/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, sys, math, time, warnings, gc, re, random\nimport pandas as pd\nimport numpy as np\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_len(l):\n    if random.randint(1,101) % 2 == 0:\n        return int(l * 0.97)\n    else:\n        return int(l * 1.03)\ndef get_binry_gendor(x):\n    if x == 'M':\n        return 1\n    else:\n        return 0\ndef get_valid_data(PATH_DATA_CSV):\n    df = pd.read_csv(PATH_DATA_CSV, iterator=True)\n    result_df = pd.DataFrame(columns = ['gender','email'])\n    for i in range(1): # This range(1) for example if do you want preprocessed all data you needed set range(4)\n        data = df.get_chunk(50000) # And add df.get_chunk(5000000)\n        data = shuffle(data)\n        data = data[(data['gender'] != 'N')]\n        data = data[(data['gender'] == 'M') | (data['gender'] == 'F')]\n        data['email'] = data['email'].map(lambda x: valid_string(x))\n        data = data.dropna()\n\n        M = data[(data['gender'] == \"M\")]\n        F = data[(data['gender'] == \"F\")]\n\n        if len(M) > len(F):\n            M = M[:get_len(len(F))]\n        else:\n            F = F[:get_len(len(M))]\n        data = pd.concat([M, F])\n        del M, F\n        gc.collect()\n        data['gender'] = data['gender'].map(lambda x: get_binry_gendor(x))\n        data = shuffle(data)\n        result_df = pd.concat([result_df, data]) \n    return result_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chars = {\"<PAD>\":0,\"a\":1,\"b\":2,\"c\":3,\"d\":4,\"e\":5,\"f\":6,\n      \"g\":7,\"h\":8,\"i\":9,\"j\":10,\"k\":11,\"l\":12,\"m\":13,\n      \"n\":14,\"o\":15,\"p\":16,\"q\":17,\"r\":18,\"s\":19,\"t\":20,\n      \"u\":21,\"v\":22,\"w\":23,\"x\":24,\"y\":25,\"z\":26,\".\": 27}\n\ndef valid_string(email):\n    char_list = list(email.lower())\n    valid_email = ''\n    for c in char_list:\n        if  ord(c.lower()) >= 97 and  ord(c.lower()) <= 122:\n            valid_email += c.lower()\n        else:\n            valid_email += ' '\n    valid_email = valid_email.lstrip()\n    valid_email = valid_email.rstrip()\n    valid_email = re.sub(\" +\", \".\", valid_email)\n    return valid_email[:15]\n\ndef conv2vec(name,no_chars):\n    vec = []\n    for char in valid_string(name):\n        index = chars[char]\n        vec.append(index)\n    if len(vec) < no_chars:\n        diff = no_chars - len(vec)\n        vec+= [0]*(diff)\n    return vec\n\n\ndef preprocess_to_vec(PATH_DATA_CSV):\n    data_df = get_valid_data(PATH_DATA_CSV)\n    data_df = shuffle(data_df) \n    data = data_df.values\n    del data_df\n    gc.collect()\n    no_chars = 0\n    for item in data:\n        name = str(item[1])\n        if len(name) > no_chars: no_chars = len(name)\n    newData = []\n    for item in data:\n        name = str(item[1])\n        name = conv2vec(name,no_chars)\n        newData.append(name + [item[0]])\n    npData = np.array(newData)\n    np.random.shuffle(npData)\n    x = npData[0:,0:15]\n    y = npData[0:,15]\n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir tfrecords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_OUTPUT= './tfrecords/'\nname_size=15\n\ndef _int_feature(list_of_ints): # int64\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n\ndef to_tfrecord(tfrec_filewriter, email, label):\n    feature = {\n      \"email\": _int_feature(email.tolist()),\n      \"label\": _int_feature([label])\n    }\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\nprint(\"Writing TFRecords\")\n\nborder=95000000 #  unique preprocessed emails ~ 95000000 \nborder_counter=0\nbatch_size = 102400\nmax_batches = border//batch_size\ncount=0\nbatch_caunt = 1\nLIST_DATA = os.listdir('/kaggle/input/tfrecords-gender/data/train/')\nwhile border > border_counter:\n    x,y = preprocess_to_vec(f'/kaggle/input/tfrecords-gender/data/train/{LIST_DATA[batch_caunt-1]}')\n    max_packing = len(x) // 102400\n    count_packing = 1\n    batch_last_size = len(x) % 102400\n    batch = []\n\n    for item in zip(x,y):\n        count+=1\n        batch.append([*item])\n        if max_packing <= count_packing and len(batch) >= batch_last_size:\n            filename = GCS_OUTPUT + \"{:02d}-{}.tfrec\".format(batch_caunt, batch_size)\n            count_packing+=1\n            with tf.io.TFRecordWriter(filename) as out_file:\n                for i_batch in batch:\n                    example = to_tfrecord(out_file,i_batch[0],i_batch[1])\n                    out_file.write(example.SerializeToString())\n                batch = []\n                batch_caunt+=1\n                count_packing = 1\n            print(\"Wrote last file {} containing {} records\".format(filename, batch_size))\n        \n        if len(batch) >= batch_size:\n            filename = GCS_OUTPUT + \"{:02d}-{}.tfrec\".format(batch_caunt, batch_size)\n            count_packing+=1\n            with tf.io.TFRecordWriter(filename) as out_file:\n                for i_batch in batch:\n                    example = to_tfrecord(out_file,i_batch[0],i_batch[1])\n                    out_file.write(example.SerializeToString())\n                batch = []\n                batch_caunt+=1\n            print(\"Wrote file {} containing {} records\".format(filename, batch_size))\n\n    del x\n    del y\n    gc.collect()\n    border_counter+=20000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tfrecord(example):\n    features = {\n        \"email\":tf.io.FixedLenFeature([15], tf.int64), \n        \"label\":tf.io.FixedLenFeature([], tf.int64, default_value=0)\n        }\n    example=tf.io.parse_single_example(example, features)\n    return example['email'], example['label']\n\ndef load_dataset(filenames):\n    option_no_order = tf.data.Options()\n    option_no_order.experimental_deterministic = False\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    dataset = dataset.with_options(option_no_order)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n    return dataset\n\ndef get_training_dataset():\n    dataset = load_dataset('./tfrecords/01-102400.tfrec')\n    dataset = dataset.shuffle(25021)\n    return dataset.prefetch(AUTO)\n\ndat = get_training_dataset()\nfor item in dat.take(10):\n    print(item[0].numpy(),item[1].numpy())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}