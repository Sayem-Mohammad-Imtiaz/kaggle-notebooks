{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подключаем библиотеки"},{"metadata":{},"cell_type":"markdown","source":"1. Деревья решений"},{"metadata":{},"cell_type":"markdown","source":"1.1 Подключитесь к набору данных. Разберитесь в том, как устроен датасет и какова постановка задачи. Сделайте необходимый препроцессинг данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Загрузка данных\ndf = pd.read_csv(\"/kaggle/input/bank-marketing-dataset/bank.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Статистика по числовым признакам\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Датасет состоит из данных маркетингового банка(возраст клиента, образование, баланс и тд). Target переменная - deposit. Цель прогнозной модели - проанализировать данные и выяснить внесет ли человек депозит.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['deposit']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Целевой признак (target) - deposit. Задача обучения - классификация, так как имеет конечное количество ответов(\"да\" или \"нет\")"},{"metadata":{},"cell_type":"markdown","source":"Сделайте необходимый препроцессинг данных (удаление лишних признаков, кодирование категориальных признаков, логарифмирование целевой переменной, масштабирование)"},{"metadata":{},"cell_type":"markdown","source":"Преобразование категориальных признаков проведем путём кодирования с помощью map()"},{"metadata":{},"cell_type":"markdown","source":"Для признаков имеющих больше двух параметров воспользуемся get_dummies()"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_values = {'yes':  1, 'no': 0} \ndf['deposit1'] = df['deposit'].map(new_values)\ndf['housing1'] = df['housing'].map(new_values)\ndf['loan1'] = df['loan'].map(new_values)\n\ndf['default1'] = df['default'].map(new_values)\ndf['contact'].value_counts()\n\nnew_values_1 = {'cellular':  1, 'unknown': 0,'telephone' : 1 } \ndf['contact1'] = df['contact'].map(new_values_1)\ndf['contact1'].value_counts()\n\nnew_values_2 = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec':12}\ndf['month1'] = df['month'].map(new_values_2)\n\ndf = df.drop(['deposit','housing','loan','default','contact', 'month'], axis = 1)\n\ndf = pd.get_dummies(df, columns=['marital','poutcome','education'])\ndf.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.2 Разбейте набор данных на обучающую и валидационную (тестовую) выборки с помощью метода train_test_split ."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('deposit1', axis=1).drop('job',axis = 1)\ny = df['deposit1'] \n\n\n# Разделение\n# test_size --- доля исходных данных, которую оставляем для валидации\n# random_state --- произвольное целое число, для воспроизводимости случайных результатов\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=12)\nX.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( X_valid.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.3 Обучите алгоритм классификации DecisionTreeClassifier. Оцените качество каждой модели на отложенной выборке с помощью accuracy_score."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ntree = DecisionTreeClassifier(max_depth=3, random_state=2019)\ntree.fit(X_train, y_train)\ny_pred = tree.predict(X_valid)\nprint('Качество модели:', accuracy_score(y_pred, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Настройка гиперпараметров дерева\n"},{"metadata":{},"cell_type":"markdown","source":"2.1 Создайте генератор разбиений, помешивающий выборку перед созданием блоков. Число блоков равно 5."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42) # n_splits играет роль K\nscores = cross_val_score(tree, X, y, cv=kf, scoring='accuracy')\nprint('Массив значений метрики:', scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.2 Осуществите кросс-валидацию модели для подбора гиперпараметров. Используйте GridSearchCV. Интервалы изменения гиперпараметров задайте самостоятельно.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Кросс-валидация и подбор гиперпараметров\nfrom sklearn.model_selection import GridSearchCV\n\ntree_params_depth = {'max_depth': np.arange(2, 11)}\n\ntree_grid_depth = GridSearchCV(tree, tree_params_depth, cv=5, scoring='accuracy') # кросс-валидация по 5 блокам\ntree_grid_depth.fit(X_train, y_train)\ntree_grid_depth.best_params_\nm_depth = tree_grid_depth.best_params_['max_depth']\nprint(m_depth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_params_split = {'min_samples_split': np.arange(2,21)}\n\ntree = DecisionTreeClassifier(max_depth = m_depth)\ntree_grid_samples_split = GridSearchCV(tree, tree_params_split, cv=5, scoring='accuracy')\ntree_grid_samples_split.fit(X_train, y_train)\ntree_grid_samples_split.best_params_\nm_split = tree_grid_samples_split.best_params_['min_samples_split']\nprint(m_split)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_params_leaf = {'min_samples_leaf':np.arange(2,21)}\n\ntree = DecisionTreeClassifier(max_depth = m_depth, min_samples_split = m_split)\ntree_grid_samples_leaf = GridSearchCV(tree, tree_params_leaf, cv=5, scoring='accuracy')\ntree_grid_samples_leaf.fit(X_train, y_train)\ntree_grid_samples_leaf.best_params_\nm_leaf = tree_grid_samples_leaf.best_params_['min_samples_leaf']\nprint(m_leaf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_params_features = {'max_features':np.arange(2,21)}\n\ntree = DecisionTreeClassifier(max_depth = m_depth, min_samples_split = m_split, min_samples_leaf = m_leaf)\ntree_grid_features = GridSearchCV(tree, tree_params_features, cv=5, scoring='accuracy')\ntree_grid_features.fit(X_train, y_train)\ntree_grid_features.best_params_\nm_features = tree_grid_features.best_params_['max_features']\nprint(m_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.3 Постройте валидационные кривые. Сделайте выводы."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Валидационная кривая\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2, 2, figsize = (10,10))\n\nax[0, 0].set_xlabel('max_depth')\nax[0, 0].set_ylabel('accuracy score')\nax[0, 0].plot(tree_params_depth['max_depth'], tree_grid_depth.cv_results_['mean_test_score']);\n\nax[0, 1].set_xlabel('min_samples_split')\nax[0, 1].set_ylabel('accuracy score')\nax[0, 1].plot(tree_params_split['min_samples_split'], tree_grid_samples_split.cv_results_['mean_test_score']);\n\nax[1, 0].set_xlabel('min_samples_leaf')\nax[1, 0].set_ylabel('accuracy score')\nax[1, 0].plot(tree_params_leaf['min_samples_leaf'], tree_grid_samples_leaf.cv_results_['mean_test_score']);\n\nax[1, 1].set_xlabel('max_features')\nax[1, 1].set_ylabel('accuracy score')\nax[1, 1].plot(tree_params_features['max_features'], tree_grid_features.cv_results_['mean_test_score']);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Вывод: набор гиперпараметров хороший, но не лучший(не удалось подобрать все 4 гиперпараметра одновременно)"},{"metadata":{},"cell_type":"markdown","source":"2.4 Постройте графически полученное дерево. Оцените важность признаков."},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth = m_depth, min_samples_split = m_split, min_samples_leaf = m_leaf, max_features = m_features, random_state=19)\ntree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\n\nexport_graphviz(tree, out_file = 'tree.dot', feature_names = X.columns)\nprint(open('tree.dot').read())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Ссылка на гугл-диск с картинкой](https://drive.google.com/file/d/1oiC1LRZHSS5olsEmKnkWzjFOc_SfgiVF/view?usp=sharing)"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dict(zip(range(len(X.columns)), X.columns))\n\n# Важность признаков\nimportances = tree.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n# Plot the feature importancies of the forest\nnum_to_plot = max(10, len(X.columns))\nfeature_indices = [ind for ind in indices[:num_to_plot]]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(num_to_plot):\n    print(f+1, features[feature_indices[f]], importances[indices[f]])\n\nplt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[i]) for i in feature_indices]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Вывод: 'duration' - самый влиятельный признак. После него идут 'month', 'contact' и далее по убыванию. Самыми не влиятельными признаками оказались 'poutcome', 'education'."},{"metadata":{},"cell_type":"markdown","source":"3. Случайный лес"},{"metadata":{},"cell_type":"markdown","source":"3.1 Постройте модельь случайного леса для вашей задачи с гиперпараметрами по умолчанию и оцените качество модели."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучение случайного леса\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100, random_state=2019)\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_valid)\n\nfrom sklearn.metrics import accuracy_score\n\nprint(accuracy_score(y_valid, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.2 Осуществите подбор гиперпараметров модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params_estimators = {\"n_estimators\":[50, 100, 150, 200, 350, 400]}\nrf_estimators = GridSearchCV(rf, rf_params_estimators, cv=5, scoring='accuracy')\nrf_estimators.fit(X_train, y_train)\nrf_estimators.best_params_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params_depth = {'max_depth': np.arange(2, 11)}\nrf = RandomForestClassifier(random_state = 19, n_estimators = 200)\nrf_grid_depth = GridSearchCV(rf, rf_params_depth, cv=5, scoring='accuracy') \nrf_grid_depth.fit(X_train, y_train)\nrf_grid_depth.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params_split = {'min_samples_split': np.arange(2, 21)}\nrf = RandomForestClassifier(random_state = 19, n_estimators = 200, max_depth = 10)\nrf_grid_split = GridSearchCV(rf, rf_params_split, cv=5, scoring='accuracy') \nrf_grid_split.fit(X_train, y_train)\nrf_grid_split.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params_leaf = {'min_samples_leaf': np.arange(2, 21)}\nrf = RandomForestClassifier(random_state = 19, n_estimators = 200, max_depth = 10, min_samples_split = 5)\nrf_grid_leaf = GridSearchCV(rf, rf_params_leaf, cv=5, scoring='accuracy') \nrf_grid_leaf.fit(X_train, y_train)\nrf_grid_leaf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params_features = {'max_features': np.arange(2, 21)}\nrf = RandomForestClassifier(random_state = 19, n_estimators = 200, max_depth = 10, min_samples_split = 5, min_samples_leaf= 7)\nrf_grid_features = GridSearchCV(rf, rf_params_features, cv=5, scoring='accuracy') \nrf_grid_features.fit(X_train, y_train)\nrf_grid_features.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Набор гиперпараметров:\n\nn_estimators = 200\n\nmax_depth = 10\n\nmin_samples_split = 5\n\nmin_samples_leaf = 7\n\nmax_features = 15"},{"metadata":{},"cell_type":"markdown","source":"3.3 Постройте валидационные кривые для каждого из гиперпараметров."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Валидационная кривая\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2, 2, figsize = (10,10))\n\nax[0,0].set_xlabel('n_estimators')\nax[0,0].set_ylabel('accuracy score')\nax[0,0].plot(rf_params_estimators['n_estimators'], rf_estimators.cv_results_[\"mean_test_score\"]);\n\nax[0, 1].set_xlabel('max_depth')\nax[0, 1].set_ylabel('accuracy score')\nax[0, 1].plot(rf_params_depth['max_depth'], rf_grid_depth.cv_results_['mean_test_score']);\n\nax[1, 0].set_xlabel('min_samples_split')\nax[1, 0].set_ylabel('accuracy score')\nax[1, 0].plot(rf_params_split['min_samples_split'], rf_grid_split.cv_results_['mean_test_score']);\n\nax[1, 1].set_xlabel('min_samples_leaf')\nax[1, 1].set_ylabel('accuracy score')\nax[1, 1].plot(rf_params_leaf['min_samples_leaf'], rf_grid_leaf.cv_results_['mean_test_score']);\n\nax[1, 2].set_xlabel('max_features')\nax[1, 2].set_ylabel('accuracy score')\nax[1, 2].plot(rf_params_features['max_features'], rf_grid_features.cv_results_['mean_test_score']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" 3.4 Оцените важность признаков данной модели. Визуализируйте топ-10 самых полезных признаков."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dict(zip(range(len(X.columns)), X.columns))\n\n# Важность признаков\nimportances = tree.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n# Plot the feature importancies of the forest\nnum_to_plot = max(10, len(X.columns))\nfeature_indices = [ind for ind in indices[:num_to_plot]]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(num_to_plot):\n    print(f+1, features[feature_indices[f]], importances[indices[f]])\n\nplt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[i]) for i in feature_indices]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Наиболее влиятельными оказались те же признаки, что и для дерева решений - 'duration', 'month' и тд. И самыми наименее значимыми признаками оказались также 'poutcome' и 'education'."},{"metadata":{},"cell_type":"markdown","source":"3.5 Сравните результаты метода ближайших соседей, дерева решений и случайного леса. Сформулируйте выводы."},{"metadata":{},"cell_type":"markdown","source":"Метод ближайших соседей является самым времязатратным и подходящим только для небольших исследований, качество модели худшее среди всех. Дерево решений справляется с задачами намного быстрее метода ближайших соседей, качество модели лучше чем в случае kNN. Случайный лес также является неплохим методом по сравнению с kNN, качество модели было лучшим среди всех, однако в данном случае(при большом кол-ве деревьев) работал очень долго. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}