{"cells":[{"metadata":{"id":"72-WEEelKuZP","colab_type":"code","outputId":"c2bc3371-e81b-47ac-949b-116eee9687c8","colab":{"base_uri":"https://localhost:8080/","height":35},"trusted":true},"cell_type":"code","source":"try:\n  # Use the %tensorflow_version magic if in colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\n\nimport tensorflow as tf\nimport time\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nprint('done')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE=64\nIMG_HEIGHT=96\nstart = time.time()\nCLASS_NAMES=[str(i) for i in range(1,103)]\n#image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\ndata_dir = \"/kaggle/input/pytorch-challange-flower-dataset/flower_data/flower_data/train\"\nlist_ds = tf.data.Dataset.list_files(str(data_dir+'/*/*'))\ndef get_label(file_path):\n  # convert the path to a list of path components\n  parts = tf.strings.split(file_path, os.path.sep)\n  # The second to last is the class-directory\n  return int(parts[-2])\ndef decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_jpeg(img, channels=3)\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.\n  return tf.image.resize(img, [IMG_HEIGHT, IMG_HEIGHT])\ndef process_path(file_path):\n  label = get_label(file_path)\n  # load the raw data from the file as a string\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label\n# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\nlabeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n\ndef prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n  # This is a small dataset, only load it once, and keep it in memory.\n  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n  # fit in memory.\n  if cache:\n    if isinstance(cache, str):\n      ds = ds.cache(cache)\n    else:\n      ds = ds.cache()\n\n  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n  # Repeat forever\n  ds = ds.repeat()\n\n  ds = ds.batch(BATCH_SIZE)\n\n  # `prefetch` lets the dataset fetch batches in the background while the model\n  # is training.\n  ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n  return ds\n\ntrain_ds = prepare_for_training(labeled_ds)\nend=time.time()\nprint((end-start)*1000/60)\ntest_dir = \"/kaggle/input/pytorch-challange-flower-dataset/flower_data/flower_data/valid\"\nlist_ds = tf.data.Dataset.list_files(str(test_dir+'/*/*'))\nlabeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = prepare_for_training(labeled_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(labeled_ds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, label in labeled_ds.take(1):\n  print(\"Image shape: \", type(image))\n  print(\"Label: \", label.numpy())\nprint(CLASS_NAMES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image_batch, label_batch in train_ds.take(1):\n   pass\n\nimage_batch.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"USvtyBxO-Izn","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\"\"\"\nmodel = tf.keras.Sequential(layers)\nmodel.compile(optimizer=tf.optimizers.Adam(),\n             loss=tf.losses.SparseCategoricalCrossentropy(),\n              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n\"\"\"\nbase_model = tf.keras.applications.MobileNetV2(input_shape=(96, 96, 3),\n                                              include_top=False,\n                                               weights='imagenet')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_batch = base_model(image_batch)\nprint(feature_batch.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_layer = tf.keras.layers.Dense(103)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"MMJ2P7co_PZa","colab_type":"code","outputId":"dff8374a-923d-4ad3-dd93-f59e44db5c85","colab":{"base_uri":"https://localhost:8080/","height":166},"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  base_model,\n  global_average_layer,\n  prediction_layer\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"r_NWCfh2_8n3","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"logdir=\"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(train_ds,steps_per_epoch=50,epochs=1,validation_data=test_ds,validation_steps=50,callbacks=[tensorboard_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext tensorboard\n%tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([4.0,6.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ntrain_path = \"/kaggle/input/pytorch-challange-flower-dataset/flower_data/flower_data/valid/\"\nimage_files = os.listdir(train_path)\ntrain_images=[]\ntrain_labels=[]\ndef load_image(file_path):\n    return cv2.imread(file_path)\nfor folder in image_files:\n  for file in os.listdir(train_path+\"/\"+folder):\n    train_images.append(load_image(train_path +folder+ \"/\"+file))\n    #train_images.append(file)\n    train_labels.append(int(folder))\nprint('done')\ndef preprocess_image(img, side=96):\n    min_side = min(img.shape[0], img.shape[1])\n    img = img[:min_side, :min_side]\n    img = cv2.resize(img, (side,side))\n    return img / 255.0\nfor i in range(len(train_images)):\n    train_images[i] = preprocess_image(train_images[i])\ntrain_images=np.array(train_images)\ntrain_labels = np.array(train_labels)\neval_predictions=model.predict(train_images)\nresult=[]\ncrct =0 \nfor i in range(len(train_labels)):\n    result.append(np.argmax(eval_predictions[i]))\n    if result[i]==train_labels[i]:\n        print(result[i],train_labels[i],\"yes\")\n        crct=crct+1 \n    else:\n        print(result[i],train_labels[i],\"no\")\nprint(crct/len(eval_predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(crct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}