{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Submitted By: Zeenat Zulfiqar \n# Submitted TO: Dr.Tehseen Zia\n# Course: Advanced Artificial intelligence\n# implementation of Deep Neural Network Model\n\n I have implement Deep Neural Network (DNN) using model on Kaggle kernel. I choose dataset from Public kaggle dataset of Fashion MNIST. Our model accuracy is 0.8542.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# STEP1: \nIn first step i have import libraries.The first library is numpy.NumPy is a Python package which stands for ‘Numerical Python’.It is the core library for scientific computing, which contains a powerful n-dimensional array object.The second library which i import is pandas, this is used for data processing.It stand for paython data analysis library.Pandas is an open source Python package that provides numerous tools for data analysis.The third library is\n'os'.The os module is a part of the standard library, within Python.The main purpose of the OS module is to interact with your operating system.The OS module in Python provides a way of using operating system dependent\nfunctionality.\n\n***NumPy is usually imported under the np alias.***\n# alias: \n**In Python alias are an alternate name for referring to the same thing.********\nCreate an alias with the as keyword while importing:\n**Now the NumPy package can be referred to as np instead of numpy.***","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# STEP2. \nAfter import the important libraries.I have load dataset as a input that take dataset from fashion mnist.\nos.listdir() method in python is used to get the list of all files and directories in the specified directory.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np         # linear algebra\nimport pandas as pd        # data processing \nimport os\n\n# in this step i have  load dataset as a input that take dataset from fashion mnist\n\n\n\n\n\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 3:\nIn this step I have Assign training and testing data to the variables.And print the values in .csv","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":" \ndata_train = pd.read_csv(\"../input/fashion-mnist_train.csv\")\ndata_test = pd.read_csv(\"../input/fashion-mnist_test.csv\")\nprint(data_train)\nprint(data_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 4: \nIn this step i have import tensorflow.TensorFlow is an open source library for fast numerical computing.After that i have assigned training data to feature variable and some labels of training data to labels variable.\n# **train-input-fn**\nTo import data to the Estimator later, we prepare an input_fn for training, testing and prediction respectively. In each input_fn, we provide all input features and values in x and the true labels in y.\n# **num_epochs**\nnum_epochs indicates how many times will the input_fn return the whole batch\n\n# batch_size \n\nbatch_size denotes the subset size of your training sample (e.g. 100 out of 1000) which is going to be used in order to train the network during its learning process\n# shuffle\nWhether to shuffle the data. Default: True. If set to False, sorts the data in alphanumeric order.\n\n# feature_columns\nAn iterable containing all the feature columns used by the model. All items in the set should be instances of classes derived from FeatureColumn\n# n_classes\nnumber of label classes. Default is binary classification. Note that class labels are integers representing the class index (i.e. values from 0 to n_classes-1). For arbitrary label values (e.g. string labels), convert to class indices first.\n# What is Linear Classifier?\nThe two most common supervised learning tasks are linear regression and linear classifier. Linear regression predicts a value while the linear classifier predicts a class.\n","execution_count":null},{"metadata":{"trusted":true,"_uuid":"10af3c0c13658c23a02b9a379f3dcffb416187e9"},"cell_type":"code","source":"import tensorflow as tf\n\n#First column of training data is assigned to features varaibles and some labels of traning data to labels  variable\nfeatures = data_train[data_train.columns[1:]]\nlabels = data_train['label']\n\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n        x={\"pixels\": features.values/255},\n        y=labels,\n        batch_size=100,\n        num_epochs=3,\n        shuffle=True)\nfeature_columns = [tf.feature_column.numeric_column(\"pixels\", shape=784)]\nclassifier = tf.estimator.LinearClassifier(\n                feature_columns=feature_columns, \n                n_classes=10\n                )\nclassifier.train(input_fn=train_input_fn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 5\nIn this step i have assign the tested data to features and labels variables.\n\n\n\n","execution_count":null},{"metadata":{"trusted":true,"_uuid":"3f73326c2c8b2a7b372288dd263a7ef985267686"},"cell_type":"code","source":"features = data_test[data_test.columns[1:]]\nlabels = data_test[\"label\"]\n\nevaluate_input_fn = tf.estimator.inputs.numpy_input_fn(\n        x={\"pixels\": features.values/255},\n        y=labels,\n        batch_size=100,\n        num_epochs=1,\n        shuffle=False)\nclassifier.evaluate(input_fn=evaluate_input_fn)[\"accuracy\"]\n\npredict_input_fn = tf.estimator.inputs.numpy_input_fn(        \n        x={'pixels': features.iloc[5000:5005].values/255},\n        batch_size=1,\n        num_epochs=1,\n        shuffle=False)\npredictions = classifier.predict(input_fn=predict_input_fn)\n\nfor prediction in predictions:\n    print(\"Predictions:    {} with probabilities {}\\n\".format(\n        prediction[\"classes\"], prediction[\"probabilities\"]))\nprint('Expected answers values: \\n{}'.format(\n    labels.iloc[5000:5005]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 6:\n# Pyplot \nis a collection of functions in the popular visualization package Matplotlib. Its functions manipulate elements of a figure, such as creating a figure, creating a plotting area, plotting lines, adding plot labels, etc.\n# Note \nthat  import the pyplot module of the matplotlib library under the alias plt.\n# Matplolib\nIt's a Python plotting library, inspired by MATLAB, meaning that the terms used (Axis, Figure, Plots) will be similar to those used in MATLAB\n# %matplotlib inline\nturns on “inline plotting”, where plot graphics will appear in your notebook. This has important implications for interactivity: for inline plotting, commands in cells below the cell that outputs a plot will not affect the plot. For example, changing the color map is not possible from cells below the cell that creates a plot.\n","execution_count":null},{"metadata":{"trusted":true,"_uuid":"9e7745be223ce875ae2b67d04c0684b744d5a080"},"cell_type":"code","source":"#Used this library for graph\nimport matplotlib.pyplot as plt\n%matplotlib inline\nclass_table = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\"\n]\n\ndef get_label_cls(label):\n    \"\"\"given an int label range [0,9], return the string description of that label\"\"\"\n    return class_table[label]\n\nget_label_cls(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 7:\n#  plt.figure()\nThe purpose of using plt.figure() is to create a figure object.\n#  plt.title\n displaying the title\n#  plt.imshow() \n creates an image from a 2-dimensional numpy array. \n","execution_count":null},{"metadata":{"trusted":true,"_uuid":"2197012a2c4bcbd8adf64790697c3b8833a399aa"},"cell_type":"code","source":"for i in range(5000,5005): \n    sample = np.reshape(data_test[data_test.columns[1:]].iloc[i].values/255, (28,28))\n    plt.figure()\n    plt.title(\"labeled class {}\".format(get_label_cls(data_test[\"label\"].iloc[i])))\n    plt.imshow(sample, 'gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 8:\n# hidden_units\nIterable of number hidden units per layer. All layers are fully connected. Ex. [40, 30,20] means first layer has 40 nodes and second one has 30 and third layer has 20 nodes.\n# feature_columns\nAn iterable containing all the feature columns used by the model. All items in the set should be instances of classes derived from _FeatureColumn.\n# n_classes\nNumber of label classes. Defaults to 2, namely binary classification. Must be > 1.\n#  model_dir\nDirectory to save model parameters, graph and etc. This can also be used to load checkpoints from the directory into a estimator to continue training a previously saved model.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"1b069ee1631e9f078491aafbdb8b006e22b8f03e"},"cell_type":"code","source":"DNN = tf.estimator.DNNClassifier(\n                feature_columns=feature_columns, \n              hidden_units=[40,30,20],\n                n_classes=10,\n                model_dir=\"./models/deep1\"\n                )\nDNN.train(input_fn=train_input_fn)\nDNN.evaluate(input_fn=evaluate_input_fn)[\"accuracy\"]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}