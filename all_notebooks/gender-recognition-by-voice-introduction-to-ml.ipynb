{"cells":[{"metadata":{"_uuid":"4b840e29c1e1e5e5b91da7bb7cb1e82a6d928db3","_cell_guid":"ad094a0b-7d1e-48d4-a53f-028189f085b2"},"cell_type":"markdown","source":"What's a Notebook?\n\nIt's an interactive computational environment, in which you can combine:\n1. code execution, \n2. **rich text**,\n3. plots. \n\nKaggle allows you to write Notebooks for free based on either R or Python using pre-loaded datasets or that you upload.\n\n**Kaggle**  is a platform for predictive modelling and analytics competitions that hosts crowdsource competitions to produce the best models for predicting and describing the datasets uploaded by companies and users.\n\nExample of an active Kaggle competition:\n[https://www.kaggle.com/c/zillow-prize-1](https://www.kaggle.com/c/zillow-prize-1)\n\n*Please go ahead and create a Kaggle account so you can fork this notebook and play with it.*\n\nSee below for a simple example of code execution:"},{"metadata":{"_uuid":"a60fd244de30985fe024a2ee5c2f946406aebd34","collapsed":true,"_cell_guid":"3e9bbccf-4f88-4e03-96df-7bf6834906f0","trusted":false},"cell_type":"code","source":"1+2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"203793f269e733298e95b5950aba18a53cd57190","collapsed":true,"_cell_guid":"9fddb47a-fdec-4e27-957f-f37f87d4d57a","trusted":false},"cell_type":"code","source":"import numpy\na = numpy.array([[1,2,3],[4,5,6],[7,8,9]])\nprint (a)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0dd86b94022b5171f8b7708cc4a06822f7e7d3b","collapsed":true,"_cell_guid":"c220e769-8ebe-4ac6-875c-a7f222c413cd","trusted":false},"cell_type":"code","source":"print (a.T) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3a0fa21400c5119cfde8180530e579ee7173670","_cell_guid":"5aa8303f-11d6-4af1-a454-8be44f512793"},"cell_type":"markdown","source":"Explain:\n1. How to run a cell\n2. How to add a cell\n3. How to switch between Markdown and code\n4. How to link a dataset\n\nMany platforms allow you to to write \"notebooks\", an example that I recommend besides Kaggle, is **Quantopian**.\n\nQuantopian is a company that aims to create a crowd-sourced hedge fund by letting freelance quantitative analysts develop, test, and use trading algorithms to buy and sell securities.\n\nHere's an example of a notebook in Quantopian:\n\nhttps://www.quantopian.com/lectures/beta-hedging\n\nAnd here's an example of a \"Mean-Reversion\" trading algorithm:\nhttps://www.quantopian.com/algorithms/5903a16ad876720010bc9c7f"},{"metadata":{"_cell_guid":"c3bb56bf-a694-428f-8538-a7838235607e","_uuid":"327c761203e8e4221b7576cff925a2c3efc9228c","scrolled":true,"collapsed":true,"_kg_hide-output":false,"trusted":false},"cell_type":"code","source":"# Numpy is a library for the Python, that adds support for large, \n# multi-dimensional arrays and matrices, along with a large collection of \n# high-level mathematical functions to operate on these arrays.\n# It's extremely handy for \"vectorizing\" operations.\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe63092104f143d0c83183331f21de6b1a9ae903","_cell_guid":"d1303b21-b152-4dfd-be94-2052e08b27ec"},"cell_type":"markdown","source":"Quantopian has great introductory tutorials to basic Python, like the following:\nhttps://www.quantopian.com/lectures/introduction-to-numpy\n\n"},{"metadata":{"_uuid":"645479c6d241d0bb50c43bcd17f2c87469b2670d","collapsed":true,"_cell_guid":"e9e362b8-ccac-424a-b7c7-ab1b0c41b8f4","trusted":false},"cell_type":"code","source":"# Pandas is a data manipulation and analysis library. \n# In particular, it offers data structures and operations for manipulating numerical \n# tables and time series.\nimport pandas as pd\n\n# scikit-learn is a Machine Learning library. It features various classification, \n# regression and clustering algorithms and is designed to interoperate with Python libraries like NumPy.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# XGBoost is one of many machine learning algorithms\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b47ecf4540dce7decb3908ab64186347d1e27da7","_cell_guid":"a410a47d-66f7-4cdb-a0a0-8d3b61a710e9"},"cell_type":"markdown","source":"Let's do a sanity check and print the list of files from our input directory.\n\nIn Kaggle, input data files are available in the `../input/` directory."},{"metadata":{"_uuid":"319bb453b21e719c25e1f5c4ea722626c41899ba","collapsed":true,"_cell_guid":"856bceb5-bb49-4e07-93b0-be34d57d81fc","trusted":false},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a3263111690a2c421c8bc25de4793df08f68eba","collapsed":true,"_cell_guid":"5661f5ab-ed31-4248-ae5d-0f0591306cbd","trusted":false},"cell_type":"code","source":"# Let's load the CSV into a variable called 'dataset'\ndataset = pd.read_csv('../input/voice.csv', header=0).values\n\n# dataset is a matrix\nprint (dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b911bb2928ea06cbcc157a26a67b3cbe8b1a6aa2","_cell_guid":"6c9659b4-37df-4b15-bb89-423fd002901f"},"cell_type":"markdown","source":"The above is saying that dataset has 3168 rows and 21 columns.\nLet's print the first row."},{"metadata":{"_uuid":"b152499004e49d244fd0392fc5f28eddba54afb6","collapsed":true,"_cell_guid":"e081d4ea-0ac7-44af-8f6c-d423c74ac5fa","trusted":false},"cell_type":"code","source":"print (dataset[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c7d7e435ff992d6b4fc72e8df6803ea7dd46ffc","_cell_guid":"3c96c3d7-0e8d-4975-846a-9b398d91d400"},"cell_type":"markdown","source":"**Detour - Quick tutorial Numpy Indexing**\n\nNumpy provides many convenient ways to index and slice matrices.\n\nExample:"},{"metadata":{"_uuid":"e155c7452f1b3d16a9ad3ca29c75deae1abe0b9a","collapsed":true,"_cell_guid":"74c14a1f-b05b-4e5f-9fd6-87dd34152503","trusted":false},"cell_type":"code","source":"my_matrix = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16], [17,18,19,20]])\nprint (my_matrix)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9076f7098b8f9a944b3fec897a8f71abae6a6a2e","collapsed":true,"_cell_guid":"2c81623e-cae5-4cde-9ee8-15fb99117f18","trusted":false},"cell_type":"code","source":"# Get the element from the first row, second column (zero-indexed)\nprint (my_matrix[0, 1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe9dd5de1f7613d46ec667c19becef95ff014630","collapsed":true,"_cell_guid":"da29a5a5-f308-4b74-a54e-ebb14468eb8d","trusted":false},"cell_type":"code","source":"# You can specify ranges using colon (:)\n\n# Print rows from 1 up to 3, columns 0 up to 3\nprint (my_matrix[1:3, 0:3])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75257124f2a69eaa07fe31a43998f81678ffedaa","collapsed":true,"_cell_guid":"ce31c4c2-92bd-4a30-bc18-aaeb58884298","trusted":false},"cell_type":"code","source":"# You can omit either \"start\" or \"end\"\n\n# print all rows up to 3rd row, every column starting from the fourth one\nprint (my_matrix[:3, 2:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e6a5e8e42b70b3f02714cc161fee337e74374bd","collapsed":true,"_cell_guid":"d8bab6f6-052a-48ef-aa3f-87b713192f5f","trusted":false},"cell_type":"code","source":"# print all rows, second column\nprint (my_matrix[:, 2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db61bab100eefa1bb79f1d71d15ee184a90b3251","collapsed":true,"_cell_guid":"270242f0-e564-42b2-ac39-cc6728604bc7","trusted":false},"cell_type":"code","source":"# QUIZ!\n\n# print all rows, all columns with the exception of last one\n# print (my_matrix[start:end, start:end])\n\n# print all rows, only last column\n# print (my_matrix[start:end, start:end])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8499059d162fd01a4af9c71ee13bdff5a477e490","_cell_guid":"664176df-1d32-4e04-81f1-22ee132b13d3"},"cell_type":"markdown","source":"**End quick tutorial for Numpy Indexing**"},{"metadata":{"_uuid":"d9d27b2f0a640d939375086dd97ad3bec4d3b26a","collapsed":true,"_cell_guid":"18cc9f88-69f8-411b-bb21-4a06e8161a9c","trusted":false},"cell_type":"code","source":"# Load all features into 'x' and labels into 'y'\nx = dataset[:, :-1]\ny = dataset[:, -1]\n\nprint (x.shape)\nprint (y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"586aa075aa3a45984f2a2cc86271c2422e85366e","collapsed":true,"_cell_guid":"a9dfea61-fe30-44bd-ae0c-5c63b24889ca","trusted":false},"cell_type":"code","source":"# Let's print the first 3 rows of x\nprint (x[:3])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"639a31905931c5d475eff9c848da29689f284e58","scrolled":true,"collapsed":true,"_cell_guid":"fc7e7542-c475-42ec-8532-09e3c6e55d94","trusted":false},"cell_type":"code","source":"# Let's print the first 3 rows of y\nprint (y[:3])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4506741c4f314513560e1495d793350b90c0c15","_cell_guid":"60c0345f-209b-40df-80ee-f1fbb80e6b9a"},"cell_type":"markdown","source":"Keep in mind what we are trying to do in this exercise:\n\nhttps://docs.google.com/presentation/d/1ChWqnFuHKRZVnVggyRVzXdH4ary9VMgphFMzQPa4mhk/edit#slide=id.g286eca3b4e_0_0\n\nWe need the 'y's to be in a numeric format. Currently they are strings. We can use a \"LabelEncoder\"."},{"metadata":{"_uuid":"1f8f151c390e0cec4e470382c321e9b0343b2df8","collapsed":true,"_cell_guid":"06d17fb6-3c98-4394-b5a6-16f427209f41","trusted":false},"cell_type":"code","source":"label_encoder = LabelEncoder()\nlabel_encoded_y = label_encoder.fit_transform(y)\n\n# print first 3 and last 3 instances of y\nprint (y[:3])\nprint (y[-3:])\n\n# print first 3 and last 3 instances of label_encoded_y\nprint (label_encoded_y[:3])\nprint (label_encoded_y[-3:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c33aa3d53304f8aae868cf3609b52d53219dc47","collapsed":true,"_cell_guid":"6e4033fa-89cb-431f-a8f2-4165bba5721f","trusted":false},"cell_type":"code","source":"# Now we are ready to pass it to a Machine Learning Algorithm\nmodel = XGBClassifier()\nmodel.fit(x, label_encoded_y)\n\n# Now 'model' is ready to do predictions!\nprint ('Mary')\nx_test0 = np.array([\n    0.217427436852732, 0.0452543270933, 0.234337899543379, 0.206392694063927, 0.243470319634703, 0.0370776255707762,\n    4.46856483331244, 28.9546502761532, 0.868510554863495, 0.272468042638548, 0.235981735159817, 0.217427436852732,\n    0.177765492697815, 0.0452772073921971, 0.279113924050633, 1.4383721534242, 0, 12.080126953125, 12.080126953125,\n    0.0789463260051495\n])[:, np.newaxis].T\ny_pred0 = model.predict(x_test0)\nprint ('Male' if y_pred0[0] == 1 else 'Female')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b7a22583210484556797daa41f1a9ff1165ffde","collapsed":true,"_cell_guid":"0fc5871e-0411-4a1a-a515-70fe310c5647","trusted":false},"cell_type":"code","source":"# Recap\n\n# XGBoost is pretty popular because it typically doesn't require tuning of hyper-parameters in\n# order to make robust predictions.\n\nimport numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\ndataset = pd.read_csv('../input/voice.csv', header=0).values\nx = dataset[:, :-1]\ny = dataset[:, -1]\n\nlabel_encoder = LabelEncoder()\nlabel_encoded_y = label_encoder.fit_transform(y)\n\nmodel = XGBClassifier()\nmodel.fit(x, label_encoded_y)\n\nprint ('Mary')\nx_test0 = np.array([\n    0.217427436852732, 0.0452543270933, 0.234337899543379, 0.206392694063927, 0.243470319634703, 0.0370776255707762,\n    4.46856483331244, 28.9546502761532, 0.868510554863495, 0.272468042638548, 0.235981735159817, 0.217427436852732,\n    0.177765492697815, 0.0452772073921971, 0.279113924050633, 1.4383721534242, 0, 12.080126953125, 12.080126953125,\n    0.0789463260051495\n])[:, np.newaxis].T\ny_pred0 = model.predict(x_test0)\nprint ('Male' if y_pred0[0] == 1 else 'Female')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e06bddc78419ad0f0c4ff99981edfa2cf2cdca70","_cell_guid":"2c2fc8c7-dd21-4ad8-b656-f0aa1461f337"},"cell_type":"markdown","source":"**How do we validate our results?**\n\nHow can we tell if we are learning something?\n\nWe can obviously use our model to predict the instances that we have seen and see how well we do.\n\nFor example:"},{"metadata":{"_uuid":"891e0cddc4ade055b0e81e48bd4aaf809bd32162","collapsed":true,"_cell_guid":"11d0ceb8-5232-45ed-aeb2-33aec1913cc7","trusted":false},"cell_type":"code","source":"y_predicted = model.predict(x)\naccuracy = accuracy_score(label_encoded_y, y_predicted)\nprint(\"Accuracy XGBoost: %.2f%%\" % (accuracy * 100.0))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cebdf03f76981a200cedebcd08911731025fd78e","_cell_guid":"a5348bcc-ed15-4285-b19a-7eea229c0576"},"cell_type":"markdown","source":"But that's considered 'cheating'. \n\nTo really know if our 'model' has learned anything, we would like to see how well it does on data that it has never seen before, the same way that it can predict Mary's or John's voice. \n\nHow do we do that?\n\nWe can **split** the data.\n\nWhat if, for all the data that we have, we split it into, say, 70% and 30%. We use the 70% to train our model and we see how effective it is on the 30%.\n\nIf our model is actually learning something, it should do well on data that it has never seen."},{"metadata":{"_uuid":"d156f5fba57fb066a759a74219366260c4a70bd5","collapsed":true,"_cell_guid":"061a1989-c4f3-459e-8f4e-7f607b615ca6","trusted":false},"cell_type":"code","source":"test_size = 0.33\nx_training, x_test, y_training, y_test = train_test_split(x,\n                                                          label_encoded_y,\n                                                          test_size=test_size,\n                                                          random_state=7)\n\nprint (\"x.shape: {}\".format(x.shape))\nprint (\"x_training.shape: {}\".format(x_training.shape))\nprint (\"x_test.shape: {}\".format(x_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d38b91ccd019b9a87976cd891d76a47508e4b5eb","collapsed":true,"_cell_guid":"47b0cd2c-448a-4253-94a8-1641dfb8ba9d","trusted":false},"cell_type":"code","source":"# train_test_split takes care of shuffling data\n\nprint (label_encoded_y.shape)\nprint (y_training.shape)\nprint (y_test.shape)\n\nprint (y_training.sum())\nprint (y_test.sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5718f9eec6fe539230fcd4b0c88f2e25e0b15f31","collapsed":true,"_cell_guid":"e450998f-8d5e-4b3b-af5c-b240dd37eeed","trusted":false},"cell_type":"code","source":"model = XGBClassifier()\nmodel.fit(x_training, y_training)\ny_pred = model.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy XGBoost: %.2f%%\" % (accuracy * 100.0))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"version":"3.6.4","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}