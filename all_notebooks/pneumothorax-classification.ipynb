{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import StratifiedKFold\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom sklearn.metrics import roc_auc_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nmain_path = '/kaggle/input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax'\nprint(os.listdir(main_path))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:48:33.209519Z","iopub.execute_input":"2021-06-12T17:48:33.210028Z","iopub.status.idle":"2021-06-12T17:48:33.217995Z","shell.execute_reply.started":"2021-06-12T17:48:33.209997Z","shell.execute_reply":"2021-06-12T17:48:33.217085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/pretrainedmodels/pretrainedmodels-0.7.4')\nimport pretrainedmodels\nfrom pneumothorax_dataset import ClassificationDataset\nfrom pneumothorax_model import get_model\nimport pneumothorax_engine as engine\n\nimport albumentations\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nepochs = 5","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:48:33.219581Z","iopub.execute_input":"2021-06-12T17:48:33.220183Z","iopub.status.idle":"2021-06-12T17:48:36.472628Z","shell.execute_reply.started":"2021-06-12T17:48:33.220153Z","shell.execute_reply":"2021-06-12T17:48:36.471753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model(pretrained=True)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:48:36.678789Z","iopub.execute_input":"2021-06-12T17:48:36.679084Z","iopub.status.idle":"2021-06-12T17:48:39.615329Z","shell.execute_reply.started":"2021-06-12T17:48:36.679055Z","shell.execute_reply":"2021-06-12T17:48:39.614294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(os.path.join(main_path, 'stage_1_train_images.csv'))\ntest_data = pd.read_csv(os.path.join(main_path, 'stage_1_test_images.csv'))\n\ntrain_data['images'] = train_data['new_filename'].apply(lambda x: os.path.join(main_path, 'png_images', x))\ntest_data['images'] = test_data['new_filename'].apply(lambda x: os.path.join(main_path, 'png_images', x))\n\nimages = train_data['images'].tolist()\ntargets = train_data['has_pneumo'].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:48:39.617265Z","iopub.execute_input":"2021-06-12T17:48:39.617715Z","iopub.status.idle":"2021-06-12T17:48:39.718671Z","shell.execute_reply.started":"2021-06-12T17:48:39.617672Z","shell.execute_reply":"2021-06-12T17:48:39.717627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\naug = albumentations.Compose([albumentations.Normalize(mean, std, max_pixel_value=255, always_apply=True)])\n\ntrain_images, val_images, train_targets, val_targets = train_test_split(images, targets, stratify=targets, train_size=0.25)\n\ntrain_dataset = ClassificationDataset(train_images, train_targets, resize=(224, 224), augmentations=aug)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n\nval_dataset = ClassificationDataset(train_images, val_targets, resize=(224, 224), augmentations=aug)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:48:39.722738Z","iopub.execute_input":"2021-06-12T17:48:39.723032Z","iopub.status.idle":"2021-06-12T17:48:39.752409Z","shell.execute_reply.started":"2021-06-12T17:48:39.723004Z","shell.execute_reply":"2021-06-12T17:48:39.75135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=5e-04)\n\nfor epoch in range(epochs):\n    engine.train(train_loader, model, optimizer, device)\n    predictions, actual = engine.evaluate(val_loader, model, device)\n    \n    roc_auc = roc_auc_score(actual, predictions)\n    \n    print(f'Epoch={epoch}, ROC score={roc_auc}')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T17:48:39.753739Z","iopub.execute_input":"2021-06-12T17:48:39.754038Z","iopub.status.idle":"2021-06-12T17:49:45.98086Z","shell.execute_reply.started":"2021-06-12T17:48:39.754009Z","shell.execute_reply":"2021-06-12T17:49:45.978755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}