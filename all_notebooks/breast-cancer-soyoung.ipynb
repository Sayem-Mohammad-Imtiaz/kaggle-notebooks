{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cancer=load_breast_cancer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test= train_test_split(cancer.data, cancer.target, stratify=cancer.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalizer(columns가 아니라 row마다 각각 정규화 so 유클리드 거리=1)로 데이터 스케일링(fit:데이터 변환 학습, transform:실제 스케일 조정)\nfrom sklearn.preprocessing import Normalizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=Normalizer()\nx_train_scale=scaler.fit_transform(x_train)\nx_test_scale=scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaling 이후 학습성능 향상 확인\nfrom sklearn.svm import SVC     #SVM은 인공신경망의 특수한 형태로 layer를 많이 쌓지 않아도 우수한 성능을 보여준다. \nsvc=SVC()\nsvc.fit(x_train, y_train)\nprint('test accuracy :%.3f' %(svc.score(x_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc.fit(x_train_scale, y_train)\nprint('after scaling test accuracy :%.3f' %(svc.score(x_test_scale, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tensorflow keras 적용\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom tensorflow.keras import optimizers\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=tf.keras.Sequential()\nmodel.add(layers.Input(shape=x_train.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(layers.Dense(100, activation='relu'))\nmodel.add(layers.Dense(1, activation='relu'))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics_nm = ['accuracy','mean_squared_error','binary_accuracy','binary_crossentropy']\nmodel.compile(tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=metrics_nm)\nhist=model.fit(x_train_scale, y_train, epochs=200, batch_size=20, validation_split=0.2, verbose=0)  \n#fit하면서 validation_split을 하는 이유? => validation_set과 train_set의 history.keys 값을 확인해 일치하는지 본다. \n#sample size와 batch size정하기?\n#hist는 print하는 의미가 없는 듯?\nhist.history.keys()  #loss와 평가방법(metrics)인, 예를 들어 accuracy, MSE의 epoch별 변화를 보여주는 것. train set과 validation set 오차가 적은지 확인하고 비로소 test set으로 evaluate 함\nplt.plot(hist.history['binary_crossentropy'])\nplt.plot(hist.history['val_binary_crossentropy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(hist.history['binary_accuracy'])\nplt.plot(hist.history['val_binary_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(x_test_scale, y_test, batch_size=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(x_test_scale)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report\nfrom sklearn.metrics import classification_report\ny_pred_class=np.where(y_pred>0.5, 1, 0)\nprint(classification_report(y_test, y_pred_class))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}