{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/spam.csv\",encoding = \"ISO-8859-1\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"577c47d20142ddd183e06efed8122cbb2b332966","_cell_guid":"035e392a-9eb3-436f-8d6a-e1042965fbd0","trusted":true},"cell_type":"code","source":"df.info()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"0ad4d19225da16ac3fb473b9ec817baee17d42b6","_cell_guid":"d0ce5cf0-b610-486e-b395-43d352c2637f","trusted":true},"cell_type":"code","source":"df.describe()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"252e8ed3468039e9ce198fcfd54dcbc6c179ba4d","_cell_guid":"8675d923-163e-4580-8898-b2d1eabbd835","trusted":true},"cell_type":"code","source":"df.head()","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"44a59f7870600618aa0567da16714f0f9989f3b8","_cell_guid":"a531876f-bc50-41e6-b371-a8cee9056e6a","trusted":true},"cell_type":"code","source":"df=df[[\"v1\",\"v2\"]]","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"e11901a0f274e7f0c984b2e5a9057e6cd8236ce9","_cell_guid":"9632d2ce-c577-4825-9be3-edab026da533","trusted":true},"cell_type":"code","source":"df.head()","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"7dd6fa6d2877f74630b4c2a5b359e8f90894712d","_cell_guid":"c56c1a6d-e87b-4280-883a-81086be66610"},"cell_type":"markdown","source":"**Workflow**\n\n* All small letters\n* Delete punktuation\n* Delete stopwords\n* Translate words into numbers\n    * List of all words\n    * Translate texts into a countlist of words\n* Train/Test split\n* Train this feature on classification ham, spam\n* Predict on test-set"},{"metadata":{"_uuid":"08b117e3de5f53d5b704be823a1cf4f6af0829bf","_cell_guid":"80097678-350a-4a43-af72-5fc752f68557","trusted":true},"cell_type":"code","source":"# All small letters\ndf[\"v2\"]=df[\"v2\"].apply(lambda x: x.lower())\ndf.head()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"bc2ba49ff83179d6723c6bce952bb1c1ff033891","_cell_guid":"4b81627e-a3a6-45ea-8a02-7996af9c467a","trusted":true},"cell_type":"code","source":"# delete punctuation\nimport string\n\ndef del_punctuation(text):\n    answer=[]\n    for letter in text:\n        if letter not in string.punctuation:\n            answer.append(letter)\n    answer=\"\".join(answer)\n    return answer\n\ndf[\"v2\"]=df[\"v2\"].apply(lambda x: del_punctuation(x))\ndf.head()","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"36ace512a355836e6ac21a52857cb7e50b1d8621","_cell_guid":"1d5f8111-0f04-41b2-8784-eb422a7b3ac3","trusted":true},"cell_type":"code","source":"# Now delete stopwords\nfrom nltk.corpus import stopwords\n\ndef del_stopwords(text):\n    answer=[]\n    for word in text.split():\n        if word not in stopwords.words(\"english\"):\n            answer.append(word)\n    answer=\" \".join(answer)\n    return answer\n\ndf[\"v2\"]=df[\"v2\"].apply(lambda x: del_stopwords(x))\ndf.head()","execution_count":10,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d53c84efb48b2a497f663137685d64b4b16302bd","_cell_guid":"46285f5f-5131-44fe-a531-4185b7ca0806"},"cell_type":"markdown","source":"single letters are not deleted\nnumbers are not deleted\ncolloquial language is not deleted (u dun = you don't)"},{"metadata":{"_uuid":"f6090b45b32ec2b7f73add897e35d593ca6b339f","_cell_guid":"e8bde3b5-3491-4a28-b8a2-e088c1271b81","trusted":true},"cell_type":"code","source":"\"\"\"#Translate words into numbers\n#    * List of all words\n#    * Translate texts into a countlist of words\nlist_of_words=[]\nfor item in df[\"v2\"]:\n    for word in item.split():\n        if word not in list_of_words:\n            list_of_words.append(word)\nprint(len(list_of_words))\nprint(list_of_words[0:4])\"\"\"\n\n# This is being done by a sklearn feature (see below)","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"61d4107447cc4b0f5646ad81ae5f92e5132f0f9d","_cell_guid":"72aa96b1-2f89-4cb2-9a32-59b12a3de0fa"},"cell_type":"markdown","source":"9431 words in total in all messages\nNow lets translate messages into vectors of dimension 1x9431 of count of words (0 if a certain word in the corpus is not in the message, 1 if it is 1 time in the message, 2 if it is in two times etc.)"},{"metadata":{"_uuid":"71189e4cc4145079d60a8bf3a9930ff014cb66cb","_cell_guid":"b54bfa6a-ade1-4688-9f21-e26cf3d93517","trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer=CountVectorizer().fit(df[\"v2\"])","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"320d2ec0d73a66f422103e4fa0e8f52bf3b618a0","_cell_guid":"f4afa278-87ce-4f0e-9094-461ddd93a598","trusted":true},"cell_type":"code","source":"vectorizer.vocabulary_","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"ff818409e7a82d7480580ded73c0971ec3506922","_cell_guid":"b8936fe7-a7fa-400f-90de-5ccbff8a15d1","trusted":true},"cell_type":"code","source":"len(vectorizer.vocabulary_)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"10d3251d858a125f0da453651599b65eb2f3bb7b","_cell_guid":"1fa8ab24-2448-4193-95a7-4a6550d5abf2","trusted":true},"cell_type":"code","source":"# different from my number calculated above. It ignores 1-letter figures and \"words\" automatically\ntest_message=vectorizer.transform(df[\"v2\"][0].split())\nprint(test_message)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"17a8fe24276151267482256916e72c488bd6b0a9","_cell_guid":"9bff4427-67ab-48a1-90e8-04c87dd8d98f","trusted":true},"cell_type":"code","source":"# Construct a matrix with the 9376 features \nX=vectorizer.transform(df[\"v2\"])\nX","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"7d24cddfee5e40484b803188fcb62f7cf467dace","_cell_guid":"8289a0c3-aff7-4739-8c03-b65a8dc4acca","trusted":true},"cell_type":"code","source":"print(X[0])","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"d66aa48d006f44bfbcac0ddc4e8a52cbcc0f4082","_cell_guid":"40b6820a-0451-4855-96d2-dfb939a56604","trusted":true},"cell_type":"code","source":"X.shape","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"a65ca7765bba68bb0b59c3747fbf287ebf3daaa3","_cell_guid":"e2dcc74e-4ade-4016-9bbf-686335698c91","trusted":true},"cell_type":"code","source":"# How many non-zero items are in the 5572*9376 matrix? (52 mn entries) About 0,09% - indeed very sparse matrix\nX.nnz","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"23804aa745cc87c936bcbb4449626db83e0e75be","_cell_guid":"5fa3a305-eb1b-49e9-9a3a-51576d21b8b2","trusted":true},"cell_type":"code","source":"# These word-counts should be measured not in absolute terms but in relative terms within the message in relation to overall corpus frequency\n# Tfidf = Term frequency inverse document frequency\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer=TfidfTransformer().fit(X)\nX_relative=tfidf_transformer.transform(X)\nX_relative","execution_count":20,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"b408ea6f7f97054b87d3e55480c73f6dbe227e22","_cell_guid":"0831da64-96ba-445c-8b25-5bc8104817a5","trusted":true},"cell_type":"code","source":"print(X_relative[0])","execution_count":21,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fb5cde717fcded48d5fe3f2eb934b545e54d1643","_cell_guid":"94830e35-6fa6-4911-921f-64ec87ebd115","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_model=MultinomialNB().fit(X_relative, df[\"v1\"])","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"94f0d86396d11d64e56905fae84a9d4292233a27","_cell_guid":"45a6f606-a440-4476-8103-55e1c41f3aac","trusted":true},"cell_type":"code","source":"spam_model.predict(X_relative)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"7d1fcc909d38be80b3fdf7b73434f6b5356317b7","_cell_guid":"3ac401dc-9186-4159-946f-0c6245739764"},"cell_type":"markdown","source":"No test_train_cross-validation split, different models, feature engineering etc.\nAlso didnt look into and analyze the data.\n\nBut the full how-to do a basic classification of text is accomplished."},{"metadata":{"trusted":true,"_uuid":"6cf2a4cfde18e6caebde503ce94e13925e333911"},"cell_type":"code","source":"# Now lets do a proper train_test_split to see if model predicts accurately\nfrom sklearn.cross_validation import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(df[\"v2\"],df[\"v1\"],test_size=0.3)\n\n# Pipeline saves a process of instructions that can be used to different datasets\nfrom sklearn.pipeline import Pipeline\npipeline = Pipeline([(\"bow\",CountVectorizer()),          # Creates sparse matrix counting the words\n                     (\"tfidf\",TfidfTransformer()),       # Relative weights\n                    (\"classifier\",MultinomialNB())])     # Fit the model\npipeline.fit(X_train,y_train)\n# Returns a fitted pipeline object","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"128c9b67424b9e3db141740a7bc9de2a0835d5d5"},"cell_type":"code","source":"predictions=pipeline.predict(X_test)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d18d8d273a28d0c8ef82970fa213e433207f53a7"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions))","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dd918b0923cf0ce1dbdfa96a7adc35b8c22ebaab"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}