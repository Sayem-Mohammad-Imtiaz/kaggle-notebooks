{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\n<font color ='blue' >\nContent:\n\n1. [Load and Check Data](#1)\n    \n2. [Variable Description](#2)\n    \n3. [Outlier Detection](#3)\n    \n4. [Missing Value](#4)\n    \n5. [Basic Data Analysis and Feature Engineering](#5)\n    \n  5.1. [Numerical Variable](#6)\n    \n  5.2. [Categorical Variable](#7)\n    \n6. [Modeling](#8)\n    \n  6.1 [Hyperparameter Tuning -- Cross Validation Setings](#9)\n    \n  6.2 [Ensemble modelling with inbalanced and balanced dataset](#10)\n        \n    6.2.1 [Inbalanced Dataset](#11)\n    \n    6.2.1 [Over sampling Dataset](#12)\n    \n    6.2.2 [Under sampling the Dataset](#13)\n    \n    6.2.3 [Smote Dataset](#14)\n    \n    6.2.4 [Adasyn Dataset](#15)\n    \n7. [Accuracy Score Table](#16)\n  7.1 [Best 10 Value Score Table](#17)\n    \n    \n    \n\n    ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.figure_factory as ff\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nimport scipy.stats as stats\nimport sklearn\nsklearn.model_selection.RandomizedSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '1'></a><br>\n<font color ='blue' >\n# Load and Check Data","metadata":{}},{"cell_type":"markdown","source":"Using the \"IBM HR Analytics Employee Attrition & Performance\" dataset, what are the factors that affect the dismissal of IBM company?  I selected the 'Attrition' feature as my Target feature in our dataset, that is Target.","metadata":{}},{"cell_type":"code","source":"employee = pd.read_csv(\"/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employee.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employee.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '2'></a><br>\n<font color ='blue' >\n# Variable Description","metadata":{}},{"cell_type":"markdown","source":"Feature descriptions are below:\n\n    * AGE: Numerical Value\n    * ATTRITION: Employee leaving the company (0=no, 1=yes)\n    * BUSINESS TRAVEL: (1=No Travel, 2=Travel Frequently, 3=Tavel Rarely)\n    * DAILY RATE: Numerical Value - Salary Level\n    * DEPARTMENT: (1=HR, 2=R&D, 3=Sales)\n    * DISTANCE FROM HOME: Numerical Value - THE DISTANCE FROM WORK TO HOME\n    * EDUCATION: Numerical Value\n    * EDUCATION FIELD: (1=HR, 2=LIFE SCIENCES, 3=MARKETING, 4=MEDICAL SCIENCES, 5=OTHERS, 6= TEHCNICAL)\n    * ENVIROMENT SATISFACTION: Numerical Value - SATISFACTION WITH THE ENVIROMENT\n    * GENDER: (1=FEMALE, 2=MALE)\n    * HOURLY RATE: Numerical Value - HOURLY SALARY\n    * JOB INVOLVEMENT: Numerical Value - JOB INVOLVEMENT\n    * JOB LEVEL: Numerical Value - LEVEL OF JOB\n    * JOB ROLE: (1=HC REP, 2=HR, 3=LAB TECHNICIAN, 4=MANAGER, 5= MANAGING DIRECTOR, 6= REASEARCH DIRECTOR, 7= RESEARCH SCIENTIST, 8=SALES EXECUTIEVE, 9= SALES REPRESENTATIVE)\n    * JOB SATISFACTION: Numerical Value - SATISFACTION WITH THE JOB\n    * MARITAL STATUS: (1=DIVORCED, 2=MARRIED, 3=SINGLE)\n    * MONTHLY INCOME: Numerical Value - MONTHLY SALARY\n    * MONTHY RATE: Numerical Value - MONTHY RATE\n    * NUMCOMPANIES WORKED: Numerical Value - NO. OF COMPANIES WORKED AT\n    * OVERTIME: (1=NO, 2=YES)\n    * PERCENT SALARY HIKE: Numerical Value - PERCENTAGE INCREASE IN SALARY\n    * PERFORMANCE RATING: Numerical Value - ERFORMANCE RATING\n    * RELATIONS SATISFACTION: Numerical Value - RELATIONS SATISFACTION\n    * STOCK OPTIONS LEVEL: Numerical Value - STOCK OPTIONS\n    * TOTAL WORKING YEARS: Numerical Value - TOTAL YEARS WORKED\n    * TRAINING TIMES LAST YEAR: Numerical Value - HOURS SPENT TRAINING\n    * WORK LIFE BALANCE: Numerical Value - TIME SPENT BEWTWEEN WORK AND OUTSIDE\n    * YEARS AT COMPANY: Numerical Value - TOTAL NUMBER OF YEARS AT THE COMPNAY\n    * YEARS IN CURRENT ROLE: Numerical Value -YEARS IN CURRENT ROLE\n    * YEARS SINCE LAST PROMOTION: Numerical Value - LAST PROMOTION\n    * YEARS WITH CURRENT MANAGER: Numerical Value - YEARS SPENT WITH CURRENT MANAGER\n","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nlayout = go.Layout(\n    title='Attrition Özelliğinin Genel Dağılımı Grafiği',\n)\nfig = go.Figure([go.Bar(x=employee[\"Attrition\"].value_counts().index.values, y=employee[\"Attrition\"].value_counts().values)],layout=layout)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n    * Dataset structure: 1470 satır, 35 özellik\n    * Data type: int64 ve object\n    * Imbalanced dataset: 1233 (84%) 'no' attrition and 237 (16%) 'yes' attrition\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id= '3'></a><br>\n<font color ='blue' >\n# Outlier Detection","metadata":{}},{"cell_type":"markdown","source":"\nInstead of deleting the features one by one according to their outlier, I deleted the outlier values ​​of the features on the common lines.","metadata":{}},{"cell_type":"code","source":"from collections import Counter\ndef detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employee.loc[detect_outliers(employee,['Age','DailyRate','DistanceFromHome','HourlyRate','MonthlyIncome','MonthlyRate','PercentSalaryHike',\n                                                           'TotalWorkingYears','YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager','NumCompaniesWorked',\n                                                           'Education','EnvironmentSatisfaction','JobInvolvement','JobLevel','JobSatisfaction','NumCompaniesWorked','PerformanceRating',\n                                                           'RelationshipSatisfaction','StockOptionLevel','TrainingTimesLastYear','WorkLifeBalance'])]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop outliers\nemployee = employee.drop(detect_outliers(employee,['Age','DailyRate','DistanceFromHome','HourlyRate','MonthlyIncome','MonthlyRate','PercentSalaryHike',\n                                                           'TotalWorkingYears','YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager','NumCompaniesWorked',\n                                                           'Education','EnvironmentSatisfaction','JobInvolvement','JobLevel','JobSatisfaction','NumCompaniesWorked','PerformanceRating',\n                                                           'RelationshipSatisfaction','StockOptionLevel','TrainingTimesLastYear','WorkLifeBalance']),axis = 0).reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '4'></a><br>\n<font color ='blue' >\n# Missing Value","metadata":{}},{"cell_type":"markdown","source":"We are checking a null value. If there is, we will evaluate it and delete it or add it with an estimate.","metadata":{}},{"cell_type":"code","source":"employee.columns[employee.isnull().any()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OLEYYYY","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '5'></a><br>\n<font color ='blue' >\n# Basic Data Analysis and Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"I looked at the number of unique values of each feature. We will also benefit from this information when determining the data type of the features.","metadata":{}},{"cell_type":"code","source":"employee.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dropped Feature\n\n Feature that has 1470 unique value\n    \n    * 'EmployeeNumber'\n    \n   \n Feature that has 1 unique value\n \n    * 'Over18'\n    * 'StandardHours' \n    * 'EmployeeCount'","metadata":{}},{"cell_type":"code","source":"employee.drop(['EmployeeCount','Over18','StandardHours','EmployeeNumber'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Categorical Variable:\n\n    * 'BusinessTravel'\n    * 'Department'\n    * 'Education'\n    * 'EducationField'\n    * 'EnvironmentSatisfaction'\n    * 'Gender'\n    * 'JobInvolvement'\n    * 'JobLevel'\n    * 'JobRole'\n    * 'JobSatisfaction'\n    * 'MaritalStatus'\n    * 'NumCompaniesWorked'\n    * 'OverTime'\n    * 'PerformanceRating'\n    * 'RelationshipSatisfaction'\n    * 'StockOptionLevel'\n    * 'TrainingTimesLastYear'\n    * 'WorkLifeBalance'\n    * 'PercentSalaryHike'\n    * 'DistanceFromHome'\n    \nNumerical Variable:\n\n    * 'Age'\n    * 'DailyRate'\n    * 'YearsSinceLastPromotion'\n    * 'HourlyRate'\n    * 'MonthlyIncome'\n    * 'MonthlyRate'\n    * 'TotalWorkingYears'\n    * 'YearsAtCompany'\n    * 'YearsWithCurrManager'\n    * 'YearsInCurrentRole\n\n Target Variable:\n \n    * 'Attrition' \n","metadata":{}},{"cell_type":"markdown","source":"<a id= '6'></a><br>\n<font color ='blue' >\n## Numerical Variable","metadata":{}},{"cell_type":"code","source":"numerical_employee=employee.drop(['Attrition','BusinessTravel','Department','Education','EducationField','EnvironmentSatisfaction','Gender','JobInvolvement','JobLevel','JobRole','JobSatisfaction','MaritalStatus','NumCompaniesWorked','OverTime','PerformanceRating','RelationshipSatisfaction','StockOptionLevel','TrainingTimesLastYear','WorkLifeBalance','DistanceFromHome','PercentSalaryHike'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_employee.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_employee.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def datauret(a,numerical_employee):\n    x = [\"Yes\", \"No\"]\n    y = [numerical_employee[employee['Attrition']=='Yes'][a].mean(),numerical_employee[employee['Attrition']=='No'][a].mean()]\n    \n    trace = go.Bar(\n        name=a,\n        x=x,\n        y=y,\n    )\n    \n    return trace","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def datahist(a,numerical_employee):\n    \n    trace = go.Histogram(\n        name=a,\n        x=numerical_employee[a],\n        nbinsx=60,\n    )\n    \n    return trace","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_numerical=list()\nrate=numerical_employee\nfor i in range(len(rate.columns)):\n    data_numerical.append(datahist(rate.columns[i],numerical_employee))\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef visibleTF_s(number):\n    liste=list()\n    for i in range(len(data_numerical)):\n        liste.append(False)\n    liste[number]=True\n    return liste\n\ndef button(attribute,number):\n    return dict(label = attribute,method = 'update',args = [{'visible': visibleTF_s(number)},{'title': 'numerical-Attribute ilişkisi'}])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layout = go.Layout(\n    barmode='stack',\n    width=700,\n    height=500,\n    autosize=False,\n    title='Numerical-Attribute relationship',\n        \n    xaxis=go.layout.XAxis(\n        title=go.layout.xaxis.Title(\n            #text='x Axis',\n            font=dict(\n                family='Courier New, monospace',\n                size=18,\n                color='#7f7f6f'\n            )\n        )\n    ),\n    yaxis=go.layout.YAxis(\n        title=go.layout.yaxis.Title(\n            #text='y Axis',\n            font=dict(\n                family='Courier New, monospace',\n                size=18,\n                color='#7f7f7f'\n            )\n        )\n    )\n)\nrate=numerical_employee\nupdatemenus = list([dict(active=-1,buttons=[button(rate.columns[i],i) for i in range(len(rate.columns))])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create figure\nfig = go.Figure()\n\nfor i in range(len(numerical_employee.columns)):\n    fig.add_trace(data_numerical[i])   \n\nfig.update_layout(\n    updatemenus=updatemenus)\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter_matrix(numerical_employee)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_employee.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### When I observed the correlation matrix and the graphs above,I will get new features by combining the highly related ones with PCA.","metadata":{}},{"cell_type":"markdown","source":"#### Age-MonthlyIncome-TotalWorkingYears","metadata":{}},{"cell_type":"markdown","source":"When PCA for the Age, MonthlyIncome and TotalWorkingYears features, We first found the value of n.","metadata":{}},{"cell_type":"code","source":"numerical_employee[['Age','MonthlyIncome','TotalWorkingYears']].corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PCA1--------------------------------Age---MonthlyIncome----TotalWorkingYears\n\nX = StandardScaler().fit_transform(numerical_employee[['Age','MonthlyIncome','TotalWorkingYears']])\npca = PCA(n_components=2)\npca.fit(X)\nX_pca=pca.transform(X)\nprint(pca.explained_variance_ratio_)\nsum(pca.explained_variance_ratio_)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\npca=PCA(whiten=True).fit(X)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulatıve explained variance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from above graph , we found n=1\nX = StandardScaler().fit_transform(numerical_employee[['Age','MonthlyIncome','TotalWorkingYears']])\npca = PCA(n_components=1)\npca.fit(X)\nX_pca=pca.transform(X)\nnumerical_employee['PCA1']=X_pca\nnumerical_employee.drop(['Age','MonthlyIncome','TotalWorkingYears'],axis=1,inplace=True)\nemployee['PCA1']=X_pca\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### YearsAtCompany--YearsInCurrentRole--YearsSinceLastPromotion--YearsWithCurrManager","metadata":{}},{"cell_type":"markdown","source":"When PCA for the YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion and YearsWithCurrManager features, We first found the value of n.","metadata":{}},{"cell_type":"code","source":"numerical_employee[['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion']].corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = StandardScaler().fit_transform(numerical_employee[['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion']])\npca = PCA(n_components=2)\npca.fit(X)\nX_pca=pca.transform(X)\nprint(pca.explained_variance_ratio_)\nsum(pca.explained_variance_ratio_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca=PCA(whiten=True).fit(X)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulatıve explained variance')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We used PCA with 2 component as PCA2 and PCA3 feature\n\nX = StandardScaler().fit_transform(numerical_employee[['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole']])\npca = PCA(n_components=2)\npca.fit(X)\nX_pca=pca.transform(X)\nnumerical_employee['PCA2']=X_pca.T[0]\nnumerical_employee['PCA3']=X_pca.T[1]\nnumerical_employee.drop(['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion'],axis=1,inplace=True)\n\nemployee['PCA2']=X_pca.T[0]\nemployee['PCA3']=X_pca.T[1]\n#employee.drop(['YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_employee.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### HourlyRate, DailyRate, MonthlyRate\nThe p values of the HourlyRate, DailyRate, MonthlyRate features in the Ttest are around 0.05 or above. Therefore, there does not appear to be a significant difference in terms of continuous value. Nevertheless, I visualized these features and observed his behavior categorically about leaving the job.","metadata":{}},{"cell_type":"code","source":"#DailyRate Feature\nnumerical_employee['Attrition']=employee['Attrition']\n\nnumerical_employee[numerical_employee['Attrition']=='Yes']['DailyRate']\ny=np.array(numerical_employee[numerical_employee['Attrition']=='Yes']['DailyRate'])\nn=np.array(numerical_employee[numerical_employee['Attrition']=='No']['DailyRate'])\n\nhist_data = [y,n]\ngroup_labels = ['distplot_yes','distplot_no'] # name of the dataset\n\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,bin_size=25)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There is a tendency to quit before 830, after which the tendency to quit is less. So this value is the threshold value\nemployee[\"DailyRate\"] = [1 if i < 830 else 2 for i in employee[\"DailyRate\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HourlyRate Feature \nnumerical_employee[numerical_employee['Attrition']=='Yes']['HourlyRate']\ny=np.array(numerical_employee[numerical_employee['Attrition']=='Yes']['HourlyRate'])\nn=np.array(numerical_employee[numerical_employee['Attrition']=='No']['HourlyRate'])\n\nhist_data = [y,n]\ngroup_labels = ['distplot_yes','distplot_no'] # name of the dataset\n\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,bin_size=25)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There are 2 threshold value as 45 and 73\nemployee[\"HourlyRate\"] = [1 if i < 45 else 3 if i > 73 else 2 for i in employee[\"HourlyRate\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MonthlyRate Feature\nnumerical_employee[numerical_employee['Attrition']=='Yes']['MonthlyRate']\ny=np.array(numerical_employee[numerical_employee['Attrition']=='Yes']['MonthlyRate'])\nn=np.array(numerical_employee[numerical_employee['Attrition']=='No']['MonthlyRate'])\n\nhist_data = [y,n]\ngroup_labels = ['distplot_yes','distplot_no'] # name of the dataset\n\nfig = ff.create_distplot(hist_data, group_labels,show_hist=False,bin_size=25)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#There is 2 threshold value as 8500 \nemployee[\"MonthlyRate\"] = [1 if i < 8500 else 2 for i in employee[\"MonthlyRate\"]]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#HourlyRate, DailyRate, MonthlyRate features will be considered as categorical features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_employee.drop(['HourlyRate', 'DailyRate', 'MonthlyRate','Attrition'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '7'></a><br>\n<font color ='blue' >\n## Categorical Variable","metadata":{}},{"cell_type":"code","source":"Categorical_employee=employee.drop(['Attrition','Age','MonthlyIncome','YearsAtCompany','YearsWithCurrManager','YearsInCurrentRole','YearsSinceLastPromotion','TotalWorkingYears','PCA1','PCA2','PCA3'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def percent_attritionbarplot(x,employee):\n    liste=employee.sort_values(by=x)[x].unique().tolist()\n    listepercentyes=[]\n    listepercentno=[]\n    genele_etki=[]\n    for i in range(len(liste)):\n        a=(len(employee[employee[x]==liste[i]][employee['Attrition']=='Yes'])/len(employee[employee[x]==liste[i]]))*100\n        b=100-a\n        listepercentyes.append(a)\n        listepercentno.append(b)\n        geneleoran=len(employee[employee[x]==liste[i]])/len(employee)\n        genele_etki.append(geneleoran*a)\n        \n    trace1 = go.Bar(\n        x=liste,\n        y=listepercentyes,\n        name='Yes',\n    )\n    \n    trace2 = go.Bar(\n        x=liste,\n        y=listepercentno,\n        name='No',\n    )\n\n    data = [trace1, trace2]\n    return data\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def attritionbarplot2(x,employee):\n    liste=employee.sort_values(by=x)[x].unique().tolist()\n    listyes=[]\n    for i in range(len(liste)):\n        #a=len(employee[employee[x]==liste[i]][employee['Attrition']=='Yes'])\n        a=len(employee[employee[x]==liste[i]])\n        listyes.append(a)\n    \n    trace1 = go.Bar(\n        x=liste,\n        y=listyes,\n        name='Yes',\n    )\n    \n    return trace1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_Categorical=list()\ndata_Categorical2=list()\nrate=Categorical_employee\nfor i in range(len(rate.columns)):\n    data_Categorical2.append(attritionbarplot2(rate.columns[i],employee))\n    for j in range(2):\n        data_Categorical.append(percent_attritionbarplot(rate.columns[i],employee)[j])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visibleTF(number):\n    liste=list()\n    for i in range(len(data_Categorical)+len(data_Categorical2)):\n        liste.append(False)\n    liste[3*number-3]=True\n    liste[3*number-2]=True\n    liste[3*number-1]=True\n    return liste","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def button(attribute,number):\n    return dict(label = attribute,method = 'update',args = [{'visible': visibleTF(number)},{'title': 'Categorical-Attrition percent relationship'}])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rate=Categorical_employee\nupdatemenus = list([dict(active=-1,buttons=[button(rate.columns[i],i+1) for i in range(len(rate.columns))])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create figure\nfig = go.Figure()\n\nfig = make_subplots(rows=1, cols=2,\n                    specs=[[{}, {}]],\n                    subplot_titles=(\"Related Feature bar graph\",\"Attrition percentage of feature \"))\n\nfor i in range(len(data_Categorical2)):\n    fig.add_trace(data_Categorical2[i],row=1, col=1) \n    fig.add_trace(data_Categorical[2*i],row=1, col=2)\n    fig.add_trace(data_Categorical[2*i+1],row=1, col=2)   \n\n\nfig.update_layout(\n    updatemenus=updatemenus)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rate=Categorical_employee\nfor i in range(len(rate.columns)):\n    employ_tablosu=pd.crosstab(employee[\"Attrition\"],employee[rate.columns[i]])\n    print(stats.chisquare(employ_tablosu, axis=None))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First of all, the necessary classification was made in the Features and divided into categories, then our data was finalized by converting to dummy by using above graphs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employee_new=Categorical_employee\nemployee_new1=pd.DataFrame()      #Only used for check the meaningful difference of new grouping\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Attrition Feature\nemployee_new[\"Attritionr\"] = [1 if i == 'Yes' else 0 for i in employee[\"Attrition\"]]\nemployee_new1[\"Attritionr\"] = employee_new[\"Attritionr\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BusinessTravel Feature\nemployee_new1[\"BusinessTravel\"]=employee_new[\"BusinessTravel\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"BusinessTravel\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"BusinessTravel\",\"Attritionr\"]].groupby([\"BusinessTravel\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Department Feature\nemployee_new1[\"Department\"]=employee_new[\"Department\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"Department\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"Department\",\"Attritionr\"]].groupby([\"Department\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Education Feature\nemployee_new[\"Educationr\"] = [13 if i == 1 or i == 3 else 24 if i == 2 or i == 4 else 5 for i in employee_new[\"Education\"]]\nemployee_new.drop(labels = [\"Education\"], axis = 1, inplace = True)\nemployee_new1[\"Educationr\"]=employee_new[\"Educationr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"Educationr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"Educationr\",\"Attritionr\"]].groupby([\"Educationr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EducationField  Feature\nemployee_new[\"EducationFieldr\"] = ['Other' if i == 'Medical' or i == 'Life Sciences' or i == 'Other' else 'Human Resources' if i == 'Human Resources' else 'Marketing' if i == 'Marketing' else 'Technical Degree' for i in employee_new[\"EducationField\"]]\nemployee_new.drop(labels = [\"EducationField\"], axis = 1, inplace = True)\nemployee_new1[\"EducationFieldr\"]=employee_new[\"EducationFieldr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"EducationFieldr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"EducationFieldr\",\"Attritionr\"]].groupby([\"EducationFieldr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EnvironmentSatisfaction  Feature\nemployee_new[\"EnvironmentSatisfactionr\"] = [234 if i == 2 or i == 3 or i == 4 else 1 for i in employee_new[\"EnvironmentSatisfaction\"]]\nemployee_new.drop(labels = [\"EnvironmentSatisfaction\"], axis = 1, inplace = True)\nemployee_new1[\"EnvironmentSatisfactionr\"]=employee_new[\"EnvironmentSatisfactionr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"EnvironmentSatisfactionr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"EnvironmentSatisfactionr\",\"Attritionr\"]].groupby([\"EnvironmentSatisfactionr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gender Feature\nemployee_new1[\"Gender\"]=employee_new[\"Gender\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"Gender\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"Gender\",\"Attritionr\"]].groupby([\"Gender\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#JobInvolvement Feature\nemployee_new1[\"JobInvolvement\"]=employee_new[\"JobInvolvement\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobInvolvement\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobInvolvement\",\"Attritionr\"]].groupby([\"JobInvolvement\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#JobLevel  Feature\nemployee_new[\"JobLevelr\"] = [45 if i == 4 or i == 5 else 3 if i == 3 else 2 if i == 2 else 1 for i in employee_new[\"JobLevel\"]]\nemployee_new.drop(labels = [\"JobLevel\"], axis = 1, inplace = True)\nemployee_new1[\"JobLevelr\"]=employee_new[\"JobLevelr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobLevelr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobLevelr\",\"Attritionr\"]].groupby([\"JobLevelr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#JobRole Feature\nemployee_new[\"JobRoler\"] = ['HMM' if i == 'Manufacturing Director' or i == 'Healthcare Representative' or i == 'Manager' else 'Sales Executive' if i == 'Sales Executive' else 'Research Scientist' if i == 'Research Scientist' else 'Sales Representative' if i == 'Sales Representative' else 'Laboratory Technician' if i == 'Laboratory Technician' else 'Research Director' if i == 'Research Director' else 'Human Resources' for i in employee_new[\"JobRole\"]]\nemployee_new.drop(labels = [\"JobRole\"], axis = 1, inplace = True)\nemployee_new1[\"JobRoler\"]=employee_new[\"JobRoler\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobRoler\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobRoler\",\"Attritionr\"]].groupby([\"JobRoler\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#JobSatisfaction  Feature\nemployee_new[\"JobSatisfactionr\"] = [23 if i == 2 or i == 3 else 1 if i == 1 else 4  for i in employee_new[\"JobSatisfaction\"]]\nemployee_new.drop(labels = [\"JobSatisfaction\"], axis = 1, inplace = True)\nemployee_new1[\"JobSatisfactionr\"]=employee_new[\"JobSatisfactionr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"JobSatisfactionr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"JobSatisfactionr\",\"Attritionr\"]].groupby([\"JobSatisfactionr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MaritalStatus Feature\nemployee_new1[\"MaritalStatus\"]=employee_new[\"MaritalStatus\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"MaritalStatus\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"MaritalStatus\",\"Attritionr\"]].groupby([\"MaritalStatus\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NumCompaniesWorked  Feature\n\nemployee_new[\"NumCompaniesWorkedr\"] = ['2or3or4' if i == 2 or i == 3 or i == 4 else 1 if i == 1 else 0 if i == 0 else '5betw9'  for i in employee_new[\"NumCompaniesWorked\"]]\nemployee_new.drop(labels = [\"NumCompaniesWorked\"], axis = 1, inplace = True)\nemployee_new1[\"NumCompaniesWorkedr\"]=employee_new[\"NumCompaniesWorkedr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"NumCompaniesWorkedr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"NumCompaniesWorkedr\",\"Attritionr\"]].groupby([\"NumCompaniesWorkedr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#OverTime\nemployee_new1[\"OverTime\"]=employee_new[\"OverTime\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"OverTime\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"OverTime\",\"Attritionr\"]].groupby([\"OverTime\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RelationshipSatisfaction  Feature\nemployee_new[\"RelationshipSatisfactionr\"] = [234 if i == 2 or i == 3 or i == 4 else 1 for i in employee_new[\"RelationshipSatisfaction\"]]\nemployee_new.drop(labels = [\"RelationshipSatisfaction\"], axis = 1, inplace = True)\nemployee_new1[\"RelationshipSatisfactionr\"]=employee_new[\"RelationshipSatisfactionr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"RelationshipSatisfactionr\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"RelationshipSatisfactionr\",\"Attritionr\"]].groupby([\"RelationshipSatisfactionr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#WorkLifeBalance  Feature\nemployee_new[\"WorkLifeBalancer\"] = [1 if i == 1  else 2 if i == 2   else 34 for i in employee_new[\"WorkLifeBalance\"]]\nemployee_new.drop(labels = [\"WorkLifeBalance\"], axis = 1, inplace = True)\nemployee_new1[\"WorkLifeBalancer\"]=employee_new[\"WorkLifeBalancer\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"WorkLifeBalancer\"])\n#Let's check the meaningful difference of new grouping\nemployee_new1[[\"WorkLifeBalancer\",\"Attritionr\"]].groupby([\"WorkLifeBalancer\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TrainingTimesLastYear Feature\nemployee_new[\"TrainingTimesLastYearr\"] = [0 if i == 0  else '1betw3' if i > 0 and i < 4 else 4 if i == 4 else 5 if i == 5 else 6 for i in employee_new[\"TrainingTimesLastYear\"]]\nemployee_new.drop(labels = [\"TrainingTimesLastYear\"], axis = 1, inplace = True)\nemployee_new1[\"TrainingTimesLastYearr\"]=employee_new[\"TrainingTimesLastYearr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"TrainingTimesLastYearr\"])\n#Yeni gruplamanın anlamlı farklılığını kontrol edelim\nemployee_new1[[\"TrainingTimesLastYearr\",\"Attritionr\"]].groupby([\"TrainingTimesLastYearr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#StockOptionLevel Feature\nemployee_new[\"StockOptionLevelr\"] = [0 if i == 0 else '1or2or3' for i in employee_new[\"StockOptionLevel\"]]\nemployee_new.drop(labels = [\"StockOptionLevel\"], axis = 1, inplace = True)\nemployee_new1[\"StockOptionLevelr\"]=employee_new[\"StockOptionLevelr\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"StockOptionLevelr\"])\n#Yeni gruplamanın anlamlı farklılığını kontrol edelim\nemployee_new1[[\"StockOptionLevelr\",\"Attritionr\"]].groupby([\"StockOptionLevelr\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DistanceFromHome Feature\nemployee_new[\"DistanceFromHomer\"] = ['1betw8' if i < 9 else '9betw11' if i > 8 and i < 12 else '12up' for i in employee_new[\"DistanceFromHome\"]]\nemployee_new.drop(labels = [\"DistanceFromHome\"], axis = 1, inplace = True)\nemployee_new1[\"DistanceFromHomer\"]=employee_new[\"DistanceFromHomer\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"DistanceFromHomer\"])\n#Yeni gruplamanın anlamlı farklılığını kontrol edelim\nemployee_new1[[\"DistanceFromHomer\",\"Attritionr\"]].groupby([\"DistanceFromHomer\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PercentSalaryHike Feature\nemployee_new[\"PercentSalaryHiker\"] = [11 if i == 11  else '12betw17' if i > 11 and i < 18 else '18betw21' if i > 17 and i < 22 else '22betw25' for i in employee_new[\"PercentSalaryHike\"]]\nemployee_new.drop(labels = [\"PercentSalaryHike\"], axis = 1, inplace = True)\nemployee_new1[\"PercentSalaryHiker\"]=employee_new[\"PercentSalaryHiker\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"PercentSalaryHiker\"])\n#Yeni gruplamanın anlamlı farklılığını kontrol edelim\nemployee_new1[[\"PercentSalaryHiker\",\"Attritionr\"]].groupby([\"PercentSalaryHiker\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DailyRate Feature\nemployee_new1[\"DailyRate\"]=employee_new[\"DailyRate\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"DailyRate\"])\n#Yeni gruplamanın anlamlı farklılığını kontrol edelim\nemployee_new1[[\"DailyRate\",\"Attritionr\"]].groupby([\"DailyRate\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HourlyRate Feature\nemployee_new1[\"HourlyRate\"]=employee_new[\"HourlyRate\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"HourlyRate\"])\n#Yeni gruplamanın anlamlı farklılığını kontrol edelim\nemployee_new1[[\"HourlyRate\",\"Attritionr\"]].groupby([\"HourlyRate\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MonthlyRate Feature\nemployee_new1[\"MonthlyRate\"]=employee_new[\"MonthlyRate\"]\nemployee_new = pd.get_dummies(employee_new,columns=[\"MonthlyRate\"])\n#Yeni gruplamanın anlamlı farklılığını kontrol edelim\nemployee_new1[[\"MonthlyRate\",\"Attritionr\"]].groupby([\"MonthlyRate\"], as_index = False).mean().sort_values(by=\"Attritionr\",ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PerformanceRating Feature is dropped\nemployee_new.drop(labels = [\"PerformanceRating\"], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nemployee_new = pd.concat([employee_new, numerical_employee],axis=1)\nemployee_new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '8'></a><br>\n<font color ='blue' >\n# MODELING","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '9'></a><br>\n<font color ='blue' >\n## Train - Test Split-- Hyperparameter Tuning -- Cross Validation Setings","metadata":{}},{"cell_type":"markdown","source":"We will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression\n\nWe use 2 cv types Grid and Search","metadata":{}},{"cell_type":"markdown","source":"<a id= '10'></a><br>\n<font color ='blue' >\n## Ensemble modelling with inbalanced and balanced dataset\n","metadata":{}},{"cell_type":"markdown","source":"We obtain the best_estimator, cv_result values of 5 machine learning algorithm  method with the following function","metadata":{}},{"cell_type":"code","source":"def machinelearning_modeling(X_train,y_train,cv_method):\n      \n    random_state = 42\n    classifier = [DecisionTreeClassifier(random_state = random_state),\n                 SVC(random_state = random_state, probability=True ),\n                 RandomForestClassifier(random_state = random_state),\n                 LogisticRegression(random_state = random_state),\n                 KNeighborsClassifier()]\n\n    dt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                    \"max_depth\": range(1,20,2)}\n\n    svc_param_grid = {\"kernel\" : [\"rbf\"],\n                     \"gamma\": [0.001, 0.01, 0.1, 1],\n                     \"C\": [1,10,50,100,200,300,1000],\n                     \"probability\" :[True]}\n\n    rf_param_grid = {\"max_features\": [1,3,10],\n                    \"min_samples_split\":[2,3,10],\n                    \"min_samples_leaf\":[1,3,10],\n                    \"bootstrap\":[False],\n                    \"n_estimators\":[100,300],\n                    \"criterion\":[\"gini\"]}\n\n    logreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                        \"penalty\": [\"l1\",\"l2\"]}\n\n    knn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                     \"weights\": [\"uniform\",\"distance\"],\n                     \"metric\":[\"euclidean\",\"manhattan\"]}\n    classifier_param = [dt_param_grid,\n                       svc_param_grid,\n                       rf_param_grid,\n                       logreg_param_grid,\n                       knn_param_grid]\n    \n    ML_Models=[\"dtc\",\"svm\",\"rfc\",\"lr\",\"knc\"]\n    \n    cv_result = []\n    global cv_results \n    best_estimators = []\n\n    if (cv_method=='GridSearchCV'):\n\n        for i in range(len(classifier)):\n            \n            clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n            clf.fit(X_train,y_train)\n            cv_result.append(clf.best_score_)\n            best_estimators.append(clf.best_estimator_)\n\n    elif (cv_method=='RandomizedSearchCV'):\n        \n        for i in range(len(classifier)):\n            clf = RandomizedSearchCV(classifier[i], param_distributions=classifier_param[i], cv = StratifiedKFold(n_splits = 10), n_iter = 10,random_state = 111,scoring = 'precision')\n            clf.fit(X_train,y_train)\n            cv_result.append(clf.best_score_)\n            best_estimators.append(clf.best_estimator_)\n\n    cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\"LogisticRegression\",\"KNeighborsClassifier\"]})\n    fig = px.bar(cv_results, x='Cross Validation Means', y='ML Models',color='ML Models')\n    fig.show()\n    \n    return best_estimators, cv_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For Accuracy Score Table \n#* Data_type is inbalanced or balanced with some techniques\n#* Voting Algorithm' is added ML Algorithm column \n\ncolumns_name = ['Data_type','CV method','ML Algorithm','Accuracy_Score']\nData_type=list()\nCV_method=list()\nML_Algorithm=list()\nAccuracy_Score=list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '11'></a><br>\n<font color ='blue' >\n### Inbalanced Dataset","metadata":{}},{"cell_type":"code","source":"\nX_train = employee_new.drop(labels = \"Attritionr\", axis = 1)\ny_train = employee_new[\"Attritionr\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\naccuracy_GSCV=machinelearning_modeling(X_train,y_train,'GridSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_GSCV[0][1]),\n                                        (\"rfc\",accuracy_GSCV[0][2]),\n                                        (\"lr\",accuracy_GSCV[0][3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Inbalanced data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_GSCV[1]['ML Models'][i])\n\nData_type.append('Inbalanced data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_test),y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\naccuracy_RSCV=machinelearning_modeling(X_train,y_train,'RandomizedSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"knc\",accuracy_RSCV[0][4]),\n                                        (\"rfc\",accuracy_RSCV[0][2]),\n                                        (\"lr\",accuracy_RSCV[0][3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Inbalanced data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_RSCV[1]['ML Models'][i])\n\nData_type.append('Inbalanced data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(KNC,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_test),y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '12'></a><br>\n<font color ='blue' >\n### Over sampling Dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample\nemployee_no = employee_new[employee_new.Attritionr == 0]\nemployee_yes = employee_new[employee_new.Attritionr == 1]\n\nemployee_yes_up = resample(employee_yes,\n                                     replace = True,\n                                     n_samples = len(employee_no),\n                                     random_state = 111)\n\nemployee_up = pd.concat([employee_no, employee_yes_up])\nemployee_up['Attritionr'].value_counts()\n\nX_up = employee_up.drop('Attritionr', axis=1)\ny_up = employee_up['Attritionr']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_up_train, X_up_test, y_up_train, y_up_test = train_test_split(X_up, y_up, test_size = 0.33, random_state = 42)\naccuracy_up_GSCV=machinelearning_modeling(X_up_train,y_up_train,'GridSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_up_GSCV[0][1]),\n                                        (\"rfc\",accuracy_up_GSCV[0][2]),\n                                        (\"knc\",accuracy_up_GSCV[0][4])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_up_train, y_up_train)\nprint(accuracy_score(votingC.predict(X_up_test),y_up_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_up data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_up_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_up_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_up data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,KNC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_up_test),y_up_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_up_RSCV=machinelearning_modeling(X_up_train,y_up_train,'RandomizedSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"rfc\",accuracy_up_RSCV[0][2]),\n                                        (\"svm\",accuracy_up_RSCV[0][1])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_up_train, y_up_train)\nprint(accuracy_score(votingC.predict(X_up_test),y_up_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_up data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_up_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_up_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_up data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,RFC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_test),y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '13'></a><br>\n<font color ='blue' >\n###  Under-sampling Dataset","metadata":{}},{"cell_type":"code","source":"employee_no_down = resample(employee_no,\n                                     replace = True,\n                                     n_samples = len(employee_yes),\n                                     random_state = 111)\n\nemployee_down = pd.concat([employee_yes, employee_no_down])\nemployee_down['Attritionr'].value_counts()\n\nX_down = employee_down.drop('Attritionr', axis=1)\ny_down = employee_down['Attritionr']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_down_train, X_down_test, y_down_train, y_down_test = train_test_split(X_down, y_down, test_size = 0.33, random_state = 42)\naccuracy_down_GSCV=machinelearning_modeling(X_down_train,y_down_train,'GridSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_down_GSCV[0][1]),\n                                        (\"rfc\",accuracy_down_GSCV[0][2]),\n                                        (\"lr\",accuracy_down_GSCV[0][3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_down_train, y_down_train)\nprint(accuracy_score(votingC.predict(X_down_test),y_down_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_down data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_down_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_down_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_down data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_down_test),y_down_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_down_RSCV=machinelearning_modeling(X_down_train,y_down_train,'RandomizedSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_down_RSCV[0][1]),\n                                        (\"dtc\",accuracy_down_RSCV[0][0])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_down_train, y_down_train)\nprint(accuracy_score(votingC.predict(X_down_test),y_down_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_down data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_down_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_down_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_down data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,DTC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_down_test),y_down_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '14'></a><br>\n<font color ='blue' >\n### Smote Dataset","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\ny=employee_new['Attritionr']\nX = employee_new.drop('Attritionr', axis=1)\n\nsm = SMOTE(random_state=27)\nX_smote, y_smote = sm.fit_resample(X, y)\n\nemployee_smote = pd.concat([X_smote, y_smote],axis=1)\n\nX_smote = employee_smote.drop('Attritionr', axis=1)\ny_smote = employee_smote['Attritionr']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = 0.33, random_state = 42)\naccuracy_smote_GSCV=machinelearning_modeling(X_smote_train,y_smote_train,'GridSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_smote_GSCV[0][1]),\n                                        (\"rfc\",accuracy_smote_GSCV[0][2]),\n                                        (\"lr\",accuracy_smote_GSCV[0][3]),\n                                        (\"knc\",accuracy_smote_GSCV[0][4])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_smote_train, y_smote_train)\nprint(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_smote data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_smote_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_smote_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_smote data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR,KNC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_smote_RSCV=machinelearning_modeling(X_smote_train,y_smote_train,'RandomizedSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"lr\",accuracy_smote_RSCV[0][3]),\n                                         (\"rfc\",accuracy_smote_RSCV[0][2]),\n                                        (\"svm\",accuracy_smote_RSCV[0][1])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_smote_train, y_smote_train)\nprint(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_smote data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_smote_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_smote_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_smote data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_smote_test),y_smote_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '15'></a><br>\n<font color ='blue' >\n### Adasyn Dataset","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import ADASYN\ny=employee_new['Attritionr']\nX = employee_new.drop('Attritionr', axis=1)\n\nad = ADASYN()\nX_adasyn, y_adasyn = ad.fit_resample(X, y)\n\nemployee_adasyn = pd.concat([X_adasyn, y_adasyn],axis=1)\n\nX_adasyn = employee_adasyn.drop('Attritionr', axis=1)\ny_adasyn = employee_adasyn['Attritionr']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_adasyn_train, X_adasyn_test, y_adasyn_train, y_adasyn_test = train_test_split(X_adasyn, y_adasyn, test_size = 0.33, random_state = 42)\naccuracy_adasyn_GSCV=machinelearning_modeling(X_adasyn_train,y_adasyn_train,'GridSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"svm\",accuracy_adasyn_GSCV[0][1]),\n                                        (\"rfc\",accuracy_adasyn_GSCV[0][2]),\n                                        (\"lr\",accuracy_adasyn_GSCV[0][3]),\n                                        (\"knc\",accuracy_adasyn_GSCV[0][4])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_adasyn_train, y_adasyn_train)\nprint(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_adasyn data')\n    CV_method.append('GridSearchCV')\n    Accuracy_Score.append(accuracy_adasyn_GSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_adasyn_GSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_adasyn data')\nCV_method.append('GridSearchCV')\nML_Algorithm.append('Voting(SVM,RFC,LR,KNC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_adasyn_RSCV=machinelearning_modeling(X_adasyn_train,y_adasyn_train,'RandomizedSearchCV')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"rfc\",accuracy_adasyn_RSCV[0][2]),\n                                        (\"svm\",accuracy_adasyn_RSCV[0][1])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_adasyn_train, y_adasyn_train)\nprint(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    Data_type.append('Balanced_adasyn data')\n    CV_method.append('RandomizedSearchCV')\n    Accuracy_Score.append(accuracy_adasyn_RSCV[1]['Cross Validation Means'][i])\n    ML_Algorithm.append(accuracy_adasyn_RSCV[1]['ML Models'][i])\n\nData_type.append('Balanced_adasyn data')\nCV_method.append('RandomizedSearchCV')\nML_Algorithm.append('Voting(SVM,RFC)')\nAccuracy_Score.append(accuracy_score(votingC.predict(X_adasyn_test),y_adasyn_test))\nAccuracy_Score=np.round(Accuracy_Score,4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '16'></a><br>\n<font color ='blue' >\n## Accuracy Score Table","metadata":{}},{"cell_type":"code","source":"Results = pd.DataFrame({\"Data_type\":Data_type, \"CV_method\":CV_method,\"ML_Algorithm\":ML_Algorithm,\"Accuracy_Score\":Accuracy_Score})\n\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(Results.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[Results.Data_type,Results.CV_method,Results.ML_Algorithm,Results.Accuracy_Score],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id= '17'></a><br>\n<font color ='blue' >\n### Best 10 Value Score Table","metadata":{}},{"cell_type":"code","source":"Ascending_Score_best10=Results.sort_values('Accuracy_Score',ascending=False)\nAscending_Score_best10.head(10)\n\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(Ascending_Score_best10.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[Ascending_Score_best10.Data_type,Ascending_Score_best10.CV_method,Ascending_Score_best10.ML_Algorithm,Ascending_Score_best10.Accuracy_Score],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}