{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Respiratory sounds: experiment, predict diagnosis with recording annotations and metainfo, if successful automatically annotate recordings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Description\nThe dataset contains recordings of healthy patients and patients with lung issues, as well as a file with demographic information for the patient and a diagnosis file. Along with every recording there is a text file with annotation of start and end time of each breath cycle and the prescence or abscence of crackles / wheezes.\n\nAs a first try don't use the audio files yet. Predict diagnosis with annotation and the meta info.\nFor a simpler first approach index the breath cycles instead of using the intervall times. My idea here was that as for the diagnosis it might be more important in which breath cycle sounds occur rather than the exact length and location in ms, which might even be to noisy for that little data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport re\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport soundfile as sf\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score\nfrom sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, precision_recall_curve, plot_precision_recall_curve\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport tensorflow as tf\nimport keras\n\ntry:\n    os.environ['KAGGLE_DATA_PROXY_TOKEN']\nexcept KeyError:\n    dir_out = \"./\"\n    dir_path = \"Respiratory_Sound_Database/Respiratory_Sound_Database/\"\n    fname_demo = dir_path + \"demographic_info.txt\"\nelse:\n    dir_out = \"/kaggle/working/\"\n    dir_path = \"/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/\"\n    fname_demo = \"/kaggle/input/respiratory-sound-database/\" + \"demographic_info.txt\"\n    \nfname_diag = dir_path + \"patient_diagnosis.csv\"\ndir_audio = dir_path + \"audio_and_txt_files/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parse / merge all the info into convenient DataFrames\nUncomment, if needed;","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"group_pat_num = \"([0-9]{3})\"\ngroup_rec_index = \"([0-9][a-z][0-9])\"\ngroup_chest_loc = \"(Tc|Al|Ar|Pl|Pr|Ll|Lr)\"\ngroup_acc_modes = \"(sc|mc)\"\ngroup_equipments = \"(AKGC417L|LittC2SE|Litt3200|Meditron)\"\n\nregex_info = re.compile(\"_\".join([group_pat_num, group_rec_index, group_chest_loc, group_acc_modes, group_equipments]))\n\ntop = os.getcwd()\nos.chdir(dir_audio)\nfnames = glob.glob(\"*.txt\")\n\n### file name info, annotation, WAV recording\n\nl_rec_info = []\nnum_cycles_sounds = []\n\nmax_cycles = 0\n\nfor fname in fnames:\n    match_info = regex_info.match(fname)\n    pat_num = int(match_info.group(1))\n    rec_index = match_info.group(2)\n    chest_loc = match_info.group(3)\n    acc_mode = match_info.group(4)\n    equipment = match_info.group(5)\n     \n    l_rec_info.append([pat_num, rec_index, chest_loc, acc_mode, equipment])\n    \n    with open(fname) as f_annot:\n        lines = [ line.strip().split() for line in f_annot.readlines() ]\n        lines = [ [ix_lines[0]] + ix_lines[1] for ix_lines in enumerate(lines) ]\n        lines = [ [pat_num] + [rec_index] + [chest_loc] + line for line in lines ]\n        \n        num_cycles_sounds.extend(lines)\n        \n        if len(lines) > max_cycles:\n            max_cycles = len(lines)\n\n\nl_rec_info.sort(key=lambda subl: (subl[0], subl[1], subl[2], subl[3], subl[4]))\nrec_info_cols = [\"Patient number\", \"Recording index\", \"Chest location\", \"Acquisition mode\", \"Recording equipment\"]\ndf_rec_info = pd.DataFrame(l_rec_info, columns=rec_info_cols)\n\nannot_cols = [\"Patient number\", \"Recording index\", \"Chest location\", \"Cycle number\", \"Cycle start\", \"Cycle end\", \"Crackles\", \"Wheezes\"]\ndf_annotation = pd.DataFrame(num_cycles_sounds, columns=annot_cols)\n\nos.chdir(top)\n\n### create a simpler auxiliary DF / CSV for the annotations: one-hot-encoded crackles / wheezes per breath cycle:\n### [cycle_0_crackles][cycle_0_wheezes][cycle_1_crackles][cycle_1_wheezes] etc.\n\ndf_tmp = df_annotation.set_index([\"Patient number\", \"Recording index\", \"Chest location\"])\n\naux = []\n\nfor ix in df_tmp.index.unique().sort_values():\n    pat_num = ix[0]\n    rec_index = ix[1]\n    chest_loc = ix[2]\n    subdf = df_tmp.loc[pat_num, rec_index, chest_loc]\n    crackles_wheezes = [ yesno for c_w in zip( subdf[\"Crackles\"], subdf[\"Wheezes\"] ) for yesno in c_w ]\n    len_cur = len(crackles_wheezes)\n    row = [pat_num] + [rec_index] + [chest_loc] + crackles_wheezes + [0] * (max_cycles * 2 - len_cur)\n    \n    aux.append(row)\n\ncol_names = [\"Patient number\", \"Recording index\", \"Chest location\"]\ncol_names_c = [\"Crackles_C{}\".format(num_c) for num_c in range(max_cycles)]\ncol_names_w = [\"Wheezes_C{}\".format(num_w) for num_w in range(max_cycles)]\n\ncol_names_cw = [ name for tup in zip(col_names_c, col_names_w) for name in  tup]\ncol_names.extend(col_names_cw)\n\ndf_annot_aux = pd.DataFrame(aux, columns=col_names)\n\n### diagnosis\n\ndiag = pd.read_csv(fname_diag, names=[\"Patient number\", \"Diagnosis\"])\ndf_rec_info_diag = pd.merge(df_rec_info, diag)\n\n### demographic info\n\nwith open(fname_demo) as f_demo:\n    # skip single empty line at the beginning\n    f_demo.readline()\n\n    lines = [line.strip().split() for line in f_demo.readlines()]\n\n\nfor split in lines:\n    split[0] = int(split[0])\n    if split[1] != \"NA\":\n        split[1] = float(split[1])\n    else:\n        split[1] = np.nan        \n    if split[2] != \"NA\":\n        pass\n    else:\n        split[2] = np.nan        \n    if split[3] != \"NA\":\n        split[3] = float(split[3])\n    else:\n        split[3] = np.nan        \n    if split[4] != \"NA\":\n        split[4] = float(split[4])\n    else:\n        split[4] = np.nan\n    if split[5] != \"NA\":\n        split[5] = float(split[5])\n    else:\n        split[5] = np.nan\n\ndf_demo = pd.DataFrame(lines, columns=[\"Patient number\", \"Age\", \"Sex\", \"Adult BMI\", \"Child weight kg\", \"Child height cm\"])\n\n\ndf_full_info = pd.merge(df_rec_info_diag, df_demo, on=\"Patient number\")\ndf_full_info.to_csv(dir_out + \"full_info.csv\", index = False)\ndf_annotation.to_csv(dir_out + \"rec_annotation.csv\", index = False)\ndf_annot_aux.to_csv(dir_out + \"annot_aux.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full_info = pd.read_csv(dir_out + \"full_info.csv\")\ndf_annotation = pd.read_csv(dir_out + \"rec_annotation.csv\")\ndf_annot_aux = pd.read_csv(dir_out + \"annot_aux.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full= pd.merge(df_full_info, df_annot_aux).set_index([\"Patient number\"])\ndf_full","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Try simple prediction\n### Try Age, Sex, Chest location, Recording equipment to predict diagnosis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"diag.groupby([\"Diagnosis\"]).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_attrs = [\"Chest location\", \"Recording equipment\"]\nnum_attrs = [\"Age\"]\n\n# one NaN there\ndf_full[\"Sex\"]  = df_full[\"Sex\"].fillna(\"F\")\ndf_full[\"Age\"]  = df_full[\"Age\"].fillna(df_full.Age.mean())\n\ncol_tr = ColumnTransformer([\n    (\"one_hot\", OneHotEncoder(), cat_attrs),\n    (\"standard\", StandardScaler(), num_attrs)\n], remainder=\"drop\")\n\nlabel_enc = LabelEncoder()\nlabel_enc.fit(diag[\"Diagnosis\"])\n\n# split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n# for train_ix, test_ix in split.split(df_full, df_full[\"Diagnosis\"]):\n#     df_train = df_full[train_ix]\n#     df_test = df_full[test_ix]\n\ndf_train, df_test = train_test_split(df_full, test_size=0.1, random_state=42)\n\nlabels_train = label_enc.transform(df_train[\"Diagnosis\"])\nlabels_test = label_enc.transform(df_test[\"Diagnosis\"])\n\ndf_train.drop([\"Diagnosis\"], axis=1, inplace=True)\ndf_test.drop([\"Diagnosis\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_trans = col_tr.fit_transform(df_train)\ntest_trans = col_tr.fit_transform(df_test)\n\ndectree_clf = DecisionTreeClassifier()\ndectree_clf.fit(train_trans, labels_train)\npred = dectree_clf.predict(train_trans)\naccuracy_score(labels_train, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(labels_train, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = dectree_clf.predict(test_trans)\naccuracy_score(labels_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(labels_test, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looks good. This might mean that it's viable to train a model to automatically annotate audio files and use the annotations for prediction of the diagnosis which is less complicated and resource intensive","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}