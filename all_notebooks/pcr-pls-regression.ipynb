{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/hitters/Hitters.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()\n#","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nIt appears that there is a null value in the \"Salary\" variable. Let's fill them with the average value of the variable with the \"fillna\" function."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(df.mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Editing The Dataset"},{"metadata":{},"cell_type":"markdown","source":"### Converting Categorical Variables To Numeric variables"},{"metadata":{},"cell_type":"markdown","source":"Categorical variables are transformed with the \"get_dummies\" function in pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_variables = [\"League\",\"Division\",\"NewLeague\"]\ndums = pd.get_dummies(df[cat_variables])\ndums.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After the categorical variables are converted, any transformed new variable belonging to each variable is selected and deleted.\n\nBecause the value of the deleted variable can be understood by looking at the other transformed variables already remaining.\n\nFor example, if all non-deleted variables are 0, it means that the deleted variable must be 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"dums.drop([\"League_N\",\"Division_W\",\"NewLeague_N\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, a new data set is created by combining the data set with the newly created variables. The old categorical variables that have been transformed are removed from the data set because they are no longer needed."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df= pd.concat([df,dums],axis=1)\nfinal_df.drop(cat_variables,axis=1,inplace=True)\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.Salary,kde= False);\n#This is the distribution of the \"Salary\" variable.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCR"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nLet's choose the dependent and independent variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = final_df.drop(\"Salary\",axis =1)\ny = final_df.Salary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nIn this data set, we took the variable \"Salary\" as the dependent variable."},{"metadata":{},"cell_type":"markdown","source":"Now we need to divide our data set into \"test\" and \"train\". Because after training our program from the \"train\" set, we will test it with our \"test\" set to see the error value.\n\nFor this we will use the \"train_test_split\" function in the \"scikit-learn\" module."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before using \"PCR\" in this dataset, the argument values ​​must be formatted with the \"scale\" function."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_scaled = PCA().fit_transform(scale(x_train))\nx_test_scaled = PCA().fit_transform(scale(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pcr_model = LinearRegression().fit(x_train_scaled,y_train)\ny_pred = pcr_model.predict(x_test_scaled)\nnp.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nAfter setting up our model, we looked at our primitive error rate. Let's now use visualization to find the best parameter for this model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\ncv_10 = model_selection.KFold(n_splits=10,shuffle = True,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nRMSE = []\nfor i in np.arange(1,x_train_scaled.shape[1]+1):\n    score = np.sqrt(-1*model_selection.cross_val_score(lm,\n                                                      x_train_scaled[:,:i],\n                                                      y_train.ravel(),\n                                                      cv=cv_10,\n                                                      scoring=\"neg_mean_squared_error\").mean())\n    RMSE.append(score)\n    \nplt.plot(RMSE,\"-v\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creates a model with all variable arrays in dependent variables and checks error rate. We set up a new model according to the lowest error value in this graph.\n\nAs seen in the graph, the lowest error rate was \"17\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"pcr_model = lm.fit(x_train_scaled[:,:17],y_train)\ny_pred = pcr_model.predict(x_train_scaled[:,:17])\nnp.sqrt(mean_squared_error(y_train,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pcr_model.predict(x_test_scaled[:,:17])\nnp.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PLS"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cross_decomposition import PLSRegression,PLSSVD ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pls_model = PLSRegression(n_components=6).fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"?PLSRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pls_model.predict(x_train)\nnp.sqrt(mean_squared_error(y_train,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_10 =model_selection.KFold(n_splits=10,shuffle=True,random_state=10)\n\nRMSE =list()\nfor i in np.arange(1,x_train.shape[1]+1):\n    pls = PLSRegression(n_components=i)\n    score = np.sqrt(-1*model_selection.cross_val_score(pls,x_train,y_train,cv=cv_10,scoring=\"neg_mean_squared_error\").mean())\n    RMSE.append(score)\n\nplt.plot(np.arange(1,x_train.shape[1]+1),np.array(RMSE),\"-v\",c=\"r\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)One of the most important parameters in the PLS model is \"n_components\". Therefore, we try to find the most suitable result by trying each value for this parameter.\n\nIt seems that the most suitable value in this graph is \"12\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"pls_model = PLSRegression(n_components=12).fit(x_train,y_train)\ny_pred = pls_model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}