{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install plotly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/covid19-case-surveillance-public-use-dataset/COVID-19_Case_Surveillance_Public_Use_Data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The purpose of this project is to build a ML algorithm to define whether or not the person with the features from the dataset will be hospitalized.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.head()\n#df.shape\n#df.isnull().sum()\n#df['current_status'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.histogram(df['age_group'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"grouped_df = df.groupby(['sex','age_group','Race and ethnicity (combined)','hosp_yn','medcond_yn']).count()\ndf1 = pd.DataFrame()\ndf1['sex'] = np.array(list(grouped_df.index))[:,0]\ndf1['age_group'] = np.array(list(grouped_df.index))[:,1]\ndf1['race'] = np.array(list(grouped_df.index))[:,2]\ndf1['hosp'] = np.array(list(grouped_df.index))[:,3]\ndf1['medc'] = np.array(list(grouped_df.index))[:,4]\ndf1['Count'] = grouped_df['icu_yn'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.sunburst(df1, path=['hosp','medc','age_group','race','sex'], values='Count', color='hosp')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['cdc_report_dt']\ndel df['pos_spec_dt']\ndel df['onset_dt']\n\n\ndf.drop(df[df['current_status'] == 'Probable Case'].index, inplace = True)\ndf.drop(df[df['hosp_yn'] == 'Missing'].index, inplace = True)\ndf.drop(df[df['Race and ethnicity (combined)'] == 'Unknown'].index, inplace = True)\n\ndel df['current_status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df[:1000]\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing \n\nlabel_encoder = preprocessing.LabelEncoder() \n\ndf1 = df1.apply(label_encoder.fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df1['hosp_yn']\nX = df1[['sex','age_group','Race and ethnicity (combined)','medcond_yn']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's begin exploring the algorithms!"},{"metadata":{},"cell_type":"markdown","source":"We start with SVM."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n\nCV_svm = GridSearchCV(SVC(), tuned_parameters)\nCV_svm.fit(X_train, y_train)\nCV_svm.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(C=1.0, kernel='linear', gamma=0.001)\nsvm.fit(X_train, y_train)\ny_pred_svm = svm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nprint(accuracy_score(y_test, y_pred_svm))\nprint(confusion_matrix(y_test, y_pred_svm))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's create a pipeline for a standard procedure for other algorithms to use."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ntree_para = {'criterion':['gini','entropy'],\n             'max_depth':[1,2,3,5,10,50,100]}\nCV_tree = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)\nCV_tree.fit(X_train, y_train)\nCV_tree.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(max_depth=2, criterion='gini')\ntree.fit(X_train, y_train)\n\ny_pred_tree = tree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(y_test, y_pred_tree))\nprint(confusion_matrix(y_test, y_pred_tree))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build an ExtraTrees classifier to get feature importances of the datase"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# Build a classification task using 3 informative features\n\n# Build a forest and compute the impurity-based feature importances\nforest = ExtraTreesClassifier(n_estimators=4,\n                              random_state=0)\n\nforest.fit(X_train, y_train)\nimportances = forest.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(X_train.shape[1]):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n# Plot the impurity-based feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(X_train.shape[1]), importances[indices],\n        color=\"b\", yerr=std[indices], align=\"center\")\nplt.xticks(range(X_train.shape[1]), indices)\nplt.xlim([-1, X_train.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Looks like the only important value is whether or not the patient has a medical condition.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}