{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Видаляємо неінформативні колонки\n2. Корегуємо назви колонок аби вони були коректними при роботі з layers\n3. Переглядаємо датасет"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndataframe = dataframe.drop(columns=[\"Unnamed: 32\", \"id\"])\n\ncns = dataframe.columns\ncn_to_replace = []\nfor cn in cns:\n    if \" \" in cn:\n        dataframe= dataframe.rename(columns={cn: \"_\".join(cn.split(\" \"))})\n        \ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Виділяємо половину датасету для навчання"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe = dataframe.sample(frac=0.8, random_state=2021)\nvalidate_dataframe = dataframe.drop(train_dataframe.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe.head()\n#validate_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Конвертуємо стрінгові значення до числових та виконуємо підготовку датасети"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n\ndef create_ds(dataframe):\n    dataframe = dataframe.copy()\n    labels = dataframe.pop(\"diagnosis\")\n    labels = labels.to_numpy()\n    sl_layer = StringLookup(num_oov_indices=0)\n    sl_layer.adapt(labels)\n    labels = sl_layer(labels)\n    \n    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n    ds = ds.shuffle(buffer_size = len(dataframe))\n    return ds\n\ntrain_ds = create_ds(train_dataframe)\nvalidate_ds = create_ds(validate_dataframe)\n\ntrain_ds = train_ds.batch(50)\nvalidate_ds = validate_ds.batch(50)\n\nfeatures = dataframe.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = []\nfor feature in features:\n    tmp = keras.Input(name = feature, shape = (1,), dtype = tf.float32)\n    if tmp.shape[-1] is None:\n        tmp = tf.expand_dims(tmp, -1)\n    inputs.append(tmp)\n    \n\nf_layers = layers.concatenate(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = layers.Dense(17, activation=\"relu\")(f_layers)\nout = layers.Dense(1, activation=\"sigmoid\")(tmp)\nmodel = keras.Model(inputs, out)\nmodel.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_ds, epochs=20, validation_data = validate_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\ndef get_x_y_df(df):\n    cdf = df.copy()\n    y = cdf.pop(\"diagnosis\")\n    voc = y.unique()\n    y = y.replace([\"B\", \"M\"], [1, 0])\n    \n    x= (cdf-cdf.min())/(cdf.max()-cdf.min())\n    \n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_x, t_y = get_x_y_df(train_dataframe)\nv_x, v_y = get_x_y_df(validate_dataframe)\n\nrfc = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(t_x, t_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(rfc.predict(v_x), v_y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}