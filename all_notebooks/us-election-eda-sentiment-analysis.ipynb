{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Trump vs Biden](https://therealdeal.com/wp-content/uploads/2020/09/1200-Will-real-estate-take-the-stage-in-the-first-presidential-debate_-705x439.jpg)\n# **Introduction**\nHi! \nHere I'll try to find interesting sides of the past USA election in tweets dedicated to two major candidates: Donald Trump and Joe Biden. \nI hope, it'll be an interesting journey. If you'll find it useful, please, **upvote** and **leave a comment**. \nWork is still in progress, so I'll be improving and expanding my analysis. Maybe I'll find some new interesting tasks. \n\nNow, let's start!\n\n### **Notebook changes:**\n**Version 5:** fixed errors in names of some figures; added comments to some parts of the code."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# basic packages\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\n# geodata\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# custom y-axis\nfrom matplotlib.ticker import FuncFormatter\ndef millions(x, pos):\n    return '%1.1fM' % (x * 1e-6)\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n# NLP\nimport unicodedata\nimport string\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter, defaultdict\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom textblob import TextBlob\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# kaggle workspace\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Loading the data\ntrump = pd.read_csv('../input/us-election-2020-tweets/hashtag_donaldtrump.csv', \n                    lineterminator='\\n', parse_dates=True)\nbiden = pd.read_csv('../input/us-election-2020-tweets/hashtag_joebiden.csv', \n                    lineterminator='\\n', parse_dates=True)\nprint('Trump dataset shape: {}'.format(trump.shape))\nprint('Biden dataset shape: {}'.format(biden.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### A first look at the data"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Trump dataset general information\ntrump.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"# Biden dataset general information\nbiden.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The sample of data\ntrump.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The sample of data\nbiden.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EDA**\n\"US Election 2020 Tweets\" dataset is an NLP task, so the EDA algorithm includes visualizations of interesting and important numeric features (like the amount of NaN values or number of tweets per day), and detailed analysis of tweets text (length, stopwords, sentiment analysis, etc.). Tweets have a very messy structure (with emojis, hashtags, and so on), so we have to clean it up first."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trump_nan = pd.Series(trump.isna().sum()[trump.isna().sum() > 0].\n                      sort_values(ascending = False))\nbiden_nan = pd.Series(biden.isna().sum()[biden.isna().sum() > 0].\n                      sort_values(ascending = False))\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle('NaN values', size = 15)\n\nsns.barplot(y = trump_nan.index, x = [len(trump)] * len(trump_nan),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax1)\nsns.barplot(y = trump_nan.index, x = trump_nan, \n            edgecolor = 'black', alpha = 0.8, ax = ax1,\n            palette = sns.color_palette(\"viridis\", len(trump_nan)))\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_title('Trump dataset', size = 13)\n\n\nsns.barplot(y = biden_nan.index, x = [len(biden)] * len(biden_nan),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax2)\nsns.barplot(y = biden_nan.index, x = biden_nan, \n            edgecolor = 'black', alpha = 0.8, ax = ax2,\n            palette = sns.color_palette(\"viridis\", len(biden_nan)))\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.set_title('Biden dataset', size = 13)\n\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that geographical information (city, state, country, etc.) is mostly unknown, so this data can't be used for analysis. We'll look only at the country feature for a small insight into the distribution of users by countries, and will visualize the geodata (lat and long)."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.kdeplot(trump['likes'], label = 'Trump', shade = True, color = 'red')\nsns.kdeplot(biden['likes'], label = 'Biden', shade = True, color = 'blue')\nplt.title('Distributions of likes', size = 15)\nplt.legend(prop={'size': 14})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more tweets dedicated to Donald Trump than Joe Biden, but most of them have less than 6k likes. The most popular tweet has around 74k likes. The most popular tweets dedicated to Joe Biden have 100k+ likes. Let's look at them."},{"metadata":{"trusted":true},"cell_type":"code","source":"# the top of #donaldtrump tweets by likes\ntrump.sort_values('likes', ascending = False)[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the top of #joebiden tweets by likes\nbiden.sort_values('likes', ascending = False)[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"The dependence of retweets on likes\", size = 15)\n\nsns.scatterplot(x = trump['likes'], y = trump['retweet_count'],\n                color = 'red', ax = ax1)\nax1.get_yaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('Likes')\nax1.set_ylabel('Retweets')\nax1.set_title('Trump', size = 13)\n\n\nsns.scatterplot(x = biden['likes'], y = biden['retweet_count'],\n                color = 'blue', ax = ax2)\nax2.get_yaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('Likes')\nax2.set_ylabel('Retweets')\nax2.set_title('Biden', size = 13)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Correlation between likes and retweets (Trump): {}'.\n      format(trump['likes'].corr(trump['retweet_count'])))\nprint('Correlation between likes and retweets (Biden): {}'.\n      format(biden['likes'].corr(biden['retweet_count'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a strong positive correlation between likes and retweets that looks logical."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(17, 5))\n\nax = sns.lineplot(data = pd.to_datetime(trump.created_at).dt.date.value_counts(), \n                  label = 'Trump', color = 'red', linewidth = 3)\nax = sns.lineplot(data = pd.to_datetime(biden.created_at).dt.date.value_counts(), \n                  label = 'Biden', color = 'blue', linewidth = 3)\nax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d %b'))\n\nplt.title('Tweets amount changing', size = 15)\nplt.legend(prop={'size': 14})\nplt.ylabel('Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The chart above shows that throughout the study period Donald Trump was a more popular target for tweets, but after November 6 this situation changed. It's related to election results and Joe Biden's victory. Two peaks in activity look logical: October 23 - the day after debate day, and November 4 - the day after Election Day."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trump_tweets_countries = trump.country.value_counts()[:10]\nbiden_tweets_countries = biden.country.value_counts()[:10]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"Tweet authors by countries\", size = 15)\n\nsns.barplot(y = trump_tweets_countries.index, \n            x = [len(trump)] * len(trump_tweets_countries),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax1)\nsns.barplot(y = trump_tweets_countries.index, \n            x = trump_tweets_countries, \n            edgecolor = 'black', color = 'red', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(y = biden_tweets_countries.index, \n            x = [len(biden)] * len(biden_tweets_countries),\n           edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax2)\nsns.barplot(y = biden_tweets_countries.index, \n            x = biden_tweets_countries, \n            edgecolor = 'black', color = 'blue', alpha = 0.8, ax = ax2)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('')\nax2.set_title('Biden', size = 13)\n\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are inconsistent country names in the data: \"United States of America\" and \"United States\", which are the same. Let's clean it up."},{"metadata":{"trusted":true},"cell_type":"code","source":"trump['country'] = trump['country'].replace(['United States of America', \n                                             'United States'], 'USA')\nbiden['country'] = biden['country'].replace(['United States of America', \n                                             'United States'], 'USA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trump_tweets_countries = trump.country.value_counts()[:10]\nbiden_tweets_countries = biden.country.value_counts()[:10]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"Tweet authors by countries\", size = 15)\n\nsns.barplot(y = trump_tweets_countries.index, x = [len(trump)] * len(trump_tweets_countries),\n            edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax1)\nsns.barplot(y = trump_tweets_countries.index, x = trump_tweets_countries, \n            edgecolor = 'black', color = 'red', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(y = biden_tweets_countries.index, x = [len(biden)] * len(biden_tweets_countries),\n           edgecolor = 'black', color = 'white', alpha = 0.6, ax = ax2)\nsns.barplot(y = biden_tweets_countries.index, x = biden_tweets_countries, \n            edgecolor = 'black', color = 'blue', alpha = 0.8, ax = ax2)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('')\nax2.set_title('Biden', size = 13)\n\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# preparation of the geodata\ntmp_tr = trump[['lat', 'long']].dropna()\ntmp_bi = biden[['lat', 'long']].dropna()\n\ngeometry_tr = [Point(xy) for xy in zip(tmp_tr['long'], tmp_tr['lat'])]\ngeometry_bi = [Point(xy) for xy in zip(tmp_bi['long'], tmp_bi['lat'])]\n\ngeo_df_tr = gpd.GeoDataFrame(geometry = geometry_tr)\ngeo_df_bi = gpd.GeoDataFrame(geometry = geometry_bi)\n\nwmap = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), facecolor = 'white')\nplt.text(x = -325, y = 120, s = \"The geodata of tweets\", fontsize = 15)\n\nwmap.plot(ax = ax1, edgecolors='black', color = 'white')\ngeo_df_tr.plot(ax = ax1, markersize = 0.5, color = 'red')\nax1.set_title('Trump', size = 13)\nax1.axis('off')\n\nwmap.plot(ax = ax2, edgecolors='black', color = 'white')\ngeo_df_bi.plot(ax = ax2, markersize = 0.5, color = 'blue')\nax2.set_title('Biden', size = 13)\nax2.axis('off')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that these features aren't useful for deep analysis because over 50% of the data is NaN and give only a small insight into the distribution of tweets by countries. More useful and interesting can be the 'user_name' feature as a list of candidates' upholders (or haters)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trump tweets authors\ntrump_count = pd.DataFrame(trump['user_name'].value_counts())\ntrump_count = pd.DataFrame({'user_name': trump_count.index, \n                            'count': trump_count.user_name})\ntrump_likes = trump[['user_name', 'likes']].groupby('user_name').sum()\ntrump_agg = pd.merge(trump_count, trump_likes, on = 'user_name', \n                     how = 'left')\n\n# Biden tweets authors\nbiden_count = pd.DataFrame(biden['user_name'].value_counts())\nbiden_count = pd.DataFrame({'user_name': biden_count.index, \n                            'count': biden_count.user_name})\nbiden_likes = biden[['user_name', 'likes']].groupby('user_name').sum()\nbiden_agg = pd.merge(biden_count, biden_likes, on = 'user_name', \n                     how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# The dependence of likes sums on tweets amounts\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"The dependence of likes sums on tweets amounts\", size = 15)\n\nsns.scatterplot(x = trump_agg['count'], y = trump_agg['likes'],\n                color = 'red', ax = ax1)\nax1.get_yaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('Amount of tweets')\nax1.set_ylabel('Sum of likes')\nax1.set_title('Trump', size = 13)\n\n\nsns.scatterplot(x = biden_agg['count'], y = biden_agg['likes'],\n                color = 'blue', ax = ax2)\nax2.get_yaxis().get_major_formatter().set_scientific(False)\nax2.set_xlabel('Amount of tweets')\nax2.set_ylabel('Sum of likes')\nax2.set_title('Biden', size = 13)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average number of likes per tweet (Trump): {}'.\n      format(round(trump_agg['likes'].sum() / trump_agg['count'].sum(), 0)))\nprint('Average number of likes per tweet (Biden): {}'.\n      format(round(biden_agg['likes'].sum() / biden_agg['count'].sum(), 0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tweets dedicated to Joe Biden liked more often."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# User followers count\ntrump_user_followers = trump[['user_name', \n                              'user_followers_count']].groupby('user_name').max()\nbiden_user_followers = biden[['user_name', \n                              'user_followers_count']].groupby('user_name').max()\n\ntrump_top_authors_by_count = pd.merge(trump_agg[:10], trump_user_followers, \n                                      on = 'user_name', how = 'left')\nbiden_top_authors_by_count = pd.merge(biden_agg[:10], biden_user_followers, \n                                      on = 'user_name', how = 'left')\n\n# Top users by tweets amount\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle(\"Top users by tweets amount\", size = 15)\n\nsns.barplot(x = trump_agg['count'][:10], y = trump_agg['user_name'][:10],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_ylabel('User name')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(x = biden_agg['count'][:10], y = biden_agg['user_name'][:10],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax3)\nax3.get_xaxis().get_major_formatter().set_scientific(False)\nax3.set_xlabel('')\nax3.set_ylabel('User name')\nax3.set_title('Biden', size = 13)\n\n\nsns.barplot(x = trump_top_authors_by_count['user_followers_count'], \n            y = trump_top_authors_by_count['user_name'],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax2)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\nax2.get_yaxis().set_visible(False)\nax2.set_xlabel('')\nax2.set_title('User followers count', size = 13)\n\n\nsns.barplot(x = biden_top_authors_by_count['user_followers_count'], \n            y = biden_top_authors_by_count['user_name'],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax4)\nax4.get_xaxis().get_major_formatter().set_scientific(False)\nax4.get_yaxis().set_visible(False)\nax4.set_xlabel('')\nax4.set_title('User followers count', size = 13)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Users who posted the most tweets have a small amount of followers."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# User followers count\ntrump_top_authors_by_likes = pd.merge(trump_agg.sort_values('likes', ascending = False)[:10], \n                                      trump_user_followers, on = 'user_name', how = 'left')\nbiden_top_authors_by_likes = pd.merge(biden_agg.sort_values('likes', ascending = False)[:10], \n                                      biden_user_followers, on = 'user_name', how = 'left')\n\n# Top users by likes\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Top users by likes', size = 15)\n\nsns.barplot(x = trump_top_authors_by_likes['likes'], \n            y = trump_top_authors_by_likes['user_name'],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax1)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\nax1.set_xlabel('')\nax1.set_ylabel('User name')\nax1.set_title('Trump', size = 13)\n\n\nsns.barplot(x = biden_top_authors_by_likes['likes'], \n            y = biden_top_authors_by_likes['user_name'],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax3)\nax3.get_xaxis().get_major_formatter().set_scientific(False)\nax3.set_xlabel('')\nax3.set_ylabel('User name')\nax3.set_title('Biden', size = 13)\n\n\nsns.barplot(x = trump_top_authors_by_likes['user_followers_count'], \n            y = trump_top_authors_by_likes['user_name'],\n            color = 'red', edgecolor = 'black', alpha = 0.8, ax = ax2)\nax2.xaxis.set_major_formatter(FuncFormatter(millions))\nax2.get_yaxis().set_visible(False)\nax2.set_xlabel('')\nax2.set_title('User followers count', size = 13)\n\n\nsns.barplot(x = biden_top_authors_by_likes['user_followers_count'], \n            y = biden_top_authors_by_likes['user_name'],\n            color = 'blue', edgecolor = 'black', alpha = 0.8, ax = ax4)\nax4.xaxis.set_major_formatter(FuncFormatter(millions))\nax4.get_yaxis().set_visible(False)\nax4.set_xlabel('')\nax4.set_title('User followers count', size = 13)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the contrary, users whose tweets got many likes have far more followers, that looks logical. We will be able to classify these users into upholders or haters after sentiment analysis."},{"metadata":{},"cell_type":"markdown","source":"At first, we have to clean the data up. We'll use a great package [re](https://docs.python.org/3/library/re.html) for this. Let's look at the random tweets."},{"metadata":{"trusted":true},"cell_type":"code","source":"trump['tweet'][19529]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"biden['tweet'][11650]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As intended, tweets have various kinds of noise, like emojis, special symbols, newline tabulators, links, etc. Also, not all tweets wrote in English (like the tweet above)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tweet cleaner\ndef tweet_cleaner(text):\n    text = text.lower()\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    text = re.sub('\\[.*?\\]', ' ', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trump_cleaned = trump.copy()\nbiden_cleaned = biden.copy()\n\ntrump_cleaned['tweet'] = trump_cleaned['tweet'].apply(lambda x: tweet_cleaner(x))\nbiden_cleaned['tweet'] = biden_cleaned['tweet'].apply(lambda x: tweet_cleaner(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trump_cleaned['tweet'][19529]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"biden_cleaned['tweet'][11650]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take a look at the length of tweets."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trump_tweet_length = trump_cleaned.tweet.str.len()\nbiden_tweet_length = biden_cleaned.tweet.str.len()\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.distplot(trump_tweet_length, label = 'Trump', color = 'red', kde = False)\nsns.distplot(biden_tweet_length, label = 'Biden', color = 'blue', kde = False)\nplt.legend(prop={'size': 14})\nplt.title('Tweet length', size = 15)\nplt.xlabel('Length of tweet (symbols)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that on average, the distributions of tweet length for both candidates are the same."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trump_words = trump_cleaned.tweet.str.split().map(lambda x: len(x))\nbiden_words = biden_cleaned.tweet.str.split().map(lambda x: len(x))\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.distplot(trump_words, label = 'Trump', color = 'red', kde = False)\nsns.distplot(biden_words, label = 'Biden', color = 'blue', kde = False)\nplt.legend(prop={'size': 14})\nplt.title('The number of words in tweet', size = 15)\nplt.xlabel('Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost the same. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trump_word_len = trump_cleaned.tweet.str.split().apply(lambda x: [len(i) for i in x]).map(lambda x: np.mean(x))\nbiden_word_len = biden_cleaned.tweet.str.split().apply(lambda x: [len(i) for i in x]).map(lambda x: np.mean(x))\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14, 5))\n\nsns.distplot(trump_word_len, label = 'Trump', color = 'red', kde = False)\nsns.distplot(biden_word_len, label = 'Biden', color = 'blue', kde = False)\nplt.legend(prop={'size': 14})\nplt.title('The average word length', size = 15)\nplt.xlabel('Length of word')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The chart above shows that almost all words have a range of lengths from 0 to 20. But there are some words with zero-length (NaN values), and, on the contrary, far longer than 20 letters (80, 100, and even more!). We'll remove only NaN-type outliers because long words are unique and don't have a powerful effect on data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tweets with NaN length\ntrump_NaN_len = trump_word_len[trump_word_len.isnull()].index\nbiden_NaN_len = biden_word_len[biden_word_len.isnull()].index\n\n# removing tweets with NaN length\ntrump_cleaned = trump_cleaned.drop(trump_NaN_len, axis = 0)\nbiden_cleaned = biden_cleaned.drop(biden_NaN_len, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating word lists\ntrump_corpus = []\nwords = trump_cleaned['tweet'].str.split().values.tolist()\ntrump_corpus = [word for i in words for word in i]\n\nbiden_corpus = []\nwords = biden_cleaned['tweet'].str.split().values.tolist()\nbiden_corpus = [word for i in words for word in i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word frequency\ntrump_counter = Counter(trump_corpus)\ntrump_most = trump_counter.most_common()\n\nbiden_counter = Counter(biden_corpus)\nbiden_most = biden_counter.most_common()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# The list of languages\nstopwords.fileids()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stopwords; we use English and Spanish as the most frequent in our data \nstop = set(np.concatenate((stopwords.words('english'), stopwords.words('spanish'))))\n\ntrump_x, trump_y = [], []\nfor word, count in trump_most[:100]:\n    if word not in stop:\n        trump_x.append(word)\n        trump_y.append(count)\n        \nbiden_x, biden_y = [], []\nfor word, count in biden_most[:100]:\n    if word not in stop:\n        biden_x.append(word)\n        biden_y.append(count)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# TOP-20 words for both candidates\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('TOP-20 words', size = 15)\n\nsns.barplot(x = trump_y[:20], y = trump_x[:20], edgecolor = 'black', color = 'red', ax = ax1)\nax1.set_title('Trump', size = 13)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\n\nsns.barplot(x = biden_y[:20], y = biden_x[:20], edgecolor = 'black', color = 'blue', ax = ax2)\nax2.set_title('Biden', size = 13)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among the most frequent words in tweets dedicated to Donald Trump (excluding candidates' proper nouns) occur both popular election words: \"vote\", \"election\", \"president\", \"people\", \"Election Day\", etc., and specific, like \"MAGA\" (Trump's tagline \"Make America Great Again\") or \"die\" (a word with negative sense). Specific words of tweets dedicated to Joe Biden: \"Kamala Harris\" (Vice President-elect of the United States), \"BidenHarris\", \"win\" (a word that is more frequent regarding Joe Biden than Donald Trump). Let's look at Bi and Tri n-grams of words."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ngrams of words\ndef get_top_ngram(corpus, n = None):\n    vec = CountVectorizer(stop_words = stop, ngram_range = (n, n)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top-10 bigrams"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Data for bigrams\ntop_trump_n_bigrams = get_top_ngram(trump_cleaned['tweet'], 2)[:10]\ntrump_x, trump_y = map(list, zip(*top_trump_n_bigrams))\n\ntop_biden_n_bigrams = get_top_ngram(biden_cleaned['tweet'], 2)[:10]\nbiden_x, biden_y = map(list, zip(*top_biden_n_bigrams))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('TOP Bigrams', size = 15)\n\nsns.barplot(x = trump_y, y = trump_x, edgecolor = 'black', color = 'red', ax = ax1)\nax1.set_title('Trump', size = 13)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\n\nsns.barplot(x = biden_y, y = biden_x, edgecolor = 'black', color = 'blue', ax = ax2)\nax2.set_title('Biden', size = 13)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top-10 trigrams"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Data for trigrams\ntop_trump_n_bigrams = get_top_ngram(trump_cleaned['tweet'], 3)[:10]\ntrump_x, trump_y = map(list, zip(*top_trump_n_bigrams))\n\ntop_biden_n_bigrams = get_top_ngram(biden_cleaned['tweet'], 3)[:10]\nbiden_x, biden_y = map(list, zip(*top_biden_n_bigrams))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('TOP Trigrams', size = 15)\n\nsns.barplot(x = trump_y, y = trump_x, edgecolor = 'black', color = 'red', ax = ax1)\nax1.set_title('Trump', size = 13)\nax1.get_xaxis().get_major_formatter().set_scientific(False)\n\nsns.barplot(x = biden_y, y = biden_x, edgecolor = 'black', color = 'blue', ax = ax2)\nax2.set_title('Biden', size = 13)\nax2.get_xaxis().get_major_formatter().set_scientific(False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wordclouds"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_wordcloud(data, title = None, color = 'white'):\n    wordcloud = WordCloud(background_color=color,\n                         stopwords=stop,\n                         max_words=10000,\n                         scale=3,\n                         width = 4000, \n                         height = 2000,\n                         collocations=False,\n                         random_state=1)\n    \n    wordcloud = wordcloud.generate(str(data))\n    \n    plt.figure(1, figsize=(16, 8))\n    plt.title(title, size = 15)\n    plt.axis('off')\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_wordcloud(trump_cleaned['tweet'].dropna(), title = 'Trump wordcloud', color = 'black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_wordcloud(biden_cleaned['tweet'].dropna(), title = 'Biden wordcloud', color = 'black')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, it's time for **sentiment analysis**."},{"metadata":{},"cell_type":"markdown","source":"# **Sentiment analysis**\nWe'll use two tools: TextBlob package, and VADER from NLTK package."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text polarity function\ndef polarity(data):\n    return TextBlob(data).sentiment.polarity\n\ntrump_cleaned['polarity'] = trump_cleaned['tweet'].apply(lambda x: polarity(x))\nbiden_cleaned['polarity'] = biden_cleaned['tweet'].apply(lambda x: polarity(x))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Polarity (TextBlob)', size = 15)\nplt.text(x=-2.3, y=20.3, s='(from -1 (extremely negative) to 1 (extremely positive))', fontsize=10, alpha=0.8)\n\n\nsns.kdeplot(trump_cleaned['polarity'], color = 'red', ax = ax1, legend = False)\nax1.set_title('Trump', size = 13)\n\nsns.kdeplot(biden_cleaned['polarity'], color = 'blue', ax = ax2, legend = False)\nax2.set_title('Biden', size = 13)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at some extremely positive and extremely negative tweets of both candidates."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trump negative tweets\ntrump_cleaned[trump_cleaned['polarity'] == -1]['tweet'][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trump positive tweets\ntrump_cleaned[trump_cleaned['polarity'] == 1]['tweet'][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Biden negative tweets\nbiden_cleaned[biden_cleaned['polarity'] == -1]['tweet'][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Biden positive tweets\nbiden_cleaned[biden_cleaned['polarity'] == 1]['tweet'][:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not perfect (because the data still dirty, and the TextBlob method not 100% effective), but it works well enough. Let's try VADER method that works better with negative sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"# VADER Analyzer\nsid = SentimentIntensityAnalyzer()\n\n# Text polarity function\ndef get_vader_score(data):\n    return sid.polarity_scores(data)['compound']\n\ntrump_cleaned['VADER'] = trump_cleaned['tweet'].apply(lambda x: get_vader_score(x))\nbiden_cleaned['VADER'] = biden_cleaned['tweet'].apply(lambda x: get_vader_score(x))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Polarity (VADER)', size = 15)\nplt.text(x=-2.4, y=9.3, s='(from -1 (extremely negative) to 1 (extremely positive))', fontsize=10, alpha=0.8)\n\n\nsns.kdeplot(trump_cleaned['VADER'], color = 'red', ax = ax1, legend = False)\nax1.set_title('Trump', size = 13)\n\nsns.kdeplot(biden_cleaned['VADER'], color = 'blue', ax = ax2, legend = False)\nax2.set_title('Biden', size = 13)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, with VADER the percentage of neutral polarities (close to zero) decreased in the negative direction."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(trump_cleaned['tweet'].loc[945451])\nprint('*'*20)\nprint(trump_cleaned[['polarity', 'VADER']].loc[945451])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(biden_cleaned['tweet'].loc[296157])\nprint('*'*20)\nprint(biden_cleaned[['polarity', 'VADER']].loc[296157])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow, VADER really looks better at recognizing negative sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"# create 'date' feature\ntrump_cleaned['date'] = pd.to_datetime(trump_cleaned['created_at']).dt.date\nbiden_cleaned['date'] = pd.to_datetime(biden_cleaned['created_at']).dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_line_plot(data1, data2, FUN, ax, title):\n    sns.lineplot(data = data1.groupby('date')[FUN].mean(), \n                 label = 'Trump', color = 'red', linewidth = 3, ax = ax)\n    sns.lineplot(data = data2.groupby('date')[FUN].mean(), \n                 label = 'Biden', color = 'blue', linewidth = 3, ax = ax)\n    ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d %b'))\n    ax.set_title(title, size = 13)\n    ax.legend(prop={'size': 14})\n    ax.set_ylabel('Polarity')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Sentiment polarity changing', size = 15)\n\ncreate_line_plot(trump_cleaned, biden_cleaned, 'polarity', ax1, '(TextBlob)')\ncreate_line_plot(trump_cleaned, biden_cleaned, 'VADER', ax2, '(VADER)')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like tweets dedicated to Joe Biden were more positive throughout the studied period. But these are average values. We should look at the changes in the polarity of positive and negative tweets separately."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Working datasets\n# Trump\ntb_pos_tr = trump_cleaned[trump_cleaned['polarity'] > 0]\ntb_neg_tr = trump_cleaned[trump_cleaned['polarity'] < 0]\nvader_pos_tr = trump_cleaned[trump_cleaned['VADER'] > 0]\nvader_neg_tr = trump_cleaned[trump_cleaned['VADER'] < 0]\n\n# Biden\ntb_pos_bi = biden_cleaned[biden_cleaned['polarity'] > 0]\ntb_neg_bi = biden_cleaned[biden_cleaned['polarity'] < 0]\nvader_pos_bi = biden_cleaned[biden_cleaned['VADER'] > 0]\nvader_neg_bi = biden_cleaned[biden_cleaned['VADER'] < 0]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Positive polarity changing', size = 15)\n\ncreate_line_plot(tb_pos_tr, tb_pos_bi, 'polarity', ax1, '(TextBlob)')\ncreate_line_plot(vader_pos_tr, vader_pos_bi, 'VADER', ax2, '(VADER)')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\nsns.set_style(\"whitegrid\")\nplt.suptitle('Negative polarity changing', size = 15)\n\ncreate_line_plot(tb_neg_tr, tb_neg_bi, 'polarity', ax1, '(TextBlob)')\ncreate_line_plot(vader_neg_tr, vader_neg_bi, 'VADER', ax2, '(VADER)')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's time for sentiment classification of users."},{"metadata":{"trusted":true},"cell_type":"code","source":"trump_users_pol = trump_cleaned.groupby('user_name')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = False)\n\nbiden_users_pol = biden_cleaned.groupby('user_name')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Datasets\ntrump_top_authors_by_count = pd.merge(trump_top_authors_by_count, \n                                      trump_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)\n\nbiden_top_authors_by_count = pd.merge(biden_top_authors_by_count, \n                                      biden_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)\n\ntrump_top_authors_by_likes = pd.merge(trump_top_authors_by_likes, \n                                      trump_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)\n\nbiden_top_authors_by_likes = pd.merge(biden_top_authors_by_likes, \n                                      biden_users_pol, on = 'user_name', \n                                      how = 'left').sort_values('VADER', ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def create_lollipop_plot(data, ax, first_color, second_color, title):\n    ax.hlines(y = data['user_name'], xmin = data['polarity'], \n               xmax = data['VADER'], color = first_color, alpha = 0.5)\n    ax.scatter(data['polarity'], data['user_name'], color = first_color, \n                alpha = 1, edgecolors = 'black', label = 'TextBlob')\n    ax.scatter(data['VADER'], data['user_name'], color = second_color, \n                alpha = 1, edgecolors = 'black', label = 'VADER')\n    ax.legend()\n    ax.set_xlim(-1, 1)\n    ax.axvline(x = 0, linestyle = '--', color = 'black', linewidth = 0.7)\n    ax.set_title(title)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Trump users sentiment polarity', size = 15)\n\ncreate_lollipop_plot(trump_top_authors_by_count, ax1, 'red', 'orange',\n                     'TOP users by tweets count')\n\ncreate_lollipop_plot(trump_top_authors_by_likes, ax2, 'red', 'orange',\n                     'TOP users by likes')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Biden users sentiment polarity', size = 15)\n\ncreate_lollipop_plot(biden_top_authors_by_count, ax1, 'blue', 'green',\n                     'TOP users by tweets count')\n\ncreate_lollipop_plot(biden_top_authors_by_likes, ax2, 'blue', 'green',\n                     'TOP users by likes')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And also we should look at the sentiment polarity of TOP-countries."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Datasets\ntr_top_countries = trump_cleaned[trump_cleaned.country.isin(trump_tweets_countries.index)]\nbi_top_countries = biden_cleaned[biden_cleaned.country.isin(biden_tweets_countries.index)]\n\ntrump_countries_pol = tr_top_countries.groupby('country')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = True)\n\nbiden_countries_pol = bi_top_countries.groupby('country')['polarity', 'VADER'] \\\n    .mean().sort_values('polarity', ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def create_lollipop_plot_2(data, ax, first_color, second_color, title):\n    ax.hlines(y = data.index, xmin = data['polarity'], \n               xmax = data['VADER'], color = first_color, alpha = 0.5)\n    ax.scatter(data['polarity'], data.index, color = first_color, \n                alpha = 1, edgecolors = 'black', label = 'TextBlob')\n    ax.scatter(data['VADER'], data.index, color = second_color, \n                alpha = 1, edgecolors = 'black', label = 'VADER')\n    ax.legend()\n    ax.set_xlim(-1, 1)\n    ax.axvline(x = 0, linestyle = '--', color = 'black', linewidth = 0.7)\n    ax.set_title(title)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\nsns.set_style(\"whitegrid\")\nfig.suptitle('Sentiment polarity by country', size = 15)\n\ncreate_lollipop_plot_2(trump_countries_pol, ax1, 'red', 'orange',\n                     'Trump')\n\ncreate_lollipop_plot_2(biden_countries_pol, ax2, 'blue', 'green',\n                     'Biden')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we've taken a quick look at the sentiment of tweets. There are a lot of analysis variants. It looks great to study the polarity of tweets by cities, or states, for instance, but these features have a lot of NaN values, and therefore don't cover the actual situation. You free to implement your own ideas (maybe I'll expand my own analysis late, this notebook is still in work). I hope you found this notebook useful. See you!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}