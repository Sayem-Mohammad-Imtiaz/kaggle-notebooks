{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI6123 Assignment 3 Code\n\nAuthor: Zhang Hanyu (G2001859G)\n\n## Environment\n\nThis notebook is tested and run on **Kaggle Notebook**, which may be incompatible with local Jupyter environment. You can create a Kaggle account and upload this notebook to Kaggle to run.\n\n## Dataset\n\nThe data used in this code is retrieved from Yahoo Finance according to the instruction of Assignment 3. This dataset has been uploaded to https://www.kaggle.com/crabass/aapl-stock, and you may directly import this dataset if you are using Kaggle Notebook.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/aapl-stock/AAPL.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First calculate the mid prices from the highest and lowest\nhigh_prices = df.loc[:,'High'].to_numpy()\nlow_prices = df.loc[:,'Low'].to_numpy()\nmid_prices = (high_prices + low_prices) / 2.0\n\nplt.figure(figsize = (18,9))\nplt.plot(range(df.shape[0]), mid_prices)\nplt.xticks(range(0,df.shape[0],200),df['Date'].loc[::200],rotation=45)\nplt.xlabel('Date',fontsize=18)\nplt.ylabel('Mid Price',fontsize=18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Data Preprocessing","metadata":{}},{"cell_type":"code","source":"TRAIN_DATA_LENGTH = 3000\ntrain_data = mid_prices[:TRAIN_DATA_LENGTH]\n\nscaler = MinMaxScaler(feature_range=(0, 1))\ntrain_data = train_data.reshape(-1,1)\napple_training_scaled = scaler.fit_transform(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATURE_LENGTH = 60\nfeatures_set = []\nlabels = []\nfor i in range(FEATURE_LENGTH, TRAIN_DATA_LENGTH):\n    features_set.append(apple_training_scaled[i - FEATURE_LENGTH:i, 0])\n    labels.append(apple_training_scaled[i, 0])\nfeatures_set, labels = np.array(features_set), np.array(labels)\nfeatures_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build & Train the LSTM Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(LSTM(units=200, return_sequences=True, input_shape=(features_set.shape[1], 1)))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=200, return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=200, return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=100))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=1))\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(features_set, labels, epochs=100, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"test_data = mid_prices[TRAIN_DATA_LENGTH:].reshape(-1, 1)\ntest_data = scaler.transform(test_data)\n\ntest_features = []\nfor i in range(len(train_data) - FEATURE_LENGTH, len(train_data)):\n    test_features.append(apple_training_scaled[i - FEATURE_LENGTH:i, 0])\nfor i in range(FEATURE_LENGTH, len(test_data)):\n    test_features.append(test_data[i - FEATURE_LENGTH:i, 0])\n\ntest_features = np.array(test_features)\ntest_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))\n\npredictions = model.predict(test_features)\npredictions = scaler.inverse_transform(predictions)\ntest_data = scaler.inverse_transform(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing Result Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(test_data, color='blue', label='Actual Apple Stock Mid-Price')\nplt.plot(predictions, color='red', label='Predicted Apple Stock Mid-Price')\nplt.title('Apple Stock Price Prediction',fontsize=18)\nplt.xlabel('Date',fontsize=18)\nplt.xticks(range(0,len(test_data),50),df['Date'].loc[TRAIN_DATA_LENGTH::50],rotation=45)\nplt.ylabel('Apple Stock Mid-Price (USD)',fontsize=18)\nplt.legend(fontsize=12)\nplt.savefig('/kaggle/working/test_result.jpg', bbox_inches='tight', dpi=150)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n\nprint(f\"MAPE: {mean_absolute_percentage_error(test_data, predictions)}\")\nprint(f\"MSE: {mean_squared_error(test_data, predictions)}\")","metadata":{},"execution_count":null,"outputs":[]}]}