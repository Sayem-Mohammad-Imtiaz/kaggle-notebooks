{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic Dataset:\n1. ****different data preprocessing and modiling and othres techniques\nand much more"},{"metadata":{},"cell_type":"markdown","source":"# 1.section1_Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#At each stage we will bring in the library that we need \nimport pandas as pd     # data processing \nimport numpy as np      # linear algebra \nimport seaborn as sns # data visualization\nimport matplotlib.pyplot as plt\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the data and displaying some rows\ndf= pd.read_csv(\"../input/titanic-extended/full.csv\")\n\ndf.head()\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"WikiId\",\"Name_wiki\",\"Age_wiki\",\"Hometown\",\"Boarded\",\"Destination\",\"Lifeboat\"\n            ,\"Body\",\"Class\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  1.1Shape analysis:\n\n#       variable/target\n     \n#       rows  and columns\n     \n#       missing values analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes.value_counts().plot.pie()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to see the missing values\ndf.isna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will look for the missing values on our dataset with simple graph\nsns.heatmap(df.isna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we notice that there are missing values, they must be treated in another step (the blank represents the missing values)exactly on the columns: \"Age\" and \"Cabin\" and some values on the columns: \"Embarked\""},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will look for the missing values on our dataset\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we have 177 missing values for the \"Age\" columns, 687 values for the \"Cabin\" column and 2 values for the \"Embarked\" columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will look for the missing values on our dataset in percentage\n(df.isna().sum()/df.shape[0]).sort_values(ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will identify the columns which have 70% missing values\ndf.isna().sum()/df.shape[0]<0.7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Elemination of unnecessary columns in our data\ndf.columns[df.isna().sum()/df.shape[0]<0.7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#elimination of unnecessary columns for the train\ndf=df[df.columns[df.isna().sum()/df.shape[0]<0.7]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we created a dataset that contains columns to determine"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.2Bottom analysis:\n#          visualization of the target\n#          meaning of variables\n#          target / variable relationship"},{"metadata":{"trusted":true},"cell_type":"code","source":"#examining the target column\ndf['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we confirm that there are two classes equilibrer which are \"survived == 1\" (342) or not \"survived == 0\" (549)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Survived'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we confirm that there are two classes equilibrer which are \"survived == 1\" (0.383838) or not \"survived == 0\" (0.616162)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#definition:\n#EDA = is Exploratory Data Analysis.this is the preliminary analysis you help on data to understand your \n#data,your variables,and even how relate to another\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# the pandas profiling library is useful on helping understand the data we're working on .It saves us some precious time in the EDE process"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling # library for automatic EDA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"report = pandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's now visualize the report genereted py pandas_profling\ndisplay(report)\n#there is an option to generate an .HTML file containing all the information generated by the report.\n#report.to_file(output_file='report.html')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the report can also exported into an interactive HTMLfile with the following code.\n#profile = df.profile_report (title='Pandas Profiling Report')\n#.to_file (output_file=\"Titanic data profiling.html\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# cufflinks library binds the power of plotly with the flexibility of pandas for easy plotting.Let's now see this "},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install cufflinks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \ndf.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# now we have nice static graphs and numeric graphs which allow us to see all the following relations: varables / variables, variables / target.On the other hand these help us to better understand our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#we are going to do another visualization to better understand the variables\nfor col in df.select_dtypes(\"float\"):\n    print(col)\n    plt.figure()\n    sns.distplot(df[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we have 2 \"float\" type variables which are: \"Age\" and \"Fare\" which are visualized by the previous graphs"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.select_dtypes('int'):\n    print(col)\n    plt.figure()\n    sns.distplot(len(df[col]))\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#discrete variable analysis\nfor col in df.select_dtypes(\"object\"):\n    print(f'{col:-<50}{df[col].unique()}')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# it is a simple method to count the categorical variable we take into account their deffrente value"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.select_dtypes (\"object\"):\n    plt.figure()\n    df[col].value_counts().plot.pie()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# it's to visualize the categorical variables (but in our model the \"Name\" variable contains a lot of value for this our graph is a little bad).Not worry we will solve the problem in the next part"},{"metadata":{},"cell_type":"markdown","source":"# more detailed analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will do some transformation on our dataset\n#according to the previous visualization we notice that we need\n#to do some transformation on the \"Name\" column to improve the perfermance of our model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_data=[df]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# combining train and test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.',expand=False)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# it's a simple code to count the number of words ending in \".\"in all the dataset.We create a new column called \"Title\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# it's a simple code to count the number of words ending in \".\"  the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#title map\n#Mr = 0\n#Miss = 1\n#Mrs = 2\n#othres = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_mapping = {\"Mr\":0, \"Miss\":1,\"Mrs\":2,\"Master\":3,\"Rev\":3,\"Col\":3,\"Dr\":3,\"Dona\":3,\"Ms\":3,\"Mlle\":3,          \n\"Col\":3,\"Mme\":3,\"Jonkheer\":3,\"Capt\":3,\"Sir\":3,\"Don\":3,\"Lady\":3,\"Countess\":3}\nfor dataset in train_test_data:\n    dataset[\"Title\"]=dataset[\"Title\"].map(title_mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we created a dictionary to transform expressions to count into binary form"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#delete unnecessary feature from dataset\ndf.drop('Name',axis=1,inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we erased the column \"Name\" after the extraction of important information"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to do some transformation on the \"Sex\" column to improve the perfermance of our model\n#male = 0\n#female = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_mapping={\"male\":0,\"female\":1}\nfor dataset in train_test_data:\n    dataset[\"Sex\"]=dataset[\"Sex\"].map(sex_mapping)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we have transformed all the values of the column \"Sex\" with \"0\" and \"1\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill missing age with median age each title(Mr,Miss,Mrs,others)\ndf[\"Age\"].fillna(df.groupby(\"Title\")[\"Age\"].transform(\"median\"),inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf[\"Survived\"].fillna(df.groupby(\"Title\")[\"Age\"].transform(\"median\"),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()\ndf.groupby(\"Title\")[\"Age\"].transform(\"median\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Age\" column we\n#will see its relation with the target \"Survived\"\n#(all the ages that are in the dataset)\n\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Age\", shade=True)\nhtf.set(xlim=(1, df[\"Age\"].max()))\nhtf.add_legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Age\" column we\n#will see its relation with the target \"Survived\"\n#(\"Age\"between 0 and 20)\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Age\", shade=True)\nhtf.set(xlim=(1, df[\"Age\"].max()))\nhtf.add_legend()\nplt.xlim(0,20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Age\" column we\n#will see its relation with the target \"Survived\"\n#(\"Age\"between 20 and 40)\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Age\", shade=True)\nhtf.set(xlim=(1, df[\"Age\"].max()))\nhtf.add_legend()\nplt.xlim(20,40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Age\" column we\n#will see its relation with the target \"Survived\"\n#(\"Age\"between 40 and 60)\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Age\", shade=True)\nhtf.set(xlim=(1, df[\"Age\"].max()))\nhtf.add_legend()\nplt.xlim(40,60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Age\" column we\n#will see its relation with the target \"Survived\"\n#(\"Age\"between 60 and 80)\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Age\", shade=True)\nhtf.set(xlim=(1, df[\"Age\"].max()))\nhtf.add_legend()\nplt.xlim(60,80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to do some transformation on the \"Embarked\" column to improve the perfermance of our model\nPclass1 = df[df[\"Pclass\"]==1][\"Embarked\"].value_counts()\nPclass2 = df[df[\"Pclass\"]==2][\"Embarked\"].value_counts()\nPclass3 = df[df[\"Pclass\"]==3][\"Embarked\"].value_counts()\ndf1 = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf1.index = ['1_class','2_class','3_class']\ndf1.plot(kind =\"bar\",stacked =True,figsize=(15,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# more than 50% os 1_class are from S embark\n# more than 50% os 2_class are from S embark\n# more than 50% os 3_class are from S embark"},{"metadata":{"trusted":true},"cell_type":"code","source":"#full out missing embark with \"s\" embark\nfor dataset in train_test_data:\n    dataset[\"Embarked\"]=dataset[\"Embarked\"].fillna(\"S\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we fill the missing values of the column \"Embarked\" by \"s\""},{"metadata":{"trusted":true},"cell_type":"code","source":"set_mapping={\"S\":0,\"C\":1,\"Q\":2}\nfor dataset in train_test_data:\n    dataset[\"Embarked\"]=dataset[\"Embarked\"].map(set_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  we have transformed all the values of the column \"Embarked\" with \"0\",\"1\" and \"2\"\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#to do some transformation on the \"Fare\" column to mprove the perfermance  of our model\n#full missing Fare with median Fare for each pclass\ndf[\"Fare\"].fillna(df.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"),inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Fare\" column we\n#will see its relation with the target \"Survived\"\n#(all the ages that are in the dataset)\n\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Fare\", shade=True)\nhtf.set(xlim=(1, df[\"Fare\"].max()))\nhtf.add_legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Fare\" column we\n#will see its relation with the target \"Survived\"\n#(\"Fare\"between 0 and 20)\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Fare\", shade=True)\nhtf.set(xlim=(1, df[\"Fare\"].max()))\nhtf.add_legend()\nplt.xlim(0,20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Fare\" column we\n#will see its relation with the target \"Survived\"\n#(\"Fare\"between 0 and 20)\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Fare\", shade=True)\nhtf.set(xlim=(1, df[\"Fare\"].max()))\nhtf.add_legend()\nplt.xlim(0,30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we have all the values of the \"Fare\" column we\n#will see its relation with the target \"Survived\"\n#(\"Fare\"between 0 and 20)\nhtf = sns.FacetGrid(df, hue=\"Survived\", aspect=2)\nhtf.map(sns.kdeplot, \"Fare\", shade=True)\nhtf.set(xlim=(1, df[\"Fare\"].max()))\nhtf.add_legend()\nplt.xlim(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# we notice the importance of the \"Fare\" feature on the \"Survived\" target\n# and that the price of the tiket has influenced the death rate in each class"},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will transform the numerical values into binary form\nfor dataset in train_test_data:\n    dataset.loc[dataset[\"Fare\"] <= 17,'Fare'] == 0\n    dataset.loc[dataset[\"Fare\"] > 17 & (dataset[\"Fare\"] <=30),'Fare'] == 1\n    dataset.loc[dataset[\"Fare\"] > 30 & (dataset[\"Fare\"] <=100),'Fare'] == 2\n    dataset.loc[dataset[\"Fare\"] > 100, 'Fare'] == 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to do some transformation on the \"SibSp\" column to mprove the perfermance  of our model\n#we will create new column \"FamilySize\"\nfor dataset in train_test_data:\n    dataset[\"Title\"]=dataset[\"Title\"].fillna(\"1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"FamilySize\"]=df[\"SibSp\"]+df[\"Parch\"]+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# according to the previous graph most people died the one who was all alone"},{"metadata":{},"cell_type":"markdown","source":"#  3.data preprosessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_drop=[\"PassengerId\",\"SibSp\",\"Parch\",\"Ticket\"]\ndf=df.drop(features_drop,axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['Survived']\nX = df.drop(['Survived'], axis=1)\nfrom sklearn.model_selection import train_test_split\nX_train, y_train,X_test, y_test = train_test_split(X,y, random_state=100, test_size=0.20, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y.shape\nX_train.shape\n#y_train.shape\n#X_test.shape\n#y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import make_column_transformer\ntransformer= make_column_transformer((StandardScaler(),[\"Fare\",\"Age\"]))\ntransformer.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1 = RandomForestClassifier(random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_2 = make_pipeline(PolynomialFeatures(2), SelectKBest(f_classif, k=10),\n                      RandomForestClassifier(random_state=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef evaluation(model):\n    \n    model.fit(X_train, y_train)\n    ypred = model.predict(X_test)\n    \n    print(confusion_matrix(y_test, ypred))\n    print(classification_report(y_test, ypred))\n    \n    N, train_score, val_score = learning_curve(model, X_train, y_train,\n                                              cv=4, scoring='f1',\n                                               train_sizes=np.linspace(0.1, 1, 10))\n    \n    \n    plt.figure(figsize=(12, 8))\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, val_score.mean(axis=1), label='validation score')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(model_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(model_1.feature_importances_, index=X_train.columns).plot.bar(figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation(model_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npreprocessor = make_pipeline(PolynomialFeatures(2, include_bias=False), SelectKBest(f_classif, k=10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nRandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\nAdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state=0))\nKNN = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndict_of_models = {'RandomForest': RandomForest,\n                  'AdaBoost' : AdaBoost,\n                  'SVM': SVM,\n                  'KNN': KNN\n                 }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in dict_of_models.items():\n    print(name)\n    evaluation(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n SVM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyper_params = {'svc__gamma':[1e-3, 1e-4, 0.0005],\n                'svc__C':[1, 10, 100, 1000, 3000], \n               'pipeline__polynomialfeatures__degree':[2, 3],\n               'pipeline__selectkbest__k': range(45, 60)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngrid = RandomizedSearchCV(SVM, hyper_params, scoring='recall', cv=4,\n                          n_iter=40)\n\ngrid.fit(X_train, Y_train)\n\nprint(grid.best_params_)\n\ny_pred = grid.predict(X_test)\n\nprint(classification_report(Y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nevaluation(grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import precision_recall_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprecision, recall, threshold = precision_recall_curve(Y_test, grid.best_estimator_.decision_function(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.plot(threshold, precision[:-1], label='precision')\nplt.plot(threshold, recall[:-1], label='recall')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef model_final(model, X, threshold=0):\n    return model.decision_function(X) > threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_pred = model_final(grid.best_estimator_, X_test, threshold=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nf1_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrecall_score(Y_test, y_pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}