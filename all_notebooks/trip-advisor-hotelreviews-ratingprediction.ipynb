{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Trip Advisor hotel review sentiments prediction and review rating prediction"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load all the required libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nsns.set_style('darkgrid')\n\nfrom wordcloud import WordCloud,STOPWORDS\nstopwords = list(STOPWORDS)\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score \nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer as CVTZ\n\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n\n\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\ndef RMSE(Y,YHAT):\n    return np.sqrt(mean_squared_error(Y,YHAT))\n\nplt.rc('figure',figsize=(20,11))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for null values\n\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef  clean_text(text):\n    \"\"\"\n    Fuction to clean the text data\n    * symbols\n    * change to lower_case\n    \"\"\"\n    text = text.str.lower()\n    text = text.apply(lambda T: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", T))  \n        \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Review']= clean_text(data['Review'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Review'] = data['Review'].str.replace('#','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Count of each rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Rating.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=data,x='Rating', palette=\"Set3\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Its clearly visible that the target variable(Rating) is not balanced, as we have huge difference in rating 1 and 5. So we will be using some sampling technique to balance these classes."},{"metadata":{},"cell_type":"markdown","source":"## Getting the number of words in each review"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Getting the number of words by splitting them by a space\nwords_per_review = [len(x.split(\" \")) for x in data['Review']]\nsns.distplot(words_per_review,fit=norm, kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wordcloud of most common words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def wordCloud_generator(data):\n    wordcloud = WordCloud(width = 800, height = 800,\n                          background_color ='black',\n                          min_font_size = 10,\n                          colormap='Pastel1'\n                         ).generate(\" \".join(data.values))\n    # plot the WordCloud image                        \n    plt.figure(figsize = (10, 10), facecolor = None) \n    plt.imshow(wordcloud, interpolation='bilinear') \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    plt.title(\"Most common words in Reviews\",fontsize=30)\n    plt.show() \n    \nwordCloud_generator(data['Review'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Now let us preprocess Reviews using some NLP tchniques like:\n1. converting to lowercase\n2. Removing Punctuation\n3. Removing stopwords\n4. Stemming\n5. Lemmatization"},{"metadata":{"trusted":true},"cell_type":"code","source":"punc=string.punctuation\n\nstop_words = set(stopwords.words('english'))\n\nstemmer = PorterStemmer()\n\nlemmatizer = WordNetLemmatizer()\n\ndef data_preprocessing(txt):\n    \n    #converting to lowercase\n    txt=txt.lower()\n    \n    #Removing Punctuation\n    txt=\"\".join([x for x in txt if x not in punc])\n    \n    #Removing stopwords\n    txt=\" \".join([word for word in str(txt).split() if word not in stop_words])\n    \n    #Stemming\n    txt = \" \".join([stemmer.stem(word) for word in txt.split()])\n    \n    #Lemmatization\n    txt = \" \".join([lemmatizer.lemmatize(word) for word in txt.split()])\n\n    return txt\n\ndata['text'] = data['Review'].apply(data_preprocessing)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorizing the input text"},{"metadata":{},"cell_type":"markdown","source":"Now we will vectorise the ratings using TF-IDF scores and we will use ```toarray()``` to convert resultant sparse matrix to dense matrix. "},{"metadata":{"trusted":true},"cell_type":"code","source":"### Creating a python object of the class TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidfconverter = TfidfVectorizer(max_features=400, min_df=0.05, max_df=0.9)\ntfidf = tfidfconverter.fit_transform(data['text']).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Divide into training and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(tfidf,data['Rating'],test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Upsampling using SMOTE\n"},{"metadata":{},"cell_type":"markdown","source":"Since our target variable is not balanced, we will use SMOTE algorithm to upsample the minority classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----Upsampling----\nfrom sklearn.utils import resample\nfrom collections import Counter\n\nprint(\"Before Upsampling:-\")\nprint(Counter(y_train))\n\n\n# Let's use SMOTE to oversample\nfrom imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX_train, y_train = oversample.fit_resample(X_train,y_train)\n\nprint(\"After Upsampling:-\")\nprint(Counter(y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model building"},{"metadata":{},"cell_type":"markdown","source":"### 1. Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training a Naive Bayes classifier \n#very fast\nfrom sklearn.naive_bayes import MultinomialNB\nmnb = MultinomialNB().fit(X_train, y_train) \n\ny_pred_NB=mnb.predict(X_test)\n\nprint(\"Accuracy of Multinominal Naive Balyes:\",accuracy_score(y_test, y_pred_NB))\nprint(classification_report(y_pred_NB,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression().fit(X_train, y_train)\n\ny_pred_lr=logreg.predict(X_test)\n\nprint(\"Accuracy of Logistic Regression:\",accuracy_score(y_test, y_pred_lr))\nprint(classification_report(y_pred_lr,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"des_tree = DecisionTreeClassifier().fit(X_train, y_train)\n\ny_pred_dt=des_tree.predict(X_test)\n\nprint(\"Accuracy of Decision Tree Classifier:\",accuracy_score(y_test, y_pred_dt))\nprint(classification_report(y_pred_dt,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier().fit(X_train, y_train)\n\ny_pred_rf=rf.predict(X_test)\n\nprint(\"Accuracy of Random Forest Classifier:\",accuracy_score(y_test, y_pred_rf))\nprint(classification_report(y_pred_rf,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"#takes huge amount of time to execute\nimport xgboost as xgb\n\nxgboost_clf = xgb.XGBClassifier().fit(X_train, y_train)\n\ny_pred_xgb=xgboost_clf.predict(X_test)\n\nprint(\"Accuracy of XGBoost Classifier:\",accuracy_score(y_test, y_pred_xgb))\nprint(classification_report(y_pred_xgb,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. k-Nearest Neighbours(KNN)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier \n\nknn = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)\n\ny_pred_knn=knn.predict(X_test)\n\nprint(\"Accuracy of k-nearest neighbours Classifier:\",accuracy_score(y_test, y_pred_knn))\nprint(classification_report(y_pred_knn,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7. Support Vector Machines(SVM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc = SVC()\n\ny_pred_svm=knn.predict(X_test)\n\nprint(\"Accuracy of SVM Classifier:\",accuracy_score(y_test, y_pred_svm))\nprint(classification_report(y_pred_svm,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Naive Bayes, Logistic Regression and Random forest are giving us maximum accuracy, In the next version I'll be fine tuning these algorithms using some hyperparameter optimization techniques and will use word embeddings like Word2Vec and Glove or even BERT to encode my input data."},{"metadata":{},"cell_type":"markdown","source":"### To be continued..."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}