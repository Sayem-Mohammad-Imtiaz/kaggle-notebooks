{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##################################################################################################################\n# Corona Virus India Network based on individualdetails.csv file from Kaggle Dataset on Novel Corona Virus Disease 2019 in India downloaded on 26 March 2020.\n# The aim of this notebook is to visualize Unique id and Contacts as a network.\n# Nodes represent Unique id or Contacts. \n# Edges represent the countries where the Unique id or Contacts have travelled.\n#####################################################################################################################\n\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n\n\n#Import Modules\nimport pandas as pd\nimport numpy as np\nimport re\nfrom time import strptime\nfrom datetime import datetime\nimport nltk\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom nltk import ne_chunk, pos_tag, word_tokenize\nfrom nltk.sem.relextract import extract_rels, rtuple\nnltk.download('maxent_ne_chunker')\nnltk.download('words')\nfrom nltk import word_tokenize, pos_tag, ne_chunk\nfrom nltk import Tree\nimport csv\nfrom operator import itemgetter\nimport networkx as nx\nfrom networkx.algorithms import community \nimport os\nimport folium\nfrom folium.plugins import FloatImage\nfrom folium.features import DivIcon\nimport geopy\nfrom  geopy.geocoders import Nominatim\nimport itertools\nfrom IPython.display import clear_output\nimport time\nimport plotly.express as px\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 1000)\n\n\ndef getRelBetnPersonLoc(x):\n    chunked = ne_chunk(pos_tag(word_tokenize(x)))\n    pat = re.compile('.*\\S.*')\n    rels = extract_rels('PER', 'GPE', chunked, corpus = 'ace', pattern = pat)\n    for rel in rels:\n        return(rtuple(rel))\n\n\ndef get_locations(text):\n    # Tokenize work, POS tag, and NER\n    tokenizeText  = word_tokenize(text)\n    posTagText = nltk.pos_tag(tokenizeText)\n    namedEnt1= nltk.ne_chunk(posTagText)\n    #namedEnt1.draw()\n    namedEnt2 = []\n    for i in namedEnt1:\n        if hasattr(i, 'label'):\n            NE_Name = ' '.join(x[0] for x in i.leaves())\n            NE_Type = i.label()\n            namedEnt2.append([NE_Name, NE_Type]) \n    #display(namedEnt2)\n    tmp = list(filter(lambda x:x[1]=='GPE',namedEnt2))\n    countries = []\n    for i in range(len(tmp)):\n        countries.append(tmp[i][0])\n    return countries \n\n\n#def fun1(x):\n    #return datetime.strptime(x, '%d/%b/%Y').date().strftime(\"%d-%m-%Y\")\n\ndef fun1(x):\n    return datetime.strptime(x, '%d-%b-%y').date().strftime(\"%d-%b-%Y\")\n\ndef fun2(x):\n    return datetime.strptime(x, '%m/%d/%Y').date().strftime(\"%d-%m-%Y\") \n\ndef fun3(x):\n    tmp = ''.join(map(str, x))\n    return tmp\n\ndef fun4(x):\n    tmp = re.findall(r'CP\\d+',x)\n    return (\", \".join(tmp))\n\n\n# Read data\ninput_data_chunk = pd.read_csv(\"/kaggle/input/covid19-india/individualdetails.csv\", chunksize=100, iterator=True, skipinitialspace=True, index_col=False)  \ninput_data = pd.concat(input_data_chunk, ignore_index=True)\ninput_data = input_data[['Unique id', 'Diagnosed date', 'Age', 'Gender', 'Detected state', 'Detected district', 'Nationality', 'Current status', 'Status change date', 'Notes', 'Contacts' ]]\ndisplay(\"Input data shape\", input_data.shape)\ndisplay(\"Input data head\", input_data.head())\n\n\n# Process data\ninput_data[['Unique id', 'Diagnosed date', 'Gender', 'Detected state', 'Detected district', 'Nationality', 'Current status', 'Status change date', 'Notes', 'Contacts']] = input_data[['Unique id', 'Diagnosed date', 'Gender', 'Detected state', 'Detected district', 'Nationality', 'Current status', 'Status change date', 'Notes',  'Contacts']].astype(str)\ninput_data[['Age']] = input_data[['Age']].apply(pd.to_numeric)\ninput_data = input_data.dropna(how='any')\ninput_data = input_data.drop(input_data[input_data.Contacts == 'nan'].index)\n\n\n\ninput_data['Diagnosed date'] = input_data['Diagnosed date'].apply(fun1)\ninput_data['Diagnosed date'] =  pd.to_datetime(input_data['Diagnosed date'], format=\"%d-%b-%Y\")\ndisplay(\"Input data head\", input_data.head())\n\n\n\n\n\ninput_data['Status change date'] = input_data['Status change date'].apply(fun2)\ninput_data['Status change date'] =  pd.to_datetime(input_data['Status change date'], format=\"%d-%m-%Y\")\n\ninput_data['DiagDate-StatusChDate'] = input_data['Status change date'] - input_data['Diagnosed date']\n\ninput_data['Contacts'] = input_data['Contacts'].str.replace('Patient ', 'CP') \n\n# Create separate columns for contacted patients using the Contacts column\ninput_data_expanded = input_data.join(input_data['Contacts'].str.split(',', expand=True).add_prefix('Contacts').fillna(np.nan))\ninput_data_expanded = input_data_expanded.drop('Contacts', 1)\n\ninput_data_expanded.rename(columns={'Unique id': 'PatientID'}, inplace=True)\ninput_data_expanded['PatientID'] = 'P' + input_data_expanded['PatientID'].astype(str)\n\ninput_data_expanded['travelledFrom'] = input_data_expanded['Notes'].apply(get_locations)\n\ninput_data_expanded['travelledFrom'] = input_data_expanded['travelledFrom'].apply(fun3)\ninput_data_expanded = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts0', 'Contacts1', 'Contacts2', 'Contacts3', 'Contacts4', 'Contacts5', 'Contacts6', 'Contacts7', 'Contacts8', 'Contacts9', 'Contacts10', 'Contacts11', 'Contacts12', 'Contacts13', 'Contacts14', 'Contacts15']]\n\n# Create edgelist for network\ntmp = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts0']]\n\ntmp1 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts1']]\ntmp1.columns = tmp.columns\ntmp1 = pd.concat([tmp, tmp1],  axis=0, ignore_index=True)\n\ntmp2 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts2']]\ntmp2.columns = tmp.columns\ntmp2 = pd.concat([tmp1, tmp2],  axis=0, ignore_index=True)\n\ntmp3 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts3']]\ntmp3.columns = tmp.columns\ntmp3 = pd.concat([tmp2, tmp3],  axis=0, ignore_index=True)\n\ntmp4 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts4']]\ntmp4.columns = tmp.columns\ntmp4 = pd.concat([tmp3, tmp4],  axis=0, ignore_index=True)\n\ntmp5 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts5']]\ntmp5.columns = tmp.columns\ntmp5 = pd.concat([tmp4, tmp5],  axis=0, ignore_index=True)\n\ntmp6 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts6']]\ntmp6.columns = tmp.columns\ntmp6 = pd.concat([tmp5, tmp6],  axis=0, ignore_index=True)\n\ntmp7 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts7']]\ntmp7.columns = tmp.columns\ntmp7 = pd.concat([tmp6, tmp7],  axis=0, ignore_index=True)\n\ntmp8 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts8']]\ntmp8.columns = tmp.columns\ntmp8 = pd.concat([tmp7, tmp8],  axis=0, ignore_index=True)\n\ntmp9 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts9']]\ntmp9.columns = tmp.columns\ntmp9 = pd.concat([tmp8, tmp9],  axis=0, ignore_index=True)\n\ntmp10 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts10']]\ntmp10.columns = tmp.columns\ntmp10 = pd.concat([tmp9, tmp10],  axis=0, ignore_index=True)\n\ntmp11 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts11']]\ntmp11.columns = tmp.columns\ntmp11 = pd.concat([tmp10, tmp11],  axis=0, ignore_index=True)\n\ntmp12 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts12']]\ntmp12.columns = tmp.columns\ntmp12 = pd.concat([tmp11, tmp12],  axis=0, ignore_index=True)\n\ntmp13 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts13']]\ntmp13.columns = tmp.columns\ntmp13 = pd.concat([tmp12, tmp13],  axis=0, ignore_index=True)\n\ntmp14 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts14']]\ntmp14.columns = tmp.columns\ntmp14 = pd.concat([tmp13, tmp14],  axis=0, ignore_index=True)\n\ntmp15 = input_data_expanded[['travelledFrom', 'PatientID', 'Contacts15']]\ntmp15.columns = tmp.columns\ntmp15 = pd.concat([tmp14, tmp15],  axis=0, ignore_index=True)\n\nedgelist = tmp15[pd.notnull(tmp15['Contacts0'])]\nedgelist = edgelist.replace(r'^\\s*$', 'NA', regex=True)\n\nedgelist = edgelist.groupby(['PatientID','Contacts0', 'travelledFrom']).size().reset_index(name='weight')\n\nedgelist['Contacts0'] = edgelist['Contacts0'].apply(fun4)\n\n#edgelist.loc[0, 'weight'] = 1\n\ndisplay(\"Processed data with edgelist of Patients and their Contact Patients\", edgelist.head())\n\n\n\n# Plot network of patients and their contacts\nplt.figure(figsize=(15,15)) \nG = nx.Graph()\nG = nx.from_pandas_edgelist(edgelist, 'PatientID', 'Contacts0', edge_attr = True)\n\n# Get information about the network nodes\n#list(G.edges)\n#list(G.nodes)\n#list(G.adj['P6'])\n#G.degree['P6'] \ndegree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n# print top 10 patients/contact patients and their degrees\ntmp = [(n, d) for n, d in G.degree()]\ndisplay(\"Top 10 patients/contact patients and their degrees\", sorted(tmp, key=lambda element: (element[1], element[0]), reverse=True)[:11])\n\nPatientIDs = list(edgelist.PatientID.unique())\ncontacts = list(edgelist.Contacts0.unique())\n\n#layout = nx.spring_layout(G)\n#layout = nx.kamada_kawai_layout(G)\nlayout = nx.fruchterman_reingold_layout(G,\n                                        k=.5,\n                                        pos=None,\n                                        fixed=None,\n                                        iterations=100,\n                                        #threshold=1e-4,\n                                        weight='weight',\n                                        scale=1,\n                                        center=None,\n                                        dim=2,\n                                        seed=None)\nnx.draw_networkx_edges(G, pos=layout, edge_color='#ABABAB')\n\nPatientIDs = [node for node in G.nodes() if node in edgelist.PatientID.unique()]\nsize = [G.degree(node) * 70 for node in G.nodes() if node in edgelist.PatientID.unique()]\nnx.draw_networkx_nodes(G, pos=layout, nodelist=PatientIDs, node_size=size, node_color='lightblue')\n\ncontacts = [node for node in G.nodes() if node in edgelist.Contacts0.unique()]\nnx.draw_networkx_nodes(G, pos=layout, nodelist=contacts, node_size=10, node_color='#ABABAB')\n\nhigh_degree_Patient0 = [node for node in G.nodes() if node in edgelist.Contacts0.unique() and G.degree(node) > 1]\nnx.draw_networkx_nodes(G, pos=layout, nodelist=high_degree_Patient0, node_size=10, node_color='#ac5d36')\n\n\nPatientIDs_dict = dict(zip(PatientIDs, PatientIDs))\nnx.draw_networkx_labels(G, pos=layout, labels=PatientIDs_dict)\ncontactsIDs_dict = dict(zip(contacts, contacts))\nnx.draw_networkx_labels(G, pos=layout, labels=contactsIDs_dict)\n\nedges = G.edges()\nweights = [G[u][v]['weight'] for u,v in edges]\n\nnx.draw(G, pos=layout, edges=edges, width=weights)\n\nedgeLabels = {}  \nfor a, b in G.edges():\n    edgeLabels[(a, b)] = str(G.get_edge_data(a, b, {\"travelledFrom\":0})[\"travelledFrom\"])\n\nnx.draw_networkx_edge_labels(G, pos=layout, edge_labels=edgeLabels, font_color='black', alpha=.7) \n\nnx.draw_networkx_nodes(G, nodelist=PatientIDs, pos=layout, node_color='lightblue', label='P-Patient')\nnx.draw_networkx_nodes(G, nodelist=contacts, pos=layout, node_color='#ABABAB', label='CP-Contact with a Patient')\nnx.draw_networkx_nodes(G, nodelist=high_degree_Patient0, pos=layout, node_color='#ac5d36', label='CP-Contact With More Than 1 Patient')\nplt.legend(numpoints = 1)\n\n\nplt.axis('off')\nplt.title(\"Corona Virus India Network based on individualdetails.csv file as on 26 March 2020\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################################################################\n############### Plot Covid19 India initial day cases on map with time.sleep() ################\n############################################################################\n\ninput_data_animation = input_data[['Diagnosed date','Detected district']]\ninput_data_animation['DetectedCountry']='India'\ninput_data_animation_grpby = input_data_animation.groupby(['Diagnosed date', 'Detected district', 'DetectedCountry'])['Diagnosed date'].agg(['count']).reset_index().rename(columns={\"count\":\"CountOfPerson\"})\ndisplay(\"Input data shape\", input_data_animation_grpby.shape)\n\n\ndef createLat(city):\n    geolocator = Nominatim()\n    country = 'India'\n    loc = geolocator.geocode(city+','+ country, timeout=10)\n    lat = loc.latitude\n    #lon = loc.longitude\n    return lat\ninput_data_animation_grpby['Lat'] =  input_data_animation_grpby['Detected district'].head(20).apply(createLat)\n\ndef createLon(city):\n    geolocator = Nominatim()\n    country = 'India'\n    loc = geolocator.geocode(city+','+ country, timeout=10)\n    #lat = loc.latitude\n    lon = loc.longitude\n    return lon\ninput_data_animation_grpby['Lon'] =  input_data_animation_grpby['Detected district'].head(20).apply(createLon)\n\ninput_data_animation_grpby = input_data_animation_grpby.head(20)\n\nsep = ['-'] * len(input_data_animation_grpby)\nlist_of_day = pd.DatetimeIndex(input_data_animation_grpby['Diagnosed date']).day.tolist()\nlist_of_day = [str(i) for i in list_of_day]\nlist_of_month = pd.DatetimeIndex(input_data_animation_grpby['Diagnosed date']).month.tolist()\nlist_of_month = [str(i) for i in list_of_month]\nlist_of_year = pd.DatetimeIndex(input_data_animation_grpby['Diagnosed date']).year.tolist()\nlist_of_year = [str(i) for i in list_of_year]\nday_month_year = [i + j + k + l + m for i, j, k, l, m in zip(list_of_day, sep, list_of_month, sep, list_of_year )] \n\n\nfor i in range(0, len(day_month_year)): \n    text = day_month_year[i]\n    m = folium.Map(location=[input_data_animation_grpby['Lat'][i], input_data_animation_grpby['Lon'][i]],  zoom_start=4)\n    folium.Circle([input_data_animation_grpby['Lat'][i], input_data_animation_grpby['Lon'][i]], 150000, fill=True).add_child(folium.Popup(text)).add_to(m)\n    folium.map.Marker([input_data_animation_grpby['Lat'][i] + 0.5, input_data_animation_grpby['Lon'][i] - 1.6], icon=DivIcon(icon_size=(150,36), icon_anchor=(0,0), html='<div style=\"font-size: 24pt\">%s</div>' % text,)).add_to(m)\n    loc = [(input_data_animation_grpby['Lat'][i]-.3, input_data_animation_grpby['Lon'][i]-.3), (input_data_animation_grpby['Lat'][i]-.3, input_data_animation_grpby['Lon'][i]+.3), (input_data_animation_grpby['Lat'][i]+.3, input_data_animation_grpby['Lon'][i]), (input_data_animation_grpby['Lat'][i]-.3, input_data_animation_grpby['Lon'][i]-.3)]\n    folium.PolyLine(loc, color='red',  dash_array='1').add_to(m)\n    clear_output(wait = True)\n    time.sleep(1)\n    display(m)\n    #m.save('fig.html')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Covid19 India initial day cases on map\n# All points plotted without animation\n\nm = folium.Map(location=[input_data_animation_grpby['Lat'][1], input_data_animation_grpby['Lon'][1]],  zoom_start=4)\nfor i in range(0, len(day_month_year)): \n    text = day_month_year[i]\n    folium.CircleMarker(location=[input_data_animation_grpby['Lat'][i], input_data_animation_grpby['Lon'][i]],\n                        radius=5,\n                        color='red',\n                        popup =('District: ' + input_data_animation_grpby['Detected district'][i] + day_month_year[i] + '<br>'),\n                        fill_color='red',\n                        fill_opacity=0.7 ).add_to(m)\n\nm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# India initial days Covid cases animation\n\nfig = px.scatter_mapbox(input_data_animation_grpby, lat=\"Lat\", lon=\"Lon\",\n                     size='CountOfPerson',hover_data=['Detected district'],\n                     color_continuous_scale='burgyl', animation_frame=input_data_animation_grpby[\"Diagnosed date\"].astype(str), \n                     title='Initial days Corona spread in India')\nfig.update(layout_coloraxis_showscale=True)\nfig.update_layout(mapbox_style=\"carto-positron\", mapbox_zoom=4, mapbox_center = {\"lat\":20.5937,\"lon\":78.9629})\nfig.update_layout(margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}