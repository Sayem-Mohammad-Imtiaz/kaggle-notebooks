{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This is the `Python` version of the notebook. For the `R` version, click [here](https://www.kaggle.com/ryanthomasallen/online-appendix-for-cae-2020-r)\n\nThis notebook is provided as supplementary material to the paper [Machine Learning for Pattern Discovery in Management Research](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3518780) by Prithwiraj Choudhury, Ryan Allen, and Michael Endres (Strategic Management Journal, 2020).\n\nWe assume users of this notebook are familiar with the paper, which lays out fundamental concepts of machine learning and the empirical setting. We also assume familiarity with Python, including the `pandas` and `scikit-learn` packages.\n\nIn order to preserve the anonymity of TECHCO and its employees, this notebook uses simulated data based on the real data used in the paper. The results in this notebook do not exactly match the results in the paper, but yield qualitatively similar findings.","execution_count":null},{"metadata":{"_uuid":"2152f21286f049467cba6e151f537ba1784e3ff1"},"cell_type":"markdown","source":"# 1. Import Libraries and Data","execution_count":null},{"metadata":{"trusted":true,"_uuid":"3b4a61bb85b05cf90c9c3ebacb1c0e6f77471d8a"},"cell_type":"code","source":"# NUMPY / PANDAS\nimport numpy as np\nimport pandas as pd\n\n# SCI-KIT LEARN\nimport sklearn\nfrom sklearn.model_selection import (GroupKFold, GroupShuffleSplit, cross_validate, \n                                       RandomizedSearchCV,GridSearchCV)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nimport sklearn.tree as tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler,OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.metrics import log_loss, roc_curve, auc\n\n#PDPbox\nfrom pdpbox import pdp\n\n# MATPLOTLIB\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# OTHER\nfrom itertools import product\nimport copy\nimport graphviz\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0154b043c8d5e8aab2302a75228f1430ce95830b"},"cell_type":"markdown","source":"Import data.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"06c8bd39b96e0f6120fe0a3fb3224e3e6be47899"},"cell_type":"code","source":"df = pd.read_csv(\"../input/simulated-data-for-ml-paper/simulated_TECHCO_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a4ad1d23b781488b1aa2555ac3f965e7636425a"},"cell_type":"markdown","source":"# 2. Preprocess and Partition Data","execution_count":null},{"metadata":{"_uuid":"1ab1df125e92fef1924b1d08ac13183257ba0981"},"cell_type":"markdown","source":"Convert variables to appropriate data types","execution_count":null},{"metadata":{"trusted":true,"_uuid":"4ed360064cf97c71b8da3586c1eeb750071ffb80"},"cell_type":"code","source":"df.time = df.time.astype(int)\ndf.is_male = df.is_male.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abcab0996e43fd68d0332a4e0eb4ac30a1d588d9"},"cell_type":"markdown","source":"Set index as `emp_id` and `time`","execution_count":null},{"metadata":{"trusted":true,"_uuid":"8fa8b7921be30c8f4d380c0956e90b5110afee94"},"cell_type":"code","source":"df.set_index(['emp_id','time'],drop=False,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9284976c974ec3fd1a82180ed95b02e047a84569"},"cell_type":"markdown","source":"Define the target, y as `turnover`. Set \"Left\" as the positive label.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"5d6d74b0cc2f91715ea4339f45d5eab8daab9b10"},"cell_type":"code","source":"df.loc[df['turnover']=='Stayed', 'turnover'] = '0 Stayed'\ndf.loc[df['turnover']=='Left', 'turnover'] = '1 Left'\ndf.turnover\ny = df.turnover","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8d3ae2be36ab59c5447049b677a07996ab34b0b"},"cell_type":"markdown","source":"Create `X`, the matrix of variables. Also use the list `cols` to set a consistent ordering of columns","execution_count":null},{"metadata":{"trusted":true,"_uuid":"c3d35de95c07527388c25f3975dd3cd423fa7641"},"cell_type":"code","source":"X = df.drop(['turnover'],axis=1)\ncols = [\"time\",\"training_score\",\"avg_literacy\",\"is_male\",\"logical_score\",\"verbal_score\",\"location_age\",\"distance\",\"similar_language\"]\nX = X[cols]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac0063f14951f279fe932266a482b92e9370946b"},"cell_type":"markdown","source":"Split to get indices for training/cross-validation and holdout test sets. We are using panel data (indices of `emp_id` and `time`) so we sample at the employee level rather than the observation level. If you are just sampling at the observation level, the code for this operation would be `GroupShuffleSplit(test_size=.3)` ","execution_count":null},{"metadata":{"trusted":true,"_uuid":"6a07ef6439bf08c454c62b50acf7bd9eeef6d689"},"cell_type":"code","source":"train_inds, test_inds = next(GroupShuffleSplit(test_size=.3,random_state=111).split(X,y,groups=df.emp_id))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fac022c28b0dfa9710ba42538b80e81b143df139"},"cell_type":"markdown","source":"Create training and test sets for `X`, `y`, and employee groupings","execution_count":null},{"metadata":{"trusted":true,"_uuid":"ca0f4f37070c502ed94126a7288d747f0ed95cab"},"cell_type":"code","source":"X_train, X_test = X.iloc[train_inds], X.iloc[test_inds]\ny_train, y_test = y.iloc[train_inds], y.iloc[test_inds]\nemployee_train = df.emp_id.iloc[train_inds]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"352bc60f412cf355c8558873297a4840da67cc2a"},"cell_type":"markdown","source":"Define `folds`: a list of partitions in the data which will be used for cross-validation. Because we are using panel data where each employee has multiple observations, we sample at the employee level, not at the observation level. We use the function `GroupKFold` to split the data into folds grouped at the employee level. ","execution_count":null},{"metadata":{"trusted":true,"_uuid":"5bea0ffea6c619efd1df344cd0ca0ecdae4197b7"},"cell_type":"code","source":"folds = list(GroupKFold(n_splits=10).split(X_train,y_train,employee_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check Correlations. We should be aware that some algorithms may randomly substitute highly related variables for one another.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_not_panel = X_train[X_train.time==1].drop(columns=\"time\")\nX_train_not_panel.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(X_train_not_panel,figsize=(16,12),alpha=0.3);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Define Custom Visualization Functions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This section defines the custom visualization functions for partial dependence plots and ROC curves that we used in the paper. You can also use off-the-shelf packages, such as the `pdpbox` package.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Function for Plotting the ROC Curve\n![](http://)![](http://)`plot_roc()` takes predictions (`y_predictions`), ground truth (`y_true`), and the name of the model (`name`) as arguments. It returns a plot of an ROC curve.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc(y_predictions,y_true,name,pos_label):\n    fpr,tpr,thresholds = roc_curve(y_true,y_predictions,pos_label=pos_label)\n    roc_auc = auc(fpr, tpr)\n    plt.title(name)\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.4f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One-way Partial Dependence Plot Function with overlaid Individual Conditional Expectation (ICE) Plot \n`pdplot()` takes a dataframe (`X`), the estimator (`model`), the name of the variable to plot (`var_name`), and the number of desired samples to plot (`n`). It returns a partial dependence plot, which plots how the model predicts each sampled observation's predicted probability of turnover over the range of possible values of the plotted variable. It also includes `n` individual ICE lines.  Note the argument `which_class`, which tells the function to predict probabilities for a specific class label (in our case, \"Left\").\n  \n**For the off-the-shelf function for plotting partial dependence and ICE plots, use the `pdp_plot()` function from `pdpbox` package.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def pdplot(X, model, n, var_name,categorical_var=False,which_class = 1):        \n    X_copy = copy.deepcopy(X)\n    #For the continuous variables that will be plotted, create 40-interval arrays.\n    if categorical_var == False:\n        var_grid_vals = np.linspace(X_copy[var_name].min(), X_copy[var_name].max(), num=40)\n    #For the categorical variables that will be plotted, create array of the unique values\n    if categorical_var == True:\n        var_grid_vals = list(set(X_copy[var_name]))\n    \n    samples=np.random.choice(len(X_copy), n, replace=False)\n    \n    predictions = pd.DataFrame()\n      \n    f=plt.figure()\n    \n    for sample in samples:\n        x_vals = list()\n        for i in var_grid_vals:\n            X_copy[var_name]=i\n            y_hat=model.predict_proba(X_copy.iloc[(sample-1):sample])[:,which_class][0]\n            y_hat_log_odds = np.log(y_hat/(1-y_hat))\n            predictions=predictions.append({'sample':sample,'x_val':i,'pred':y_hat_log_odds},ignore_index=True)\n        sample_preds = predictions[predictions['sample']==sample]\n        plt.plot(sample_preds.x_val, sample_preds.pred, c='C1', alpha=1.0, linewidth=0.1)\n        \n    preds_grouped = predictions.groupby(['x_val']).mean().reset_index()\n    plt.plot(preds_grouped.x_val, preds_grouped.pred, c='C0', linestyle='--')\n    plt.ylabel(r'Log Odds of Turnover Probability (log $\\frac{h_\\theta(x)}{1-h_\\theta(x)}$)')\n    plt.xlabel(var_name)\n    plt.ylim(-8,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Two-way Partial Dependence Plot function\n`plot_twoway_pdp()` takes a dataframe (`X`), the estimator (`model`), the name of the variable to plot on the x-axis (`var1_name`), and the name of the variable to plot on the y-axis (`var2_name`). The function returns a two-way PDP, which displays the model's predicted probability of turnover for each point across the range of 40 values for two variables (40\\*40 = 1600 points total).    \n  \nThe argument `which_class` tells the function to predict probabilities for a specific class label (in our case, \"Left\").\n  \n**For an off-the-shelf function for plotting two way partial dependence use the `pdp_interact_plot()` function from `pdpbox` package.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_twoway_pdp(X,model,var1_name,var2_name,categorical_var1=False,categorical_var2=False,\n                 var1_min=None,var1_max=None,\n                 var2_min=None,var2_max=None,\n                 which_class = 1):\n    #Set the min and max value to plot for both variables. Default is the min and max of the variable\n    if var1_min is None:\n        var1_min=X[var1_name].min() \n    if var1_max is None:\n        var1_max=X[var1_name].max() \n    if var2_min is None:\n        var2_min=X[var2_name].min()\n    if var2_max is None:\n        var2_max=X[var2_name].max() \n        \n    X_copy = copy.deepcopy(X)\n    \n    #For the continuous variables that will be plotted, create 40-interval arrays.\n    if categorical_var1 == False:\n        var1_grid_vals = np.linspace(var1_min, var1_max, num=40)\n    if categorical_var2 == False:\n        var2_grid_vals = np.linspace(var2_min, var2_max, num=40)\n        \n    #For the categorical variables that will be plotted, create array of the unique values\n    if categorical_var1 == True:\n        var1_grid_vals = list(set(X_copy[var1_name]))\n    if categorical_var2 == True:\n        var2_grid_vals = list(set(X_copy[var2_name]))\n    \n    predictions_from_grid = list()\n    x_vals = list()\n    y_vals =list()\n    \n    for i in var1_grid_vals:\n        for j in var2_grid_vals:\n            X_copy[var1_name]=i\n            X_copy[var2_name]=j\n            y_hats = model.predict_proba(X_copy)[:,which_class]\n            predictions_from_grid.append(np.mean(y_hats))   \n            x_vals.append(i)\n            y_vals.append(j)\n\n    plt.figure()\n    plt.scatter(x_vals,y_vals,c=np.log(predictions_from_grid),marker='s',vmin=-8,vmax=-1)\n    plt.xlabel(var1_name)\n    plt.ylabel(var2_name)\n    cbar = plt.colorbar(ticks=range(-8,0))\n    cbar.ax.set_yticklabels(['$10^{'+str(i)+'}$' for i in range(-8,0) ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Algorithm Implementation and Results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Using `RandomizedSearchCV` we can try many hyperparameter combinations. We make a dictionary (which we call `random_grid`) of different hyperparameter values that we want the algorithm to try.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make a dictionary of combinations of hyperparameters to try\nrandom_grid = {'criterion': ['entropy','gini'],\n               'max_depth': np.unique( np.exp(np.linspace(0, 10, 100)).astype(int) ),\n               'min_samples_leaf': np.unique( np.exp(np.linspace(0, 8, 100)).astype(int) ),\n               'min_impurity_decrease': np.exp(np.linspace(-9, -1, 100))}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`RandomizedSearchCV` randomly tries different combinations of Decision Tree hyperparameters from the `random_grid` dictionary. We tell it to try 100 different combinations (`n_iter=100`), to use the `neg_log_loss` score to evaluate each model's performance, and to use `cv=folds` for cross-validation (if we were simply sampling at the observation level rather than at the employee level, we could just set `cv=10`).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_random_search = RandomizedSearchCV(estimator = DecisionTreeClassifier(), \n                                      param_distributions = random_grid,\n                                      random_state=345, n_iter = 100,\n                                      scoring='neg_log_loss',n_jobs=-1,\n                                      cv =folds,return_train_score=True)\ndt_random_search.fit(X=X_train,y=y_train)\ndt_random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could keep tuning, but for simplicity we stop here to set the model using the hyperparameters that returned the best results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=dt_random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save the cross-validation scores and standard deviations (will plot later)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_index = dt_random_search.best_index_\ndt_train_score = dt_random_search.cv_results_['mean_train_score'][best_model_index]\ndt_validation_score = dt_random_search.cv_results_['mean_test_score'][best_model_index]\ndt_train_std = dt_random_search.cv_results_['std_train_score'][best_model_index]\ndt_validation_std = dt_random_search.cv_results_['std_test_score'][best_model_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the best model to make predictions on the holdout test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"decisiontree_test_pred = dt.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluate the holdout test loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss_dt = log_loss(y_test.values,decisiontree_test_pred)\nprint(\"Test Loss: %0.4f\" % test_loss_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree = graphviz.Source( tree.export_graphviz(dt, out_file=None, feature_names=X_train.columns, filled=False, rounded=True,impurity=True))\ndecision_tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: ROC Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(decisiontree_test_pred,y_test,\"Decision Tree ROC Curve\",pos_label=\"1 Left\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Variable Importance (Feature Importance)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = dt.feature_importances_\n\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(X.shape[1]), importances,\n       color=\"b\", align=\"center\")\nplt.xticks(range(X.shape[1]), cols,rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pdplot(X=X_train,var_name='time',n=500,model=dt,which_class = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Two-way Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_twoway_pdp(X=X_train, model=dt,\n             var1_name='time',var2_name='training_score',\n             var2_min=2.5,which_class=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Using `RandomizedSearchCV` we try many hyperparameter combinations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make a dictionary of which combinations of hyperparameters to try\nrandom_grid = {'criterion': ['entropy'],\n               'max_depth': np.unique( np.exp(np.linspace(0, 10, 100)).astype(int) ),\n               'min_samples_leaf': np.unique( np.exp(np.linspace(0, 8, 100)).astype(int) ),\n               'max_features': [None,'auto','log2'],\n               'min_impurity_decrease': np.exp(np.linspace(-9, -1, 100))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random_search = RandomizedSearchCV(estimator = RandomForestClassifier(n_estimators=100), \n                                      param_distributions = random_grid,\n                                      random_state=345, n_iter = 100,\n                                      scoring='neg_log_loss',n_jobs=-1,\n                                      cv =folds,return_train_score=True)\nrf_random_search.fit(X=X_train,y=y_train)\nrf_random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We set the model using the parameters that returned the best results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = rf_random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the cross validation scores (these will be plotted at the end)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model_index = rf_random_search.best_index_\nrf_train_score = rf_random_search.cv_results_['mean_train_score'][best_model_index]\nrf_validation_score = rf_random_search.cv_results_['mean_test_score'][best_model_index]\nrf_train_std = rf_random_search.cv_results_['std_train_score'][best_model_index]\nrf_validation_std = rf_random_search.cv_results_['std_test_score'][best_model_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions on the holdout test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"randomforest_test_pred = rf.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluate the test loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss_rf = log_loss(y_test.values,randomforest_test_pred)\nprint(\"Test Loss: %0.4f\" % test_loss_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: ROC Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(randomforest_test_pred,y_test,\"Random Forest ROC Curve\",pos_label=\"1 Left\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Variable Importance (Feature Importance)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf.feature_importances_\n\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(X.shape[1]), importances,\n       color=\"b\", align=\"center\")\nplt.xticks(range(X.shape[1]), cols,rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pdplot(X=X_train,var_name='time',n=500,model=rf,which_class = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Two-way Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_twoway_pdp(X=X_train, model=rf,\n             var1_name='time',var2_name='training_score',\n             var2_min=2.5,which_class=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Neural Network","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Neural networks perform better with standardized variable scaling. In cross-validation, variables should be rescaled using the training set within each fold, so rather than scaling the data before cross-validation, we add scaling as a pre-step to fitting the model in a pipeline using the `make_pipeline` function. Now when we fit the model using the pipeline, it will first standardize the variables using `scaler` before fitting the model `nnet`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nnet = MLPClassifier(random_state=345,max_iter=100)\nscaler = StandardScaler()\nnnet_pipeline = make_pipeline(scaler,nnet)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using `RandomizedSearchCV` we can try many hyperparameter combinations and select the best performing combination. When using a pipeline, we have to specify to which step the hyperparameters belong. For example rather than writing `'hidden_layer_sizes'` we write `'mlpclassifier__hidden_layer_sizes'` to denote that hidden layer size parameter belongs to the classifier and not the scaler.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make a dictionary of which combinations of hyperparameters to try\nrandom_grid = {'mlpclassifier__solver': ['adam'],\n               'mlpclassifier__activation': ['tanh','relu','logistic'],\n               'mlpclassifier__alpha': [0.01,0.05],\n               'mlpclassifier__hidden_layer_sizes': [(30,20,10),(20,20),(25,15),(10,40,10),(20,20,20),(30,10)]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Commented out for speed\n# nnet_random_search = RandomizedSearchCV(estimator = nnet_pipeline, \n#                                       param_distributions = random_grid, n_iter = 25,\n#                                       #random_state=345, \n#                                       scoring='neg_log_loss',n_jobs=-1,\n#                                       cv =folds,return_train_score=True)\n# nnet_random_search.fit(X=X_train,y=y_train)\n# nnet_random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the model which returned the best results (slightly modified the hidden layer sizes from (30,10) to (32,12))","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nnet = MLPClassifier(solver='adam', \n                     activation='tanh',\n                     alpha=1e-2, \n                     hidden_layer_sizes=(32,12), \n                     random_state=345)\nnnet_pipeline = make_pipeline(scaler,nnet)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the cross validation scores (these will be plotted at the end)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results_nnet = cross_validate(\n    estimator=nnet_pipeline,\n    X=X_train,\n    y=y_train,\n    cv=folds,\n    scoring='neg_log_loss',\n    return_train_score=True\n)\ncv_val_score_nnet = -cv_results_nnet['test_score'].mean()\n\nprint(\"Mean cross-validation score (log loss) for neural network model: %0.4f\" % cv_val_score_nnet)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions on the holdout test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nnet_pipeline.fit(X_train,y_train)\nnnet_test_pred = nnet_pipeline.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluate the test loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss_nnet = log_loss(y_test.values,nnet_test_pred)\nprint(\"Test Loss: %0.4f\" % test_loss_nnet)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: ROC Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(nnet_test_pred,y_test,\"Neural Network ROC Curve\",pos_label=\"1 Left\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Variable Importance (Feature Importance)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Neural networks don't have an intrinsic variable importance like decision trees and random forests. However, if you want an interpretation of variable importance for neural nets, there are alternative packages that can help (e.g. the`LIME` package)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pdplot(X=X_train,var_name='time',n=500,model=nnet_pipeline,which_class = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Two-way Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_twoway_pdp(X=X_train, model=nnet_pipeline,\n             var1_name='time',var2_name='training_score',\n             var2_min=2.5,which_class=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In our logistic regression we include time fixed effects. So we add a preprocessing step that uses `OneHotEncoder()` to transform `time` into a dummy variable for each month.\n  \nThe default for `sklearn.linear_model.LogisticRegression` is to include the L2 regularization term, and it isn't possible to entirely exclude a regularization term. To replicate a traditional logistic regression model with no regularization (like logit in Stata), set the parameter `C` to a very high number to make the strength of the L2 regularization term essentially zero (smaller values of `C` specify stronger regularization).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess = make_column_transformer(\n    (OneHotEncoder(), [\"time\"]),\nremainder=\"passthrough\")\n\nlogistic = LogisticRegression(C=1e8)\n\nlogistic_pipeline = make_pipeline(\n    preprocess,\n    logistic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the cross validation scores (these will be plotted at the end)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results_logistic = cross_validate(\n    estimator=logistic_pipeline,\n    X=X_train,\n    y=y_train,\n    cv=folds,\n    scoring='neg_log_loss',\n    return_train_score=True\n)\ncv_val_score_logistic = -cv_results_logistic['test_score'].mean()\n\nprint(\"Mean cross-validation score (log loss) for logistic model: %0.4f\" % cv_val_score_logistic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the model using the training data, and use it to make predictions on the holdout test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_pipeline.fit(X_train,y_train)\nlogistic_test_pred = logistic_pipeline.predict_proba(X_test)[:,1]\n\nprint(\"Test Loss: %0.4f\" % log_loss(y_test.values,logistic_test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualizations","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: ROC Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(logistic_test_pred,y_test,\"Logistic ROC Curve\",pos_label=\"1 Left\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Note since the variable time is categorical in our logistic_pipeline model, we set categorical_var=True in the pdplot function\npdplot(X=X_train,var_name='time',categorical_var=True,n=500,model=logistic_pipeline)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Visualizations: Two-way Partial Dependence Plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Note since the variable time is categorical in our logistic_pipeline model, we set categorical_var1=True in the plot_twoway_pdp function\nplot_twoway_pdp(X=X_train, model=logistic_pipeline,\n             var1_name='time',var2_name='training_score',categorical_var1=True,\n             var2_min=2.5,which_class=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plots that compare training to test loss for all the models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Plot the cross validation loss for the training and holdout test set on the x and y axis, respectively. Error bars represent standard deviation variance yielded by the k-folds cross-validation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[-dt_train_score,-rf_train_score,-cv_results_nnet['train_score'].mean(),-cv_results_logistic['train_score'].mean()]\nx_err=[dt_train_std,rf_train_std,np.std(cv_results_nnet['train_score']),np.std(cv_results_logistic['train_score'])]\ny=[-dt_validation_score,-rf_validation_score,-cv_results_nnet['test_score'].mean(),-cv_results_logistic['test_score'].mean()]\ny_err=[dt_validation_std,rf_validation_std,np.std(cv_results_nnet['test_score']),np.std(cv_results_logistic['test_score'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([-1,1],[-1,1], c='k', marker='None',linestyle='--',label='_nolegend_')\nfor ax, ax_err, ay, ay_err in zip(x, x_err, y, y_err):\n    plt.errorbar(ax, ay, xerr=ax_err, yerr=ay_err, label='Training',marker='o', linestyle='None')\nplt.xlim(0.06,0.07625)\nplt.ylim(0.06,0.07625)\nplt.xlabel('Training Loss')\nplt.ylabel('Validation Loss')\nplt.legend(['Decision Tree','Random Forest','Neural Network','Logistic Regression'], loc=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now plot the cross validation loss *relative to the logistic regression model* for the training and holdout test set on the x and y axis, respectively. Error bars represent standard deviation variance yielded by the k-folds cross-validation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[-(dt_train_score-cv_results_logistic['train_score'].mean()),-(rf_train_score-cv_results_logistic['train_score'].mean()),-(cv_results_nnet['train_score'].mean()-cv_results_logistic['train_score'].mean()),0]\nx_err=[np.std(dt_train_std-cv_results_logistic['train_score']),np.std(rf_train_std-cv_results_logistic['train_score']),np.std(cv_results_nnet['train_score']-cv_results_logistic['train_score']),0]\ny=[-(dt_validation_score-cv_results_logistic['test_score'].mean()),-(rf_validation_score-cv_results_logistic['test_score'].mean()),-(cv_results_nnet['test_score'].mean()-cv_results_logistic['test_score'].mean()),0]\ny_err=[np.std(dt_validation_std-cv_results_logistic['test_score']),np.std(rf_validation_std-cv_results_logistic['test_score']),np.std(cv_results_nnet['test_score']-cv_results_logistic['test_score']),0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot([-1,1],[-1,1], c='k', marker='None',linestyle='--',label='_nolegend_')\nfor ax, ax_err, ay, ay_err in zip(x, x_err, y, y_err):\n    plt.errorbar(ax, ay, xerr=ax_err, yerr=ay_err, label='Training',marker='o', linestyle='None')\nplt.xlim(-0.010,0.002)\nplt.ylim(-0.0082,0.0025)\nplt.xlabel('Training Loss (Relative to Logistic)')\nplt.ylabel('Validation Loss (Relative to Logistic)')\nplt.legend(['Decision Tree','Random Forest','Neural Network','Logistic Regression'], loc=4)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}