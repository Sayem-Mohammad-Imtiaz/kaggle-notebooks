{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q aitextgen\nfrom aitextgen import aitextgen\nimport pandas as pd\nfrom aitextgen.TokenDataset import TokenDataset\nimport json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Trent p책 total Arxiv**","metadata":{}},{"cell_type":"code","source":"def get_clean_authors(authors):\n    r = []\n    for a in authors:\n        r.append(\" \".join(a).strip())\n    return r\n\narticles = []\ncategory = 'nucl-ex'\nwith open(\"../input/arxiv/arxiv-metadata-oai-snapshot.json\", \"r\") as f:\n    for i,l in enumerate(f):\n        #if i%100000==0:\n            #print(i)\n        d = json.loads(l)\n        if category in d['categories'].split(' '):\n            d['clean_authors'] = get_clean_authors(d['authors_parsed']) \n            articles.append(d)\n\narticles_df = pd.DataFrame().from_records(articles)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install pylatexenc -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pylatexenc.latex2text import LatexNodes2Text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LatexNodes2Text().latex_to_text(articles_df['abstract'][2]).replace('\\n', ' ').strip()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# LaTex to UTF\nclean_abstract = []\nclean_title = []\nfor i,a in articles_df.iterrows():\n    if i%100==0:\n            print(i)\n            \n    # Clean abstract\n    try:\n        clean_abstract.append(LatexNodes2Text().latex_to_text(a['abstract']).replace('\\n', ' ').strip()) \n    except:\n        clean_abstract.append(a['abstract'].replace('\\n', ' ').strip())\narticles_df['clean_abstracts'] = clean_abstract\narticles_df['clean_title'] = clean_title","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_arxiv = list(articles_df.abstract)\n\ncount = 0\nfor abstract in list_arxiv:\n    if \"climate change\" in abstract:\n        count += 1\n    elif \"Climate change\" in abstract:\n        count += 1\n    elif \"global warming\" in abstract:\n        count += 1\n    elif \"Global warming\" in abstract:\n        count += 1\n\n\n\nprint(count, len(list_arxiv))\nprint(list_arxiv[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data_arxiv = TokenDataset(texts=list_arxiv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_arxiv = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nai_arxiv.train(training_data_arxiv, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_arxiv.generate(n=3,prompt='Climate change is', max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Trent p책 fake news**","metadata":{}},{"cell_type":"code","source":"df_fake_news = pd.read_csv(\"../input/fakenewsnet/BuzzFeed_fake_news_content.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_fake_news = list(df_fake_news.text)\ntraining_data_fn = TokenDataset(texts=list_fake_news)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_fn = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nai_fn.train(training_data_fn, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_fn.generate(n=3,prompt='Climate change is', max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Trent p책 Arxiv-papers-2010-2020**","metadata":{}},{"cell_type":"code","source":"df_arxiv_2010 = pd.read_json(\"../input/arxiv-papers-2010-2020/arXiv_title_abstract_20200809_2011_2020.json\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_summary = list(df_arxiv_2010.abstract)\n\ncount = 0\nfor summary in list_summary:\n    if \"climate change\" in summary:\n        count += 1\n    elif \"Climate change\" in summary:\n        count += 1\n    elif \"global warming\" in summary:\n        count += 1\n    elif \"Global warming\" in summary:\n        count += 1\n\nprint(count, len(list_summary))\nprint(list_summary[2:10])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data_arxiv_2010 = TokenDataset(texts=list_summary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_arx_2010 = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nai_arx_2010.train(training_data_arxiv_2010, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_arx_2010.generate(n=3,prompt='Climate change is', max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ****Trained on twitter-set****","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_csv(\"../input/twitter-climate-change-sentiment-dataset/twitter_sentiment_data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twitter_message = []\nfor i in range(len(df1)):\n    tweet = df1.message[i]\n    if '@' in tweet:\n        tweet = \" \".join(filter(lambda x:x[0]!='@', tweet.split()))\n    if 'RT' in tweet:\n        tweet = \" \".join(filter(lambda x:x[0:2]!='RT' , tweet.split()))\n    if 'https' in tweet:\n        tweet = \" \".join(filter(lambda x:x[0:6]!='https' , tweet.split()))\n    twitter_message.append(tweet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data_twitter = TokenDataset(texts=twitter_message)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_twitter = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_twitter.train(training_data_twitter, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_twitter.generate(n=3,prompt='Climate change is', max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Trent p책 alle datasett over**","metadata":{}},{"cell_type":"code","source":"ai_all = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nai_all.train(training_data_arxiv, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )\n\nai_all.train(training_data_arxiv_2010, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )\n\nai_all.train(training_data_fn, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )\n\nai_all.train(training_data_twitter, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_all.generate(n=3,prompt='Climate change is', max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Trained on total arxiv**","metadata":{}},{"cell_type":"code","source":"df_arxiv = pd.read_json(\"../input/arxivdataset/arxivData.json\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viser at datasettet ikke er spesielt relevant\nlist_summary = list(df_arxiv[df_arxiv.summary==df_arxiv.summary].summary)\n\nlist_climate_summary = []\ncount = 0\nfor summary in list_summary:\n    if \"climate change\" in summary:\n        count += 1\n        list_relevant_summary.append(summary)\n    elif \"Climate change\" in summary:\n        count += 1\n        list_relevant_summary.append(summary)\n    elif \"global warming\" in summary:\n        count += 1\n        list_relevant_summary.append(summary)\n    elif \"Global warming\" in summary:\n        count += 1\n        list_relevant_summary.append(summary)\n\nprint(count)\n#training_data = TokenDataset(texts=list_summary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai.train(training_data, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=20,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )\n\n#generate_every=20,","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai.generate(n=3,prompt='Climate change is', max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Trained on 5 articles**","metadata":{}},{"cell_type":"code","source":"articles_file = open(\"../input/5-cc-articles/combined.txt\", \"r\")\narticles = articles_file.read()\narticles_list = articles.split(\"\\n\")\nprint(articles_list[3]) #OBS, fjern tomrom\narticles_list = [name for name in articles_list if name.strip()]\nprint(articles_list[1])\n#training_data = TokenDataset(texts=articles_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(articles_list))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai.train(training_data, \n        line_by_line=True,\n        from_cache=False,\n        num_steps=100,\n        generate_every=10,\n        learning_rate=1e-4,\n        fp16=False,\n        batch_size=1\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai.generate(n=5,prompt='Climate change is', max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Trained on many articles**","metadata":{}},{"cell_type":"code","source":"articles_file = open(\"../input/many-cc-articles/articles.txt\", \"r\")\narticles = articles_file.read()\narticles_list = articles.split(\"\\n\")\nprint(articles_list[3]) #OBS, fjern tomrom\narticles_list = [name for name in articles_list if name.strip()]\nprint(articles_list[10])\n#training_data = TokenDataset(texts=articles_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Not-trained model** (saved as files)","metadata":{}},{"cell_type":"code","source":"ai = aitextgen(model_name=\"gpt-small\", to_gpu=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai.generate(n=3, prompt=\"Climate change is\", max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai.generate_to_file(n=3, prompt=\"Trump is president because\", max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai.generate_to_file(n=3, prompt=\"Climate change is\", max_length=100)\nai.generate_to_file(n=3, prompt=\"The coronavirus is\", max_length=100)\nai.generate_to_file(n=3, prompt=\"What is Black Lives Matter?\", max_length=100)\nai.generate_to_file(n=3, prompt=\"What is white supremacy?\", max_length=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}