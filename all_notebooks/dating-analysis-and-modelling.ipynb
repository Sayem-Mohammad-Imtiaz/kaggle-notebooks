{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"**1&nbsp;&nbsp;[Introduction](#1)**  \n&nbsp;&nbsp;&nbsp;&nbsp;1.1&nbsp;&nbsp;[Problem definition](#1.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;1.2&nbsp;&nbsp;[Dataset](#1.2)  \n**2&nbsp;&nbsp;[Environment](#2)**  \n&nbsp;&nbsp;&nbsp;&nbsp;2.1&nbsp;&nbsp;[Libraries](#2.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;2.2&nbsp;&nbsp;[Data](#2.2)  \n&nbsp;&nbsp;&nbsp;&nbsp;2.3&nbsp;&nbsp;[Functions](#2.3)  \n**3&nbsp;&nbsp;[Wrangling](#3)**  \n&nbsp;&nbsp;&nbsp;&nbsp;3.1&nbsp;&nbsp;[Relevant features](#3.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;3.2&nbsp;&nbsp;[Feature datatypes](#3.2)  \n&nbsp;&nbsp;&nbsp;&nbsp;3.3&nbsp;&nbsp;[Data export](#3.3)  \n**4&nbsp;&nbsp;[Exploration](#4)**  \n&nbsp;&nbsp;&nbsp;&nbsp;4.1&nbsp;&nbsp;[Univariate analysis](#4.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;4.2&nbsp;&nbsp;[Bivariate analysis](#4.2)  \n**5&nbsp;&nbsp;[Engineering](#5)**  \n&nbsp;&nbsp;&nbsp;&nbsp;5.1&nbsp;&nbsp;[Sample analysis](#5.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;5.2&nbsp;&nbsp;[Feature representation](#5.2)  \n&nbsp;&nbsp;&nbsp;&nbsp;5.3&nbsp;&nbsp;[Feature interactions](#5.3)  \n&nbsp;&nbsp;&nbsp;&nbsp;5.4&nbsp;&nbsp;[Feature transformations](#5.4)  \n&nbsp;&nbsp;&nbsp;&nbsp;5.5&nbsp;&nbsp;[Feature selection](#5.5)  \n&nbsp;&nbsp;&nbsp;&nbsp;5.6&nbsp;&nbsp;[Data export](#5.6)  \n**6&nbsp;&nbsp;[Modelling](#6)**  \n&nbsp;&nbsp;&nbsp;&nbsp;6.1&nbsp;&nbsp;[Baseline models](#6.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;6.2&nbsp;&nbsp;[Ensemble models](#6.2)  \n**7&nbsp;&nbsp;[Evaluation](#7)**  \n&nbsp;&nbsp;&nbsp;&nbsp;7.1&nbsp;&nbsp;[Classifier performance](#7.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;7.2&nbsp;&nbsp;[Feature importance](#7.2)  \n&nbsp;&nbsp;&nbsp;&nbsp;7.3&nbsp;&nbsp;[Learning rate](#7.3)  \n**8&nbsp;&nbsp;[Conclusion](#8)**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## 1 Introduction<a id=\"1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Problem definition<a id=\"1.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"- This notebook will investigate whether it is possible to **predict if a partner will match with their date** based on **dating preferences**, **attribute ratings** and **background information**.\n- The problem can be framed as a supervised, binary classification problem where the model predicts if a partner has accepted or rejected their date."},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Dataset<a id=\"1.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"- A study conducted by Columbia University explored gender differences in dating preferences.\n- Participants attended a dating event where they had a 4-minute date with every other participant of the opposite sex who attended the same event.\n- The participants decided to accept or reject their partner. If both the participant and partner matched, they received each other's contact information.\n- Participants rated their partners on six personal attributes: attractiveness, sincerity, intelligence, fun, ambition and shared interests.\n- Before and after the event, participants rated their preferences in the six attributes and gave themselves ratings.\n- Other information was collected about the participants' background and preferences."},{"metadata":{},"cell_type":"markdown","source":"## 2 Environment<a id=\"2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Libraries<a id=\"2.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Load libraries into notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np              # arrays\nimport pandas as pd             # dataframes\nimport matplotlib.pyplot as plt # graphs\nimport seaborn as sns           # visualisations\nfrom scipy import stats         # statistics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer # enable experimental imputer\nfrom sklearn.impute import IterativeImputer               # sample imputation\nfrom sklearn import preprocessing                         # encoders, transformations\nfrom sklearn.model_selection import cross_validate        # cross-validation, model evaluation\nfrom sklearn.model_selection import GridSearchCV          # hyper-parameter tuning\nfrom sklearn.linear_model import LogisticRegression       # logistic regression model\nfrom sklearn.svm import SVC                               # support vector machine model\nfrom sklearn.neighbors import KNeighborsClassifier        # k-nearest neighbours model\nfrom sklearn.ensemble import GradientBoostingClassifier   # gradient boosting model\nfrom sklearn.ensemble import VotingClassifier             # voting ensemble model\nfrom sklearn.ensemble import StackingClassifier           # stacking ensemble model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Data<a id=\"2.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Import raw dataset into a dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw = pd.read_csv(\n    filepath_or_buffer='../input/speed-dating-experiment/Speed Dating Data.csv',\n    engine='python'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get number of rows and columns of raw dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get memory usage of raw dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw.memory_usage().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Functions<a id=\"2.3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Define a function to plot distribution functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution(data, bins, title, xlabel, ylabel):\n    ax = sns.distplot(\n        data,\n        bins=bins,\n        hist_kws={\n            \"linewidth\": 1,\n            'edgecolor': 'black',\n            'alpha': 1.0\n            },\n        kde=False\n    )\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define a function to plot relationship between two features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_relationship(x, y, title, xlabel, ylabel):\n    ax = sns.barplot(\n        x=x,\n        y=y,\n        orient='h'\n    )\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define a function to print a feature's mean, standard deviation, skewness and kurtosis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_moments(title, feature):\n    print(title)\n    print('Mean: '+'{:>18.2f}'.format(feature.mean()))\n    print('Standard deviation: '+'{:.2f}'.format(feature.std()))\n    print('Skewness: '+'{:>14.2f}'.format(feature.skew()))\n    print('Kurtosis: '+'{:>14.2f}'.format(feature.kurtosis()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3 Wrangling<a id=\"3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Relevant features<a id=\"3.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Identify relevant features and associated datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"relevant_features = [\n    ['iid', 'int16'],\n    ['gender', 'bool'],\n    ['wave', 'int16'],\n    ['position', 'int16'],\n    ['order', 'int16'],\n    ['pid', 'int16'],\n    ['age_o', 'int16'],\n    ['race_o', 'category'],\n    ['pf_o_att', 'int16'],\n    ['pf_o_sin', 'int16'],\n    ['pf_o_int', 'int16'],\n    ['pf_o_fun', 'int16'],\n    ['pf_o_amb', 'int16'],\n    ['pf_o_sha', 'int16'],\n    ['dec_o', 'bool'],\n    ['attr_o', 'int16'],\n    ['sinc_o', 'int16'],\n    ['intel_o', 'int16'],\n    ['fun_o', 'int16'],\n    ['amb_o', 'int16'],\n    ['shar_o', 'int16'],\n    ['like_o', 'int16'],\n    ['prob_o', 'int16'],\n    ['met_o', 'bool'],\n    ['age', 'int16'],\n    ['field_cd', 'category'],\n    ['race', 'category'],\n    ['imprace', 'int16'],\n    ['imprelig', 'int16'],\n    ['goal', 'category'],\n    ['date', 'int16'],\n    ['go_out', 'int16'],\n    ['career_c', 'category'],\n    ['sports', 'int16'],\n    ['tvsports', 'int16'],\n    ['exercise', 'int16'],\n    ['dining', 'int16'],\n    ['museums', 'int16'],\n    ['art', 'int16'],\n    ['hiking', 'int16'],\n    ['gaming', 'int16'],\n    ['clubbing', 'int16'],\n    ['reading', 'int16'],\n    ['tv', 'int16'],\n    ['theater', 'int16'],\n    ['movies', 'int16'],\n    ['concerts', 'int16'],\n    ['music', 'int16'],\n    ['shopping', 'int16'],\n    ['yoga', 'int16'],\n    ['exphappy', 'int16'],\n    ['expnum', 'int16'],\n    ['attr1_1', 'int16'],\n    ['sinc1_1', 'int16'],\n    ['intel1_1', 'int16'],\n    ['fun1_1', 'int16'],\n    ['amb1_1', 'int16'],\n    ['shar1_1', 'int16'],\n    ['attr3_1', 'int16'],\n    ['sinc3_1', 'int16'],\n    ['fun3_1', 'int16'],\n    ['intel3_1', 'int16'],\n    ['amb3_1', 'int16'],\n    ['dec', 'bool'],\n    ['attr', 'int16'],\n    ['sinc', 'int16'],\n    ['intel', 'int16'],\n    ['fun', 'int16'],\n    ['amb', 'int16'],\n    ['shar', 'int16'],\n    ['like', 'int16'],\n    ['prob', 'int16'],\n    ['met', 'int16'],\n    ['match_es', 'int16'],\n    ['satis_2', 'int16'],\n    ['length', 'int16'],\n    ['numdat_2', 'int16']\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new dataframe containing relevant features"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data_raw[[feature[0] for feature in relevant_features]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get number of rows and columns of new dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get memory usage of new dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.memory_usage().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Feature datatypes<a id=\"3.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Update feature datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.astype({feature: datatype if all(data[feature].notna().values) else 'float32' if datatype == 'int16' else datatype for (feature, datatype) in relevant_features})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get memory usage of updated dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.memory_usage().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Data export<a id=\"3.3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Persist dataframe containing relevant features with appropriate datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv(\n    path_or_buf='./data.csv',\n    index=False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4 Exploration<a id=\"4\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Univariate analysis<a id=\"4.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Get proportion of dates where partner matched with subject"},{"metadata":{"trusted":true},"cell_type":"code","source":"partner_accepts = data['dec_o']\nround(partner_accepts[partner_accepts == True].count()/partner_accepts.count(),3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the distributions of subject attribute ratings from their partners"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,10))\nplt.tight_layout(pad=5.0)\n\nplt.subplot(2,3,1)\nplot_distribution(\n    data=data['attr_o'],\n    bins=np.arange(0, 10, 0.5).tolist(),\n    title='Subject\\'s attractiveness rating',\n    xlabel='Attractiveness rating',\n    ylabel='Number of subjects'\n)\nplt.subplot(2,3,2)\nplot_distribution(\n    data=data['sinc_o'],\n    bins=np.arange(0, 10, 0.5).tolist(),\n    title='Subject\\'s sincerity rating',\n    xlabel='Sincerity rating',\n    ylabel='Number of subjects'\n)\nplt.subplot(2,3,3)\nplot_distribution(\n    data=data['intel_o'],\n    bins=np.arange(0, 10, 0.5).tolist(),\n    title='Subject\\'s intelligence rating',\n    xlabel='Intelligence rating',\n    ylabel='Number of subjects'\n)\nplt.subplot(2,3,4)\nplot_distribution(\n    data=data['fun_o'],\n    bins=np.arange(0, 10, 0.5).tolist(),\n    title='Subject\\'s fun rating',\n    xlabel='Fun rating',\n    ylabel='Number of subjects'\n)\nplt.subplot(2,3,5)\nplot_distribution(\n    data=data['amb_o'],\n    bins=np.arange(0, 10, 0.5).tolist(),\n    title='Subject\\'s ambition rating',\n    xlabel='Ambition rating',\n    ylabel='Number of subjects'\n)\nplt.subplot(2,3,6)\nplot_distribution(\n    data=data['shar_o'],\n    bins=np.arange(0, 10, 0.5).tolist(),\n    title='Subject\\'s shared interest rating',\n    xlabel='Shared interest rating',\n    ylabel='Number of subjects'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate the moments of subject attribute ratings from their partners"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_moments('Attractiveness rating', data['attr_o'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_moments('Sincerity rating', data['sinc_o'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_moments('Intelligence rating', data['intel_o'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_moments('Fun rating', data['fun_o'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_moments('Ambition rating', data['amb_o'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_moments('Shared interest rating', data['shar_o'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get features with highest variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.std().sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get features with highest skew"},{"metadata":{"trusted":true},"cell_type":"code","source":"abs(data.skew()).sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Bivariate analysis<a id=\"4.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Visualise correlation between selected features"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_selected = [\n    'dec_o',\n    'pf_o_att',\n    'pf_o_sin',\n    'pf_o_int',\n    'pf_o_fun',\n    'pf_o_amb',\n    'pf_o_sha',\n    'attr_o',\n    'sinc_o',\n    'intel_o',\n    'fun_o',\n    'amb_o',\n    'shar_o'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\ncmap = plt.cm.RdBu\nmask = np.triu(data[features_selected].astype(float).corr())\nsns.heatmap(\n    data[features_selected].astype(float).corr(),\n    square=True,\n    cmap=cmap,\n    mask=mask,\n    linewidths=0.1,\n    vmax=1.0,\n    linecolor='white'\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualise correlation between selected features for men"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_men = data[data['gender']==1]\n\nplt.figure(figsize=(12,10))\ncmap = plt.cm.RdBu\nmask = np.triu(data_men[features_selected].astype(float).corr())\nsns.heatmap(\n    data_men[features_selected].astype(float).corr(),\n    square=True,\n    cmap=cmap,\n    mask=mask,\n    linewidths=0.1,\n    vmax=1.0,\n    linecolor='white'\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualise correlation between selected features for women"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_women = data[data['gender']==0]\n\nplt.figure(figsize=(12,10))\ncmap = plt.cm.RdBu\nmask = np.triu(data_women[features_selected].astype(float).corr())\nsns.heatmap(\n    data_women[features_selected].astype(float).corr(),\n    square=True,\n    cmap=cmap,\n    mask=mask,\n    linewidths=0.1,\n    vmax=1.0,\n    linecolor='white'\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get highest correlated feature pairs"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = data.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\ncorrelations = correlations[correlations != 1]\ncorrelations[correlations > 0.6]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get highest correlated features with target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"partner_decision_correlations = correlations.loc['dec_o']\npartner_decision_correlations[partner_decision_correlations > 0.1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5 Engineering<a id=\"5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 5.1 Sample analysis<a id=\"5.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Get proportion of dataframe with missing samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_samples_proportion = data.isnull().sum()/len(data)\nmissing_samples_proportion.sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop features with more than 50% missing samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing_half_samples = missing_samples_proportion[missing_samples_proportion > 0.5].index.values\n#data.drop(columns=missing_half_samples, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Impute missing samples using iterative imputer"},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = IterativeImputer(\n    missing_values=np.nan,\n    sample_posterior=True,\n    n_nearest_features=5,\n    min_value=0,\n    max_value=100,\n    random_state=0\n)\nimputer.fit(data)\ndata_imputed = np.around(imputer.transform(data))\ndata = pd.DataFrame(data_imputed, columns=data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.astype({feature: datatype if all(data[feature].notna().values) else 'float32' if datatype == 'int16' else datatype for (feature, datatype) in relevant_features})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.2 Feature representation<a id=\"5.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Encode nominal features using one-hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_nominal = data.dtypes[data.dtypes == 'category'].index.values\ndata = pd.get_dummies(data, prefix=features_nominal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.3 Feature interactions<a id=\"5.3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Calculate the average attribute ratings for each subject"},{"metadata":{"trusted":true},"cell_type":"code","source":"subject_attractiveness_mean = data[['iid', 'attr_o']].groupby(['iid']).mean()['attr_o']\nsubject_sincerity_mean = data[['iid', 'sinc_o']].groupby(['iid']).mean()['sinc_o']\nsubject_intelligence_mean = data[['iid', 'intel_o']].groupby(['iid']).mean()['intel_o']\nsubject_fun_mean = data[['iid', 'fun_o']].groupby(['iid']).mean()['fun_o']\nsubject_ambition_mean = data[['iid', 'amb_o']].groupby(['iid']).mean()['amb_o']\nsubject_shared_interest_mean = data[['iid', 'shar_o']].groupby(['iid']).mean()['shar_o']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Insert average attribute ratings into dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.merge(\n    right=subject_attractiveness_mean,\n    how='inner',\n    on='iid'\n).rename(columns={\n    'attr_o_x': 'attr_o',\n    'attr_o_y': 'subject_attractiveness_mean'\n})\ndata = data.merge(\n    right=subject_sincerity_mean,\n    how='inner',\n    on='iid'\n).rename(columns={\n    'sinc_o_x': 'sinc_o',\n    'sinc_o_y': 'subject_sincerity_mean'\n})\ndata = data.merge(\n    right=subject_intelligence_mean,\n    how='inner',\n    on='iid'\n).rename(columns={\n    'intel_o_x': 'intel_o',\n    'intel_o_y': 'subject_intelligence_mean'\n})\ndata = data.merge(\n    right=subject_fun_mean,\n    how='inner',\n    on='iid'\n).rename(columns={\n    'fun_o_x': 'fun_o',\n    'fun_o_y': 'subject_fun_mean'\n})\ndata = data.merge(\n    right=subject_ambition_mean,\n    how='inner',\n    on='iid'\n).rename(columns={\n    'amb_o_x': 'amb_o',\n    'amb_o_y': 'subject_ambition_mean'\n})\ndata = data.merge(\n    right=subject_shared_interest_mean,\n    how='inner',\n    on='iid'\n).rename(columns={\n    'shar_o_x': 'shar_o',\n    'shar_o_y': 'subject_shared_interest_mean'\n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate difference between subject and partner's ages"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['age_difference'] = abs(data['age'] - data['age_o'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate difference between subject's attribute ratings and partner's attributes ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['attractiveness_difference'] = abs(data['attr'] - data['attr_o'])\ndata['sincerity_difference'] = abs(data['sinc'] - data['sinc_o'])\ndata['intelligence_difference'] = abs(data['intel'] - data['intel_o'])\ndata['fun_difference'] = abs(data['fun'] - data['fun_o'])\ndata['ambition_difference'] = abs(data['amb'] - data['amb_o'])\ndata['shared_interest_difference'] = abs(data['shar'] - data['shar_o'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.4 Feature transformations<a id=\"5.4\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Scale normal features to zero mean and unit variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_normal = [\n    'attr_o',\n    'sinc_o',\n    'intel_o',\n    'fun_o',\n    'amb_o',\n    'shar_o',\n    'age_difference',\n    'attractiveness_difference',\n    'sincerity_difference',\n    'intelligence_difference',\n    'fun_difference',\n    'ambition_difference',\n    'shared_interest_difference'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[features_normal] = data[features_normal].apply(lambda x: preprocessing.scale(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.5 Feature selection<a id=\"5.5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Drop irrelevant features which contain no information about the target variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"features_no_information = [\n    'iid',\n    'pid',\n    'wave',\n    'position',\n    'order'\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop features that are known in the future"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_future_information = [\n    'dec',\n    'dec_o',\n    'like',\n    'prob',\n    'like_o',\n    'prob_o'\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop features that have low variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_variances = data.std().sort_values(ascending=True)\nfeatures_low_variance = feature_variances[feature_variances < 0.1].index.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop features that have weak correlation with target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_weak_correlation = partner_decision_correlations[partner_decision_correlations < 0.1].axes[0].to_list()\nfeatures_weak_correlation = list(set(features_weak_correlation) - set(features_future_information) - set(features_no_information))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop features that were used in interaction variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_interaction = [\n    'age',\n    'age_o',\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_remove = features_no_information+features_future_information+features_low_variance+features_weak_correlation+features_interaction\ndata_model = data.drop(columns=features_remove)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get memory usage of model dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model.memory_usage().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.6 Data export<a id=\"5.6\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Persist dataframe containing features to be used in model"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model.to_csv(\n    path_or_buf='./data_model.csv',\n    index=False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6 Modelling<a id=\"6\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 6.1 Baseline models<a id=\"6.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Define feature and target variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data_model\ntarget = data['dec_o']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instantiate, train and tune a linear model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'penalty': ['l2'],\n    'solver': ['lbfgs'],\n    'C': np.logspace(-4, 4, 20),\n    'max_iter': [10000]\n}\nclassifier_lr = LogisticRegression(random_state=0)\nclassifier_lr = GridSearchCV(\n    estimator=classifier_lr,\n    param_grid=parameters,\n    cv=5,\n    verbose=2,\n    n_jobs=-1\n)\nclassifier_lr.fit(features, target)\nclassifier_lr.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_lr = LogisticRegression(\n    random_state=0,\n    penalty=classifier_lr.best_params_['penalty'],\n    solver=classifier_lr.best_params_['solver'],\n    C=classifier_lr.best_params_['C'],\n    max_iter=classifier_lr.best_params_['max_iter']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instantiate, train and tune a discriminative model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'kernel': ['rbf'],\n    'gamma': [1e-4, 1e-3, 1e-2],\n    'C': [1, 10, 100, 1000]\n}\nclassifier_sv = SVC(random_state=0)\nclassifier_sv = GridSearchCV(\n    estimator=classifier_sv,\n    param_grid=parameters,\n    cv=5,\n    verbose=2,\n    n_jobs=-1\n)\nclassifier_sv.fit(features, target)\nclassifier_sv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_sv = SVC(\n    random_state=0,\n    kernel=classifier_sv.best_params_['kernel'],\n    gamma=classifier_sv.best_params_['gamma'],\n    C=classifier_sv.best_params_['C']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instantiate, train and tune a instance-based model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'n_neighbors': [5,11,19,29],\n    'weights': ['uniform', 'distance'],\n    'metric': ['minkowski', 'euclidean', 'manhattan']\n}\nclassifier_kn = KNeighborsClassifier()\nclassifier_kn = GridSearchCV(\n    estimator=classifier_kn,\n    param_grid=parameters,\n    cv=5,\n    verbose=2,\n    n_jobs=-1\n)\nclassifier_kn.fit(features, target)\nclassifier_kn.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_kn = KNeighborsClassifier(\n    n_neighbors=classifier_kn.best_params_['n_neighbors'],\n    weights=classifier_kn.best_params_['weights'],\n    metric=classifier_kn.best_params_['metric']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.2 Ensemble models<a id=\"6.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Instantiate, train and tune a boosting model"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'loss': ['deviance', 'exponential'],\n    'learning_rate': [0.05],\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 4, 5],\n    'max_features': ['sqrt', 'log2']\n}\nclassifier_gb = GradientBoostingClassifier(random_state=0)\nclassifier_gb = GridSearchCV(\n    estimator=classifier_gb,\n    param_grid=parameters,\n    cv=5,\n    verbose=2,\n    n_jobs=-1\n)\nclassifier_gb.fit(features, target)\nclassifier_gb.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_gb = GradientBoostingClassifier(\n    random_state=0,\n    loss=classifier_gb.best_params_['loss'],\n    learning_rate=classifier_gb.best_params_['learning_rate'],\n    n_estimators=classifier_gb.best_params_['n_estimators'],\n    max_depth=classifier_gb.best_params_['max_depth'],\n    max_features=classifier_gb.best_params_['max_features']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instantiate and train a voting and stacking model"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [\n    ('lr', classifier_lr),\n    ('sv', classifier_sv),\n    ('kn', classifier_kn),\n    ('gb', classifier_gb)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_ve = VotingClassifier(\n    estimators=estimators,\n    voting='hard'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_se = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression()\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7 Evaluation<a id=\"7\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 7.1 Classifier performance<a id=\"7.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Calculate performance metrics for each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics = ['accuracy', 'precision', 'recall', 'f1_macro']\n\nfor classifier, label in zip(\n    [classifier_lr, classifier_sv, classifier_kn, classifier_gb, classifier_ve, classifier_se],\n    ['Logistic Regression', 'Support Vector Machine', 'k-Nearest Neighbours', 'Gradient Boosting', 'Voting Ensemble', 'Stacking Ensemble']\n):\n    print('{}'.format(label))\n    scores = cross_validate(\n        estimator=classifier,\n        X=features,\n        y=target,\n        scoring=metrics,\n        cv=5,\n        n_jobs=-1\n    )\n    for key, value in scores.items():\n        print('{:14} {:.3f} +/- {:.3f}'.format(key, value.mean(), value.std()))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7.2 Feature importance<a id=\"7.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Get coefficients of features in linear model"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = features.columns.values\nweights = classifier_lr.fit(features,target).coef_[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get features with highest magnitude"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features = sorted(list(zip(labels,weights)), reverse=True, key = lambda x: abs(x[1]))[0:10]\ntop_labels = [x[0] for x in top_features]\ntop_weights = [x[1] for x in top_features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot features with highest magnitude"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplot_relationship(top_weights, top_labels, 'Most significant features in linear model', 'Weight', 'Feature')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8 Conclusion<a id=\"8\"></a>"},{"metadata":{},"cell_type":"markdown","source":"- This notebook explored whether a machine learning model could predict if a partner will match with their date.\n- The best performing classifier was a stacking ensemble model with an accuracy of **~76%** and an F1 score of **~75%**.\n- Based on correlation analysis and weights in the linear model:\n  - **Attractiveness**, **shared interests** and being **fun** were the most significant factors in a partner's decision.\n  - **Medical students** had the highest probability of being matched while **psychologists** and **academics** had the lowest.\n- Further feature engineering such as introducing more interaction features and performing more thorough feature selection could improve the classifier performance."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}