{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv')\n\ndef eda(dfA, all=False, desc='Exploratory Data Analysis'):\n    print(desc)\n    print(f'\\nShape:\\n{dfA.shape}')\n    print(f'\\nIs Null: {dfA.isnull().sum().sum()}')\n    print(f'{dfA.isnull().mean().sort_values(ascending=False)}')\n    dup = dfA.duplicated()\n    print(f'\\nDuplicated: \\n{dfA[dup].shape}\\n')\n    try:\n        print(dfA[dfA.duplicated(keep=False)].sample(4))\n    except:\n        pass\n    if all:  # here you put yours prefered analysis that detail more your dataset\n\n        print(f'\\nDTypes - Numerics')\n        print(dfA.describe(include=[np.number]))\n        print(f'\\nDTypes - Categoricals')\n        print(dfA.describe(include=['object']))\n\n        # print(df.loc[:, df.dtypes=='object'].columns)\n        print(f'\\nHead:\\n{dfA.head()}')\n        print(f'\\nSamples:\\n{dfA.sample(2)}')\n        print(f'\\nTail:\\n{dfA.tail()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uniques = df.apply(pd.Series.nunique)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uniques","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots( sharey=True, figsize=(15,5))\nsns.barplot(x=uniques.index, y=uniques.values, ax=ax1).set_title('Uniques by Column')\nplt.xticks(rotation=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushClass = df['class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushClass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ed = df[df['class'] == mushClass[1]]['class'].shape[0]\nined = df[df['class'] == mushClass[0]]['class'].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie([ed,ined], labels=['Edible', 'Poisonous'], autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, PoissonRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.dummy import DummyRegressor\n\n# ML train & test data selection\nfrom sklearn.model_selection import train_test_split\n# mae metric\nfrom sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sepColumns(dataset):\n    num = []\n    cat = []\n    for i in dataset.columns:\n        if dataset[i].dtype == 'object':\n            cat.append(i)\n        else:\n            num.append(i)\n    return num, cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num, cat = sepColumns(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vuCat = []\nfor c in cat:\n    v = df[c].unique().tolist()\n    x = {c: v}\n    vuCat.append(v)\nprint(vuCat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos=0\nfor vc in cat:\n    col = vc.replace('-','_')\n    newCol = f'{col}_N'\n    df[newCol] = df[vc].apply(lambda x: vuCat[pos].index(x))\n    pos += 1\n    print(newCol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num, _ = sepColumns(df)\nnewDf = df[num]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation(df, varT, xpoint=-0.5, showGraph=True):\n    corr = df.corr()\n    print(f'\\nFeatures correlation:\\n'\n          f'Target: {varT}\\n'\n          f'Reference.: {xpoint}\\n'\n          f'\\nMain features:')\n    corrs = corr[varT]\n    features = []\n    for i in range(0, len(corrs)):\n        if corrs[i] > xpoint and corrs.index[i] != varT:\n            print(corrs.index[i], f'{corrs[i]:.2f}')\n            features.append(corrs.index[i])\n    if showGraph:\n        fig, ax1 = plt.subplots( sharey=True, figsize=(15,10))\n        sns.heatmap(corr,\n                    annot=True, fmt='.2f', vmin=-1, vmax=1, linewidth=0.01,\n                    linecolor='black', cmap='RdBu_r', ax=ax1\n                    )\n        plt.title('Correlations between features w/ target')\n        plt.show()\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"varTarget = 'class_N'\nvarFeatures = correlation(newDf, varTarget, 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = newDf[varFeatures]\ny = newDf[varTarget]\nXtreino, Xteste, ytreino, yteste = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressors = [\n        DecisionTreeRegressor(),\n        RandomForestRegressor(),\n        SVR(),\n        LinearRegression(),\n        GradientBoostingRegressor(),\n        PoissonRegressor(),\n        DummyRegressor(),\n        LogisticRegression(),\n        GaussianNB()\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = []\nmae = []\nsco = []\nfor regressor in regressors:\n    modelo = regressor\n    modelo.fit(Xtreino, np.array(ytreino))\n    sco.append(modelo.score(Xtreino, ytreino))\n    previsao = modelo.predict(Xteste)\n    mae.append(round(mean_absolute_error(yteste, previsao), 2))\n    reg.append(regressor)\n\nmeuMae = pd.DataFrame(columns=['Regressor', 'mae', 'score'])\nmeuMae['Regressor'] = reg\nmeuMae['mae'] = mae\nmeuMae['score'] = sco\nmeuMae = meuMae.sort_values(by='score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meuMae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meuMae[\"Regressor\"].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[varFeatures].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for vf in varFeatures:\n    var = vf.replace('_N','')\n    var = var.replace('_','-')\n    print(var, cat.index(var), vuCat[cat.index(var)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valFeatures = cap-surface == 'f'  <==> cap_surface_N == 2\n#               stalk-shape == 'e'  <==> stalk_shape_N == 0\n#               ring-number == 't'  <==> ring_number_N == 1\nvarFeaturesP = ['cap_surface_N', 'stalk_shape_N', 'ring_number_N']\nvalFeaturesP = [2, 0, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = meuMae[\"Regressor\"].values[0]\nx = newDf[varFeaturesP]\ny = newDf[varTarget]\nmodel.fit(x, y)\npredict = model.predict([valFeaturesP])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Summary:\\n'\n          f'Regs analyzed: {len(newDf)}\\n'\n          f'ML applied: {meuMae[\"Regressor\"].values[0]}\\n'\n          f'Features analyzed:')\nfor p in range(0, len(varFeaturesP)):\n    print(f' - {varFeaturesP[p]}: {valFeaturesP[p]}')\n\nprint(f\"Predicted mushroom class: {vuCat[0][predict[0]]} \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view = []\nview = varFeatures[:]\nview.append('class')\nview","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.query('cap_surface_N == 2 and stalk_shape_N == 0 and ring_number_N == 1')[view].sample(15)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}