{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"#modelos\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\n#plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#dados\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom scipy import stats\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import recall_score\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lendo o dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\n\nX = df.drop(\"Outcome\", axis=1)\ny = df[\"Outcome\"]\n\nprint(df.columns)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise de dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribuição da classe (Outcome)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Outcome'],kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Percentual de negativos (0) vs. positivos (1)\ndf['Outcome'].value_counts()/df['Outcome'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlação"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(), annot=True, fmt=\".2f\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pares de dados\nSeparando diabéticos de não-diabéticos"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, hue=\"Outcome\", palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Glucose - Outcome\nNota-se que os Outcomes positivos estão concentrados mais acima do que os Outcomes negativos"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.swarmplot(data=df, y='Glucose', x='Outcome')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Glucose - BMI\nHá uma certa separação entre direita e esquerda, e valores mais acima são em maioria de pessoas com Outcome positivo, especialmente em Glucose = 0 (provavelmente outliers?)."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, x='Glucose', y='BMI', hue='Outcome')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age - Pregnancies\nApesar de haver uma correlação moderada entre idade e número de gravidez, não é possível encontrar algum padrão sobre o Outcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(data=df, x='Pregnancies', y='Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=df, y='Age', x='Pregnancies', hue='Outcome')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encontrando outliers\nAlgumas colunas têm valores 0 que não fazem sentido no mundo real, como o BMI (Índice de Massa Corporal)"},{"metadata":{},"cell_type":"markdown","source":"### BMI"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['BMI'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bmiout = df[(df['BMI'] > 50) | (df['BMI'] < 15)]\nsns.pairplot(bmiout, hue='Outcome',palette='husl', diag_kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(bmiout.corr(),annot=True, fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Glucose"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['Glucose'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['Glucose'].quantile(0.25)\nq3 = df['Glucose'].quantile(0.75)\niqr = q3 - q1\n\nprint(q3 + 1.5 * iqr)\ngluout = df[(df['Glucose'] > q3 + 1.5 * iqr) | (df['Glucose'] < q1 - 1.5 * iqr)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insulin"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['Insulin'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['Insulin'].quantile(0.25)\nq3 = df['Insulin'].quantile(0.75)\niqr = q3 - q1\n\nprint(q3 + 1.5 * iqr)\ninsout = df[(df['Insulin'] > q3 + 1.5 * iqr)]\nsns.pairplot(insout, hue='Outcome',palette='husl', diag_kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(insout.corr(), annot=True, fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Skin Thickness"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['SkinThickness'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['SkinThickness'].quantile(0.25)\nq3 = df['SkinThickness'].quantile(0.75)\niqr = q3 - q1\n\nprint(q3 + 1.5 * iqr)\nsknout = df[(df['SkinThickness'] > q3 + 1.5 * iqr) | (df['SkinThickness'] < q1 - 1.5 * iqr)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pregnancies"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['Pregnancies'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['Pregnancies'].quantile(0.25)\nq3 = df['Pregnancies'].quantile(0.75)\niqr = q3 - q1\n\nprint(q3 + 1.5 * iqr)\nprgout = df[(df['Pregnancies'] > q3 + 1.5 * iqr) | (df['Pregnancies'] < q1 - 1.5 * iqr)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Blood Pressure"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['BloodPressure'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['BloodPressure'].quantile(0.25)\nq3 = df['BloodPressure'].quantile(0.75)\niqr = q3 - q1\n\nprint(q3 + 1.5 * iqr)\nblpout = df[(df['BloodPressure'] > q3 + 1.5 * iqr) | (df['BloodPressure'] < q1 - 1.5 * iqr)]\nsns.pairplot(blpout, hue='Outcome',palette='husl', diag_kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(blpout.corr(), annot=True, fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Diabetes Pedigree Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['DiabetesPedigreeFunction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['DiabetesPedigreeFunction'].quantile(0.25)\nq3 = df['DiabetesPedigreeFunction'].quantile(0.75)\niqr = q3 - q1\n\nprint(q3 + 1.5 * iqr)\ndpfout = df[(df['DiabetesPedigreeFunction'] > q3 + 1.5 * iqr) | (df['DiabetesPedigreeFunction'] < q1 - 1.5 * iqr)]\nsns.pairplot(dpfout, hue='Outcome',palette='husl', diag_kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(dpfout.corr(), annot=True, fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['Age'].quantile(0.25)\nq3 = df['Age'].quantile(0.75)\niqr = q3 - q1\n\nprint(q3 + 1.5 * iqr)\nageout = df[(df['Age'] > q3 + 1.5 * iqr) | (df['Age'] < q1 - 1.5 * iqr)]\nsns.pairplot(ageout, hue='Outcome',palette='husl', diag_kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(ageout.corr(), annot=True, fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Números de outliers e porcentagens por atributo"},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_count = {'Pregnancies':prgout.count().max(), 'Glucose':gluout.count().max(), 'Blood Pressure':blpout.count().max(), 'Skin Thickness':sknout.count().max(), 'Insulin':insout.count().max(), 'BMI':bmiout.count().max(), 'Diabetes Pedigree Function':dpfout.count().max(), 'Age':ageout.count().max()}\noutlier_count = {k: v for k, v in reversed(sorted(outlier_count.items(), key=lambda item: item[1]))}\noutlier_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_percent = {}\nfor key in outlier_count:\n    outlier_percent[key] = round(outlier_count[key] / df.count().max(),4)\n\noutlier_percent = {k: v for k, v in reversed(sorted(outlier_percent.items(), key=lambda item: item[1]))}\noutlier_percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Procurando por valores nulos\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cálculo de VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_vif(tabela):\n  vif = pd.DataFrame()\n  vif['variaveis'] = tabela.columns\n  vif['vif'] = [variance_inflation_factor(tabela.values, i) for i in range(tabela.shape[1])]\n\n  return vif\n\nvif = calc_vif(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif.sort_values('vif', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importância das features\nFoi feito um ranqueamento entre os atributos com base em um algoritmo de Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest = RandomForestClassifier(n_estimators=100,\n                              random_state=0)\n\nforest.fit(X, y)\n\nfeatures = forest.feature_importances_\nfeatures_and_names = {}\nfor i in range(len(features)):\n    features_and_names[df.columns[i]] = features[i]\n\nfeatures_and_names = {k: v for k, v in reversed(sorted(features_and_names.items(), key=lambda item: item[1]))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_and_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nota-se que os atributos mais importantes são Glucose, BMI, Age e DiabetesPedigreeFunction, enquanto Insulin e SkinThickness são os que menos influenciam."},{"metadata":{},"cell_type":"markdown","source":"## Distribuições"},{"metadata":{},"cell_type":"markdown","source":"### Glucose (Outcomes positivos e negativos)\nNota-se uma considerável distinção entre a distribuição dos positivos e dos negativos"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[df['Outcome'] == 0]['Glucose'], kde=False)\nsns.distplot(df[df['Outcome'] == 1]['Glucose'], kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### BMI (Outcomes positivos e negativos)\nA distribuição dos positivos se \"camufla\" no meio da distribuição dos negativos"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[df['Outcome'] == 0]['BMI'], kde=False)\nsns.distplot(df[df['Outcome'] == 1]['BMI'], kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribuição geral de cada atributo"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,3,figsize=(30,15))\nfor variable, i in zip(df.columns, range(len(df.columns))):\n  sns.distplot(df[variable], ax=ax[i//3][i%3])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning\nDado que os Outcomes são valores 0 ou 1, foi decidido que classificadores são mais adequados para este problema.\n\n### Modelos testados:\n- Random Forest Classifier\n- XGB Classifier\n- Logistic Regression\n- K Neighbors Classifier\n- Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_auc = {}\nstats_ks = {}\nstats_recall = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(X_test)\n\nprint(preds[:20])\nprint(y_test.head(20))\n\nfpr, tpr, _ = roc_curve(y_test, preds)\nalg = 'Random Forest'\na = auc(fpr,tpr)\nks = stats.ks_2samp(preds,y_test)\nrec = recall_score(y_test, preds)\nstats_auc[alg] = a\nstats_ks[alg] = ks.pvalue\nstats_recall[alg] = rec\nprint(\"AUC:\",a)\nprint(\"KS statistic:\",ks.statistic, \"pvalue:\", ks.pvalue)\nprint(\"Recall:\",rec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = model.predict_proba(X_test)\nsns.distplot(probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGB Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(n_estimators=100,learning_rate=0.05, random_state=0) \n\nxgb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = xgb.predict(X_test)\n\nprint(preds[:20])\nprint(y_test.head(20))\n\nfpr, tpr, _ = roc_curve(y_test, preds)\nalg = 'XGB'\na = auc(fpr,tpr)\nks = stats.ks_2samp(preds,y_test)\nrec = recall_score(y_test, preds)\nstats_auc[alg] = a\nstats_ks[alg] = ks.pvalue\nstats_recall[alg] = rec\nprint(\"AUC:\",a)\nprint(\"KS statistic:\",ks.statistic, \"pvalue:\", ks.pvalue)\nprint(\"Recall:\",rec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = xgb.predict_proba(X_test)\nsns.distplot(probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(random_state=0,max_iter=1000000)\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = lr.predict(X_test)\n\nfpr, tpr, _ = roc_curve(y_test, preds)\nalg = 'Logistic Regression'\na = auc(fpr,tpr)\nks = stats.ks_2samp(preds,y_test)\nrec = recall_score(y_test, preds)\nstats_auc[alg] = a\nstats_ks[alg] = ks.pvalue\nstats_recall[alg] = rec\nprint(\"AUC:\",a)\nprint(\"KS statistic:\",ks.statistic, \"pvalue:\", ks.pvalue)\nprint(\"Recall:\",rec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K Neighbors Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=13)\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = knn.predict(X_test)\n\nfpr, tpr, _ = roc_curve(y_test, preds)\nalg = 'KNN'\na = auc(fpr,tpr)\nks = stats.ks_2samp(preds,y_test)\nrec = recall_score(y_test, preds)\nstats_auc[alg] = a\nstats_ks[alg] = ks.pvalue\nstats_recall[alg] = rec\nprint(\"AUC:\",a)\nprint(\"KS statistic:\",ks.statistic, \"pvalue:\", ks.pvalue)\nprint(\"Recall:\",rec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = knn.predict_proba(X_test)\nsns.distplot(probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = tree.predict(X_test)\n\nprint(preds[:20])\nprint(y_test.head(20))\n\nfpr, tpr, _ = roc_curve(y_test, preds)\nalg = 'Decision Tree'\na = auc(fpr,tpr)\nks = stats.ks_2samp(y_test,preds)\nrec = recall_score(y_test, preds)\nstats_auc[alg] = a\nstats_ks[alg] = ks.pvalue\nstats_recall[alg] = rec\nprint(\"AUC:\",a)\nprint(\"KS statistic:\",ks.statistic, \"pvalue:\", ks.pvalue)\nprint(\"Recall:\",rec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = tree.predict_proba(X_test)\nsns.distplot(probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resultados\n\nForam utilizadas 3 métricas: AUC, Kolmogorov-Smirnov e Recall Médio. Todos os resultados estão em ordem decrescente."},{"metadata":{},"cell_type":"markdown","source":"### AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_auc = {k: v for k, v in reversed(sorted(stats_auc.items(), key=lambda item: item[1]))}\nstats_auc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kolmogorov-Smirnov"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_ks = {k: v for k, v in reversed(sorted(stats_ks.items(), key=lambda item: item[1]))}\nstats_ks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recall médio"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_recall = {k: v for k, v in reversed(sorted(stats_recall.items(), key=lambda item: item[1]))}\nstats_recall","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Em termos de distribuição das predições, o modelo que mais aproximou da distribuição real do dataset foi a Logistic Regression. <br><br>\nQuanto ao resultado AUC, os valores mais altos foram do XGB e Logistic Regression, aproximando-se de 0.75. <br><br>\nNo teste KS, a Decision Tree, XGB e KNN tiveram resultados próximos ao 1.0, enquanto Logistic Regression e Random Forest tiveram resultados mais baixos, com 0.77 e 0.51. <br><br>\nNo recall médio, o XGB Classifier mostrou os maiores resultados, com 0.66, enquanto todos os outros encontram-se abaixo de 0.60."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}