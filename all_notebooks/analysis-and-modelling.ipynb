{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install Afinn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport time\nimport nltk\nfrom afinn import Afinn\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, f1_score\nfrom sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(nltk.corpus.stopwords.words('english'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/national-hockey-league-interviews/interview_data.csv').set_index('RowId')\ndata['date'] = pd.to_datetime(data.date)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing data."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(data.job, order=data.job.value_counts().index);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data.job != 'other']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's study only the players' and coaches' interviews."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.countplot(data.date.map(lambda x: x.year)).set_title('Number of Interviews Each Year');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['num_words'] = data.text.map(lambda x: len(x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data.num_words);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(np.log(data.num_words)).set(xlabel='Natural Logarithm of num_words', title='Skew: {}'.format(round(np.log(data.num_words).skew(),3)));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The log distribution of word count is only moderately skewed. Perhaps we can add interview length to the list of natural (\"naturally\" is loosely defined) phenomena (rainfall, inflation rates, etc.) that tend to have a log-normal distribution. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"kwargs = {'cumulative': True}\nsns.distplot(data.num_words, kde=False, norm_hist=True, hist_kws=kwargs).set(ylabel='% of Entries');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Roughly 50% of interviews have 500 or fewer words. \n# Sentiment Analysis\n## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"afinn = Afinn()\n# this takes 50 seconds\ndata['sentiment'] = data.text.map(lambda x: afinn.score(x)/len(x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data.sentiment);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use the Afinn lexicon-based sentiment scoring method. It scores a list of words by summing each word's sentiment score. We divide by the number of words in order to limit the effects interview length. "},{"metadata":{"trusted":true},"cell_type":"code","source":"low_sent = data.loc[data.sentiment.idxmin()]\nprint(low_sent.drop(columns=['text']))\nprint('\\n'+low_sent.text)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"high_sent = data.loc[data.sentiment.idxmax()]\nprint(high_sent.drop(columns=['text']))\nprint('\\n'+high_sent.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data.num_words, data.sentiment);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above graph and the output of the above cell we see the downside of dividing by the number of words. The word \"thanks\" has a high positive sentiment score, \"terry\" is neutral, and the final score is half the score of \"thanks\". Each individual word in a shorter sentence has a larger impact on the sentiment, so we can expect the variance of the sentiment of these sentences to be large. Larger variant sentence types are more likely to be at the extremes, so we have a two words sentence as the most positive sentence. \n\nDoes it follow that scaling sentiment by sentence length is a bad idea? I think not. See the following graph of num_words vs unscaled sentiment. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(data.num_words, data.sentiment*data.num_words);\nprint(data.num_words.corr(data.sentiment*data.num_words))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a strong positive correlation (Pearson coefficient > 0.8) between num_words and sentiment. Clearly this is unrealistic. Let's stick to our scaled sentiment.\n\nLet's see how the sentiment distributions of coaches and players differ."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x='job', y='sentiment', data=data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As I noted in this Medium article, \"coaches have a slightly less positive and moderately less variable interview sentiment. Anyone whoâ€™s seen the reaction of players (cheering pileup) and coaches (smiling handshake) to a game-winning goal will find this unsurprising.\"\n\n## Hypothesis Testing\n\nThis hand-wave-y observation is all well and good, but let's make our analysis more rigorous. We'll do this through hypothesis testing. The average sentiment of players is noticeably higher than that of coaches, so we'll use a one-tailed test. We'll use a Welsh ttest  (selected by setting usevar equal to 'unequal') because the standard deviations of the two samples are clearly different. "},{"metadata":{"trusted":true},"cell_type":"code","source":"player_sentiment = data[data.job == 'player']['sentiment']\ncoach_sentiment = data[data.job == 'coach']['sentiment']\n_, p, _ = sm.stats.ttest_ind(player_sentiment, coach_sentiment, alternative='larger', usevar='unequal')\nprint(player_sentiment.mean())\nprint(coach_sentiment.mean())\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since p < 0.05, we can can conclude that the higher mean sentiment among players compared to coaches is statistically significant. One could be forgiven for thinking otherwise by looking at the graph alone. This serves as an important reminder of the imporance of hypothesis testing. "},{"metadata":{},"cell_type":"markdown","source":"# \"Selfishness\" Analysis\n## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"selfish_lexicon = {\n    'i':1,'my':1,'i\\'m':1,'i\\'ve':1,'i\\'ll':1,'myself':1,\n    'we':-1, 'our':-1,'us':-1,'we\\'re':-1,'we\\'ve':-1,\n    'we\\'ll':-1,'ourselves':-1\n}\nstart_time = time.time()\ndata['selfishness'] = data.text.apply(lambda x: sum([selfish_lexicon.get(w, 0) for w in x.split()])/len(x.split()))\nprint(time.time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x='job', y='selfishness', data=data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I've created a lexicon-based selfishness scoring method. It assigns postive selfishness scores to first person singular pronouns and negative selfishness scores to first person plural pronouns.\n\nThe means of the two distributions are roughly equal, but coaches once again have a distribution with lower variance.\n\n## Hypothesis Testing\n\nSince the standard deviations of the two distributions are noticeably different, we'll once again again use a Welsh t-test to compare the two distributions. In this case we'll use a two-tailed t-test since neither average is noticeably larger than the other. "},{"metadata":{"trusted":true},"cell_type":"code","source":"player_selfishness = data[data.job == 'player']['selfishness']\ncoach_selfishness = data[data.job == 'coach']['selfishness']\n_, p, _ = sm.stats.ttest_ind(player_selfishness, coach_selfishness, alternative='two-sided', usevar='unequal')\nprint(player_selfishness.mean())\nprint(coach_selfishness.mean())\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since p > 0.05, we can cannot conclude that there is a statistically significant difference between player and coach selfishness. Whereas the sentiment of the two groups appeared roughly equal but the hypothesis test revealed that they are significantly different, in this case the visualization and the hypothesis test agree that there is not a significant difference between the two. \n\n# Hypothesis Testing: A Caveat\nHypothesis testing is a statistically rigorous method of comparing samples, and the conclusions we came to in the above section are likely to be true. However, these tests depend on our chosen method of measuring sentiment and selfishness. When we refer to selfishness/sentiment in the above hypothesis testing sections, we really mean to say selfishness/sentiment *as measured by our selfishness and sentiment metrics*. It is entirely possible that, had we used different metrics, we would have reached different conclusions. "},{"metadata":{},"cell_type":"markdown","source":"# Player vs Coach Classification\nCan we train a model to determine whether a given interview transcript was from a coach or a player?"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(314)\nmask = np.random.random(len(data)) < 0.8\ny = (data.job == 'player').astype(int).values\nX = data.text.values\ny_train = y[mask]\ny_test = y[~mask]\nX_train = X[mask]\nX_test = X[~mask]\nprint((y_train==1).sum()/len(y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's bear in mind that the training set (and likely the test set, but let's pretend we don't know that) has an imbalance of 75%/25%.\n\nOur model will be logistic regression with the ft-idf as features. This is a simple yet often highly accurate model. Neural models such as RNNs or BERT may be a step up, but they have a high overhead and generally require large amounts of data in order to outperform more traditional models."},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'C': [10**i for i in range(-4, 8)]\n}\nkfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=314)\nlr_pipe_grid = make_pipeline(\n    CountVectorizer(),\n    TfidfTransformer(),\n    GridSearchCV(LogisticRegression(max_iter=10**4), params, cv=kfold)\n)\nlr_pipe_grid.fit(X_train, y_train)\ngrid = lr_pipe_grid[2]\nprint(grid.best_params_)\nif len(params) == 1:\n    param_name = next(iter(params))\n    param_list = next(iter(params.values()))\n    accs = np.array(grid.cv_results_['mean_test_score'])\n    sns.lineplot(param_list, accs).set(xscale='log', xlabel=param_name, ylabel='Mean CV Accuracy');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# this cell takes approximately 3 minutes to run\nstart_time = time.time()\nparams = {\n    'C': [10**i for i in range(2, 8)]\n}\nkfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=30, random_state=314)\nlr_pipe_grid = make_pipeline(\n    CountVectorizer(),\n    TfidfTransformer(),\n    GridSearchCV(LogisticRegression(max_iter=10**4), params, cv=kfold)\n)\nlr_pipe_grid.fit(X_train, y_train)\ngrid = lr_pipe_grid[2]\nprint(grid.best_params_)\nif len(params) == 1:\n    param_name = next(iter(params))\n    param_list = next(iter(params.values()))\n    accs = np.array(grid.cv_results_['mean_test_score'])\n    sns.lineplot(param_list, accs).set(xscale='log', xlabel=param_name, ylabel='Mean CV Accuracy');\nprint(time.time() - start_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like 10\\*\\*6 is our optimal C parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_pipe = make_pipeline(\n    CountVectorizer(), \n    TfidfTransformer(), \n    LogisticRegression(C=10**6, class_weight='balanced')\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_pipe.fit(X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lr_pipe.predict(X_test)\n(y_pred == y_test).sum()/len(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\nconf_mat = confusion_matrix(y_test, y_pred)/len(y_pred)\nsns.heatmap(conf_mat, annot=True, ax=ax).set(xlabel='Predicted', ylabel='True');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_preds = lr_pipe.predict_proba(X_test)\nprob_preds = prob_preds[:,1]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fpr, tpr, threshold = roc_curve(y_test, prob_preds)\nroc_auc = auc(fpr, tpr)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n'AUC: {}'.format(round(roc_auc, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROC curves can give an overly optimistic estimate of model performance when the dataset is imbalanced. A much better alternative in this case is a precision-recall curve. "},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_prec, lr_rec, _ = precision_recall_curve(y_test, prob_preds)\nbaseline = (y_test==1).sum()/len(y_test)\nsns.lineplot(lr_rec, lr_prec, label='Logistic Regression').set(xlabel='Recall', ylabel='Precision');\nsns.lineplot([0, 1], [baseline, baseline], label='Baseline');\nlr_f1 = f1_score(y_test, y_pred)\nlr_auc = auc(lr_rec, lr_prec)\n'F1: {}, AUC: {}'.format(round(lr_f1, 3), round(lr_auc, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that I adapted the code from [Machine Learning Mastery Article](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/) to make the above plots. "},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nWe've studied the difference between coaches and players along two axes, sentiment and selfishness. We found that the higher mean sentiment among players compared to coaches is statistically significant. We've created a binary classification model with a test F1 score of 0.97. \n\nIn other work I used this dataset to train an RNN-based Facebook Messenger chatbot to respond to messages as a hockey player might. If you send the bot the beginning of an interview response, it will respond with a 5-sentence continuation of that response. For example, it could receive \"Well you know\" and respond with \"Well you know we played hard out there and...\". Follow [this](m.me/102447081166159) link to interact with the chatbot and [this](https://medium.com/analytics-vidhya/nhl-player-chatbot-5c882e330fb7) link to read the Medium article where I explain how I created the bot (and how you can too!).\n\nI've had a lot of fun with this dataset and I hope you can too!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}