{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing all the important libraries for the dataset\n%matplotlib inline\nimport pandas as pd\nimport nltk\nimport sqlite3\nimport string\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review = pd.read_csv('../input/amazon-fine-food-reviews/Reviews.csv')\nreview.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of entries from the dataframe:\",review.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review['ProductId'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review['UserId'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for the Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"review.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the values with the null values\nreview.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NEUTRAL REVIEWS\n> we drop the rows where score = 3 because neutral reviews don't provide value to the prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"review = review[review['Score'] !=3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TARGET VARIABLE\n> next we create a column called positive where any score above 3 is encoded as 1 otherwise 0.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"review['positive']=np.where(review[\"Score\"]>3,1,0)\nreview.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(review['positive'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MEMORY USAGE"},{"metadata":{"trusted":true},"cell_type":"code","source":"review.info(memory_usage='deep')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LOW MEMORY\n> drop down the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"review=review.drop(['ProductId','UserId','ProfileName','Id','HelpfulnessNumerator','HelpfulnessDenominator','Score','Time','Summary'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the memory usage again\nreview.info(memory_usage='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the data into training and testing data.\n#text will be used for training.\n#positive is what we are predicting.\nx_train,x_test,y_train,y_test=train_test_split(review['Text'],review['positive'],random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('x_train first entry: \\n\\n',x_train[0])\nprint('\\n\\nx_train shape:',x_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TOKENIZATON\n> In order to perform machine learning on text documents,we first need to turn these text content into numerical feature vectors that scikit-Learn can use."},{"metadata":{},"cell_type":"markdown","source":"BAG OF WORDS\n> The simplest way to do so is to use bags-of-words.First we convert the text documentation into a matrix of tokens.\nThe default configuration tokenizes the string,by extracting words of at least 2 letters or numbers,\nseperated by word boundaries,converts everything to lowercase and builds a vocabulary using these tokens"},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = CountVectorizer().fit(x_train)\nvect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the features\nfeat=vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud=WordCloud(width=1440, height=1080).generate(\" \".join(feat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# larger the size of the word, more the times it appear.\nplt.figure(figsize=(20,15))\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Sparse Matrix\n> we now transform the documents into bag-of-words representation i.e matrix form. The result is stored in a sparse matrix i.e it has very few non zero elements.\n> Rows represent a word in a document while columns represent the words in our training vocabulary."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_vectorized=vect.transform(x_train)\n# the interpretation of the columns can be retreived as follows\n# X_train_vectorized .toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression()\nmodel.fit(x_train_vectorized, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy\npredictions=model.predict(vect.transform(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# area under the curve.\nroc_auc=roc_auc_score(y_test,predictions)\nprint('AUC:',roc_auc)\nfpr,tpr,thresholds=roc_curve(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('ROC for logistic regression on bag of words',fontsize=20)\nplt.plot(fpr,tpr,'b',label='AUC= %0.2f'%roc_auc)\nplt.plot([0,1], [0,1],'r--')\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.ylabel('True positive rate',fontsize=20)\nplt.xlabel('False negative rate',fontsize=20)\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficient determine the weight of a word (positive or negative)\n# checking the top 10 positive and negative words\n\n#getting the feature names\nfeature_names=np.array(vect.get_feature_names())\n\n#argsort: Integer indicies that would sort the index if used as an indexer\nsorted_coef_index=model.coef_[0].argsort()\n\nprint('Smallest coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TF IDF(term-frequency-inverse-document-frequency).\n> This means that we weigh the terms by how uncommon they are, meaning that we care more about rare words than common words.\n\n"},{"metadata":{},"cell_type":"markdown","source":"Why use TF IDF over bag of words?\n> In large texts,some words may be repeated often but will cary very little meaningful information about the actual contents of the document. If we were to feed the count data directly to a classifier those very frequent terms would shadow the frequencies of rare yet more interesting terms.\n"},{"metadata":{},"cell_type":"markdown","source":"TF IDF allows us to weight terms based on how important they are to a document."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignore the terms that appear in less than 5 documents\nvect= TfidfVectorizer(min_df=5).fit(x_train)\nlen(vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the top 10 features for positive and negative\n# reviews again, the AUC has improved\nfeature_names=np.array(vect.get_feature_names())\nsorted_coef_index=model.coef_[0].argsort()\n\n# print('Smallest coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:10]))\n# print('Largest coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:11:-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat=vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud=WordCloud(width=1440,height=1080).generate(\" \".join(feat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# larger the size of the word more the times it appears\nplt.figure(figsize=(20,15))\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_vectorized=vect.transform(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression()\nmodel.fit(x_train_vectorized,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict(vect.transform(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc=roc_auc_score(y_test, predictions)\nprint('AUC:',roc_auc)\nfpr,tpr,thresholds=roc_curve(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('ROC for logistic regressio on TF-IDF',fontsize=25)\nplt.plot([0,1], [0,1],'r--')\nplt.plot(fpr,tpr,'b',label='AUC = %0.2f' %roc_auc)\nplt.legend(loc=\"lower right\")\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.ylabel('True positive rate',fontsize=20)\nplt.xlabel('False positive rate',fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# even tho we reduced the number of features considerably\n# AUC did not change much\n\n# let us test our model\nnew_review=['The food was delicious','The food was not good']\nprint(model.predict(vect.transform(new_review)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bigrams\n> Since our classifier missclassifies things like 'not good', we will use bag of words instead of single words. This method is called n grams. Here we take 1 and 2 words into consideration."},{"metadata":{"trusted":true},"cell_type":"code","source":"vect=CountVectorizer(min_df=5, ngram_range=(1,2)).fit(x_train)\nx_train_vactorized=vect.transform(x_train)\nlen(vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat=vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud=WordCloud(width=1440, height=1080).generate(\" \".join(feat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The number of feature has increased again.\n# checking for the AUC\nmodel=LogisticRegression()\nmodel.fit(x_train_vactorized, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict(vect.transform(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc=roc_auc_score(y_test, predictions)\nprint('AUC:',roc_auc)\nfpr,tpr,thresholds=roc_curve(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('ROC for logistic Regression on Bigrams',fontsize=20)\nplt.plot(fpr,tpr,'b', label= 'AUC=%0.2f' %roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.xlim([0,1])\nplt.ylim([0,1])\nplt.ylabel('True positive rate',fontsize=20)\nplt.xlabel('False positive rate',fontsize=20)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}