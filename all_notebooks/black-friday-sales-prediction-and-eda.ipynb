{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet\nimport xgboost as xgb\nfrom xgboost import plot_importance\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the dataset\ndf = pd.read_csv(\"../input/black-friday/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Null Values\ndf.isna().sum(axis = 0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping the Gender \ndf['Gender'] = df['Gender'].replace({\"F\" : \"Female\", \"M\" : \"Male\"})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"#### Distribution of Age group according to Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [12, 9]\nsns.set(style = 'whitegrid', font_scale = 1.3)\nax = sns.countplot('Age', hue = 'Gender',data = df, order = ['0-17', '18-25', '26-35', '36-45', '46-50', '51-55', '55+']);\nax.set(title = \"Distribution of Age group according to Gender\", xlabel = \"Age Group\", ylabel = \"Count\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Product_Category_1 Countplot with respect to Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [20, 10]\nax = sns.countplot('Gender', hue = 'Product_Category_1', data = df);\nax.set(title = \"Product_Category_1 Bargraph with respect to Gender\", xlabel = \"Gender\", ylabel = \"Count\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Product_Category_2 Countplot with respect to Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [20, 10]\nax = sns.countplot('Gender', hue = 'Product_Category_2', data = df);\nax.set(title = \"Product_Category_2 Countplot with respect to Gender\", xlabel = \"Gender\", ylabel = \"Count\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Product_Category_3 Countplot with respect to Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [20, 10]\nax = sns.countplot('Gender', hue = 'Product_Category_3', data = df);\nax.set(title = \"Product_Category_3 Countplot with respect to Gender\", xlabel = \"Gender\", ylabel = \"Count\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Distribution of the Purchase"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [14, 8]\ndist = sns.distplot(df['Purchase'], color = 'lightseagreen')\ndist.set(title = \"Distribution of the Purchase\", xlabel = \"Purchase\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Donut Graph showing Martial status of the customers according to the gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = df['Marital_Status'].groupby(df['Gender']).value_counts()['Female'].values\nb = df['Marital_Status'].groupby(df['Gender']).value_counts()['Male'].values\n\nt = df.Gender.value_counts().values\nt1 = np.array([b, a])\n\nfig, ax = plt.subplots()\nsns.set(font_scale = 1.3)\nsize = 0.3 \n\ncmap = plt.get_cmap(\"tab20b_r\")\nouter_colors = cmap(np.arange(3)*4)\ninner_colors = cmap(np.array([1, 2, 5, 6, 9, 10]))\n\nax.pie(t, radius=1, colors=outer_colors,\n       wedgeprops=dict(width=size, edgecolor='w'), autopct='%.01f%%', labels = ['Male', 'Female'])\n\nax.pie(t1.flatten(), radius=1-size, colors=inner_colors,\n       wedgeprops=dict(width=size, edgecolor='w'), labels = [0, 1, 0, 1])\n\nax.set(aspect=\"equal\", title='Marital Status according to the gender')\nax.legend(['Male', 'Female'], loc = 'best');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"The approach here to fill the null values will be taking the mode(most used product) of the product Category 2 and 3 according to the age group and fill the values in the particular age group."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most Used product according to the age group in the given data\n\nprod_2 = df.groupby('Age')['Product_Category_2'].agg(lambda x:x.value_counts().index[0])\nprod_2 = dict(prod_2)\nprint (prod_2)\n\nprod_3 = df.groupby('Age')['Product_Category_3'].agg(lambda x:x.value_counts().index[0])\nprod_3 = dict(prod_3)\nprint (prod_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since the most used product in product category 3 for all age group is 16.0 so, fillna can be used\ndf.Product_Category_3.fillna (value = 16.0, inplace = True)\n\n# Filling the null values of the product category 2\nfor i in range(len(df)):\n    if np.isnan(df.iloc[i, 9]) == True:\n        key = df.iloc[i, 3]\n        df.iloc[i, 9] = prod_2[key]\n        \ndf['Product_Category_2'] = df['Product_Category_2'].astype(int)\ndf['Product_Category_3'] = df['Product_Category_3'].astype(int)\n\nprint (\"Null values present : \")\ndf.isna().sum(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Unique product ID : \", df.Product_ID.nunique())\nprint (\"Size of the data set : \", df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the ProductID into numeric data\nprint (\"The Product IDs containing the P00 : \", df.Product_ID.str.contains('P00').sum())\n\ndf.Product_ID = df.Product_ID.str.replace(\"P00\", \"\")\ndf.Product_ID = df.Product_ID.astype(int)\n\n# Normalizing the User_ID\ndf.User_ID = df.User_ID - 1000000\ndf.User_ID\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing age to numerical data\nage = df['Age'].unique().tolist()\nprint (age)\ndict_age = dict(zip(age, [17, 60, 35, 50, 55, 45, 25]))\n\nprint (dict_age)\ndf.Age = df.Age.map(dict_age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing stay years to numerical data\nstay = df.Stay_In_Current_City_Years.unique().tolist()\nprint (stay)\ndict_stay = dict(zip(stay, [2, 4, 3, 1, 0]))\n\nprint (dict_stay)\ndf.Stay_In_Current_City_Years = df.Stay_In_Current_City_Years.map(dict_stay)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the rest of the categorical variables to numeric data\n\nlabel_encoder_feat = {}\nfor feature in ['Gender', 'City_Category']:\n    label_encoder_feat[feature] = preprocessing.LabelEncoder()\n    df[feature] = label_encoder_feat[feature].fit_transform(df[feature])\n\nprint(df.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset in 80:20 ratio for training:testing\n\nYtr = df['Purchase']\nXtr = df.drop(columns = ['Purchase'])\n\nX_train, X_test, y_train, y_test = train_test_split(Xtr, Ytr, test_size = 0.20, random_state=0)\n\nprint (\"The shape of the training data : \", X_train.shape)\nprint (\"The shape of the testing data  : \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training\nlin_reg = LinearRegression(normalize = True).fit(X_train,y_train)\n\n# Predictions\npredictions = lin_reg.predict(X_test)\n\n# Scores\nprint (\"RMSE : \", math.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint (\"MAE  : \", metrics.mean_absolute_error(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Polynomial Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforming data\npoly = preprocessing.PolynomialFeatures(degree = 2)\n\nX_poly = poly.fit_transform(Xtr)\nX_poly, X_test_poly, y_poly, y_test_poly = train_test_split(X_poly, Ytr, test_size = 0.20, random_state=0)\n\npol_reg = LinearRegression().fit(X_poly,y_poly)\n\n# Predictions\npredictions = pol_reg.predict(X_test_poly)\n\n# Scores\nprint (\"RMSE : \", math.sqrt(metrics.mean_squared_error(y_test_poly, predictions)))\nprint (\"MAE  : \", metrics.mean_absolute_error(y_test_poly, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Lasso Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training\nlinlasso = Lasso(alpha = 1,max_iter = 1000).fit(X_train, y_train)\n\n# Predictions\npredictions = linlasso.predict(X_test)\n\n# Scores\nprint (\"RMSE : \", math.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint (\"MAE  : \", metrics.mean_absolute_error(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training\nxgb_reg = xgb.XGBRegressor(objective ='reg:linear',\n                           colsample_bytree = 0.3,\n                           learning_rate = 0.05,\n                           max_depth = 10,\n                           alpha = 10,\n                           n_estimators = 1000)\n\nxgb_reg.fit(X_train, y_train)\n\n# Predictions\npredictions = xgb_reg.predict(X_test)\n\n# Scores\nprint (\"RMSE : \", math.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint (\"MAE  : \", metrics.mean_absolute_error(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance plot\nplot_importance(xgb_reg);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ElasticNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training\nelastic_reg = ElasticNet(random_state=0)\nelastic_reg.fit(X_train, y_train)\n\n# Predictions\npredictions = elastic_reg.predict(X_test)\n\n# Scores\nprint (\"RMSE : \", math.sqrt(metrics.mean_squared_error(y_test, predictions)))\nprint (\"MAE  : \", metrics.mean_absolute_error(y_test, predictions))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}