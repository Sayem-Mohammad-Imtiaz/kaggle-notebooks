{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nimport pickle\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport shutil\nimport random","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1) Data cleaning:"},{"metadata":{},"cell_type":"markdown","source":"## Firstly, all the images were changed from `png format to jpg format`, however, the updated folder `datacleaningglassesnoglasses` contains already this mentioned change"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Glasess:"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"../input/datacleaningglassesnoglasses/glasses.txt\", \"rb\") as fp:\n    glasses = pickle.load(fp)\nplt.figure(figsize=(12, 12))\nran_num = []\nfor i in range(0,9):\n    n = random.randint(0,len(glasses))\n    ran_num.append(n)\nfor i in range(9):\n    ax= plt.subplot(3, 3, i + 1)\n    plt.imshow(mpimg.imread(glasses[ran_num[i]]))\n    plt.title(\"glasses\")\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## No glasses:"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"../input/datacleaningglassesnoglasses/no_glasses.txt\", \"rb\") as fp: \n    no_glasses = pickle.load(fp)\nplt.figure(figsize=(12, 12))\nran_num = []\nfor i in range(0,9):\n    n = random.randint(0,len(no_glasses))\n    ran_num.append(n)\nfor i in range(9):\n    ax= plt.subplot(3, 3, i + 1)\n    plt.imshow(mpimg.imread(no_glasses[ran_num[i]]))\n    plt.title(\"no_glasses\")\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## No clear:"},{"metadata":{},"cell_type":"markdown","source":"### The data is created `artificially`, hence, in some photos it was not clear wheter the photos belong to the class `glasses` or `no_glasses`"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"../input/datacleaningglassesnoglasses/no_clear.txt\", \"rb\") as fp: \n    no_clear = pickle.load(fp)\nplt.figure(figsize=(12, 12))\nran_num = []\nfor i in range(0,9):\n    n = random.randint(0,len(no_clear))\n    ran_num.append(n)\nfor i in range(9):\n    ax= plt.subplot(3, 3, i + 1)\n    plt.imshow(mpimg.imread(no_clear[ran_num[i]]))\n    plt.title(\"no_clear\")\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The length of the different groups:\" + \"-Glasses: \" + str(len(glasses)) + \" -No glasses: \" + str(len(no_glasses)) + \" -No clear: \" + str(len(no_clear)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### It seems the data is `imbalance` there are `much more glasses images than no glasses images`. On the other hand, `77 images` are not going to be used in the model because are `not clear`"},{"metadata":{},"cell_type":"markdown","source":"## The next model is based on Tensorflow/Learn/Tutorials/Images/Transfer learning and fine-tuning - https://www.tensorflow.org/tutorials"},{"metadata":{},"cell_type":"markdown","source":"# 2) Data processing:"},{"metadata":{},"cell_type":"markdown","source":"## In this project a `classification model` will be created in order to classify images of people with glasses and no glasses"},{"metadata":{},"cell_type":"markdown","source":"## The `random seed` is going to be applied, it will be used along all the model. In this way we will be sure that the same random seed is applied when it is optional to be called"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.random.set_seed(123456)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## To this end several parameteres are going to be selected, firstly the `batch size equal to 32`, and the `image size (height and width) equal to 160`"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nIMG_SIZE = (160, 160)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_images= glasses + no_glasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir= \"/kaggle/input/datacleaningglassesnoglasses/Images/Images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## After selecting the parameters, we are ready to split the data, in this case it will be separated as per below:\n- 70% Training data\n- 30% Validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.3,\n    subset=\"training\",\n    shuffle=True,\n    seed=123456,\n    image_size= IMG_SIZE,\n    batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.3,\n    subset=\"validation\",\n    shuffle=True,\n    seed=123456,\n    image_size= IMG_SIZE,\n    batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## It seems the train_dataset contains 4920 images, and the validation_datset 1476, out of 4920 files"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = train_dataset.class_names\nprint(class_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Below we can see `some images from the train_dataset`, as we can observe there are from the two desired classes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = train_dataset.class_names\n\nplt.figure(figsize=(12, 12))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Currently we have the `train_dataset` and `validation_dataset` created, however it is important to have also a `small split to test the model`, test_dataset. This will be `20% of the validation_dataset`, this means, more or less `6%`"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_batches = tf.data.experimental.cardinality(validation_dataset)\ntest_dataset = validation_dataset.take(val_batches // 5)\nvalidation_dataset = validation_dataset.skip(val_batches // 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of training batches: %d' % tf.data.experimental.cardinality(train_dataset))\nprint('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## This configuration allows the model to speed up the training process¶"},{"metadata":{},"cell_type":"markdown","source":"## The Dataset.prefetch() function used in the three splits, overlaps data preprocessing and model execution during the training process"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Preparing base model:"},{"metadata":{},"cell_type":"markdown","source":"## 3.1) Data augmentation¶"},{"metadata":{},"cell_type":"markdown","source":"### Data augmentation is an optional step which introduces several artificial observations to the training sample.\n### In this model we are going to introduce two data augmentations:¶"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Below we can find the results of the data augmentation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, _ in train_dataset.take(1):\n    plt.figure(figsize=(12, 12))\n    first_image = image[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0] / 255)\n        plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2) Rescale pixel values:¶"},{"metadata":{},"cell_type":"markdown","source":"### Firstly, the application `MobileNetV2` will be downloaded, which is going to be used as a base for the model. This is a way of performing transfer learning, which consists in using a training learning from a pre-trained network"},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This model expects `pixel values between -1 and 1`, hence the images should be `preprocessed`"},{"metadata":{"trusted":true},"cell_type":"code","source":"rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3) Creating base model from MobileNet V2"},{"metadata":{},"cell_type":"markdown","source":"### The base model `MobileNet V2` was developed by Google\n### It contains a large dataset with `1.4 million of images` and `1000 classes`\n### It is important to include `include_top=False` because the classification layers previously created should be included"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This feature extractor converts the images from `160x160x3` to `5x5x1280`"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.4) Feature extraction"},{"metadata":{},"cell_type":"markdown","source":"### First of all, we should `freeze the convolutional base` created from the previous step, because it is going to be used as a `feature extractor`"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.5) Adding classification head"},{"metadata":{},"cell_type":"markdown","source":"### The layer `tf.keras.layers.GlobalAveragePooling2D` is going to be used, in order to convert the features in a `1280-element vector`, per each image"},{"metadata":{"trusted":true},"cell_type":"code","source":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### `tf.keras.layers.Dense` is a layer that converts the features into a `single prediction`"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_layer = tf.keras.layers.Dense(1)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### It is time to apply the previous process to the model:\n- `Data augmentation`\n- `Rescaling`\n- `Basel model`\n- `Feature extractor`"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = tf.keras.Input(shape=(160, 160, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.6) Compilation of the model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There are `two variable objects`. Divided between around `2.5 million of MobilNet` parameters which are `frozen`, and `1.2 thousend` of trainable parameter in the `Dense layer`"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(model.trainable_variables)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.7) Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_epochs = 10\nloss0, accuracy0 = model.evaluate(validation_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit = model.fit(train_dataset,\n                    epochs= initial_epochs,\n                    validation_data= validation_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = model_fit.history['accuracy']\nval_acc = model_fit.history['val_accuracy']\nloss_ = model_fit.history['loss']\nval_loss_ = model_fit.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## 3.8) Results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss_, label='Training Loss')\nplt.plot(val_loss_, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As it can be seen in the graphs the `accuracy` along the `10 epochs` was `really similar` for the `validation` and `training` samples\n### However, it seems that for some epochs the model works slighty better in the `validation sample` than in the `training sample`. This probably happened due to the application of some layers like `tf.keras.layers.BatchNormalization` and `tf.keras.layers.Dropout`, which are applied during the `training process`"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(test_dataset)\nloss, accuracy1 = model.evaluate(train_dataset)\nprint('Test accuracy :', accuracy)\nprint('Train accuracy :', accuracy1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) Model with fine tunning"},{"metadata":{},"cell_type":"markdown","source":"### This model is a continuation of the `Model 1`, however, a `fine tunning`process will be applied in order to `increase the performance`\n### During the previos process the `weights of the pre-trained network` were `not updated` during the training.\n### However, it is possible to increase the performance applying these `weights`"},{"metadata":{},"cell_type":"markdown","source":"## 4.1) Unfreeze the top layers of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of layers in the base model: \", len(base_model.layers))\nfine_tune_at = 100\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2) Compile the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(model.trainable_variables)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3) Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_tune_epochs = 5\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nmodel_fit_fine = model.fit(train_dataset,\n                         epochs= total_epochs,\n                         initial_epoch= model_fit.epoch[-1],\n                         validation_data= validation_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc += model_fit_fine.history['accuracy']\nval_acc += model_fit_fine.history['val_accuracy']\nloss_ += model_fit_fine.history['loss']\nval_loss_ += model_fit_fine.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4) Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss_, label='Training Loss')\nplt.plot(val_loss_, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(test_dataset)\nloss, accuracy1 = model.evaluate(train_dataset)\nloss, accuracy2 = model.evaluate(validation_dataset)\nprint('Test accuracy :', accuracy)\nprint('Train accuracy :', accuracy1)\nprint('Validation accuracy :', accuracy2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As it can be seen in the `training` and `test`samples the accuracy is really high, greater than 0.99, hence this `model is robust` and `works really well`"},{"metadata":{},"cell_type":"markdown","source":"# 5) Prediction"},{"metadata":{},"cell_type":"markdown","source":"### In this case the `Model 2 with fine tuning` will be applied, as the performance of the same was better. The prediction is going to be done in the `test sample`"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, label_batch = test_dataset.as_numpy_iterator().next()\npredictions = model.predict_on_batch(image_batch).flatten()\n\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)\n\nprint('Predictions:\\n', predictions.numpy())\nprint('Labels:\\n', label_batch)\n\nplt.figure(figsize=(12, 12))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].astype(\"uint8\"))\n    plt.title(class_names[predictions[i]])\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As per the results, it looks like that the `model classified perfectly the images`, it can be seen that the array of `Predictions` is the same as `Labels`"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}