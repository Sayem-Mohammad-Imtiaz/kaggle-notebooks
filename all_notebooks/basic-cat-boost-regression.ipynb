{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nHello there!\nThis notebook describes how to implement basic CatBoost regression.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Analysis\nTo begin we first importing everything we need, then we going to check our data.","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing, model_selection\nimport sklearn\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_absolute_error\nimport os\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is 1 csv file in the current version of the dataset:\n","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndata = pd.read_csv('/kaggle/input/new_data_99_06_03_13_04.csv', delimiter=',')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check the data!","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data.shape\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see some NaN values, lets check how many NaNs we got.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"len(data) - data.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets also check unique values of each column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data[:].nunique()\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that about 63% of data in 'Владение' is missing. We going to drop this. Also we going to drop 'description' columns since in have only text description, that we can use in NLP but not in this case. Aswell we should drop those 1-7 NaNs wich are not very important given the volume of other data. 'Таможня' column got only 1 value, so its going to be dropped too.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Таможня', 'description'], axis='columns', inplace=False)\ndata = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the data for NaNs again and lets check the data types of columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data) - data.count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see - there are zero NaN values. Columns of data contains lot of objects. For various purposes (for example, to visualize correlations), we need to convert those objects to numbers. In this case we can use Lable Encoder, wich is pretty easy to implement.","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ncategorical_columns = data.columns[data.dtypes == 'object']\n\nfor column in categorical_columns:\n    data[column] = le.fit_transform(list(data[column]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a quick look at types now, again.","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Now we can implement some correlation visualisation.","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,8))\nax1 = fig.add_subplot(111)\nplt.imshow(data.corr(), cmap='hot', interpolation='nearest')\nplt.colorbar()\nlabels = data.columns\nax1.set_xticks(np.arange(len(labels)))\nax1.set_yticks(np.arange(len(labels)))\nax1.set_xticklabels(labels,rotation=90, fontsize=10)\nax1.set_yticklabels(labels,fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see both negative and positive correlations between price and features like enginepower, mileage and etc. To tune the prediction model we should drop features with low correlation, maybe generate some new features...but this is base-lane notebook, so we try to train model with all those features and and we'll see what happens.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Building the model\nLets build the model and try to predict price of cars with features we got.","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"predict = 'Price'\n\nX = np.array(data.drop([predict], 1))\ny = np.array(data[predict])\n\nx_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n\nmodel = CatBoostRegressor(learning_rate=0.5)\nmodel.fit(x_train, y_train)\naccuracy = model.score(x_test, y_test)\nprint('Accuracy of model:', accuracy)\n\npredictions = model.predict(x_test)\nmae = mean_absolute_error(predictions, y_test)\nprint(\"Mean Absolute Error:\", mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nWithout any model tuning or feature engineering we got 90-93 pepercents accuracy, wich is pretty good. You can achive way more better scores with those key items i mentioned before - feature engineering and tuning the model.\nFeel free to comment and fork this notebook, stay safe.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}