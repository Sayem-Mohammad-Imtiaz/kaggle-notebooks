{"cells":[{"metadata":{},"cell_type":"markdown","source":"## MeLi Data Challenge\n\nThis notebook is a quick start where we are going to preprocess and merge the original data to a more \"pandas-like\" format. Intermediate datasets will be saved to pickle files\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfrom datetime import datetime\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_json(\"/kaggle/input/meli-data-challenge-2020/train_dataset.jl\", lines=True, orient='columns')\ntrain_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adapted from https://github.com/Santivg/ml-challenge\n\ndef preprocess_hist(df):\n    df['user_view']= pd.Series(dtype='object')\n    df['timestamps']= pd.Series(dtype='object')\n    df['user_search']= pd.Series(dtype='object')\n    df['search_timestamps']= pd.Series(dtype='object')\n\n    for i in df.index:\n        lista_view=[]\n        lista_time=[]\n        lista_search=[]\n        lista_search_t=[]\n        for item in df.user_history[i]:\n            if item['event_type'] =='view':\n                lista_view.append(int(item['event_info']))\n                time_string=item['event_timestamp'].replace(\"T\", \" \").split('.')[0]\n                timestamp=datetime.timestamp(datetime.strptime(time_string, '%Y-%m-%d %H:%M:%S'))\n                lista_time.append(int(timestamp))\n            if item['event_type'] =='search':\n                lista_search.append(item['event_info'])\n                time_string=item['event_timestamp'].replace(\"T\", \" \").split('.')[0]\n                timestamp=datetime.timestamp(datetime.strptime(time_string, '%Y-%m-%d %H:%M:%S'))\n                lista_search_t.append(int(timestamp))\n\n        df.at[i,'user_view']= lista_view\n        df.at[i,'timestamps']= lista_time\n\n        df.at[i,'user_search']= lista_search\n        df.at[i,'search_timestamps']= lista_search_t\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train part\ntrain_data = preprocess_hist(train_data)\ntrain_data.drop('user_history', axis=1, inplace=True)\ntrain_data.to_pickle('train.pickle')\ntrain_data.head(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**item_bought:** ID for the purchased item\n\n**user_view:** List of IDs for each item that the user has seen in the last week\n\n**timestamps:** List of timestamps for each visualization\n\n**user_search:** List of search tokens in the last week\n\n**search_timestamps:** List of timestamps for each search"},{"metadata":{"trusted":true},"cell_type":"code","source":"# same for the test set\ntest_data = pd.read_json(\"/kaggle/input/meli-data-challenge-2020/test_dataset.jl\", lines=True, orient='columns')\ntest_data = preprocess_hist(test_data)\ntest_data.drop('user_history', axis=1, inplace=True)\ntest_data.to_pickle('test.pickle')\ntest_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape, test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Products"},{"metadata":{"trusted":true},"cell_type":"code","source":"item_data = pd.read_json(\"/kaggle/input/meli-data-challenge-2020/item_data.jl\", lines=True, orient='columns')\nitem_data.to_pickle('products.pickle')\nitem_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Join item_bought metadata (only available for training set)"},{"metadata":{"trusted":true},"cell_type":"code","source":"rename_dict = {\n    'title': 'bought_title', 'domain_id': 'bought_domain_id', 'price': 'bought_price',\n    'category_id': 'bought_category_id', 'condition': 'bought_condition'\n}\n\n# remove/change two columns from item data\nitem_data['condition'] = item_data.condition.map({'new': 0, 'used': 1, 'not_specified': 2})\nitem_data.drop('product_id', axis=1, inplace=True)\n\n# merge on item_bought id\ntrain_data = train_data.merge(item_data, left_on='item_bought', right_on='item_id', how='left')\ntrain_data = train_data.drop('item_id', axis=1).rename(rename_dict, axis=1)\ntrain_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Melt data and merge user_view data\n\nMelt the list of products that each user has seen (user_view column) and merge the metadata for the product."},{"metadata":{"trusted":true},"cell_type":"code","source":"def melt_views(df):\n    views = df[[c for c in df.columns if c != 'user_search' and c != 'search_timestamps']]\n    views = views.reset_index().rename({'index': 'row_id'}, axis=1)\n\n    views = views.set_index(['row_id']).apply(pd.Series.explode).reset_index()\n    views = views[~views.user_view.isna()]  # remove purchases with no previous views\n    return views.merge(item_data, left_on='user_view', right_on='item_id', how='left').drop('item_id', axis=1)\n\nviews_data = melt_views(train_data)\nviews_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"views_data.to_pickle('train_views.pickle')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Corpus size (number of itens):\", item_data.item_id.nunique())\nprint(\"Number of domains:\", item_data.domain_id.nunique())\nprint(\"Number of categories:\", item_data.category_id.nunique())\nprint(\"\\nTop domains:\")\nprint(item_data.domain_id.value_counts().head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 2.1 million items in 7.894 domains and 11.493 categories"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"items_count = views_data.groupby('row_id')['user_view'].count()\nplt.figure(figsize=(10, 4))\nplt.title(\"Views distribution number for user\")\np = sns.distplot(items_count, bins=100)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"views_data['same_item'] = (views_data.item_bought == views_data.user_view).astype('int8')\nsame_item = views_data.groupby('row_id')['same_item'].max()\nplt.title(\"Has seen the item before buying it? (item_bought is in user_view list)\")\np = sns.countplot(same_item)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hope this notebook helps as a quick start for this dataset."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}