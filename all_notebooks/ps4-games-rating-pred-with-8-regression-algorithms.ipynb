{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PS4 games rating predictions\n## *Comparing 8 regression algorithms*\n\n![video games](https://i.imgur.com/9U3sXgz.png)","metadata":{}},{"cell_type":"markdown","source":"# Table of contents\n\n[<h3>1. Data Description</h3>](#1)\n\n[<h3>2. Data Preprocessing</h3>](#2)\n\n[<h3>3. Model comparison</h3>](#3)\n\n[<h3>4. Prediction metrics of the best model using the test set</h3>](#4)\n\n[<h3>5. Visualization of the result</h3>](#5)\n\n## Context\nThis dataset include all games for PlayStation 4 for the present.\nI used the truetrophies website to create this dataset.\n\n## Content\nYou can find 1 datasets :\ngames_data.csv: contend up to date list of PlayStation 4 (PS4) games , games name and some details like score, rating for each game etc.\n\nThis dataset includes 1584 games information\n\n","metadata":{}},{"cell_type":"markdown","source":"# Load the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, LinearRegression, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom time import perf_counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Markdown, display\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Description<a class=\"anchor\" id=\"1\"></a><a class=\"anchor\" id=\"1\"></a>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/ps4-games/games_data.csv', index_col = 0)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n\ndf['rating'].plot.hist(by='rating',ax = axes[0], color = '#ff8c8e')\naxes[0].set_title('Rating\\'s histogram', fontsize = 15)\n\ndf['rating'].plot.box(ax = axes[1])\naxes[1].set_title('Rating\\'s Boxplot', fontsize = 15)\n\nsns.violinplot(ax = axes[2], y = 'rating', data = df, color = '#ff8c8e')\naxes[2].set_title('Rating\\'s distribution (violinplot)', fontsize = 15)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printmd(f'### Number of rows in the dataset: {df.shape[0]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Preprocessing<a class=\"anchor\" id=\"2\"></a><a class=\"anchor\" id=\"2\"></a>","metadata":{}},{"cell_type":"code","source":"def preprocessing(df):\n    df = df.copy()\n    \n    # Drop game and URL columns\n    df = df.drop('game', axis=1)\n    df = df.drop('url', axis=1)\n    \n    # Shuffle the data\n    df = df.sample(frac=1.0, random_state=0).reset_index(drop=True)\n    \n    X = df.drop('rating', axis=1)\n    y = df['rating']\n    \n    X = pd.DataFrame(X, index=X.index, columns=X.columns)\n    \n    return X, y\n\n# Preprocessing\nX,y = preprocessing(df)\n\n# Split into a training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# Scale the datasets\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Display the result\nX_train[:2], y_train[:2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model comparison<a class=\"anchor\" id=\"3\"></a><a class=\"anchor\" id=\"3\"></a>","metadata":{}},{"cell_type":"code","source":"models = {\n    \"LinearRegression\":{\"model\":LinearRegression() },\n    \"Lasso\":{\"model\":Lasso() },\n    \"Ridge\":{\"model\":Ridge() },\n    \"DecisionTreeRegressor\":{\"model\":DecisionTreeRegressor() },\n    \"RandomForestRegressor\":{\"model\":RandomForestRegressor() },\n    \"MLPRegressor\":{\"model\":MLPRegressor() },\n    \"GradientBoostingRegressor\":{\"model\":GradientBoostingRegressor() },\n    \"AdaBoostRegressor\":{\"model\":AdaBoostRegressor() }\n}\n\n# Use the K-fold cross validation for each model\n# to get the mean validation accuracy and the mean training time\nk = 10\nfor name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    result = cross_validate(model, X_train,y_train, cv = k, scoring='neg_mean_squared_error')\n    \n    # Mean accuracy and mean training time\n    result['test_score'] = result['test_score']\n    mean_RMSE = [(-x)**0.5 for x in result['test_score']] # Root Mean Square Error\n    mean_RMSE = sum(mean_RMSE)/len(mean_RMSE)\n    mean_RMSE = round(mean_RMSE,4)\n    mean_fit_time = round( sum(result['fit_time']) / len(result['fit_time']), 4)\n    \n    # Add the result to the dictionary witht he models\n    m['mean_RMSE'] = mean_RMSE\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} mean MSRE for {k}-fold CV: {mean_RMSE} - mean training time {mean_fit_time} sec\")","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    lst = [name, v['mean_RMSE'],v['Training time (sec)']]\n    models_result.append(lst)\n\ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','RMSE','Training time (sec)'])\ndf_results.sort_values(by='RMSE', ascending=True, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'RMSE', data = df_results)\nplt.title(f'{k}-fold mean RMSE for each Model\\nSmaller is better', fontsize = 15)\n# plt.ylim(0.8,1.005)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('RMSE',fontsize=15)\nplt.xticks(rotation=90, fontsize=12)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\nplt.title('Training time for each Model in sec\\nSmaller is better', fontsize = 15)\nplt.xticks(rotation=90, fontsize=12)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Training time (sec)',fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Prediction metrics of the best model using the test set<a class=\"anchor\" id=\"4\"></a><a class=\"anchor\" id=\"1\"></a>","metadata":{}},{"cell_type":"code","source":"# Get the model with the highest mean validation accuracy\nbest_model = df_results.iloc[0]\n\n# Fit the model\nmodel = models[best_model[0]]['model']\nmodel.fit(X_train,y_train)\n\n# Predict the labels with the data set\npred = model.predict(X_test)\n\nMSRE = mean_squared_error(y_test,pred)**0.5\nMSRE = round(MSRE, 2)\n\n# Display the results\nprintmd(f'### Best Model: {best_model[0]} with a MSRE of {MSRE} on the test set')\nprintmd(f'### Trained in: {best_model[2]} sec')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Visualization of the result<a class=\"anchor\" id=\"5\"></a>","metadata":{}},{"cell_type":"code","source":"# Concatenate the ratings of the test set\n# with the predictions of those ratings\npred_s = pd.Series(pred)\ny_test_s = y_test.reset_index(drop=True)\n\ndf_result = pd.concat([y_test_s,pred_s], axis = 1)\ndf_result.columns = ['Real Rating', 'Predicted Rating']\ndf_result.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result.plot.box()\nplt.title('Boxplot Real Rating VS Predicted Rating', fontsize = 15)\nplt.show()\n\ndf_result.plot.scatter(x='Real Rating', y='Predicted Rating')\nplt.title('Scatterplot Real Rating VS Predicted Rating', fontsize = 15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}