{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Lead Score Case Study","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing all the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns \nfrom matplotlib.pyplot import xticks\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import precision_recall_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/leads-dataset/Leads.csv' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf = pd.read_csv( path )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.describe( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.info( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Finding the missing values - ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"'Select' value is similiar to missing value, as the user did not select the option for a given dropdown feild.\nThus is best to convert it to nan and then try handling the missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf = leadScoreDf.replace('Select', np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for null values for all the columns\nleadScoreDf.isnull( ).sum( axis = 0 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the percentages would give a better insight - \nround( 100*( leadScoreDf.isnull( ).sum( )/len( leadScoreDf.index ) ), 2 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the percentages of the missing values are not that high( mostly around 30% ), we can impute the missing values depending on the values of the caolumn\nFor e.g. if it is a categorical variable, we can impute the missing value with mode.\n\nHowever columns with more than 70% missing values should be dropped.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Imputing the columns - ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Imputing the columns, based on the % of missing values starting with the highest % - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping columns with more than 70% missing values - \n\nleadScoreDf = leadScoreDf.drop( leadScoreDf.loc[:,list( round( 100*( leadScoreDf.isnull().sum()/len( leadScoreDf.index ) ), 2 ) > 70 ) ].columns, 1 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lead Quality - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Lead Quality' ].describe( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Lead Quality' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing the missing values for 'Lead Quality' with 'Not sure' as we are imputing the columns based on intuition and not some logic.\nWe cannot impute them with 'Might be', even though it has the highest count as it can be quite misleading.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Lead Quality' ] = leadScoreDf[ 'Lead Quality' ].replace( np.nan, 'Not sure' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Asymmetrique -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2,2, figsize = (10,8))\nplt1 = sns.countplot(leadScoreDf['Asymmetrique Activity Index'], ax = axs[0,0])\nplt2 = sns.boxplot(leadScoreDf['Asymmetrique Activity Score'], ax = axs[0,1])\nplt3 = sns.countplot(leadScoreDf['Asymmetrique Profile Index'], ax = axs[1,0])\nplt4 = sns.boxplot(leadScoreDf['Asymmetrique Profile Score'], ax = axs[1,1])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Asymmetrique Activity Index' ].describe( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Asymmetrique Activity Index' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Asymmetrique Profile Index' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Asymmetrique Activity Score' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Asymmetrique Profile Score' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the value counts and the plots, we can see that the values are varying.\nIt would be the best if we would just drop the column rather than imputing the missing values.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf = leadScoreDf.drop( [ 'Asymmetrique Activity Index','Asymmetrique Activity Score',\n                                 'Asymmetrique Profile Index','Asymmetrique Profile Score' ], 1 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### City -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'City' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the value counts, we can see that 'Mumbai' is most common city.\nWe can impute missing values with 'Mumbai'\n\n\nThis column can be dropped as well as X is an online Education system. City and Country does not really matter","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['City'] = leadScoreDf['City'].replace( np.nan, 'Mumbai' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tags -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Tags' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'Will revert after reading the email' is the most commonly selected option.\nWe can impute the missing values with this option","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Tags' ] = leadScoreDf[ 'Tags' ].replace( np.nan, 'Will revert after reading the email' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Specialization - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Specialization' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even though, the most commonly used option is 'Finance', lead may have some specialization which is not mentioned in the options.\nIt would be better to impute the missing values with 'Others'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Specialization' ] = leadScoreDf[ 'Specialization' ].replace( np.nan, 'Others' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### What is your current occupation - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'What is your current occupation'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'Unemployed' would be the best option for imputing the missing values as it the mode for this column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'What is your current occupation'] = leadScoreDf[ 'What is your current occupation'].replace( np.nan, 'Unemployed' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### What matters most to you in choosing a course -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'What matters most to you in choosing a course' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As mode of the column is 'Better Career Prospects', we will impute the missing values with this option.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['What matters most to you in choosing a course'] = leadScoreDf['What matters most to you in choosing a course'].replace( np.nan, 'Better Career Prospects' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Country -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Country' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Imputing the missing values with 'India'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'Country' ] = leadScoreDf[ 'Country' ].replace( np.nan, 'India' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rest of the missing values are below 2%, and thus those rows can be dropped","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.dropna( inplace = True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the % of missing values after the imputation - \nround( 100*( leadScoreDf.isnull( ).sum( )/len( leadScoreDf.index ) ), 2 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can drop the last five columns as they have only 1 unique value\nleadScoreDf.drop(['Receive More Updates About Our Courses', 'Update me on Supply Chain Content', 'Get updates on DM Content', 'Magazine',  \n       'I agree to pay the amount through cheque'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping Prospect ID & Lead Number as they are only IDs\nleadScoreDf.drop(['Prospect ID','Lead Number'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for var in leadScoreDf.select_dtypes(exclude = ['int64', 'float64']).columns:\n    print(leadScoreDf[var].value_counts(), '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that the data is cleaned, we can start with exploring the data and try to find patters","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Lead Origin-","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can analyze how many leads got converted and how the lead originated","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"Lead Origin\", hue = \"Converted\", data = leadScoreDf )\nxticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the graph, we can see that -\n- most conversions have been when the lead is on 'Landing Page'.\n- The least conversions are for lead Imports\n\nTo increase the conversion rate, 'Lead Add Form' and 'Lead Import' will have to be improved","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Lead Source-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"Lead Source\", hue = \"Converted\", data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Lead Source'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the categories for 'Lead Source' have almost negligible entries, thus we can combine them into 1 category 'Others'\nAlso there are 2 variations for google i.e. 'Google' and 'google'. We should change this and only keep 1 category.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Lead Source'] = leadScoreDf[ 'Lead Source'].replace(['Click2call', 'Live Chat', 'NC_EDM', 'Pay per Click Ads', 'Press_Release',\n  'Social Media', 'WeLearn', 'bing', 'blog', 'testone', 'welearnblog_Home', 'youtubechannel'], 'Others')\n\nleadScoreDf['Lead Source']  = leadScoreDf[ 'Lead Source' ].replace( 'google', 'Google' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"Lead Source\", hue = \"Converted\", data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the updated plot, we can observe the following -\n- Most of the conversions are for 'Google' and 'Direct Traffic'\n- Others, Facebook and Reference have a very low conversion rate","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Do not Email and Do Not Call - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1,2, figsize = (10,8))\nplt1 = sns.countplot(x = \"Do Not Email\", hue = \"Converted\", data = leadScoreDf, ax = axs[ 0]  )\nxticks( rotation = 90 )\n\nplt2 = sns.countplot(x = \"Do Not Call\", hue = \"Converted\", data = leadScoreDf, ax = axs[ 1 ] )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Leads who select 'No' i.e. want the email communications, tend to have a higher conversion rate then people who dont want the email communications\n- Leads who dont want calls are never converted.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Last Activity -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"Last Activity\", hue = \"Converted\", data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"categories like - \n- 'Had a Phone Conversation', \n- 'Visited Booth in Tradeshow', \n- 'Approached upfront', \n- 'Resubscribed to emails',\n- 'Email Marked Spam' \n\nhave very low/negligible values.\nIt would be best to merge these columns into a single category 'Other Activity'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Last Activity'] = leadScoreDf['Last Activity'].replace(['Had a Phone Conversation', 'View in browser link Clicked', \n                                                       'Visited Booth in Tradeshow', 'Approached upfront',\n                                                       'Resubscribed to emails','Email Received', 'Email Marked Spam'], 'Other Activity')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"Last Activity\", hue = \"Converted\", data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the updated plot, we can see that the leads who 'Opened the email' have the highest conversion rates, followed by Leads who 'Sent SMS'.\nThe least conversions have happened for Leads 'Other Activity' and leads who 'Unsubscribed'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Country - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize = (15,5))\nsns.countplot(x = \"Country\", hue = \"Converted\", data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the values for Country is 'India' followed by 'Russia' and the rest are all negligible values.\nAs the company is an online education system, the Country doesnt really matter and it can be dropped.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.drop( 'Country', inplace = True, axis = 1 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Specialization -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize = (15,5))\nsns.countplot(x = \"Specialization\", hue = \"Converted\", data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can determine that most of the conversions are for the 'Others' category of specialization.\n\nFocus should be put on improving the conersion rates of categories like 'Retail Management', 'Services Excellence','E-Business'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### What is your current occupation and  What matters most to you in choosing a course - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2,1, figsize = (15,10))\nplt1 = sns.countplot(y = \"What is your current occupation\", hue = \"Converted\", data = leadScoreDf, ax = axs[ 0]  )\nxticks( rotation = 90 )\n\nplt2 = sns.countplot(y = \"What matters most to you in choosing a course\", hue = \"Converted\", data = leadScoreDf, ax = axs[ 1 ] )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['What matters most to you in choosing a course'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 'What is your current occupation', most of the entries are 'Unemployed' and they have a high conversion rate.\n\n\nIn 'What matters most to you in choosing a course' has only 1 value for 'Flexibility & Convience' and 'Other'. Thus providing no real information. It would be better to drop this column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.drop( 'What matters most to you in choosing a course', inplace = True, axis = 1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'Others' category is already present in Specialization, it would be better to rename this category to 'Other Occupation'\nleadScoreDf['What is your current occupation'] = leadScoreDf['What is your current occupation'].replace( 'Others', 'Other Occupation' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Search - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot( x = 'Search', hue = 'Converted', data = leadScoreDf )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Search'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the values are 'No', no inference can be drawn from this column.\nIt would be best to drop this column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.drop( 'Search', axis = 1, inplace = True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Newspaper Article and Newspaper-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1,3, figsize = (15,5))\nplt1 = sns.countplot(x = \"Newspaper Article\", hue = \"Converted\", data = leadScoreDf, ax = axs[ 0]  )\nxticks( rotation = 90 )\n\nplt2 = sns.countplot(x = \"Newspaper\", hue = \"Converted\", data = leadScoreDf, ax = axs[ 1 ] )\nxticks( rotation = 90 )\n\nplt2 = sns.countplot( x = 'Digital Advertisement', hue = 'Converted', data = leadScoreDf, ax = axs[ 2 ] )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Newspaper Article'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Newspaper'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Digital Advertisement'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'Digital Advertisement', 'Newspaper' and 'Newspaper Article' have maximum values for 'No'.\n\nThere are hardly 2-3 rows with 'Yes'.\n\nNo Inference can be drawn from these columns, also they would not help in the model. Thus we should drop these columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.drop(['Newspaper', 'Newspaper Article', 'Digital Advertisement' ], axis = 1, inplace = True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### X Education Forums - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot( x = 'X Education Forums', hue = 'Converted', data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf[ 'X Education Forums' ].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there is only 1 value for 'Yes', this column would not provide any insights.\n\nHence we should drop the column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.drop( 'X Education Forums', axis = 1, inplace = True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Through Recommendations - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot( x = 'Through Recommendations', hue = 'Converted', data = leadScoreDf )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Through Recommendations'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are very few values for 'Through Recommendations', it would be for the best to just drop the column ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.drop( 'Through Recommendations', axis = 1, inplace = True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tags-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (15,5))\nsns.countplot( x = 'Tags', hue = 'Converted', data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Tags'].value_counts( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are certain categories which have very less values.\n\nThese categories can be clubbed together into a single category 'Other Tags'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Tags'] = leadScoreDf['Tags'].replace( ['in touch with EINS', 'Lost to Others', 'Still Thinking', \n                              'Want to take admission but has financial problems', 'Interested in Next batch',\n                              'Shall take in the next coming month', 'University not recognized'\n                              'In confusion whether part time or DLP', 'Lateral student', \n                              'University not recognized', 'Recognition issue (DEC approval)'], 'Other Tags' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (15,5))\nsns.countplot( x = 'Tags', hue = 'Converted', data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the new plot we can say that -\n- leads with tags 'Will revert after reading the email' have the highest conversion rate. \n- tag 'Will revert after reading the email' also has a high non conversion rate.\n- leads with tags 'Closed by Horizon' and 'Lost to EINS' do not get converted.\n- tags 'Already a student' are usually converted","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Lead Quality - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot( x = 'Lead Quality', hue = 'Converted', data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are 2 variations of not sure, we can combine them.\nOn the basis of the plot, we can infere that - \n- Not Sure has a high conversion rate\n- High ub Relevance, Might be and Low in Relevance have a low conversion rate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf['Lead Quality'] = leadScoreDf['Lead Quality'].replace('Not sure', 'Not Sure')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### City - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (15,5))\nsns.countplot( x = 'City', hue = 'Converted', data = leadScoreDf )\nxticks( rotation = 90 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Mumbai has highest lead conversion rate\n- There are very few leads from Tier II cities\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the data is cleaned and analysis has been done, we can move onto Preparing the data for model building","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.head( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting Binary variables\n\nWe need to convert the 'Yes' and 'No' values into 1 and 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns to be mapped -\ncolList =  ['Do Not Email', 'Do Not Call', 'A free copy of Mastering The Interview']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the columns\nleadScoreDf[colList] = leadScoreDf[colList].apply(binary_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Dummy Variables - \n\nThe categorical variables with multiple levels, need to be converted to dummy variables.\nFor e.g. 'Lead Origin' can be broken down into 'Landing Page Submission', 'Lead Add form' and 'Lead Import'.\n- 001 would mean its a 'Lead Import' \n- 100 would mean its a 'Landing Page Submission'\n- 000 would mean its an 'API' Lead Origin.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dummyCols = [ 'Lead Origin', 'Lead Source', 'Last Activity', 'Specialization','What is your current occupation',\n                              'Tags','Lead Quality','City','Last Notable Activity' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummyDf = pd.get_dummies( leadScoreDf [ dummyCols ], drop_first=True )\ndummyDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining the dummy dataframe and the leadScore dataframe -\n\nleadScoreDf = pd.concat( [ leadScoreDf, dummyDf ], axis=1 )\nleadScoreDf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Original Categorical Columns are not required as they have been converted to the dummy variables.\nThus we can drop them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.drop( dummyCols, axis = 1, inplace = True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadScoreDf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data into Train and Test Data set - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Putting feature variable to X\nX = leadScoreDf.drop( 'Converted', axis=1 )\ny = leadScoreDf[ 'Converted' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split( X, y, train_size=0.7, test_size=0.3, random_state=100 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']] = scaler.fit_transform(X_train[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']])\n\nX_train.head( )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Conversion Rate - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Converted = ( sum( leadScoreDf[ 'Converted' ] ) / len( leadScoreDf[ 'Converted' ] ) ) * 100\nConverted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The current conversion rate is around 38%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Model Building - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression model\nlogm1 = sm.GLM( y_train,( sm.add_constant( X_train ) ), family = sm.families.Binomial( ) )\nlogm1.fit( ).summary() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection using RFE - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\n\nfrom sklearn.feature_selection import RFE\nrfe = RFE(logreg, 15)             # running RFE with 15 variables as output\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.support_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfeCols = X_train.columns[rfe.support_]\nrfeCols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm = sm.add_constant( X_train[ rfeCols ] )\nlogm2 = sm.GLM( y_train,X_train_sm, family = sm.families.Binomial( ) )\nres = logm2.fit( )\nres.summary( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfeCol1 = rfeCols.drop( [ 'Tags_invalid number', 'Tags_number not provided' ], 1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rebuilding the model - \nX_train_sm = sm.add_constant( X_train[ rfeCol1 ] )\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Predicting values on the training data set - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = res.predict(X_train_sm)\ny_train_pred[ : 5 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[ : 5 ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### DataFrame with Converted Values and the Converted Probability - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final = pd.DataFrame( { 'Converted':y_train.values, 'Converted_prob':y_train_pred } )\ny_train_pred_final['Prospect ID'] = y_train.index\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Predicted value is set to 1 if the probability is greater than 0.5 - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['predicted'] = y_train_pred_final.Converted_prob.map(lambda x: 1 if x > 0.5 else 0)\n\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Getting the Confusion matrix, Accuracy - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\n# Confusion matrix -\nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overall accuracy -\nprint(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking VIFs - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature variables and their respective VIFs - \nvif = pd.DataFrame()\nvif[ 'Features' ] = X_train[ rfeCol1 ].columns\nvif[ 'VIF' ] = [ variance_inflation_factor(X_train[ rfeCols ].values, i ) for i in range( X_train[ rfeCol1 ].shape[1] ) ]\nvif[ 'VIF' ] = round( vif[ 'VIF' ], 2 )\nvif = vif.sort_values( by = \"VIF\", ascending = False )\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the VIF for all the features is below 5, we dont need to remove any feature and build the model again.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Metrics beyond Accuracy - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sensitivity - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TP / float(TP+FN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Specificity - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TN / float(TN+FP)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Positive Predictive Value - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print (TP / float(TP+FP))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Negative Predictive Value - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print (TN / float(TN+ FN))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting the ROC Curve - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Converted_prob, drop_intermediate = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_roc( y_train_pred_final.Converted, y_train_pred_final.Converted_prob )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the ROC Curve we can see that the curve is closer to the left hand corner, indicating that the test is accurate","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Finding the Cut-off Point - \n\nOptimal cut-off point would be the one where the specificity and sensitivity are balanced.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create columns with different probability cutoffs \nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Converted_prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the basis of the plot, we can see that the point at which all the 3 values i.e. accuracy, sensitivity and specificity are balanced for probability of 0.2 .\nThus we will take 0.2 as the cut-off probability.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_prob.map( lambda x: 1 if x > 0.2 else 0)\n\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Assigning the Lead Score - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final[ 'Lead_Score' ] = y_train_pred_final.Converted_prob.map( lambda x: round(x*100))\n\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the overall Accuracy - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmetrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\n\nconfusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\nconfusion2\n\nTP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Sensitivity -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TP / float(TP+FN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Specificity - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TN / float(TN+FP)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision and Recall - ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Precision - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nTP / TP + FP\n\nconfusion[1,1]/(confusion[0,1]+confusion[1,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_score(y_train_pred_final.Converted , y_train_pred_final.predicted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Recall - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TP / TP + FN\n\nconfusion[1,1]/(confusion[1,0]+confusion[1,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recall_score(y_train_pred_final.Converted, y_train_pred_final.predicted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions on the Test Data Set - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']] = scaler.fit_transform(X_test[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']])\n\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test[ rfeCol1 ]\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_sm = sm.add_constant(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making predictions - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = res.predict( X_test_sm )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting y_pred and y_test to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)\ny_test_df = pd.DataFrame(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_df['Prospect ID'] = y_test_df.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)\ny_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_prob'})\n\ny_pred_final['final_predicted'] = y_pred_final.Converted_prob.map(lambda x: 1 if x > 0.2 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking the overall accuracy of the test data - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion3 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted )\nconfusion3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sensitivity -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TP / float(TP+FN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Specificity - ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TN / float(TN+FP)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}