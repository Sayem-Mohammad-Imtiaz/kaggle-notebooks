{"cells":[{"metadata":{},"cell_type":"markdown","source":"- This notebook is a modification of the original written in this [article](https://medium.com/analytics-vidhya/arima-model-from-scratch-in-python-489e961603ce).\n- To have a better understanding of the ARIMA model, I suggest this [article](https://towardsdatascience.com/understanding-arima-time-series-modeling-d99cd11be3f8) written by Tony Yiu."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"DATA_PATH = '../input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths_US.csv'\n\nP = 2\nQ = 2\nTRAIN_SIZE = 0.8","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.plotting import autocorrelation_plot\nfrom sklearn.linear_model import LinearRegression\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(DATA_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns[112:235].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data = df.iloc[:, 112:235].sum().reset_index().rename(columns={'index': 'date', 0: 'value'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.lineplot(data=raw_data, x='date', y='value', ax=ax)\nfor ind, label in enumerate(ax.get_xticklabels()):\n    if ind % 10 == 0:  # every 10th label is kept\n        label.set_visible(True)\n    else:\n        label.set_visible(False)\nplt.xticks(rotation=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.set_index('date', inplace=True)\nraw_data.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ARIMA(object):\n    def __init__(self):\n        pass\n    \n    @staticmethod\n    def _regressor(df, n, val_col, out_pred_col, train_size=0.8):\n        _df = df.copy()\n\n        #Generating the lagged n terms\n        for i in range(1, n + 1):\n            _df[f'shifted_values_{i}'] = _df[val_col].shift(i)\n        _df.dropna(inplace=True)\n\n\n        _train_size = int(train_size * _df.shape[0])\n\n        #Breaking data set into test and training\n        _df_train = pd.DataFrame(_df[:_train_size])\n        _df_test = pd.DataFrame(_df[_train_size:])\n\n        #X contains the lagged values ,hence we skip the first column\n        X_train = _df_train.iloc[:, 1:].values.reshape(-1, n)\n        #Y contains the value, it is the first column\n        y_train = _df_train.iloc[:, 0].values.reshape(-1, 1)\n        \n        # We do the same thing with the test set\n        X_test = _df_test.iloc[:, 1:].values.reshape(-1, n)\n        y_test = _df_test.iloc[:, 0].values.reshape(-1, 1)\n\n        #Running linear regression to generate the coefficents of lagged terms\n        lr = LinearRegression()\n        lr.fit(X_train, y_train)\n\n        theta  = lr.coef_.T\n        intercept = lr.intercept_\n        _df_train[out_pred_col] = X_train.dot(theta) + intercept\n#         _df_train[[val_col, out_pred_col]].plot()\n\n        _df_test[out_pred_col] = X_test.dot(theta) + intercept\n#         _df_test[[val_col, out_pred_col]].plot()\n\n        rmse = np.sqrt(mean_squared_error(y_test, _df_test[out_pred_col]))\n\n#         print(f'RMSE = {rmse}. Value of n = {n}')\n        new_df = pd.concat([_df_train, _df_test])[[val_col, out_pred_col]]\n        return new_df, theta, intercept, rmse, np.abs(_df_test[out_pred_col].mean())\n    \n    @staticmethod\n    def AR(df, p, val_col='value', out_pred_col='predicted_value', train_size=0.8):\n        return ARIMA._regressor(df, p, val_col, out_pred_col, train_size)\n    \n    @staticmethod\n    def I(df, val_col='value', fn=None):\n        _df = df.copy()\n        if fn is not None:\n            return pd.DataFrame(fn(_df[val_col])).dropna()\n        return _df\n\n    @staticmethod\n    def MA(df, q, val_col='value', in_pred_col='predicted_value', out_pred_col='ma_predicted_value', train_size=0.8):\n        _df = df.copy()\n        _df['residual'] = _df[val_col] - _df[in_pred_col]\n        return ARIMA._regressor(_df[['residual']], q, 'residual', out_pred_col, train_size)\n    \n    \n    def fit(self, df, p, q, val_col, train_size, stationary_fn=None):\n        _df = df.copy()\n        stationary_df = ARIMA.I(_df, val_col, stationary_fn)\n#         stationary_df[val_col].plot()\n#         plt.show()\n        \n        ar_out_df, ar_theta, ar_intercept, ar_rmse, ar_mean_pred = ARIMA.AR(stationary_df, p, val_col, 'ar_predicted_value', train_size)\n#         print(ar_rmse)\n#         ar_out_df['ar_predicted_value'].plot()\n#         plt.show()\n        \n        ma_out_df, ma_theta, ma_intercept, ma_rmse, ma_mean_pred = ARIMA.MA(ar_out_df, q, val_col, 'ar_predicted_value', 'ma_predicted_value', train_size)\n#         print(ma_rmse)\n#         ma_out_df['ma_predicted_value'].plot()\n#         plt.show()\n        \n#         final_predictions = (ar_out_df['ar_predicted_value'] + ma_out_df['ma_predicted_value']).dropna()\n#         final_predictions.plot()\n        \n#         return final_predictions\n        stationary_df['prediction'] = ar_out_df['ar_predicted_value'] + ma_out_df['ma_predicted_value']\n        return stationary_df.dropna(), ar_theta, ar_intercept, ma_theta, ma_intercept, ar_rmse, ma_rmse, ar_mean_pred, ma_mean_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arima_model = ARIMA()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stationary_fn = lambda x: x.diff()\n# def reverse_stationary_fn(ori_x, new_x):\n#     x = new_x.copy()\n#     x += ori_x.shift(1)\n#     return x\n\nstationary_fn = lambda x: x.diff().diff()\ndef reverse_stationary_fn(ori_x, new_x):\n    x = new_x.copy()\n    x += ori_x.shift(1)\n    x += ori_x.diff().shift(1)\n    return x\n\n# stationary_fn = lambda x: np.log(x).diff()\n# def reverse_stationary_fn(ori_x, new_x):\n#     x = new_x.copy()\n#     x += np.log(ori_x).shift(1)\n#     return np.exp(x)\n\n# stationary_fn = lambda x: np.log(x).diff().diff()\n# def reverse_stationary_fn(ori_x, new_x):\n#     x = new_x.copy()\n#     x += np.log(ori_x).shift(1)\n#     x += np.log(ori_x).diff().shift(1)\n#     return np.exp(x)\n\nmin_ar_rmse = float('inf')\nmin_ma_rmse = float('inf')\nbest_ar_mean_pred = None\nbest_ma_mean_pred = None\nbest_p = 1\nbest_q = 1\n\nfor i in range(1, 21):\n    final_predictions, \\\n        ar_theta, ar_intercept, \\\n        ma_theta, ma_intercept, \\\n        ar_rmse, ma_rmse, \\\n        ar_mean_pred, ma_mean_pred = arima_model.fit(raw_data, i, best_q, 'value', TRAIN_SIZE, stationary_fn)\n\n    if ar_rmse < min_ar_rmse:\n        min_ar_rmse = ar_rmse\n        best_ar_mean_pred = ar_mean_pred\n        best_p = i\n\n            \nfor j in range(1, 21):\n    final_predictions, \\\n        ar_theta, ar_intercept, \\\n        ma_theta, ma_intercept, \\\n        ar_rmse, ma_rmse, \\\n        ar_mean_pred, ma_mean_pred = arima_model.fit(raw_data, best_p, j, 'value', TRAIN_SIZE, stationary_fn)\n\n    if ma_rmse < min_ma_rmse:\n        min_ma_rmse = ma_rmse\n        best_ma_mean_pred = ma_mean_pred\n        best_q = j","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Min RMSE of AR model: {min_ar_rmse} (relative err: {min_ar_rmse/best_ar_mean_pred}). Best P: {best_p}')\nprint(f'Min RMSE of MA model: {min_ma_rmse} (relative err: {min_ma_rmse/best_ma_mean_pred}). Best Q: {best_q}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions, \\\n    ar_theta, ar_intercept, \\\n    ma_theta, ma_intercept, \\\n    ar_rmse, ma_rmse, \\\n    ar_mean_pred, ma_mean_pred = arima_model.fit(raw_data, 14, 12, 'value', TRAIN_SIZE, stationary_fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.lineplot(data=pd.DataFrame(reverse_stationary_fn(raw_data['value'], final_predictions['value'])).reset_index(), x='date', y='value', ax=ax)\nsns.lineplot(data=pd.DataFrame(reverse_stationary_fn(raw_data['value'], final_predictions['prediction'])).reset_index(), x='date', y='prediction', ax=ax)\nfor ind, label in enumerate(ax.get_xticklabels()):\n    if ind % 10 == 0:  # every 10th label is kept\n        label.set_visible(True)\n    else:\n        label.set_visible(False)\nplt.xticks(rotation=15)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}