{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/figure-eight-labelled-textual-dataset/text_emotion.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Misspelled data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"misspell_data = pd.read_csv(\"/kaggle/input/spelling/aspell.txt\",sep=\":\",names=[\"correction\",\"misspell\"])\nmisspell_data.misspell = misspell_data.misspell.str.strip()\nmisspell_data.misspell = misspell_data.misspell.str.split(\" \")\nmisspell_data = misspell_data.explode(\"misspell\").reset_index(drop=True)\nmisspell_data.drop_duplicates(\"misspell\",inplace=True)\nmiss_corr = dict(zip(misspell_data.misspell, misspell_data.correction))\n\n#Sample of the dict\n{v:miss_corr[v] for v in [list(miss_corr.keys())[k] for k in range(20)]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def misspelled_correction(val):\n    for x in val.split(): \n        if x in miss_corr.keys(): \n            val = val.replace(x, miss_corr[x]) \n    return val\n\ndata[\"clean_content\"] = data.content.apply(lambda x : misspelled_correction(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Contractions"},{"metadata":{"trusted":true},"cell_type":"code","source":"contractions = pd.read_csv(\"/kaggle/input/contractions/contractions.csv\")\ncont_dic = dict(zip(contractions.Contraction, contractions.Meaning))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cont_to_meaning(val): \n  \n    for x in val.split(): \n        if x in cont_dic.keys(): \n            val = val.replace(x, cont_dic[x]) \n    return val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.clean_content = data.clean_content.apply(lambda x : cont_to_meaning(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove URLS and mentions"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tweet-preprocessor 2>/dev/null 1>/dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import preprocessor as p\np.set_options(p.OPT.MENTION, p.OPT.URL)\np.clean(\"hello guys @alx #sport🔥 1245 https://github.com/s/preprocessor\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"clean_content\"]=data.content.apply(lambda x : p.clean(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Punctuations and emojis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def punctuation(val): \n  \n    punctuations = '''()-[]{};:'\"\\,<>./@#$%^&_~'''\n  \n    for x in val.lower(): \n        if x in punctuations: \n            val = val.replace(x, \" \") \n    return val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"punctuation(\"test @ #ldfldlf??? !! \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install emoji","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import emoji\nprint(emoji.emojize(\":grinning_face_with_big_eyes:\"))\nprint(\"\\U0001f600\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.clean_content = data.clean_content.apply(lambda x : ' '.join(punctuation(emoji.demojize(x)).split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(val):\n    val = misspelled_correction(val)\n    val = cont_to_meaning(val)\n    val = p.clean(val)\n    val = ' '.join(punctuation(emoji.demojize(val)).split())\n    \n    return val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_text(\"isn't 💡 adultry @ttt good bad ... ! ? \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove empty comments"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data.clean_content != \"\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding the data and train test split "},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_to_id  = {\"empty\":0, \"sadness\":1,\"enthusiasm\":2,\"neutral\":3,\"worry\":4,\n                        \"surprise\":5,\"love\":6,\"fun\":7,\"hate\":8,\"happiness\":9,\"boredom\":10,\"relief\":11,\"anger\":12}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"sentiment_id\"] = data['sentiment'].map(sent_to_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(data.sentiment_id)\n\nonehot_encoder = OneHotEncoder(sparse=False)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nY = onehot_encoder.fit_transform(integer_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data.clean_content,Y, random_state=1995, test_size=0.2, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL BUILDING"},{"metadata":{},"cell_type":"markdown","source":"# LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.initializers import Constant\nfrom keras.layers import (LSTM, \n                          Embedding, \n                          BatchNormalization,\n                          Dense, \n                          TimeDistributed, \n                          Dropout, \n                          Bidirectional,\n                          Flatten, \n                          GlobalMaxPool1D,\n                          SpatialDropout1D)\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.layers.embeddings import Embedding\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import (\n    precision_score, \n    recall_score, \n    f1_score, \n    classification_report,\n    accuracy_score\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using keras tokenizer here\ntoken = Tokenizer(num_words=None)\nmax_len = 160\nEpoch = 5\ntoken.fit_on_texts(list(X_train) + list(X_test))\nX_train_pad = sequence.pad_sequences(token.texts_to_sequences(X_train), maxlen=max_len)\nX_test_pad = sequence.pad_sequences(token.texts_to_sequences(X_test), maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w_idx = token.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_dim = 160\nlstm_out = 250\n\nmodel = Sequential()\nmodel.add(Embedding(len(w_idx) +1 , embed_dim,input_length = X_test_pad.shape[1]))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(keras.layers.core.Dense(13, activation='softmax'))\n#adam rmsprop \nmodel.compile(loss = \"categorical_crossentropy\", optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_pad, y_train, epochs = Epoch, batch_size=batch_size,validation_data=(X_test_pad, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sentiment(model,text):\n    text = clean_text(text)\n    #tokenize\n    twt = token.texts_to_sequences([text])\n    twt = sequence.pad_sequences(twt, maxlen=max_len, dtype='int32')\n    sentiment = model.predict(twt,batch_size=1,verbose = 2)\n    sent = np.round(np.dot(sentiment,100).tolist(),0)[0]\n    result = pd.DataFrame([sent_to_id.keys(),sent]).T\n    result.columns = [\"sentiment\",\"percentage\"]\n    result=result[result.percentage !=0]\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\ndef plot_result(df):\n    #colors=['#D50000','#000000','#008EF8','#F5B27B','#EDECEC','#D84A09','#019BBD','#FFD000','#7800A0','#098F45','#807C7C','#85DDE9','#F55E10']\n    #fig = go.Figure(data=[go.Pie(labels=df.sentiment,values=df.percentage, hole=.3,textinfo='percent',hoverinfo='percent+label',marker=dict(colors=colors, line=dict(color='#000000', width=2)))])\n    #fig.show()\n    colors={'love':'rgb(213,0,0)','empty':'rgb(0,0,0)',\n                    'sadness':'rgb(0,142,248)','enthusiasm':'rgb(245,178,123)',\n                    'neutral':'rgb(237,236,236)','worry':'rgb(216,74,9)',\n                    'surprise':'rgb(1,155,189)','fun':'rgb(255,208,0)',\n                    'hate':'rgb(120,0,160)','happiness':'rgb(9,143,69)',\n                    'boredom':'rgb(128,124,124)','relief':'rgb(133,221,233)',\n                    'anger':'rgb(245,94,16)'}\n    col_2={}\n    for i in result.sentiment.to_list():\n        col_2[i]=colors[i]\n    fig = px.pie(df, values='percentage', names='sentiment',color='sentiment',color_discrete_map=col_2,hole=0.3)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test LSTM Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"result =get_sentiment(model,\"Had an absolutely brilliant day ðŸ˜ loved seeing an old friend and reminiscing\")\nplot_result(result)\nresult =get_sentiment(model,\"The pain my heart feels is just too much for it to bear. Nothing eases this pain. I can’t hold myself back. I really miss you\")\nplot_result(result)\nresult =get_sentiment(model,\"I hate this game so much,It make me angry all the time \")\nplot_result(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing from Disaster Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"result =get_sentiment(model,\"Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\")\nplot_result(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result =get_sentiment(model,\"London is cool ;)\")\nplot_result(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result =get_sentiment(model,\"I gained 3 followers in the last week. You? Know your stats and grow with http://t.co/TIyUliF5c6\")\nplot_result(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}