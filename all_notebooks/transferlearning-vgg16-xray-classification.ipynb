{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Required Library","metadata":{}},{"cell_type":"code","source":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport os ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get the Path for Images","metadata":{}},{"cell_type":"code","source":"os.makedirs('./COVID19-DATASET/train/covid19')\nos.makedirs('./COVID19-DATASET/train/normal')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./COVID19-DATASET/test/covid19')\nos.makedirs('./COVID19-DATASET/test/normal')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./COVID19-DATASET/val/covid19')\nos.makedirs('./COVID19-DATASET/val/normal')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COVID_PATH = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID'\nNORMAL_PATH = '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**copy data from dataset in to train folder**","metadata":{}},{"cell_type":"code","source":"from distutils.dir_util import copy_tree\nfromDirectory= '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID'\ntoDirectory='./COVID19-DATASET/train/covid19'\ncopy_tree(fromDirectory, toDirectory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fromDirectory= '../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal'\ntoDirectory='./COVID19-DATASET/train/normal'\ncopy_tree(fromDirectory, toDirectory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fromDirectory= '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\ntoDirectory='./COVID19-DATASET/train/covid19'\ncopy_tree(fromDirectory, toDirectory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fromDirectory= ('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID'[:1000])\ntoDirectory='./COVID19-DATASET/test/covid19'\ncopy_tree(fromDirectory, toDirectory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fromDirectory= ('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal'[:1000])\ntoDirectory='./COVID19-DATASET/test/normal'\ncopy_tree(fromDirectory, toDirectory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**copy data from dataset in to validation folder**","metadata":{}},{"cell_type":"code","source":"from distutils.dir_util import copy_tree\nfromDirectory= ('../input/covid19-xray-dataset-train-test-sets/xray_dataset_covid19/test/NORMAL'[:200])\ntoDirectory='./COVID19-DATASET/val/normal'\ncopy_tree(fromDirectory, toDirectory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from distutils.dir_util import copy_tree\nfromDirectory= ('../input/covid19-xray-images-using-cnn/images/test/corona'[:200])\ntoDirectory='./COVID19-DATASET/val/covid19'\ncopy_tree(fromDirectory, toDirectory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = './COVID19-DATASET/train'\nval_path = './COVID19-DATASET/val'\ntest_path = '../input/chest-xray-pneumonia/chest_xray/test/'\n#test_path= test_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Constants","metadata":{}},{"cell_type":"code","source":"# re-size all the images to a size VGG-16 expects.\nIMAGE_SIZE = [224, 224]\n\n# Set the batch size\nBATCH_SIZE = 32  # try reducing batch size or freeze more layers if your GPU runs out of memory\nNUM_EPOCHS = 5\nLEARNING_RATE = 0.0001\nNUM_CLASSES = 2 # We are aware of it.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nCLASSES = os.listdir(train_path)\nNUM_CLASSES = len(CLASSES)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Class --> {} \\n and the length is : {}\".format(CLASSES, NUM_CLASSES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Data / Images","metadata":{}},{"cell_type":"markdown","source":"## For Training dataset","metadata":{}},{"cell_type":"code","source":"# Image Data Augmentation\n\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the images from the train dataset.\n# Make sure to provide the same target size as initialied for the image size\ntraining_set = train_datagen.flow_from_directory(\n    directory = train_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For Test Dataset","metadata":{}},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the images from the test dataset.\n\ntest_set = test_datagen.flow_from_directory(\n    directory = test_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the VGG 16 library as shown below and add preprocessing layer to the front of VGG\n# Here we will be using imagenet weights\n\nvgg = VGG16(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# don't train existing weights\nfor layer in vgg.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Sample... for adding Pooling (optional)\n# global_average_layer = GlobalAveragePooling2D()\n\n# prediction = Dense(NUM_CLASSES,activation='softmax')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# our layers - you can add more if you want\nx = Flatten()(vgg.output)\n\nprediction = Dense(NUM_CLASSES, activation='softmax')(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  training_set,\n  validation_data=test_set,\n  epochs=5,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('my_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the Model","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_path = './COVID19-DATASET/val'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate Validation set.\nvalidation_datagen = ImageDataGenerator(rescale = 1./255)\n\nvalidation_set = validation_datagen.flow_from_directory(\n    directory = val_path,\n    target_size = (224, 224),\n    batch_size = BATCH_SIZE,\n    class_mode = 'categorical'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_steps = 200\n\nloss0,accuracy0 = model.evaluate(validation_set, steps = validation_steps)\n\nprint(\"loss: {:.2f}\".format(loss0))\nprint(\"accuracy: {:.2f}\".format(accuracy0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate Validation set.\nvalidation_set2 = validation_datagen.flow_from_directory(\n    directory = val_path,\n    target_size = (224, 224),\n    batch_size = 1,\n    shuffle=False, \n    seed=42, \n    class_mode=\"binary\"\n)\n\n# validation_set2.reset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# just capture the loss and accuray into val variable... unlike in pervious code to capture into loss0 and accuracy0. Just to showcase alternate way.\n\nval = model.evaluate(validation_set, steps = validation_steps)\n\nprint(\"loss: {:.2f}\".format(val[0]))\nprint(\"accuracy: {:.2f}\".format(val[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\n\nplt.plot(history.history['loss'], label='Train loss')\nplt.plot(history.history['val_loss'], label='Validation (Test) loss')\nplt.title('summarize history for loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('summarize history for accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"# get sample image to test.\nimg_normal = image.load_img('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/Normal-10.png', target_size = (224, 224))\nimg_pneumonia = image.load_img('../input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/person1947_bacteria_4876.jpeg', target_size = (224, 224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_predict(img, actual):\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis = 0)\n    x_processed = preprocess_input(x)\n    result = model.predict(x_processed)\n    if(result[0][0]<.50):\n        result=\"normal\"\n    else:\n        result=\"corona positive\"\n        \n    plt.figure()\n    plt.imshow(img)\n    plt.title('Actual : {} --> Predicted  : {}'.format(actual, result))\n    \n#     return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_normal = model_predict(img_normal, \"normal\")\npred_pneumonia = model_predict(img_pneumonia, \"corona positive\")","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = image.load_img('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/Normal-100.png', target_size = (224, 224))\n\npred = model_predict(img, \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}