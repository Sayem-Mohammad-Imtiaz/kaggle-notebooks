{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\nimport matplotlib.patches as patches\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nimport json\nimport tensorflow\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom sklearn.model_selection import train_test_split\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, BatchNormalization\n# from tensorflow.keras.layers import Activation, MaxPooling2D\n# from tensorflow.keras.layers import Conv2D, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import load_model, Model\nfrom PIL import Image\nfrom mtcnn.mtcnn import MTCNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\n# print(len(os.listdir(images)))\nannotations = os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=os.listdir(images)\nb=os.listdir(annotations)\na.sort()\nb.sort()\n# print(a[1698:1708])\n# print(b[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images=a[:1698]\ntrain_images=a[1698:]\ntrain_ann=b\nlen(train_images)==len(train_ann)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_path = \"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations/\"\njdata = json.load(open(ann_path+train_ann[1860]))\nanns = jdata[\"Annotations\"]\n# bb = anns[0]['BoundingBox']\nbb = get_boxes('1861.jpg')\nimgpath = \"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/1861.jpg\"\nim = cv2.imread(imgpath)\nfig,ax = plt.subplots(1)\nax.imshow(im)\nprint(bb)\nfor box in bb:\n    print(box)\n    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n    ax.add_patch(rect)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimg=plt.imread(os.path.join(images,train_images[0]))\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\nsubmission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_csv\nbbox=[]\nfor i in range(len(train_csv)):\n    arr=[]\n    for j in df.iloc[i][[\"x1\",'x2','y1','y2']]:\n        arr.append(j)\n    bbox.append(arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"bbox\"]=bbox\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_boxes(id):\n    boxes=[]\n    for i in df[df[\"name\"]==str(id)][\"bbox\"]:\n        boxes.append(i)\n    return boxes\n# print(get_boxes('1810.jpg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image=train_images[11]\n\nimg=plt.imread(os.path.join(images,image))\n\nfig,ax = plt.subplots(1)\nax.imshow(img)\nboxes=get_boxes(image)\nfor box in boxes:\n    rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=2,edgecolor='r',facecolor='none')\n    ax.add_patch(rect)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"name\"]==train_images[11]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PreProcessing for training process","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/\"\ntrain_features = []\ntrain_labels = []\nimg_size = 128\n\nfor image_name in range(3550):\n    img = cv2.imread(path + train_images[image_name])\n    boxes = get_boxes(train_images[image_name])\n    for idx, bb in enumerate(boxes):\n        x,y,w,h = bb\n        label = list(df[df[\"name\"]==train_images[image_name]][\"classname\"])\n        #if label[idx] == \"face_no_mask\" or label[idx] == \"face_with_mask\":\n        roi = img[y:h, x:w]\n        try:\n            roi = cv2.resize(roi, (img_size, img_size), cv2.INTER_AREA)\n            train_features.append(roi)\n            train_labels.append(label[idx])\n        except Exception as e:\n            print(\"[ERROR]\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(train_features, dtype=\"float32\")\nX /= 255.0\ny = np.array(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = [\"hijab_niqab\", \"mask_colorful\", \"mask_surgical\", \"face_no_mask\",\n          \"face_with_mask_incorrect\", \"face_with_mask\", \"face_other_covering\",\n          \"scarf_bandana\", \"balaclava_ski_mask\", \"face_shield\", \"gas_mask\",\n          \"turban\", \"helmet\", \"sunglasses\", \"eyeglasses\", \"hair_net\", \"hat\",\n          \"goggles\", \"hood\", \"other\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(y)\ny = le.transform(y)\ny = to_categorical(y, num_classes=len(classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X, y = shuffle(X, y, random_state=2)\n# import pickle\n# with open(\"X.pickle\",\"wb\") as f1:\n#     pickle.dump(X, f1)\n# with open(\"y.pickle\",\"wb\") as f2:\n#     pickle.dump(y, f2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.12, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MY CUSTOM littleVGG\n# img_size = 128\n\n# model = Sequential()\n# #1st layer\n# model.add(Conv2D(64,kernel_size=(3,3),padding=\"same\",input_shape=(img_size,img_size,)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# #2nd layer\n# model.add(Conv2D(64,kernel_size=(3,3)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.2))\n# #3rd layer\n# model.add(Conv2D(128,kernel_size=(3,3),padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# #4th layer\n# model.add(Conv2D(128,kernel_size=(3,3)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.2))\n# #5th layer\n# model.add(Conv2D(256,kernel_size=(3,3),padding=\"same\"))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# #6th layer\n# model.add(Conv2D(256,kernel_size=(3,3)))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(2,2))\n# model.add(Dropout(0.2))\n\n# model.add(Flatten())\n# #7th layer\n# model.add(Dense(256))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# #8th layer\n# model.add(Dense(256))\n# model.add(Activation(\"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n# #9th layer\n# model.add(Dense(len(classes)))\n# model.add(Activation(\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 128\n\nvgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\nfor layer in vgg.layers:\n    layer.trainable = False\ntop = vgg.output\ntop = GlobalAveragePooling2D()(top)\ntop = Dense(units=256, activation=\"relu\")(top)\ntop = Dense(units=128, activation=\"relu\")(top)\ntop = Dense(units=len(classes), activation=\"softmax\")(top)\n\nmodel = Model(inputs=vgg.input, outputs=top)\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('face_mask.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\nreduceLR = ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,verbose=1,min_delta=0.0001)\n\ncallbacks = [checkpoint, reduceLR]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(x_train, y_train, batch_size=64, epochs=45, \n                 validation_data=(x_test, y_test), verbose=1,\n                callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save('face_mask_last.h5')\n# import pickle\n# pickle_in1 = open('X.pickle', \"rb\")\n# X = pickle.load(pickle_in1)\n# pickle_in2 = open('y.pickle', \"rb\")\n# y = pickle.load(pickle_in2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('face_mask.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score = model.evaluate(x_test, y_test)\n# score\n# accuracy = 80.93% on 10 epochs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = \"/kaggle/input/face-mask-detection-dataset/submission.csv\"\nsubdf = pd.read_csv(sub)\nsubmission_images = list(subdf[\"name\"])\n# FILE NAMES IS INCORRECT,SHOULD BE JPEG BUT ITS JPE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/\"\n\npredicted_classes = []\ncoordinates = []\nimage_names = []\n\ndetector = MTCNN()\n\nfor img_name in submission_images:\n    first = img_name.split(\".\")[0]\n    last = img_name.split(\".\")[1]\n    if last == \"jpe\":\n        img_name = first+\".\"+\"jpeg\"\n    im = cv2.imread(path+img_name)\n    color = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = np.asarray(color)\n    faces = detector.detect_faces(im)\n    for i in range(len(faces)):\n        x,y,w,h = faces[i]['box']\n        x, y = abs(x), abs(y)\n        roi = color[y:y+h, x:x+w]\n        roi = cv2.resize(roi, (128,128), cv2.INTER_AREA)\n        roi = np.array(roi).astype('float32')\n        roi = roi.reshape(1, 128, 128, 3)\n        preds = model.predict(roi)\n        pred = np.argmax(preds, axis=1)\n        predicted_classes.append(classes[int(pred)])\n        coordinates.append([x,y,w,h])\n        image_names.append(img_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total size:\", len(predicted_classes))\nprint(\"Image name:\", image_names[6])\nprint(\"coordinates:\", coordinates[6])\nprint(\"predicted class:\", predicted_classes[6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_names = pd.DataFrame(image_names, columns=[\"name\"])\ndf_coord = pd.DataFrame(coordinates, columns=['x1','x2','y1','y2'], dtype=float)\ndf_class = pd.DataFrame(predicted_classes, columns=[\"classname\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframes = [df_names, df_coord, df_class]\nresult = pd.concat(dataframes, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv(r'final_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'final_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.head(n=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subdf.head(n=20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}