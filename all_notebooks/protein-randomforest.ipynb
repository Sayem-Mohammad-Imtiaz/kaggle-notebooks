{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.impute import KNNImputer\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extracting column names from .txt file\ncol_names = []\nwith open(\"../input/protein-localization/field_descriptions.txt\", \"rt\") as myfile:\n    for line in myfile:\n        col_name = line.split(\":\")[0]\n        col_names.append(col_name.strip())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(23)\nprotein1 = pd.read_csv('../input/protein-localization/train.csv', names=col_names, na_values=['?'])\nprotein2 = pd.read_csv('../input/protein-localization/test.csv', names=col_names[:-1], na_values=['?'])\nprotein2['Label'] = [0]*381\nframe = [protein1, protein2]\nprotein = pd.concat(frame)\nprotein_labels = pd.read_csv('../input/protein-localization/label_legend.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# only taking out the columns from concatenated protein data frame\n\nprotein_ft = protein.iloc[:,-16:-1:].columns.values #function to localization\n\nprotein = protein.drop(columns=protein_ft) # dropped last 16 rows\n\n\npercent_missing = protein.isnull().sum() * 100 / len(protein)\nmissing_value_df = pd.DataFrame({'column_name': protein.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df.sort_values('percent_missing', inplace=True, ascending=False)\n\nmissing_colnames = []\nfor idx, row in missing_value_df.iterrows():\n     if (row['percent_missing'] > 10):\n            missing_colnames.append(row['column_name'])\n\n                \n\nprotein = protein.drop(columns=missing_colnames)\n# missing_value_df1[missing_value_df1['percent_missing']>10]\nprotein.isnull().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we do label encoding and one hot encoding on the concatenated data frame\n\n# One-Hot encoding of categorical variables \n# Lable encoding for protein response \n\nprotein_index = protein[\"Protein\"] ## to be added later \n\n#####################################\n\nprotein = protein.drop(\"Protein\",axis=1)\ncategorical_feature_mask = protein.dtypes==object\ncat_cols = protein.columns[categorical_feature_mask].tolist()\n\n# finding the binary columns \nbin_cols = [*protein.loc[:,protein.isin(['Yes','No']).all()].columns]\n\n# finding multi class variables\nmult_cols = [x for x in cat_cols if x not in bin_cols]\n\n\nnon_cat_mask = protein.dtypes!=object\nnon_cat_cols = protein.columns[non_cat_mask].tolist()\n\n#Label encoding\nle = LabelEncoder()\nprotein[bin_cols] = protein[bin_cols].apply(lambda col: le.fit_transform(col))\n# One-hot encoding\nprotein = pd.get_dummies(protein, columns = mult_cols, drop_first=True)\nprotein","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dividing the dataframe protein into train and test seperately\nprotein[\"Protein\"] = protein_index\nprotein_train = protein.iloc[:862,:]\nprotein_test = protein.iloc[862:,:]\nprotein_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Uses KNNImputer\n## fill up the column instead of dropping it\n\nimputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\nprotein_train_label = protein_train['Label']\nprotein_train_index = protein_train['Protein']\n\nprotein_train_imputer = protein_train.drop(['Protein', 'Label'],axis=1)\nimputer.fit(protein_train_imputer)\nprotein_train = pd.DataFrame(imputer.fit_transform(protein_train_imputer),columns = protein_train_imputer.columns)\n# protein_train = protein_train.dropna()\n# protein_train.isnull().sum().sum()\nprotein_train['Label'], protein_train['Protein'] = protein_train_label, protein_train_index\nprotein_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## dropping the protein_train rows in which na's are present\n\n## fill up the column instead of dropping it\n\n\nprotein_test_label = protein_test['Label']\nprotein_test_index = protein_test['Protein']\n\nprotein_test_imputer = protein_test.drop(['Protein', 'Label'],axis=1)\nimputer.fit(protein_test_imputer)\nprotein_test = pd.DataFrame(imputer.fit_transform(protein_test_imputer),columns = protein_test_imputer.columns)\n# protein_train = protein_train.dropna()\n# protein_train.isnull().sum().sum()\nprotein_test['Label'], protein_test['Protein'] = protein_test_label, protein_test_index\n\nprotein_org = protein_test\n# protein_test = protein_test.dropna()\nprotein_test.isnull().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into train and valid set\n# label_lst = protein_labels['Label']\n# class_lst = protein_labels['Class']\n\n# rf_random = RandomForestClassifier(n_estimators=244, min_samples_split=5,\n#                                    min_samples_leaf=1,max_features='auto',\n#                                    max_depth=42,bootstrap=False,random_state=42)\n# Train the model on the training data\n\n# cl_dict = dict(zip(label_lst, class_lst))\n\n\nX = protein_train.drop(['Label', 'Protein'],axis=1)\ny = protein_train['Label']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size = 0.25, random_state=42)\n# X_train, X_vs, y_train, y_vs = train_test_split(X_temp, y_temp, train_size = 0.75, test_size = 0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyptertuning the parameters for rf using random hyperparameter grid \n\n# Number of trees in random forest\n# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 800, num = 10)]\n# Number of features to consider at every split\n# max_features = ['auto', 'sqrt', 'log2']\n# Maximum number of levels in tree\n# max_depth = [int(x) for x in np.linspace(10, 60, num = 11)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\n# min_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\n# min_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\n# bootstrap = [True, False]\n\n# random_grid = {'n_estimators': n_estimators,\n#               'max_features': max_features,\n#               'max_depth': max_depth,\n#               'min_samples_split': min_samples_split,\n#               'min_samples_leaf': min_samples_leaf,\n#               'bootstrap': bootstrap}\n\n# random_grid\n# results \n# {'bootstrap': False,\n#  'max_depth': None,\n#  'max_features': 'auto',\n#  'min_samples_leaf': 1,\n#  'min_samples_split': 2,\n#  'n_estimators': 422}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\n# Instantiate model with 100 decision trees\nrf = RandomForestClassifier()\nrf_base = RandomForestClassifier(n_estimators = 100, random_state=42)\n# rf_custom_random = GridSearchCV(estimator = rf,param_grid=random_grid, cv = 5, scoring=\"balanced_accuracy\")\nrf_custom_random = RandomForestClassifier(n_estimators = 422, bootstrap = False, max_depth = None, max_features = 'auto', min_samples_leaf = 1,\n                                          min_samples_split = 2, random_state=42)\n\nrf_base.fit(X_train, y_train)\nrf_custom_random.fit(X_train, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report\ny_pred = rf_base.predict(X_test)\n\ny_pred_random = rf_custom_random.predict(X_test)\n\nprecision = accuracy_score(y_test, y_pred)\nprint(precision)\nprint(classification_report(y_test, y_pred))\n\nprecision_random = accuracy_score(y_test, y_pred_random)\nprint(precision_random)\nprint(classification_report(y_test, y_pred_random))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"protein_test_index = protein_test['Protein']\nprotein_test = protein_test.drop(['Protein', 'Label'],axis=1)\ny_pred_random_t = rf_custom_random.predict(protein_test)\n[protein_test_index, y_pred_random_t]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"protein_final_vals = protein_index[-381:].values\n\nlstvals = protein_index[-381:].values\nlstx = []\ncount = 0\nfor i in protein_test_index.values:\n    elem = [i,y_pred_random_t[count]]\n    lstx.append(elem)\n    count += 1\n\nfinal_key = []\nfinal_label = []\ncount  = 0\nfor x in protein_final_vals:\n    if (x == lstx[count][0]):\n        final_key.append(lstx[count][0])\n        final_label.append(lstx[count][1])\n        count += 1\n    else:\n        final_key.append(x)\n        final_label.append(0)\n\n\n\nresult = pd.DataFrame({'Key':final_key, 'Label':final_label})\n\nresult.to_csv(r'./result_KNN_RF_2.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}