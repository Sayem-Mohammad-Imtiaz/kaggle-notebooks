{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center><h1>Animal Crossing<h1></center>\nAnimal Crossing is a social simulation video game series developed and published by Nintendo and created by Katsuya Eguchi and Hisashi Nogami. In Animal Crossing, the player character is a human who lives in a village inhabited by various anthropomorphic animals, carrying out various activities such as fishing, bug catching, and fossil hunting. The series is notable for its open-ended gameplay and extensive use of the video game console's internal clock and calendar to simulate real passage of time.\n\nSince it's release the game has had an astounding world-wide reception. Some of the popular critics have rated the game highly and have termed it 'meditative'. Apparently the users have a very calming effect while playing and find the progress enjoyable. \n\n![Image](https://venturebeat.com/wp-content/uploads/2020/02/animal-crossing-new-horizons.jpg?fit=578%2C353&strip=all)\n\nThis kernel attempts to explore some aspects of the game such as the items and villagers. It will also analyze user and critic reviews along with a sentiment analysis.\n\nThis is a work in progress and will be updated in the coming weeks.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# read data\nitems = pd.read_csv('/kaggle/input/animal-crossing/items.csv')\nuser_reviews = pd.read_csv('/kaggle/input/animal-crossing/user_reviews.csv')\ncritic = pd.read_csv('/kaggle/input/animal-crossing/critic.csv')\nvillagers = pd.read_csv('/kaggle/input/animal-crossing/villagers.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Standard plotly imports\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\n\nimport plotly.express as px\nimport plotly.io as pio\n\n# Using plotly + cufflinks in offline mode\nimport cufflinks\ncufflinks.go_offline(connected=True)\ninit_notebook_mode(connected=True)\n\npd.set_option('display.max_columns',500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ITEMS","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"items.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first thing to note in the items dataset is that the recipe, recipe_id and sources column is split into rows for the same item. See example below for the Acoustic Guitar and Rusted Part Items. We need to be careful when aggregating data.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"items[items.name == 'Acoustic Guitar'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"items[items.name == 'Rusted Part'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.shape[0], items.name.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"missing_values = items.isna().sum().sort_values(ascending=False)\nmissing_values = pd.DataFrame({'Feature':missing_values.index, 'Missing Value Count':missing_values.values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# plot missing values\nfig = px.bar(missing_values[::-1], x= 'Missing Value Count', y='Feature', orientation='h',text='Missing Value Count',\n             title='Missing Value Count in Features - Items Dataset',template=\"plotly_dark\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The recipe column has 87% missing values. And as mentioned earlier the recipe is split across the rows creating duplicate items in the items dataset.  The sources column also has ~80% missing values. Unless we have sufficient knowledge about the dataset we will not be able to fix the missing values. Or we will need to create a predictive model just to impute these values. ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# drop the recipe column \nitems = items.drop(['recipe','recipe_id','sources'], axis=1)\n\n# drop duplicates \nitems = items.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.shape[0], items.name.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following are the some of the initial findings after looking at the data:\n\n* The raw data consists of 4,565 rows and 13 columns.\n* The different recipe_id, reecipe and sources column for the same item are populated in different rows. \n* The above mentioned columns have more than 80% missing values and have been dropped from the analysis.\n* Some columns such as num_id, id, games_id, id_full and image_url are not of much interest.\n* There are a total of 4,200 distinct items in the datatset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The next step is to fill the missing values in the items data. The following methods will be used for the imputing missing values in the different columns:\n\n* For customizable column - fill with 'Non Customizable' when the value is either missing or False. The true values will be replaced with 'Customizable'.\n* For orderable column - the same strategy as above. Column will be populated as 'Orderable' and 'Non Orderable'.\n* buy_currency will be filled with a new category as 'None' since you cannot buy the items and buy_value will be filled with 0.\n* sale_value is 1/4th the buy_value and will be populated accordingly where the buy value is available. Otherwise the value is 0.\n* sale currency is filled with 0 for the missing values.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"items['customizable'] = np.where(items['customizable'] == True,'Customizable','Non Customizable')\nitems['orderable'] = np.where(items['orderable'] == True,'Orderable','Not Orderable')\nitems['buy_currency'] = items['buy_currency'].fillna('None')\nitems['buy_value'] = items['buy_value'].fillna(0)\nitems['sell_value'] = np.where(items['sell_value'].isnull(), items['buy_value']/4,items['sell_value'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cat_counts = items.groupby('category')['category'].count()\ncat_counts = pd.DataFrame({'Category':cat_counts.index,'Count':cat_counts.values})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>What are the different Item Categories?</center>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.pie(cat_counts, values='Count', names='Category', title='Category Distribution for the Items', \n             template=\"plotly_dark\",height=500)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# cutomizable counts\ncustomizable = items[items.customizable == 'Customizable'].groupby('category')['category'].count()\nnon_customizable = items[items.customizable == 'Non Customizable'].groupby('category')['category'].count().sort_values(ascending=False)\n\n# orderable counts\norderable = items[items.orderable == 'Orderable'].groupby('category')['category'].count()\nnon_orderable = items[items.orderable == 'Not Orderable'].groupby('category')['category'].count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>Can I customize my socks?</center>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='Non Customizable', x=non_customizable.index, y=non_customizable.values,marker_color='cyan'),\n    go.Bar(name='Customizable', x=customizable.index, y=customizable.values, marker_color='chartreuse')\n])\n# Change the bar mode\nfig.update_layout(barmode='group',template=\"plotly_dark\",title_text='Customizable and Non-Customizable Category Counts',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>What can I not order?<center>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='Non Orderable', x=non_orderable.index, y=non_orderable.values,marker_color='cyan'),\n    go.Bar(name='Orderable', x=orderable.index, y=orderable.values, marker_color='chartreuse')\n])\n# Change the bar mode\nfig.update_layout(barmode='group',template=\"plotly_dark\",title_text='Orderable and Non-Orderable Category Counts',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>How much does the Royal Crown Cost?</center>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"expensive_items = items[['name','buy_value']].sort_values(by='buy_value', ascending=False).head(10)\ncheapest_items = items[items.buy_value > 0][['name','buy_value']].sort_values(by='buy_value').head(10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='Most Expensive Items', x=expensive_items[::-1].buy_value, y=expensive_items[::-1].name,marker_color='cornsilk',\n           orientation='h'),\n])\n# Change the bar mode\nfig.update_layout(template=\"plotly_dark\",title_text='Top 10 Expensive Items',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='Cheapest Items', x=cheapest_items.buy_value, y=cheapest_items.name,marker_color='coral',\n           orientation='h'),\n])\n# Change the bar mode\nfig.update_layout(template=\"plotly_dark\",title_text='Top 10 Cheapest Items',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>Buying & Selling Values by Category<center>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cat_buy_value = items.groupby('category')['buy_value'].median().sort_values(ascending=False)\ncat_sale_value = items.groupby('category')['sell_value'].median().sort_values(ascending=False)\n\ncategories = items.category.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\nfor cats in categories:\n    fig.add_trace(go.Violin(x=items['category'][items['category'] == cats],\n                            y=items['buy_value'][items['category'] == cats],\n                            name=cats,\n                            box_visible=False,\n                            meanline_visible=False,jitter=0.05))\n\nfig.update_layout(template=\"plotly_dark\",title_text='Buy Value Distribution by Category',height=400)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\nfor cats in categories:\n    fig.add_trace(go.Violin(x=items['category'][items['category'] == cats],\n                            y=items['sell_value'][items['category'] == cats],\n                            name=cats,\n                            box_visible=False,\n                            meanline_visible=False,jitter=0.05))\n\nfig.update_layout(template=\"plotly_dark\",title_text='Sell Value Distribution by Category',height=400)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='Category', x=cat_buy_value.index, y=cat_buy_value.values,marker_color='yellow')\n])\n# Change the bar mode\nfig.update_layout(template=\"plotly_dark\",title_text='Buy Value (Median)',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='Category', x=cat_sale_value.index, y=cat_sale_value.values,marker_color='red')\n])\n# Change the bar mode\nfig.update_layout(template=\"plotly_dark\",title_text='Sale Value (Median)',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusions from the Items Dataset:\n* There are total of 21 categories in the dataset. Furniture and Photos are dominant and account for 45% of the data. \n* Some categories such Fruit(6) andSeashells (8) have extremely low counts. Maybe these are very special to obtain.\n* Only the Furnitue and Tools are customizable. All the rest are not customizable. Wonder why we can't customize dresses, hats etc.\n* Only a few items such as furniture, flooring, tops and similar items can be ordered. \n* Some items like the royal crown that belong to the 'hats' category are extremely expenive and cost around 1.2M.\n* The cheapest items are typically the photos. There are some items that are free, that is can be only found and sold. \n* Based on the median values, music is the most expensive category to buy.\n* The fossils have the highest sale value. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# VILLAGERS","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"villagers.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"missing_values_villagers = villagers.isna().sum().sort_values(ascending=False)\nmissing_values_villagers = pd.DataFrame({'Feature':missing_values_villagers.index, 'Missing Value Count':missing_values_villagers.values})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# plot missing values\nfig = px.bar(missing_values_villagers[::-1], x= 'Missing Value Count', y='Feature', orientation='h',text='Missing Value Count',\n             title='Missing Value Count in Features - Villagers Dataset',template=\"plotly_dark\",height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>What are the dominant villager species?</center>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"species_count = villagers.groupby('species')['species'].count()\nspecies_count = pd.DataFrame({'Species':species_count.index,'Count':species_count.values})\n\nfig = px.pie(species_count, values='Count', names='Species', title='Species Distribution for the Villagers', \n             template=\"plotly_dark\",height=500)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"males = villagers[villagers.gender == 'male'].groupby('species')['species'].count().sort_values(ascending=False)\nfemales = villagers[villagers.gender == 'female'].groupby('species')['species'].count().sort_values(ascending=False)\n\nfig = go.Figure(data=[\n    go.Bar(name='Males', x=males[::-1].index, y=males[::-1].values,marker_color='lightskyblue'),\n    go.Bar(name='FeMales', x=females.index, y=males.values,marker_color='lightsalmon')\n])\n# Change the bar mode\nfig.update_layout(barmode='group',template=\"plotly_dark\",title_text='Species Counts - Males & Females',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>Are the villagers cranky?<center>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"personality = villagers.groupby('personality')['personality'].count().sort_values()\nmales = villagers[villagers.gender == 'male'].groupby('personality')['personality'].count().sort_values(ascending = False)\nfemales = villagers[villagers.gender == 'female'].groupby('personality')['personality'].count().sort_values(ascending = False)\n\nfig = go.Figure(data=[\n    go.Bar(name='Personality', x=personality[::-1].index, y=personality[::-1].values,marker_color=' steelblue')\n])\nfig.update_layout(barmode='group',template=\"plotly_dark\",title_text='Personality Types for Villagers',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='Males', x=males[::-1].index, y=males[::-1].values,marker_color='lightskyblue'),\n    go.Bar(name='FeMales', x=females.index, y=males.values,marker_color='lightsalmon')\n])\nfig.update_layout(barmode='group',template=\"plotly_dark\",title_text='Personality - Males and Females',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The following are some of the findings for the villagers dataset:\n* The dataset is fairly clean with very few missing values.\n\n* There are a total of 390 villagers and 35 species. The species are fairly evenly distributed - overall and by gender. Surprisingly there are no females in the lion species. The bulls have no females and the cows have no males, which is obvious. The maximum number of males are found in the frogs and the maximum number of females are found in cat.\n\n* There are 8 different personality types. They are equally distributed mostly, though uchi (caring) and smug are on the lower side. There is a clear distinction between the personalities of the males and females. The males are mostly lazy and cranky (my wife would agree) and the females are normal and snooty. Even among the females, the number of caring ones are less. Hmmm...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# What are the users saying?\nThis section will analyze the reviews from the users, which is one of the main focus for analysis. The following will be dealt with:\n* User review trends (overall and high ratings)\n* sentiment analysis ","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"user_reviews['date'] = pd.to_datetime(user_reviews['date'], format='%Y-%m-%d', errors='ignore')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"user_review_counts = user_reviews.groupby('date')['user_name'].count()\n\nfig = px.line(x=user_review_counts.index, y=user_review_counts.values, range_x=['2020-03-20','2020-05-03'])\n\nfig.update_layout(\n    xaxis = dict(title_text = \"Date\"),\n    yaxis = dict(title_text='Review Count'),height=350,title_text='Review Counts')\n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"review_grade_count = user_reviews.groupby('grade')['user_name'].count()\n\nfig = go.Figure(data=[\n    go.Bar(name='Count', x=review_grade_count[::-1].index, y=review_grade_count[::-1].values,marker_color='red')\n])\nfig.update_layout(title_text='Review Counts by Score',height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"high_rank_trend = user_reviews[user_reviews.grade >= 9].groupby('date')['user_name'].count()\n\nfig = px.line(x=high_rank_trend.index, y=high_rank_trend.values, range_x=['2020-03-20','2020-05-03'])\n\nfig.update_layout(\n    xaxis = dict(title_text = \"Date\"),\n    yaxis = dict(title_text='Review Count'),height=400,title_text='Review Counts - Grade >= 9')\n    \nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preliminary findings from user reviews:\n* There was a spike in the number of reviews on March 24th, 2020. This makes sense since the latest version was released on Mar 20,2020 and there will be that initial buzz. After that there is a considerable drop, and stays consistent, other than a small spike in Apr 28, 2020.\n\n* The highest rating, 10 accounts for 25% of the data. 38% of the data has the lowest rating 0.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The next step is to deal with the review 'text' column. We will also add a new column called 'is_bad_review'. A review will be considered bad if the rating is below 7 (an arbitrary assumption).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a column to for bad reviews and good reviews - any review above >7 is good and the rest is bad. \nuser_reviews['is_bad_review'] = user_reviews['grade'].apply(lambda x: 1 if x < 7 else 0)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# create a separate dataset with the text column and the newly created 'is_bad_review' column.\nreviews_df = user_reviews[['text','is_bad_review']].rename(columns={'text':'review'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following will be the steps for cleaning the review column:\n* Convert to lowercase\n* Tokenize text (split text to words) and remove punctuation\n* Remove words that contain numbers\n* Remove stop words\n* Part of speed tagging such as adjective, noun, verb\n* Lemmatize text - convert words to root form (eg: texting to text, relaxing to relax)\n\nWe will create functions for these steps.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# define functions for cleaning data\nfrom nltk.corpus import wordnet\nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\n\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n\ndef clean_text(text):\n    # lower text\n    text = text.lower()\n    # tokenize text and remove puncutation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # remove stop words\n    stop = stopwords.words('english')\n    text = [x for x in text if x not in stop]\n    # remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    # pos tag text\n    pos_tags = pos_tag(text)\n    # lemmatize text\n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)\n\n# clean data\nreviews_df[\"review_clean\"] = reviews_df[\"review\"].apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the review column is clean we, will add a few more columns:\n* Create number of words\n* Create length of characters\n* positivity, neutratlity, negativity score and a combined score for all (based on Vader, a nltk package for sentiment analysis)","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# add character count column\nreviews_df[\"Char_Count\"] = reviews_df[\"review\"].apply(lambda x: len(x))\n\n# add number of words column\nreviews_df[\"Word_Count\"] = reviews_df[\"review\"].apply(lambda x: len(x.split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# add sentiment anaylsis columns\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nsid = SentimentIntensityAnalyzer()\nreviews_df[\"sentiments\"] = reviews_df[\"review\"].apply(lambda x: sid.polarity_scores(x))\nreviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"reviews_df[reviews_df[\"Word_Count\"] >= 5].sort_values(\"pos\", ascending = False)[[\"review\", \"pos\"]].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the highest positive sentiment reviews corresponding to some great feedback. The very first record has words like amazing, great, good, fantastic, incredible all in the same review. No wonder it has a positive score of 0.930.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"reviews_df[reviews_df[\"Word_Count\"] >= 5].sort_values(\"neg\", ascending = False)[[\"review\", \"neg\"]].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The highest rated negative sentiment reviews do indeed have some harsh words such as 'Terrible game', 'No Cloud Saving', 'Disgusting practice'. The one review that talks about contradicting the unfair zero's is given a high negative segment. This is wrong. Vader has misunderstood the context here.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nfor x in [0, 1]:\n    subset = reviews_df[reviews_df['is_bad_review'] == x]\n    \n    # Draw the density plot\n    if x == 0:\n        label = \"Good reviews\"\n    else:\n        label = \"Bad reviews\"\n    sns.distplot(subset['compound'], hist = False, label = label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph shows the distribution of the good and bad reviews with the compund score.  For the most part Vader has classified the the good reviews as positive. And the bad reviews tend to have lower compound sentiment score.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Coming up - \nCritic reviews text and sentiment analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}