{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\nfrom sklearn.feature_selection import SelectKBest, chi2, mutual_info_regression, f_regression\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor, PassiveAggressiveRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.experimental import enable_hist_gradient_boosting  # noqa\nfrom sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom xgboost import XGBRegressor\nfrom sklearn.svm import SVR\nfrom scipy import stats\nfrom scipy.stats import boxcox\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-prices-data/train.csv')\ndt = pd.read_csv('/kaggle/input/house-prices-data/test.csv')\ntest_dataY = pd.read_csv('/kaggle/input/submission/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Remove Outlier</h1>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df.SalePrice < 350000]\ndf.reset_index(drop=True, inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Id','PoolQC','MiscFeature','Alley','Fence'],axis=1,inplace=True)\ndt.drop(['Id','PoolQC','MiscFeature','Alley','Fence'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Replace null</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['SalePrice']\ndf.drop(['SalePrice'], axis = 1, inplace = True)\ndata = pd.concat([df,dt], axis = 0)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(((data.isnull().sum())*100)/len(data)).sort_values(\n            ascending = False, kind = 'mergesort').head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_all = ['YearBuilt', 'YearRemodAdd','YrSold','MoSold','GarageYrBlt']\nfor i in year_all:\n    data[i] = data[i].astype(object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qual_listt = ['HeatingQC','OverallQual','ExterQual','BsmtQual','KitchenQual','FireplaceQu','GarageQual']\ncond_listt = ['OverallCond','ExterCond','BsmtCond','GarageCond']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['BsmtQual'] = data['BsmtQual'].fillna('NA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {'NA':.5,'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 3.5, 'Ex': 5}\nfor i in (qual_listt+cond_listt):\n  data[i] = data[i].fillna(data[i].mode()[0])\n  if data[i].dtype == object:\n    data[i] = data[i].map(dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['BsmtExposure'] = data['BsmtExposure'].fillna('NA')\ndata['BsmtFinType1'] = data['BsmtFinType1'].fillna('NA')\ndata['BsmtFinType2'] = data['BsmtFinType2'].fillna('NA')\ndata['GarageType'] = data['GarageType'].fillna('NA')\ndata['GarageFinish'] = data['GarageFinish'].fillna('NA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in data:\n    if data[j].dtype == object:\n        data[j] = data[j].fillna(data[j].mode()[0])\n    else:\n        data[i] = data[i].astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['LotFrontage'] = data['LotFrontage'].fillna(data['LotFrontage'].mean())\ndata['MasVnrArea'] = data['MasVnrArea'].fillna(data['MasVnrArea'].mean())\ndata['GarageArea'] = data['GarageArea'].fillna(data['GarageArea'].mean())\ndata['TotalBsmtSF'] = data['TotalBsmtSF'].fillna(data['TotalBsmtSF'].mean())\ndata['BsmtUnfSF'] = data['BsmtUnfSF'].fillna(data['BsmtUnfSF'].mean())\ndata['BsmtFinSF2'] = data['BsmtFinSF2'].fillna(data['BsmtFinSF2'].mean())\ndata['BsmtFinSF1'] = data['BsmtFinSF1'].fillna(data['BsmtFinSF1'].mean())\ndata['BsmtHalfBath'] = data['BsmtHalfBath'].fillna(data['BsmtHalfBath'].mode()[0])\ndata['BsmtFullBath'] = data['BsmtFullBath'].fillna(data['BsmtFullBath'].mode()[0])\ndata['GarageCars'] = data['GarageCars'].fillna(data['GarageCars'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Encoding categorical features</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"house_style = {'1.5Unf':1,'SFoyer':2, '1.5Fin': 3, '2.5Unf': 4, 'SLvl': 5, '1Story': 6, '2Story': 7, '2.5Fin': 8}\nutilities = {'NoSeWa':1,'AllPub':2}\nroof_matl = {'Roll':1,'ClyTile':2, 'CompShg': 3, 'Metal': 4, 'Tar&Grv': 5, 'WdShake': 6, 'Membran': 7, 'WdShngl': 8}\nheating = {'Floor':1,'Grav':2, 'Wall': 3, 'OthW': 4, 'GasW': 5, 'GasA': 6}\nelectrical = {'Mix':1,'FuseP':2, 'FuseF': 3, 'FuseA': 4, 'SBrkr': 5}\n\ndata['Utilities'] = data['Utilities'].map(utilities)\ndata['HouseStyle'] = data['HouseStyle'].map(house_style)\ndata['RoofMatl'] = data['RoofMatl'].map(roof_matl)\ndata['Heating'] = data['Heating'].map(heating)\ndata['Electrical'] = data['Electrical'].map(electrical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Create new features</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['RemodAdd'] = data['YearBuilt']\n\nfor i in range(len(data)):\n    if data['YearBuilt'].iloc[i] == data['YearRemodAdd'].iloc[i]:\n        data['RemodAdd'].iloc[i] = 0\n    else:\n        data['RemodAdd'].iloc[i] = abs(data['YearBuilt'].iloc[i]- data['YearRemodAdd'].iloc[i])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['DiffEx'] = data['ExterCond']\n\nfor i in range(len(data)):\n    if data['ExterQual'].iloc[i] == data['ExterCond'].iloc[i]:\n        data['DiffEx'].iloc[i] = 0\n    else:\n        data['DiffEx'].iloc[i] = abs(data['ExterQual'].iloc[i]- data['ExterCond'].iloc[i])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['CompletedBstmSf'] = data['TotalBsmtSF'] - data['BsmtUnfSF']\ndata['CompletedFloorSF'] = data['1stFlrSF'] + data['2ndFlrSF']\ndata['TotalBath'] = data['BsmtFullBath'] + data['BsmtHalfBath'] + data['FullBath'] + data['HalfBath']\ndata['GarageAreaPerCar'] = (data['GarageArea']+1) / (data['GarageCars'] +1)\ndata['TotalExtraArea'] = data['WoodDeckSF'] + data['OpenPorchSF'] + data['EnclosedPorch'] + data['3SsnPorch']+ data['PoolArea']\ndata['AgeOfHouse'] = abs(data['YrSold'] - data['YearBuilt'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Features Selection</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.select_dtypes(exclude=object).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx = data.iloc[:len(y), :]\ntx = np.log1p(tx.select_dtypes(exclude=object).copy())\n#tx.drop(['SalePrice'],axis=1,inplace=True)\nty = np.log1p(y)\nX_train, X_test, y_train, y_test = train_test_split(tx, ty, test_size=0.2, random_state=13)\n\nparams = {'n_estimators': 500,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}\nreg = ensemble.GradientBoostingRegressor(**params)\nreg.fit(X_train, y_train)\n\nmse = mean_squared_error(y_test, reg.predict(X_test))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n\ntest_score = np.zeros((params['n_estimators'],), dtype=np.float64)\nfor i, y_pred in enumerate(reg.staged_predict(X_test)):\n    test_score[i] = reg.loss_(y_test, y_pred)\n\nfig = plt.figure(figsize=(6, 6))\nplt.subplot(1, 1, 1)\nplt.title('Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, reg.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = reg.feature_importances_\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n#print(pos)\n#print(np.array(tx.columns)[sorted_idx])\nfig = plt.figure(figsize=(40, 30))\nplt.subplot(1, 2, 1)\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, np.array(tx.columns)[sorted_idx])\naa = (pos, np.array(tx.columns)[sorted_idx])\nplt.title('Feature Importance (MDI)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aa[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_selection = ['GarageAreaPerCar',\n       'HeatingQC', 'TotalExtraArea', 'LotFrontage', 'BsmtFinSF1',\n       'Fireplaces', 'YearRemodAdd', 'AgeOfHouse', 'BsmtQual', '1stFlrSF',\n       'YearBuilt', 'CompletedBstmSf', 'GarageCars', 'OverallCond',\n       'LotArea', 'GarageArea', 'GrLivArea', 'ExterQual', 'KitchenQual',\n       'TotalBath', 'TotalBsmtSF', 'CompletedFloorSF', 'OverallQual']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx = data.iloc[:len(y), :]\ntx = np.log1p(tx.select_dtypes(exclude=object).copy())\nfilter = []\nfor i in tx:\n  if tx[i].dtypes != object:\n    r = tx[i].corr(np.log1p(y))\n    if r >= .3 or r<=-.3:\n      print(i,' ',r)\n      filter.append(str(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature selection\ndef select_features(X, Y, func):\n  bestfeatures = SelectKBest(score_func=func, k='all')\n  fit = bestfeatures.fit(X,Y)\n  return fit,bestfeatures\nfit,fs = select_features(tx, np.log1p(y), mutual_info_regression)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(tx.columns)\nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score'] \n\nmutual_info = featureScores.nlargest(30,'Score')\nmutual_info = list(mutual_info['Specs'])\nprint(len(mutual_info),'\\n',mutual_info)\nprint(featureScores.nlargest(32,'Score'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nskewed = []\nc = 0\nfor i in tx:\n  if tx[i].skew() <=.5 and tx[i].skew() >=-.5:\n    skewed.append(i)\n    c+=1\n    #print('fairly symmetrical: ',i,'\\n')\n  elif tx[i].skew() <=-.5 and tx[i].skew() >=-1:\n    skewed.append(i)\n    c+=1\n    #print('negatively skewed: ',i,'\\n')\n  elif tx[i].skew() >=.5 and tx[i].skew() <=1:\n    skewed.append(i)\n    c+=1\n    #print('positively skewed: ',i,'\\n')\n  #elif tx[i].skew() <-1:\n    #skewed.append(i)\n    #c+=1\n    #print('negatively highly skewed: ',i,'\\n')\n  #elif tx[i].skew() >1:\n    #skewed.append(i)\n    #c+=1\n    #print('positively highly skewed: ',i,'\\n')\nprint(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(skewed),len(filter),len(xgb_selection), len(mutual_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = 0\nc1 = 0\nfor i in skewed:\n  if i in filter:\n    c+=1\n  if i in xgb_selection:\n    c1+=1\nprint(c,' ',c1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.select_dtypes(include=object).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_skewed = features.filter(skewed,axis = 1)\nfeatures_filter = features.filter(filter,axis = 1)\nfeatures_xgb_selection = features.filter(xgb_selection,axis = 1)\nfeatures_mutual_info = features.filter(mutual_info,axis = 1)\n\n\nfeatures_skewed = pd.concat([features_skewed,features.select_dtypes(include=object)], axis = 1)\nfeatures_mutual_info = pd.concat([features_mutual_info,features.select_dtypes(include=object)], axis = 1)\nfeatures_filter = pd.concat([features_filter,features.select_dtypes(include=object)], axis = 1)\nfeatures_xgb_selection = pd.concat([features_xgb_selection,features.select_dtypes(include=object)], axis = 1)\n\nfeatures_skewed.shape,features_filter.shape,features_xgb_selection.shape,features_mutual_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_skewed = pd.get_dummies(features_skewed, drop_first=True)\nfeatures_filter = pd.get_dummies(features_filter, drop_first=True)\nfeatures_mutual_info = pd.get_dummies(features_mutual_info, drop_first=True)\nfeatures_xgb_selection = pd.get_dummies(features_xgb_selection, drop_first=True)\nall_features = pd.get_dummies(features, drop_first=True)\n\nall_features.shape, features_skewed.shape,features_filter.shape,features_xgb_selection.shape,features_mutual_info.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Train & Test</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nHistGradientBoostingRegressor(l2_regularization=0, learning_rate=0.1,\n                          loss='least_absolute_deviation', max_bins=255,\n                          max_depth=15, max_iter=500, max_leaf_nodes=15,\n                          min_samples_leaf=20, n_iter_no_change=None,\n                          random_state=None, scoring=None, tol=1e-07,\n                          validation_fraction=0.1, verbose=0,\n                          warm_start=False),'''\nclassifiers = [\n    LinearRegression(),\n    Ridge(alpha=.7),\n    PassiveAggressiveRegressor(max_iter=100000, random_state=5000,tol=1e-3),\n    AdaBoostRegressor(random_state=3500, n_estimators=1000,loss='square'),\n    GradientBoostingRegressor(n_estimators=5000, learning_rate=0.009,\n                                max_depth=25, max_features='sqrt',\n                                min_samples_leaf=15, min_samples_split=10,\n                                loss='huber', random_state=300),\n    XGBRegressor(learning_rate=0.001, n_estimators=3500,\n                       max_depth=5, min_child_weight=0,\n                       gamma=0.01, subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:linear', nthread=-1,\n                       scale_pos_weight=1, seed=30,\n                       reg_alpha=0.00005),\n    \n    SVR(C=20, epsilon=0.009, gamma=0.0004, )\n\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = [all_features,features_skewed, features_filter, features_xgb_selection, features_mutual_info]\ndata_name = ['all_features','features_skewed', 'features_filter', 'features_xgb_selection', 'features_mutual_info']\nY = np.log1p(y)\nfor data,nm in zip(all_data,data_name):\n    print(nm)\n    train = data.iloc[:len(y), :]\n    test = data.iloc[len(train):, :]\n    X_train, X_test, y_train, y_test = train_test_split(train, Y, test_size=0.1, random_state=1)\n    for clf in classifiers:\n        try:\n            clf.fit(X_train,y_train)\n            print(clf.__class__.__name__,' ', round(clf.score(X_test, y_test) * 100, 2))\n            print(mean_squared_error(y_test, clf.predict(X_test)))\n            print()\n        except:\n            continue\n            #print('hello') \n    print('___END___')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = 0\nlog_data = data.copy()\nsqrt_data = data.copy()\nbox_data = data.copy()\nfor i in box_data:\n    if box_data[i].dtypes != object:\n        if box_data[i].skew() <=.5 and box_data[i].skew() >=-.5:\n            box_data[i],lam = stats.boxcox(box_data[i]+1)\n            log_data[i] = np.log1p(log_data[i])\n        sqrt_data[i] = np.sqrt(sqrt_data[i])\nlog_data = pd.get_dummies(log_data, drop_first=True)\nsqrt_data = pd.get_dummies(sqrt_data, drop_first=True)\nbox_data = pd.get_dummies(box_data, drop_first=True)\ny_log = np.log1p(y)\ny_box,l = stats.boxcox(y+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = [log_data,sqrt_data, box_data]\nall_y = [y_log, y_box]\ndata_name = ['log_data','sqrt_data', 'box_data']\nY = np.log1p(y)\nfor data,nm in zip(all_data,data_name):\n    print(nm)\n    for dy in all_y:\n        train = data.iloc[:len(y), :]\n        #test = data.iloc[len(train):, :]\n        X_train, X_test, y_train, y_test = train_test_split(train, dy, test_size=0.1, random_state=1)\n        for clf in classifiers:\n            try:\n                clf.fit(X_train,y_train)\n                print(clf.__class__.__name__,' ', round(clf.score(X_test, y_test) * 100, 2))\n                print(mean_squared_error(y_test, clf.predict(X_test)))\n                print()\n            except:\n                continue\n                #print('hello') \n        print('__end__')\n    print('___END___')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale = [\n    StandardScaler(),\n    MinMaxScaler(),\n    RobustScaler(),\n    PowerTransformer(method='yeo-johnson'),\n    QuantileTransformer(output_distribution='normal'),\n    QuantileTransformer(output_distribution='uniform'),\n    Normalizer()\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = features_skewed.iloc[:len(y), :]\ntest = features_skewed.iloc[len(train):, :]\n\nfor scl in scale:\n    print(scl)\n    train = data.iloc[:len(y), :]\n    #test = data.iloc[len(train):, :]\n    try:\n        train = scl.fit_transform(train)\n        X_train, X_test, y_train, y_test = train_test_split(train, y_log, test_size=0.1, random_state=1)\n        for clf in classifiers:\n            clf.fit(X_train,y_train)\n            print(clf.__class__.__name__,' ', round(clf.score(X_test, y_test) * 100, 2))\n            print(mean_squared_error(y_test, clf.predict(X_test)))\n            print()\n    except:\n        continue\n        #print('hello') \n    print('___END___')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = log_data.iloc[:len(y), :]\ntest = log_data.iloc[len(train):, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, y_log, test_size=0.1, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nparameters = {'n_estimators':[5000,4000], 'learning_rate':[.005,.009,.0001],\n              'max_depth':[30,45],'max_features':['sqrt'],'min_samples_leaf':[20,25],\n              'min_samples_split':[10,20],'loss':['ls','huber'],'random_state':[500,1000]}\n'''\nclf = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.005,\n                                max_depth=50, max_features='sqrt',\n                                min_samples_leaf=15, min_samples_split=20,\n                                loss='huber', random_state=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = []\ncv = KFold(n_splits=5, random_state=42, shuffle=False)\nfor train_index, test_index in cv.split(train):\n    X_train, X_test, y_train, y_test = train.iloc[train_index], train.iloc[test_index], y_log[train_index], y_log[test_index]\n    clf.fit(X_train, y_train)\n    scores.append(clf.score(X_test, y_test))\n    lin_pred = clf.predict(X_test)\n    print(clf.score(X_test, y_test))\n    print('Mean squared error: %.2f' % mean_squared_error(y_test, lin_pred))\n    #The coefficient of determination: 1 is perfect prediction\n    print('Coefficient of determination: %.2f'% r2_score(y_test, lin_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)\nprint(clf.score(X_test, y_test))\nprint('Mean squared error: %.2f' % mean_squared_error(y_test, clf.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(test)\ny_pred = np.expm1(y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_y = y_pred.reshape(-1)\nall_id = np.array(test_dataY['Id'])\ny_pred = pd.DataFrame(list(zip(all_id, pred_y)),columns =['Id', 'SalePrice'])\ny_pred.to_csv(\"svr.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}