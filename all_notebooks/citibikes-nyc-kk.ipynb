{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_cs\nimport datetime \n\n## data visualization \nimport geopandas\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndf = pd.read_csv(\"/kaggle/input/new-york-city-bike-share-dataset/NYC-BikeShare-2015-2017-combined.csv\")\n        \n\"\"\"\n\n Objective of the Project: \n\n1 Group targetting based on most common group- Age Group/Gender/Location/time of year/month/day\n based on cutomer or one time users \n2. Use geospacial data to show where are all bikes located and highlight the one with most common used routes for starting and endind\n3. Average and median time by customers/one time users \n4. Figure out which one are more relevant stations (volume) and then look at trends for top five station\n5. Most popular trip (https://towardsdatascience.com/citi-bike-2017-analysis-efd298e6c22c: Part 3 )\n6. So we can identify which bike would need some attention/replacement - busiest bike. Will help which category of bikes and location need customer care  \n\n7. Predictive Model: Estimate (https://towardsdatascience.com/citi-bike-2017-analysis-efd298e6c22c)\n\n\n\nhttps://github.com/alhankeser/citibike-analysis\n\n\"\"\"\n# For a good project \n\n# https://studentwork.prattsi.org/infovis/projects/visualizing-citi-bikes/ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"First step is to import and understand what is in the data. \n\nThis step involves looking at the columns and their data type \n\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### fixing the datatypes \ndf['ignore'] = \"\"\ndf['ignore_reason'] = \"\"\ndf[['Start Time','Stop Time']] = df[['Start Time','Stop Time']].apply(pd.to_datetime, format='%Y-%m-%d %H:%M:%S.%f')\ndf['Birth Year'] = pd.to_numeric(df['Birth Year'], downcast='integer')\n# df.info()\n\n\n\n# count = df[\"Birth Year\"].isna().sum() to count number of nas \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Looking at unique values \n\ndf['Gender'].value_counts()\ndf['Birth Year'].value_counts(sort= True)\ndf['User Type'].value_counts(sort= True)\ndf['Start Station Name'].value_counts(sort= True)  ## Try to put this in a map with count \ndf['Trip_Duration_in_min'].value_counts(sort= True)  ## trip duration of 1 minutes makes no sense have to clean up the data \n## multiple 1 values don't make sense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Looking for duplicated in the data \n\nduplicates = df.duplicated(keep='first')\ndf.insert(len(df.columns), \"duplicate\", duplicates, allow_duplicates = False)\nprint(\"Found {} duplicate rows\".format(len(df[duplicates])))\n\n### Validating data \n\ndf['Years_old'] = df['Start Time'].dt.year - df['Birth Year'] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_subscribers = df[df[\"User Type\"] == \"Subscriber\"]\ndf_customers = df[df[\"User Type\"] == \"Customer\"]\nsns.set(style=\"whitegrid\", color_codes=True)\nsns.distplot(df_subscribers['Years_old'], kde= False,color = \"Green\", label = \"subscriber\", bins = 100 ,rug = True)\nsns.distplot(df_customers['Years_old'], kde= False, color = \"Red\" , label = \"customers\", bins = 100)\nplt.legend(prop={'size': 12})\nplt.title('Age of bikers')\nplt.xlabel('Age of bikers')\nplt.ylabel('Count')\n\n\"\"\"\nWe can clearly see that the population distribution of subcriber is well distributed than the customers. There are also \nsome data points where the age is above 80. It is untilike someone above 100 is riding bike, this needs to be \nremoved from the data\"\n\"\"\"\ndf.loc[df['Years_old'] > 80, \"ignore_reason\"] += \"Age invalid\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TIME_RANGES_LIMITS = [0, 5, 15, 30, 45, np.inf]\nTIME_RANGES = [\"<5\", \"6-15\", \"16-30\", \"31-45\", \"45+\"]\n\ndf[\"Trip_Duration_range\"] = pd.cut(df[\"Trip_Duration_in_min\"], TIME_RANGES_LIMITS, labels=TIME_RANGES)\n\ndf_subscribers = df[df[\"User Type\"] == \"Subscriber\"]\ndf_customers = df[df[\"User Type\"] == \"Customer\"]\nDATAFRAMES = [df, df_subscribers, df_customers]\n\nFONT_SCALE = 1\nfor i in range(3):\n    dfr = DATAFRAMES[i]\n\n    with sns.plotting_context(\"notebook\", font_scale=FONT_SCALE):\n        f = sns.countplot(y = \"Trip_Duration_range\",palette = \"Blues\", data=DATAFRAMES[i])\n        f.get_figure().get_axes()[0]\n        f.set(xlabel='Trip Count', ylabel='Trip Duration in Minute')\n        plt.show()\n\n\"\"\"\n From the results we can infer that for the customers the counts for trip less than 5 minutes is very high, \nthis could be ither because glitch first time customers run into (very often) or could be that customers tend \nto take trips less than 5 minutes. This makes little sense. \n\nFor the purpose of analysis, I will get rid of data which has trip time less than 5 minutes \n\n\"\"\"        \n\ndf.loc[df['Trip_Duration_in_min'] >= 5, \"ignore_reason\"] += \"Invalid Trip duration\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Find most common start and end routes \nimport folium\ndf_sub = df[['Start Station Name','End Station Name', 'Start Station Latitude','Start Station Longitude','End Station Latitude','End Station Longitude']]\n# df_routes = df_sub.groupby(['Start Station Name','Start Station Latitude', 'Start Station Longitude', 'End Station Name', 'End Station Latitude','End Station Longitude']).size().reset_index(name='Counts of trips')\n\n# df_routes = df_routes.nlargest(50, columns=['Counts of trips'])\n# # print(df_routes)\n\n# df_sub = df_sub[df_sub['Start Station Name'] != df_sub['End Station Name']]\ndf_sub['both'] = df_sub['Start Station Name'] + ', ' + df_sub['End Station Name']\n# # perform the transformation asked\ndf_sub = df_sub.groupby(['Start Station Name','Start Station Latitude', 'Start Station Longitude', 'End Station Name', 'End Station Latitude','End Station Longitude'])['both'].count().reset_index(name='Counts of trips')\n\n\n\ndf_sub = df_sub.nsmallest(100, columns=['Counts of trips'])\n# print(df_sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmap1 = folium.Map(\n\n    location=[40.732775,-74.105973],\n    tiles='cartodbpositron',\n    zoom_start= 15,\n    max_width= 150, max_height=150\n    \n#     m = folium.Map(location=[20, 0], tiles=\"Mapbox Bright\", zoom_start=2)\n\n)\n\n\ndf_sub.apply(lambda row:folium.CircleMarker(location=[row[\"End Station Latitude\"], row[\"End Station Longitude\"]], popup=row[\"End Station Name\"],radius=5, color=\"Red\").add_to(map1), axis=1)\ndf_sub.apply(lambda row:folium.CircleMarker(location=[row[\"Start Station Latitude\"], row[\"Start Station Longitude\"]],popup=row[\"Start Station Name\"]).add_to(map1), axis=1)\n\n\nmap1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmap1 = folium.Map(\n\n    location=[40.732775,-74.105973],\n    tiles='cartodbpositron',\n    zoom_start= 15,\n    max_width= 250, max_height=250\n)\n# df_routes.apply(lambda row:folium.CircleMarker(location=[row[\"Start Station Latitude\"], row[\"Start Station Longitude\"]],radius=2, color=\"#007849\").add_to(map1),axis=1)\ndf_routes.apply(lambda row:folium.CircleMarker(location=[row[\"End Station Latitude\"], row[\"End Station Longitude\"]], popup=row[\"End Station Name\"],radius=2, color=\"Red\").add_to(map1),axis=1)\ndf_routes.apply(lambda row:folium.CircleMarker(location=[row[\"Start Station Latitude\"], row[\"Start Station Longitude\"]],popup=row[\"Start Station Name\"], radius=2, color=\"#007849\").add_to(map1),axis=1)\n\npopup\nmap1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Construct downtown map\n# downtown_map = folium.Map(location = 'nashville', zoom_start = 15)\n# folium.GeoJson(urban_polygon).add_to(downtown_map)\n\n# # Create popups inside the loop you built to create the markers\n# for row in urban_art.iterrows():\n#     row_values = row[1] \n#     location = [row_values['lat'], row_values['lng']]\n#     popup = (str(row_values['title']) + ': ' + \n#              str(row_values['desc'])).replace(\"'\", \"`\")\n#     marker = folium.Marker(location = location, popup = popup)\n#     marker.add_to(downtown_map)\n\nimport folium\nmap1 = folium.Map(\nlocation=[40.785091, -73.968285],\ntiles='cartodbpositron',\nzoom_start= 10,\nwidth='50%', height='50%'\n)\nnew_start.apply(lambda row:folium.CircleMarker(location=[row[\"Start Station Latitude\"], row[\"Start Station Longitude\"]],popup=row['Start Station Name'],radius=2, color=\"#007849\").add_to(map1),axis=1)\nmap1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Find most common start and end routes \nimport folium\ndf_sub = df[['Start Station Name', 'Start Station Latitude','Start Station Longitude','End Station Name','End Station Latitude','End Station Longitude','Trip_Duration_in_min']]\ndf_routes = df_sub.groupby(['Start Station Name','Start Station Latitude', 'Start Station Longitude', 'End Station Name', 'End Station Latitude','End Station Longitude'], as_index = False).agg({'Trip_Duration_in_min': ['mean']}).rename(columns={'mean':'Avg_trip_duration','Start Station Name': 'Start Station' , 'End Station Name': 'End Station' })\ndf_routes.columns = df_routes.columns.droplevel(1)\ndf_routes.rename(columns = {'Trip_Duration_in_min':'Avg_Trip_Duration'},  inplace=True)\ndf_routes = df_routes.nlargest(10, columns=['Avg_Trip_Duration'])\n\nmap1 = folium.Map(\n\n    location=[40.732775,-74.105973],\n    tiles='cartodbpositron',\n    zoom_start= 15,\n    max_width= 250, max_height=250\n)\n\nfor row in df_routes.iterrows():\n    print(row[\"End Station Latitude\"])\n    folium.CircleMarker(location=[row[\"End Station Latitude\"], row[\"End Station Longitude\"]], \n                        popup=row[\"End Station Name\"],radius=2, color=\"Red\")\n#     df_routes.apply(lambda row:folium.CircleMarker(location=[row[\"Start Station Latitude\"], row[\"Start Station Longitude\"]],popup=row[\"Start Station Name\"], radius=2, color=\"#007849\").add_to(map1),axis=1)\n\ndf_routes.apply(lambda row:folium.CircleMarker(location=[row[\"End Station Latitude\"], row[\"End Station Longitude\"]], popup=row[\"End Station Name\"],radius=2, color=\"Red\").add_to(map1),axis=1)\ndf_routes.apply(lambda row:folium.CircleMarker(location=[row[\"Start Station Latitude\"], row[\"Start Station Longitude\"]],popup=row[\"Start Station Name\"], radius=2, color=\"#007849\").add_to(map1),axis=1)\n\n\nmap1\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}