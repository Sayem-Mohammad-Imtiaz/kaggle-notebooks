{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\n\nprefix = '../input/diplomwork/'\n\nimages_radiopedia = np.load(os.path.join(prefix, 'images_radiopedia.npy')).astype(np.float32)\nmasks_radiopedia = np.load(os.path.join(prefix, 'masks_radiopedia.npy')).astype(np.int8)\n\nimages_medseg = np.load(os.path.join(prefix, 'images_medseg.npy')).astype(np.float32)\nmasks_medseg = np.load(os.path.join(prefix, 'masks_medseg.npy')).astype(np.int8)\ntest_images_medseg = np.load(os.path.join(prefix, 'test_images_medseg.npy')).astype(np.float32)\n\nimages_mosmed = np.load(os.path.join(prefix, 'images_mosmed.npy')).astype(np.float32)\nmasks_mosmed = np.load(os.path.join(prefix, 'masks_mosmed.npy')).astype(np.int8)\n\ndef preprocess_images(images_arr, mean_std=None):\n    images_arr[images_arr > 500] = 500\n    images_arr[images_arr < -1500] = -1500\n    min_perc, max_perc = np.percentile(images_arr, 5), np.percentile(images_arr, 95)\n    images_arr_valid = images_arr[(images_arr > min_perc) & (images_arr < max_perc)]\n    mean, std = (images_arr_valid.mean(), images_arr_valid.std()) if mean_std is None else mean_std\n    images_arr = (images_arr - mean) / std\n    print(f'mean {mean}, std {std}')\n    return images_arr, (mean, std)\n\nimages_radiopedia, mean_std = preprocess_images(images_radiopedia)\nimages_medseg, _ = preprocess_images(images_medseg, mean_std)\nimages_mosmed, _ = preprocess_images(images_mosmed, mean_std)\ntest_images_medseg, _ = preprocess_images(test_images_medseg, mean_std)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T20:54:13.627117Z","iopub.execute_input":"2021-05-31T20:54:13.627875Z","iopub.status.idle":"2021-05-31T20:54:27.750784Z","shell.execute_reply.started":"2021-05-31T20:54:13.627833Z","shell.execute_reply":"2021-05-31T20:54:27.74981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow\nimport albumentations\nimport cv2\n\nSOURCE_SIZE = 512\nTARGET_SIZE = 256\n\ntrain_augs = albumentations.Compose([\n    albumentations.Rotate(limit=360, p=0.9, border_mode=cv2.BORDER_REPLICATE),\n    albumentations.RandomSizedCrop((int(SOURCE_SIZE * 0.75), SOURCE_SIZE), \n                                   TARGET_SIZE, \n                                   TARGET_SIZE, \n                                   interpolation=cv2.INTER_NEAREST),\n    albumentations.HorizontalFlip(p=0.5),\n\n])\n\nval_augs = albumentations.Compose([\n    albumentations.Resize(TARGET_SIZE, TARGET_SIZE, interpolation=cv2.INTER_NEAREST)\n])\n\nclass Dataset:   \n    def __init__(\n            self, \n            images, \n            masks,\n            augmentations=None\n    ):\n        self.images = images\n        self.masks = masks\n        self.augmentations = augmentations\n    \n    def __getitem__(self, i):\n        image = self.images[i]\n        mask = self.masks[i]\n        \n        if self.augmentations:\n            sample = self.augmentations(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n        return image, mask\n        \n    def __len__(self):\n        return len(self.images)\n    \n    \nclass Dataloder(tensorflow.keras.utils.Sequence):\n    \"\"\"Load data from dataset and form batches\n    \n    Args:\n        dataset: instance of Dataset class for image loading and preprocessing.\n        batch_size: Integet number of images in batch.\n        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n    \"\"\"\n    \n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(dataset))\n\n        self.on_epoch_end()\n\n    def __getitem__(self, i):\n        \n        # collect batch data\n        start = i * self.batch_size\n        stop = (i + 1) * self.batch_size\n        images = []\n        masks = []\n        for j in range(start, stop):\n            image, mask = self.dataset[self.indexes[j]]\n            images.append(image)\n            masks.append(mask)\n        \n        images = np.stack(images, axis=0)\n        masks = np.stack(masks, axis=0).astype(np.float32)\n        \n        return (images, masks)\n    \n    def __len__(self):\n        \"\"\"Denotes the number of batches per epoch\"\"\"\n        return len(self.indexes) // self.batch_size\n    \n    def on_epoch_end(self):\n        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n        if self.shuffle:\n            self.indexes = np.random.permutation(self.indexes)\n            \ntrain_dataset = Dataset(train_images, train_masks, train_augs)\nval_dataset = Dataset(val_images, val_masks, val_augs)\n\ntrain_dataloader = Dataloder(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = Dataloder(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T20:54:27.753166Z","iopub.execute_input":"2021-05-31T20:54:27.753614Z","iopub.status.idle":"2021-05-31T20:54:35.194488Z","shell.execute_reply.started":"2021-05-31T20:54:27.753569Z","shell.execute_reply":"2021-05-31T20:54:35.191882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from segmentation_models import Unet\nimport segmentation_models as sm\n\nclassification_model = resnet101(weights=\"imagenet\")\n\nsegmentation_model = Unet(backbone_name='efficientnetb0',\n                  encoder_weights='imagenet',\n                  classes=8, \n                  activation='softmax')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T20:54:35.195485Z","iopub.status.idle":"2021-05-31T20:54:35.195998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nmodel = Sequential([Input(shape=(TARGET_SIZE, TARGET_SIZE, 1)),\n                    Conv2D(3, (1, 1)),  # map N channels data to 3 channels\n                    base_model])\n    \nmodel.compile(Adam(learning_rate=0.001, amsgrad=True),\n              loss=sm.losses.categorical_crossentropy,\n              metrics=[accuracy, fscore])\n\ncheckpoint_callback = ModelCheckpoint('best_model',\n                                      monitor='fscore',\n                                      mode='max',\n                                      save_best_only=True)\n\nmodel.fit(\n    train_dataloader,\n    steps_per_epoch=len(train_dataloader) * 6,\n    epochs=30,\n    validation_data=val_dataloader,\n    validation_steps=len(val_dataloader),\n    callbacks=[checkpoint_callback],\n    workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T20:54:35.19735Z","iopub.status.idle":"2021-05-31T20:54:35.198043Z"},"trusted":true},"execution_count":null,"outputs":[]}]}