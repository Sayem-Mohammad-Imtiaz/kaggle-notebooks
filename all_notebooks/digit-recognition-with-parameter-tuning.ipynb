{"cells":[{"metadata":{"heading_collapsed":true,"_uuid":"51e3577debd5ec8f9a6adc92dfa716b1e9420e7b"},"cell_type":"markdown","source":"# Digit Recognition\n\nIn this project, I will work with the MNIST dataset which includes a large number of images with each image representing a digit from `0` to `9`. The aim of this project is to train a model on the data and correctly classify the images. As an extension, I will work with `GridSearchCV` to tune parameters and extract the best parameters for the model."},{"metadata":{"heading_collapsed":true,"hidden":true,"_uuid":"7f62f6a600ab3fed5d5502933791db931109e8f7"},"cell_type":"markdown","source":"## Import libraries and dataset\n\nI import `numpy`, and `pandas` to work with data. Next, I use `matplotlib` to read images and draw visualizations. Finally, I use `sklearn` to import necessary subpackges to get the model to train on the data."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"34600bca3376ce805ae18b8ca74f22584b4c3ba3"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import rainbow\n%matplotlib inline\n\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"_uuid":"e4f9850dc89940f43ca4645b7479415f63eb3f6b"},"cell_type":"markdown","source":"We can read the dataset from the files already present in Kaggle."},{"metadata":{"hidden":true,"_kg_hide-input":true,"trusted":true,"_uuid":"81a28f3ed26eda00645f18a6f7f62c2a12fc196c"},"cell_type":"code","source":"train_data = pd.read_csv('../input/mnist_train.csv')\ntest_data = pd.read_csv('../input/mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"trusted":true,"_uuid":"178ea26e1532af689975b5d6812802bc78a98289"},"cell_type":"code","source":"print(\"Training data:\")\nprint(\"Shape: {}\".format(train_data.shape))\nprint(\"Total images: {}\".format(train_data.shape[0]))\n\nprint(\"Testing data:\")\nprint(\"Shape: {}\".format(test_data.shape))\nprint(\"Total images: {}\".format(test_data.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"_uuid":"38875b76b5a75c6350f3159cfb33ebcdd39f0535"},"cell_type":"markdown","source":"There are **60,000 training images** and **10,000 testing images**. The dataset includes the class inside the column name `label`. I'll now separate the features and labels for both training and testing data."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"92a3f54ab980720674952b431d83e3cdd30c7591"},"cell_type":"code","source":"train_y = train_data['label']\ntrain_X = train_data.drop(columns = ['label'])\n\ntest_y = test_data['label']\ntest_X = test_data.drop(columns = ['label'])","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true,"hidden":true,"_uuid":"3af5cffb188df11ee2a59d8403a1d49ba417cba5"},"cell_type":"markdown","source":"## Exploring data\n\nHere, I'll keep the testing dataset aside and work with the training data only. I'll now use test data only during final model evaluation."},{"metadata":{"heading_collapsed":true,"hidden":true,"_uuid":"d93b2b5ad18cd5f281451ba3c10bcb8a429d690c"},"cell_type":"markdown","source":"### Analysing class distribution\n\nFirst, I count the labels in the training set and check if the classes include comparatively equal count of images."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"c7bfdbaf4ff800924b1a1f5d8f5f3244f98dcabd"},"cell_type":"code","source":"train_labels = train_y.value_counts()\nplt.figure(figsize = (12, 8))\ncmap = rainbow(np.linspace(0, 1, train_labels.shape[0]))\nplt.bar(train_labels.index.values, train_labels, color = cmap)\nplt.xticks(train_labels.index.values)\nplt.xlabel('Digits')\nplt.ylabel('Count of images')\nplt.title('Count of images for each digit (0 - 9)')","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"_uuid":"22e816061be466f14889fb330fb1175f669ba959"},"cell_type":"markdown","source":"While there is some variation across count of images for each class, the variation can be ignored and we can proceed to analyse the data further as it won;t hugely impact the training of the model."},{"metadata":{"heading_collapsed":true,"hidden":true,"_uuid":"c09d5753dc6725c04562ef9ce3d4e96dd3895a8b"},"cell_type":"markdown","source":"### Viewing the training data images\n\nI'll now randomly select 10 images from the training data and view them."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"6c928314396d641ba76236a16e3ff8907771039d"},"cell_type":"code","source":"np.random.seed(0)\nplt.figure(figsize = (20, 8))\nfor i in range(10):\n    index = np.random.randint(train_X.shape[0])\n    image_matrix = train_X.iloc[index].values.reshape(28, 28)\n    plt.subplot(2, 5, i+1)\n    plt.imshow(image_matrix, cmap=plt.cm.gray)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"_uuid":"97a02796d4be5a04b8a054d369fa1ca1f2699f49"},"cell_type":"markdown","source":"While it's easy to recognize the digit represented by each image, one must note that not each digit's image matches the other. The three images of `4` is different from one another in the form of style as well as thickness. This would make learning for the machine learning challenging. Let's see how Random Forest performs on the dataset."},{"metadata":{"heading_collapsed":true,"hidden":true,"_uuid":"d268f4ac9aba48e9e87a1c4de0abf00542e3a20f"},"cell_type":"markdown","source":"## Applying Machine Learning\n\nAfter analysing the data, I'll now apply **Random Forest Classifier** using the default parameter values."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"683fde2d06e46e511b8a2edcdc515059e4ee99c1"},"cell_type":"code","source":"random_forest_classifier = RandomForestClassifier()\nrandom_forest_classifier.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true,"hidden":true,"_uuid":"8ff91a4e1c5ec2eb7e27ba708a62a176fc693d08"},"cell_type":"markdown","source":"## Classifying and analysing\n\nNow, I'll use the trained model to classify the testing images and analyse the results. First, I'll use the `predict` method to predict the results on the test data."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"70676928981bbffa5382fc7c8155276dcbc31181"},"cell_type":"code","source":"pred_y = random_forest_classifier.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true,"hidden":true,"_uuid":"2a595c85c33c15ab552117a4404ddf7c17db9c56"},"cell_type":"markdown","source":"### Metrics\n\nI'll use **accuracy_score** and **confusion_matrix** to analyse the classification done by the model."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"b8aa1f7a372ea7495a5aaaf1e010b6c931a31195"},"cell_type":"code","source":"print(\"Accuracy: {}%\".format(accuracy_score(test_y, pred_y)*100))\nprint(\"Confusion Matrix:\")\nprint(\"{}\".format(confusion_matrix(test_y, pred_y)))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"_uuid":"ffd2cb3f0ad7f832bdc82a8a493720d21454bc5e"},"cell_type":"markdown","source":"### Analysing"},{"metadata":{"hidden":true,"_uuid":"822f9a7ffa111a4c9e927954a6429c264e6d78b4"},"cell_type":"markdown","source":"Taking a look at the metrics, the model has very well performed on the test data and has acheived an **accuracy of 94.42%**. The confusion matrix also displays the same trend where majority classes are correctly identified as can be seen with the values across the diagonal."},{"metadata":{"hidden":true,"_uuid":"482cbd7279cbb06fcf9adfe1848ae1208366603c"},"cell_type":"markdown","source":"Let's also take a look at 10 examples from the test data and see how correctly our model predicts."},{"metadata":{"hidden":true,"trusted":true,"_uuid":"3423270f0efa7e60e9e75685acff50ebe82fcbd2"},"cell_type":"code","source":"np.random.seed(0)\nplt.figure(figsize = (20, 8))\nfor i in range(10):\n    index = np.random.randint(test_X.shape[0])\n    image_matrix = test_X.iloc[index].values.reshape(28, 28)\n    plt.subplot(2, 5, i+1)\n    plt.imshow(image_matrix, cmap=plt.cm.gray)\n    plt.title(\"Model predicted number: {}\".format(random_forest_classifier\n                                                  .predict(test_X.iloc[index].values.reshape(1, -1))[0]))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true,"_uuid":"eeba2cab7055a39dd8d44ed480fe5b1fffd86573"},"cell_type":"markdown","source":"It's amazing how the model is even able to predict the 9th image as `2` which is very difficult to predict even for a human. However, it incorrectly predicts the 8th image as `3` while it clearly is `5`."},{"metadata":{"_uuid":"cf0fe4f979f78fd70c4e70c0aa8eead508136a61"},"cell_type":"markdown","source":"# Parameter Tuning\n\nIn this part, I will use `GridSearchCV` to identify the best parameters for the estimator and then use it to check if the accuracy for test data has improved or not."},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"e04e4748078cff2a6b256bd294ef156066582fc3"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 50, 100],\n    'min_samples_split': [2, 4],\n    'max_features': ['sqrt', 'log2']\n}\n\ngrid = GridSearchCV(random_forest_classifier, param_grid = param_grid, cv = 5, verbose = 5, n_jobs = -1)\ngrid.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35b0c477c831feb52f8b4c7d292528f7209841de"},"cell_type":"markdown","source":"The `grid` shall now have the best estimator parameters for **Random Forest Classifier**. I will now save the model in the variable `best_estimator`."},{"metadata":{"trusted":true,"_uuid":"f9be5cc40cef76372ecb94efd866480a68b0a15c"},"cell_type":"code","source":"best_estiomator = grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f5caabf418e5741b508acf93bb6b9fe0ae44064"},"cell_type":"markdown","source":"As my model is now ready, I'll simply use it to predict the results on the test data and calculate both `accuracy_score` and `confusion_matrix`."},{"metadata":{"trusted":true,"_uuid":"0f90c001d73d6cdaf93579e55dc029bfa01fa446"},"cell_type":"code","source":"best_pred_y = best_estiomator.predict(test_X)\nprint(\"Accuracy: {}%\".format(accuracy_score(test_y, best_pred_y)*100))\nprint(\"Confusion Matrix:\")\nprint(\"{}\".format(confusion_matrix(test_y, best_pred_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d87c75eed9bac903d8ba115f8547eef18a1203a9"},"cell_type":"markdown","source":"As we can see, just by selecting the best combination of parameters for our model, I was able to improve the accuracy of the **Random Forest Classifier** to **97.08%** from **94.42%**."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}