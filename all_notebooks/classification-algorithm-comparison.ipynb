{"cells":[{"metadata":{"_uuid":"bef591877799ad7c27a17f7aa4c022e47e792dab"},"cell_type":"markdown","source":"# Comparison of Various Machine Learning Module Using UCI Heart Disease Data"},{"metadata":{},"cell_type":"markdown","source":"**In this karnel compare result of various machine learning module using the scikit-learn package**"},{"metadata":{"_uuid":"0bf0c2c5e3307c34f42fe785dc6637c1d08a36a2"},"cell_type":"markdown","source":"**Importing the required libaries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom  sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nplt.style.use('seaborn')\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"file_name = '../input/heart.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e92a6fc73ebc7cfb268578a5aaf68db2f0c3fb85"},"cell_type":"code","source":"data_df = pd.read_csv(file_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"925376726a16626fb5142a69d5639c7d28939dd3"},"cell_type":"code","source":"data_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns\nage: age in years\nsex: (1 = male; 0 = female)\ncp: chest pain type\ntrestbps: resting blood pressure (in mm Hg on admission to the hospital)\nchol:serum cholestoral in mg/dl\nfbs:(fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\nrestecg:resting electrocardiographic results\nthalach:maximum heart rate achieved\nexang:exercise induced angina (1 = yes; 0 = no)\noldpeak:ST depression induced by exercise relative to rest\nslope:the slope of the peak exercise ST segment\nca:number of major vessels (0-3) colored by flourosopy\nthal:3 = normal; 6 = fixed defect; 7 = reversable defect\ntarget:1 or 0 "},{"metadata":{"_uuid":"9a9e17a7ae0b6fe6d41588b096ff669524516d75"},"cell_type":"markdown","source":"### Checking for Null Values\nIf there are any null values we need to handle them. To learn about various ways to handle the missing values go through [this](http://www.dipeshpoudel.com.np/2018/08/16/foreplay-before-doing-data-part-i-handling-missing-data/) blog post written by me."},{"metadata":{"trusted":true,"_uuid":"9db6dc65354df401324cd01e9fb0ac181279d760"},"cell_type":"code","source":"pd.DataFrame(data_df.isna().sum(),columns=['null_count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are no missing values we do not need to handle them"},{"metadata":{},"cell_type":"markdown","source":"In the given dataset all the data are in the numeric form but they are not continuous data. In this particular case the description of each column is given and we can use it to determine which is a numerical column is and which is a categorical. If this information is not provided then we can use take a look at the distribution plot of each column to determine if the column is categorical or numerical in nature."},{"metadata":{"trusted":true,"_uuid":"832d936dfd264636d06fb1322b08895c3e16312b"},"cell_type":"code","source":"for col in data_df.columns:\n    fig, ax = plt.subplots(figsize=(20, 10))\n    sns.distplot(data_df[col])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['target'].value_counts().plot(kind='bar')\nplt.title(\"Target Frequency\")\nplt.xlabel(\"Target\")\nplt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the observation of the charts above we need to convert some of the columns to categorical."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype_map={\"sex\":\"category\",\"cp\":\"category\",\"fbs\":\"category\",\"restecg\":\"category\",\"exang\":\"category\",\n           \"slope\":\"category\",\"ca\":\"category\",\"thal\":\"category\",\"target\":\"category\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = data_df.astype(dtype_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = data_df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_df.drop(columns=['target'])\ny = data_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare models\nmodels = []\nmodels.append((\"LogisticRegression\",LogisticRegression()))\nmodels.append((\"SVC\",SVC()))\nmodels.append((\"LinearSVC\",LinearSVC()))\nmodels.append((\"KNeighbors\",KNeighborsClassifier()))\nmodels.append((\"DecisionTree\",DecisionTreeClassifier()))\nmodels.append((\"RandomForest\",RandomForestClassifier()))\nrf2 = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0, max_features=None)\nmodels.append((\"RandomForest2\",rf2))\nmodels.append((\"MLPClassifier\",MLPClassifier()))\n# evaluate each model in turn\nresults = []\nnames = []\nseed=0\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    cross_val_result = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(\"Print the Corss Validation Result {}\".format(name))\n    print(cross_val_result)\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    cm = confusion_matrix(y_test,y_pred)\n    plot_confusion_matrix(cm=cm, classes=[0,1])\n    acc_score = accuracy_score(y_test,y_pred)\n    print(\"Accuracy Score of {} is {}\".format(name,acc_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"From the analysis above we can reach the following conclusion:\n1. The cross validation score shows that Random Forest is the best model for this dataset since the average accuarcy from cross validation is high and the standard deviation (value inside bracket) is low.\n2. In terms of accuracy Multi Layer Precprton (MLP) is the best model."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}