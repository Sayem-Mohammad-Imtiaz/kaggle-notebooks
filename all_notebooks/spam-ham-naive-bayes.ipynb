{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\ndata_dir = \"../input/\"\n\ndf = pd.read_csv(data_dir + '/spam.csv', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14709194741622cf2b770ee66a9303dd80728e49"},"cell_type":"code","source":"# observe the data\nprint(df.head())\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9a4c80e87ba0eb65878903078c293f8d391bbea4"},"cell_type":"markdown","source":"**Split dataset into train test**"},{"metadata":{"trusted":true,"_uuid":"b7a19d80feda9ce247c337c5ea33519da4c0528a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# split into train and test\ndata_train, data_test, labels_train, labels_test = train_test_split(\n    df.v2,\n    df.v1, \n    test_size=0.2, \n    random_state=0) \n\nprint (data_train.head())\nprint (labels_train.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bd16bc846126da7aab41d8dbe690641db56c90a"},"cell_type":"markdown","source":"**'CountVectorizer' demo**"},{"metadata":{"trusted":true,"_uuid":"e3b683281112b17713f196e46edd3c3daabba7ef"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nvect = CountVectorizer()\nexample = ['I love you, good bad bad', 'you are soo good']\n\nresult = vect.fit_transform(example)\nprint(result)\nprint (vect.vocabulary_)\nprint('\\n')\n\nresult1 = vect.transform(example)\nprint(result1)\nprint (vect.vocabulary_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd3414e2649bc133f3a3aab12e323de1485d621b"},"cell_type":"markdown","source":"**Count the number of vectors in training dataset -- method 1**"},{"metadata":{"trusted":true,"_uuid":"d8485a37370b99f8c16eb0267d002e12cb0f4a64"},"cell_type":"code","source":"vectorizer = CountVectorizer()\n\ndata_train_count = vectorizer.fit_transform(data_train)\ndata_test_count  = vectorizer.transform(data_test)\nprint (data_train_count.shape)\nprint (data_test_count.shape)\n# print (vectorizer.vocabulary_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54bbb491db3391273aef04767f31b9f079f92040"},"cell_type":"markdown","source":"**Count the number of vectors in training dataset -- method 2**"},{"metadata":{"trusted":true,"_uuid":"f7cfbf49aedac3a5de3d9fbc829e1e1630ebb998"},"cell_type":"code","source":"# Count the total numbers of unique word\ndef GetVocabulary(data): \n    vocab_set = set([])\n    for document in data:\n        words = document.split()\n        for word in words:\n            vocab_set.add(word) \n    return list(vocab_set)\n\nvocab_list = GetVocabulary(data_train)\nprint ('Number of all the unique words : ' + str(len(vocab_list)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fde1a9b7d69002d89b813d90429e2282078b606b"},"cell_type":"code","source":"# function that convert sentences into word vectors\ndef Document2Vector(vocab_list, data):\n    word_vector = np.zeros(len(vocab_list))\n    words = data.split()\n    for word in words:\n        if word in vocab_list:\n            word_vector[vocab_list.index(word)] += 1\n    return word_vector\n\nprint (data_train[1:2,])\nprint (data_train.values[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"675ff43d8212aa460b3ce3dcbd499e7150cdec82"},"cell_type":"code","source":"train_matrix = []\nfor document in data_train.values:\n    word_vector = Document2Vector(vocab_list, document)\n    train_matrix.append(word_vector)\n\nprint (len(train_matrix))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3271176d17f72b6652f3241394163aadc19c7180"},"cell_type":"code","source":"word_freq_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'occurrences':data_train_count.toarray().sum(axis=0)})\nword_freq_df['frequency'] = word_freq_df['occurrences'] / np.sum(word_freq_df['occurrences'])\nplt.plot(word_freq_df.occurrences)\nplt.show()\n\nword_freq_df_sort = word_freq_df.sort_values(by=['occurrences'], ascending=False)\nprint(word_freq_df_sort.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54fc22715215eb3579adbc22cc1db0d41d04bb0c"},"cell_type":"markdown","source":"**Model training**"},{"metadata":{"trusted":true,"_uuid":"f65342f9b6e0f9209b5fedbf5e98d68979d4ed10"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\n\nmodel = MultinomialNB()\nmodel.fit(data_train_count, labels_train)\npredictions = model.predict(data_test_count)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee53c8aa735bbc8383e5ce8162dc5b0d29ab8654"},"cell_type":"markdown","source":"**Print evaluation scores of our model**"},{"metadata":{"trusted":true,"_uuid":"1cfc52782973747e4c38e2bd733324dae212a6c0"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nfrom sklearn.model_selection import cross_val_score\n\nprint (accuracy_score(labels_test, predictions))\nprint (classification_report(labels_test, predictions))\nprint (confusion_matrix(labels_test, predictions))\n\ncross_val = cross_val_score(model, data_train_count, labels_train, cv=20, scoring='accuracy')\nprint (cross_val)\nprint (np.mean(cross_val))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}