{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing relevant libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport tensorflow as tf\nimport math\nfrom scipy import special #comb, factorial\nfrom keras import backend as K\nfrom scipy.stats import uniform\nfrom matplotlib import pyplot as plt\nfrom sklearn import tree\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest,chi2\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler,LabelEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, recall_score, make_scorer, plot_confusion_matrix, confusion_matrix, accuracy_score,f1_score\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/internet-articles-data-with-users-engagement/articles_data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting basic info"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how many nulls we have"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will remove columns that won't be used"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cols_to_remove = ['Unnamed: 0', \n                  'source_id',\n                  'author','url', \n                  'url_to_image',\n                  'description',\n                  'content'\n                 ]\n\ndf.drop(cols_to_remove,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We further drop rows with nulls"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we cleaned our dataset, we can begin exploring."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many media organizations our dataset took articles from?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['source_name'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the distribution"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.countplot(x=df['source_name'],order=df['source_name'].value_counts().index)\nplt.xticks(rotation=45)\nplt.title('Count of articles per each newspaper')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's look at the distribution of the time when the articles were published."},{"metadata":{},"cell_type":"markdown","source":"The earliest article in the dataset was published at:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['published_at'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The latest article in the dataset was published at:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['published_at'].max()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\ndf['published_at'] = pd.to_datetime(df['published_at'])\ndf['published_at'].hist()\nplt.xticks(rotation=45)\nplt.title('Distribution of time the articles were published at')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's look at the continuous features."},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features = ['engagement_reaction_count', 'engagement_comment_count',\n       'engagement_share_count', 'engagement_comment_plugin_count']\ndf[cont_features].describe().round(2).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that there are pretty extreme oultiers here (e.g., `engagement_reaction_count`'s 75% percentile is 43, but the max is 354132). Furthermore, we see that most values in `engagement_comment_plugin_count` are zero. Let's check out how many zero values there are."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"zerov = df[df['engagement_comment_plugin_count'] == 0].shape[0]\nnonzerov = df[df['engagement_comment_plugin_count'] != 0].shape[0]\n\nprint(f'Number of zero values in `engagement_comment_plugin_count`: {zerov}')\nprint(f'Number of non-zero values in `engagement_comment_plugin_count`: {nonzerov}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that only $0.4\\%$ values in `engagement_comment_plugin_count` are non-zero. Due to the extremely low variance, we will remove this column"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.drop(['engagement_comment_plugin_count'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the distributions of the remaining continuous features using histogram (to make graphs more readable, we will ignore all entries where values exceed 75th percentile)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cont_features = ['engagement_reaction_count', 'engagement_comment_count',\n       'engagement_share_count']\nWIDTH = 20\nLENGTH = 7\n\nrows = math.ceil(len(cont_features)/3)\nfig, ax = plt.subplots(1,3,figsize=(WIDTH,LENGTH))\nax = ax.flatten()\nfor i,feature in enumerate(cont_features):\n    ax[i].hist(df[df[feature] < df[feature].quantile(.75)][feature],alpha=0.6)\n    ax[i].set_title(f'Distribution of a feature `{feature}`')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that even after we removed all entries with larger values, the tail still remains."},{"metadata":{},"cell_type":"markdown","source":"# Are continuous features correlated?\n\nWe would expect them to be, but let's check anyways."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cont_features = ['engagement_reaction_count', \n                 'engagement_comment_count',\n                 'engagement_share_count']\n\ndf1 = df[cont_features]\ncorr=df1.corr()\n\nplt.figure(figsize=(10,7))\nsns.heatmap(corr,\n            xticklabels=df1.columns,\n            yticklabels=df1.columns,\n           annot=True)\nplt.title('Correlation matrix of the continuous features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, we have a very strong positive correlation between features."},{"metadata":{},"cell_type":"markdown","source":"# Which newspapers have the most shared articles?\n\nWe define \"one of the most shared articles\" as an article whose share count exceeds 75% percentile."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df1 = df[df['engagement_share_count'] > df['engagement_share_count'].quantile(.75)]\n\nplt.figure(figsize=(10,8))\nsns.countplot(x=df1['source_name'],order=df1['source_name'].value_counts().index)\nplt.xticks(rotation=45)\nplt.title(\"Count of the most shared articles\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's an interesting finding: If we consider ALL articles, CNN is on the 4th place; yet if we consider most shared articles, CNN comes on top."},{"metadata":{},"cell_type":"markdown","source":"# Which newspapers has the highest proportion of the most shared articles?\n\nThe proportion will be calculated as:\n\n$$\\frac{\\text{Count of most shared articles published by }X}{\\text{Count of all articles published by } X}$$"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df1 = df[['source_name','engagement_share_count']].copy()\ndf1['> 0.75'] = df1['engagement_share_count'] > df1['engagement_share_count'].quantile(0.75)\ndf1 = df1.groupby(['source_name','> 0.75']).count()\ndf1['percent'] = df1.groupby(level=0).transform(lambda x: (x / x.sum()).round(2))\ndf1.reset_index(inplace=True)\ndf1 = df1[df1['> 0.75'] == True]\n\n\n\nplt.figure(figsize=(12,8))\nsns.barplot(x=df1['source_name'],\n            y=df1['percent'],\n            order=df1.sort_values(by='percent', ascending=False)['source_name'])\nplt.xticks(rotation=45)\nplt.title('Proportion of most shared articles')\nplt.ylabel('Proportion (%)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result almost agrees with out previous graph (although there some changes (e.g., BBC moving downards and WS journal moving up to top 4))"},{"metadata":{},"cell_type":"markdown","source":"# Which newspapers have the articles with the most user activity?\n\nBy \"user activity\" we mean the value in `engagement_reaction_count`\n\nBy \"most\" we mean that value must exceed 75th percentile."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df1 = df[df['engagement_reaction_count'] > df['engagement_reaction_count'].quantile(.75)]\n\nplt.figure(figsize=(10,8))\nsns.countplot(x=df1['source_name'],order=df1['source_name'].value_counts().index)\nplt.xticks(rotation=45)\nplt.title(\"Count of the most reacted to articles\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The top 5 remains almost unchanged. Although it is worth noting that when we were considering newspapers with top share count, Reuters was in top 3, but when we consider `engagement_reaction_count`, Reuters drops to the very bottom."},{"metadata":{},"cell_type":"markdown","source":"# Are continuous variables correlated with the `source_name`?\n\nWe will use ANOVA to test independence between each continuous feature and `source_name` (which itself is a categorical variable listing all the publishers)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from scipy.stats import f_oneway\n\ncont_features = ['engagement_reaction_count', \n                 'engagement_comment_count',\n                 'engagement_share_count']\n\nlabel = 'source_name'\ndic = {'Categorical': [],\n    'Numerical': [],\n    'p-value': [],\n    'p < 0.05': [],\n    'statistic': []}\n\n\nfor feature in cont_features:\n    values = []\n    for value in df[label].unique():\n        values.append(df[df[label] == value][feature].values)\n    \n    statistic, pval = f_oneway(*values)\n    \n    dic['Categorical'].append(label)\n    dic['Numerical'].append(feature)\n    dic['p-value'].append(pval)\n    dic['p < 0.05'].append(pval<0.05)\n    dic['statistic'].append(statistic)\n\n\npd.DataFrame(dic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that the `source_name` is indeed strongly correlated with all numerical variables, implying that numerical variables may have significant predictive power (if we are to try to predict `source_name`)"},{"metadata":{},"cell_type":"markdown","source":"# What are the most frequent words in our articles? (all articles)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS \n\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n  \n# iterate through the csv file \nfor val in df['title']: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word cloud gives us a pretty good idea of what most articles are about: politics. \n\nNow let's take a look at the world cloud of the MOST SHARED articles"},{"metadata":{},"cell_type":"markdown","source":"# What are the most frequent words in our articles? (top 25% most shared articles)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS \n\n\ncomment_words = '' \nstopwords = set(STOPWORDS) \n  \ndf1 = df[df['engagement_share_count'] > df['engagement_share_count'].quantile(0.75)].copy()\n# iterate through the csv file \nfor val in df1['title']: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pattern is almost unchanged. What is interesting to note though, words like \"China\", \"Hong Kong\", \"Brexit\" are more frequent in the top 25% articles (signified by the larger fontsize)."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Conclusions:\n\n1. Most articles are about politics.\n2. Distribution of the number of articles published by each newspaper is quite uneven. For example: the dataset contains over 1k articles published by Reuters, yet there are only $82$ articles published by ESPN.\n2. Reuters, BBC news and ABC news have the biggest number of articles in the dataset. Yet the most shared articles are those of CNN, NY times and Reuters. Furthermore, the most reacted to articles are published by NY times, CNN and CBS news.\n3. Distributions of the features `engagement_reaction_count`, `engagement_comment_count`,`engagement_share_count` have very long tails to the right, which implies that most articles have fairly low user activity (few comments, few shares etc.), but some articles are **very** popular (with views,shares exceeding tens of thousands).\n4. `engagement_reaction_count`, `engagement_comment_count`,`engagement_share_count`  have strong positive correlation between each other, in other words: More comments implies more sharing, more shares implies more reactions (and vice versa).\n5. Continuous features `engagement_reaction_count`, `engagement_comment_count`,`engagement_share_count` are not independent from the categorical variable `source_name` (which is just a variable listing the publishers of the articles). That means that if we are to try to predict the publisher of an article, the aforementioned numerical features may have significant predictive power."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}