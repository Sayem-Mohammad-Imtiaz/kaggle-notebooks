{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing all required packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import xticks\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set the maximum display columns and rows\npd.set_option('display.max_columns', 111)\npd.set_option('display.max_rows', 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading and Understanding the Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing dataset\ndf = pd.read_csv(\"/kaggle/input/house-price-prediction/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Column which contains null data\nround(100*(df.isnull().sum()/len(df.index)), 2)[round(df.isnull().sum()/len(df.index), 2).values > 0.00].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking numeric column data\ndf.select_dtypes(include=['float64', 'int64']).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert year column to number or calculate the age for the column YearBuilt, YearRemodAdd, GarageYrBlt, YrSold\ndf['AgeYearBuilt'] = df.YearBuilt.max() - df['YearBuilt']\ndf['AgeYearRemodAdd'] = df.YearRemodAdd.max() - df['YearRemodAdd']\ndf['AgeGarageYrBlt'] = df.GarageYrBlt.max() - df['GarageYrBlt']\ndf['AgeYrSold'] = df.YrSold.max() - df['YrSold']\n\n# drop the original column as we will use above created column\ndf.drop(['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['AgeYearBuilt', 'AgeYearRemodAdd', 'AgeGarageYrBlt', 'AgeYrSold']].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As per the above null % below are the column list which has 50 % of missing data so droping it.\n- PoolQC           99.52\n- MiscFeature      96.30\n- Alley            93.77\n- Fence            80.75\n- FireplaceQu      47.26","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping the column which have \ndf.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# No use of 'Id' column so droping it\ndf.drop(['Id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of column still have empty data\nround(100*(df.isnull().sum()/len(df.index)), 2)[round(df.isnull().sum()/len(df.index), 2).values > 0.00].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# viewing data based on the interval percentage\ndf.describe(percentiles = [0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.99, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As per the above details few columns have standard value which we can use as categorical instead of numerical\ndf['MoSold'] = df['MoSold'].astype('object')\ndf['OverallQual'] = df['OverallQual'].astype('object')\ndf['OverallCond'] = df['OverallCond'].astype('object')\ndf['BsmtFullBath'] = df['BsmtFullBath'].astype('object')\ndf['BsmtHalfBath'] = df['BsmtHalfBath'].astype('object')\ndf['FullBath'] = df['FullBath'].astype('object')\ndf['HalfBath'] = df['HalfBath'].astype('object')\ndf['BedroomAbvGr'] = df['BedroomAbvGr'].astype('object')\ndf['KitchenAbvGr'] = df['KitchenAbvGr'].astype('object')\ndf['TotRmsAbvGrd'] = df['TotRmsAbvGrd'].astype('object')\ndf['Fireplaces'] = df['Fireplaces'].astype('object')\ndf['GarageCars'] = df['GarageCars'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Column which contains outliers \nout_col = [\n    'LotArea',\n    'TotalBsmtSF',\n    'PoolArea',\n    'MiscVal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxplot method to generate the graph to Check the outliers \n\ndef draw_boxplot(cols):\n    int_range = range(len(cols))[::3]\n    col_length = len(cols)\n    for col in int_range:\n        print('----------------',cols[col:col+3],' ----------------')\n        plt.figure(figsize=(17, 5))\n        if col < col_length:  \n            plt.subplot(1,3,1)\n            sns.boxplot(x=cols[col], orient='v', data=df)\n        if col+1 < col_length:                    \n            plt.subplot(1,3,2)\n            sns.boxplot(x=cols[col+1], orient='v', data=df)\n        if col+2 < col_length:                \n            plt.subplot(1,3,3)\n            sns.boxplot(x=cols[col+2], orient='v', data=df)\n                        \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method call to draw boxplot for the outliers\ndraw_boxplot(out_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Size before removing the outliers\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# method to remove outliers\ndef remove_outliers(x, num_cols, s_quntl=0.05, e_quntl=0.95):\n    for col in num_cols:\n        Q1 = x[col].quantile(s_quntl)\n        Q3 = x[col].quantile(e_quntl)\n        IQR = Q3-Q1\n        x =  x[(x[col] >= (Q1-(1.5*IQR))) & (x[col] <= (Q3+(1.5*IQR)))] \n    return x   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# call remove outliers method for the selected columns\ndf=remove_outliers(df, out_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataframe size after removing the outliers\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(percentiles = [0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to replace the null value with the selected values\ndef filling_missing_values(col, replace_type:str, other_value=None):\n    if replace_type == 'mean':\n        df[col].fillna(df[col].mean(), inplace=True)  \n    if replace_type == 'mode':\n        df[col].fillna(df[col].mode()[0], inplace=True)\n    if replace_type == 'median':\n        df[col].fillna(df[col].median(), inplace=True)\n    if replace_type == 'other':\n        df[col].fillna(other_value, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of columns which contains null value\nnull_cols = df.columns[round(df.isnull().sum()/len(df.index), 2).values > 0.00]\nnull_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# column list which has null value\ndf[null_cols].describe(percentiles = [0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical value updating using mode values\nfor col in null_cols:\n    if col not in ['LotFrontage', 'AgeGarageYrBlt', 'MasVnrArea']:\n        filling_missing_values(col, 'mode')\n\n# updating with mean value for the variable MasVnrArea   \nfilling_missing_values('LotFrontage', 'mean') \nfilling_missing_values('MasVnrArea', 'mean') \nfilling_missing_values('AgeGarageYrBlt', 'other', other_value=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the column which still have null values\nround(100*(df.isnull().sum()/len(df.index)), 2)[round(df.isnull().sum()/len(df.index), 2).values > 0.00].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols=df.select_dtypes(include=['int64', 'float']).columns\nnum_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to fetch column list which contains more than 90% duplicate value\ndef percentage_of_duplicate(num_cols):\n    x=list()\n    for col in (num_cols):\n        if(df[col].value_counts().max()/df.shape[0] >= 0.90):\n            x.append(col)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop filtered column\nfilter_cols=percentage_of_duplicate(num_cols)\nprint(filter_cols)\ndf.drop(filter_cols, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# target variable SalePrice\nplt.figure(figsize=(15,5))\nplt.title('SalePrice')\nsns.distplot(df.SalePrice)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('SalePrice')\nsns.distplot(np.log1p(df['SalePrice']), bins=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nstats.probplot(df['SalePrice'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method to viewing all the categorical variable\ndef categorical_data(cols):\n    for col in cols:\n        print('\\n')\n        print('---------------------------------------------- ',col,' -----------------------------------------------')\n        print(df[col].astype('category').value_counts())\n        f, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(12,3), dpi=90) \n        sns.countplot(data=df, x=col, order=df[col].value_counts().index, ax=ax1) \n        ax1.set_ylabel('Count') \n        ax1.set_title(f'{col}', weight=\"bold\") \n        ax1.set_xlabel(col) \n        if col == 'Neighborhood':\n            xticks(rotation = 90)\n        plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of categorical columns\ncateg_var = df.select_dtypes(include=['object']).columns\n# Visualise the data\ncategorical_data(categ_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As per the above graph Street and utilities has lower variance so dorpping it\ndf.drop(['Street','Utilities'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Numerical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numerical variable analysis using pairplots\ndef numerical_data(cols):\n    int_range = range(len(cols))[::3]\n    col_length = len(cols)\n    for col in int_range:\n        print('------------------ ',cols[col:col+3],' ---------------------')\n        sns.pairplot(df, x_vars=cols[col:col+3], y_vars='SalePrice',height=3, aspect=1,kind='scatter')            \n        plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of numeric columns \nnum_cols=df.select_dtypes(include=['int64', 'float']).columns\nnum_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = num_cols.drop(labels='SalePrice')\nnum_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the numerical values using pairplots\n\n# Target variable SalePrice and other variables\nnumerical_data(num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation table to check the correlation for the variable with others\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap to check correlatoin between the variables \nfig, ax = plt.subplots() \nfig.set_size_inches(35, 30) \nsns.heatmap(df.corr(),cmap =\"YlGnBu\",linewidths = 0.1, annot = True)\ntop, bottom = ax.get_ylim()\nax.set_ylim(top+0.5, bottom-0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# positive correlation with SalePrice greater than 50%\ncorr = df.corr()\ntop_feature = corr.index[abs(corr['SalePrice']>0.5)]\nfig, ax = plt.subplots() \nfig.set_size_inches(15, 10) \ntop_corr = df[top_feature].corr()\nsns.heatmap(top_corr,cmap =\"YlGnBu\",linewidths = 0.1, annot = True)\ntop, bottom = ax.get_ylim()\nax.set_ylim(top+0.5, bottom-0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# negative correlation with SalePrice less then -0.5\ncorr = df.corr()\ntop_feature = corr.index[abs(corr['SalePrice']<-0.5)]\nfig, ax = plt.subplots() \nfig.set_size_inches(10, 5) \ntop_corr = df[top_feature].corr()\nsns.heatmap(top_corr,cmap =\"YlGnBu\",linewidths = 0.1, annot = True)\ntop, bottom = ax.get_ylim()\nax.set_ylim(top+0.5, bottom-0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preperation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividing dataframe into X and Y sets for the model building\nX=df.drop(columns=['SalePrice'])\ny=np.log(df['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Viewing categorical data\ncategorical_data = X.select_dtypes(include=['object'])\ncategorical_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dummy Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use pandas library to create the dummy variables\ndummies = pd.get_dummies(categorical_data, drop_first=True)\ndummies.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop categorical data for that dummy variable has created\nX=X.drop(columns=categorical_data)\nX.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concat dummies with the X numerical variable\nX=pd.concat([X,dummies],axis=1)\nX.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the Data into Training and Testing Sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Train and test data shape\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rescaling the Features \n\nusing scaling from the sklearn.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_col=X_train.select_dtypes(include=['int64','float64']).columns\nnum_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply scaler() to all the columns except the dummy variables which we creaeted before\nscaler = StandardScaler()\nX_train[num_col] = scaler.fit_transform(X_train[num_col])\nX_test[num_col] = scaler.transform(X_test[num_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RFE\nRecursive feature elimination","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing RFE and LinearRegression from the sklearn\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running RFE with the output number of the variable \nlm = LinearRegression()\nlm.fit(X_train,y_train)\nrfe = RFE(lm, 25)\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe_df = pd.DataFrame(list(zip(X_train.columns,rfe.support_,rfe.ranking_)), columns=['Variable', 'rfe_support', 'rfe_ranking'])\nrfe_df = rfe_df.loc[rfe_df['rfe_support'] == True]\nrfe_df.reset_index(drop=True, inplace=True)\nrfe_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selected column list \ncol = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_train_rfe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building model & evaluations using Ridge & Lasso Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import Ridge and Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\n# from sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ridge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of alphas to tune our model\nparams = {'alpha': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.001, 0.002, 0.003, 0.004, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge \nridge = Ridge()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation \nfolds = 5\nRidgeModelCV = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)           \nRidgeModelCV.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the value of optimum number of parameters\nprint(RidgeModelCV.best_params_)\nprint(RidgeModelCV.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Result based on the mean score\n\nRidgeModelCVResults = pd.DataFrame(RidgeModelCV.cv_results_)\nRidgeCVResults = RidgeModelCVResults[RidgeModelCVResults['param_alpha']<=200]\nRidgeCVResults[['param_alpha', 'mean_train_score', 'mean_test_score', 'rank_test_score']].sort_values(by = ['rank_test_score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nRidgeCVResults['param_alpha'] = RidgeCVResults['param_alpha'].astype('int32')\n# plotting mean for train and test score with alpha \nRidgeCVResults['param_alpha'] = RidgeCVResults['param_alpha']\nplt.figure(figsize=(16,5))\nplt.plot(RidgeCVResults['param_alpha'], RidgeCVResults['mean_train_score'])\nplt.plot(RidgeCVResults['param_alpha'], RidgeCVResults['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RidgeModelCV.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(int(RidgeModelCV.best_params_.get('alpha')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = int(RidgeModelCV.best_params_.get('alpha'))\nridge = Ridge(alpha=alpha)\n\nridge.fit(X_train, y_train)\nridge.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets predict the R-squared value of test and train data\ny_train_pred = ridge.predict(X_train)\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = ridge.predict(X_test)\nprint(metrics.r2_score(y_true=y_test, y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RMSE\nmetrics.mean_squared_error(y_test, ridge.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change in the model if we choose double the value of aplha","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = int(RidgeModelCV.best_params_.get('alpha'))*2\nridge = Ridge(alpha=alpha)\n\nridge.fit(X_train, y_train)\nridge.coef_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = ridge.predict(X_train)\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = ridge.predict(X_test)\nprint(metrics.r2_score(y_true=y_test, y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RMSE\nmetrics.mean_squared_error(y_test, ridge.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':ridge.coef_.round(4)})\nridge_df.reset_index(drop=True, inplace=True)\nridge_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert in dict for other usages\nridge_coeff = dict(pd.Series(ridge.coef_.round(4), index = X_train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# minimise the feature using RFE\nX_train_ridge = X_train[ridge_df.Features]\n\nlm = LinearRegression()\nlm.fit(X_train_ridge, y_train)\n\nrfe = RFE(lm, 15)            \nrfe = rfe.fit(X_train_ridge, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_df1 = pd.DataFrame(list(zip( X_train_ridge.columns, rfe.support_, rfe.ranking_)), columns=['Features', 'rfe_support', 'rfe_ranking'])\nridge_df1 = ridge_df1.loc[ridge_df1['rfe_support'] == True]\nridge_df1.reset_index(drop=True, inplace=True)\n\nridge_df1['Coefficient'] = ridge_df1['Features'].apply(lambda x: ridge_coeff[x])\nridge_df1 = ridge_df1.sort_values(by=['Coefficient'], ascending=False)\nridge_df1 = ridge_df1.head(10)\nridge_df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.barplot(y = 'Features', x='Coefficient', data = ridge_df1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lasso","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso = Lasso()\n\n# list of alphas\nparams = {'alpha': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.001, 0.002, 0.003, 0.004, 0.005, 0.01]}\n\n# cross validation\nfolds = 5\nLassoModelCV = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)             \n\nLassoModelCV.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the value of optimum number of parameters\nprint(LassoModelCV.best_params_)\nprint(LassoModelCV.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display the mean scores\n\nLassoModelCVResults = pd.DataFrame(LassoModelCV.cv_results_)\nLassoModelCVResults[['param_alpha', 'mean_train_score', 'mean_test_score', 'rank_test_score']].sort_values(by = ['rank_test_score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LassoModelCVResults['param_alpha'] = LassoModelCVResults['param_alpha'].astype('float32')\n\n# plotting mean for train and test score with alpha \n\nplt.figure(figsize=(16,5))\nplt.plot(LassoModelCVResults['param_alpha'], LassoModelCVResults['mean_train_score'])\nplt.plot(LassoModelCVResults['param_alpha'], LassoModelCVResults['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LassoModelCV.best_params_.get('alpha')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = LassoModelCV.best_params_.get('alpha')\nlasso = Lasso(alpha=alpha)\nlasso.fit(X_train, y_train) \nlasso.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets predict the R-squared value of test and train data\ny_train_pred = lasso.predict(X_train)\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = lasso.predict(X_test)\nprint(metrics.r2_score(y_true=y_test, y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RMSE\nmetrics.mean_squared_error(y_test, lasso.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change in the model if we choose double the value of aplha","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = LassoModelCV.best_params_.get('alpha')*2\nlasso = Lasso(alpha=alpha)\nlasso.fit(X_train, y_train) \nlasso.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = lasso.predict(X_train)\nprint(metrics.r2_score(y_true=y_train, y_pred=y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = lasso.predict(X_test)\nprint(metrics.r2_score(y_true=y_test, y_pred=y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.mean_squared_error(y_test, lasso.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_df = pd.DataFrame({'Features':X_train.columns, 'Coefficient':lasso.coef_.round(4)})\nlasso_df.reset_index(drop=True, inplace=True)\nlasso_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_coeff = dict(pd.Series(lasso.coef_.round(4), index = X_train.columns))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# minimise the feature using RFE\nX_train_lasso = X_train[lasso_df.Features]\n\nlm = LinearRegression()\nlm.fit(X_train_lasso, y_train)\n\nrfe = RFE(lm, 15)            \nrfe = rfe.fit(X_train_lasso, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_df = pd.DataFrame(list(zip( X_train_lasso.columns, rfe.support_, rfe.ranking_)), columns=['Features', 'rfe_support', 'rfe_ranking'])\nlasso_df = lasso_df.loc[lasso_df['rfe_support'] == True]\nlasso_df.reset_index(drop=True, inplace=True)\n\nlasso_df['Coefficient'] = lasso_df['Features'].apply(lambda x: lasso_coeff[x])\nlasso_df = lasso_df.sort_values(by=['Coefficient'], ascending=False)\nlasso_df = lasso_df.head(10)\nlasso_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.barplot(y = 'Features', x='Coefficient', data = lasso_df)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}