{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np\n# linear algebra\nimport pandas as pd \n# data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import Callback\nimport os\n\n#模型存盘检查点，每训练5趟保存一次模型\nclass EpochCheckpoint(Callback):\n    def __init__(self,output_path,every=5,start_at=0):\n        #调用父类构造函数\n        super(Callback,self).__init__()\n\n        self.output_path = output_path    #模型保存目录\n        self.every = every                #间隔趟数\n        self.start_epoch = start_at       #起始趟数\n\n\n    def on_epoch_end(self, epoch, logs={}):\n        #检查是否要向磁盘保存模型\n        if (self.start_epoch + 1)% self.every ==0:\n            p = os.path.sep.join([self.output_path,\n                                  \"epoch_{}.hdf5\".format(self.start_epoch + 1)])\n            self.model.save(p, overwrite = True)\n            #增加内部的趟数计数器\n            self.start_epoch += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import concatenate\n\n# 核初始化\nkernel_init = tf.keras.initializers.glorot_uniform()\n\n# 偏置初始化\nbias_init = tf.keras.initializers.Constant(value=0.2)\n\n\n# 生成潜深模块（Inception Module）的函数\ndef inception_module(x,\n                     filters_1x1,\n                     filters_3x3_reduce,\n                     filters_3x3,\n                     filters_5x5_reduce,\n                     filters_5x5,\n                     filters_pool_proj,\n                     name=None):\n    # 1×1卷积\n    conv_1x1 = Conv2D(filters_1x1,\n                      (1, 1),\n                      padding='same',\n                      activation='relu')(x)\n    conv_1x1 = BatchNormalization()(conv_1x1)\n\n    # 消解降维3x3卷积的1×1卷积\n    conv_3x3 = Conv2D(filters_3x3_reduce,\n                      (1, 1),\n                      padding='same',\n                      activation='relu')(x)\n    conv_3x3 = BatchNormalization()(conv_3x3)\n\n    # 3x3卷积\n    conv_3x3 = Conv2D(filters_3x3,\n                      (3, 3),\n                      padding='same',\n                      activation='relu')(conv_3x3)\n    conv_3x3 = BatchNormalization()(conv_3x3)\n\n    # 消解降维5x5卷积的1×1卷积\n    conv_5x5 = Conv2D(filters_5x5_reduce,\n                      (1, 1),\n                      padding='same',\n                      activation='relu')(x)\n    conv_5x5 = BatchNormalization()(conv_5x5)\n\n    # 5x5卷积\n    conv_5x5 = Conv2D(filters_5x5, (5, 5),\n                      padding='same',\n                      activation='relu')(conv_5x5)\n    conv_5x5 = BatchNormalization()(conv_5x5)\n\n    # 最大池化\n    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n\n    # 消解降维最大池化的1×1卷积\n    pool_proj = Conv2D(filters_pool_proj,\n                       (1, 1),\n                       padding='same',\n                       activation='relu')(pool_proj)\n    pool_proj = BatchNormalization()(pool_proj)\n    # 堆叠合并\n    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n\n    return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\n\n\n# 定义 GoogleNet类\nclass GoogleNet:\n    @staticmethod\n    def build(width, height, channel, classes):\n        input_layer = Input(shape=(width, height, channel))\n\n        # 核初始化\n        kernel_init = tf.keras.initializers.glorot_uniform()\n\n        # 偏置初始化\n        bias_init = tf.keras.initializers.Constant(value=0.2)\n\n        # 卷积\n        x = Conv2D(64,\n                   (7, 7),\n                   padding='same',\n                   strides=(2, 2),\n                   activation='relu',\n                   name='conv_1_7x7/2')(input_layer)\n        x = BatchNormalization()(x)\n\n        # 最大池化\n        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n         # 卷积\n        x = Conv2D(64,\n                   (1, 1),\n                   padding='same',\n                   strides=(1, 1),\n                   activation='relu',\n                   name='conv_2a_3x3/1')(x)\n        x = BatchNormalization()(x)\n\n        # 卷积\n        x = Conv2D(192,\n                   (3, 3),\n                   padding='same',\n                   strides=(1, 1),\n                   activation='relu',\n                   name='conv_2b_3x3/1')(x)\n        x = BatchNormalization()(x)\n\n        # 最大池化\n        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n         # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=64,\n                             filters_3x3_reduce=96,\n                             filters_3x3=128,\n                             filters_5x5_reduce=16,\n                             filters_5x5=32,\n                             filters_pool_proj=32,\n                             name='inception_3a')\n\n        # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=128,\n                             filters_3x3_reduce=128,\n                             filters_3x3=192,\n                             filters_5x5_reduce=32,\n                             filters_5x5=96,\n                             filters_pool_proj=64,\n                             name='inception_3b')\n\n        # 最大池化\n        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n        # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=192,\n                             filters_3x3_reduce=96,\n                             filters_3x3=208,\n                             filters_5x5_reduce=16,\n                             filters_5x5=48,\n                             filters_pool_proj=64,\n                             name='inception_4a')\n          # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=160,\n                             filters_3x3_reduce=112,\n                             filters_3x3=224,\n                             filters_5x5_reduce=24,\n                             filters_5x5=64,\n                             filters_pool_proj=64,\n                             name='inception_4b')\n\n        # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=128,\n                             filters_3x3_reduce=128,\n                             filters_3x3=256,\n                             filters_5x5_reduce=24,\n                             filters_5x5=64,\n                             filters_pool_proj=64,\n                             name='inception_4c')\n\n        # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=112,\n                             filters_3x3_reduce=144,\n                             filters_3x3=288,\n                             filters_5x5_reduce=32,\n                             filters_5x5=64,\n                             filters_pool_proj=64,\n                             name='inception_4d')\n         # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=256,\n                             filters_3x3_reduce=160,\n                             filters_3x3=320,\n                             filters_5x5_reduce=32,\n                             filters_5x5=128,\n                             filters_pool_proj=128,\n                             name='inception_4e')\n\n        # 最大池化\n        x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n\n        # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=256,\n                             filters_3x3_reduce=160,\n                             filters_3x3=320,\n                             filters_5x5_reduce=32,\n                             filters_5x5=128,\n                             filters_pool_proj=128,\n                             name='inception_5a')\n          # 潜深模块\n        x = inception_module(x,\n                             filters_1x1=384,\n                             filters_3x3_reduce=192,\n                             filters_3x3=384,\n                             filters_5x5_reduce=48,\n                             filters_5x5=128,\n                             filters_pool_proj=128,\n                             name='inception_5b')\n\n        # 全局平均池化\n        x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n\n        # 随机失活\n        x = Dropout(0.40)(x)\n\n        # 全连接\n        x = Dense(classes, activation='softmax', name='output')(x)\n\n        # 创建GoogleNet模型\n        # return Model(input_layer, [x, x1, x2], name='inception_v1')\n        return Model(input_layer, x, name='inception_v1')\n        \n# 测试GoogleNet类实例化并输出GoogleNet模型的概要信息\nif __name__ == \"__main__\":\n    model = GoogleNet.build(width=224, height=224, channel=3, classes=196)\n    print(model.summary())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD, Adam, Adamax\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport math\n\n# 训练样本全路径文件名称\ntrain_dirs = '/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/train'\n# 测试样本全路径文件名称\ntest_dirs ='/kaggle/input/stanford-car-dataset-by-classes-folder/car_data/car_data/test'\n\n# 初始化优化器\nepochs = 30\nbatch_size = 128\ninitial_lrate = 0.01\n\n\n#  随训练趟数降低学习率\ndef decay(epoch, steps=100):\n    initial_lrate = 0.01\n    drop = 0.96\n    epochs_drop = 8\n    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n    return lrate\n\n\n# 初始化学习调度器\nlr_scheduler = LearningRateScheduler(decay, verbose=1)\n\n\n# 构造用于数据增强的训练图像生成器\ntrain_datagen = ImageDataGenerator(rotation_range=20,\n                                   zoom_range=0.15,\n                                   width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n                                   height_shift_range=0.2, # randomly shift images vertically (fraction of total height))\n                                   shear_range=0.15,\n                                   horizontal_flip=True,\n                                   rescale=1./255,\n                                   fill_mode=\"nearest\")  \n\nval_datagen = ImageDataGenerator(rescale=1./255)\ntrainGen = train_datagen.flow_from_directory(\n        train_dirs,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        shuffle=True)\n\nvalGen = val_datagen.flow_from_directory(\n        test_dirs,\n        target_size=(224, 224),      \n        batch_size=batch_size,\n        shuffle=True)\n\n\nopt = SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n#opt = Adamax()\nmodel = GoogleNet.build(width=224, height=224, channel=3, classes=196)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\ncallbacks = [lr_scheduler]\nhistory = model.fit_generator(trainGen,\n                              steps_per_epoch=8144 // batch_size,\n                              epochs=epochs,\n                              validation_data=valGen,\n                              validation_steps=8041 // batch_size,\n                              max_queue_size=batch_size * 2,\n                              callbacks=callbacks,\n                              verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('320203305 googlenet Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,31))\nax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\nax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, 31, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch #')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, history.history['loss'], label='Train Loss')\nax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, 31, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch #')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}