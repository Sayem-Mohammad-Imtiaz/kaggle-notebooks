{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center> Machine Learning in Agriculture Starter</center>\n_____________________\n\n<center><img src=\"https://datahack-prod.s3.ap-south-1.amazonaws.com/__sized__/contest_cover/cover_1_CTBt1pB-thumbnail-1200x1200-90.jpg\" width=800 /></center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Note:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Hi everyone !!!!\n\nMy name is Vinay Vikram, I am DL/NLP/CV research engineer. Especially I am in Love with Computer Vision.. What about NLP ( Currently not practicing a lot) .\n\nToday I would like to share with you, My approach to any of the hackathons,But With this kernel I have no intention to ruin the competition spirit, it is created to just help you to get started.\n\n- I am a regular participants of Analytics vidhya hackathons and multiple time i featured among top 10 Ranking.\n\nMore about me: [Check My website](https://vikramvinay.github.io/)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<center><img src='https://germistoncitynews.co.za/wp-content/uploads/sites/31/2017/01/st0290.png' height=300 width=500/></center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## About the Hackathon\n\nRecently we have observed the emerging concept of smart farming that makes agriculture more efficient and effective with the help of high-precision algorithms. The mechanism that drives it is Machine Learning — the scientific field that gives machines the ability to learn without being strictly programmed. It has emerged together with big data technologies and high-performance computing to create new opportunities to unravel, quantify, and understand data intensive processes in agricultural operational environments.\n\n> Machine learning is everywhere throughout the whole growing and harvesting cycle. It begins with a seed being planted in the soil — from the soil preparation, seeds breeding and water feed measurement — and it ends when neural networks pick up the harvest determining the ripeness with the help of computer vision.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Problem Statement\n\n```The Toxic Pesticides```\n\nThough, many of us don't appreciate much, but a farmer's job is real test of endurance and determination. Once the seeds are sown, he works days and nights to make sure that he cultivates a good harvest at the end of season. A good harvest is ensured by several factors such as availability of water, soil fertility, protecting crops from rodents, timely use of pesticides & other useful chemicals and nature. While a lot of these factors are difficult to control for, the amount and frequency of pesticides is something the farmer can control.\n\nPesticides are also special, because while they protect the crop with the right dosage. But, if you add more than required, they may spoil the entire harvest. A high level of pesticide can deem the crop dead / unsuitable for consumption among many outcomes. This data is based on crops harvested by various farmers at the end of harvest season. To simplify the problem, you can assume that all other factors like variations in farming techniques have been controlled for.\n\n- You need to daetermine the outcome of the harvest season, i.e. whether the crop would be healthy (alive), damaged by pesticides or damaged by other reasons.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Description","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"| <font color='blue'><h2>Column Name</h2></font>                       | <font color='blue'><h2>Description</h2></font>                                                                                        |\n| ------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------:|\n| Id                       | UniqueID                                                                                                   | \n| Estimated_Insects_Count                          | Estimated insects count per square meter                                                                  | \n| Crop_Type                            | Category of Crop(0,1)                                                                                    | \n| Soil_Type                              | Category of Soil (0,1)                                                                                 | \n| Pesticide_Use_Category                               | Type of pesticides uses (1- Never, 2-Previously Used, 3-Currently Using)                                                                                   |\n| Number_Doses_Week                               | Number of doses per week                                                                                   |\n|Number_Weeks_Used                             |   Number of weeks used                   |\n| Number_Weeks_Quit                             | Number of weeks quit                                          |\n| Season                             | Season Category (1,2,3)                                         |\n| <font color='red'>Crop_Damage</font>                            | Crop Damage Category (0=alive, 1=Damage due to other causes, 2=Damage due to Pesticides)                                                                                      |","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Let's Begin\n> In this notebook i provide you some hints if you implement them in your notebook,Surely gonna get better results.(because i already implemented and bla.. bla... ....).\n> \n> So keep your eye on given hints.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# To print multiple output in a cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cufflinks  as cf\n\n#We set the all charts as public\ncf.set_config_file(sharing='public',theme='pearl',offline=False)\ncf.go_offline()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n## Import all the required libraries\n\nimport pandas as pd\nimport numpy as np\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.style.use('bmh')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read the files\n\ntrain_d=pd.read_csv('../input/av-janatahack-machine-learning-in-agriculture/train_yaOffsB.csv')\n\ntest_d=pd.read_csv('../input/av-janatahack-machine-learning-in-agriculture/test_pFkWwen.csv')\n\nsample=pd.read_csv('../input/av-janatahack-machine-learning-in-agriculture/sample_submission_O1oDc4H.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_d.head(10)\nprint('Shape of training data is {}'.format(train_d.shape))\n\nprint('-------------'*5)\n\ntest_d.head()\nprint('Shape of test data is {}'.format(test_d.shape))\n\n# print('--------------'*5)\n\n# sample.head()\n# sample.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time for Better Data Understanding (EDA)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<center> <img src=\"https://i.pinimg.com/originals/c9/91/72/c99172c17b83d3c620b997858351b2a5.gif\"/></center>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_d['Crop_Damage'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Don't hesitate to leave me a comment or upvote if you found it useful. If I'm completely wrong somewhere or if my findings makes no sense don't hesitate to leave me a comment.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Missing value in the dataset\n\ntrain_d.isnull().sum()\ntest_d.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# value count for the target variable.\ntrain_d.Crop_Damage.value_counts().iplot(kind='bar',yTitle='Count',title='Crop Damaged',color=['red'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Can see a high data imbalance in the target variable.\n\n## Hint1: \n\n- This suggest accuracy is not a better model evaluation metric. \n\nI recommend looking at the following performance measures that can give more insight into the accuracy of the model than traditional classification accuracy:\n\n- ```Confusion Matrix```: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).\n- ```Precision```: A measure of a classifiers exactness.\n- ```Recall```: A measure of a classifiers completeness\n- ```F1 Score (or F-score)```: A weighted average of precision and recall.\n\n\n## Hint2:\n\n- To deal with the Imbalance \n\n    - I prefer SMOTE.\n    - For other techniques check [this blog](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Crop type which is more prone to pests\ntrain_d.groupby('Crop_Type')['Estimated_Insects_Count'].sum().iplot(kind='bar',xTitle='Type of Crop',yTitle='Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ```Crop type -0``` is more prone to get attacked by the insects. \n\n> So it requires more frequent pestisides weeks.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Soil type which require more pestiside\n\ntrain_d.groupby('Soil_Type')['Estimated_Insects_Count'].sum().iplot(kind='bar',xTitle='Type of Soil',yTitle='Count',color=['blue'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Very much balanced ratio.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Estimated_Insects_Count\ntrain_d['Estimated_Insects_Count'].iplot(kind='hist',color=['green'],xTitle='Estimated_Insects_Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Bit Right skewed. \n- Try to remove skewness and then see its impact on the final accuracy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check the presence of outliers in Estimated_Insects_Count\n\ntrain_d['Estimated_Insects_Count'].iplot(kind='box',color=['pink'],xTitle='Estimated_Insects_Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For outlier generally used strategy is : ```(Q1 - 1.5 * IQR or Q3 + 1.5 * IQR)```\n\n- Very much balanced data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution of number of weeks used\ntrain_d['Number_Weeks_Used'].iplot(kind='hist',xTitle='Number_Weeks_Used',yTitle='count',title='Distribution for Week_used')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Join the trian and test data together ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# join test and train data\ntrain_d['train_or_test']='train'\ntest_d['train_or_test']='test'\ndf=pd.concat([train_d,test_d])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Number_Weeks_Used'].mode()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Number_Weeks_Used']=df['Number_Weeks_Used'].fillna(df['Number_Weeks_Used'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"one hot encoding Junction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# \n\n# for col in ['Crop_Type','Soil_Type','Pesticide_Use_Category','Season']:\n#     df = pd.get_dummies(df, columns=[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate the train and test data before training.\n\ntrain=df.loc[df.train_or_test.isin(['train'])]\ntest=df.loc[df.train_or_test.isin(['test'])]\ntrain.drop(columns={'train_or_test'},axis=1,inplace=True)\ntest.drop(columns={'train_or_test'},axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('ID',axis=1,inplace=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['ID','Crop_Damage'],axis=1,inplace=True)\ntest.head()\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert to X and Y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, Y = train.drop([\"Crop_Damage\"], axis=1).values, train[\"Crop_Damage\"].values\nX_test = test.values\n\nX_train.shape, Y.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model creation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import f1_score\nfrom imblearn.over_sampling import SMOTE\nfrom catboost import CatBoostClassifier\n\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_class1, num_class2, num_class3 = Counter(Y)[0], Counter(Y)[1], Counter(Y)[2]\n\nprint(num_class1)\nprint(num_class2)\nprint(num_class3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold, scores = KFold(n_splits=5, shuffle=True, random_state=0), list()\nfor train, test in kfold.split(X_train):\n    x_train, x_test = X_train[train], X_train[test]\n    y_train, y_test = Y[train], Y[test]\n    \n    num_class1, num_class2, num_class3 = Counter(y_train)[0], Counter(y_train)[1], Counter(y_train)[2]\n    sm = SMOTE(random_state=27, sampling_strategy={0: int(1.3*num_class1), 1: int(7*num_class2), 2: int(3.2*num_class3)})\n    x_train, y_train = sm.fit_resample(x_train, y_train)\n    \n    model = LGBMClassifier(random_state=27, max_depth=6, n_estimators=400)\n    model.fit(x_train, y_train)\n    preds = model.predict(x_test)\n    score = f1_score(y_test, preds, average=\"weighted\")\n    scores.append(score)\n    print(score)\nprint(\"Average: \", sum(scores)/len(scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hint:\n\nInstead of using ```auto``` sampling strategy make you own strategy to balance the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Make final prediction using LGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(random_state=27, sampling_strategy={0: int(1.3*num_class1), 1: int(7*num_class2), 2: int(3.2*num_class3)})\nx_train, y_train = sm.fit_resample(x_train, y_train)\n\nmodel1 = LGBMClassifier(random_state=27, max_depth=6, n_estimators=800)\nmodel1.fit(X_train, Y)\npreds = model1.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds=np.argmax(preds,axis=1)\n# preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample['Crop_Damage']=preds\n# sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample.to_csv('submission3.csv',index=False,encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making prediction using Catboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold, scores = KFold(n_splits=5, shuffle=True, random_state=0), list()\nfor train, test in kfold.split(X_train):\n    x_train, x_test = X_train[train], X_train[test]\n    y_train, y_test = Y[train], Y[test]\n    \n    model = CatBoostClassifier(random_state=27, max_depth=4, task_type=\"CPU\", devices=\"0:1\", n_estimators=1000, verbose=500)\n    model.fit(x_train, y_train)\n    preds_t = model.predict(x_test)\n    score = f1_score(y_test, preds_t, average=\"weighted\")\n    scores.append(score)\n    print(score)\nprint(\"Average: \", sum(scores)/len(scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = CatBoostClassifier(random_state=27, task_type=\"CPU\", devices=\"0:1\", n_estimators=1000, max_depth=4, verbose=500)\nmodel2.fit(X_train, Y)\npreds1 = model2.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds1=np.argmax(preds1,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample['Crop_Damage']=preds1\n# sample.to_csv('submission_catboost1.csv',index=False,encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making predictions using XGBoost","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Ensembling both predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preds\npreds1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = list()\ncb_weight=0.6 # Catboost\nlb_weight=0.4 # LGBM\nfor i, j in zip(preds, preds1):\n    xx = [(cb_weight * i[0]) + (lb_weight * j[0]),\n          (cb_weight * i[1]) + (lb_weight * j[1]),\n          (cb_weight * i[2]) + (lb_weight * j[2])]\n    predictions.append(xx)\n# print(predictions[:10])\npreds_ensemble=np.argmax(predictions,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ensemble[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['Crop_Damage']=preds_ensemble\nsample.to_csv('submission_ensemble1.csv',index=False,encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hint 3 : \n\n__Public and Private split__\n\n- The public leaderboard is based on __30% of test data__, while final rank would be decided on remaining __70% of test data__ (which is private leaderboard).\n\n- So There is a high chance of getting stuck in to a ```overfitting trap```. \n\nHow to avoid this- \n\nCheck [This notebook](https://www.kaggle.com/vin1234/starter-janatahack-demand-forecasting) in the very end a explained a good technique to deal with overfitting.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Hint 4: That Make me reach to 84% accuracy","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> 1. I Tried almost all the Gradient boosting algorithms and among all till now i find XGBoost is the best performing.\n\n> 2. Got a great boost of 2% by using a simple imputation technique ( aka don't try to impute with ```Mean , Mode, Median```)\n\n> 3. Don't make your xgboost model very heavy, make it very simple __eg(120 estimator - which I used)__.\n\n> 4. To achieve 84% accuracy i didn't use any kind of new feature creation.\n\n> 5. Don't apply xgb classifier from sklern( Dont' know why it didn't output better results). Try the original methond ```xgb.train``` to train the model (i.e model training by creating ```DMatrix```)\n\n\nBy applying all these tectics i achieved 84.92% and 12th Rank..\n\n\nStill working and will tell you new tricks as the competition goes on.. Hopefully all these tricks help you and make you lie in the top 50..\n\n- Consider upvoting this kernel.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"_______________________________________________________________","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As this competition is still going on .............Stay tuned for new and improved version.\n\n- Till then, If you like my kernel and it helped you then :\n\n        - Upvote\n        - Have doubts regarding this kernel use comment section.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}