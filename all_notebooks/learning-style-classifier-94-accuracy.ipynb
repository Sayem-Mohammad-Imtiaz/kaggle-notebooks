{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport pickle\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:08:12.657505Z","iopub.execute_input":"2021-09-01T18:08:12.658062Z","iopub.status.idle":"2021-09-01T18:08:14.132376Z","shell.execute_reply.started":"2021-09-01T18:08:12.657979Z","shell.execute_reply":"2021-09-01T18:08:14.131404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Variables\n\n# Initialize Stemming class to use 'stem' function\nps = PorterStemmer()\n\n# Select the top n words occured in the dataset\nn_top_words = 550\n\n# Import english stopwords\nstopwords.words(\"english\")\n\n#nltk.download('stopwords') # Run this if 'english stopwords not found'\n\n# Read dataset\ndataset = pd.read_csv(\"../input/learning-style-vak/dataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:08:31.753612Z","iopub.execute_input":"2021-09-01T18:08:31.753956Z","iopub.status.idle":"2021-09-01T18:08:31.829858Z","shell.execute_reply.started":"2021-09-01T18:08:31.753927Z","shell.execute_reply":"2021-09-01T18:08:31.829071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize data distribution\ndataset['Type'].hist()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:08:35.225049Z","iopub.execute_input":"2021-09-01T18:08:35.225406Z","iopub.status.idle":"2021-09-01T18:08:35.407691Z","shell.execute_reply.started":"2021-09-01T18:08:35.225377Z","shell.execute_reply":"2021-09-01T18:08:35.406691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to preprocess text\ndef clean(text):\n    text = re.sub(\"[^a-zA-z]\", \" \", text).lower()\n    text = text.split()\n    text = [ ps.stem(word) for word in text if word not in set(stopwords.words(\"english\"))]\n    text = \" \".join(text)\n    return text\n\n# Function to encode the text using an object of CountVectorizer\ndef encode(text, cv):\n    encoded_text = cv.transform(list([text])).toarray()\n    return encoded_text\n\n# Function to decode the classification result\ndef decode(result, label_encoder):\n    decoded_result = label_encoder.inverse_transform(result)[0]\n    return decoded_result","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:08:38.813134Z","iopub.execute_input":"2021-09-01T18:08:38.813507Z","iopub.status.idle":"2021-09-01T18:08:38.820631Z","shell.execute_reply.started":"2021-09-01T18:08:38.813477Z","shell.execute_reply":"2021-09-01T18:08:38.819266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean sentences\nsentences = dataset[\"Sentence\"].apply(clean)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T18:08:41.720929Z","iopub.execute_input":"2021-09-01T18:08:41.721269Z","iopub.status.idle":"2021-09-01T18:09:22.820002Z","shell.execute_reply.started":"2021-09-01T18:08:41.721236Z","shell.execute_reply":"2021-09-01T18:09:22.819214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing\n\n# Initialize CountVectorizer so it uses a specific number for top occuring words\ncount_vector = CountVectorizer(max_features = n_top_words)\n\n# Transform all the sentences to a rows and vector form\nX = count_vector.fit_transform(sentences).toarray()\n\n# Set y (the output) to the second column of the dataset\ny = dataset.iloc[:, 1]\n\n# Initialize label encoder and encode the learning style labels\nlabel_enc = LabelEncoder()\ny = label_enc.fit_transform(y)\n\n# Split the dataset into training set and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bulding the model and applying it to the encoded data\nclassifier = LogisticRegression()\nclassifier.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the model accuracy\nscore = classifier.score(X_test, y_test) * 100\nprint(\"Model score = \" + str(score))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing the model on 3 samples\n\n# Initialize data\nsentence1 = \"I like to try out things to understand how it works, 'experiencing' is my power to learn\"\nsentence2 = \"All what we do is visualizing how things work and imagine new possibilities\"\nsentence3 = \"I hear the wind call my name, the sound that leads me home again\"\n\n# Preprocess & Encode data\nsample1 = encode(clean(sentence1), count_vector)\nsample2 = encode(clean(sentence2), count_vector)\nsample3 = encode(clean(sentence3), count_vector)\n\n# Classify & Decode results\nprint( decode(classifier.predict(sample1), label_enc) ) # Kinesthetic\nprint( decode(classifier.predict(sample2), label_enc) ) # Visual\nprint( decode(classifier.predict(sample3), label_enc) ) # Auditory","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nwith open(\"classifier.pkl\", 'wb') as file:\n        pickle.dump(classifier, file)","metadata":{},"execution_count":null,"outputs":[]}]}