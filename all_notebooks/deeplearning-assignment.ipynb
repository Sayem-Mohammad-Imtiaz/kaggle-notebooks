{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Learning Assignment - RNN , LSTM \n## Reg 20MAI0014 | Krupa Gajjar","metadata":{}},{"cell_type":"markdown","source":"# 1.LSTM MODEL","metadata":{}},{"cell_type":"markdown","source":"### Import Library\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv',delimiter=',',encoding='latin-1')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Drop the columns that are not required by neural network","metadata":{}},{"cell_type":"code","source":"df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df.v1)\nplt.xlabel('Label')\nplt.title('Number of ham and spam messages')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.v2\nY = df.v1\nle = LabelEncoder()\nY = le.fit_transform(Y)\nY = Y.reshape(-1,1)\nY","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Process the data\n* Tokenize the data and convert the text to sequences.\n* Add padding to ensure that all the sequences have the same shape.\n* There are many ways of taking the max_len and here an arbitrary length of 150 is chosen.","metadata":{}},{"cell_type":"code","source":"max_words = 1000\nmax_len = 150\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\nprint(sequences_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RNN**\nDefine the RNN structure.","metadata":{}},{"cell_type":"code","source":"def RNN():\n    inputs = Input(name='inputs',shape=[max_len])\n    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256,name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(1,name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs,outputs=layer)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RNN()\nmodel.summary()\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sequences = tok.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accr = model.evaluate(test_sequences_matrix,Y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. VANILLA RNN","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.metrics import accuracy_score\nfrom keras.datasets import reuters\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN, Activation\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n# parameters for data load\nnum_words = 30000\nmaxlen = 50\ntest_split = 0.3\n\n(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)\n\n# pad the sequences with zeros \n# padding parameter is set to 'post' => 0's are appended to end of sequences\nX_train = pad_sequences(X_train, padding = 'post')\nX_test = pad_sequences(X_test, padding = 'post')\n\nX_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\nX_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n\ny_data = np.concatenate((y_train, y_test))\ny_data = to_categorical(y_data)\ny_train = y_data[:1395]\ny_test = y_data[1395:]\n\ndef vanilla_rnn():\n    model = Sequential()\n    model.add(SimpleRNN(50, input_shape = (49,1), return_sequences = False))\n    model.add(Dense(46))\n    model.add(Activation('softmax'))\n    \n    adam = optimizers.Adam(lr = 0.001)\n    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    \n    return model\n\nmodel = KerasClassifier(build_fn = vanilla_rnn, epochs = 200, batch_size = 50, verbose = 1)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\ny_test_ = np.argmax(y_test, axis = 1)\n\nprint(accuracy_score(y_pred, y_test_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}