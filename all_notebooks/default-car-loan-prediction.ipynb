{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.options.mode.chained_assignment = None \n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/ltfs-av-data/train.csv\")\ntest_data = pd.read_csv(\"../input/ltfs-av-data/test_bqCt9Pv.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns=train_data.columns.str.replace('.','_')\ntest_data.columns=test_data.columns.str.replace('.','_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" Shape of training dataframe: \", train_data.shape)\nprint(\" Shape of testing dataframe: \", test_data.shape)\n# Drop duplicates\ntrain_data.drop_duplicates()\ntest_data.drop_duplicates()\nprint(train_data.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.info())\nprint(train_data.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_data.info())\nprint(test_data.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data-Cleaning"},{"metadata":{},"cell_type":"markdown","source":"There are 7661 missing values of Employment_Type in train_data and 3443 in test_data.\nWe perform Data-Cleaning."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing the missing Employment_type by it's mode value.\ntrain_data['Employment_Type'] = train_data['Employment_Type'].fillna( train_data['Employment_Type'].dropna().mode().values[0] )\ntest_data['Employment_Type'] = test_data['Employment_Type'].fillna( test_data['Employment_Type'].dropna().mode().values[0] )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We first bring the Average_acct_age and Credit_history_length into normal date_time format.\n<br> we split the given age type into it's respective part that is years and months\n<br> Then convert it into str and int then concatenate to bring it into normal form.\n<br> Then Divide the Age by 12 to get the Average "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing AVERAGE_ACCT_AGE & CREDIT_HISTORY_LENGTH\n\ntrain_data[['AVERAGE_ACCT_Yr','AVERAGE_ACCT_Month']] = train_data['AVERAGE_ACCT_AGE'].str.split(\"yrs\",expand=True)\ntrain_data[['AVERAGE_ACCT_Month','AVERAGE_ACCT_Month1']] = train_data['AVERAGE_ACCT_Month'].str.split(\"mon\",expand=True)\ntrain_data[\"AVERAGE_ACCT_AGE\"]= train_data[\"AVERAGE_ACCT_Yr\"].astype(str).astype(int)+((train_data[\"AVERAGE_ACCT_Month\"].astype(str).astype(int))/12)\ntrain_data= train_data.drop(columns= [\"AVERAGE_ACCT_Yr\",\"AVERAGE_ACCT_Month\",'AVERAGE_ACCT_Month1'])\n\ntest_data[['AVERAGE_ACCT_Yr','AVERAGE_ACCT_Month']] = test_data['AVERAGE_ACCT_AGE'].str.split(\"yrs\",expand=True)\ntest_data[['AVERAGE_ACCT_Month','AVERAGE_ACCT_Month1']] = test_data['AVERAGE_ACCT_Month'].str.split(\"mon\",expand=True)\ntest_data[\"AVERAGE_ACCT_AGE\"]= test_data[\"AVERAGE_ACCT_Yr\"].astype(str).astype(int)+((test_data[\"AVERAGE_ACCT_Month\"].astype(str).astype(int))/12)\ntest_data= test_data.drop(columns= [\"AVERAGE_ACCT_Yr\",\"AVERAGE_ACCT_Month\",'AVERAGE_ACCT_Month1'])\n\ntrain_data[['CREDIT_HISTORY_LENGTH_Yr','CREDIT_HISTORY_LENGTH_Month']] = train_data['CREDIT_HISTORY_LENGTH'].str.split(\"yrs\",expand=True)\ntrain_data[['CREDIT_HISTORY_LENGTH_Month','CREDIT_HISTORY_LENGTH_Month1']] = train_data['CREDIT_HISTORY_LENGTH_Month'].str.split(\"mon\",expand=True)\ntrain_data[\"CREDIT_HISTORY_LENGTH\"]= train_data[\"CREDIT_HISTORY_LENGTH_Yr\"].astype(str).astype(int)+((train_data[\"CREDIT_HISTORY_LENGTH_Month\"].astype(str).astype(int))/12)\ntrain_data= train_data.drop(columns= [\"CREDIT_HISTORY_LENGTH_Yr\",\"CREDIT_HISTORY_LENGTH_Month\",'CREDIT_HISTORY_LENGTH_Month1'])\n\ntest_data[['CREDIT_HISTORY_LENGTH_Yr','CREDIT_HISTORY_LENGTH_Month']] = test_data['CREDIT_HISTORY_LENGTH'].str.split(\"yrs\",expand=True)\ntest_data[['CREDIT_HISTORY_LENGTH_Month','CREDIT_HISTORY_LENGTH_Month1']] = test_data['CREDIT_HISTORY_LENGTH_Month'].str.split(\"mon\",expand=True)\ntest_data[\"CREDIT_HISTORY_LENGTH\"]= test_data[\"CREDIT_HISTORY_LENGTH_Yr\"].astype(str).astype(int)+((test_data[\"CREDIT_HISTORY_LENGTH_Month\"].astype(str).astype(int))/12)\ntest_data= test_data.drop(columns= [\"CREDIT_HISTORY_LENGTH_Yr\",\"CREDIT_HISTORY_LENGTH_Month\",'CREDIT_HISTORY_LENGTH_Month1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data['AVERAGE_ACCT_AGE'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting the DOB and Disbursal-Date into DateTime Format.\n<br> Also Converting into Days."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Date_of_Birth'] =  pd.to_datetime(train_data['Date_of_Birth'], format='%d-%m-%y')\ntest_data['Date_of_Birth'] =  pd.to_datetime(test_data['Date_of_Birth'], format='%d-%m-%y')\ntrain_data['DisbursalDate'] =  pd.to_datetime(train_data['DisbursalDate'], format='%d-%m-%y')\ntest_data['DisbursalDate'] =  pd.to_datetime(test_data['DisbursalDate'], format='%d-%m-%y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"now = pd.Timestamp('now')\ntrain_data['age'] = (now - train_data['Date_of_Birth'])  \n\ntrain_data['age']= train_data['age'].astype(str)\ntrain_data[['age','age_waste']] = train_data['age'].str.split(\"days\",expand=True)\ntrain_data['age']= train_data['age'].astype(str).astype(int)\ntrain_data= train_data.drop(columns= ['age_waste', 'Date_of_Birth'])\n\nprint(train_data['age'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"now = pd.Timestamp('now')\ntest_data['age'] = (now - test_data['Date_of_Birth'])  \n\ntest_data['age']= test_data['age'].astype(str)\ntest_data[['age','age_waste']] = test_data['age'].str.split(\"days\",expand=True)\ntest_data['age']= test_data['age'].astype(str).astype(int)\ntest_data= test_data.drop(columns= ['age_waste', 'Date_of_Birth'])\n\nprint(test_data['age'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['disbursal_time'] = (now - train_data['DisbursalDate'])  \n\ntrain_data['disbursal_time']= train_data['disbursal_time'].astype(str)\ntrain_data[['disbursal_time','disbursal_time_waste']] = train_data['disbursal_time'].str.split(\"days\",expand=True)\ntrain_data['disbursal_time']= train_data['disbursal_time'].astype(str).astype(int)\ntrain_data= train_data.drop(columns= ['disbursal_time_waste'])\n\ntrain_data = train_data.drop(columns=['DisbursalDate'])\nprint(train_data['disbursal_time'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['disbursal_time'] = (now - test_data['DisbursalDate'])  \n\ntest_data['disbursal_time']= test_data['disbursal_time'].astype(str)\ntest_data[['disbursal_time','disbursal_time_waste']] = test_data['disbursal_time'].str.split(\"days\",expand=True)\ntest_data['disbursal_time']= test_data['disbursal_time'].astype(str).astype(int)\ntest_data= test_data.drop(columns= ['disbursal_time_waste'])\n\ntest_data = test_data.drop(columns=['DisbursalDate'])\nprint(test_data['disbursal_time'].head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ONE-HOT Encoding.\nWe will Manually one hot encode the Employment_type and PERFORM_CNS_SCORE_DESCRIPTION."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Employment_Type'] = train_data['Employment_Type'].map({'Salaried':0, 'Self employed':1}).astype(np.int)\ntest_data['Employment_Type'] = test_data['Employment_Type'].map({'Salaried':0, 'Self employed':1}).astype(np.int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['PERFORM_CNS_SCORE_DESCRIPTION'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['PERFORM_CNS_SCORE_DESCRIPTION'] = train_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('No Bureau History Available', \n                                     'Not Scored: Sufficient History Not Available','Not Scored: Not Enough Info available on the customer',\n                                     'Not Scored: No Activity seen on the customer (Inactive)', \n                                     'Not Scored: No Updates available in last 36 months', 'Not Scored: Only a Guarantor', \n                                     'Not Scored: More than 50 active Accounts found'),(0, 0, 0, 0, 0, 0, 0))\n\ntrain_data['PERFORM_CNS_SCORE_DESCRIPTION'] = train_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('L-Very High Risk', 'M-Very High Risk'), (1, 1))\n\ntrain_data['PERFORM_CNS_SCORE_DESCRIPTION'] = train_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('J-High Risk', 'K-High Risk'), (2, 2))\n\ntrain_data['PERFORM_CNS_SCORE_DESCRIPTION'] = train_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('H-Medium Risk', 'I-Medium Risk'), (3, 3))\n\ntrain_data['PERFORM_CNS_SCORE_DESCRIPTION'] = train_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('E-Low Risk', 'F-Low Risk', 'G-Low Risk'), (4, 4, 4))\n\ntrain_data['PERFORM_CNS_SCORE_DESCRIPTION'] = train_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('A-Very Low Risk', 'B-Very Low Risk',\n                                      'C-Very Low Risk', 'D-Very Low Risk'), (5, 5, 5, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['PERFORM_CNS_SCORE_DESCRIPTION'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['PERFORM_CNS_SCORE_DESCRIPTION'] = test_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('No Bureau History Available', \n                                     'Not Scored: Sufficient History Not Available','Not Scored: Not Enough Info available on the customer',\n                                     'Not Scored: No Activity seen on the customer (Inactive)', \n                                     'Not Scored: No Updates available in last 36 months', 'Not Scored: Only a Guarantor', \n                                     'Not Scored: More than 50 active Accounts found'),(0, 0, 0, 0, 0, 0, 0))\n\ntest_data['PERFORM_CNS_SCORE_DESCRIPTION'] = test_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('L-Very High Risk', 'M-Very High Risk'), (1, 1))\n\ntest_data['PERFORM_CNS_SCORE_DESCRIPTION'] = test_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('J-High Risk', 'K-High Risk'), (2, 2))\n\ntest_data['PERFORM_CNS_SCORE_DESCRIPTION'] = test_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('H-Medium Risk', 'I-Medium Risk'), (3, 3))\n\ntest_data['PERFORM_CNS_SCORE_DESCRIPTION'] = test_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('E-Low Risk', 'F-Low Risk', 'G-Low Risk'), (4, 4, 4))\n\ntest_data['PERFORM_CNS_SCORE_DESCRIPTION'] = test_data['PERFORM_CNS_SCORE_DESCRIPTION'].replace(('A-Very Low Risk', 'B-Very Low Risk',\n                                      'C-Very Low Risk', 'D-Very Low Risk'), (5, 5, 5, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['PERFORM_CNS_SCORE_DESCRIPTION'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.info())\nprint(train_data.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see the Data is Cleaned and all the object are converted into int64"},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (12,9), dpi=100)\nsns.heatmap(train_data.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the distribution of disbursed amount\n\nplt.rcParams['figure.figsize'] = (18, 5)\n\nplt.subplot(1, 3, 1)\nsns.distplot(train_data['disbursed_amount'],  color = 'orange')\nplt.title('Disbursed Amount')\n\nplt.subplot(1, 3, 2)\nsns.distplot(train_data['asset_cost'], color = 'pink')\nplt.title('Asset Cost')\n\nplt.subplot(1, 3, 3)\nsns.distplot(train_data['ltv'], color = 'red')\nplt.title('Loan to value of the asset')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#performing log transformations on disbursed amount, ltv, and asset cost\n\ntrain_data['disbursed_amount'] = np.log1p(train_data['disbursed_amount'])\ntrain_data['ltv'] = np.log1p(train_data['ltv'])\ntrain_data['asset_cost'] = np.log1p(train_data['asset_cost'])\n\n\nplt.rcParams['figure.figsize'] = (18, 5)\n\nplt.subplot(1, 3, 1)\nsns.distplot(train_data['disbursed_amount'],  color = 'orange')\nplt.title('Disbursed Amount')\n\nplt.subplot(1, 3, 2)\nsns.distplot(train_data['asset_cost'], color = 'pink')\nplt.title('Asset Cost')\n\nplt.subplot(1, 3, 3)\nsns.distplot(train_data['ltv'], color = 'red')\nplt.title('Loan to value of the asset')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_data['age'], color = 'blue')\nplt.title('Distribution of Date of birth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['NO_OF_INQUIRIES'], palette = 'muted')\nplt.title('No. of Inquiries',  fontsize = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (18, 5)\nsns.countplot(train_data['CREDIT_HISTORY_LENGTH'].head(10))\nplt.title('Credit History')\nplt.xticks(rotation = 45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['AVERAGE_ACCT_AGE'].head(10), palette = 'colorblind')\nplt.title('Average Loan Tenure')\nplt.xticks(rotation = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's apply log transformations on EMI Amount of the Primary Loan and Secondary loan\n\ntrain_data['PRIMARY_INSTAL_AMT'] = np.log1p(train_data['PRIMARY_INSTAL_AMT'])\ntrain_data['SEC_INSTAL_AMT'] = np.log1p(train_data['SEC_INSTAL_AMT'])\n\nplt.subplot(1, 2, 1)\nsns.distplot(train_data['SEC_INSTAL_AMT'], color = 'yellow', kde_kws={'bw':0.1})\nplt.title('EMI Amount Secondary Plan', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.subplot(1, 2, 2)\nsns.distplot(train_data['PRIMARY_INSTAL_AMT'],color = 'yellow', kde_kws={'bw':0.1})\nplt.title('EMI Amount Primary Plan', fontsize = 20)\nplt.xticks(rotation = 45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# distribution for different attributesof secondary accounts\n\n\nplt.rcParams['figure.figsize'] = (18, 12)    \nplt.subplot(2, 3, 1)\nsns.distplot(train_data['SEC_NO_OF_ACCTS'], color = 'green', kde_kws={'bw':0.1})\nplt.title('Total loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 2)\nsns.distplot(train_data['SEC_ACTIVE_ACCTS'], color = 'green', kde_kws={'bw':0.1})\nplt.title('Active loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 3)\nsns.distplot(train_data['SEC_OVERDUE_ACCTS'], color = 'green', kde_kws={'bw':0.1})\nplt.title('Default Accounts at the time of disbursement')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 4)\nsns.distplot(train_data['SEC_CURRENT_BALANCE'], color = 'green', kde_kws={'bw':0.1})\nplt.title('Principal Outstanding amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 5)\nsns.distplot(train_data['SEC_SANCTIONED_AMOUNT'], color = 'green', kde_kws={'bw':0.1})\nplt.title('Total Sanctioned Amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 6)\nsns.distplot(train_data['SEC_DISBURSED_AMOUNT'], color = 'green', kde_kws={'bw':0.1})\nplt.title('Total Disbured Amount')\nplt.xticks(rotation = 45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting distribution plots for these attributes\n\nplt.rcParams['figure.figsize'] = (18, 12)    \nplt.subplot(2, 3, 1)\nsns.distplot(train_data['PRI_NO_OF_ACCTS'], color = 'violet', kde_kws={'bw':0.1})\nplt.title('Total loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 2)\nsns.distplot(train_data['PRI_ACTIVE_ACCTS'], color = 'violet', kde_kws={'bw':0.1})\nplt.title('Active loan taken by customer')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 3)\nsns.distplot(train_data['PRI_OVERDUE_ACCTS'], color = 'violet', kde_kws={'bw':0.1})\nplt.title('Default Accounts')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 4)\nsns.distplot(train_data['PRI_CURRENT_BALANCE'], color = 'violet', kde_kws={'bw':0.1})\nplt.title('Principal Outstanding amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 5)\nsns.distplot(train_data['PRI_SANCTIONED_AMOUNT'], color = 'violet', kde_kws={'bw':0.1})\nplt.title('Total Sanctioned Amount')\nplt.xticks(rotation = 45)\n\nplt.subplot(2, 3, 6)\nsns.distplot(train_data['PRI_DISBURSED_AMOUNT'], color = 'violet')\nplt.title('Total Disbured Amount')\nplt.xticks(rotation = 45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (19, 6)\nsns.countplot(train_data['PERFORM_CNS_SCORE_DESCRIPTION'], palette = 'pastel')\nplt.title('Bureau Score Description', fontsize = 30)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 5)\nplt.subplot(1, 2, 1)\nsns.distplot(train_data['PERFORM_CNS_SCORE'], color = 'purple')\nplt.title('Before Log transformations')\n\nplt.subplot(1, 2, 2)\ntrain_data['PERFORM_CNS_SCORE'] = np.log1p(train_data['PERFORM_CNS_SCORE'])\nsns.distplot(train_data['PERFORM_CNS_SCORE'], color = 'maroon')\nplt.title('After Log transformations')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models Import\n\nfrom sklearn.model_selection import train_test_split\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import balanced_accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Useless features\ntrain_data = train_data.drop(['UniqueID', 'State_ID', 'Employee_code_ID', 'supplier_id', 'manufacturer_id', 'Current_pincode_ID','branch_id'],axis=1)\ntest_data = test_data.drop(['State_ID', 'Employee_code_ID', 'supplier_id', 'manufacturer_id', 'Current_pincode_ID','branch_id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data[['loan_default']]\nX= train_data.loc[:, train_data.columns != 'loan_default']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 101)\nprint(\"Shape of train :\", X_train.shape)\nprint(\"Shape of test :\", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logmodel = LogisticRegression() \nlogmodel.fit(X_train,y_train)\nlogpred = logmodel.predict(X_test)\n\n\nprint(confusion_matrix(y_test, logpred))\nprint(round(accuracy_score(y_test, logpred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, logpred))\nprint(\"F1 Score \",f1_score(y_test, logpred))\nprint(\"Recall Score \",recall_score(y_test, logpred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, logpred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nrfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n\n# predict on test set\nrfc_pred = rfc.predict(X_test)\nprint(confusion_matrix(y_test, rfc_pred))\nprint(round(accuracy_score(y_test, rfc_pred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, rfc_pred))\nprint(\"F1 Score \",f1_score(y_test, rfc_pred))\nprint(\"Recall Score \",recall_score(y_test, rfc_pred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nnb = GaussianNB().fit(X_train, y_train)\n\n# predict on test set\nnb_pred = nb.predict(X_test)\nprint(confusion_matrix(y_test, nb_pred))\nprint(round(accuracy_score(y_test, nb_pred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, nb_pred))\nprint(\"F1 Score \",f1_score(y_test, nb_pred))\nprint(\"Recall Score \",recall_score(y_test, nb_pred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, nb_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nsgd = SGDClassifier(loss= \"modified_huber\", shuffle = True, random_state= 101).fit(X_train, y_train)\n\n# predict on test set\nsgd_pred = sgd.predict(X_test)\nprint(confusion_matrix(y_test, sgd_pred))\nprint(round(accuracy_score(y_test, sgd_pred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, sgd_pred))\nprint(\"F1 Score \",f1_score(y_test, sgd_pred))\nprint(\"Recall Score \",recall_score(y_test, sgd_pred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, sgd_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\ndtree = DecisionTreeClassifier(max_depth = 10, random_state= 101, max_features =None , min_samples_leaf = 30).fit(X_train, y_train)\n\n# predict on test set\ndtree_pred = dtree.predict(X_test)\nprint(confusion_matrix(y_test, dtree_pred))\nprint(round(accuracy_score(y_test, dtree_pred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, dtree_pred))\nprint(\"F1 Score \",f1_score(y_test, dtree_pred))\nprint(\"Recall Score \",recall_score(y_test, dtree_pred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, dtree_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb = LGBMClassifier()\nlgb.fit(X_train, y_train)\n\nlgb_pred = lgb.predict(X_test)\n\nprint(confusion_matrix(y_test, lgb_pred))\nprint(round(accuracy_score(y_test, lgb_pred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, lgb_pred))\nprint(\"F1 Score \",f1_score(y_test, lgb_pred))\nprint(\"Recall Score \",recall_score(y_test, lgb_pred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, lgb_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\nxgb_pred = xgb.predict(X_test)\n\nprint(confusion_matrix(y_test, xgb_pred))\nprint(round(accuracy_score(y_test, xgb_pred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, xgb_pred))\nprint(\"F1 Score \",f1_score(y_test, xgb_pred))\nprint(\"Recall Score \",recall_score(y_test, xgb_pred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, xgb_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada = AdaBoostClassifier()\nada.fit(X_train, y_train)\n\nada_pred = ada.predict(X_test)\n\nprint(confusion_matrix(y_test, ada_pred))\nprint(round(accuracy_score(y_test, ada_pred),2)*100)\nLOGCV = (cross_val_score(logmodel, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy of model \",accuracy_score(y_test, ada_pred))\nprint(\"F1 Score \",f1_score(y_test, ada_pred))\nprint(\"Recall Score \",recall_score(y_test, ada_pred))\nprint(\"Balanced Accuracy Score \",balanced_accuracy_score(y_test, ada_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy of Different Models.\n\n#### LogisticRegression <br> Accuracy = 78% <br> Balanced Accuracy Score  0.50\n#### RandomForestClassifier <br> Accuracy = 77% <br> Balanced Accuracy Score  0.51\n#### GaussianNB <br> Accuracy = 78% <br> Balanced Accuracy Score  0.49\n#### SGDClassifier <br> Accuracy = 53% <br> Balanced Accuracy Score  0.49\n#### DecisionTreeClassifier <br> Accuracy = 78% <br> Balanced Accuracy Score  0.51\n#### LGBMClassifier <br> Accuracy = 78%<br> Balanced Accuracy Score  0.50\n#### XGBClassifier<br> Accuracy = 78%<br> Balanced Accuracy Score  0.51\n#### AdaBoostClassifier <br>  Accuracy = 78%<br> Balanced Accuracy Score  0.50"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}