{"cells":[{"metadata":{},"cell_type":"markdown","source":"SARS-CoV-2, Novel Coronavirus, Covid-19, Corona. There are almost as many names for the virus that has shaken the world in the last 5 months as there are approaches countries have taken to combat it. But what's really working?\n\n\nTo start answering this difficult question, we've decided to focus on a four extreme cases - two \"bad\" examples, and two \"good\" examples. What are the common threads and what metrics can best predict whether a region's actions during a pandemic are good or bad?\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# More Effective Covid-19 Response Strategies\n\n**South Korea**\n- Early school closures\n- Widespread testing \n- No lockdown\n\n**New Zealand**\n- Widespread testing\n\n# Less Effective Covid-19 Response Strategies\n\n**Italy**\n- Lockdowns too late\n- Elderly population\n\n**United States**\n- Lockdowns\n- Limited Testing","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport datetime\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import dataset\ncovid_df = pd.read_csv('../input/covid19dataexploration/covid19_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename columns for ease of use \ncovid_df['Date'] = pd.to_datetime(covid_df['Date'])\ncovid_df = covid_df.rename(columns={'Cumulative tests': 'agg_tests',\n                                    'Cumulative tests per million': 'agg_tests_per_mil',\n                                    'Total confirmed cases (cases)': 'agg_cases',\n                                    'Confirmed cases per million (cases per million)': 'agg_cases_per_mil',\n                                    'Total confirmed deaths (deaths)': 'agg_deaths',\n                                    'Confirmed deaths per million (deaths per million)': 'agg_deaths_per_mil'})\ncovid_df[['agg_tests', 'agg_cases', 'agg_deaths']] = covid_df[['agg_tests', 'agg_cases', 'agg_deaths']].fillna(value=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll start by comparing total confirmed deaths over the course of the pandemic for the 4 countries we have chosen, but we will begin on the day that the country had at least 1 confirmed deaths to compare similar stages within each region. This represents an approximation of speed of the outbreak in each country.\n\nWe can do the same analysis for total confirmed cases and cumulative tests as well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate days since first X (can be cases, tests, death, etc.)\ndef days_since_first(col):\n    first_dates = covid_df[covid_df[col] != 0].groupby('Entity').first()['Date']\n    \n    def day_diff(row):\n        if row['Entity'] not in first_dates:\n            return None\n        return (row['Date'] - first_dates[row['Entity']]).days\n    \n    return covid_df.apply(day_diff, axis=1)\n\ncovid_df['days_since_1st_death'] = days_since_first('agg_deaths')\ncovid_df['days_since_1st_case'] = days_since_first('agg_cases')\ncovid_df['days_since_1st_test'] = days_since_first('agg_tests')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=covid_df[covid_df['Entity'].isin(['Italy','United States', 'South Korea','New Zealand'])]\nfig = px.line(data[data['days_since_1st_death'] >=0], x='days_since_1st_death', y='agg_deaths_per_mil', color='Entity')\nfig.update_layout(title='Figure 1. Total Confirmed COVID-19 Deaths per Million Since 1st Confirmed Death',\n                   xaxis_title='Days Since 1st Confirmed Death',\n                   yaxis_title='Total Confirmed Deaths per Million')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=covid_df[covid_df['Entity'].isin(['Italy','United States', 'South Korea','New Zealand'])]\nfig = px.line(data[data['days_since_1st_case'] >=0], x='days_since_1st_case', y='agg_cases_per_mil', color='Entity')\nfig.update_layout(title='Figure 2. Total Confirmed COVID-19 Cases per Million Since 1st Confirmed Case',\n                   xaxis_title='Days Since 1st Confirmed Case',\n                   yaxis_title='Total Confirmed Cases per Million')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=covid_df[covid_df['Entity'].isin(['Italy','United States', 'South Korea','New Zealand'])]\nfig = px.line(data[data['days_since_1st_test'] >=0], x='days_since_1st_test', y='agg_tests_per_mil', color='Entity')\nfig.update_layout(title='Figure 3. Total COVID-19 Tests per Million Since 1st Confirmed Test',\n                   xaxis_title='Days Since 1st Reported Test',\n                   yaxis_title='Total Confirmed Tests per Million')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The figures comparing deaths per million and cases per million (Figures 1 and 2) make sense; Italy and the U.S. take on a more exponential curve while New Zealand and South Korea are flat. Figure 3 comparing tests per million is more surprising. When it comes to testing, it would seem more rapid deployment of many tests would spell greater success for disease management. However,it appears Italy deployed more tests per million at a faster rate than South Korea, yet still saw the most dramatic exponential growth in deaths per million. \n\nLet's investigate the timing that these tests were deployed to see if that sheds more insight. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data=covid_df[covid_df['Entity'].isin(['Italy','United States', 'South Korea','New Zealand'])]\nfig = px.line(data[data['days_since_1st_case'] >= 0], y='agg_tests_per_mil', color='Entity')\nfig.update_layout(title='Figure 4. Total COVID-19 Tests per Million since 1st Confirmed Case',\n                   xaxis_title='Days Since 1st Confirmed Case',\n                   yaxis_title='Total Confirmed Tests per Million')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Figure 4 still shows that there may be something more to the story here as South Korea did not employ significantly more tests at a faster rate than Italy when compared to the first confirmed case in the region, yet experienced significantly more deaths per capita. Perhaps there were already a lot of un-confirmed cases in Italy by the time the first case was confirmed, and the virus was spreading undetected? \n\nTo investigate this, we will look at the Test Positive Ratio, or the percentage of tests performed in a given region that come back as confirmed cases. The higher the Test Positive Ratio (TPR), the more likely that there are more cases out there that haven't been caught. A high TPR can imply that a region is primarily only testing to confirm obvious cases, leaving a lot of the less severe cases to go under the radar. \n\nTo see if TPR is a better metric for understanding a region's response to COVID-19, we will look at the relationship between the maximum TPR vs deaths per million (Figure 5).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_positive_ratio = covid_df['agg_cases_per_mil'].astype(float) / covid_df['agg_tests_per_mil'].astype(float)\ncovid_df['test_positive_ratio'] = test_positive_ratio","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some days within the data where the U.S. is reporting more confirmed cases than tests performed. This could potentially be due to U.S. patients being tested by agencies outside the U.S. as they contracted the virus outside of the country. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_df[covid_df['test_positive_ratio'] > 1]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the sake of the following analysis, we will remove these lines of data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_max(df, col):\n    return df.groupby('Entity')[col].max()\n\nmax_positive_ratio = generate_max(covid_df[covid_df['test_positive_ratio'] <= 1], 'test_positive_ratio')\nmax_death_per_mil = generate_max(covid_df[covid_df['test_positive_ratio'] <= 1], 'agg_deaths_per_mil')\nmax_cases_per_mil = generate_max(covid_df[covid_df['test_positive_ratio'] <= 1], 'agg_cases_per_mil')\nall_entities = covid_df['Entity'].unique()\npositive_test_ratio_vs_deaths = pd.DataFrame({'max_positive_ratio': max_positive_ratio[all_entities],\n                                              'max_cases_per_mil': max_cases_per_mil[all_entities],\n                                              'Entity':all_entities})\n\nfig = px.scatter(positive_test_ratio_vs_deaths,\n                 x=positive_test_ratio_vs_deaths['max_positive_ratio'],\n                 y=positive_test_ratio_vs_deaths['max_cases_per_mil'],\n                 color='Entity')\nfig.update_layout(title='Figure 5. Maximum Test Positive Ratio (TPR) vs. Total Deaths per Million',\n                   xaxis_title='Maximum Test Positive Ratio (TPR)',\n                   yaxis_title='Total Cases per Million')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## There appears to be a relatively linear trend between TPR and Total Deaths per Million where the higher the Test Positive Ratio, the more severe the pandemic is in that region. \n\nThere are some significant outliers in to this trend. The Phillipines has a very high maximum TPR but a low Deaths Per Million, indicating that the Phillipines may be underreporting deaths. Italy has a very high total Deaths per Million, yet a relatively low maximum TPR. **WHY IS THIS THE CASE FOR ITALY?**\n\n\nIf a higher the Test Positive Ratio (TPR) means an increased probability that there are more cases in a country that aren't being caught, then a decrease in TPR over time could mean that the region is through the peak of the pandemic. Let's dig in some more and see how TPR changes in our regions of interest over the course of the pandemic. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Percentage of days that tests are reported since the first case in a region is reported. We'll call this the test reporting rate.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"entity = covid_df[covid_df['days_since_1st_case'] > 0].groupby('Entity')\nentity_trr = entity['agg_tests_per_mil'].count() / (entity['days_since_1st_test'].last() - entity['days_since_1st_test'].first())\n# Let's drop entities with zero tests.\nentity_trr = entity_trr[entity_trr.ne(0)].dropna()\n\nfig = plt.figure(figsize=(15,5))\ng = sns.barplot(x=entity_trr.index, y=entity_trr.values)\ng.axes.axhline(1, ls='--')\nplt.title('Figure 6. Test Reporting Rate by Entity')\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To account for sporadic test recording and get a better feel for general trends, we will take a rolling mean of TPR data over 5 days.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_against_entity(df, entity_list, x, y, title, xaxis_title, yaxis_title, horiz_line=False):\n    entity_df = df[df['Entity'].isin(entity_list)][['Entity', x, y]]\n    fig = px.line(entity_df, x=x, y=y, color='Entity')\n    fig.update_layout(title=title, xaxis_title=xaxis_title, yaxis_title=yaxis_title)\n    if horiz_line:\n        fig.update_layout(shapes=[dict(type='line',\n                                   yref='y', y0=0, y1=0,\n                                   xref='paper', x0=0, x1=1)])\n    return fig\n\ndef generate_rolling_mean(df, days, mean_col):\n    return df.reset_index().set_index('days_since_1st_case').groupby('Entity').rolling(days, min_periods=1)[mean_col].mean().values\n\ncovid_df.loc[covid_df['test_positive_ratio'] <= 1, 'test_positive_ratio_7_day_rolling'] = generate_rolling_mean(covid_df[covid_df['test_positive_ratio'] <= 1], 7, 'test_positive_ratio')\n\n# covid_df.loc['test_positive_ratio'] <= 1]['test_positive_ratio_5_day_rolling'] = generate_rolling_mean(covid_df[covid_df['test_positive_ratio'] <= 1], 5, 'test_positive_ratio')\n\nplot_against_entity(df=covid_df[(covid_df['days_since_1st_test'] >= 0) & (covid_df['test_positive_ratio'] <= 1)], \n                    entity_list=['Italy','United States', 'South Korea','New Zealand'], \n                    x='days_since_1st_test', y='test_positive_ratio_7_day_rolling',\n                    title='Figure 7. 7-Day Rolling Test Positive Ratio (TPR)', \n                    xaxis_title='Days Since 1st Test', \n                    yaxis_title='7-Day Rolling Test Positive Ratio (TPR)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Italy appears to peak \n\nI'd like to look at the maximum test positive rate ROC to find where an outbreak might be occurring.To remove some of the noise that appears to occur in the first week of reported testing data, we will look at days 8 and beyond from the 1st reported test. Perhaps there is noise due to getting test reporting structures in place for each country. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# covid_df['test_positive_ratio_7_day_rolling_ROC'] = covid_df['test_positive_ratio_7_day_rolling'].pct_change()\ncovid_df['test_positive_ratio_ROC'] = covid_df[covid_df['test_positive_ratio'] <= 1]['test_positive_ratio'].pct_change()\n\n# Replace infinite values with NaN\ncovid_df = covid_df.replace([np.inf, -np.inf], np.nan)\n\ncovid_df['test_positive_ratio_7_day_rolling_ROC'] = generate_rolling_mean(covid_df, 7, 'test_positive_ratio_ROC')\n\n# max_tpr_5_day_rolling_roc = covid_df.groupby('Entity')['test_positive_ratio_5_day_rolling_ROC'].max()\n\ncovid_df_after_7_days = covid_df[covid_df['days_since_1st_test'] >= 7]\nfig = plot_against_entity(df=covid_df_after_7_days,\n                    entity_list=['Italy', 'New Zealand', 'South Korea', 'United States'],\n                    x='days_since_1st_test',\n                    y='test_positive_ratio_7_day_rolling_ROC',\n                    title='Figure 8. 7-Day Rolling Test Positive Ratio (TPR) Rate of Change (ROC)', \n                    xaxis_title='Days Since 1st Reported Test ', \n                    yaxis_title='7-Day Rolling Test Positive Ratio (TPR) Rate of Change (ROC)',\n                    horiz_line=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's add columns to the dataset showing rates of increase in cases and tests over a rolling week-long period. We can then compare the ratio of rate of increase in cases to rate of increase in tests.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"maxidx_tpr_7_day_rolling_roc_per_entity = covid_df_after_7_days.replace([np.inf, -np.inf], np.nan).groupby('Entity')['test_positive_ratio_7_day_rolling_ROC'].idxmax().dropna()\n\ndef find_neg_tpr_roc_after_max(row):\n    if row['Entity'] not in maxidx_tpr_7_day_rolling_roc_per_entity:\n        return\n    if row.name < maxidx_tpr_7_day_rolling_roc_per_entity[row['Entity']]:\n        return\n    if row['test_positive_ratio_7_day_rolling_ROC'] < 0:\n        return row['Date']\n    \nentity_with_completed_peak_list = []\nfirst_neg_tpr_roc_after_max = []\nfor entity in covid_df_after_7_days['Entity'].unique():\n    tmp = covid_df_after_7_days[covid_df_after_7_days['Entity'] == entity].apply(find_neg_tpr_roc_after_max, axis=1)\n    if len(tmp.dropna().index) > 0:\n        entity_with_completed_peak_list.append(entity)\n        first_neg_tpr_roc_after_max.append(tmp.dropna().iloc[0])\n\nentity_first_neg_dict = dict(zip(entity_with_completed_peak_list, first_neg_tpr_roc_after_max))\n\n# Now using this dictionary we can find the length of the peaks for those countries that had a negative TPR ROC after the max.\nentities_completed_peak_length = {}\nfor entity, first_neg_date in entity_first_neg_dict.items():\n    tpr_roc_max_idx = maxidx_tpr_7_day_rolling_roc_per_entity[entity]\n    tpr_roc_max_date = covid_df.loc[tpr_roc_max_idx, 'Date']\n    length = (first_neg_date - tpr_roc_max_date).days\n    entities_completed_peak_length.update({entity: length})\n\nprint(entities_completed_peak_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"entities_peak_length_df = pd.DataFrame(entities_completed_peak_length.values(), columns=['Peak Length'], index=entities_completed_peak_length.keys())\n\nfig = px.bar(entities_peak_length_df, x=entities_peak_length_df.index, y=entities_peak_length_df['Peak Length'])\nfig.update_layout(title='Figure 9. Completed Peak Lengths by Entity',\n                   xaxis_title='Entities',\n                   yaxis_title='Peak Length')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's get the average outbreak length across all these countries. We can use this to \"predict\" when countries that have not yet reached the peak might reach it.\n\nThere are a lot of factors we're not accounting for. We could define a transfer function between tests/cases/deaths (or rate of change of those) and the length in days of the outbreak. This would help us better predict the length of our current outbreak.\n\nif an entity hasn't reached the peak yet, but is more than the average amount of days (~12 days) from max TPR ROC to first negative TPR ROC, we could hypothesize that they either haven't reached their true maximum TPR ROC or the measures they are taking are flattening the curve.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"average_outbreak_length = np.array([entities_completed_peak_length[entity] for entity in entities_completed_peak_length]).mean()\nprint('Average Outbreak Length: {} days'.format(average_outbreak_length))\n\nentities_not_yet_through_peak = set(maxidx_tpr_7_day_rolling_roc_per_entity.index).difference(set(entity_with_completed_peak_list))\nprint('Entities not yet through peak: {}'.format(entities_not_yet_through_peak))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the entities that are not yet through their peak of the pandemic, let's try to fit a model to predict when they will experience a peak. To accomplish this, we will use the maximum of Deaths per Million, Cases per Million, and Tests per Million as inputs to the model, as well as generated features such as Mean Case Fatality Rate (CFR, deaths per confirmed cases), Maximum CFR, Mean and Maximum TPR, Mean and Maximum TPR ROC, and the incremental area under the curve of TPR (TPR iAUC).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Feature Generation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_features(covid_entity):\n    # Let's build a DataFrame of maximum aggregate X per million with the outbreak length in days.\n    covid_entity['max_agg_deaths_per_mil'] = covid_entity['agg_deaths_per_mil'].max()\n    covid_entity['max_agg_cases_per_mil'] = covid_entity['agg_cases_per_mil'].max()\n    covid_entity['max_agg_tests_per_mil'] = covid_entity['agg_tests_per_mil'].max()\n\n    # Calculate Case Fatality Rate (CFR) and find the maximum and mean.\n    covid_entity['mean_cfr'] = covid_entity['cfr'].mean()\n    covid_entity['max_cfr'] = covid_entity['cfr'].max()\n\n    # Calculate mean/max Test Positive Rate\n    covid_entity['mean_tpr'] = covid_entity['test_positive_ratio'].mean()\n    covid_entity['max_tpr'] = covid_entity['test_positive_ratio'].max()\n\n    # Calculate mean Test Positive Rate Rate of Change\n    covid_entity['mean_tpr_roc'] = covid_entity['test_positive_ratio_ROC'].mean()\n    covid_entity['max_tpr_roc'] = covid_entity['test_positive_ratio_7_day_rolling_ROC'].max()\n\n    # Calculate Area Under the Curve of Test Positive Rate over Time\n    covid_entity_prev_days = covid_entity['days_since_1st_test'].shift(periods=1)\n    covid_entity_prev_tpr = covid_entity['test_positive_ratio'].shift(periods=1)\n    day_diff = covid_entity['days_since_1st_test'] - covid_entity_prev_days\n    tpr_sum = covid_entity['test_positive_ratio'] + covid_entity_prev_tpr\n    tpr_auc = 0.5 * day_diff * tpr_sum\n    covid_entity['tpr_iauc'] = tpr_auc.sum()\n\n    return covid_entity\n    \ncovid_df['cfr'] = covid_df['agg_deaths'] / covid_df['agg_cases']\n\ncalculated_features = covid_df.groupby('Entity').apply(calc_features) # .dropna()\n\nfeature_list = ['max_agg_deaths_per_mil', 'max_agg_cases_per_mil', 'max_agg_tests_per_mil',\n                'mean_cfr', 'max_cfr',\n                'mean_tpr', 'max_tpr', 'max_tpr_roc', 'mean_tpr_roc', 'tpr_iauc']\n\n# Let's see what these features look like.\nprint(calculated_features[calculated_features['Entity'] == 'South Korea'][feature_list].head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build a DataFrame consisting of only the countries that have completed their outbreak.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"outbreak_length_df = pd.DataFrame(entities_completed_peak_length.values(), index=entities_completed_peak_length.keys(), columns=['outbreak_length_in_days'])\nsingle_calc_features = calculated_features.groupby('Entity')[feature_list].first()\nfor feature in feature_list:\n    outbreak_length_df[feature] = single_calc_features[feature]\n\n    \noutbreak_length_df = outbreak_length_df\n\n# Let's look at this too.\nprint(outbreak_length_df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training\n\nNow let's fit a couple models to the data. One will be polynomial and the other will be linear.\n\nWe're using all of the data from entities that are through the peak of the pandemic. We're doing this due to lack of data. We can test our models by comparing the predicted peaks to real data from entities that have since completed their peaks (we only have data through early April in our dataset).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\nX = outbreak_length_df[feature_list].values\ny = outbreak_length_df['outbreak_length_in_days'].values\n\npoly_reg = PolynomialFeatures(degree=2)\nX_poly = poly_reg.fit_transform(X)\n        \npoly_model = LinearRegression(normalize=True)\npoly_model.fit(X_poly, y)\n\nprint('Poly Model Score: {}\\n'.format(poly_model.score(X_poly, y)))\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nprint('Linear Model Score: {}\\n'.format(model.score(X, y)))\n\ndef predict_peak(entity):\n    values = [single_calc_features.loc[entity, feature_list].values]\n    return model.predict(values)[0]\n\ndef predict_peak_poly(entity):\n    values = poly_reg.fit_transform([single_calc_features.loc[entity, feature_list].values])\n    return poly_model.predict(values)[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction\n\nWe got a perfect fit with the polynomial model, so we've most certainly overfit our small dataset with that model. 0.53 is the best R^2 value we've been able to get for the linear model. Let's use our models to predict the end of the pandemic peak for entities that have not yet made it to the peak (with the data we have).\n\nFirst, let's use the Polynomial Model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_entities_through_model(poly=False):\n    predicted_peak = {}\n    for entity in entities_not_yet_through_peak:\n        if entity not in single_calc_features.index:\n            continue\n        maxdate = covid_df.loc[maxidx_tpr_7_day_rolling_roc_per_entity[entity], 'Date']\n        predicted_peaklength = predict_peak_poly(entity) if poly else predict_peak(entity)\n        predicted_peakdate = maxdate + datetime.timedelta(days=predicted_peaklength)\n        predicted_peak.update({entity: {'start': maxdate, 'peak': predicted_peakdate, 'length': predicted_peaklength}})\n        \n    return predicted_peak\n\npredicted_peak_poly = run_entities_through_model(poly=True)\n\nfig = plt.figure(figsize=(15,5))\nsns.barplot(x=list(predicted_peak_poly.keys()), y=[val['length'] for val in predicted_peak_poly.values()])\nplt.title('Figure 10. Predicted Peak Length in Days (Polynomial Model)')\nplt.xlabel('Entity')\nplt.ylabel('Peak Length (Days)')\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're getting huge negative numbers for the Philippines and even larger numbers for US. This seems like the polynomial model has definitely overfit the dataset. Let's try to use the Linear model instead.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_peak = run_entities_through_model(poly=False)\n\nfig = plt.figure(figsize=(15,5))\nsns.barplot(x=list(predicted_peak.keys()), y=[val['length'] for val in predicted_peak.values()])\nplt.title('Figure 11. Predicted Peak Length in Days (Linear Model)')\nplt.xlabel('Entity')\nplt.ylabel('Peak Length (Days)')\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This seems far more reasonable. Let's create a timeline with this data, showing start and end points of the pandemic outbreak to peak.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nplt.title('Figure 12. Predicted Peak Timeline')\nplt.xlabel('Date')\nplt.ylabel('Entity')\nplt.grid(True)\nfor entity, item in predicted_peak.items():\n    plt.plot([item['start'], item['peak']], [entity, entity], linewidth=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for entity, item in predicted_peak.items():\n    print(entity)\n    print('Start: {}, End: {}\\n'.format(item['start'], item['peak']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check our model with more current real data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ihme_covid_df = pd.read_csv('/kaggle/input/ihmes-covid19-projections/2020_05_10/Hospitalization_all_locs.csv')\nihme_covid_df['date'] = pd.to_datetime(ihme_covid_df['date'])\nihme_covid_df['tpr'] = ihme_covid_df['confirmed_infections'] / ihme_covid_df['total_tests']\n\ndef days_since_first_ihme(col):\n    first_dates = ihme_covid_df[ihme_covid_df[col] != 0].groupby('location_name').first()['date']\n    \n    def day_diff(row):\n        if row['location_name'] not in first_dates:\n            return None\n        return (row['date'] - first_dates[row['location_name']]).days\n    \n    return ihme_covid_df.apply(day_diff, axis=1)\n\nihme_covid_df['days_since_1st_case'] = days_since_first_ihme('confirmed_infections')\nihme_covid_df['days_since_1st_test'] = days_since_first_ihme('total_tests')\n\ndef generate_rolling_mean_ihme(df, days, mean_col):\n    return df.reset_index().set_index('days_since_1st_case').groupby('location_name').rolling(days, min_periods=1)[mean_col].mean().values\n\nihme_covid_df.loc[ihme_covid_df['tpr'] <= 1, 'tpr_7_day_rolling'] = generate_rolling_mean_ihme(ihme_covid_df[ihme_covid_df['tpr'] <= 1], 7, 'tpr')\n\nihme_covid_df['tpr_ROC'] = ihme_covid_df[ihme_covid_df['tpr'] <= 1]['tpr'].pct_change()\n\n# Replace infinite values with NaN\nihme_covid_df = ihme_covid_df.replace([np.inf, -np.inf], np.nan)\n\nihme_covid_df['tpr_7_day_rolling_ROC'] = generate_rolling_mean_ihme(ihme_covid_df, 7, 'tpr_ROC')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ihme_covid_df_after_7_days = ihme_covid_df[ihme_covid_df['days_since_1st_test'] >= 7]\nmaxidx_tpr_7_day_rolling_roc_per_entity = ihme_covid_df_after_7_days.replace([np.inf, -np.inf], np.nan).groupby('location_name')['tpr_7_day_rolling_ROC'].idxmax().dropna()\n\ndef find_neg_tpr_roc_after_max_ihme(row):\n    if row['location_name'] not in maxidx_tpr_7_day_rolling_roc_per_entity:\n        return\n    if row.name < maxidx_tpr_7_day_rolling_roc_per_entity[row['location_name']]:\n        return\n    if row['tpr_7_day_rolling_ROC'] < 0:\n        return row['date']\n    \nentity_with_completed_peak_list_ihme = []\nfirst_neg_tpr_roc_after_max_ihme = []\nfor entity in ihme_covid_df_after_7_days['location_name'].unique():\n    tmp = ihme_covid_df_after_7_days[ihme_covid_df_after_7_days['location_name'] == entity].apply(find_neg_tpr_roc_after_max_ihme, axis=1)\n    if len(tmp.dropna().index) > 0:\n        entity_with_completed_peak_list_ihme.append(entity)\n        first_neg_tpr_roc_after_max_ihme.append(tmp.dropna().iloc[0])\n\nentity_first_neg_dict_ihme = dict(zip(entity_with_completed_peak_list_ihme, first_neg_tpr_roc_after_max_ihme))\n\n# Now using this dictionary we can find the length of the peaks for those countries that had a negative TPR ROC after the max.\nentities_completed_peak_length_ihme = {}\nfor entity, first_neg_date in entity_first_neg_dict_ihme.items():\n    tpr_roc_max_idx = maxidx_tpr_7_day_rolling_roc_per_entity[entity]\n    tpr_roc_max_date = ihme_covid_df.loc[tpr_roc_max_idx, 'date']\n    length = (first_neg_date - tpr_roc_max_date).days\n    entities_completed_peak_length_ihme.update({entity: length})\n\nprint(entities_completed_peak_length_ihme)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"entity_absolute_relative_error = []\nentity_ok = []\nfor entity, length in entities_completed_peak_length_ihme.items():\n    if length <= 0:\n        continue\n    if entity in predicted_peak:\n        print('Entity: {}'.format(entity))\n        print('Predicted length of pandemic peak: {}'.format(predicted_peak[entity]['length']))\n        print('Actual length of pandemic peak: {}'.format(length))\n        score = abs(predicted_peak[entity]['length'] - length) / length\n        print('Error: {}\\n'.format(score))\n        entity_absolute_relative_error.append(score)\n        entity_ok.append(entity)\n        \n        \n\nprint('Average relative error: {}'.format(np.array(entity_absolute_relative_error).mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfor entity, item in predicted_peak.items():\n    if entity not in entity_ok:\n        continue\n    entity_ihme = ihme_covid_df[ihme_covid_df['location_name'] == entity]\n    entity_df = entity_ihme[['date', 'confirmed_infections']].dropna()\n    fig = px.line(entity_df, x='date', y='confirmed_infections')\n    fig.update_layout(title='{} Infections Per Day with Pandemic Peak Prediction Overlay'.format(entity))\n    fig.add_shape(\n                type=\"rect\",\n                # x-reference is assigned to the x-values\n                xref=\"x\",\n                # y-reference is assigned to the plot paper [0,1]\n                yref=\"paper\",\n                x0=item['start'],\n                y0=0,\n                x1=item['peak'],\n                y1=1,\n                fillcolor=\"LightSalmon\",\n                opacity=0.5,\n                layer=\"below\",\n                line_width=0,\n            )\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}