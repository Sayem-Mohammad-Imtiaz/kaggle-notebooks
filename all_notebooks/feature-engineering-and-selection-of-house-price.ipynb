{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing The Training Dataset\ndf = pd.read_csv('../input/house-price-prediction-dataset/train.csv')\n# Displaying all the columns\npd.set_option('Display.max_columns', 81)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting The Feature Names\ndf.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing And EDA\n\nIn data preprocessing section, the dataset may have contained some errors such as missing values, outliers etc.\nThis dataset does not have any duplicate values. Data preprocessing is an operation for making the dataset errorless\nfor EDA.","metadata":{}},{"cell_type":"markdown","source":"### Missing values","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nprint(df.isna().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Many null values are there in the dataset therefore we have to find the relation between null values and SalesPrice.\nBelow used diagrams are showing the relationship of null values and SalesPrice.","metadata":{}},{"cell_type":"markdown","source":"### Numerical Variable","metadata":{}},{"cell_type":"code","source":"numerical_features = [features for features in df.columns if df[features].dtypes != object]\nprint('Number Of Numerical Variables : ', len(numerical_features))\ndf[numerical_features].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Date-Time Variables / Temporal Variables","metadata":{}},{"cell_type":"code","source":"# 'Yr' and \"Year\" are there in all the year variables\nyear_features = [features for features in numerical_features if 'Yr' in features or 'Year' in features]\nyear_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can get number of years by the difference of YearBuilt and YrSold","metadata":{}},{"cell_type":"code","source":"# Relation between YrSold and SalePrice\nplt.style.use('dark_background')\ndf.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title('Year Sold VS House Price')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we'll see the difference between Year Sold And All the year variables.\nfor feature in year_features :\n    if feature != 'YrSold':\n        df[feature] = df['YrSold'] - df[feature]\n        plt.scatter(df[feature], df['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('Sale Price')\n        plt.tight_layout()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Discrete Variable\ndiscrete_features = [feature for feature in numerical_features if len(df[feature].unique())<25 and feature not in year_features + [['ID']]]\nprint('Number Of Discrete Features : ', len(discrete_features))\ndf[discrete_features].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Relationship Between Discrete Features And Sale Price\nfor feature in discrete_features :\n    df.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('Sale Price')\n    plt.title(feature)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there is a relationship between number of variables and SalePrice","metadata":{}},{"cell_type":"code","source":"# Continuous Variable\ncontinuous_features = [feature for feature in numerical_features if feature not in discrete_features +year_features +['Id']]\nprint('Number Of Discrete Features : ', len(continuous_features))\ndf[continuous_features].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing The Relationship Of Continuous Variable By Histogram\nfor feature in continuous_features :\n    plt.hist(df[feature], bins = 25)\n    plt.xlabel(feature)\n    plt.ylabel('Count')\n    plt.title(feature)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Outliers","metadata":{}},{"cell_type":"code","source":"for feature in continuous_features:\n    if 0 in df[feature].unique():\n        pass\n    else:\n        plt.style.use('default')\n        df[feature] = np.log(df[feature])\n        df.boxplot(column = feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.tight_layout()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical Variables\ncategorical_features = [feature for feature in df.columns if df[feature].dtypes == object]\nfor feature in categorical_features:\n    print('In {} number of categories are {}'.format(feature, len(df[feature].unique())))\ndf[categorical_features].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyzing The Relationship Of Categorical Variable\nfor feature in categorical_features :\n    plt.style.use('dark_background')\n    df.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Replacing null values of categorical feature with a new label\ncat_na_features = [feature for feature in df.columns if df[feature].isna().sum()>1 and df[feature].dtypes == 'O']\n\ndf[cat_na_features] = df[cat_na_features].fillna('Missing')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dealing with missing values in numerical variables\nnum_na_features = [feature for feature in df.columns if df[feature].isna().sum()>1 and df[feature].dtypes != object]\n\nfor feature in num_na_features:\n    \n    # Replacing it by median values because there are outliers\n    median_value = df[feature].median()\n    \n    # Creating a new feature for capturing nan values\n    df[feature + 'nan'] = np.where(df[feature].isna(), 1,0)\n    df[feature].fillna(median_value, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Rare Categorical Feature\n\nRemoving categorical features which are less than 1% of the observations.","metadata":{}},{"cell_type":"code","source":"categorical_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in categorical_features :\n    temp = df.groupby(feature)['SalePrice'].count() / len(df)\n    temp_df = temp[temp > 0.01].index\n    df[feature] = np.where(df[feature].isin(temp_df), df[feature],'Rare_var')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nenc_features = ['MSZoning','Street','Alley','LotShape','LandContour','Utilities',\n                'LotConfig','LandSlope','Neighborhood',\n                'Condition1','Condition2','BldgType','HouseStyle','RoofStyle',\n                'RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual',\n                'ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure',\n                'BsmtFinType1','BsmtFinType2','Heating','HeatingQC',\n                'CentralAir','Electrical','KitchenQual','Functional',\n                'FireplaceQu','GarageType','GarageFinish','GarageQual',\n                'GarageCond','PavedDrive','PoolQC','Fence','MiscFeature',\n                'SaleType','SaleCondition']\nfor feature in enc_features :\n    df[feature] = le.fit_transform(df[feature])\n\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Scaling","metadata":{}},{"cell_type":"code","source":"feature_scale = [feature for feature in df.columns if feature not in ['Id','SalePrice']]\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(df[feature_scale])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.transform(df[feature_scale])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(df, df['SalePrice'], test_size = 0.1, random_state = 0)  \nX_train.drop(['Id','SalePrice'], axis =1)\nX_test.drop(['Id','SalePrice'], axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}