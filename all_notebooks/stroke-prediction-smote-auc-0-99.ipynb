{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**About the Dataset**\n* Total of 5110 observations and 12 attributes\n* Nuemeric continuous variables - id, age, avg_glucose_level, bmi\n* Categorical variables - gender, hypertension, heart_disease, ever_married, work_type, Residence_type, smoking_status\n\n\n**Attribute Information**\n* id: unique identifier\n* gender: patient's gender\n* age: age of the patient\n* hypertension: if patient suffers from hypertension (0 - No, 1 - Yes)\n* heart_disease: if patient suffers from heart disease (0 - No, 1 - Yes)\n* ever_married: if patient is married (No, Yes)\n* work_type: patients' job type\n* Residence_type: patients' residential location\n* avg_glucose_level: patients' average blood glucose level\n* bmi: patients' body mass index\n* smoking_status: patients' past and present smoking status\n* stroke: if patient suffers from stroke (0 - No, 1 - Yes)\n\n\n**Contents**\n* Importing libraries and data\n* A peek into the data\n* Checking for missing values\n* EDA on categorical and numeric columns\n* Tailoring dataframe for building model\n* Comparing multiple classifiers\n* Prediction and evaluation\n\n**Aim**\n* Develop model to predict stroke based on numeric and categorical variables","metadata":{}},{"cell_type":"markdown","source":"# Importing required libraries and packages","metadata":{}},{"cell_type":"code","source":"# -- Importing required libraries and packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import KNNImputer\nfrom sklearn.metrics import accuracy_score\nimport missingno as msno\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:26.582549Z","iopub.execute_input":"2021-06-08T13:03:26.583237Z","iopub.status.idle":"2021-06-08T13:03:27.995804Z","shell.execute_reply.started":"2021-06-08T13:03:26.583135Z","shell.execute_reply":"2021-06-08T13:03:27.994769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing data | Skimming data | Missing values","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:27.998162Z","iopub.execute_input":"2021-06-08T13:03:27.998531Z","iopub.status.idle":"2021-06-08T13:03:28.063248Z","shell.execute_reply.started":"2021-06-08T13:03:27.998498Z","shell.execute_reply":"2021-06-08T13:03:28.062312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- getting a feel for the dataset\ndf.info()\n\n# -- bmi has a few missing values\n\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:28.064801Z","iopub.execute_input":"2021-06-08T13:03:28.065297Z","iopub.status.idle":"2021-06-08T13:03:28.12534Z","shell.execute_reply.started":"2021-06-08T13:03:28.065259Z","shell.execute_reply":"2021-06-08T13:03:28.12453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- dropping 'id' column\ndf.drop(columns='id', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:28.126756Z","iopub.execute_input":"2021-06-08T13:03:28.12723Z","iopub.status.idle":"2021-06-08T13:03:28.132998Z","shell.execute_reply.started":"2021-06-08T13:03:28.127192Z","shell.execute_reply":"2021-06-08T13:03:28.132173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- looking for missing values in this dataset\n\nax = sns.heatmap(df.isna(), yticklabels=False)\nax.set_title(label=\"(white bars are missing values)\")\n\nprint('Shape of the dataset - {}'.format(df.shape))\n\n# -- The missing values can be attended to lateron","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:28.135291Z","iopub.execute_input":"2021-06-08T13:03:28.135777Z","iopub.status.idle":"2021-06-08T13:03:28.537137Z","shell.execute_reply.started":"2021-06-08T13:03:28.135727Z","shell.execute_reply":"2021-06-08T13:03:28.536204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- how are the missing values distributed \nmsno.matrix(df)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:28.538324Z","iopub.execute_input":"2021-06-08T13:03:28.538749Z","iopub.status.idle":"2021-06-08T13:03:29.097135Z","shell.execute_reply.started":"2021-06-08T13:03:28.538714Z","shell.execute_reply":"2021-06-08T13:03:29.09594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling missing values","metadata":{}},{"cell_type":"code","source":"# -- Handling missing bmi values ussing KNNImputer from sklearn\nimputer = KNNImputer(n_neighbors=2)\n\n# -- Selecting numerical columns for imputing missing bmi values\ndf_num = df.select_dtypes(exclude=['object'])\narray_ = imputer.fit_transform(df_num)\n\n# -- adding the column names back\ncolx = df_num.columns\ndf_num_nn = pd.DataFrame(array_, columns=colx)\n\ndf_obj = df.select_dtypes(exclude=['int64','float64'])\n\n# -- concatenating the imputed numeric and object columns \ndf = pd.concat([df_obj,df_num_nn], axis=1)\n\n# -- df is new dataframe without missing values \ndf.info() , df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:29.098605Z","iopub.execute_input":"2021-06-08T13:03:29.09895Z","iopub.status.idle":"2021-06-08T13:03:29.448523Z","shell.execute_reply.started":"2021-06-08T13:03:29.098915Z","shell.execute_reply":"2021-06-08T13:03:29.447431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Having a look at thegender column\ndf.gender.value_counts()\n\n# -- row with 'Other' can be dropped","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:29.451992Z","iopub.execute_input":"2021-06-08T13:03:29.452477Z","iopub.status.idle":"2021-06-08T13:03:29.464795Z","shell.execute_reply.started":"2021-06-08T13:03:29.452424Z","shell.execute_reply":"2021-06-08T13:03:29.463599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(df[df['gender'] == 'Other'].index, inplace = True)\ndf.gender.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:29.466769Z","iopub.execute_input":"2021-06-08T13:03:29.467142Z","iopub.status.idle":"2021-06-08T13:03:29.48635Z","shell.execute_reply.started":"2021-06-08T13:03:29.467095Z","shell.execute_reply":"2021-06-08T13:03:29.485376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA on how Stroke relates to different parameters","metadata":{}},{"cell_type":"markdown","source":"**Stroke cases relation to continuous numeric variables**","metadata":{}},{"cell_type":"code","source":"# -- total no. of strokes in this dataset\nsns.set_theme()\nsns.set_palette('husl')\n\ndf.stroke.value_counts().plot(kind='bar',label='Stroke-cases Count',figsize=(12,7))\nplt.legend()\n\n# -- This is highly imbalanced and needs to be evened out","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:29.487767Z","iopub.execute_input":"2021-06-08T13:03:29.4886Z","iopub.status.idle":"2021-06-08T13:03:29.682201Z","shell.execute_reply.started":"2021-06-08T13:03:29.488544Z","shell.execute_reply":"2021-06-08T13:03:29.681192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Does age have anything to do with stroke cases?\n\nplt.figure(figsize=(12,5))\nsns.histplot(x='age', data=df, hue='stroke', bins=40)\n# -- We can observe that stroke risk increases with age","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:29.68356Z","iopub.execute_input":"2021-06-08T13:03:29.684058Z","iopub.status.idle":"2021-06-08T13:03:30.146518Z","shell.execute_reply.started":"2021-06-08T13:03:29.68402Z","shell.execute_reply":"2021-06-08T13:03:30.145192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Stroke cases distribution with average sugar level\n\nplt.figure(figsize=(12,5))\ng = sns.histplot(x='avg_glucose_level', data=df, hue='stroke', bins=50, palette='husl')\ng.set_title('Stroke vs Avg. Blood Glucose Level')\n# -- The distribution shows 2 small peaks. Once at about 75 and once at ~200. Not many stroke cases between 125 and 175","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:30.148092Z","iopub.execute_input":"2021-06-08T13:03:30.148426Z","iopub.status.idle":"2021-06-08T13:03:30.664371Z","shell.execute_reply.started":"2021-06-08T13:03:30.148396Z","shell.execute_reply":"2021-06-08T13:03:30.663213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- How do stroke cases vary with Body Mass Indices?\nplt.figure(figsize=(12,5))\ng = sns.histplot(x='bmi', bins=40, data=df, hue='stroke', alpha=0.4)\ng.set_title('stroke vs BMI')\n# -- No. of stroke cases peak with the no-stroke counts between 20 and 40.\n# -- We see some of the outliers in bmi values after 60","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:30.665699Z","iopub.execute_input":"2021-06-08T13:03:30.666022Z","iopub.status.idle":"2021-06-08T13:03:31.146641Z","shell.execute_reply.started":"2021-06-08T13:03:30.665988Z","shell.execute_reply":"2021-06-08T13:03:31.145199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Stroke cases in relation to categorical variables**","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(4,2, figsize=(17,15))\n\nsns.countplot(ax=ax[0,0],data=df,x='gender', hue='stroke', palette='Dark2')\nsns.countplot(ax=ax[0,1],data=df,x='hypertension', hue='stroke', palette='Dark2')\nsns.countplot(ax=ax[1,0],data=df,x='heart_disease', hue='stroke', palette='Dark2')\nsns.countplot(ax=ax[1,1],data=df,x='ever_married', hue='stroke', palette='Dark2')\nsns.countplot(ax=ax[2,0],data=df,x='work_type', hue='stroke', palette='Dark2')\nsns.countplot(ax=ax[2,1],data=df,x='Residence_type', hue='stroke', palette='Dark2')\nsns.countplot(ax=ax[3,0],data=df,x='smoking_status', hue='stroke', palette='Dark2')\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:31.148403Z","iopub.execute_input":"2021-06-08T13:03:31.148769Z","iopub.status.idle":"2021-06-08T13:03:32.779977Z","shell.execute_reply.started":"2021-06-08T13:03:31.14873Z","shell.execute_reply":"2021-06-08T13:03:32.778722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_list=['gender','hypertension','heart_disease','ever_married','work_type','Residence_type','smoking_status']\nl = []\n\nfor i in cat_list:\n    j = df.groupby(i)['stroke'].mean() * 100\n    l.append(j)\n\nl = [pd.DataFrame(l[i]) for i in range(len(l))]\n\nsns.set_palette('Set2')\nfig, ax = plt.subplots(4,2, figsize=(17,15))\nst = fig.suptitle(\"% STROKE CASES FOR EACH OF THE CATEGORIES\", fontsize=\"x-large\")\nst.set_y(0.92)\n\ng0=sns.barplot(x=l[0].index, data=l[0], y='stroke', ax=ax[0,0])\ng1=sns.barplot(x=l[1].index, data=l[1], y='stroke', ax=ax[0,1])\ng2=sns.barplot(x=l[2].index, data=l[2], y='stroke', ax=ax[1,0])\ng3=sns.barplot(x=l[3].index, data=l[3], y='stroke', ax=ax[1,1])\ng4=sns.barplot(x=l[4].index, data=l[4], y='stroke', ax=ax[2,0])\ng5=sns.barplot(x=l[5].index, data=l[5], y='stroke', ax=ax[2,1])\ng6=sns.barplot(x=l[6].index, data=l[6], y='stroke', ax=ax[3,0])\n\n# -- Gender and Residence types doesn't have much difference in stroke risk\n# -- people with 'hypertension', 'heart_disease' or 'ever_married' are at a higher risk of stroke\n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:32.78155Z","iopub.execute_input":"2021-06-08T13:03:32.781953Z","iopub.status.idle":"2021-06-08T13:03:34.140939Z","shell.execute_reply.started":"2021-06-08T13:03:32.781912Z","shell.execute_reply":"2021-06-08T13:03:34.140138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Stroke risks among married and unmarried indivisuals grouped by gender\ngp = df.groupby(['gender','ever_married'], as_index=False)['stroke'].count()\nplt.figure(figsize=(12,5))\ng = sns.barplot(x='ever_married', data=gp, y='stroke', hue='gender')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:34.142206Z","iopub.execute_input":"2021-06-08T13:03:34.142685Z","iopub.status.idle":"2021-06-08T13:03:34.349076Z","shell.execute_reply.started":"2021-06-08T13:03:34.142634Z","shell.execute_reply":"2021-06-08T13:03:34.347972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Smoking status based on occupation\n\ngp2 = df.groupby(['work_type','smoking_status'], as_index=False)['stroke'].count()\nplt.figure(figsize=(12,5))\nsns.barplot(x='work_type', data=gp2, y='stroke', hue='smoking_status')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:34.350687Z","iopub.execute_input":"2021-06-08T13:03:34.351105Z","iopub.status.idle":"2021-06-08T13:03:34.673238Z","shell.execute_reply.started":"2021-06-08T13:03:34.351064Z","shell.execute_reply":"2021-06-08T13:03:34.672284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Categorical variables' distribution along age\nfig, (ax0, ax1,ax2, ax3) = plt.subplots(4,figsize=(11,12))\nsns.kdeplot(x='age', data=df, hue='work_type', palette='Dark2', fill=True, ax=ax0)\nsns.kdeplot(x='age', data=df, hue='smoking_status', palette='Dark2', fill=True, ax=ax1)\nsns.kdeplot(x='age', data=df, hue='hypertension', palette='Dark2', fill=True, ax=ax2)\nsns.kdeplot(x='age', data=df, hue='heart_disease', palette='Dark2', fill=True, ax=ax3)\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:34.674671Z","iopub.execute_input":"2021-06-08T13:03:34.675264Z","iopub.status.idle":"2021-06-08T13:03:35.935316Z","shell.execute_reply.started":"2021-06-08T13:03:34.675225Z","shell.execute_reply":"2021-06-08T13:03:35.934114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Avg. glucose levels and BMI relations with age\nplt.figure(figsize=(8, 5), dpi=80)\nsns.scatterplot(x='age',y='avg_glucose_level',data=df,hue='stroke',s=6,marker='o',palette='Dark2')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:35.9368Z","iopub.execute_input":"2021-06-08T13:03:35.937179Z","iopub.status.idle":"2021-06-08T13:03:36.374282Z","shell.execute_reply.started":"2021-06-08T13:03:35.937141Z","shell.execute_reply":"2021-06-08T13:03:36.373138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 5), dpi=80)\nsns.scatterplot(x='age',y='bmi',data=df,hue='stroke',s=6,marker='o',palette='Dark2')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:36.375821Z","iopub.execute_input":"2021-06-08T13:03:36.376233Z","iopub.status.idle":"2021-06-08T13:03:36.76127Z","shell.execute_reply.started":"2021-06-08T13:03:36.376193Z","shell.execute_reply":"2021-06-08T13:03:36.760324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- correlation between numerical variables\nsns.heatmap(df[['age','avg_glucose_level','bmi']].corr(), annot=True)\n\n# -- no concrete correlations seen here","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:36.762488Z","iopub.execute_input":"2021-06-08T13:03:36.762961Z","iopub.status.idle":"2021-06-08T13:03:37.066062Z","shell.execute_reply.started":"2021-06-08T13:03:36.762924Z","shell.execute_reply":"2021-06-08T13:03:37.065167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modifying dataframe for building model","metadata":{}},{"cell_type":"code","source":"# -- Using dummy variables showed better accuracy score as opposed to Label Encoder\n# -- converting work_type and smoking_status to dummy variables\n# -- Other categorical columns have 2 unique values (0 and 1) anyway so let's leave them that way \n\nWT_dummy = pd.get_dummies(df['work_type'],prefix_sep='_',prefix='WT',drop_first=True)\nSS_dummy = pd.get_dummies(df['smoking_status'],prefix_sep='_',prefix='SS',drop_first=True)\nG_dummy = pd.get_dummies(df['gender'],prefix_sep='_',prefix='G',drop_first=True)\nM_dummy = pd.get_dummies(df['ever_married'],prefix_sep='_',prefix='M',drop_first=True)\nRes_dummy = pd.get_dummies(df['Residence_type'],prefix_sep='_',prefix='Res',drop_first=True)\ndf = pd.concat([df,WT_dummy,SS_dummy,G_dummy,M_dummy,Res_dummy], axis=1)\n\n# -- dropping original categorical columns as they've been converetd to dummy columns\n\ndf.drop(columns=['work_type','smoking_status','gender','ever_married','Residence_type'], inplace=True)\ndf['hypertension']=df.hypertension.astype('int32')\ndf['heart_disease']=df.hypertension.astype('int32')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.067214Z","iopub.execute_input":"2021-06-08T13:03:37.067641Z","iopub.status.idle":"2021-06-08T13:03:37.106384Z","shell.execute_reply.started":"2021-06-08T13:03:37.067606Z","shell.execute_reply":"2021-06-08T13:03:37.105463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Balancing 'stroke' column using SMOTE oversampling**","metadata":{}},{"cell_type":"code","source":"df.stroke.value_counts()\n\n# -- Given the high imbalance in this dataset we carry out some tailoring ","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.109439Z","iopub.execute_input":"2021-06-08T13:03:37.109937Z","iopub.status.idle":"2021-06-08T13:03:37.118538Z","shell.execute_reply.started":"2021-06-08T13:03:37.1099Z","shell.execute_reply":"2021-06-08T13:03:37.117399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Balancing can be carried out by either undersampling or oversampling\nfrom imblearn.over_sampling import SMOTE\n\nsamp = SMOTE()\nX = df.drop(columns='stroke')\ny = df[['stroke']]\nX,y = samp.fit_resample(X,y)\ny.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.120489Z","iopub.execute_input":"2021-06-08T13:03:37.121232Z","iopub.status.idle":"2021-06-08T13:03:37.396876Z","shell.execute_reply.started":"2021-06-08T13:03:37.121177Z","shell.execute_reply":"2021-06-08T13:03:37.395724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- joining back the target and predictors into a new DF -> DF2\ndf2 = pd.concat([X,y], axis=1)\n\ndf2.info(), df2.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.398277Z","iopub.execute_input":"2021-06-08T13:03:37.398923Z","iopub.status.idle":"2021-06-08T13:03:37.430996Z","shell.execute_reply.started":"2021-06-08T13:03:37.398876Z","shell.execute_reply":"2021-06-08T13:03:37.429753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction using Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Importing required prediction libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, plot_roc_curve, confusion_matrix, confusion_matrix , \\\nprecision_score , recall_score ,f1_score , accuracy_score , classification_report , roc_curve , auc\n","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.432417Z","iopub.execute_input":"2021-06-08T13:03:37.432858Z","iopub.status.idle":"2021-06-08T13:03:37.437705Z","shell.execute_reply.started":"2021-06-08T13:03:37.432798Z","shell.execute_reply":"2021-06-08T13:03:37.436923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df2.drop(columns='stroke')\ny = df2.stroke\n\n# -- Splitting dataset into testing and training sub-sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\ntype(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.438983Z","iopub.execute_input":"2021-06-08T13:03:37.439362Z","iopub.status.idle":"2021-06-08T13:03:37.466158Z","shell.execute_reply.started":"2021-06-08T13:03:37.439331Z","shell.execute_reply":"2021-06-08T13:03:37.465093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Training the logistic regression model\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\n# -- Prediction\npred = logreg.predict(X_test)\n\n# Checking accuracy of predictions\naccu_ = accuracy_score(y_test, pred)\nprint('Accuracy score for Logistic Regression is: {:.3f}'.format(accu_))\nprint(f\"The ROC_AUC score for Logistic Regression model is {roc_auc_score(y_test, pred)}\")\nprint(f\"The Precision score for Logistic Regression model is {precision_score(y_test, pred)}\")\nprint(f\"The recall score for Logistic Regression model is {recall_score(y_test, pred)}\")\nprint(f\"The f1 score for Logistic Regression model is {f1_score(y_test, pred)}\")\nprint(f\"The Confusion Matrix score for Logistic Regression model is \\n {confusion_matrix(y_test, pred)}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.470184Z","iopub.execute_input":"2021-06-08T13:03:37.470586Z","iopub.status.idle":"2021-06-08T13:03:37.705257Z","shell.execute_reply.started":"2021-06-08T13:03:37.470536Z","shell.execute_reply":"2021-06-08T13:03:37.703706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- ROC curve for Logistic Regression\nplot_roc_curve(logreg, X_test, y_test)\nplt.show","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.707615Z","iopub.execute_input":"2021-06-08T13:03:37.708511Z","iopub.status.idle":"2021-06-08T13:03:37.974389Z","shell.execute_reply.started":"2021-06-08T13:03:37.708452Z","shell.execute_reply":"2021-06-08T13:03:37.973438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Can we use any other classifier for better accuracy and roc_auc values?","metadata":{}},{"cell_type":"markdown","source":"**Here we try**\n* KNeighborsClassifier\n* RandomForestClassifier \n* SVC\n-classification models and see how they fare against Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.976609Z","iopub.execute_input":"2021-06-08T13:03:37.977297Z","iopub.status.idle":"2021-06-08T13:03:37.982765Z","shell.execute_reply.started":"2021-06-08T13:03:37.977247Z","shell.execute_reply":"2021-06-08T13:03:37.981969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_list = [LogisticRegression, KNeighborsClassifier, RandomForestClassifier, SVC]\n\nfor i in model_list:\n    model = i()\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    acc_ = accuracy_score(y_test, pred)\n    roc_auc = roc_auc_score(y_test, pred)\n    print(f\"The accuracy score for {i} model is: {acc_}\")\n    print(f\"The ROC_AUC score for {i} model is: {roc_auc}\")\n    print(f\"The Precision score for {i} model is: {precision_score(y_test, pred)}\")\n    print(f\"The recall score for {i} model is: {recall_score(y_test, pred)}\")\n    print(f\"The f1 score for {i} model is: {f1_score(y_test, pred)}\")\n    print(f\"The Confusion Matrix for {i} model is :\\n {confusion_matrix(y_test, pred)}\")\n    plot_roc_curve(model,X_test,y_test)\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:03:37.984281Z","iopub.execute_input":"2021-06-08T13:03:37.985002Z","iopub.status.idle":"2021-06-08T13:03:43.848218Z","shell.execute_reply.started":"2021-06-08T13:03:37.984953Z","shell.execute_reply":"2021-06-08T13:03:43.846949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}