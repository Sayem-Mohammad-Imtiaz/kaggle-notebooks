{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Point\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.linear_model import LinearRegression,Ridge, Lasso, SGDRegressor, RidgeCV\n\nfrom mpl_toolkits.mplot3d import Axes3D \n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/california-housing-prices/housing.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GEO_X_FEATURE = ['longitude','latitude']\nNUM_X_FEATURE = ['housing_median_age','median_income','ocean_proximity']\nY_FEATURE = 'median_house_value'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geo_x = df[GEO_X_FEATURE]\nnum_x = df[NUM_X_FEATURE]\ny = df[Y_FEATURE]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 0: Visualization\n\ncalifornia_shp = gpd.read_file('../input/california-basemap-shapefile/cnty19_1.shp')\ncalifornia_shp = california_shp.set_crs(epsg=3395, inplace=True, allow_override=True)\ncalifornia_shp = california_shp.to_crs(epsg=4326)\ncalifornia_shp.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geom = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\ngeom_df = gpd.GeoDataFrame(df, geometry=geom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,100))\nax1 = fig.add_subplot(111)\ncalifornia_shp.plot(ax=ax1, alpha=1, color='grey')\ngeom_df.plot(ax=ax1, column='median_house_value',cmap='YlOrRd', markersize=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.median_house_value.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(df.median_house_value, cumulative=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(df.median_house_value, cumulative=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(40,40))\nax1 = fig.add_subplot(221)\nax2 = fig.add_subplot(222)\nax3 = fig.add_subplot(223)\nax4 = fig.add_subplot(224)\n\n# lower 25% house\ncalifornia_shp.plot(ax=ax1, alpha=1, color='grey')\ngeom_df[(geom_df.median_house_value >=0) & (geom_df.median_house_value<=119600)].plot(ax=ax1, column='median_house_value',cmap='YlOrRd', markersize=3)\n\n# 25% - 50% house\ncalifornia_shp.plot(ax=ax2, alpha=1, color='grey')\ngeom_df[(geom_df.median_house_value >119600) & (geom_df.median_house_value<=179700)].plot(ax=ax2, column='median_house_value',cmap='YlOrRd', markersize=3)\n\n# 50% - 75% house\ncalifornia_shp.plot(ax=ax3, alpha=1, color='grey')\ngeom_df[(geom_df.median_house_value >179700) & (geom_df.median_house_value<=264725)].plot(ax=ax3, column='median_house_value',cmap='YlOrRd', markersize=3)\n\n\n# top 25% house\ncalifornia_shp.plot(ax=ax4, alpha=1, color='grey')\ngeom_df[(geom_df.median_house_value >264725) & (geom_df.median_house_value<=500001)].plot(ax=ax4, column='median_house_value',cmap='YlOrRd', markersize=3)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,100))\nax1 = fig.add_subplot(111)\ncalifornia_shp.plot(ax=ax1, alpha=1, color='grey')\ngeom_df.plot(ax=ax1, column='median_income',cmap='YlOrRd', markersize=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['median_income','median_house_value']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# STEP 1: Train Geo feature of X by KNN\n\ngeo_x_train, geo_x_test, y_train, y_test = train_test_split(geo_x, y, test_size=0.2, random_state=42)\n\nklist = np.arange(5,20)\nblist = np.arange(10000,20000,250)\n\ndef train_hyperpara_in_knn_oneinstance(k_value, bin_para, geo_x_train, y_train, geo_x_test, y_test):\n    knnc = KNeighborsClassifier(n_neighbors=k_value)\n    y_train_binned = y_train.apply(lambda x:bin_para*np.floor(x/bin_para))\n    knnc.fit(geo_x_train,y_train_binned)\n    pred = knnc.predict(geo_x_test)\n    return mean_squared_error(pred,y_test)\n\n\n\ndef train_hyperpara_in_knn(k_value_list, bin_para_list, geo_x_train, y_train, geo_x_test, y_test):\n    kb_s_map = {}\n    for k_value in k_value_list:\n        for b_value in bin_para_list:\n            ret = train_hyperpara_in_knn_oneinstance(k_value, b_value, geo_x_train, y_train, geo_x_test, y_test )\n            kb_s_map[(k_value, b_value)] = ret\n    return kb_s_map\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ret = train_hyperpara_in_knn(klist, blist, geo_x_train,y_train, geo_x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_by_res_3d(result_dict):\n    d1, d2 = zip(*result_dict.keys())\n    d3 = list(result_dict.values()) \n    fig = plt.figure() \n    pr = fig.gca(projection='3d') \n    return pr.scatter(d1,d2,d3)\n    \nplot_by_res_3d(ret)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_k(k_v):\n    x_t = []\n    y_t = []\n    for _ in ret.keys():\n        if _[0] == k_v:\n            x_t.append(_[1])\n            y_t.append(ret[_])\n    plt.plot(x_t,y_t)\ndef draw_b(b_v):\n    x_t = []\n    y_t = []\n    for _ in ret.keys():\n        if _[1] == b_v:\n            x_t.append(_[0])\n            y_t.append(ret[_])\n    plt.plot(x_t,y_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_k(8);draw_k(9);draw_k(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_b(13750);draw_b(14000);draw_b(14250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we got the optimal k and b for knn model\nOPT_K = 9\nOPT_B = 14000\nopt_knnc = KNeighborsClassifier(n_neighbors=OPT_K)\ny_binned = y.apply(lambda x:OPT_B*np.floor(x/OPT_B))\nopt_knnc.fit(geo_x,y_binned)\npred_knn = opt_knnc.predict(geo_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# STEP 2: Train (result of knn + num feature of x) by linear regression\n\nnum_x_onehot = pd.get_dummies(num_x)\nmerged_x = pd.concat([num_x_onehot, pd.Series(pred_knn, name=\"knn_pred\")],axis=1)\nnum_x_train, num_x_test, y_train, y_test = train_test_split(merged_x, y, test_size=0.2, random_state=42)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lmlist = [LinearRegression, Ridge, Lasso, RidgeCV]\n\ndef trainLinear_oneinstance(lm):\n    lmc = lm()\n    lmc.fit(num_x_train, y_train)\n    #pred = lmc.predict(num_x_test)\n    return lmc.score(num_x_test, y_test)\n\ndef trainLinear(model_list):\n    m_s_map = {}\n    for m_ in model_list:\n        ret = trainLinear_oneinstance(m_)\n        m_s_map[m_] = ret\n    return m_s_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ret = trainLinear(lmlist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OPT_LM = LinearRegression\nopt_lmc = OPT_LM()\nopt_lmc.fit(merged_x,y)\npred_lm = opt_lmc.predict(merged_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 3: Integrate the models\n\noverall_df = pd.concat([geo_x, num_x, pd.Series(pred_knn, name=\"knn_pred\"), y, pd.Series(pred_lm, name=\"lm_pred\")],axis=1)\noverall_df['RelErr'] = abs(overall_df['median_house_value'] - overall_df['lm_pred']) / overall_df['median_house_value'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overall_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overall_df['RelErr'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What is next?\n\n#Cluster Spatial Points First\n#Then K-NN\n#Then LM\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}