{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Decision Tree and Random Forest (RU, EN)\n\nВ данном ноутбуке я разбираю, как работают DecisionTree и RandomForestClassifier из библиотеки sklearn для обучения классификатора в задаче [Airline Passenger Satisfaction](https://www.kaggle.com/teejmahal20/airline-passenger-satisfaction) и показываю способ нахождения наиболее важных фичей в определении удовлетворённости пассажира авиакомпаниии.\n\nIn this notebook, I'm looking at how DecisionTree and RandomForestClassifier from the sklearn library work to train the classifier in the [Airline Passenger Satisfaction](https://www.kaggle.com/teejmahal20/airline-passenger-satisfaction) problem and show a way to determine the most important features in determining passenger satisfaction with the airline.\n\n**ИТОГОВЫЙ РЕЗУЛЬТАТ (FINAL RESULT): accuracy=0.96, ROC AUC=0.99**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://img2.goodfon.ru/original/1999x1333/8/4c/park-les-derevya-priroda.jpg)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Загрузка данных (Data loading)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"SEED = 15\ntrain = pd.read_csv('../input/airline-passenger-satisfaction/train.csv')\ntest = pd.read_csv('../input/airline-passenger-satisfaction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Импорт необходимыx библиотек (Importing the necessary libraries)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее о работе этих инструментов мозно прочитать, перейдя по этим ссылкам.\n\nYou can read more about how these tools work by clicking on these links.\n\n* [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier)\n* [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split)\n* [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier)\n* [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV)\n* [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html?highlight=labelencoder#sklearn.preprocessing.LabelEncoder)\n* [tree](https://scikit-learn.org/stable/modules/classes.html?highlight=tree#module-sklearn.tree)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Подготовка данных для обучения (Preparing data for training)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Функция для очистки датасета от неопределённых значний ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#clears the dataset of undefined values\ndef clean_dataset(data):\n    assert isinstance(data, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    data.dropna(inplace=True)\n    indices_to_keep = ~data.isin([np.nan, np.inf, -np.inf]).any(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Функции для находения категориальных переменных и их замены","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_cat(data, max_count_unique=5):\n    for name in data.columns:\n        s = ''\n        s += name\n        if type(data[name][0]) == str:\n            s += ' is string, '\n        if data[name].nunique() <= max_count_unique:\n            s += ' few unique'\n        if s != name:\n            print(s, data[name].unique())\n\n#replacing categorical variables\ndef encoding_cat(data, max_count_unique=5, msg=True):\n    for name in data.columns:\n        if type(data[name][0]) == str and data[name].nunique() <= max_count_unique:\n            le = LabelEncoder()\n            le.fit(data[name])\n            data[name] = le.transform(data[name])\n    if msg:\n        print('Encoding done!')\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_dataset(train)\nfind_cat(train)\nencoding_cat(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Делаем финальные штрихи в подготовке данных.\nПодправляем категориальную числовую переменную класса пассажира в соответствии со смыслом. \nУдаляем ненужные строки.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Class = train.Class.replace({0: 3}) \n#Correcting Class variable in accordance with the meaning Eco -> Eco Plus -> Business\ntrain['Arrival Delay in Minutes'].astype('int')\ny = train.satisfaction\nX = train.drop(['Unnamed: 0', 'id', 'satisfaction'], axis=1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разделяем обуающую выборку (Splitting the training selection)\n\n![](https://lh6.googleusercontent.com/uuKkYCYun1Ky6C7_GwEtv0gNdaoHyx0WTXiM8jvGOQqGx75gIRVhx1to7OapyGDbOsmKyAl9Eyi5RC-atbk6AXukkA7UBXA-NutKcAdHaTGDsWSzNGyBaCBMvVu1HLuU1Wm6TxWb)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обучение решающего дерева (Training DecisionTree)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Создаём классификатор и тренируем его (Creating a classifier and training it)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 10, random_state=SEED)\ndecision_tree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Формула подсчёта энтропии (formula for calculating entropy criterion)\n\n![](https://i.stack.imgur.com/r5exj.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Визуализации дерева решений (DecisionTree Visualisation)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw\nimport graphviz  \nfrom sklearn.tree import export_graphviz\n\n# Export our trained model as a .dot file\nwith open(\"tree1.dot\", 'w') as f:\n     f = export_graphviz(decision_tree, out_file=f, max_depth = 4,\n                         impurity = True, feature_names = X_train.columns,\n                         rounded = True, filled= True )\n#Convert .dot to .png to allow display in web notebook\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree.png'])\n# Annotating chart with PIL\nimg = Image.open(\"tree.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Итоговая точность классификатора (final accuracy of the classifier):**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree.score(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обучение случайного леса","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://i.ytimg.com/vi/goPiwckWE9M/maxresdefault.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Попробуем улучшить классификацию и увеличим число деревьев. Каждое дерево независмо друг от друга будет производить классификацию. А после этого деревья (лес) примут общее решение в результате голосования, тем самым, подстраховывая друг друга от ошибок.\n\nLet's try to improve the classification and increase the number of trees. Each tree will classify independently of each other. And after that, the trees (forest) will make a common decision as a result of voting, thereby protecting each other from mistakes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def search_param(model, param, X_train, y_train, X_val, y_val, area=range(1, 11), msg=True, plot=True, seed=None):\n    import matplotlib.pyplot as plt\n    import time\n    score_list = []\n    if msg:\n        print('#     accuracy  time')\n    for i in area:\n        start = time.time()\n        rfc = eval(model + '(' + param + '=' + str(i) + ', random_state=' + str(seed) + ')')\n        rfc.fit(X_train, y_train)\n        s = rfc.score(X_val, y_val)\n        end = time.time()\n        score_list.append(s)\n        if msg:\n            print(\"%-3d %10f  %7f\" % (i, s, end - start))\n    if plot:\n        plt.plot(list(area), score_list)\n    return list(area)[score_list.index(max(score_list))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Производим поиск оптимальных параметров случайного леса (search optimal parameters of a RandomForest)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**n_estimators** \n\nКоличество деревьев в лесу.\n\nThe number of trees in the forest.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"search_param('RandomForestClassifier', 'n_estimators', X_train, y_train, X_val, y_val, area=range(1, 51), seed=SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**max_depth**\n\nМаксимальная глубина дерева. Если нет, то узлы расширяются до тех пор, пока все листья не станут чистыми или пока все листья не будут содержать меньше образцов min_samples_split.\n\nThe maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"search_param('RandomForestClassifier', 'max_depth', X_train, y_train, X_val, y_val, range(1, 25), seed=SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**min_samples_split**\n\nМинимальное количество выборок, необходимых для разделения внутреннего узла:\n* Если int, то рассмотрим min_samples_split как минимальное число.\n* Если float, то min_samples_split-это дробь, а ceil(min_samples_split * n_samples) - минимальное количество выборок для каждого разделения.\n\nThe minimum number of samples required to split an internal node:\n* If int, then consider min_samples_split as the minimum number.\n* If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"search_param('RandomForestClassifier', 'min_samples_split', X_train, y_train, X_val, y_val, range(2, 10), seed=SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**min_samples_leaf**\n\nМинимальное количество примеров, требуемое для нахождения в листовом узле. Точка разделения на любой глубине будет рассматриваться только в том случае, если она оставляет по крайней мере обучающие выборки min_samples_leaf в каждой из левых и правых ветвей.\n* Если int, то считайте min_samples_leaf минимальным числом.\n* Если float, то min_samples_leaf-это дробь, а ceil(min_samples_leaf * n_samples) - минимальное количество выборок для каждого узла.\n\nThe minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches.\n* If int, then consider min_samples_leaf as the minimum number.\n* If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"search_param('RandomForestClassifier', 'min_samples_leaf', X_train, y_train, X_val, y_val, range(1, 10), seed=SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Финальный отбор лучших алгоритмов (final selection of the best algorithms)**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://cf2.ppt-online.org/files2/slide/v/VXgjNpHShCby6zFJdWZeUocmsLTvaltkQERxfOuqP7/slide-12.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"При отборе использется кросс-валидация. Кросс-валидация или скользящий контроль — процедура эмпирического оценивания обобщающей способности алгоритмов. С помощью кросс-валидации эмулируется наличие тестовой выборки, которая не участвует в обучении, но для которой известны правильные ответы.\n\nCross-validation is used for selection. Cross-validation or sliding control is a procedure for empirically evaluating the generalizing ability of algorithms. Cross-validation emulates the presence of a test sample that does not participate in training, but for which the correct answers are known.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(random_state=SEED)\nparam = {'n_estimators': [i for i in range(38, 51)], 'max_depth': [i for i in range(20, 25)]}\ngscv =  GridSearchCV(rfc, param, cv=3, n_jobs=-1, verbose=1)\ngscv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Вывод лучших параметров классификатора (output of the best classifier parameters)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gscv.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Результаты обучения","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Визуализация важности фичей в определении удовлетворённости пассажиров\n\nVisualization of the importance of features in determining passenger satisfaction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_c = gscv.best_estimator_\nimp = pd.DataFrame(best_c.feature_importances_, index=X_train.columns, columns=['importance'])\nimp.sort_values('importance').plot(kind='barh', figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_c.score(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Итоговая проверка алгоритма (final verification of the algorithm)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_dataset(test)\nfind_cat(test)\nencoding_cat(test)\ntest.Class = test.Class.replace({0: 3})\ntest['Arrival Delay in Minutes'].astype('int')\ny_test = test['satisfaction']\nX_test = test.drop(['Unnamed: 0', 'id', 'satisfaction'], axis=1)\nbest_c.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Визуализируем метрику ROC AUC (Visualize the ROC AUC metric)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score , roc_curve\nimport matplotlib.pyplot as plt\ndtc_proba=best_c.predict_proba(X_test)\ndtc_proba=dtc_proba[:,1]\nauc=roc_auc_score(y_test, dtc_proba)\nprint('Random Forest Classifier: ROC AUC=%.3f' % (auc))\nlr_fpr, lr_tpr, _ = roc_curve(y_test, dtc_proba)\nplt.plot(lr_fpr, lr_tpr, marker='.', label='Random Forest Classifier')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf ./sample-out.png ./tree1.dot ./tree.png","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ИТОГОВЫЙ РЕЗУЛЬТАТ(FINAL RESULT): accuracy=0.96, ROC AUC=0.99**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}