{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"The data set describes the sale of individual residential property in Ames, Iowa\nfrom 2006 to 2010. The data set contains 2930 observations and a large number of explanatory\nvariables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous) involved in assessing home\nvalues.\n\nIn this note book we will explore the Ames housing data set. We will focus on:\n1. Removing outliers \n2. Dealing with missing data\n3. Building and assessing the model","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n## Setting max displayed rows to 500, in order to display the full output of any command \npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T18:20:23.06333Z","iopub.execute_input":"2021-05-29T18:20:23.063888Z","iopub.status.idle":"2021-05-29T18:20:23.935682Z","shell.execute_reply.started":"2021-05-29T18:20:23.063847Z","shell.execute_reply":"2021-05-29T18:20:23.934863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the data \ndf = pd.read_csv(\"../input/ames-housing-data/Ames_Housing_Data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T18:20:23.937247Z","iopub.execute_input":"2021-05-29T18:20:23.937805Z","iopub.status.idle":"2021-05-29T18:20:24.030482Z","shell.execute_reply.started":"2021-05-29T18:20:23.937759Z","shell.execute_reply":"2021-05-29T18:20:24.029473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:33:40.497099Z","iopub.execute_input":"2021-05-29T16:33:40.497514Z","iopub.status.idle":"2021-05-29T16:33:40.568438Z","shell.execute_reply.started":"2021-05-29T16:33:40.497478Z","shell.execute_reply":"2021-05-29T16:33:40.567176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:33:45.821476Z","iopub.execute_input":"2021-05-29T16:33:45.821845Z","iopub.status.idle":"2021-05-29T16:33:45.829304Z","shell.execute_reply.started":"2021-05-29T16:33:45.821812Z","shell.execute_reply":"2021-05-29T16:33:45.827892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:07.528999Z","iopub.execute_input":"2021-05-29T16:30:07.529556Z","iopub.status.idle":"2021-05-29T16:30:07.673024Z","shell.execute_reply.started":"2021-05-29T16:30:07.52952Z","shell.execute_reply":"2021-05-29T16:30:07.672113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:07.675056Z","iopub.execute_input":"2021-05-29T16:30:07.675393Z","iopub.status.idle":"2021-05-29T16:30:07.709522Z","shell.execute_reply.started":"2021-05-29T16:30:07.675361Z","shell.execute_reply":"2021-05-29T16:30:07.708425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Checking for outliers\nThe following example shows why outliers are very dangerous. They significantly affect the mean and the standard deviation and thus affecting the estimators of the model.","metadata":{}},{"cell_type":"markdown","source":"|| | Data without outlier |  | Data with outlier | \n|--||--||--|\n|**Data**| |1,2,3,3,4,5,4 |  |1,2,3,3,4,5,**400** | \n|**Mean**| |3.142 | |**59.714** |  \n|**Median**| |3|  |3|\n|**Standard Deviation**| |1.345185| |**150.057**|","metadata":{}},{"cell_type":"markdown","source":"In order to visually see outliers, we need a box plot or a scatter plot. \nTherefore, lets see the most correlated features with sale price to plot them a gainst each others.","metadata":{}},{"cell_type":"code","source":"df.corr()[\"SalePrice\"].sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:07.711461Z","iopub.execute_input":"2021-05-29T16:30:07.711763Z","iopub.status.idle":"2021-05-29T16:30:07.74024Z","shell.execute_reply.started":"2021-05-29T16:30:07.711734Z","shell.execute_reply":"2021-05-29T16:30:07.739102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Overall Qual\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:07.741638Z","iopub.execute_input":"2021-05-29T16:30:07.741989Z","iopub.status.idle":"2021-05-29T16:30:08.019739Z","shell.execute_reply.started":"2021-05-29T16:30:07.741948Z","shell.execute_reply":"2021-05-29T16:30:08.01841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see there are some points with very high quality (10/10) but very low price. Lets explore other highly correlated features with Sale Price","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Gr Liv Area\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.021112Z","iopub.execute_input":"2021-05-29T16:30:08.02145Z","iopub.status.idle":"2021-05-29T16:30:08.215575Z","shell.execute_reply.started":"2021-05-29T16:30:08.021419Z","shell.execute_reply":"2021-05-29T16:30:08.214754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Total Bsmt SF\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.216584Z","iopub.execute_input":"2021-05-29T16:30:08.216981Z","iopub.status.idle":"2021-05-29T16:30:08.414536Z","shell.execute_reply.started":"2021-05-29T16:30:08.216952Z","shell.execute_reply":"2021-05-29T16:30:08.413804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The points that indicate very high price and also very high living area (at the top right corner) are not outliers. They make sense as they are follwing a trend, therefore they will not hurt our model.\n\nOn the other hand The 3 points at the right-lower corner indicate very high living area but very low price. They are very likely to be outliers because they are not following the general trend.\n\n\n\n#### Lets now check those points closely","metadata":{}},{"cell_type":"code","source":"df[(df[\"SalePrice\"] < 200000) & (df[\"Overall Qual\"] > 8)]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.415544Z","iopub.execute_input":"2021-05-29T16:30:08.415944Z","iopub.status.idle":"2021-05-29T16:30:08.482122Z","shell.execute_reply.started":"2021-05-29T16:30:08.415913Z","shell.execute_reply":"2021-05-29T16:30:08.481419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[(df[\"SalePrice\"] < 200000) & (df[\"Overall Qual\"] > 8) & (df[\"Gr Liv Area\"] > 4000)]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.48475Z","iopub.execute_input":"2021-05-29T16:30:08.485273Z","iopub.status.idle":"2021-05-29T16:30:08.556322Z","shell.execute_reply.started":"2021-05-29T16:30:08.48521Z","shell.execute_reply":"2021-05-29T16:30:08.555207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_index = df[(df[\"SalePrice\"] < 200000) & (df[\"Overall Qual\"] > 8) & (df[\"Gr Liv Area\"] > 4000)].index","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.558351Z","iopub.execute_input":"2021-05-29T16:30:08.558689Z","iopub.status.idle":"2021-05-29T16:30:08.572239Z","shell.execute_reply.started":"2021-05-29T16:30:08.558657Z","shell.execute_reply":"2021-05-29T16:30:08.571089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(drop_index, axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.573752Z","iopub.execute_input":"2021-05-29T16:30:08.57421Z","iopub.status.idle":"2021-05-29T16:30:08.590926Z","shell.execute_reply.started":"2021-05-29T16:30:08.574154Z","shell.execute_reply":"2021-05-29T16:30:08.589648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lets now repeat one of the scatter plots that we had before","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Gr Liv Area\", y = \"SalePrice\");","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.592498Z","iopub.execute_input":"2021-05-29T16:30:08.593043Z","iopub.status.idle":"2021-05-29T16:30:08.828399Z","shell.execute_reply.started":"2021-05-29T16:30:08.592978Z","shell.execute_reply":"2021-05-29T16:30:08.827577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Dealing with missing data","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.829553Z","iopub.execute_input":"2021-05-29T16:30:08.830002Z","iopub.status.idle":"2021-05-29T16:30:08.901603Z","shell.execute_reply.started":"2021-05-29T16:30:08.82997Z","shell.execute_reply":"2021-05-29T16:30:08.900763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PID is just an identifier, it has no numeric value for the model. Set it as index, or drop it. Dropping it will not make any problems, because we have the default identifier (0, 1, 2, 3, ... ) ","metadata":{}},{"cell_type":"code","source":"df = df.drop(\"PID\", axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.902716Z","iopub.execute_input":"2021-05-29T16:30:08.903199Z","iopub.status.idle":"2021-05-29T16:30:08.914499Z","shell.execute_reply.started":"2021-05-29T16:30:08.903149Z","shell.execute_reply":"2021-05-29T16:30:08.913662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.915704Z","iopub.execute_input":"2021-05-29T16:30:08.916158Z","iopub.status.idle":"2021-05-29T16:30:08.957173Z","shell.execute_reply.started":"2021-05-29T16:30:08.916115Z","shell.execute_reply":"2021-05-29T16:30:08.956041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## lets create a functions that can be used for any future data\ndef percent_missing_data(df):\n    missing_count = df.isna().sum().sort_values(ascending = False)\n    missing_percent = 100 * df.isna().sum().sort_values(ascending = False) / len(df)\n    missing_count = pd.DataFrame(missing_count[missing_count > 0])\n    missing_percent = pd.DataFrame(missing_percent[missing_percent > 0])\n    missing_table = pd.concat([missing_count,missing_percent], axis = 1)\n    missing_table.columns = [\"missing_count\", \"missing_percent\"]\n    \n    return missing_table","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.958779Z","iopub.execute_input":"2021-05-29T16:30:08.959219Z","iopub.status.idle":"2021-05-29T16:30:08.969501Z","shell.execute_reply.started":"2021-05-29T16:30:08.95917Z","shell.execute_reply":"2021-05-29T16:30:08.968108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:08.972971Z","iopub.execute_input":"2021-05-29T16:30:08.973329Z","iopub.status.idle":"2021-05-29T16:30:09.023885Z","shell.execute_reply.started":"2021-05-29T16:30:08.973295Z","shell.execute_reply":"2021-05-29T16:30:09.022565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:09.025507Z","iopub.execute_input":"2021-05-29T16:30:09.025917Z","iopub.status.idle":"2021-05-29T16:30:09.648254Z","shell.execute_reply.started":"2021-05-29T16:30:09.025872Z","shell.execute_reply":"2021-05-29T16:30:09.647219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In principle we should go through each feature and decide whether we will keep it, fill it or drop it. When we speak about dropping we can drop columns or rows.\n\nFor example Pool QC values are missing for 99.6 percent of houses. This might be due to:\n1. These houses have no pools, and instead of nan it should have been zero.\n2. These houses have pools, but the data is actually missing.\n\nWe should go back to the description file and try to understand it better. But now, lets deal with columns with very few missing values.","metadata":{}},{"cell_type":"code","source":"## lets see the features that has less than on percent missing\nplt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.ylim(0,1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:09.649553Z","iopub.execute_input":"2021-05-29T16:30:09.649886Z","iopub.status.idle":"2021-05-29T16:30:10.021431Z","shell.execute_reply.started":"2021-05-29T16:30:09.649855Z","shell.execute_reply":"2021-05-29T16:30:10.020306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"lets now look at these rows, there might be houses with missing values across all features","metadata":{}},{"cell_type":"code","source":"percent_nan[percent_nan[\"missing_percent\"] < 1]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.022738Z","iopub.execute_input":"2021-05-29T16:30:10.023045Z","iopub.status.idle":"2021-05-29T16:30:10.033924Z","shell.execute_reply.started":"2021-05-29T16:30:10.023015Z","shell.execute_reply":"2021-05-29T16:30:10.033137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = percent_nan[percent_nan[\"missing_percent\"] < 1].index\nfor name in index:\n    print(df[df[\"BsmtFin SF 2\"].isnull()][name])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.034884Z","iopub.execute_input":"2021-05-29T16:30:10.035158Z","iopub.status.idle":"2021-05-29T16:30:10.067657Z","shell.execute_reply.started":"2021-05-29T16:30:10.03513Z","shell.execute_reply":"2021-05-29T16:30:10.066316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"Garage Cars\"].isnull()][\"Garage Area\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.069014Z","iopub.execute_input":"2021-05-29T16:30:10.06935Z","iopub.status.idle":"2021-05-29T16:30:10.078623Z","shell.execute_reply.started":"2021-05-29T16:30:10.069317Z","shell.execute_reply":"2021-05-29T16:30:10.077463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(axis = 0, subset = [\"Garage Cars\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.079863Z","iopub.execute_input":"2021-05-29T16:30:10.080174Z","iopub.status.idle":"2021-05-29T16:30:10.095013Z","shell.execute_reply.started":"2021-05-29T16:30:10.080143Z","shell.execute_reply":"2021-05-29T16:30:10.093697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.097229Z","iopub.execute_input":"2021-05-29T16:30:10.097734Z","iopub.status.idle":"2021-05-29T16:30:10.145327Z","shell.execute_reply.started":"2021-05-29T16:30:10.097685Z","shell.execute_reply":"2021-05-29T16:30:10.144176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"BsmtFin SF 1\"].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.146852Z","iopub.execute_input":"2021-05-29T16:30:10.147306Z","iopub.status.idle":"2021-05-29T16:30:10.20315Z","shell.execute_reply.started":"2021-05-29T16:30:10.147241Z","shell.execute_reply":"2021-05-29T16:30:10.202091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that all features related Basement have very high number of missing values. If we go back to data description you will find that Nan actually means that the house do not has a basement. It is not missing, it just has one. Therefore, it does make sense to replace nan values with a string saying that the house has no Basement. This will work for Basement string columns, as for Basement numeric columns we will replace them with zero.","metadata":{}},{"cell_type":"code","source":"## basement numeric features ==> fillna 0\nbsmt_num_cols = ['BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF','Total Bsmt SF', 'Bsmt Full Bath', 'Bsmt Half Bath']\ndf[bsmt_num_cols] = df[bsmt_num_cols].fillna(0)\n\n## basement string features ==> fillna none\nbsmt_str_cols =  ['Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2']\ndf[bsmt_str_cols] = df[bsmt_str_cols].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.204141Z","iopub.execute_input":"2021-05-29T16:30:10.204451Z","iopub.status.idle":"2021-05-29T16:30:10.217122Z","shell.execute_reply.started":"2021-05-29T16:30:10.204421Z","shell.execute_reply":"2021-05-29T16:30:10.215946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now if you check again, you will find no nulls\ndf[df[\"BsmtFin SF 1\"].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.224122Z","iopub.execute_input":"2021-05-29T16:30:10.224504Z","iopub.status.idle":"2021-05-29T16:30:10.255742Z","shell.execute_reply.started":"2021-05-29T16:30:10.22447Z","shell.execute_reply":"2021-05-29T16:30:10.254521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.258881Z","iopub.execute_input":"2021-05-29T16:30:10.259332Z","iopub.status.idle":"2021-05-29T16:30:10.300678Z","shell.execute_reply.started":"2021-05-29T16:30:10.259295Z","shell.execute_reply":"2021-05-29T16:30:10.299809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Electrical still has 1 missing value, lets look at it closely and decide","metadata":{}},{"cell_type":"code","source":"df[df[\"Electrical\"].isnull()]","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.301949Z","iopub.execute_input":"2021-05-29T16:30:10.302234Z","iopub.status.idle":"2021-05-29T16:30:10.355428Z","shell.execute_reply.started":"2021-05-29T16:30:10.302208Z","shell.execute_reply":"2021-05-29T16:30:10.354609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You have the choice of filling it with the mode or dropping it, I will drop it\ndf = df.dropna(axis = 0, subset = [\"Electrical\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.356469Z","iopub.execute_input":"2021-05-29T16:30:10.356892Z","iopub.status.idle":"2021-05-29T16:30:10.371771Z","shell.execute_reply.started":"2021-05-29T16:30:10.356863Z","shell.execute_reply":"2021-05-29T16:30:10.370992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.372907Z","iopub.execute_input":"2021-05-29T16:30:10.373401Z","iopub.status.idle":"2021-05-29T16:30:10.421567Z","shell.execute_reply.started":"2021-05-29T16:30:10.373365Z","shell.execute_reply":"2021-05-29T16:30:10.420525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both \"Mas Vnr Area\" and \"Mas Vnr Type\" have less than 1 percent of null values. How to deal with them? \n\nGoing back to data description, we found that there is a category for none: It does not have \"Mas Vnr\". We can assume that those missing values are also none but they are mistakenly filled with Nan.","metadata":{}},{"cell_type":"code","source":"df[[\"Mas Vnr Area\"]] = df[[\"Mas Vnr Area\"]].fillna(0)\ndf[[\"Mas Vnr Type\"]] = df[[\"Mas Vnr Type\"]].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T18:20:30.851515Z","iopub.execute_input":"2021-05-29T18:20:30.85188Z","iopub.status.idle":"2021-05-29T18:20:30.871856Z","shell.execute_reply.started":"2021-05-29T18:20:30.851849Z","shell.execute_reply":"2021-05-29T18:20:30.87064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.432534Z","iopub.execute_input":"2021-05-29T16:30:10.432814Z","iopub.status.idle":"2021-05-29T16:30:10.477908Z","shell.execute_reply.started":"2021-05-29T16:30:10.432787Z","shell.execute_reply":"2021-05-29T16:30:10.477004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### What to do with the rest?\nThe rest of the features have more than 1% missing data. We need to carefully look at each one and decide how to deal with them. For sure, dropping rows is not a possible strategy any more. so we need to figure out something else. We have two options:\n1. Fill in missing values\n2. Drop thr feature column","metadata":{}},{"cell_type":"markdown","source":"As for all garage features, going back to data description we found that Nan means that there is no garage. Therefore, it is resonable to fill it with zero for numeric features and \"none\" for text features. ","metadata":{}},{"cell_type":"code","source":"gar_str_cols = ['Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond']\ndf[gar_str_cols] = df[gar_str_cols].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.479026Z","iopub.execute_input":"2021-05-29T16:30:10.479315Z","iopub.status.idle":"2021-05-29T16:30:10.488202Z","shell.execute_reply.started":"2021-05-29T16:30:10.479288Z","shell.execute_reply":"2021-05-29T16:30:10.487045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Garage Yr Blt'] = df['Garage Yr Blt'].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.489568Z","iopub.execute_input":"2021-05-29T16:30:10.489885Z","iopub.status.idle":"2021-05-29T16:30:10.501936Z","shell.execute_reply.started":"2021-05-29T16:30:10.489854Z","shell.execute_reply":"2021-05-29T16:30:10.500775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.503193Z","iopub.execute_input":"2021-05-29T16:30:10.503728Z","iopub.status.idle":"2021-05-29T16:30:10.547922Z","shell.execute_reply.started":"2021-05-29T16:30:10.503692Z","shell.execute_reply":"2021-05-29T16:30:10.546849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.549004Z","iopub.execute_input":"2021-05-29T16:30:10.549306Z","iopub.status.idle":"2021-05-29T16:30:10.712507Z","shell.execute_reply.started":"2021-05-29T16:30:10.549278Z","shell.execute_reply":"2021-05-29T16:30:10.711527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some of the above features have more than 99 percent missing data, dropping these features can be the best strategy to opt for.","metadata":{}},{"cell_type":"code","source":"df = df.drop([\"Pool QC\", \"Misc Feature\", \"Alley\", \"Fence\"], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.71373Z","iopub.execute_input":"2021-05-29T16:30:10.71402Z","iopub.status.idle":"2021-05-29T16:30:10.724225Z","shell.execute_reply.started":"2021-05-29T16:30:10.713991Z","shell.execute_reply":"2021-05-29T16:30:10.7231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.725685Z","iopub.execute_input":"2021-05-29T16:30:10.726141Z","iopub.status.idle":"2021-05-29T16:30:10.774889Z","shell.execute_reply.started":"2021-05-29T16:30:10.726092Z","shell.execute_reply":"2021-05-29T16:30:10.773862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.776423Z","iopub.execute_input":"2021-05-29T16:30:10.776751Z","iopub.status.idle":"2021-05-29T16:30:10.905937Z","shell.execute_reply.started":"2021-05-29T16:30:10.776718Z","shell.execute_reply":"2021-05-29T16:30:10.904785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are left with just to columns. You have to be carefull and do a lot of thinking because you can not just drop the rows nor the feature columns. Not enough to drop the feature but not too little to drop the rows.","metadata":{}},{"cell_type":"code","source":"df[\"Fireplace Qu\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.907264Z","iopub.execute_input":"2021-05-29T16:30:10.907583Z","iopub.status.idle":"2021-05-29T16:30:10.917754Z","shell.execute_reply.started":"2021-05-29T16:30:10.907554Z","shell.execute_reply":"2021-05-29T16:30:10.91637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since it is a categorical variable we can fill missing data with \"None\"","metadata":{}},{"cell_type":"code","source":"df[\"Fireplace Qu\"] = df[\"Fireplace Qu\"].fillna(\"None\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.919605Z","iopub.execute_input":"2021-05-29T16:30:10.920179Z","iopub.status.idle":"2021-05-29T16:30:10.929028Z","shell.execute_reply.started":"2021-05-29T16:30:10.920131Z","shell.execute_reply":"2021-05-29T16:30:10.927812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.930733Z","iopub.execute_input":"2021-05-29T16:30:10.931281Z","iopub.status.idle":"2021-05-29T16:30:10.972762Z","shell.execute_reply.started":"2021-05-29T16:30:10.931165Z","shell.execute_reply":"2021-05-29T16:30:10.97157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Lot Frontage\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.97395Z","iopub.execute_input":"2021-05-29T16:30:10.97423Z","iopub.status.idle":"2021-05-29T16:30:10.991317Z","shell.execute_reply.started":"2021-05-29T16:30:10.974203Z","shell.execute_reply":"2021-05-29T16:30:10.990569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is tricky, it is numeric. I can not longer go back to the description and fill it with a convenient text. \nWe will use the Neighborhood feature calculate the missing feature.\n\nNeighborhood: Physical locations within Ames city limits\n\nLotFrontage: Linear feet of street connected to property\n\nWe will operate under the assumption that the Lot Frontage is related to what neighborhood a house is in.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.boxplot(x = \"Neighborhood\", y = \"Lot Frontage\", data = df)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:10.992592Z","iopub.execute_input":"2021-05-29T16:30:10.992869Z","iopub.status.idle":"2021-05-29T16:30:11.63615Z","shell.execute_reply.started":"2021-05-29T16:30:10.992842Z","shell.execute_reply":"2021-05-29T16:30:11.635022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see each category is unique enough to make the assumption that we can impute the LotFrontage based on Neighborhood categories. ","metadata":{}},{"cell_type":"code","source":"df.groupby(\"Neighborhood\")[\"Lot Frontage\"].mean()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:11.637985Z","iopub.execute_input":"2021-05-29T16:30:11.638446Z","iopub.status.idle":"2021-05-29T16:30:11.649417Z","shell.execute_reply.started":"2021-05-29T16:30:11.638397Z","shell.execute_reply":"2021-05-29T16:30:11.648343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To achieve the intended result, we will use pandas transform method. I calls group by and fill in missing vsalues based on it. ","metadata":{}},{"cell_type":"code","source":"df[\"Lot Frontage\"] = df.groupby(\"Neighborhood\")[\"Lot Frontage\"].transform(lambda value: value.fillna(value.mean()))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:11.65132Z","iopub.execute_input":"2021-05-29T16:30:11.651919Z","iopub.status.idle":"2021-05-29T16:30:11.677236Z","shell.execute_reply.started":"2021-05-29T16:30:11.651882Z","shell.execute_reply":"2021-05-29T16:30:11.676119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:11.678843Z","iopub.execute_input":"2021-05-29T16:30:11.679196Z","iopub.status.idle":"2021-05-29T16:30:11.717818Z","shell.execute_reply.started":"2021-05-29T16:30:11.679151Z","shell.execute_reply":"2021-05-29T16:30:11.716737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Lot Frontage\"] = df[\"Lot Frontage\"].fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:11.719122Z","iopub.execute_input":"2021-05-29T16:30:11.719487Z","iopub.status.idle":"2021-05-29T16:30:11.726339Z","shell.execute_reply.started":"2021-05-29T16:30:11.719452Z","shell.execute_reply":"2021-05-29T16:30:11.725283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_nan = percent_missing_data(df)\npercent_nan","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:11.727788Z","iopub.execute_input":"2021-05-29T16:30:11.728137Z","iopub.status.idle":"2021-05-29T16:30:11.771428Z","shell.execute_reply.started":"2021-05-29T16:30:11.728104Z","shell.execute_reply":"2021-05-29T16:30:11.769427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Yeah! Congratulations! we did it. Nothing is missing any more!**\n \n","metadata":{}}]}