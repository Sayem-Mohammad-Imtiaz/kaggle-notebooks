{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Concrete Compressive Strength Prediction Notebook\n\nThis notebook is for training and predicting Concrete Compressive Strength. The training was done on a 80-20 train-test split using XGBoost.","metadata":{}},{"cell_type":"markdown","source":"1. Importing all the necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score\n\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\n\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:56.450424Z","iopub.execute_input":"2021-06-21T21:53:56.450708Z","iopub.status.idle":"2021-06-21T21:53:57.804047Z","shell.execute_reply.started":"2021-06-21T21:53:56.450684Z","shell.execute_reply":"2021-06-21T21:53:57.802527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Read the dataset localed in the kaggle datastore","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        file = os.path.join(dirname, filename)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:57.805728Z","iopub.execute_input":"2021-06-21T21:53:57.805991Z","iopub.status.idle":"2021-06-21T21:53:57.822478Z","shell.execute_reply.started":"2021-06-21T21:53:57.80596Z","shell.execute_reply":"2021-06-21T21:53:57.821396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading the dataset using pandas and printing the head values\n\ndata = pd.read_csv(file)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:57.824175Z","iopub.execute_input":"2021-06-21T21:53:57.82448Z","iopub.status.idle":"2021-06-21T21:53:57.871133Z","shell.execute_reply.started":"2021-06-21T21:53:57.824451Z","shell.execute_reply":"2021-06-21T21:53:57.870268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Describe and understand the data. The task her is to identify missing informations or any missing data.","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:57.872258Z","iopub.execute_input":"2021-06-21T21:53:57.872496Z","iopub.status.idle":"2021-06-21T21:53:57.893092Z","shell.execute_reply.started":"2021-06-21T21:53:57.872473Z","shell.execute_reply":"2021-06-21T21:53:57.891685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data seems to be pretty accurate in terms of the rows.","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:57.894857Z","iopub.execute_input":"2021-06-21T21:53:57.895157Z","iopub.status.idle":"2021-06-21T21:53:57.944696Z","shell.execute_reply.started":"2021-06-21T21:53:57.895131Z","shell.execute_reply":"2021-06-21T21:53:57.943291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum() ## checking for null data","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:57.946138Z","iopub.execute_input":"2021-06-21T21:53:57.946364Z","iopub.status.idle":"2021-06-21T21:53:57.956028Z","shell.execute_reply.started":"2021-06-21T21:53:57.946341Z","shell.execute_reply":"2021-06-21T21:53:57.954826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is pretty clean with no NULL records. So no need to do a lot of cleanup","metadata":{}},{"cell_type":"markdown","source":"Now plotting the data and understanding the correlation between the attributes of the data.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\nheatmap = sns.heatmap(data.corr(), annot=True, vmin=-1, vmax=1)\nheatmap.set_title('Correlation heatmap', pad=10, fontdict={'fontsize':12})\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:57.957058Z","iopub.execute_input":"2021-06-21T21:53:57.957371Z","iopub.status.idle":"2021-06-21T21:53:58.537426Z","shell.execute_reply.started":"2021-06-21T21:53:57.957339Z","shell.execute_reply":"2021-06-21T21:53:58.536031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The darker area of the correlation map shows higher corelation between the attributes.","metadata":{}},{"cell_type":"markdown","source":"4. Splitting and Preparing the Dataset for training","metadata":{}},{"cell_type":"markdown","source":"We need to predict \"Stength\" of the concrete. Hence the prediction value becomes \"Strength\" which we are assigned to variable \"y\". Rest of the feature columns are assigned to \"X\"","metadata":{}},{"cell_type":"code","source":"X = data[data.columns[data.columns!='Strength']].values \ny = data['Strength']","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:58.541176Z","iopub.execute_input":"2021-06-21T21:53:58.541417Z","iopub.status.idle":"2021-06-21T21:53:58.547619Z","shell.execute_reply.started":"2021-06-21T21:53:58.541394Z","shell.execute_reply":"2021-06-21T21:53:58.546732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to maintain the scaling between the attributes, normalizing the dataset is important","metadata":{}},{"cell_type":"code","source":"# normalize the dataset\nprint(f'X mean: {X.mean()}')\nprint(f'X std: {X.std()}')\n\nX_normalized = (X - X.mean())/X.std()\nX_normalized","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:58.548961Z","iopub.execute_input":"2021-06-21T21:53:58.549288Z","iopub.status.idle":"2021-06-21T21:53:58.571227Z","shell.execute_reply.started":"2021-06-21T21:53:58.549256Z","shell.execute_reply":"2021-06-21T21:53:58.569786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X_normalized, y, \n                                                    test_size = 0.2, \n                                                    shuffle=True, \n                                                    random_state=128)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:58.572736Z","iopub.execute_input":"2021-06-21T21:53:58.573157Z","iopub.status.idle":"2021-06-21T21:53:58.58054Z","shell.execute_reply.started":"2021-06-21T21:53:58.573131Z","shell.execute_reply":"2021-06-21T21:53:58.579147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Train shape: X = {X_train.shape} ; y={y_train.shape}')\nprint(f'Test shape: X = {X_test.shape} ; y={y_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:58.58147Z","iopub.execute_input":"2021-06-21T21:53:58.581695Z","iopub.status.idle":"2021-06-21T21:53:58.601508Z","shell.execute_reply.started":"2021-06-21T21:53:58.581673Z","shell.execute_reply":"2021-06-21T21:53:58.600507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Training the data using XGBoost","metadata":{}},{"cell_type":"markdown","source":"We will be using Grid Search to find the best model across multiple parameters selection.","metadata":{}},{"cell_type":"code","source":"#Prepare and train the model\n\nmodel = XGBRegressor(n_jobs=4)\n\n## grid search to find the best model parameter\n\nparam_grid = {\n        'n_estimators': [50, 100, 500],\n        'max_depth': [2, 4, 6, 8, 10],\n        'gamma': [0.001, 0.01],\n        'learning_rate': [0.01, 0.1, 0.3],\n        'booster': ['gbtree']\n    }\n\ngrid_search_model = GridSearchCV(model, param_grid=param_grid, cv=5, return_train_score=True)\n\ngrid_search_model.fit(X_train, y_train)\n\nprint(f'Best Score: {grid_search_model.best_score_}')\nprint(f'Best Param: {grid_search_model.best_params_}')","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:53:58.602441Z","iopub.execute_input":"2021-06-21T21:53:58.602828Z","iopub.status.idle":"2021-06-21T21:55:40.074602Z","shell.execute_reply.started":"2021-06-21T21:53:58.60277Z","shell.execute_reply":"2021-06-21T21:55:40.073279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## fitting the best model\n\nbest_model = grid_search_model.best_estimator_\n\nbest_model.fit(X_train, y_train)\n\nprint(f'Train Score: {best_model.score(X_train, y_train)}')\nprint(f'Test Score: {best_model.score(X_test, y_test)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:55:40.075757Z","iopub.execute_input":"2021-06-21T21:55:40.076038Z","iopub.status.idle":"2021-06-21T21:55:40.417695Z","shell.execute_reply.started":"2021-06-21T21:55:40.076011Z","shell.execute_reply":"2021-06-21T21:55:40.416573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = best_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:55:40.420816Z","iopub.execute_input":"2021-06-21T21:55:40.421076Z","iopub.status.idle":"2021-06-21T21:55:40.427806Z","shell.execute_reply.started":"2021-06-21T21:55:40.421049Z","shell.execute_reply":"2021-06-21T21:55:40.426972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Mean Absolute Error (MAE): {mae(y_test, prediction)}')\nprint(f'Mean Squared Error (MSE): {mse(y_test, prediction)}')\nprint(f'RMSE: {mse(y_test, prediction)**(1/2)}')\nprint(f'R2 Score: {r2_score(y_test, prediction)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:55:40.429077Z","iopub.execute_input":"2021-06-21T21:55:40.429315Z","iopub.status.idle":"2021-06-21T21:55:40.443771Z","shell.execute_reply.started":"2021-06-21T21:55:40.429289Z","shell.execute_reply":"2021-06-21T21:55:40.442487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the feature importance plot","metadata":{}},{"cell_type":"code","source":"xgb.plot_importance(best_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:55:40.445769Z","iopub.execute_input":"2021-06-21T21:55:40.446289Z","iopub.status.idle":"2021-06-21T21:55:40.776561Z","shell.execute_reply.started":"2021-06-21T21:55:40.446213Z","shell.execute_reply":"2021-06-21T21:55:40.775671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Plotting the Concrete Strength Prediction Graph based on the original and predicted data","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,6))\n\nx_ax = range(len(y_test))\nplt.plot(x_ax, y_test, label=\"original\")\nplt.plot(x_ax, prediction, label=\"predicted\")\nplt.title(\"Concrete Strength prediction graph\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-21T21:55:40.77799Z","iopub.execute_input":"2021-06-21T21:55:40.778251Z","iopub.status.idle":"2021-06-21T21:55:41.006445Z","shell.execute_reply.started":"2021-06-21T21:55:40.778225Z","shell.execute_reply":"2021-06-21T21:55:41.004991Z"},"trusted":true},"execution_count":null,"outputs":[]}]}