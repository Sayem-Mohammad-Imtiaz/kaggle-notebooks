{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nfrom sklearn.neighbors import NearestCentroid\nimport numpy as np\nX = np.array([[-1, -0.5], [-2, -1], [-3, -2], [1, 0.5], [1, 1], [2, 1], [3, 2], [0, -1]])\ny = np.array([1, 1, 1, 1, 2, 2, 2, 2])\n\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='rainbow');\nclf = NearestCentroid()\n\n\nclf.fit(X, y)\nNearestCentroid()\nprint(clf.predict([[2, 1]]))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nX_train = np.array([[-1, -0.5], [-2, -1], [-3, -2], [1, 0.5], [1, 1], [2, 1], [3, 2], [0, -1]])\ny_train = np.array([1, 1, 1, 1, 2, 2, 2, 2])\n\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='rainbow');\n\n\nknn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\nknn.fit(X_train, y_train)\n\n\ny_pred = knn.predict([[-0.5, -1]])\n\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nX_train = np.array([[-1, -0.5], [-2, -1], [-3, -2], [1, 0.5], [1, 1], [2, 1], [3, 2], [0, -1]])\ny_train = np.array([1, 1, 1, 1, 2, 2, 2, 2])\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='rainbow');\nknn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\nknn.fit(X_train, y_train)\nsingle_point = np.array([[-0.5,1]])\ny_pred = knn.predict(single_point)\nprint(y_pred)\ndist = (X_train - single_point)**2\ndist = np.sum(dist, axis=1)\ndist = np.sqrt(dist)\nprint(dist)\n\ndist_1 = ((-0.5-(-1.0))*(-0.5-(-1.0))) + ((1-(-0.5))*(1-(-0.5))) \nprint(dist_1)\nprint(np.sqrt(dist_1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# AB_NYC_2019.csv has 48895 rows in reality, but we are only loading/previewing the first 1000 rows\n\ndf = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'AB_NYC_2019'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# AB_NYC_2019.csv has 48895 rows in reality, but we are only loading/previewing the first 1000 rows\n\ndf = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'AB_NYC_2019'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndisplay(df.head(10))\n\ndf2 = df[['price','number_of_reviews','room_type']]\n\ndf2_ar = pd.DataFrame(df2).to_numpy()\n\ndisplay(df2)\nprint(df2_ar)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# AB_NYC_2019.csv has 48895 rows in reality, but we are only loading/previewing the first 1000 rows\n\ndf = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'AB_NYC_2019'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndisplay(df.head(10))\n\ndf2 = df[['price','number_of_reviews','room_type']]\n\ndf2_ar = pd.DataFrame(df2).to_numpy()\n\ndisplay(df2)\nprint(df2_ar)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# AB_NYC_2019.csv has 48895 rows in reality, but we are only loading/previewing the first 1000 rows\n\ndf = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'AB_NYC_2019'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\n# display(df.head(10))\n\ndf2 = df[['price','number_of_reviews','room_type']]\n\ndf2_ar = pd.DataFrame(df2).to_numpy()\n\ndisplay(df2)\nprint(df2_ar)\n\nX = df2_ar[:,0:1]\ny = df2_ar[:,2]\n\nprint(X)\nprint(y)\n\n# plt.scatter(X[:, 0], X[:, 1], c=y, cmap='rainbow');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# AB_NYC_2019.csv has 48895 rows in reality, but we are only loading/previewing the first 1000 rows\n\ndf = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'AB_NYC_2019'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\n# display(df.head(10))\n\ndf2 = df[['price','number_of_reviews','room_type']]\n\ndf2_ar = pd.DataFrame(df2).to_numpy()\n\n# display(df2)\n# print(df2_ar)\n\nX = df2_ar[:,0:2]\ny = df2_ar[:,2]\n\n# print(X[:,:])\n# print(y)\n\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nle.fit([\"Private room\", \"Entire home/apt\", \"Shared room\"])\n# LabelEncoder()\nlist(le.classes_)\n\ny1 = le.transform(y)\n\nplt.scatter(X[:, 0], X[:, 1], c=y1, cmap='rainbow');\n# plt.scatter(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# AB_NYC_2019.csv has 48895 rows in reality, but we are only loading/previewing the first 1000 rows\n\ndf = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'AB_NYC_2019'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\n# display(df.head(10))\n\ndf2 = df[['price','number_of_reviews','room_type']]\n\ndf2_ar = pd.DataFrame(df2).to_numpy()\n\n# display(df2)\n# print(df2_ar)\n\nX = df2_ar[:,0:2]\ny = df2_ar[:,2]\n\n# print(X[:,:])\n# print(y)\n\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nle.fit([\"Private room\", \"Entire home/apt\", \"Shared room\"])\n# LabelEncoder()\nprint(list(le.classes_))\n\ny1 = le.transform(y)\n\nplt.xlim([0, 500]) \nplt.scatter(X[:, 0], X[:, 1], c=y1, cmap='rainbow');\n\n\nknn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\nknn.fit(X, y1)\nsingle_point = np.array([[50,180]])\ny_pred = knn.predict(single_point)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# AB_NYC_2019.csv has 48895 rows in reality, but we are only loading/previewing the first 1000 rows\n\ndf = pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'AB_NYC_2019'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\n# display(df.head(10))\n\ndf2 = df[['price','number_of_reviews','room_type']]\n\ndf2_ar = pd.DataFrame(df2).to_numpy()\n\n# display(df2)\n# print(df2_ar)\n\nX = df2_ar[:,0:2]\ny = df2_ar[:,2]\n\n# print(X[:,:])\n# print(y)\n\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nle.fit([\"Private room\", \"Entire home/apt\", \"Shared room\"])\n# LabelEncoder()\nprint(list(le.classes_))\n\ny1 = le.transform(y)\n\nplt.xlim([0, 500]) \nplt.scatter(X[:, 0], X[:, 1], c=y1, cmap='rainbow');\n\n\nknn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\nknn.fit(X, y1)\nsingle_point = np\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}