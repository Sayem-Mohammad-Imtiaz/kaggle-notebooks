{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import and Read the Raw Data\n## Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport math\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import and Read the Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 5)\npd.set_option('display.max_colwidth', -1)\n\nantam = pd.read_csv('../input/antam-stock-market-by-kitto/ANTM.JK.csv', parse_dates=True)\nantam['Date'] = pd.to_datetime(antam['Date'])\nantam.index = antam['Date']\n\nantam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Info and Description"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\n\nantam_desc = pd.DataFrame()\nantam_desc['isna'] = antam.isna().sum()\nantam_desc['isnull'] = antam.isnull().sum()\nantam_desc['nunique'] = antam.nunique()\n\nprint(antam.info(verbose=True), '\\n','-'*80,'\\n','-'*80,'\\n', antam_desc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill NaN value"},{"metadata":{"trusted":true},"cell_type":"code","source":"antam['Open'] = antam['Open'].interpolate()\nantam['Close'] = antam['Close'].interpolate()\nantam['High'] = antam['High'].interpolate()\nantam['Low'] = antam['Low'].interpolate()\nantam['Adj Close'] = antam['Adj Close'].interpolate()\nantam['Volume'] = antam['Volume'].interpolate()\n\nantam.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"antam.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 5))\n\nax.plot(antam['Date'], antam['Close'])\nax.set_title('Close Prices of ANTM.JK', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM\nfrom tensorflow.python.keras.layers import CuDNNLSTM\nfrom tensorflow.keras.models import Sequential\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split Data into Train and Test Sets"},{"metadata":{},"cell_type":"markdown","source":"Let's say because of pandemic, the data should only contain on when pandemic started until today. A 11 months from pandemic started is train set, on 30 January 2020, declared the outbreak of COVID-19 to be a Public Health Emergency of International Concern. A month later until end of the data as the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"antam[\"Close\"]['2020-01-30':'2021'].plot(figsize=(10,5),legend=True)\nantam[\"Close\"]['2021':].plot(figsize=(10,5),legend=True)\nplt.legend(['Training set','Test set'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = antam.Close[(antam.index > '2020-01-30') & (antam.index < '2021-01-01')].values.reshape(-1, 1)\nall_set = antam.Close[antam.index > '2020-01-30'].values.reshape(-1, 1)\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled_all = scaler.fit_transform(all_set)\nscaled_train = scaler.transform(train_set)\n\nprint(\"Train shape = {}\".format(scaled_train.shape))\nprint(\"All shape = {}\".format(scaled_all.shape))\n\nwindow_size = 10    # Window size = number of previous values to predict the next value\n\ndef generateSequence(sequence, backward):\n    x_train, y_train = list(), list()\n    for i in range(sequence.shape[0]-backward):\n        seq_x, seq_y = sequence[i:i+backward], sequence[i+backward]\n        x_train.append(seq_x)\n        y_train.append(seq_y)\n    x_train = np.array(x_train)\n    y_train = np.array(y_train)\n    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n    return x_train, y_train\n    \nx_train, y_train = generateSequence(scaled_train, window_size)\nprint(\"x shape = {}\".format(x_train.shape))\nprint(\"y shape = {}\".format(y_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm = Sequential()\nmodel_lstm.add(LSTM(units=50, return_sequences=True, activation='relu', input_shape=(x_train.shape[1], 1)))\nmodel_lstm.add(LSTM(units=50))\nmodel_lstm.add(Dense(1))\n\nmodel_lstm.compile(loss='mean_squared_error', optimizer='adam')\nepoch_history = model_lstm.fit(x_train, y_train, epochs=100, batch_size=36, verbose=2, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = model_lstm.evaluate(x_train, y_train)\nprint('Train Score: %.6f MSE (%.6f RMSE)' % (train_score, math.sqrt(train_score)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nplt.plot(epoch_history.history['loss'])\nplt.plot(epoch_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"antam[\"Close\"]['2020-01-30':'2021'].plot(figsize=(10,5),legend=True)\nantam[\"Close\"]['2021':].plot(figsize=(10,5),legend=True)\nplt.legend(['Training set','Test set'])\nplt.show()\n\ny_train_predicted = model_lstm.predict(x_train)\ny_inverse = scaler.inverse_transform(y_train)\ny_train_predicted_inverse = scaler.inverse_transform(y_train_predicted)\n\nplt.figure(figsize=(10, 5))\nplt.plot(y_inverse.ravel(), label=\"Price\", color='black')\nplt.plot(y_train_predicted_inverse.ravel(), label=\"Predicted Price\", color='blue')\nplt.legend(loc=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict all data when on Pandemic"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train = generateSequence(scaled_all, window_size)\n\ny_predicted = model_lstm.predict(x_train)\ny_inverse = scaler.inverse_transform(y_train)\ny_predicted_inverse = scaler.inverse_transform(y_predicted)\n\nplt.figure(figsize=(10, 5))\nplt.plot(y_inverse.ravel(), label=\"Close Price\", color='black')\nplt.plot(pd.Series(y_predicted_inverse[:211].ravel(),index=range(0,211)), label=\"Train Predicted Close Price\", color='blue')\nplt.plot(pd.Series(y_predicted_inverse[211:].ravel(),index=range(211,234)), label=\"Test Predicted Close Price\", color='red')\nplt.legend(loc=2)\nplt.title(\"All data - Prediction at 1 day based on the previous {} days\".format(window_size))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Additional"},{"metadata":{},"cell_type":"markdown","source":"Still don't know should to handle this missing date or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"antam['delta'] = antam['Date'] - antam['Date'].shift(1)\n#antam[['Date', 'delta']].head()\nantam['delta'].sum(), antam['Date'].count(), antam['delta'].nunique(), antam['delta'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still on progress and further analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}