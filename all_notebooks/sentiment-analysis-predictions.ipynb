{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport nltk\nimport pandas as pd\nfrom nltk.stem.porter import PorterStemmer\nimport re\nimport random\nfrom itertools import groupby\nimport numpy as np\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"data=pd.read_csv(\"../input/Tweets.csv\")\n#data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"data.loc[data[\"airline_sentiment\"]==\"positive\",\"airline_sentiment\"]=4\ndata.loc[data[\"airline_sentiment\"]==\"neutral\",\"airline_sentiment\"]=2\ndata.loc[data[\"airline_sentiment\"]==\"negative\",\"airline_sentiment\"]=0"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"data[\"tweet_created\"].describe()\ndate=[]\ntime=[]\nfor e in data[\"tweet_created\"]:\n    lst=e.strip().split(\" \")\n    date.append(lst[0])\n    time.append(lst[1])\n\ndata[\"date\"]=date\ndata[\"time\"]=time"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def wordcount(text):\n    p=PorterStemmer()\n    text2=re.sub(r'^[A-Za-z @]',\"\",text)\n    #print(text2)\n    lst=text2.strip().split(\" \")\n    s=\"\"\n    for e in lst:\n        try:\n            index=stopwords.index(e.lower())\n        except:\n            \n            s=s+\" \"+(e.lower())\n            \n    tr=s.strip().split()\n    s=\"\"\n    for ele in tr:\n        try:\n            s=s+\" \"+p.stem(ele)\n        except:\n            continue\n   \n    #s2=re.sub(r'^[A-Za-z0-9@ ]','',s)\n    \n    lst1=s.strip().split(\" \")\n    \n    st1=set(lst1)\n    lst2=[]\n    for el in st1:\n        c=lst1.count(el)\n        lst2.append((el,c))\n    return lst2"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"wc=[]\nfor e in data[\"text\"]:\n    wc.append(wordcount(e))\n#wc[0:10]\ndata[\"wordcount\"]=wc\n#print(wc[0:2])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"columns=[\"airline\",\"wordcount\",\"date\",\"airline_sentiment_confidence\",\"airline_sentiment\"]\ndata=data[columns]\ndate_unique=data[\"date\"].unique()\nfor i in range(len(date_unique)):\n    data.loc[data[\"date\"]==date_unique[i],\"date\"]=i\n#data[\"date\"].unique()\n#virginamerica,americanair,unit,southwestair,jetblu,usairway\nx=data[\"airline\"].unique()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"flight_tokens=[\"virginamerica\",\"americanair\",\"unit\",\"southwestair\",\"jetblu\",\"usairway\"]"},{"cell_type":"markdown","metadata":{},"source":"## split train and test data"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"split_ratio=0.7\nlength=len(data)\nlen_train=int(0.7*length)\nlen_test=int(length-len_train)\ntrain_index=[]\ni=0\ntrain=[]\ntrain_df=pd.DataFrame(columns=columns)\ntest=data\nwhile(i<len_train):\n    index1=random.randint(0,length)\n    flag=1\n    try:\n        g=train_index.index(index1)\n        flag=0\n    except:\n        train_index.append(index1)\n        i=i+1\n        #k=data.iloc[index1]\n        #h=[k[i] for i in range(len(k))]\n        #train.append(h)\n        train_df=train_df.append(data[index1:index1+1])\n        test1=(test[0:index1]).append(test[index1+1:])\n        test=test1\nind1=range(len_test)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_df2=train_df.reset_index(drop=True)\ntrain_df=train_df2\ntest_df=test.reset_index(drop=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test_df.head()"},{"cell_type":"markdown","metadata":{},"source":"## Separate positive,negative and neutral in train data"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_pos=train_df[train_df[\"airline_sentiment\"]==4]\ntrain_neu=train_df[train_df[\"airline_sentiment\"]==2]\ntrain_neg=train_df[train_df[\"airline_sentiment\"]==0]\n#print(len(train_pos),\"pos\")\n#print(len(train_neu),\"neu\")\n#print(len(train_neg),\"neg\")\nglobal prob_airline_pos,prob_airline_neg,prob_airline_neu,airline_lst\nairline_lst=list(x)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"prob_airline_pos=[]\nprob_airline_neg=[]\nprob_airline_neu=[]\nfor el in airline_lst:\n    c=len(train_pos[train_pos[\"airline\"]==el])\n    #print(c)\n    prob_airline_pos.append(c/(len(train_pos)*1.0))\n    c=len(train_neu[train_neu[\"airline\"]==el])\n    #print(c)\n    prob_airline_neu.append(c/(len(train_neu)*1.0))\n    c=len(train_neg[train_neg[\"airline\"]==el])\n    #print(c)\n    prob_airline_neg.append(c/(len(train_neg)*1.0))"},{"cell_type":"markdown","metadata":{},"source":"## combined wordcounts for positive, negative and neutral"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"pos_wordcount=[]\nneg_wordcount=[]\nneu_wordcount=[]\nfor element in train_pos[\"wordcount\"]:\n    for (k,v) in element:\n        pos_wordcount.append((k,v))\nfor element in train_neg[\"wordcount\"]:\n    for (k,v) in element:\n        neg_wordcount.append((k,v))\nfor element in train_neu[\"wordcount\"]:\n    for (k,v) in element:\n        neu_wordcount.append((k,v))\npos_wordcount.sort()\nneg_wordcount.sort()\nneu_wordcount.sort()\npos_wc=[]\npos_wc_word=[]\npos_wc_count=[]\nneg_wc=[]\nneg_wc_word=[]\nneg_wc_count=[]\nneu_wc=[]\nneu_wc_word=[]\nneu_wc_count=[]\n\nfor key, group in groupby(pos_wordcount, lambda x: x[0]):\n    val=0\n    for thing in group:\n        val=val+thing[1]\n    pos_wc.append((key,val))\n    pos_wc_word.append(key)\n    pos_wc_count.append(val)\nfor key, group in groupby(neg_wordcount, lambda x: x[0]):\n    val=0\n    for thing in group:\n        val=val+thing[1]\n    neg_wc.append((key,val))\n    neg_wc_word.append(key)\n    neg_wc_count.append(val)\nfor key, group in groupby(neu_wordcount, lambda x: x[0]):\n    val=0\n    for thing in group:\n        val=val+thing[1]\n    neu_wc.append((key,val))   \n    neu_wc_word.append(key)\n    neu_wc_count.append(val)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"global date_airline_pos,date_airline_neg,date_airline_neu\ndate_airline_pos=[]\ndate_airline_neg=[]\ndate_airline_neu=[]\n#print(train_pos[\"date\"].unique())\nfor airline in airline_lst:\n    al=train_pos[train_pos[\"airline\"]==airline]\n    num=[]\n    for date in range(9):\n        #print(date)\n        k=al[al[\"date\"]==date]\n        num.append(len(k))\n    date_airline_pos.append(num)\nfor airline in airline_lst:\n    al=train_neg[train_neg[\"airline\"]==airline]\n    num=[]\n    for date in range(9):\n        #print(date)\n        k=al[al[\"date\"]==date]\n        num.append(len(k))\n    date_airline_neg.append(num)\nfor airline in airline_lst:\n    al=train_neu[train_neu[\"airline\"]==airline]\n    num=[]\n    for date in range(9):\n        #print(date)\n        k=al[al[\"date\"]==date]\n        num.append(len(k))\n    date_airline_neu.append(num)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# words common to wordcounts of the three categories (pos, neg, neu)\nglobal common_set\ncommon_set=[]\nst_pos=set(pos_wc_word)\nst_neg=set(neg_wc_word)\nst_neu=set(neu_wc_word)\ncommon_set=list(st_pos.intersection(st_neg.intersection(st_neu)))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"num_pos=sum([v for (k,v) in pos_wc])\nnum_neg=sum([v for (k,v) in neg_wc])\nnum_neu=sum([v for (k,v) in neu_wc])\nprint(num_pos,num_neg,num_neu)\n\n\ndef predict(wordcount,airline,date):\n    global prob_airline_pos,prob_airline_neg,prob_airline_neu,airline_lst\n    global date_airline_pos,date_airline_neg,date_airline_neu,common_set\n    total_words=sum([v for (k,v) in wordcount])\n    pos_score=1\n    neg_score=1\n    neu_score=1\n    airline_index=airline_lst.index(airline)\n    pos_score1=date_airline_pos[airline_index][date]/(len(train_pos)*1.0)\n    neg_score1=date_airline_neg[airline_index][date]/(len(train_neg)*1.0)\n    neu_score1=date_airline_neu[airline_index][date]/(len(train_neu)*1.0)\n    pos_score2=pos_score*prob_airline_pos[airline_index]\n    neg_score2=neg_score*prob_airline_neg[airline_index]\n    neu_score2=neu_score*prob_airline_neu[airline_index]\n    #number of words that match\n    pos_match=0\n    neg_match=0\n    neu_match=0\n    for (token,val) in wordcount:\n        try:\n            jj=common_set.index(token)\n        except:\n            try:\n                index=pos_wc_word.index(token)\n                pos_score=pos_score*(pos_wc_count[index]/(num_pos*1.0))**(val) #--[1]\n                pos_match=pos_match+1\n            except:\n                continue\n    for (token,val) in wordcount:\n        try:\n            jj=common_set.index(token)\n        except:\n            try:\n                index=neg_wc_word.index(token)\n                neg_score=neg_score*(neg_wc_count[index]/(num_neg*1.0))**(val) #--[1]\n                neg_match=neg_match+1\n            except:\n                continue\n    for (token,val) in wordcount:\n        try:\n            jj=common_set.index(token)\n        except:           \n           \n            try:\n                index=neu_wc_word.index(token)\n                neu_score=neu_score*(neu_wc_count[index]/(num_neu*1.0))**(val) #--[1]\n                neu_match=neu_match+1\n            except:\n                continue\n    \n    #pos_score=pos_score*pos_match#*1.0/total_words\n    #neg_score=neg_score*neg_match#*1.0/total_words\n    #neu_score=neu_score*neu_match#*1.0/total_words\n    lst=[pos_score,neg_score,neu_score]\n    max_1=min(lst) #minimum since score is multiplied by power of probability --see [1]-- hence lower score better prediction\n    index=lst.index(max_1)\n    pred=-1\n    if(index==0):\n        pred=4\n    elif(index==1):\n        pred=0\n    else:\n        pred=2\n    return pred"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"predictions=[]\nfor i in range(len(test_df)):\n    predictions.append(predict(test_df[\"wordcount\"][i],test_df[\"airline\"][i],test_df[\"date\"][i]))\nacc=sum([int(test_df[\"airline_sentiment\"][j]==predictions[j]) for j in range(len(predictions))])\naccuracy=acc/(len(predictions)*1.0)\nprint(accuracy)"},{"cell_type":"markdown","metadata":{},"source":"## worst case probability, model should beat this\n### max category= negative hence predicting \"negative\" for each test case"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"acc=sum([int(test_df[\"airline_sentiment\"][j]==0) for j in range(len(test_df))])\naccuracy=acc/(len(test_df)*1.0)\nprint(accuracy)"},{"cell_type":"markdown","metadata":{},"source":"## Confusion Matrix"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test_df[\"pred\"]=predictions\ncategories=[4,0,2]\ncon_mat=[[\"label\",\"pred-positive\",\"pred-negative\",\"pred-neutral\"]]\ntest_pos=test_df[test_df[\"airline_sentiment\"]==4]\ntest_neg=test_df[test_df[\"airline_sentiment\"]==0]\ntest_neu=test_df[test_df[\"airline_sentiment\"]==2]\nnum=np.zeros(len(categories))\ntest_pos=test_pos.reset_index(drop=True)\ntest_neg=test_neg.reset_index(drop=True)\ntest_neu=test_neu.reset_index(drop=True)\nfor i in range(len(test_pos)):\n    if(test_pos[\"pred\"][i]==4):\n        num[0]=num[0]+1\n    elif(test_pos[\"pred\"][i]==0):\n        num[1]=num[1]+1\n    else:\n        num[2]=num[2]+1\ncon_mat.append([\"positive\",num[0],num[1],num[2]])\n\nnum=np.zeros(len(categories))\nfor i in range(len(test_neg)):\n    if(test_neg[\"pred\"][i]==4):\n        num[0]=num[0]+1\n    elif(test_neg[\"pred\"][i]==0):\n        num[1]=num[1]+1\n    else:\n        num[2]=num[2]+1\ncon_mat.append([\"negative\",num[0],num[1],num[2]])\n\nnum=np.zeros(len(categories))\nfor i in range(len(test_neu)):\n    if(test_neu[\"pred\"][i]==4):\n        num[0]=num[0]+1\n    elif(test_neu[\"pred\"][i]==0):\n        num[1]=num[1]+1\n    else:\n        num[2]=num[2]+1\ncon_mat.append([\"neutral\",num[0],num[1],num[2]])  \nfor r in con_mat:\n    print(r)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}