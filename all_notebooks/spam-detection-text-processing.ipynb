{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nimport nltk \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scikitplot as skplt\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/spam.csv',encoding='latin-1')\ndf=df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'])\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c97709a874850db2da1cd5d3e7bef40e72dce1a7"},"cell_type":"code","source":"#spliting the labels and the data seperately\ndf_labels=df['v1']\ndf_labels.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"08626da0cd5d6af6bb27299dfb20295e23752d2e"},"cell_type":"markdown","source":"# Data Visualization\n\nVisualizing the data using wordcloud and piechart \n* To check the most used word in Ham sms and Spam sms \n* To visualize the percentage of ham and spam sms\n"},{"metadata":{"trusted":true,"_uuid":"fc9683d2fa501b7cfd8344c39c4ccb82a915906c"},"cell_type":"code","source":"#stopwords\nstopwords= STOPWORDS\nstopwords = list(stopwords)\nSTOPWORDS = nltk.corpus.stopwords.words('english')\nstopwords=stopwords+STOPWORDS\n\nham_dataset=df[df.v1 == 'ham']\nspam_dataset=df[df.v1 == 'spam']\nham_words =''\nspam_words=''\n\nfor words in ham_dataset.v2:\n    txt = words.lower()\n    tokens = nltk.word_tokenize(txt)\n    for word in tokens:\n        ham_words = ham_words + word +\" \"\nfor words in spam_dataset.v2:\n    txt = words.lower()\n    tokens = nltk.word_tokenize(txt)\n    for word in tokens:\n        spam_words = spam_words + word +\" \"\ndef gen_wordcloud(wordcloud):\n    plt.figure( figsize=(10,8), facecolor='k')\n    plt.imshow(wordcloud)\n    plt.tight_layout(pad=0)\n    plt.axis('off')\n    plt.show()\n#wordcloud =WordCloud(background_color='white',width=500, height=500,stopwords=stopwords,max_words=500,max_font_size=50,random_state=42).generate(ham_words)\n#gen_wordcloud(wordcloud)\n#wordcloud =WordCloud(background_color='white',width=500, height=500,stopwords=stopwords,max_words=500,max_font_size=50,random_state=42).generate(spam_words)\n#gen_wordcloud(wordcloud)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"657e7f7d68c64594a46ab929c3fc62a423afdf2f"},"cell_type":"code","source":"#plotting ham and spam data % in pie chart \ncount_Class=pd.value_counts(df.v1, sort= True)\n\n# Data to plot\nlabels = 'Ham', 'Spam'\nsizes = [count_Class[0], count_Class[1]]\ncolors = ['gold', 'yellowgreen'] # 'lightcoral', 'lightskyblue'\nexplode = (0.1, 0.1)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=140)\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"234293f04a8796892e39325e5a5a53af872ab3cd"},"cell_type":"code","source":"#splitting the test and train data \ntrainset, testset, trainlabel, testlabel = train_test_split(df, df_labels, test_size=0.33, random_state=42)\nprint(trainset.shape[1])\nprint(testset.shape)\nprint(\"The Trainset consists of {} records and {} features\".format(trainset.shape[0],trainset.shape[1]))\nprint(\"The Testset consists of {} records and {} features\".format(testset.shape[0],trainset.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d8608f7c66b3037f15806085cd4e0c6b0277342"},"cell_type":"code","source":"#extracting n-grams from the text data\ncountvect= CountVectorizer(ngram_range=(2,2),)\nx_counts = countvect.fit(trainset.v2)\n#preparing for training set\nx_train_df =countvect.transform(trainset.v2)\n#preparing for test set\nx_test_df = countvect.transform(testset.v2)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"970c98da46837f7154cdd6073ae638f10499ec45"},"cell_type":"markdown","source":"# Data Model \n\nFor classification there are some famous classification algorithms and we are going to use the below classification algorithms with this data set and see their prediction results \nThe Algorithms used below in this notebooks are \n* Naive Bayes\n* K-Nearest\n* Decision Tree\n* Support Vector Machine\n* Random Forest\n* Multi-Layer perceptron"},{"metadata":{"trusted":true,"_uuid":"7f1412fed53b6e5f3c73b6479263592c3e6d51a5"},"cell_type":"code","source":"#Creating the model using naive bayes\nclf=MultinomialNB()\nclf.fit(x_train_df,trainset.v1)\npredicted_values = clf.predict(x_test_df)\npredictions=dict()\nacurracy = accuracy_score(testset.v1,predicted_values)\npredictions['Naive Bayes']=acurracy*100\nconfusionmatrix = confusion_matrix(testset.v1,predicted_values)\nprint(\"The accuracy of the model is {}%\".format(acurracy*100 ))\nprint(confusionmatrix)\nskplt.metrics.plot_confusion_matrix(testset.v1,predicted_values, normalize=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"283450e6a4ceaa44afa4615e71b6866efce7435b"},"cell_type":"code","source":"#using K-Nearest to predict \nKNN=KNeighborsClassifier()\nKNN.fit(x_train_df,trainset.v1)\npredictedValues = KNN.predict(x_test_df)\nprint(predictedValues)\nacurracy_KNN = accuracy_score(testset.v1,predictedValues)\npredictions['KNN']=acurracy_KNN*100\nprint(\"The accuracy of the model is {}%\".format(acurracy_KNN*100 ))\nconfusion_matrix_KNN = confusion_matrix(testset.v1,predictedValues)\nprint(confusion_matrix_KNN)\nskplt.metrics.plot_confusion_matrix(testset.v1,predictedValues, normalize=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98f48782279654579fdda86fa533211c2e9e5dab"},"cell_type":"code","source":"#using Decision Tree Classifier to model \nDT=DecisionTreeClassifier()\nDT.fit(x_train_df,trainset.v1)\npredicted_values_DT = DT.predict(x_test_df)\nprint(predicted_values_DT)\nacurracy_DT = accuracy_score(testset.v1,predicted_values_DT)\npredictions['DecisionTree']=acurracy_DT*100\nprint(\"The accuracy of the model is {}%\".format(acurracy_DT*100 ))\n#print(testset.v1)\nconfusion_matrix_DT = confusion_matrix(testset.v1,predicted_values_DT)\nprint(confusion_matrix_DT)\nskplt.metrics.plot_confusion_matrix(testset.v1,predicted_values_DT, normalize=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fea6f8a874661b54e3d4dad68621ebe5dabbe36f"},"cell_type":"code","source":"#Training the model using SVM Classifier\nSVM = svm.SVC()\nSVM.fit(x_train_df,trainset.v1)\npredicted_values_svm=SVM.predict(x_test_df)\nprint(predicted_values_svm)\nacurracy_SVM = accuracy_score(testset.v1,predicted_values_svm)\npredictions['SVM']=acurracy_SVM*100\nprint(\"The accuracy of the model is {}%\".format(acurracy_SVM*100 ))\nconfusion_matrix_SVM = confusion_matrix(testset.v1,predicted_values_svm)\nprint(confusion_matrix_SVM)\nskplt.metrics.plot_confusion_matrix(testset.v1,predicted_values_svm, normalize=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eae982be9c04b17a28fe8895a609213047e7207e"},"cell_type":"code","source":"#Predicting using RandomForest\nRF = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\nRF.fit(x_train_df,trainset.v1)\npredicted_values_RF = RF.predict(x_test_df)\nprint(predicted_values_RF)\nacurracy_RF = accuracy_score(testset.v1,predicted_values_RF)\npredictions['RandomForest']=acurracy_RF*100\nprint(\"The accuracy of the model is {}%\".format(acurracy_RF*100 ))\n#print(testset.v1)\nconfusion_matrix_RF = confusion_matrix(testset.v1,predicted_values_RF)\nprint(confusion_matrix_RF)\nskplt.metrics.plot_confusion_matrix(testset.v1,predicted_values_RF, normalize=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86ea45f996a97f7b638c7d6de74cd6a6c1a9199e"},"cell_type":"code","source":"#modelling using Multi-layer perceptron\nMLP = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\nMLP.fit(x_train_df,trainset.v1)\npredicted_values_MLP = MLP.predict(x_test_df)\nprint('Predicted Values {}'.format(predicted_values_MLP))\naccuracy_MLP = accuracy_score(testset.v1,predicted_values_MLP)\npredictions['Neural Networks']=accuracy_MLP*100\nprint(\"The accuracy of the model is {}\".format(accuracy_MLP*100))\nskplt.metrics.plot_confusion_matrix(testset.v1,predicted_values_MLP, normalize=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8467e7ca7041719e141d1362f252fdea01db0431"},"cell_type":"code","source":"#using XGBoost to model and predict\nXGB = XGBClassifier()\nXGB.fit(x_train_df,trainset.v1)\npredicted_values_XGB=XGB.predict(x_test_df)\nprint(predicted_values_XGB)\naccuracy_XGB = accuracy_score(testset.v1,predicted_values_XGB)\npredictions['XGBoost']=accuracy_XGB*100\nprint(\"The accuracy of the model is {}\".format(accuracy_XGB*100))\nskplt.metrics.plot_confusion_matrix(testset.v1,predicted_values_XGB, normalize=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3150dbab80de1e1b8e67e9d496bdac7983a32f75"},"cell_type":"code","source":"fig, (ax1) = plt.subplots(ncols=1, sharey=True,figsize=(15,5))\ndf=pd.DataFrame(list(predictions.items()),columns=['Algorithms','Percentage'])\ndisplay(df)\nsns.pointplot(x=\"Algorithms\", y=\"Percentage\", data=df,ax=ax1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c1ec9eb4aaf15b8f54d0f4ff89eb3c5dd7b2ab4"},"cell_type":"code","source":"#pr, tpr, thresholds = roc_curve(testset.v1,predicted_values_XGB, pos_label=2)\ntest_prediction = testset.v1.tolist()\npredicted_values = predicted_values_XGB.tolist()\ntest_prediction = [1 if pred==\"spam\" else 0 for pred in test_prediction]\npredicted_values = [1 if pred==\"spam\" else 0 for pred in predicted_values]\nfpr, tpr, thresholds = roc_curve(test_prediction,predicted_values)\nroc_auc = auc(fpr, tpr)\nprint(\"The ROC Accuracy is {}\".format(roc_auc))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55169968ed4a941ea96df5dca57de625a462a821"},"cell_type":"code","source":"plt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',\nlabel='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}