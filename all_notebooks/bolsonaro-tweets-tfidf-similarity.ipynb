{"cells":[{"metadata":{"_uuid":"6b9ec4dbd47dfe440e827ec73ed6f7f66af54197"},"cell_type":"markdown","source":"# Simple Cosine Similarity Analysis on Jair Bolsonaro tweets"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"208971545956afa3a0eb5d1d9ea45dffc0fb51c5"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport seaborn as sns\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c01464f9833cf6ab809cc9b9cce73d04ef9574d3"},"cell_type":"code","source":"df = pd.read_csv('../input/bolsonaro_tweets.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f92e22b07d20df33ad8d92287ca58da75d9c820","scrolled":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use data only after the day Bolsonaro was elected as the President of Brazil\ndf = df[df['date'] >= '2018-10-28'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10fb6b8fd3e17202e5aacb25d0d711f9c8eb45de"},"cell_type":"markdown","source":"# Cleaning the text\n\nLet's do some cleaning on the text before doing word clouds and using the scatter text library for visualization"},{"metadata":{"trusted":true,"_uuid":"8e2a8cc85aa57133f24a5437276f87ea7e6622dc"},"cell_type":"code","source":"def clean_df(df_clean):\n    remove_names = False # if True, assumes you have a nomes.txt file with common brazilian names in your current dir\n    remove_usernames = False\n    \n    # Copy the original text for later metadata\n    df_clean['original_text'] = df_clean['text']\n\n    # Lower case\n    df_clean['text'] = df_clean['text'].apply(\n        lambda x: \" \".join(x.lower() for x in x.split()))\n\n    # Remove usernames\n    if remove_usernames:\n        df_clean['text'] = df_clean['text'].str.replace(\n            '@[^\\s]+', \"\")\n\n    # Remove links\n    df_clean['text'] = df_clean['text'].str.replace(\n        'https?:\\/\\/.*[\\r\\n]*', '')\n\n    # Remove punctuation\n    df_clean['text'] = df_clean['text'].str.replace(\n        '[^\\w\\s]', '')\n\n    # Remove stopwords\n    from nltk.corpus import stopwords\n    stop = stopwords.words('portuguese')\n    df_clean['text'] = df_clean['text'].apply(\n        lambda x: \" \".join(x for x in x.split() if x not in stop))\n\n    # Remove common brazilian names\n    if remove_names:\n        nomes = pd.read_csv('nomes.txt', encoding='latin', header=None)\n        lista_nomes = (nomes[0].str.lower()).tolist()\n        df_clean['text'] = df_clean['text'].apply(lambda x: \" \".join(\n            x for x in x.split() if x not in lista_nomes))\n\n    # Remove numbers\n    df_clean['text'] = df_clean['text'].str.replace(\n        '\\d+', '')\n\n    # Remove words with 1-3 chars\n    df_clean['text'] = df_clean['text'].str.replace(\n        r'\\b(\\w{1,3})\\b', '')\n\n    # Replace accents and รง\n    df_clean.text = df_clean.text.str.normalize('NFKD')\\\n        .str.encode('ascii', errors='ignore')\\\n        .str.decode('utf-8')\n    \n    return df_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8043c6bfe36038ffae3376a043383ef14af0821"},"cell_type":"code","source":"df = clean_df(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07620940e3acfbe1844ccb9305ed82397b983862"},"cell_type":"markdown","source":"We see that some tweets disappeared as they were just emoji. We won't bother cleaning these rows as our libraries won't take them in consideration anyways. A future idea that we could implement is to substitute each emoji by a word that describes it.\n\n# Word clouds\n\nWe're going to use [this](https://github.com/amueller/word_cloud) word cloud library to provide a beautiful visualization. I will keep the background _white_ in the _before_ dataframe and **dark** in the **after** dataframe just to help us visualize."},{"metadata":{"trusted":true,"_uuid":"6bcb01da69f9ae3dfe28301fd93710befd441750"},"cell_type":"code","source":"text = \" \".join(review for review in df.text)\nwordcloud = WordCloud(\n    width=3000,\n    height=2000,\n    background_color='white').generate(text)\nfig = plt.figure(\n    figsize=(40, 30))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Most common words"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer()\ncount_matrix = cv.fit_transform(df['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_count = pd.DataFrame(cv.get_feature_names(), columns=[\"word\"])\nword_count[\"count\"] = count_matrix.sum(axis=0).tolist()[0]\nword_count = word_count.sort_values(\"count\", ascending=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_series = pd.Series.from_array(word_count['count'][:10])\n\nx_labels = word_count['word'][:10]\n\nplt.figure(figsize=(12, 8))\nax = freq_series.plot(kind='bar')\nax.set_xticklabels(x_labels)\n\nrects = ax.patches\nlabels = word_count['count'][:10]\n\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width() / 2, height + 5, label,\n            ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tfidf_vectorizer.fit_transform(df['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tfidf_vectorizer.get_feature_names()[0:10])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"print(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cosine_similarity(X[0:1], X).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig, ax = plt.subplots(figsize=(20, 20))\n# Drop self-correlations\n#dropSelf = np.zeros_like(cos_sim)\n#dropSelf[np.triu_indices_from(dropSelf)] = True\n# Generate Color Map\n#colormap = sns.diverging_palette(220, 10, as_cmap=True)\n#sns.heatmap(cos_sim,mask=dropSelf,cmap=colormap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_similar(tfidf_matrix, index, top_n = 5):\n    cosine_similarities = cosine_similarity(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n    return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text'][100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, score in find_similar(X, 100):\n       print(\"{} - {}\".format(score, df['text'][index]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text'][25]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, score in find_similar(X, 25):\n       print(\"{} - {}\".format(score, df['text'][index]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}