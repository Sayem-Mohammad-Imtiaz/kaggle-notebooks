{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \nimport numpy\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import np_utils\n...\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-13T09:13:39.562069Z","iopub.execute_input":"2021-07-13T09:13:39.562483Z","iopub.status.idle":"2021-07-13T09:13:39.576518Z","shell.execute_reply.started":"2021-07-13T09:13:39.562453Z","shell.execute_reply":"2021-07-13T09:13:39.574796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load ascii text and covert to lowercase\nfilename = \"../input/wonderland/wonderland.txt\"\nraw_text = open(filename, 'r', encoding='utf-8').read()\nraw_text = raw_text.lower()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:39.578866Z","iopub.execute_input":"2021-07-13T09:13:39.579448Z","iopub.status.idle":"2021-07-13T09:13:39.587596Z","shell.execute_reply.started":"2021-07-13T09:13:39.579409Z","shell.execute_reply":"2021-07-13T09:13:39.586433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create mapping of unique chars to integers\nchars = sorted(list(set(raw_text)))\nchar_to_int = dict((c, i) for i, c in enumerate(chars))","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:39.597252Z","iopub.execute_input":"2021-07-13T09:13:39.597637Z","iopub.status.idle":"2021-07-13T09:13:39.605536Z","shell.execute_reply.started":"2021-07-13T09:13:39.59761Z","shell.execute_reply":"2021-07-13T09:13:39.603634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_chars = len(raw_text)\nprint(\"Total Characters: \", n_chars)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:39.607924Z","iopub.execute_input":"2021-07-13T09:13:39.608453Z","iopub.status.idle":"2021-07-13T09:13:39.619311Z","shell.execute_reply.started":"2021-07-13T09:13:39.608413Z","shell.execute_reply":"2021-07-13T09:13:39.618023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_vocab = len(chars)\nprint(\"Total Vocab: \", n_vocab)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:39.621733Z","iopub.execute_input":"2021-07-13T09:13:39.622716Z","iopub.status.idle":"2021-07-13T09:13:39.629955Z","shell.execute_reply.started":"2021-07-13T09:13:39.622673Z","shell.execute_reply":"2021-07-13T09:13:39.628389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare the dataset of input to output pairs encoded as integers\nseq_length = 100\ndataX = []\ndataY = []\nfor i in range(0, n_chars - seq_length, 1):\n    seq_in = raw_text[i:i + seq_length]\n    seq_out = raw_text[i + seq_length]\n    dataX.append([char_to_int[char] for char in seq_in])\n    dataY.append(char_to_int[seq_out])\nn_patterns = len(dataX)\nprint(\"Total Patterns: \", n_patterns)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:39.632249Z","iopub.execute_input":"2021-07-13T09:13:39.633146Z","iopub.status.idle":"2021-07-13T09:13:41.482388Z","shell.execute_reply.started":"2021-07-13T09:13:39.633102Z","shell.execute_reply":"2021-07-13T09:13:41.481008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape X to be [samples, time steps, features]\nX = numpy.reshape(dataX, (n_patterns, seq_length, 1))#note 1\n# normalize\nX = X / float(n_vocab)\n# one hot encode the output variable\ny = np_utils.to_categorical(dataY)#note 2","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:41.484693Z","iopub.execute_input":"2021-07-13T09:13:41.485386Z","iopub.status.idle":"2021-07-13T09:13:44.880887Z","shell.execute_reply.started":"2021-07-13T09:13:41.485306Z","shell.execute_reply":"2021-07-13T09:13:44.879676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))#note 3\nmodel.add(Dropout(0.2))#note 4\nmodel.add(Dense(y.shape[1], activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:44.884713Z","iopub.execute_input":"2021-07-13T09:13:44.885121Z","iopub.status.idle":"2021-07-13T09:13:45.207078Z","shell.execute_reply.started":"2021-07-13T09:13:44.88508Z","shell.execute_reply":"2021-07-13T09:13:45.206011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:45.208803Z","iopub.execute_input":"2021-07-13T09:13:45.209317Z","iopub.status.idle":"2021-07-13T09:13:45.214907Z","shell.execute_reply.started":"2021-07-13T09:13:45.209273Z","shell.execute_reply":"2021-07-13T09:13:45.213684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:13:45.216503Z","iopub.execute_input":"2021-07-13T09:13:45.217196Z","iopub.status.idle":"2021-07-13T09:16:38.877696Z","shell.execute_reply.started":"2021-07-13T09:13:45.217153Z","shell.execute_reply":"2021-07-13T09:16:38.87647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the network weights\nfilename = \"./weights-improvement-10-2.3639.hdf5\"\nmodel.load_weights(filename)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nint_to_char = dict((i, c) for i, c in enumerate(chars))\n# pick a random seed\nimport sys\nstart = numpy.random.randint(0, len(dataX)-1)\npattern = dataX[start]\nprint (\"Seed1:\")\nprint (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n# generate characters\nfor i in range(1000):\n    x = numpy.reshape(pattern, (1, len(pattern), 1))\n    x = x / float(n_vocab)\n    prediction = model.predict(x, verbose=0)\n    index = numpy.argmax(prediction)\n    result = int_to_char[index]\n    seq_in = [int_to_char[value] for value in pattern]\n    sys.stdout.write(result)\n    pattern.append(index)\n    pattern = pattern[1:len(pattern)]\nprint(\"\\nDone.\")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:16:38.883504Z","iopub.execute_input":"2021-07-13T09:16:38.88418Z","iopub.status.idle":"2021-07-13T09:17:22.124994Z","shell.execute_reply.started":"2021-07-13T09:16:38.884133Z","shell.execute_reply":"2021-07-13T09:17:22.123937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# we can see the repeatation so, now will try to improve our model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(256))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(y.shape[1], activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:17:22.126808Z","iopub.execute_input":"2021-07-13T09:17:22.127185Z","iopub.status.idle":"2021-07-13T09:17:22.720235Z","shell.execute_reply.started":"2021-07-13T09:17:22.127157Z","shell.execute_reply":"2021-07-13T09:17:22.719149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:17:22.721804Z","iopub.execute_input":"2021-07-13T09:17:22.722184Z","iopub.status.idle":"2021-07-13T09:17:22.73033Z","shell.execute_reply.started":"2021-07-13T09:17:22.722146Z","shell.execute_reply":"2021-07-13T09:17:22.729083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, epochs=40, batch_size=64, callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:17:22.731816Z","iopub.execute_input":"2021-07-13T09:17:22.732664Z","iopub.status.idle":"2021-07-13T09:56:20.415571Z","shell.execute_reply.started":"2021-07-13T09:17:22.732609Z","shell.execute_reply":"2021-07-13T09:56:20.414488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the network weights\nfilename = \"./weights-improvement-40-1.3549-bigger.hdf5\"\nmodel.load_weights(filename)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\nint_to_char = dict((i, c) for i, c in enumerate(chars))","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:06:34.467857Z","iopub.execute_input":"2021-07-13T10:06:34.468246Z","iopub.status.idle":"2021-07-13T10:06:34.505689Z","shell.execute_reply.started":"2021-07-13T10:06:34.468196Z","shell.execute_reply":"2021-07-13T10:06:34.504581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# pick a random seed\nimport sys\nstart = numpy.random.randint(0, len(dataX)-1)\npattern = dataX[start]\nprint (\"Seed2:\")\nprint (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n# generate characters\nfor i in range(1000):\n    x = numpy.reshape(pattern, (1, len(pattern), 1))\n    x = x / float(n_vocab)\n    prediction = model.predict(x, verbose=0)\n    index = numpy.argmax(prediction)\n    result = int_to_char[index]\n    seq_in = [int_to_char[value] for value in pattern]\n    sys.stdout.write(result)\n    pattern.append(index)\n    pattern = pattern[1:len(pattern)]\nprint(\"\\nDone.\")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:06:40.686937Z","iopub.execute_input":"2021-07-13T10:06:40.687348Z","iopub.status.idle":"2021-07-13T10:07:27.756239Z","shell.execute_reply.started":"2021-07-13T10:06:40.687318Z","shell.execute_reply":"2021-07-13T10:07:27.754421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we can see that the repeatation of the words is less as compared to the previous training","metadata":{}}]}