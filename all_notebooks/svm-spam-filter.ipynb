{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SVM SPAM Filter\n\nI recently learnt about SVMs so I thought I would try out my new knowledge on a dataset they were well suited for. I chose a SPAM dataset as its a binary classification problem, and because the dataset was small (SVMs scale well with features but not with instances). This dataset also gave me an opportunity to look at vectorizing text.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vectorizing Text Data\n\nFirst we need to read in the data. The first thing to note is that only the first two columns in the csv file are needed, hence we can ignore all others. Also, whilst the first row in the csv file gives headers, I preferred to use ones I found more descriptive. Finally, I noticed that choosing the right encoding was important. ","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', usecols=(0,1),\n                   encoding='latin-1', names=[\"Label\",\"Text\"], skiprows = 1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The instances were already shuffled. To get a feel for the data available, we can count the instances of each. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Label\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two labels present were spam and ham, as expected. The next step is to separate the dataset into a training and testing dataset. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Create a training and testing dataset.\ntrain, test = train_test_split(data,shuffle=True, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are a lot more ham instances than spam. The datasets were shuffled prior to splitting, so there should be decent numbers of each instance in each dataset, but we can check quickly to make sure one dataset isn't lacking. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare ratio of SPAM instances to HAM instances\nprint('Percentage of Instances which are SPAM:')\nprint('Train: ',round(100.*len(train.loc[train[\"Label\"]==\"spam\"])/len(train),2),'%')\nprint('Test: ',round(100.*len(test.loc[test[\"Label\"]==\"spam\"])/len(test),2),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now start to think about vectorizing the text data. First of all, the spam and ham labels need to be converted into a numeric value. I chose spam=1 (positive) and ham=0 (negative). Secondly, the text has to be converted into a numeric representation. There are several ways to do this, but for simplicity I chose to use CountVectorizer in sci-kit learn. This will create a dictionary of the words found in the training set of the sms messages. We can then use it to convert each message into a sparse array of the same length of the dictionary, in which the only non-zero elements will correspond to words which occur in that message. Because we fit the tokenizer (CountVectorizer) using only the training set, its possible that words will occur in the test set, which will not be in the dictionary. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# First replace the label with a numeric value\nmapping = {'spam': 1, 'ham': 0}\ntrain_labels = train.replace({\"Label\": mapping})\ntrain_labels = train_labels[\"Label\"]\ntest_labels = test.replace({\"Label\": mapping})\ntest_labels = test_labels[\"Label\"]\n\n# Define a method to vectorize the text data, and fit it using the \n# training dataset.\nvectorizer = CountVectorizer()\nvectorizer.fit(train[\"Text\"])\n\n# Now convert all sms data to vector form\ntrain_text = vectorizer.transform(train[\"Text\"])\ntest_text = vectorizer.transform(test[\"Text\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training a Support Vector Machine\n\nA SVM is a good option for this dataset, as there are lots of features (one per word which occurs in the training data) and comparitively fewer instances. Because of this, training should be fairly fast. We will first compare different kernel types: Linear, Polynomial, Sigmoid and Gaussian Radial Bias Function (RBF).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\n\nlinear_classifier = SVC(kernel='linear',random_state = 42)\nlinear_scores = cross_val_score(linear_classifier,train_text,train_labels,cv=5)\n\npoly_classifier = SVC(kernel='poly',random_state = 42)\npoly_scores = cross_val_score(poly_classifier,train_text,train_labels,cv=5)\n\nsigmoid_classifier = SVC(kernel='sigmoid',random_state = 42)\nsigmoid_scores = cross_val_score(sigmoid_classifier,train_text,train_labels,cv=5)\n\nrbf_classifier = SVC(kernel='rbf',random_state = 42)\nrbf_scores = cross_val_score(rbf_classifier,train_text,train_labels,cv=5)\n\nprint('Kernel\\tMean Score')\nprint('Linear: ',round(100*np.mean(linear_scores),2),'%')\nprint('Polynomial: ',round(100*np.mean(poly_scores),2),'%')\nprint('Sigmoid: ',round(100*np.mean(sigmoid_scores),2),'%')\nprint('RBF: ',round(100*np.mean(rbf_scores),2),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those scores are already pretty good (as a baseline, we can use that roughly 13% of the instances are spam, so if a model simply outputted that every instance was ham, we would be right 87% of the time). This means a SVM is well suited to this classification task. The linear and RBF kernels look the most promising, so we will use Grid Search to tune the hyperparameters of these. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nclassifier = SVC(random_state = 26)\nparam_grid = [{'kernel': ['linear','rbf'], 'C':[0.5,0.75,1.0,1.5,2.0], 'gamma': ['auto','scale']}]\n\ngrid_search = GridSearchCV(classifier, param_grid, cv=5, scoring=\"accuracy\", return_train_score=True)\ngrid_search.fit(train_text, train_labels)\n\ncurves = grid_search.cv_results_\nprint(f'Highest Score: ', round(100.*max(curves[\"mean_test_score\"]),2), '%')\nprint(f'Corresponding Parameters: ', curves[\"params\"][np.argmax(curves[\"mean_test_score\"])])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The default parameters seem to be the best here. Whilst accuracy is the final scoring metric we will use, we can also check the models generalisation by looking at the ROC curve, and the area underneath it. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_predict\n\nclassifier = SVC(random_state=34, kernel='linear', probability=True)\nspam_prob = cross_val_predict(classifier, train_text, train_labels, cv=3, method=\"predict_proba\" )\nspam_score = spam_prob[:,1] # Probability text is spam\nfpr,tpr, thresholds = roc_curve(train_labels,spam_score)\n\nfig = plt.figure(figsize=(6,6))\nax = fig.add_subplot(111)\nax.plot([0,1],[0,1], color='black', ls='dashed', label='Random Baseline')\nax.plot(fpr, tpr, color='mediumvioletred', label='Linear SVM')\nax.set_xlabel('False Positive Rate',fontsize=12); ax.set_ylabel(\"True Positive Rate\",fontsize=12)\nax.set_xlim(0,1); ax.set_ylim(0,1)\nplt.legend(frameon=False)\nplt.show()\n\nprint('AUC Score: ',round(roc_auc_score(train_labels,spam_score),5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, that's a fairly good score. We can take a closer look at the TPR, FPR and F1 scores as well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nspam_pred = cross_val_predict(classifier, train_text, train_labels, cv=3, method=\"predict\" )\nprint(classification_report(train_labels,spam_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In general, the precision, recall and f1 scores are all fairly high for this model. However, in order to see how well it really does, we should evaluate it on the test datset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate model on test data\nclassifier.fit(train_text, train_labels)\npredictions = classifier.predict(test_text)\ncorrect = test_labels==predictions\n\nprint('Accuracy: ', round(100.*np.sum(correct)/len(correct),2),'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(test_labels,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy, precision, recall and f1 scores are not much lower on the test data, which implies the model generalises well. Overall, a SVM seems to be a good model for this problem, and the linear kernel works well. To improve this score, its probably worth looking more at vectorizing the text (I was really more interested in testing out SVM classifiers).","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}