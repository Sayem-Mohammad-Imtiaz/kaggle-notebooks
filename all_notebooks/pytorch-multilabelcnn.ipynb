{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_csv = pd.read_csv('../input/age-gender-and-ethnicity-face-data-csv/age_gender.csv')\nprint(data_csv['age'].unique()) #1~116\nprint(data_csv['ethnicity'].unique()) #0~4\ndata_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def age_cvt(age) :\n    return int(age/10)\n\ndata_csv['age'] = data_csv['age'].apply(lambda x : age_cvt(x))\ndata_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndata_csv['pixels'] = data_csv['pixels'].apply(lambda x : np.array(x.split(), dtype=\"float32\"))\ndata_csv['pixels'] = data_csv['pixels'] / 255.0\n\nplt.imshow(data_csv['pixels'][0].reshape(48, 48)) #2304 = 48*48\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_list = [4, 504, 1004, 2504, 5004, 6904, 17894, 18644, 20004, 23014]\n\nprint(len(data_csv))\n\ntest_csv = pd.DataFrame()\nfor i in test_list :\n    test_csv = test_csv.append(data_csv.iloc[i])\n    data_csv = data_csv.drop(i)\n\nprint(len(data_csv))\ntest_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch\nimport cv2\n\nclass dataset(Dataset) :\n    def __init__(self, age_label, eth_label, gen_label, img) :\n        self.age_label = np.array(age_label)\n        self.eth_label = np.array(eth_label)\n        self.gen_label = np.array(gen_label)\n        self.img = np.array(img)\n        \n        self.transform = transforms.Compose([\n            transforms.ToTensor()\n        ])\n        \n    def __len__(self) :\n        return len(self.img)\n    \n    def __getitem__(self, index) :\n        age_label = self.age_label[index]\n        eth_label = self.eth_label[index]\n        gen_label = self.gen_label[index]\n        \n        img = self.img[index].reshape(48, 48, 1)\n        #img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n        img = self.transform(img)\n        \n        return img, age_label, eth_label, gen_label\n    \ntrain_data = dataset(data_csv['age'][:], data_csv['ethnicity'][:], \n                     data_csv['gender'][:], data_csv['pixels'][:])\ntrain_data = DataLoader(train_data, batch_size = 128, shuffle = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_features = len(data_csv['age'].unique())\neth_features = len(data_csv['ethnicity'].unique())\ngen_features = len(data_csv['gender'].unique())\n\nprint(age_features, eth_features, gen_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport timm\nfrom timm.models.layers.classifier import ClassifierHead\nfrom torchsummary import summary\n\nclass MultiLabelCNN(nn.Module) :\n    def __init__(self, age_features, ethnicity_features, gender_features) :\n        super().__init__()   \n        '''\n        self.model = timm.create_model('dm_nfnet_f0', pretrained = False)\n        n_features = self.model.num_features\n        self.age_classifier = ClassifierHead(n_features, age_features)\n        self.eth_classifier = ClassifierHead(n_features, ethnicity_features)\n        self.gen_classifier = ClassifierHead(n_features, gender_features)\n        '''\n        self.cnnModel = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1),\n            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1), #24\n            nn.LeakyReLU(),\n            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1), #12\n            nn.LeakyReLU(),\n            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1), #6\n            nn.LeakyReLU(),\n            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1), #3\n            #nn.LeakyReLU(),\n            nn.AdaptiveAvgPool2d((1,1)) #flatten\n        )\n        \n        self.dnnModel = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, 64),\n            nn.LeakyReLU(),\n            nn.Linear(64, 32),\n            nn.LeakyReLU(),\n        )\n        \n        self.age_classifier = nn.Linear(32, age_features)\n        self.eth_classifier = nn.Linear(32, ethnicity_features)\n        self.gen_classifier = nn.Linear(32, gender_features)     \n    def forward(self, x) :\n        '''\n        output = self.model.forward_features(x)\n        age = self.age_classifier(output)\n        eth = self.eth_classifier(output)\n        gen = self.gen_classifier(output)\n        '''\n        output = self.cnnModel(x)\n        output = output.squeeze()\n        output = self.dnnModel(output)\n        \n        age = self.age_classifier(output)\n        eth = self.eth_classifier(output)\n        gen = self.gen_classifier(output)\n        return age, eth, gen\n    \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MultiLabelCNN(age_features, eth_features, gen_features).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n\ndef custom_loss (output, target) :\n    age_loss = nn.CrossEntropyLoss().to(device)(output[0], target[0])\n    eth_loss =  nn.CrossEntropyLoss().to(device)(output[1], target[1])\n    gen_loss =  nn.CrossEntropyLoss().to(device)(output[2], target[2])\n    \n    return age_loss + eth_loss + gen_loss, age_loss.item(), eth_loss.item(), gen_loss.item()\n\nsummary(model, input_size=(1, 48, 48))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\nepoch_num = 100\nmodel.train()\n\nfor epoch in range(epoch_num) :\n    epoch_loss = 0\n    epoch_acc = 0\n    for img, age, eth, gen in tqdm(train_data) :\n        img = img.to(device)\n        age = age.to(device)\n        eth = eth.to(device)\n        gen = gen.to(device)\n        \n        predict = model(img)\n        \n        loss = custom_loss(predict, (age, eth, gen))\n        \n        optimizer.zero_grad()\n        loss[0].backward()\n        optimizer.step()\n        \n        correct_prediction = 0\n        for i, _ in enumerate(age) :\n            if torch.argmax(predict[0][i]) == age[i] and \\\n            torch.argmax(predict[1][i]) == eth[i] and \\\n            torch.argmax(predict[2][i]) == gen[i] :\n                correct_prediction += 1\n                \n        epoch_loss += loss[0]\n        epoch_acc += correct_prediction / img.shape[0]\n        \n    epoch_loss = epoch_loss / len(train_data)\n    epoch_acc = epoch_acc / len(train_data)\n    print('Epoch : {}/{},   loss : {:.5f},    acc : {:.5f}'.format(epoch+1, epoch_num, epoch_loss, epoch_acc))\n    \n    if epoch_acc > 0.93 and epoch_loss < 0.2 :\n        print('early stop')\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\ntest_data = dataset(test_csv['age'][:], test_csv['ethnicity'][:], \\\n                     test_csv['gender'][:], test_csv['pixels'][:])\ntest_data = DataLoader(test_data, batch_size = 1, shuffle = False)\nprint(len(test_data))\n\ncorrect_prediction = 0\nfor img, age, eth, gen in test_data :\n    img = img.to(device)\n    age = age.to(device)\n    eth = eth.to(device)\n    gen = gen.to(device)\n    \n    predict = model(img)\n    \n    real = str(age[0].item()) + ' ' + str(eth[0].item()) + ' ' + str(gen[0].item())\n    pred = str(torch.argmax(predict[0]).item()) + ' ' + \\\n    str(torch.argmax(predict[1]).item()) + ' ' + str(torch.argmax(predict[2]).item())\n    \n    img = img.reshape(1, 48, 48).to('cpu').numpy()\n    plt.imshow(img.transpose(1, 2, 0))\n    plt.title('real : ' + str(real) + ' / predict : ' + str(pred))\n    plt.show()\n    \n    if age[0] == torch.argmax(predict[0]) and \\\n    eth[0] == torch.argmax(predict[1]) and \\\n    gen[0] == torch.argmax(predict[2]) : correct_prediction += 1\n\nprint('total_acc : ', str(correct_prediction / len(test_data)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}