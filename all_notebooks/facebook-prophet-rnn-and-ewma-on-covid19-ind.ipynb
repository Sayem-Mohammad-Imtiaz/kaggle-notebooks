{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/novel-corona-virus-2019-dataset/covid_19_data.csv',index_col='ObservationDate',parse_dates=True)\ncovidIndia = df[df['Country/Region'] == 'India']\ncovidIndia.drop(['SNo','Last Update','Province/State'],axis=1,inplace = True)\ncovidIndia.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covidIndia.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of Data is ==> \",covidIndia.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covidIndia.index[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covidIndia.index.freq = 'D'\ncovidIndia.index[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I have checked Index to set frequency of Time Series data. It is important to set frequency of Time Series data to avoid unnecessary errors in statsmodels."},{"metadata":{},"cell_type":"markdown","source":"# ETS Decomposition\n\nThe <a href='https://en.wikipedia.org/wiki/Decomposition_of_time_series'>decomposition</a> of a time series attempts to isolate individual components such as <em>error</em>, <em>trend</em>, and <em>seasonality</em> (ETS)."},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nresult = seasonal_decompose(covidIndia['Confirmed'], model='mul')\n\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12,8\nresult.plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I will be using Multiplicative model because trend is not linear , It is exponential. Also i will not be using seasonality because it looks like there is no seasonal pattern."},{"metadata":{},"cell_type":"markdown","source":"# Holt Winters Method\n\n### <font color=blue>Simple Exponential Smoothing / Simple Moving Average</font>\nThis is the simplest to forecast. $\\hat{y}$ is equal to the most recent value in the dataset, and the forecast plot is simply a horizontal line extending from the most recent value.\n### <font color=blue>Double Exponential Smoothing / Holt's Method</font>\nThis model takes trend into account. Here the forecast plot is still a straight line extending from the most recent value, but it has slope.\n### <font color=blue>Triple Exponential Smoothing / Holt-Winters Method</font>\nThis model has (so far) the \"best\" looking forecast plot, as it takes seasonality into account. When we expect regular fluctuations in the future, this model attempts to map the seasonal behavior."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"train_data = covidIndia.iloc[:78]\ntest_data = covidIndia.iloc[78:]\n\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\n\nfitted_model = ExponentialSmoothing(train_data['Confirmed'],trend='mul').fit()\n\ntest_predictions = fitted_model.forecast(15).rename('Confirmed Forecast')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Prediction ==> \\n\",test_predictions[:5])\nprint(\"\\n\",\"Actual Data ==> \\n\",test_data[:5]['Confirmed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Date',ylabel = 'Count of Cases',title = 'Comparision : Test VS Prediction')\ntrain_data['Confirmed'].plot(legend=True,label='TRAIN',lw = 2)\ntest_data['Confirmed'].plot(legend=True,label='TEST',figsize=(8,4),lw = 2)\ntest_predictions.plot(legend=True,label='PREDICTION',lw = 2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Date',ylabel = 'Count of Cases',title = 'Comparision : Test VS Prediction (Zoon In)')\ntest_data['Confirmed'].plot(legend=True,label='TEST DATA',figsize=(8,4),lw = 2)\ntest_predictions.plot(legend=True,label='PREDICTION',xlim=['2020-04-23','2020-04-27'],lw = 2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,mean_absolute_error\n\nprint(\"MAE ==> \",mean_absolute_error(test_data['Confirmed'],test_predictions))\nprint(\"MSE ==> \",mean_squared_error(test_data['Confirmed'],test_predictions))\nprint(\"RMSE ==> \",np.sqrt(mean_squared_error(test_data['Confirmed'],test_predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.describe()['Confirmed']['std']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Forecasting using Holt Method"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"final_model = ExponentialSmoothing(train_data['Confirmed'],trend='mul').fit()\nforecast_predictions = final_model.forecast(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Date',ylabel = 'Count of Cases',title = 'Forecast : (May 1, 2020) to (May 15, 2020)')\ncovidIndia['Confirmed'].plot(figsize=(8,4),lw = 2,legend = True,label = 'Actual Confirmed')\nforecast_predictions.plot(lw=2,legend = True,label = 'Forecast Confirmed',xlim = ['2020-04-20','2020-05-15']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let me explain the things now :-\n\n1. I have splitted the data in train and test set, Size of test is 15 because i wanted to forecast for next 15 days.\n2. We can clearly see , How good this simple model is explaining the trend and able to forecast result.\n3. Looking at MSE, you might think the model is doing worst, But think again!! One should not judge model performance by just looking at MSE,RMSE. Compare these values with given data. If it is close to our data then model is doing good. In this case we can see there are little difference between RMSE and STD of actual data. So this simple is not doing that much bad :)"},{"metadata":{},"cell_type":"markdown","source":"# RNN\n\n![](https://miro.medium.com/fit/c/1838/551/1*HgAY1lLMYSANqtgTgwWeXQ.png)\n\nA recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs.This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.\n\nYou can read more on RNN [here.](https://en.wikipedia.org/wiki/Recurrent_neural_network)\n\n### RNN for time series =>\n\n![](https://upload.wikimedia.org/wikipedia/commons/3/3b/The_LSTM_cell.png)\n\nA powerful type of neural network designed to handle sequence dependence is called recurrent neural networks. The Long Short-Term Memory network or LSTM network is a type of recurrent neural network used in deep learning because very large architectures can be successfully trained.\n\nYou can read more on LSTM RNN [here](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\ntrain = pd.DataFrame(covidIndia.iloc[:78,1])\ntest = pd.DataFrame(covidIndia.iloc[78:,1])\n\nscaler.fit(train)\nscaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Scaled Train Set ==> \\n\", scaled_train[:5],\"\\n\")\nprint(\"Scaled Test Set==> \\n\", scaled_test[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time Series Generator\n\nThis class takes in a sequence of data-points gathered at\nequal intervals, along with time series parameters such as\nstride, length of history, etc., to produce batches for\ntraining/validation.\n\n#### Arguments\n    data: Indexable generator (such as list or Numpy array)\n        containing consecutive data points (timesteps).\n        The data should be at 2D, and axis 0 is expected\n        to be the time dimension.\n    \n    targets: Targets corresponding to timesteps in `data`.\n        It should have same length as `data`.\n    \n    length: Length of the output sequences (in number of timesteps).\n    \n    batch_size: Number of timeseries samples in each batch\n        (except maybe the last one)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import TimeseriesGenerator\nn_input = 15\nn_features = 1\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RNN LSTM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n\n# define model\nmodel = Sequential()\nmodel.add(LSTM(150, activation='relu', input_shape=(n_input, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# fit model\nmodel.fit_generator(generator,epochs=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"loss_per_epoch = model.history.history['loss']\nfig = plt.figure(dpi = 120,figsize = (8,4))\nax = plt.axes()\nax.set(xlabel = 'Number of Epochs',ylabel = 'MSE Loss',title = 'Loss Curve of RNN LSTM')\nplt.plot(range(len(loss_per_epoch)),loss_per_epoch,lw = 2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can see how good our model is able to converge !!"},{"metadata":{},"cell_type":"markdown","source":"## Evaluate on Test Data\n\nThis part is little bit trickt to understand. RNN LSTM actually uses past data to predict next one data point. Here our input length is 15, So in each iteration model will use past 15 data to predict next one."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-n_input:]\ncurrent_batch = first_eval_batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_predictions = scaler.inverse_transform(test_predictions)\ntest['Predictions'] = true_predictions\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(dpi = 120)\nax=plt.axes()\ntest.plot(legend=True,figsize=(14,6),lw = 2,ax=ax)\nplt.xlabel('Date')\nplt.ylabel('Count of Cases')\nplt.title('Comparision B/W Test and Prediction')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can see our model is caapturing trend, But India is beating Corona !! :)"},{"metadata":{},"cell_type":"markdown","source":"## Forecasting\n\nTo forecast, we need to refit model again with whole data points."},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\ntrain = pd.DataFrame(covidIndia.iloc[:,1])\n\n\nscaler.fit(train)\nscaled_train = scaler.transform(train)\n\nn_input = 15\nn_features = 1\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size=1)\n\n# define model\nmodel = Sequential()\nmodel.add(LSTM(150, activation='relu', input_shape=(n_input, n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\n\n# fit model\nmodel.fit_generator(generator,epochs=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_per_epoch = model.history.history['loss']\nfig = plt.figure(dpi = 120,figsize = (8,4))\nax = plt.axes()\nax.set(xlabel = 'Number of Epochs',ylabel = 'MSE Loss',title = 'Loss Curve of RNN LSTM')\nplt.plot(range(len(loss_per_epoch)),loss_per_epoch,lw = 2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"forecast = []\n\nfirst_eval_batch = scaled_train[-n_input:]\ncurrent_batch = first_eval_batch.reshape((1, n_input, n_features))\n\nfor i in range(15):\n    current_pred = model.predict(current_batch)[0]\n    forecast.append(current_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n\nforecast= scaler.inverse_transform(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = pd.DataFrame({'Forecast':forecast.flatten()})\nforecast.index = np.arange('2020-05-01',15,dtype='datetime64[D]')\nforecast.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(dpi=120,figsize = (14,6))\nax = plt.axes()\nax.set(xlabel = 'Date',ylabel = 'Count of Cases (Lacs)',title = 'Forecast : (May 1, 2020) to (May 15, 2020)')\nforecast.plot(label = 'Forecast',ax=ax,color='red',lw=2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> So , Here is forecast for 15 days using RNN."},{"metadata":{},"cell_type":"markdown","source":"# Facebook Prophet\n\n![](https://www.kdnuggets.com/wp-content/uploads/prophet-facebook.jpg)\n\nProphet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\n\n## IMPORTANT NOTE ONE:\n\n**You should really read the papaer for Prophet! It is relatively straightforward and has a lot of insight on their techniques on how Prophet works internally!**\n\nLink to paper: https://peerj.com/preprints/3190.pdf"},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n\nProphet needs a specific format at input. So we need little bit preprocessing here."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(covidIndia.iloc[:,1])\ndf.reset_index(inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['ds','y']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(dpi = 120)\naxes = plt.axes()\naxes.set(xlabel = 'Date',ylabel = 'Count of Cases',title = 'Trend')\ndf.plot(x='ds',y='y',figsize=(8,4),lw=2,color = 'blue',ax=axes);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df.iloc[:78]\ntest = df.iloc[78:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\nm = Prophet()\nm.fit(train)\nfuture = m.make_future_dataframe(periods=15)\nforecast = m.predict(future)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(dpi = 120)\nax = plt.axes()\nax.set(xlabel = 'Date',ylabel = 'Count of Cases',title = 'Comparision B/W Test & Prediction')\nforecast.plot(x='ds',y='yhat',label='Predictions',legend=True,figsize=(8,4),ax=ax,lw=2)\ntest.plot(x='ds',y='y',label='True Miles',legend=True,ax=ax,xlim=('2020-04-17','2020-05-01'),lw=2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Well according to Prophet prediction, Number of Cases should have been decreased as compared to real data!! But our model is doing good."},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tools.eval_measures import rmse\npredictions = forecast.iloc[-15:]['yhat']\nprint(\"RMSE ==> \",rmse(predictions,test['y']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Mean ==> \",test.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Forecast\n\nLet us forecast for May 1, 2020 to May 15, 2020. Note we have to fit again on whole data..."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\nm = Prophet()\nm.fit(df)\nfuture = m.make_future_dataframe(periods=15)\nforecast = m.predict(future)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(dpi = 120 )\naxes = plt.axes()\nm.plot(forecast, figsize = (8,4),ax=axes)\nplt.xlabel('Date')\nplt.ylabel('Count of Cases')\nplt.title('Forecast')\nplt.xticks(rotation = 90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How good Prophet is doing, Just see black dots are actual confirmed cases while line are prediction with uncertainity..."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(dpi = 120)\naxes = plt.axes()\nm.plot(forecast,ax=axes,figsize = (8,4))\nstart = pd.to_datetime(['2020-04-25'])\nend = pd.to_datetime(['2020-05-15'])\nplt.xlabel('Date')\nplt.ylabel('Count of Cases')\nplt.title('Forecast : (May 1, 2020) - (May 15, 2020)')\nplt.xlim(start,end)\nplt.ylim(20000,60000)\nplt.xticks(rotation = 90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we have forecast for May 1, 2020 to May 15, 2020.\n\n## Now i will end up my notebook here , Thank you for reading!! I hope you guys have learned something.\n\n## Please do upvote, if you like !!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}