{"cells":[{"metadata":{"papermill":{"duration":0.029718,"end_time":"2020-10-26T12:46:41.276296","exception":false,"start_time":"2020-10-26T12:46:41.246578","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<img src=\"https://whatcar.vn/media/2018/09/car-lot-940x470.jpg\"/>\n\n## Прогнозирование стоимости автомобиля по характеристикам"},{"metadata":{"papermill":{"duration":0.028027,"end_time":"2020-10-26T12:46:41.334278","exception":false,"start_time":"2020-10-26T12:46:41.306251","status":"completed"},"tags":[]},"cell_type":"markdown","source":"По условию соревнования, нам нужно самостоятельно собрать обучающий датасет. "},{"metadata":{},"cell_type":"markdown","source":"## Парсер сайта AUTO.RU (Актуальность: декабрь 2020 г.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfrom fake_useragent import UserAgent \nfrom bs4 import BeautifulSoup    \nimport requests  \nimport re\nimport time\nimport pandas as pd\nimport numpy as np\nimport itertools\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\n\n\n\n\n# Функция по извлечению данных со страницы объявления в словарь data_dict\ndef parsing_page_one_ad(url):\n\n    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})    \n    response.encoding ='utf8'   \n    \n    # Теперь создадим объект BeautifulSoup, указывая html парсер    \n    page = BeautifulSoup(response.text, 'html.parser')\n    data_dict = {}\n\n    data_dict['car_url'] = url\n    data_dict['parsing_unixtime'] = int(time.time())\n\n\n     # в разделах script ищем вхождение 'complectation\":{\"id\"'\n    for script in page.find_all(\"script\"):\n        if 'complectation\":{\"id\"' in str(script):\n            a = str(script)  # присваиваем a содержимое скрипта как строку\n    # в a  ищем 'complectation\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n            data_dict['complectation_dict'] = re.search(r'complectation\":{\"id.*?}', a)[0][15:]\n\n        if 'equipment\":{' in str(script):\n            a = str(script)  # присваиваем a содержимое скрипта как строку\n        # в a  ищем 'equipment\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n            data_dict['equipment_dict'] = re.search(r'equipment\":{.*?}', a)[0][11:]\n\n        if '{\"mileage\":' in str(script):\n            a = str(script)  # присваиваем a содержимое скрипта как строку\n        # в a  ищем '{\"mileage\":' и содержимое между {}. Отсекаем начало, оставляя только содержимое словаря\n            data_dict['mileage'] = re.search(r'\"mileage\":\\d*', a)[0][10:]\n\n        if '\"model_info\":' in str(script):\n            a = str(script)  # присваиваем a содержимое скрипта как строку\n            data_dict['model_info'] = re.search(r'\"model_info\":{.*?}', a)[0][13:]\n            data_dict['model_name'] = re.search(r'model_info\":{\"code\":\".*?\"', a)[0][20:].strip('\"')\n\n        if 'super_gen\":{' in str(script):\n            a = str(script)  # присваиваем a содержимое скрипта как строку\n            data_dict['super_gen'] = re.search(r'super_gen\":{.*?}', a)[0][11:] \n\n        if 'vendor\":\"' in str(script):\n            a = str(script)  # присваиваем a содержимое скрипта как строку\n            data_dict['vendor'] = re.search(r'vendor\":\".*?\"', a)[0][9:].strip('\"')\n\n\n    for tag in page.find_all('div'):\n        if tag.get(\"title\") == \"Идентификатор объявления\":\n            data_dict['sell_id'] = re.search(r'\\d+', tag.text)[0]\n\n\n    for tag in page.find_all(\"meta\"):\n        if tag.get(\"itemprop\") == \"bodyType\":\n            data_dict['bodyType'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"brand\":\n            data_dict['brand'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"color\":\n            data_dict['color'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"description\":\n            data_dict['description'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"engineDisplacement\":\n            data_dict['engineDisplacement'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"enginePower\":\n            data_dict['enginePower'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"fuelType\":\n            data_dict['fuelType'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"modelDate\":\n            data_dict['modelDate'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"name\":\n            data_dict['name'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"numberOfDoors\":\n            data_dict['numberOfDoors'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"price\":\n            data_dict['price'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"priceCurrency\":\n            data_dict['priceCurrency'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"productionDate\":\n            data_dict['productionDate'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"vehicleConfiguration\":\n            data_dict['vehicleConfiguration'] = tag.get(\"content\")\n\n        if tag.get(\"itemprop\") == \"vehicleTransmission\":\n            data_dict['vehicleTransmission'] = tag.get(\"content\")\n\n\n    span_CardInfoRow__cell = page.find_all('span', {'class': 'CardInfoRow__cell'})\n\n    for i,tag in enumerate (span_CardInfoRow__cell):\n        if tag.text == \"Владельцы\":\n            data_dict['Владельцы'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n\n        if tag.text == \"Владение\":\n            data_dict['Владение'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел    \n\n        if tag.text == \"ПТС\":\n            data_dict['ПТС'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел    \n\n        if tag.text == \"Привод\":\n            data_dict['Привод'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел \n\n        if tag.text == \"Руль\":\n            data_dict['Руль'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n\n        if tag.text == \"Состояние\":\n            data_dict['Состояние'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел \n\n        if tag.text == \"Таможня\":\n            data_dict['Таможня'] = span_CardInfoRow__cell[i+1].text.replace(u'\\xa0', u' ') # в  конце заменяем юникодовский пробел\n\n    return data_dict\n\n    \n# Функция по созданию списка ссылок links_list  на объявления о продаже автомобилей  \ndef extraction_links(url):\n    links_list =[] \n    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})  \n    response.encoding ='utf8'\n    page = BeautifulSoup(response.text, 'html.parser') \n    links = page.find_all('a', class_='Link ListingItemTitle-module__link')\n    \n    for link in links:\n        links_list.append(link.get(\"href\"))\n    return links_list\n    \n    \n    \n    \n    \ndf = pd.DataFrame() # инициализируем итоговый датафрейм \n\nurl_link_list = [] # список страниц по годам и номерам от 1 до 99\n\nranges = [range(2006, 2011), range(1, 100)] # указываем года и диапазон страниц, которые будем парсить \n\n# index[0] - year, index[1] - page \nfor index in itertools.product(*ranges):\n    # формируем ссылки страницы со списками объявлений\n    на  = (f\"https://auto.ru/moskva/cars/{index[0]}-year/all/?output_type=table&page={index[1]}\")\n    url_link_list.append(url_links) # заносим их в список\n    \nlinks_list = [] # список списков ссылок на объявления c одной страницы таблицы объявлений\n\n#for url_links in url_link_list:\n# извлекаем в links_list список ссылок на объявления\ntry:\n        #links_list = extraction_links(url_links)\n    links_list = Parallel(n_jobs = 2)(delayed(extraction_links)(url_links) for url_links in url_link_list)\nexcept:\n    pass \n\nads_dict_list = [] # список словарей содержимого объявлений\n\nfor links in links_list:\n    try:\n        ads_dict_list = Parallel(n_jobs = 2)(delayed(parsing_page_one_ad)(ad_url) for ad_url in links)\n    except:\n        pass\n    \n    for ad in ads_dict_list:\n        try:\n            df = df.append(ad, ignore_index=True)\n        except:\n            pass\n\ndf.to_csv('_auto_ru_XXXX-XXXX.csv', encoding = 'utf-8', index=False) # записываем содержимое датафрейма в файл\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Объединение спарсенных датафреймов в один и его первичная обработка"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nimport os\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame()\nlist_file = os.listdir(path=\".\") # получение списка файлов в папке\n\nfor file in list_file:\n    if '.csv' in file: # если у файла расширение .csv, то читаем его как DF\n        df_temp = pd.read_csv(file)\n        df = pd.concat([df, df_temp], ignore_index=True)\n        \ndf = df.drop_duplicates(subset=['car_url']) # удаление дубликатов по URL объявления\n\ndf = df.replace('{}',  None) # замена пустых словарей на NaN\ndf['mileage'] = df['mileage'].apply(lambda x: int(x) if type(x) == str else x) # приведение 'mileage' к числовму виду\ndf = df.replace(np.nan,  None)\n\ndf.to_csv('auto_ru_moskva_12_12_2020.csv', encoding = 'utf-8', index=False)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подгружаем библиотеки и наш датасет"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-10-26T12:46:41.400302Z","iopub.status.busy":"2020-10-26T12:46:41.399317Z","iopub.status.idle":"2020-10-26T12:46:42.581426Z","shell.execute_reply":"2020-10-26T12:46:42.580431Z"},"papermill":{"duration":1.219772,"end_time":"2020-10-26T12:46:42.581597","exception":false,"start_time":"2020-10-26T12:46:41.361825","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\nimport seaborn as sns\nimport datetime\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm.notebook import tqdm\n\nfrom catboost import CatBoostRegressor\n\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import LabelEncoder, PolynomialFeatures\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None) #отображение всех столбцов датасета","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-26T12:46:42.646795Z","iopub.status.busy":"2020-10-26T12:46:42.645765Z","iopub.status.idle":"2020-10-26T12:46:42.649793Z","shell.execute_reply":"2020-10-26T12:46:42.650407Z"},"papermill":{"duration":0.040034,"end_time":"2020-10-26T12:46:42.650603","exception":false,"start_time":"2020-10-26T12:46:42.610569","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-26T12:46:42.716039Z","iopub.status.busy":"2020-10-26T12:46:42.715184Z","iopub.status.idle":"2020-10-26T12:46:47.852433Z","shell.execute_reply":"2020-10-26T12:46:47.851661Z"},"papermill":{"duration":5.172536,"end_time":"2020-10-26T12:46:47.852593","exception":false,"start_time":"2020-10-26T12:46:42.680057","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:47.919419Z","iopub.status.busy":"2020-10-26T12:46:47.918168Z","iopub.status.idle":"2020-10-26T12:46:47.922267Z","shell.execute_reply":"2020-10-26T12:46:47.921365Z"},"papermill":{"duration":0.039842,"end_time":"2020-10-26T12:46:47.922434","exception":false,"start_time":"2020-10-26T12:46:47.882592","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Определение базовых функций"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Функция по сбору информации по каждому столбцу\n\n\ndef my_describe(df):\n    \"\"\"Отображение описательных статистик датафрейма в удобной форме\"\"\"\n    temp = {}\n    temp['Имя признака'] = list(df.columns)\n    temp['Тип'] = df.dtypes\n    temp['Всего значений'] = df.describe(include='all').loc['count']\n    temp['Число пропусков'] = df.isnull().sum().values \n    temp['Кол-во уникальных'] = df.nunique().values\n    temp['Минимум'] = df.describe(include='all').loc['min']\n    temp['Максимум'] = df.describe(include='all').loc['max']\n    temp['Среднее'] = df.describe(include='all').loc['mean']\n    temp['Медиана'] = df.describe(include='all').loc['50%']\n    temp = pd.DataFrame.from_dict(temp, orient='index')\n    display(temp.T)\n    return\n\n\ndef show_plot_boxplot(df, column, bins=80):\n    \"\"\"Построение гистограммы по столбцу и boxplot-а\"\"\"\n    color_text = plt.get_cmap('PuBuGn')(0.9)\n    plt.style.use('seaborn')\n    plt.rcParams['figure.figsize'] = (10, 4)\n    _, axes = plt.subplots(2, 1)\n    axes[0].hist(df[column], bins=bins)\n    axes[0].set_title(\"Гистограмма и boxplot для признака \"+column)\n    axes[1].boxplot(df[column], vert=False, showmeans = True)\n    axes[1].set_title('')\n    return\n\n\n# Пропишем функцию расчета IQR и квартилей.\n\ndef IQR_perc(df,list_cols):\n    temp = {}\n    temp['Имя признака'] = list_cols\n    temp['IQR'] = df[list_cols].quantile(0.75) - df[list_cols].quantile(0.25)\n    temp['perc25'] = df[list_cols].quantile(0.25)\n    temp['perc75'] = df[list_cols].quantile(0.75)\n    temp['Л. граница выбросов'] = df[list_cols].quantile(0.25) - 1.5*(df[list_cols].quantile(0.75) - df[list_cols].quantile(0.25))\n    temp['П. граница выбросов'] =df[list_cols].quantile(0.75) + 1.5*(df[list_cols].quantile(0.75) - df[list_cols].quantile(0.25))\n    temp = pd.DataFrame.from_dict(temp, orient='index')\n    display(temp.T)\n    return\n\n\ndef mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true)) # функция вычисления MAPE – средней абсолютной ошибки","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.028837,"end_time":"2020-10-26T12:46:47.981435","exception":false,"start_time":"2020-10-26T12:46:47.952598","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Setup"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.05046Z","iopub.status.busy":"2020-10-26T12:46:48.049412Z","iopub.status.idle":"2020-10-26T12:46:48.052578Z","shell.execute_reply":"2020-10-26T12:46:48.051917Z"},"papermill":{"duration":0.039969,"end_time":"2020-10-26T12:46:48.052728","exception":false,"start_time":"2020-10-26T12:46:48.012759","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"VERSION    = 15\nDIR_TRAIN = '/kaggle/input/autorumoskva/' # подключил к ноутбуку внешний датасет\nDIR_TEST   = '/kaggle/input/sf-dst-car-price-prediction/'\nVAL_SIZE   = 0.20   # 20%\n\n# CATBOOST\nITERATIONS = 5000\nLR         = 0.1","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.030254,"end_time":"2020-10-26T12:46:48.112586","exception":false,"start_time":"2020-10-26T12:46:48.082332","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.179769Z","iopub.status.busy":"2020-10-26T12:46:48.178918Z","iopub.status.idle":"2020-10-26T12:46:48.924574Z","shell.execute_reply":"2020-10-26T12:46:48.925184Z"},"papermill":{"duration":0.783211,"end_time":"2020-10-26T12:46:48.925418","exception":false,"start_time":"2020-10-26T12:46:48.142207","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!ls '../input'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-26T12:46:49.007668Z","iopub.status.busy":"2020-10-26T12:46:49.006762Z","iopub.status.idle":"2020-10-26T12:47:02.121152Z","shell.execute_reply":"2020-10-26T12:47:02.120434Z"},"papermill":{"duration":13.16556,"end_time":"2020-10-26T12:47:02.12133","exception":false,"start_time":"2020-10-26T12:46:48.95577","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train = pd.read_csv(DIR_TRAIN+'auto_ru_moskva_12_12_2020.csv') # датасет для обучения модели\ntest = pd.read_csv(DIR_TEST+'test.csv')\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.22557Z","iopub.status.busy":"2020-10-26T12:47:02.21916Z","iopub.status.idle":"2020-10-26T12:47:02.245921Z","shell.execute_reply":"2020-10-26T12:47:02.246559Z"},"papermill":{"duration":0.09378,"end_time":"2020-10-26T12:47:02.246755","exception":false,"start_time":"2020-10-26T12:47:02.152975","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.317036Z","iopub.status.busy":"2020-10-26T12:47:02.316251Z","iopub.status.idle":"2020-10-26T12:47:02.50135Z","shell.execute_reply":"2020-10-26T12:47:02.501985Z"},"papermill":{"duration":0.22352,"end_time":"2020-10-26T12:47:02.502166","exception":false,"start_time":"2020-10-26T12:47:02.278646","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"my_describe(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 6))\nplt.ylim(top=3_000_000)\nax = sns.boxplot(y=\"price\", data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> На графике видим, что 75% предложений, это цена до 1_300_000р. И все что свыше  3 млн. рублей - считается выбросами "},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train[train['price']>3_000_000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Общая доля выбросов по признаку \"price\" :', round(len(train[train['price']>3_000_000])/len(train) * 100,2), '%')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.599966Z","iopub.status.busy":"2020-10-26T12:47:02.598892Z","iopub.status.idle":"2020-10-26T12:47:02.604335Z","shell.execute_reply":"2020-10-26T12:47:02.60353Z"},"papermill":{"duration":0.069985,"end_time":"2020-10-26T12:47:02.604497","exception":false,"start_time":"2020-10-26T12:47:02.534512","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:02.7822Z","iopub.status.busy":"2020-10-26T12:47:02.781391Z","iopub.status.idle":"2020-10-26T12:47:02.797734Z","shell.execute_reply":"2020-10-26T12:47:02.798395Z"},"papermill":{"duration":0.160401,"end_time":"2020-10-26T12:47:02.798587","exception":false,"start_time":"2020-10-26T12:47:02.638186","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"my_describe(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# В train отсутствует признак Image, поэтому в test сразу его удалим\ntest.drop(['image'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.033402,"end_time":"2020-10-26T12:47:02.866506","exception":false,"start_time":"2020-10-26T12:47:02.833104","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# сохраним целевую переменную, а после удалим из тренировочного датасета\ny = train['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['price'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = train#[columns]\ndf_test = test#[columns]\n\n# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Первичный отсмотр данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_describe(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Удалим столбцы не несущие в себе параметры автомобиля, и не влиящие на предсказание цены \ndata.drop(['car_url', 'parsing_unixtime', 'sell_id'], axis=1,inplace=True)\n# В связи с отсутствие времени на обработку текста, также удалим 'description'\ndata.drop(['description'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Работа с пропусками"},{"metadata":{"trusted":true},"cell_type":"code","source":"# построим карту пропусков данных\nf, ax = plt.subplots(figsize=(12, 5))\nsns.heatmap(data.isnull(), cbar=True)\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"У наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, даже отсутствие информации может быть важным признаком! По этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подсчитаем общее число строк с пропусками\ndata.shape[0] - data.dropna().shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Такое количество строк удалять мы не будем, значит нужно решить чем их заполнить"},{"metadata":{"trusted":true},"cell_type":"code","source":"#пропуски в значительном количестве наблюдаем о в столбцах \"complectation_dict\",'equipment_dict' и 'Владение'.\n#Создадим новые столбцы с признаком пропуска данных в них\ncols ={\"complectation_dict\",'equipment_dict', 'Владение'}\nfor col in cols:\n    data[f'{col}_isNAN'] = pd.isna(data[col]).astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# один пропуск наблюдаем в \"ПТС\". Заполним его самым частым значением: data[\"ПТС\"].value_counts().index[0]\ndata[\"ПТС\"] = data[\"ПТС\"].fillna(data[\"ПТС\"].value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Признак \"complectation_dict\""},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"complectation_dict\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Самым частым непустым значением в столбце является значение {\"id\":\"0\"}. Чтобы не нарушать структуру данных оставим его без изменений, и им заполним пропуски в столбце. И ячейкам в  ['complectation_dict_isNAN'], соответствующих этому значению, присвоим единицу "},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"complectation_dict\"] = data[\"complectation_dict\"].fillna('{\"id\":\"0\"}')\ndata['complectation_dict_isNAN'] = data[\"complectation_dict\"].apply(lambda x: 1 if x == '{\"id\":\"0\"}' else 0)\ndata['complectation_dict_isNAN'] = data['complectation_dict_isNAN'].astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Признак \"equipment_dict\""},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"equipment_dict\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Наиболее универсального варианта здесь не видно, поэтому присвоим пропускам значение : {\"unknown\" :true}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"equipment_dict\"] = data[\"equipment_dict\"].fillna('{\"unknown\" :true}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Признак \"Владение\""},{"metadata":{"trusted":true},"cell_type":"code","source":"  data[\"Владение\"].value_counts()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Владельцы'][data[\"Владение\"].isnull()].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Так как  машины с пропусками в признаке \"Владение\" выпущены в разные годы (большинство не новые из автосалона), и зачастую имели более одного владельца, то пропуски заполним значением: 'Неизвестно'  "},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Владение\"] = data[\"Владение\"].fillna('Неизвестно')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_describe(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Просматриваем и обрабатываем все признаки","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Обработка признаков"},{"metadata":{},"cell_type":"markdown","source":"Для начала посмотрим какие признаки у нас могут быть категориальныe, бинарные и числовые:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сформируем списки столбцов по группам исходя из типов признаков\nnum_cols = ['mileage', 'modelDate', 'productionDate']\nbin_cols =['Руль', 'Состояние', 'Таможня', 'ПТС'] \ncategory_cols = ['model_info', 'model_name', 'name', 'super_gen', 'complectation_dict', 'equipment_dict',  'bodyType', 'brand', 'color', 'fuelType', 'numberOfDoors', \n                 'priceCurrency',  'vehicleConfiguration', 'vehicleTransmission', 'vendor', 'Владельцы', 'Владение', 'Привод', 'engineDisplacement', 'enginePower']\n# 'priceCurrency' - тип валюты. В настоящее время у нас только рубли, но могут быть и др. варианты. Поэтому отнесем к категориальным данным ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Числовые признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим параметры IQR, гистограммы и боксплоты числовых признаков\nIQR_perc(data, num_cols)\nfor column in num_cols:\n    show_plot_boxplot(data,column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Выводы:\n\nПо графикам и предыдущим таблицам видно, что основное число машин  произведено примерно в 2010г и в среднем имеют пробег 146_000 км. Данные разрежены, позднее логарифмируем их"},{"metadata":{},"cell_type":"markdown","source":"Попытка удаления выбросов в тренировочном датасете метрику не улучшило"},{"metadata":{},"cell_type":"markdown","source":"### Корреляция"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для проверки корреляции возьмем числовые признаки тренировочного датасета \n# и присоединим к ним целевую переменную в виде датафрейма df\nX = data.query('sample == 1').drop(['sample'], axis=1)\n\ndf = pd.DataFrame(X[num_cols]).reset_index()\ndf.drop(['index'], axis=1,inplace=True)\ndf['price']=y\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = df.corr()\nplt.figure(figsize=(10, 6))\nsns.heatmap(correlation, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что modelDate и ProductionDate как и ожидалось сильно коррелируют между собою, а также  engineDisplacement и enginePower слабо  коррелируют с целевой переменной (ценой). Пробег же с целевой переменной корреллирует отрицательно - чем больше пробег, тем ниже цена"},{"metadata":{},"cell_type":"markdown","source":"### Бинарные признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Переведем бинарные признаки в числа при  LabelEncoder\n\nlabel_encoder = LabelEncoder()\n\nfor column in bin_cols:\n    data[column] = label_encoder.fit_transform(data[column])\n    \n# убедимся в преобразовании    \ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Категориальные признаки"},{"metadata":{},"cell_type":"markdown","source":"Осмотрим значения признаков имеющих неболшое количество значений: "},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['bodyType', 'color', 'engineDisplacement', 'enginePower', 'fuelType', 'numberOfDoors', 'priceCurrency', \n'vehicleTransmission', 'vendor', 'Владельцы', 'Владение', 'Привод']:\n    print(f'{col}: {data[col].unique()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# В признаке 'Владельцы' заменим юникодовский пробел на ascii пробел\ndata[\"Владельцы\"] = data[\"Владельцы\"].str.replace(u'\\xa0', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Переведем категориальные признаки в числа\n# в алфавитном порядке \n\"\"\"label_encoder = LabelEncoder()\n\nfor column in category_cols:\n    data[column] = label_encoder.fit_transform(data[column])\ndata.head()\"\"\"\n\nfor colum in category_cols:\n    data[colum] = data[colum].astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Создание новых признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['km_in_year'] = data['mileage'] / ((datetime.datetime.now().year +1) - data['productionDate'])\nnum_cols.append('km_in_year')\n\n# Введение данных признаков (атикварные и старые автомобили ) немного ухудшило метрику\n\n#data['antique_car'] = data['productionDate'].apply(lambda x: 1 if x<(datetime.datetime.now().year-50) else 0)\n#data['old_car'] = data['productionDate'].apply(lambda x: 1 if \\\n#((datetime.datetime.now().year-50)<= x <=(datetime.datetime.now().year-20)) else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразуем числовые признаки в полиномиальные\npoly = PolynomialFeatures(3,interaction_only=True)\ndata_num = pd.DataFrame(poly.fit_transform(data[num_cols].values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Логарифмирование признаков (числовых и целевого)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Прологарифмируем целевую функцию. А после предсказания взять экспоненту от получившегося рузультата: y=np.exp(y)-1\ny= np.log(y+1)\n# прологарифмируем числовые признаки и полученные от них полиномиальные признаки\ndata[num_cols] = np.log(data[num_cols]+1)\ndata_num = np.log(data_num +1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Присоединим к датасету ,блок нормализованных полиномиальных признаков\ndata = pd.concat([data,data_num], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отделим тренировочный датасет от тестового:\n\nX = data.query('sample == 1').drop(['sample'], axis=1)\nX_sub = data.query('sample == 0').drop(['sample'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.035737,"end_time":"2020-10-26T12:47:03.826552","exception":false,"start_time":"2020-10-26T12:47:03.790815","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Подготовка данных к машинному обучению"},{"metadata":{},"cell_type":"markdown","source":"Разделим  тренировочные данные для обучения следующим образом:"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:03.90948Z","iopub.status.busy":"2020-10-26T12:47:03.908518Z","iopub.status.idle":"2020-10-26T12:47:03.923409Z","shell.execute_reply":"2020-10-26T12:47:03.922602Z"},"papermill":{"duration":0.059208,"end_time":"2020-10-26T12:47:03.923564","exception":false,"start_time":"2020-10-26T12:47:03.864356","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Модели ML"},{"metadata":{"papermill":{"duration":0.037164,"end_time":"2020-10-26T12:47:03.997616","exception":false,"start_time":"2020-10-26T12:47:03.960452","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Model #1: Модель CatBoost c заданными параметрами \n\n\n![](https://pbs.twimg.com/media/DP-jUCyXcAArRTo.png:large)   \n\n\nУ нас в данных практически все признаки категориальные. Специально для работы с такими данными была создана очень удобная библиотека CatBoost от Яндекса. [https://catboost.ai](http://)     \nНа данный момент **CatBoost является одной из лучших библиотек для табличных данных!**\n\n#### Полезные видео о CatBoost (на русском):\n* [Доклад про CatBoost](https://youtu.be/9ZrfErvm97M)\n* [Свежий Туториал от команды CatBoost (практическая часть)](https://youtu.be/wQt4kgAOgV0) "},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:04.256865Z","iopub.status.busy":"2020-10-26T12:47:04.248328Z","iopub.status.idle":"2020-10-26T12:48:12.17834Z","shell.execute_reply":"2020-10-26T12:48:12.17762Z"},"papermill":{"duration":67.991521,"end_time":"2020-10-26T12:48:12.178488","exception":false,"start_time":"2020-10-26T12:47:04.186967","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# вычисления закомментированы для ускорения записи на Kaggle\nmodel1 = CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = LR,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE']\n                         )\n#model1.fit(X_train, y_train,\n#         eval_set=(X_test, y_test),\n#         verbose_eval=100,\n#         use_best_model=True,\n#         plot=True\n#         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = np.round((np.exp(model1.predict(X_test))-1)/1000) *1000\ny_test_exp = np.exp(y_test)-1\n\n# оцениваем точность\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test_exp, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Без подбора параметров MAPE составила 16.93% "},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:48:12.389716Z","iopub.status.busy":"2020-10-26T12:48:12.388722Z","iopub.status.idle":"2020-10-26T12:48:12.393213Z","shell.execute_reply":"2020-10-26T12:48:12.392387Z"},"papermill":{"duration":0.135345,"end_time":"2020-10-26T12:48:12.393406","exception":false,"start_time":"2020-10-26T12:48:12.258061","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Не знаю пока что это, но сохраню на будущее\n#model1.save_model('catboost_single_model_baseline.model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Модель 2 (с найденными лучшими гиперпараметрами)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Поиск наилучших параметров для CatBoostRegressor\ncbr = CatBoostRegressor()\n\ngrid = {'learning_rate': [round(x,3) for x in np.linspace(start = 0.025, stop = 0.4, num = 40)],\n        'depth': [int(x) for x in np.linspace(start = 5, stop = 10, num = 5)],\n        'l2_leaf_reg': [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]}\n\n#grid_search_result = cbr.grid_search(grid, \n#                                       X=X_train, \n#                                       y=y_train, \n#                                       plot=False)\n#print(grid_search_result['params'])\n\n# {'depth': 7, 'l2_leaf_reg': 1, 'learning_rate': 0.083} bestTest = 0.01254271153 bestIteration = 3746","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = CatBoostRegressor(iterations = 3747,\n                          learning_rate = 0.083,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          depth = 7,\n                          l2_leaf_reg = 1 \n                         )\n#model2.fit(X_train, y_train,\n#         eval_set=(X_test, y_test),\n#         verbose_eval=100,\n#         use_best_model=True,\n#         plot=True\n#         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict = np.round((np.exp(model2.predict(X_test))-1)/1000) *1000#\n#y_test_exp = np.exp(y_test)-1\n\n# оцениваем точность\n#print(f\"Точность модели по метрике MAPE: {(mape(y_test_exp, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность модели по метрике MAPE: 16.97%\nМодель с лучшими параметрами  на  X_sub(test) улучшила метрику на 0.5%"},{"metadata":{},"cell_type":"markdown","source":"### Model 3. Стекинг"},{"metadata":{},"cell_type":"markdown","source":"Применим в стекинге  sklearn.StackingRegressor() следующие алгоритмов:  CatBoostRegressor, LinearRegression, KNeighborsRegressor, GradientBoostingRegressor и RandomForestRegressor. И для некоторых попробуем найти оптимальные значения"},{"metadata":{},"cell_type":"markdown","source":"Подбор параметров для RandomForest  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# вычисления закомментированы\nrandom_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)],\n               'max_features': ['auto', 'sqrt'],\n               'max_depth': [int(x) for x in np.linspace(5, 15, num = 6)] + [None],\n               'min_samples_split': [2, 5, 10],\n               'min_samples_leaf': [1, 2, 4],\n               'bootstrap': [True, False]}\n#rf = RandomForestRegressor(random_state = RANDOM_SEED)\n#rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=10, random_state=RANDOM_SEED, n_jobs = -1)\n#rf_random.fit(X_train, y_train)\n#rf_random.best_params_\n\n#best_params_: \n#{'n_estimators': 200,\n #'min_samples_split': 2,\n #'min_samples_leaf': 2,\n #'max_features': 'auto',\n# 'max_depth': None,\n# 'bootstrap': True}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=200, min_samples_split=2, min_samples_leaf=2, \n                            max_features='auto', max_depth=None, bootstrap=True)\n#rf.fit(X_train, y_train)\n\n#predict2 = np.round((np.exp(rf.predict(X_test))-1)/1000) *1000\n#y_test_exp2 = np.exp(y_test)-1\n\n# оцениваем точность\n#print(f\"Точность модели по метрике MAPE: {(mape(y_test_exp2, predict2))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность модели по метрике MAPE: 17.56%"},{"metadata":{},"cell_type":"markdown","source":"Подбор параметров для KNeighborsRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"#knr = KNeighborsRegressor()\n\n#cv = 5\n#grid = {'n_neighbors': [int(x) for x in np.linspace(start = 3, stop = 7, num = 3)],\n        'weights': ['uniform', 'distance'],\n        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n        'leaf_size': [int(x) for x in np.linspace(start = 5, stop = 50, num = 10)]}\n\n#grid_search_result = GridSearchCV(knr, param_grid=grid, cv=cv).fit(X_train, y_train)\n\n#print(grid_search_result.best_params_)\n#{'algorithm': 'auto', 'leaf_size': 40, 'n_neighbors': 7, 'weights': 'distance'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knr = KNeighborsRegressor(algorithm='auto', leaf_size=40, n_neighbors=7, weights='distance', n_jobs=-1)\n#knr.fit(X_train, y_train)\n\n#predict3 = np.round((np.exp(knr.predict(X_test))-1)/1000) *1000\n#predict = np.exp(model.predict(X_test))-1\n#y_test_exp3 = np.exp(y_test)-1\n\n# оцениваем точность\n#print(f\"Точность модели по метрике MAPE: {(mape(y_test_exp3, predict3))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность модели по метрике MAPE: 48.45%"},{"metadata":{},"cell_type":"markdown","source":"Подбор параметров для GradientBoostingRegressor провести не удалось в связи с большей  длительностью данного процесса. Поэтому возьмем параметры по умолчанию, установим только n_estimators=300"},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr = GradientBoostingRegressor(n_estimators=300, random_state=RANDOM_SEED,  warm_start=10,  tol=0.0001)\n#gbr.fit(X_train, y_train)\n\n#predict5 = np.round((np.exp(gbr.predict(X_test))-1)/1000) *1000\n#y_test_exp5 = np.exp(y_test)-1\n\n# оцениваем точность\n#print(f\"Точность модели по метрике MAPE: {(mape(y_test_exp5, predict5))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность модели по метрике MAPE: 21.16%"},{"metadata":{},"cell_type":"markdown","source":"### Стекинг. "},{"metadata":{},"cell_type":"markdown","source":"1 вариант"},{"metadata":{"trusted":true},"cell_type":"code","source":"# вычисления закомментированы для ускорения записи на Kaggle\nestimators=[\n        ('rf1', RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=200, min_samples_split=2, min_samples_leaf=2, \n                            max_features='auto', max_depth=5, bootstrap=True, n_jobs=-1)),\n        ('gbr', GradientBoostingRegressor(n_estimators=300, random_state=RANDOM_SEED,  warm_start=10,  tol=0.0001)),\n        ('knr', KNeighborsRegressor(algorithm='auto', leaf_size=40, n_neighbors=7, weights='distance', n_jobs=-1)),\n            ]\n\nreg1 = StackingRegressor(estimators=estimators,\n     final_estimator = CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = 0.083,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          depth=7,\n                          l2_leaf_reg=1               \n                        )\n                    )\n\n    \n#reg1.fit(X, y)\n\n#predict = np.round((np.exp(reg1.predict(X))-1)/1000) *1000\n#y_test_exp = np.exp(y)-1\n\n# оцениваем точность\n#print(f\"Точность модели по метрике MAPE: {(mape(y_test_exp, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность модели по метрике MAPE: 26.05%"},{"metadata":{},"cell_type":"markdown","source":"2 вариант"},{"metadata":{"trusted":true},"cell_type":"code","source":"# вычисления закомментированы для ускорения записи на Kaggle\nestimators=[\n        ('rf1', RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=200, min_samples_split=2, min_samples_leaf=2, \n                            max_features='auto', max_depth=5, bootstrap=True, n_jobs=-1)),\n        ('gbr', GradientBoostingRegressor(n_estimators=300, random_state=RANDOM_SEED,  warm_start=10,  tol=0.0001)),\n        ('сbr',  CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = 0.083,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          depth=7,\n                          l2_leaf_reg=1)\n        )\n            ]\n\nreg2 = StackingRegressor(estimators=estimators,\n     final_estimator = KNeighborsRegressor(algorithm='auto', leaf_size=40, n_neighbors=7, weights='distance', n_jobs=-1)\n                    )\n\n    \n#reg2.fit(X, y)\n\n#predict = np.round((np.exp(reg2.predict(X))-1)/1000) *1000\n#y_test_exp = np.exp(y)-1\n\n# оцениваем точность\n#print(f\"Точность модели по метрике MAPE: {(mape(y_test_exp, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность модели по метрике MAPE: 17.49%"},{"metadata":{},"cell_type":"markdown","source":"3 вариант"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators=[\n        ('rf1', RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=200, min_samples_split=2, min_samples_leaf=2, \n                            max_features='auto', max_depth=5, bootstrap=True, n_jobs=-1)),\n        ('knr', KNeighborsRegressor(algorithm='auto', leaf_size=40, n_neighbors=7, weights='distance', n_jobs=-1)),\n        ('сbr',  CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = 0.083,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          depth=7,\n                          l2_leaf_reg=1)\n        )\n            ]\n\nreg3 = StackingRegressor(estimators=estimators,\n     final_estimator = GradientBoostingRegressor(n_estimators=300, random_state=RANDOM_SEED,  warm_start=10,  tol=0.0001)\n                    )\n\n    \nreg3.fit(X, y)\n\npredict = np.round((np.exp(reg3.predict(X))-1)/1000) *1000\ny_test_exp = np.exp(y)-1\n\n# оцениваем точность\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test_exp, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Точность модели по метрике MAPE: 12.50%**"},{"metadata":{},"cell_type":"markdown","source":"4 вариант"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators=[\n            ('сbr',  CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = 0.083,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          depth=7,\n                          l2_leaf_reg=1)\n        )\n            ]\n\nreg4 = StackingRegressor(estimators=estimators,\n     final_estimator = GradientBoostingRegressor(n_estimators=300, random_state=RANDOM_SEED,  warm_start=10,  tol=0.0001)\n                    )\n\n    \n#reg4.fit(X, y)\n\n#predict = np.round((np.exp(reg4.predict(X))-1)/1000) *1000\n#y_test_exp = np.exp(y)-1\n\n# оцениваем точность\n#print(f\"Точность модели по метрике MAPE: {(mape(y_test_exp, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Точность модели по метрике MAPE: 12.66%\n\nВидим, что основными алгоритмами в стекинге являются CatBoost и GradientBoosting - использование других алгоритмов дает незначительное улучшение модели "},{"metadata":{},"cell_type":"markdown","source":"По результатам стекинга видно, что так как CatBoost чувствителен к набору признаков,а так же его оптимальные параметры подобраны для обучения на исходном датасете, без дополнительных признаков, полученных от других алгоритмов, то его лучше ставить в базовый набор алгоритмов стекинга.\n\nФинальным (итоговым) алгоритмом стекинга лучше всего ставить бустинг. В данном случае -  GradientBoosting"},{"metadata":{"papermill":{"duration":0.085876,"end_time":"2020-10-26T12:48:12.734207","exception":false,"start_time":"2020-10-26T12:48:12.648331","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Submission"},{"metadata":{},"cell_type":"markdown","source":"Вычислим submission на основе 3-ой модели стекинга"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:48:12.920825Z","iopub.status.busy":"2020-10-26T12:48:12.919528Z","iopub.status.idle":"2020-10-26T12:48:13.047456Z","shell.execute_reply":"2020-10-26T12:48:13.046446Z"},"papermill":{"duration":0.221439,"end_time":"2020-10-26T12:48:13.047693","exception":false,"start_time":"2020-10-26T12:48:12.826254","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"predict_submission = np.round((np.exp(reg3.predict(X_sub))-1)/1000) *1000\npredict_submission ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:48:13.227584Z","iopub.status.busy":"2020-10-26T12:48:13.226285Z","iopub.status.idle":"2020-10-26T12:48:13.762529Z","shell.execute_reply":"2020-10-26T12:48:13.763259Z"},"papermill":{"duration":0.628302,"end_time":"2020-10-26T12:48:13.763488","exception":false,"start_time":"2020-10-26T12:48:13.135186","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"sample_submission['price'] = predict_submission\nsample_submission.to_csv(f'submission_v{VERSION}.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.083769,"end_time":"2020-10-26T12:48:13.930562","exception":false,"start_time":"2020-10-26T12:48:13.846793","status":"completed"},"tags":[]},"cell_type":"markdown","source":"* На лидерборде получили 15.24% Видно что стекинг в целом дает хорошие результаты, но сказываются некоторые различия между тренировочным и тестовым датасетом с каггла: возможно за полтора месяца (разница в собирании датасетов) произошло некоторое изменение цены автомобилей?"},{"metadata":{"papermill":{"duration":0.087712,"end_time":"2020-10-26T12:48:14.104388","exception":false,"start_time":"2020-10-26T12:48:14.016676","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Выводы\nВ итоге видим:\n\n\n* Попытка удаления выбросов в тренировочном датасете метрику не улучшило\n* Добавление новых бинарных признаков несколько ухудшает метрику, но ее улучшает введение полиномиальных\n* Логарифмирование числовых и целевого признаков значительно улучшает метрику\n* Поиск оптимальных параметров CatBoost незначительно улучшает метрику\n* По результатам стекинга видно, что так как CatBoost чувствителен к набору признаков,а так же его оптимальные параметры подобраны для обучения на исходном датасете, без дополнительных признаков, полученных от других алгоритмов, то его лучше ставить в базовый набор алгоритмов стекинга.\n* Финальным (итоговым) аглгоритмом стекинга лучше всего ставить бустинг. В данном случае -  GradientBoosting\n\nПочему-то наилучший результат  на тестовом датасете (из каггла) показало использование только CatBoost с оптимальными параметрами. На тренировочном же датасете лучший результат показывает стекинг, с использованием CatBoost, GradientBoosting, RandomForest и  KNeighborsRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}