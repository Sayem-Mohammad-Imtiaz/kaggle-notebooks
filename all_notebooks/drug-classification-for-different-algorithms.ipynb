{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/drug-classification/drug200.csv\")\n\nfrom sklearn.preprocessing import LabelEncoder\n\ndef label_encoder(y):\n    le = LabelEncoder()\n    data[y] = le.fit_transform(data[y])\n\n#data['Na_to_K_Bigger_Than_15'] = [1 if i >=15.015 else 0 for i in data.Na_to_K]\n#label_list = [\"Sex\",\"BP\",\"Cholesterol\",\"Na_to_K\",\"Na_to_K_Bigger_Than_15\",\"Drug\"]\n\nlabel_list = [\"Sex\",\"BP\",\"Cholesterol\",\"Na_to_K\",\"Drug\"]\n\nfor l in label_list:\n    label_encoder(l)\n    \nX, y = data.drop(['Drug'], axis=1), data['Drug']\ntrain_X, test_X, train_y, test_y= train_test_split(X,y, test_size=0.33, random_state=101)\nprint(train_X.shape)\nprint(test_X.shape)\n\ndata.head()\nfinal_results = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug']\nsns.set_style('darkgrid')\nsns.pairplot(data[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\naxes = pd.plotting.scatter_matrix(data, alpha = 0.3, figsize = (10,7), diagonal = 'kde' ,s=80)\ncorr = data.corr().values\n\nplt.xticks(fontsize =10,rotation =0)\nplt.yticks(fontsize =10)\nfor ax in axes.ravel():\n    ax.set_xlabel(ax.get_xlabel(),fontsize = 15, rotation = 60)\n    ax.set_ylabel(ax.get_ylabel(),fontsize = 15, rotation = 60)\n# put the correlation between each pair of variables on each graph\nfor i, j in zip(*np.triu_indices_from(axes, k=1)):\n    axes[i, j].annotate(\"%.3f\" %corr[i, j], (0.8, 0.8), xycoords=\"axes fraction\", ha=\"center\", va=\"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dt(ccp_alpha):\n    clf = DecisionTreeClassifier(ccp_alpha=ccp_alpha, random_state=0)\n    clf = clf.fit(train_X, train_y)\n    return [ccp_alpha, clf.score(train_X, train_y), clf.score(test_X, test_y)]\n\nclf = DecisionTreeClassifier(random_state=0)\npath = clf.cost_complexity_pruning_path(train_X, train_y)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\n\nprint(len(ccp_alphas), len(impurities))\n\nresults=[]\nfor ccp_alpha in ccp_alphas:\n    results.append(dt(ccp_alpha))\n    \ncolumns=['ccp', 'train_score', 'test_score']\nresults = pd.DataFrame(results, columns=columns)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, results['train_score'], marker='o', label=\"train\",\n        drawstyle=\"steps-post\")\nax.plot(ccp_alphas, results['test_score'], marker='o', label=\"test\",\n        drawstyle=\"steps-post\")\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_result = results.iloc[results['test_score'].idxmax()]\nprint(f'For decision tree, pick ccp_alpha={best_result[\"ccp\"]}, train_score={best_result[\"train_score\"]}, test_scores={best_result[\"test_score\"]}')\n\nfinal_results.append(['decision tree', best_result[\"train_score\"], best_result[\"test_score\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {'n_neighbors':np.arange(1,90),\n        'p':np.arange(1,3),\n        'weights':['uniform','distance']\n       }\n\nknn = KNeighborsClassifier(algorithm = \"auto\")\nknn_cv = GridSearchCV(knn,grid,cv=5)\nknn_cv.fit(train_X,train_y)\n\nprint(\"Hyperparameters:\",knn_cv.best_params_)\nprint(\"Train Score:\",knn_cv.best_score_)\nprint(\"Test Score:\",knn_cv.score(test_X,test_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_results.append(['KNN', knn_cv.best_score_, knn_cv.score(test_X,test_y)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ndef boosted_dt(ccp_alpha):\n    clf = GradientBoostingClassifier(ccp_alpha=ccp_alpha, random_state=0)\n    clf = clf.fit(train_X, train_y)\n    return [ccp_alpha, clf.score(train_X, train_y), clf.score(test_X, test_y)]\n\n#clf = GradientBoostingRegressor(random_state=0)\n#path = clf.cost_complexity_pruning_path(train_X, train_y)\n#ccp_alphas, impurities = path.ccp_alphas, path.impurities\n\nprint(len(ccp_alphas), len(impurities))\n\nresults=[]\nfor ccp_alpha in ccp_alphas:\n    results.append(dt(ccp_alpha))\n    \ncolumns=['ccp', 'train_score', 'test_score']\nresults = pd.DataFrame(results, columns=columns)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nbest_result = results.iloc[results['test_score'].idxmax()]\nprint(f'For GradientBoostingClassifier, pick ccp_alpha={best_result[\"ccp\"]}, train_score={best_result[\"train_score\"]}, test_scores={best_result[\"test_score\"]}')\nfinal_results.append(['GradientBoostingClassifier', best_result[\"train_score\"], best_result[\"test_score\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\n    'C':[0.01,0.1,1,10],\n    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n    'degree' : [1,3,5,7],\n    'gamma' : [0.01,1]\n}\n\nsvm  = SVC ();\nsvm_cv = GridSearchCV(svm, grid, cv = 5)\nsvm_cv.fit(train_X,train_y)\nprint(\"Best Parameters:\",svm_cv.best_params_)\nprint(\"Train Score:\",svm_cv.best_score_)\nprint(\"Test Score:\",svm_cv.score(test_X,test_y))\nfinal_results.append(['Support Vector Machines', svm_cv.best_score_, svm_cv.score(test_X,test_y)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_mlp(hls, alpha):\n    clf = MLPClassifier(activation='identity', alpha=alpha, hidden_layer_sizes=hls, solver='lbfgs', random_state=0, max_iter=200)\n    clf = clf.fit(train_X, np.ravel(train_y, order='C'))\n    #print(clf.score(train_X, train_y), clf.score(test_X, test_y))\n    return [hls, alpha, clf.score(train_X, train_y), clf.score(test_X, test_y)]\n\nresults=[]\nfor hidden_layer_sizes in [(i,) for i in range(1,20)]:\n        results.append(test_mlp(hidden_layer_sizes, 0.0001))\n    \ncolumns=['hidden_layer_sizes',  'alpha', 'train_score', 'test_score']\nresults = pd.DataFrame(results, columns=columns)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nbest_result = results.iloc[results['test_score'].idxmax()]\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_results.append(['Neural Network', best_result[\"train_score\"], best_result[\"test_score\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=['algorithm', 'train_score', 'test_score']\npd.DataFrame(final_results, columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}