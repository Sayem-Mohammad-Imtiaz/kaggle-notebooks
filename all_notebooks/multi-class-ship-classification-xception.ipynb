{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multi Class Ship Classification by Transfer Learning (XCeption)\n\nApplications of autonomous ships and underwater vessels are increasing in the maritime industry.\n\nSome of the applications I can think of for autonomous vessels can be listed as:\n\n* Maritime logistics, \n* Military and rescue operations, \n* Guarding and protecting important bays/marine protected areas/offshore platforms, \n* Oceanographic/hydrograpic surveys, \n* Marine biology research activities,\n* Fish farm observations. \n\nAutonomous vessels need to identify nearby objects in order to conduct these operations safely. There are several sensors and components like 360 cameras, RADAR, automatic identification system (AIS), GPS, echo sounders (SONARs), which can be used onboard autonomous ships to increase situational awareness.\n\nIn this study, I want to focus on image data. From the camera onboard autonomous ships, we can detect and identify nearby objects, especially ships. With the help of computer vision and deep learning algorithms, we can classify different ship types.\n\nIndividual ship types can be compared from the GPS and AIS data to verify that individual ship's identity. Autonomous ships can detect and report illegal fishing or migration boats to the national authorities.\n\nThe dataset used in this study is from Analytics Vidhya. 6252 ship images of 5 classes are divided into train, validation and test splits. Data augmentation is applied in order to increase the model performance. Instead of creating a custom convolutional neural network (CNN), a pre-trained Xception model is used as the base model.\n\nModel is evaluated with the confusion matrix, accuracy, precision, recall and F1 scores.\n\nAt the end of the study, 5 random images from another dataset are used for an additional demonstration of the model performance.\n\nResources\n\nDataset: https://www.kaggle.com/arpitjain007/game-of-deep-learning-ship-datasets\n\nPhoto: https://www.liquid-robotics.com/"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom IPython.display import Image\n\nprint('Example of an autonomous vessel: Liquid Robotics Wave Glider')\ndisplay(Image(\"../input/autonomous-ship-images/liquid_robotics.jpeg\", width=768, height=384))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing the Dataset\n\nThere are 8932 images in the dataset. 6252 of the images are separated for training and only those images are labeled. \n\n6252 labeled images are used in the study and they will be splitted as train, validation and test data.\n\nIn the first part, csv file containing the image names and corresponding ship categories is imported."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_csv = pd.read_csv('../input/game-of-deep-learning-ship-datasets/train/train.csv')\nprint('Data shape: ', data_csv.shape)\n\ncategories = {0: 'Cargo', 1:'Military', 2:'Carrier', 3:'Cruise', 4:'Tankers'}\n\n# I want classes to start from 0. So I subtracted 1 from the categories\ndata_csv['category'] = data_csv['category'] - 1\ndata_csv['label'] = data_csv['category'].map(categories)\ndata_csv['label']  = pd.Categorical(data_csv['label'])\ndata_csv.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As one can see from the graph below, the dataset is not equally distributed between the categories. Because this is not an academic study or part of an industry project, I am not going to manipulate the dataset. I will use all the images."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.countplot(data_csv['label'])\nplt.title('Ship Category Distribution')\nplt.xlabel('Categories')\nplt.ylabel('Counts of Observations');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to import the images, first of all file path is defined. \n\nThen each image name from the csv file is extracted in a loop and corresponding image is read. \n\nLater, each image is converted into RGB format and resized to have the same dimensions.\n\nLastly, each image is saved to a list in Numpy array format."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the images.\n\nimport cv2\n\npath = '../input/game-of-deep-learning-ship-datasets/train/images/'\n\n# List of image names\nimg_list = list(data_csv['image'])\n\ndata_img = []\n\nfor each in img_list:\n    # Each image path\n    each_path = os.path.join(path, each)\n    # Read each image\n    each_img = cv2.imread(each_path)\n    # OpenCv default color is BGR. Convert it to RGB\n    each_img = cv2.cvtColor(each_img, cv2.COLOR_BGR2RGB)\n    # Resize the images\n    each_img_resized = cv2.resize(each_img, (128,128))\n    # Save arrays to a list\n    data_img.append(each_img_resized)\n\n# Converting list to numpy array\nX = np.array(data_img)\nprint('Shape of X: ', X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Labels from the csv file is extracted and one hot encoding is applied to have a target feature (dependent variable)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ny = OneHotEncoder(dtype='int8', sparse=False).fit_transform(data_csv['category'].values.reshape(-1,1))\nprint('Shape of y: ', y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at some random images and their labels."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"indices = np.random.randint(0,6252,8) \ni = 1\nplt.figure(figsize=(14,7))\nfor each in indices:\n    plt.subplot(2,4,i)\n    plt.imshow(X[each])\n    plt.title(data_csv['label'].loc[each])\n    plt.xticks([])\n    plt.yticks([])\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train, Validation and Test Split\n\nThe dataset is divided into train, validation and test splits."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_data, X_test, y_data, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n\nprint('X_train shape: ', X_train.shape)\nprint('y_train shape: ', y_train.shape)\nprint('X_val shape  : ', X_val.shape)\nprint('y_val shape  : ', y_val.shape)\nprint('X_test shape : ', X_test.shape)\nprint('y_test shape : ', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation\n\nData augmentation is applied to the training and validation data. With the help of data augmentation, the model is fed with random images with random differences. That way, the model is trained with more data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_gen = ImageDataGenerator(horizontal_flip=True,\n                               rotation_range = 45,\n                               zoom_range=0.2,\n                               height_shift_range = 0.5,\n                               width_shift_range = 0.5)\n\nvalidation_gen = ImageDataGenerator(horizontal_flip=True,\n                               rotation_range = 45,\n                               zoom_range=0.2,\n                               height_shift_range = 0.5,\n                               width_shift_range = 0.5)\n\ntrain_gen.fit(X_train)\nvalidation_gen.fit(X_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Model with Xception\n\nInstead of building a custom CNN model, pre-trained Xception model is used as our base model. \n\nGlobal average pooling method is chosen before the classifier dense layer.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.optimizers import Adam\n\n# Defining batch and epoch sizes\nbatch_size = 100\nepochs = 15\n\n# Defining the pretrained base model\nbase = Xception(include_top=False, weights='imagenet', input_shape=(128,128,3))\nx = base.output\nx = GlobalAveragePooling2D()(x)\n# Defining the head of the model where the prediction is conducted\nhead = Dense(5, activation='softmax')(x)\n# Combining base and head \nmodel = Model(inputs=base.input, outputs=head)\n\n# Compiling the model\nmodel.compile(optimizer=Adam(lr=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics=['accuracy'])\n\n# Fitting the model with train and validation augmented datasets.\nhistory = model.fit_generator(train_gen.flow(X_train, y_train, batch_size=batch_size),\n                              epochs = epochs,\n                              validation_data = validation_gen.flow(X_val, y_val, batch_size=batch_size),\n                              steps_per_epoch = X_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\n\nplt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplt.plot(history_df['loss'], label='training loss')\nplt.plot(history_df['val_loss'], label='validation loss')\nplt.title('Model Loss Function')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(history_df['accuracy'], label='training accuracy')\nplt.plot(history_df['val_accuracy'], label='validation accuracy')\nplt.title('Model Accuracy')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting Test Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Predicting labels from X_test data\ny_pred = model.predict(X_test)\n\n# Converting prediction classes from one hot encoding to list\n# Argmax returns the position of the largest value\ny_pred_classes = np.argmax(y_pred, axis = 1)\n\n# Convert test labels from one hot encoding to list\ny_test_classes = np.argmax(y_test, axis = 1)\n\n# Create the confusion matrix\nconfmx = confusion_matrix(y_test_classes, y_pred_classes)\nf, ax = plt.subplots(figsize = (8,8))\nsns.heatmap(confmx, annot=True, fmt='.1f', ax = ax)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing the model scores:\nprint(classification_report(y_test_classes, y_pred_classes))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see model scores for each categories. The model's performance is good enough with 0.91 accuracy and F1 score.\n\nNow let's use the model with 5 random images."},{"metadata":{},"cell_type":"markdown","source":"## Trying the Model with Some Images"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"test_img = pd.read_csv('../input/game-of-deep-learning-ship-datasets/test_ApKoW4T.csv')\nsample_img = test_img.sample(5)\n\n# List of image names\nimg_list = list(sample_img['image'])\n\nsample_img_data = []\n\nfor each in img_list:\n    # Each images' path\n    each_path = os.path.join(path, each)\n    # Read each image\n    each_img = cv2.imread(each_path)\n    # OpenCv default color is BGR. Convert it to RGB\n    each_img = cv2.cvtColor(each_img, cv2.COLOR_BGR2RGB)\n    # Resize the images\n    each_img_resized = cv2.resize(each_img, (128,128))\n    # Save arrays to a list\n    sample_img_data.append(each_img_resized)\n\n# Converting list to numpy array\nsample_img_data = np.array(sample_img_data)\nprint('Shape of X: ', sample_img_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting random 5 images\nsample_pred = model.predict(sample_img_data)\nsample_classes = np.argmax(sample_pred, axis = 1)\n\n# Visualizing the predictions\ni = 0\nplt.figure(figsize=(18,9))\nfor each in range(4):\n    i += 1\n    plt.subplot(2,4,i)\n    plt.imshow(sample_img_data[each])\n    plt.xlabel('PREDICTION: ' + str(categories[sample_classes[each]]))\n    plt.xticks([])\n    plt.yticks([])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I hope you liked this study and learned something new. Feel free to add your opinions, ask questions in the comment section.\n\nMelih"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}