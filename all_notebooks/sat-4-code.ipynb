{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import csv\nimport pandas as pd\nimport numpy as np\nfrom numpy.random import randint, random, normal\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filenames\nlabel_table = pd.read_csv(dirname+ '/' +'sat4annotations.csv', header=None)\nlabel_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\nBATCH_SIZE = 64\nIMG_SHAPE = 28, 28, 4\n\nTRAIN_NUM, TEST_NUM = 400000, 100000  # from the dataset site\ntrain_steps, test_steps = TRAIN_NUM // BATCH_SIZE, TEST_NUM // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_gen(x_csv_path, y_csv_path, batch_size=BATCH_SIZE,\n            img_shape=IMG_SHAPE, labels_num=6, augment=False):\n  \"\"\"\n  Return a generator.\n  \n  This function returns a data generator. Every time the generator is called\n  it yields one batch of pairs (images, labels).\n  \"\"\"\n  xf, yf = open(x_csv_path), open(y_csv_path)\n  x_reader, y_reader = csv.reader(xf, delimiter=\",\"), csv.reader(yf, delimiter=\",\")\n\n  while True:\n    imgs = np.zeros((batch_size, *img_shape))\n    labels = np.zeros((batch_size, labels_num))\n\n    for i in range(batch_size):\n\n      try:\n        x_line, y_line = next(x_reader), next(y_reader)\n      except:\n        # this except clause resets the line readers when they reach the end of the files\n        xf.close()\n        yf.close()\n        xf, yf = open(x_csv_path), open(y_csv_path)\n        x_reader, y_reader = csv.reader(xf, delimiter=\",\"), csv.reader(yf, delimiter=\",\")\n        x_line, y_line = next(x_reader), next(y_reader)\n\n      img = np.reshape(list(map(int, x_line)), img_shape)\n      img = preprocess_img(img, augment)\n      imgs[i] = img\n\n      label = np.array(list(map(int, y_line)))\n      labels[i] = label\n\n    yield imgs, labels\n\n\ndef preprocess_img(img, augment=False):\n  \"\"\"\n  Preprocess the images.\n  \n  Takes as input an image and a boolean value (augment).\n  The standard preprocess includes only division by 255.0 (which maps from [0, 255] to [0.0, 1.0]).\n  \"\"\"\n  img = img / 255.0\n  if augment:\n    img = augment_img(img)\n  \n  return img\n\n\ndef augment_img(img):\n  \"\"\"\n  Augment an image.\n  \n  Image augmentation is useful in order to avoid overfitting.\n  This function adds random (normal) noise and randomly flip and/or rotate each image.\n  \"\"\"\n  # add noise\n  gauss = normal(0, 0.05, img.shape)\n  img = img + gauss\n  img = np.clip(img, 0, 1)\n\n  # rotate 0/90/180/270\n  img = np.rot90(img, randint(0, 3), axes=(0, 1))\n\n  # flip/no-flip orizontaly/vertical\n  if random() < 0.5: img = img[:, ::-1, :]\n  if random() < 0.5: img = img[::-1, :, :]\n\n  return img\n\n\ndef plot_images(images, labels=None, preds=None):\n  \"\"\"\n  Plot a batch of images and labels.\n  \n  This function plots a sample of images from the dataset along with their labels as image header.\n  If preds is given the header is real label/predicted label.\n  \"\"\"\n  c = 8\n  labels = np.argmax(labels, -1) if labels is not None else labels\n  r = int(len(images) / c)\n  if preds is not None: preds = np.argmax(preds, -1)\n  fig, axs = plt.subplots(r, c, figsize=(16, 16))\n  cnt = 0\n  for i in range(r):\n    for j in range(c):\n      axs[i, j].imshow(images[cnt, ..., :3], cmap='gray')\n      axs[i, j].axis('off')\n      if labels is not None:\n        title = label_names[labels[cnt]] if preds is None else '%s/%s' % (label_names[labels[cnt]],\n                                                                        label_names[preds[cnt]])\n        axs[i, j].set_title(title, fontsize=12 if preds is None else 8)\n      cnt += 1\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = get_gen('X_train_sat4.csv', 'y_train_sat4.csv', augment=True)\ntest_gen = get_gen('X_test_sat4.csv', 'y_test_sat4.csv')\n\nlabel_names = list(pd.read_csv('/kaggle/input/deepsat-sat4/sat4annotations.csv', header=None)[0])\nprint('label names:\\n%s' % ', '.join(label_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ['barren_land','trees', 'grassland','none']\ntraining_labels = pd.read_csv(dirname+ '/' + 'y_train_sat4.csv', header=None)\ntraining_labels.columns = classes\ntraining_labels[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perc_of_class_train = {x: round(training_labels[x].sum()/400000, 3) * 100 for (i, x) in enumerate(classes)}\nplt.bar(range(len(perc_of_class_train)), list(perc_of_class_train.values()), align='center')\nplt.xticks(range(len(perc_of_class_train)), list(perc_of_class_train.keys()))\nplt.ylabel('Percent of Class')\nplt.xlabel('Classes')\nplt.title('Representation of Classes in Training Set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perc_of_class_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = pd.read_csv(dirname+ '/' +'y_test_sat4.csv', header=None)\ntest_labels.columns = classes\nperc_of_class_test = {x: round(test_labels[x].sum()/100000, 3) * 100 for (i, x) in enumerate(classes)}\nplt.bar(range(len(perc_of_class_test)), list(perc_of_class_test.values()), align='center')\nplt.xticks(range(len(perc_of_class_test)), list(perc_of_class_test.keys()))\nplt.ylabel('Percent of Class')\nplt.xlabel('Classes')\nplt.title('Representation of Classes in Test Set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perc_of_class_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.read_csv(dirname+ '/''X_train_sat4.csv', header=None, nrows=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def row_to_img(row_values, ir=False):\n    if ir:\n        return row_values.reshape(-1, 28, 28, 4).clip(0, 255).astype(np.uint8).squeeze(axis=0)[:,:,-1]\n    else:\n        return row_values.reshape(-1, 28, 28, 4).clip(0, 255).astype(np.uint8).squeeze(axis=0)[:,:,:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_labels(row_values):\n    annotations = ['barren_land','trees', 'grassland', 'none']\n    labels = [annotations[i] for i, x in enumerate(row_values) if x == 1]\n    return labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(5, 5, figsize = (20, 20))\nfor i, ax in enumerate(axs.flatten()):\n    ax.set_title(get_labels(training_labels.iloc[i].values))\n    ax.imshow(row_to_img(X_train.iloc[i].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(5, 5, figsize = (20, 20))\nfor i, ax in enumerate(axs.flatten()):\n    ax.set_title(get_labels(training_labels.iloc[i].values))\n    ax.imshow(row_to_img(X_train.iloc[i].values, ir=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = X_train.copy()\nsample['labels'] = [get_labels(x.values) for i, x in training_labels[:300].iterrows()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=2)\ncomponents = pd.DataFrame(pca.fit_transform(sample.drop('labels', axis=1)), columns=['component_1', 'component_2'])\ncomponents['labels'] = sample['labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"components.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subsets = [components.loc[components['labels'] == x] for x in classes]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (10,10))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('PCA of SAT-6', fontsize = 20)\n\ncolor_map = { 'barren_land': '#011627', 'trees': '#F71735', 'grassland': '#41EAD4', 'none': '#5AFF15'}\n\nfor subset in subsets:\n    label = subset['labels'].values.tolist()[0]\n    ax.scatter(x=subset['component_1'], y=subset['component_2'], s=50, c=color_map[label])\n\nax.legend(color_map.keys())\nax.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_95 = PCA(n_components=0.95, svd_solver='full')\ncomponents_95 = pca_95.fit_transform(sample.drop('labels', axis=1))\ncomponents_95.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne = TSNE(n_components=2, perplexity=32)\ncomponents = pd.DataFrame(tsne.fit_transform(sample.drop('labels', axis=1)), columns=['component_1', 'component_2'])\ncomponents['labels'] = sample['labels']\ncomponents.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subsets = [components.loc[components['labels'] == x] for x in classes]\nfig = plt.figure(figsize = (10,10))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('TSNE of SAT-6', fontsize = 20)\n\ncolor_map = { 'barren_land': '#011627', 'trees': '#F71735', 'grassland': '#41EAD4', 'none': '#5AFF15'}\n\nfor subset in subsets:\n    label = subset['labels'].values.tolist()[0]\n    ax.scatter(x=subset['component_1'], y=subset['component_2'], s=50, c=color_map[label])\n\nax.legend(color_map.keys())\nax.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nnp.random.seed(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(verbose=True)\nX = components_95\ny = sample['labels']\nX_train, X_test, y_train, y_test = train_test_split(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\nprint(classification_report(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With precision 89% and overall accuracy of 77% my classifier has successfully classified all scenes of SAT-4 dataset. SAT-4 has 4 classes which are barren land, grass land, tress and none. Future task should be improvement in the overall accuracy."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}