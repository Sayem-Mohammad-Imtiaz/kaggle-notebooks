{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\nfrom sklearn.metrics import classification_report # for accuracy and F1 score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the data into a pandas dataframe\nhealth_df = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\nhealth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the id column since we don't need it.\nhealth_df.drop('id', axis = 1,inplace = True)\nhealth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find null data\nhealth_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see how many datapoints are null and if small delete those rows\nprint(f\"% BMI missing  {(health_df['bmi'].isnull().sum()/health_df.shape[0])*100:0.2f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove null rows\nhealth_df.dropna(axis = 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check gender data \nhealth_df.gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove \"Other\"\nhealth_df.drop(health_df[health_df[\"gender\"] == \"Other\"].index, axis = 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classify BMI as group\nhealth_df['bmi_group'] = 0 # create new column\nfor i in range(len(health_df.index)):\n    if health_df.iloc[i, 8] < 18.5:\n        health_df.iloc[i, 11] = 'Underweight'\n    elif health_df.iloc[i, 8] < 25.0 and health_df.iloc[i, 8] >= 18.5:\n        health_df.iloc[i, 11] = 'Normal weight'\n    elif health_df.iloc[i, 8] < 30.0 and health_df.iloc[i, 8] >= 25.0:\n        health_df.iloc[i, 11] = 'Overweight'\n    else:\n        health_df.iloc[i, 11] = 'Obese'\n        \nhealth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health_df.bmi_group.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classify glucose as group\nhealth_df['glucose_group'] = 0 # create new column\nfor i in range(len(health_df.index)):\n    if health_df.iloc[i, 7] < 100.0:\n        health_df.iloc[i, 12] = 'Normal'\n    elif health_df.iloc[i, 7] >= 100.0 and health_df.iloc[i, 7] < 125.0:\n        health_df.iloc[i, 12] = 'Prediabetes'\n    else:\n        health_df.iloc[i, 12] = 'Diabetes'\n\nhealth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health_df.glucose_group.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform string lables into numeric ones\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nhealth_df[\"gender\"] = le.fit_transform(health_df[\"gender\"])\nhealth_df[\"ever_married\"] = le.fit_transform(health_df[\"ever_married\"])\nhealth_df[\"work_type\"] = le.fit_transform(health_df[\"work_type\"])\nhealth_df[\"Residence_type\"] = le.fit_transform(health_df[\"Residence_type\"])\nhealth_df[\"smoking_status\"] = le.fit_transform(health_df[\"smoking_status\"])\nhealth_df[\"bmi_group\"] = le.fit_transform(health_df[\"bmi_group\"])\nhealth_df[\"glucose_group\"] = le.fit_transform(health_df[\"glucose_group\"])\n\nhealth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assigning values and spliting test & train\nX = health_df.drop(['stroke', 'avg_glucose_level', 'bmi'], axis = 1)\ny = health_df['stroke']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(kernel='linear')\nsvc.fit(X_train, y_train)\noutcome_SVC = svc.predict(X_test)\n\nprint(classification_report(y_test, outcome_SVC))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 3)\nclf = clf.fit(X_train, y_train)\noutcome_DTC = clf.predict(X_test)\n\nprint(classification_report(y_test, outcome_DTC))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators = 100)\nforest_fit = forest.fit(X_train, y_train)\noutcome_forest = forest.predict(X_test)\n\nprint(classification_report(y_test, outcome_forest))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier\nxgb = XGBClassifier(n_estimators = 100, learning_rate = 0.1,\n                    max_depth = 5, subsample = 1, gamma = 0,\n                    reg_lambda = 1, max_delta_step = 0, colsample_bytree = 1,\n                    min_child_weight = 1, seed = 1000)\nxgb_fit = xgb.fit(X_train, y_train)\noutcome_xgb = xgb.predict(X_test)\n\nprint(classification_report(y_test, outcome_xgb))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Export file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df_1.to_csv('submission_1.csv', index=False) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}