{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","file_extension":".py","version":"3.6.0","nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"name":"python"}},"cells":[{"outputs":[],"metadata":{"_uuid":"d38ba4b329c8ad9e93ef6b7952854d6660e4201e"},"source":"# Detecting communities\nAfter having read paper \"Fast unfolding of communities in large networks\" written by Vincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte and Etienne Lefebvre, I was feeling like trying it on some dataset.\n\n<b>Resources:</b>\n\n- Paper: https://arxiv.org/abs/0803.0476\n\n- \"Python-louvain\" implementation: http://perso.crans.org/aynaud/communities/","cell_type":"markdown","execution_count":null},{"outputs":[],"metadata":{"_uuid":"46f9221eef82e79caae63c0f8eff6d8270a865ba"},"source":"## Import packages\nLet's import all packages we need.","cell_type":"markdown","execution_count":null},{"outputs":[],"metadata":{"collapsed":true,"_uuid":"ad333c78901dfafa548ed40e4394bb2edfb9ba55"},"execution_count":null,"cell_type":"code","source":"# SQL\nimport sqlite3\n\n# Pandas\nimport pandas as pd\n\n# Graph\nimport community\nimport networkx as nx\n\n# Plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Combinations\nimport itertools"},{"outputs":[],"metadata":{"_uuid":"a687cc5760b85296c66a528d913ba6dc27ea5320"},"source":"## Get data\nI am just gonna consider NIPS papers of year 2014 and 2015.","cell_type":"markdown","execution_count":null},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"6821a0dba1cd94e0a8ecc43c87512b8793043aaf"},"execution_count":null,"cell_type":"code","source":"# Get data\nconnect = sqlite3.connect('../input/database.sqlite')\nquery = \"\"\"\nSELECT pa.paper_id, pa.author_id, a.name\nFROM paper_authors AS pa JOIN papers AS p ON pa.paper_id = p.id\nJOIN authors as a ON pa.author_id = a.id\nWHERE p.Year BETWEEN '2014' AND '2015'\n\"\"\"\ndf = pd.read_sql(query, connect)\n\n# Have a look at data\ndf.head(10)"},{"outputs":[],"metadata":{"_uuid":"1e0457af703ee68af9114b4c4cde54b93cf69c4f"},"source":"## Create graph","cell_type":"markdown","execution_count":null},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"f20aacf7883f3ccca5384f5e9c927a8ab586d93a"},"execution_count":null,"cell_type":"code","source":"# Initialize graph\nG = nx.Graph()\n\n# Transform\n# REMARK: The algorithm seems more stable by doing '*=2' than '+=1'\n# REMARK: I use 'name' instead of 'author_id' for label purposes.\nfor p, a in df.groupby('paper_id')['name']: \n    for u, v in itertools.combinations(a, 2):\n        if G.has_edge(u, v):\n            G[u][v]['weight'] *= 2\n        else:\n            G.add_edge(u, v, weight=1)\n            \n# Print graph size\nprint('\\nSize of graph, i.e. number of edges:', G.size())"},{"outputs":[],"metadata":{"_uuid":"ecb10d58e18f484e934b4795ea46f1d9ee36649d"},"source":"## Compute best partition","cell_type":"markdown","execution_count":null},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"b290767f040369a1df22a543574978db88223d44"},"execution_count":null,"cell_type":"code","source":"# Get best partition\npartition = community.best_partition(G)\nprint('Modularity: ', community.modularity(partition, G))"},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"3bfd7607bd1f267da4df38ef37243e1ca9cff0dc"},"execution_count":null,"cell_type":"code","source":"# Draw graph\nplt.figure(figsize=(13, 9))\nsize = float(len(set(partition.values())))\npos = nx.spring_layout(G)\ncount = 0\nfor com in set(partition.values()) :\n    count = count + 1\n    list_nodes = [nodes for nodes in partition.keys() if partition[nodes] == com]\n    nx.draw_networkx_nodes(G, pos, list_nodes, node_size = 20, node_color = str(count / size))\nnx.draw_networkx_edges(G, pos, alpha=0.5)\nplt.axis('off')\nplt.show()"},{"outputs":[],"metadata":{"_uuid":"6af677dc0b0fe6fa13a105a72ce3dc8fe87c0aa8"},"source":"## Filter communities\nLet's have a look at the largest communities detected. The ones with more than 30 members.","cell_type":"markdown","execution_count":null},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"7dd68687186ec9a346a1ee655c8161968ada089f"},"execution_count":null,"cell_type":"code","source":"# Keep only communities with a minimum of authors\ncenters = {}\ncommunities = {}\nG_main_com = G.copy()\nmin_nb = 30\nfor com in set(partition.values()) :\n    list_nodes = [nodes for nodes in partition.keys() if partition[nodes] == com]\n    if len(list_nodes) < min_nb:\n        G_main_com.remove_nodes_from(list_nodes)\n    else:\n        # Get center\n        H = G_main_com.subgraph(list_nodes)\n        d_c = nx.degree_centrality(H)\n        center = max(d_c, key=d_c.get)\n        centers[center] = com\n        communities[com] = center\n        # Print community\n        print('Community of ', center , '(ID ', com, ') - ', len(list_nodes), ' authors:')\n        print(list_nodes, '\\n')"},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"8e904b8e8351af12e4ad247f8798a6546f88b4f6"},"execution_count":null,"cell_type":"code","source":"# Display graph\nplt.figure(figsize=(13, 9))\nnode_size = 50\ncount = 0\npos = nx.spring_layout(G_main_com)\ncolors = dict(zip(communities.keys(), sns.color_palette('hls', len(communities.keys()))))\n\nfor com in communities.keys():\n    count = count + 1\n    list_nodes = [nodes for nodes in partition.keys() if partition[nodes] == com and nodes not in communities.values()]\n    nx.draw_networkx_nodes(G_main_com, pos, list_nodes, node_size = node_size, node_color = colors[com])\n    nx.draw_networkx_nodes(G_main_com, pos, list([communities[com]]), node_size = node_size*5, node_color = colors[com])\nnx.draw_networkx_edges(G_main_com, pos, alpha=0.5)\nlabels = {k: str(v) + ': ' + k for k,v in centers.items()}\nnx.draw_networkx_labels(G_main_com, pos, labels)\nplt.axis('off')\nplt.show()"},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"69f2095753e69a389eecf5baa44eeb1cdce5d123"},"execution_count":null,"cell_type":"code","source":"# Display induced graph\nnodes_main_com = {k: v for k, v in partition.items() if v in communities}\nind = community.induced_graph(nodes_main_com, G_main_com)\nprint('Number of communities', len(ind.nodes()))\nprint('\\nMain communities and their center node:', communities)"},{"outputs":[],"metadata":{"_uuid":"dcde28e776e9e5f52b3bef4cda9251ff1573b6ec"},"source":"## Display induced graph\nLet's now look at the induced graph, i.e. the graph of communities.","cell_type":"markdown","execution_count":null},{"outputs":[],"metadata":{"collapsed":false,"_uuid":"f890425bde92cc1d16e6f4d79a4c5847c3a6ecf1"},"execution_count":null,"cell_type":"code","source":"# Display induced graph\npos_ind = nx.spring_layout(ind)\nlabels = {k: str(k) + ': ' + v for k,v in communities.items()}\nnx.draw(ind, pos_ind, node_list=list(colors.keys()), node_color=list(colors.values()), labels=labels)\nplt.show()"},{"outputs":[],"metadata":{"_uuid":"1f1d219f6a03444a1baacc91499812503451d5a4"},"source":"A next step might be to analyze the papers by community (word count,...).","cell_type":"markdown","execution_count":null}],"nbformat":4,"nbformat_minor":2}