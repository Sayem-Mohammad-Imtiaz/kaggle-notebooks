{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import the necessary packages\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation, LSTM, ConvLSTM2D, Lambda, Reshape, BatchNormalization, Bidirectional\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\nimport shutil\nimport cv2\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = './dataset'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\nrm -rf dataset\nmkdir -p dataset/covid\nmkdir -p dataset/pneumonia\nmkdir -p dataset/normal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build Covid xray dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_dataset_path = '../input/covid-chest-xray'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct the path to the metadata CSV file and load it\ncsvPath = os.path.sep.join([covid_dataset_path, \"metadata.csv\"])\ndf = pd.read_csv(csvPath)\n\n# loop over the rows of the COVID-19 data frame\nfor (i, row) in df.iterrows():\n    # if (1) the current case is not COVID-19 or (2) this is not a 'PA' view, then ignore the row\n    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n        continue\n\n    # build the path to the input image file\n    imagePath = os.path.sep.join([covid_dataset_path, \"images\", row[\"filename\"]])\n\n    # if the input image file does not exist ignore the row\n    if not os.path.exists(imagePath):\n        continue\n\n    # extract the filename from the image path and then construct the path to the copied image file\n    filename = row[\"filename\"].split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/covid\", filename])\n\n    # copy the image\n    shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir('../working/dataset/covid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = 140","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build normal xray dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pneumonia_dataset_path ='../input/chest-xray-pneumonia/chest_xray'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"NORMAL\"])\nimagePaths = list(paths.list_images(basePath))\n\n# randomly sample the image paths\nrandom.seed(42)\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:samples]\n\nfor (i, imagePath) in enumerate(imagePaths):\n    filename = imagePath.split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n\n    # copy the image\n    shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir('../working/dataset/normal'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build pneumonia xray dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"PNEUMONIA\"])\nimagePaths = list(paths.list_images(basePath))\n\n# randomly sample the image paths\nrandom.seed(42)\nrandom.shuffle(imagePaths)\nimagePaths = imagePaths[:samples]\n\n# loop over the image paths\nfor (i, imagePath) in enumerate(imagePaths):\n    # extract the filename from the image path and then construct the\n    # path to the copied image file\n    filename = imagePath.split(os.path.sep)[-1]\n    outputPath = os.path.sep.join([f\"{dataset_path}/pneumonia\", filename])\n\n    # copy the image\n    shutil.copy2(imagePath, outputPath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir('../working/dataset/pneumonia'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot x-rays","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def ceildiv(a, b):\n    return -(-a // b)\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    f = plt.figure(figsize=(40,20))\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=26)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=26)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img, cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_images = list(paths.list_images(f\"{dataset_path}/normal\"))\ncovid_images = list(paths.list_images(f\"{dataset_path}/covid\"))\npneumonia_images = list(paths.list_images(f\"{dataset_path}/pneumonia\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_from_files(normal_images, rows=8, maintitle=\"Normal X-ray images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_from_files(covid_images, rows=8, maintitle=\"Covid-19 X-ray images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_from_files(pneumonia_images, rows=8, maintitle=\"Pneumonia X-ray images\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_to_label_map = {'pneumonia' : 2, 'covid' : 1, 'normal' : 0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagePaths = list(paths.list_images(dataset_path))\ndata = []\nlabels = []\nfor imagePath in imagePaths:\n    # extract the class label from the filename\n    label = imagePath.split(os.path.sep)[-2]\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (224, 224))\n    data.append(image)\n    labels.append(class_to_label_map[label])\n    \n# convert the data and labels to NumPy arrays while scaling the pixel intensities to the range [0, 1]\ndata = np.array(data) / 255.0\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)\ntrainAug = ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dims = 224\nINIT_LR = 1e-3\nEPOCHS = 30\nBS = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input layer\ninputs = Input(shape=(img_dims, img_dims, 3))\n\n# 1st conv block\nx = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(inputs)\nx = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# 2nd conv block\nx = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# 3rd conv block\nx = Conv2D(filters=256, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = Conv2D(filters=256, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# 4th conv block\nx = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# 5th conv block\nx = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', trainable=False, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = AveragePooling2D(pool_size=(4, 4))(x)\n\n# LSTM layer\nx = Reshape((1, 512))(x)\nx = ((LSTM(512, activation=\"relu\", return_sequences=True)))(x)\n\n# FC layer\nx = Flatten(name=\"flatten\")(x)\nx = Dense(units=64, activation='relu')(x)\nx = Dropout(0.5)(x)\n\n# Output layer\noutput = Dense(units=3, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=output)\n\n# compile our model\nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"H = model.fit_generator(\n    trainAug.flow(trainX, trainY, batch_size=BS),\n    steps_per_epoch=len(trainX) // BS,\n    validation_data=(testX, testY),\n    validation_steps=len(testX) // BS,\n    epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot trining metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"N = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(10, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(H.history[met])\n    ax[i].plot(H.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(testX, batch_size=BS)\ntest_result = np.argmax(testY, axis=1)\nprediction_result = np.argmax(prediction, axis=1)\nconfusion__matrix=confusion_matrix(test_result, prediction_result)\nprint(classification_report(test_result, prediction_result, target_names=class_to_label_map))\nprint(confusion__matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}