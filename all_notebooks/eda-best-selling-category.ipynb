{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the csv file\ndata = pd.read_csv('/kaggle/input/pakistans-largest-ecommerce-dataset/Pakistan Largest Ecommerce Dataset.csv')\ndf = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Data Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing / NaN values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Doing a visual inspection of all columns\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- Out of 26 columns, last 5 columns in the dataset contain NaN values for all records\n- Records at 464051 indices (from the bottom) contain NaN values for all columns\n- ' MV ' is an ambiguous column name with extra spaces\n- Some of the columns have incorrect data types\n\n##### Actions\n- Last 5 columns need to be dropped from the dataset\n- 464051 rows, containing NaN values need to be dropped from the dataset\n- Renamed the columns ' MV ' and 'category_name_1' to 'MV' and 'category_name'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"Unnamed: 21\", \"Unnamed: 22\", \"Unnamed: 23\", \"Unnamed: 24\", \"Unnamed: 25\"], axis = 1, inplace=True)\ndf.dropna(subset=[\"item_id\"], axis=0, inplace=True)\ndf.rename(columns={\" MV \": \"MV\", \"category_name_1\": \"category_name\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dropping duplicate entries, if any, from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Basic data quality and integrity checks"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of rows with negative or zero Quantity:\",sum(n <= 0 for n in df.qty_ordered))\nprint(\"The number of rows with negative Price:\",sum(n < 0 for n in df.price))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Convert all values in 'sku' column to upper case for uniformity"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sku']=df['sku'].str.upper()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exploring all columns, finding and Imputing Null Values\n#### Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- There are a lot of labels for 'status' column.\n- Need to check if any relationship exists between 'status' and 'BI Status' columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('BI Status')['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- All transactions marked as either **'complete' or 'closed'**, fall in the **'Net' category** for 'BI Status'\n- All transactions marked as **'received','paid','cod','exchanged' or something related to refund** are marked in **'Valid' category**\n- All transactions marked as **either 'canceled' or something to do with incomplete transation** are marked in **'Gross' category**\n- '#REF!' looks an erroneus label.\n\n##### Actions\n**Replace values inside the 'status' column by creating new labels**\n\n- **'complete','closed','received','paid','cod'** will belong to category **'Completed'**\n- **'order_refunded','refund', 'exchange'** will belong to category **'Refund'**\n- **'pending','payment_review','processing','holded','pending_paypal','\\N'** will beling to **'Pending'**\n- **'canceled'** will belong to **'Cancelled'**\n- **'fraud'** will belong to **'Fraud'**\n**Also replace the '#REF!'' entry to 'Net' in 'BI status'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'] = df['status'].replace('complete', 'Completed')\ndf['status'] = df['status'].replace('closed', 'Completed')\ndf['status'] = df['status'].replace('received', 'Completed')\ndf['status'] = df['status'].replace('paid', 'Completed')\ndf['status'] = df['status'].replace('cod', 'Completed')\ndf['status'] = df['status'].replace('order_refunded', 'Refund')\ndf['status'] = df['status'].replace('refund', 'Refund')\ndf['status'] = df['status'].replace('exchange', 'Refund')\ndf['status'] = df['status'].replace('pending', 'Pending')\ndf['status'] = df['status'].replace('payment_review', 'Pending')\ndf['status'] = df['status'].replace('processing', 'Pending')\ndf['status'] = df['status'].replace('holded', 'Pending')\ndf['status'] = df['status'].replace('pending_paypal', 'Pending')\ndf['status'] = df['status'].replace(r'\\\\N', 'Pending', regex=True)\ndf['status'] = df['status'].replace('fraud', 'Fraud')\ndf['status'] = df['status'].replace('canceled', 'Cancelled')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BI Status'] = df['BI Status'].replace('#REF!', 'Net')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BI Status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Handling Null values in 'status' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['status'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observation\n- 15 NaN values in 'status' column have 'Gross' in the BI column meaning all these transactions are not valid\n\n##### Actions\n- Replacing NaN values with label **'Cancelled'** in line with our understanding of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'].fillna(\"Cancelled\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling NaN values in 'category_name' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['category_name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- There are 164 NaN values in the **'category_name'** column that can be filled using some information from **'sku'** column. Not doing it right now\n- 7850 transactions have a unicode label associated with them.\n- 164 transactions have NaN values.\n\n##### Actions\n- Replacing the unicode label and NaN values with label 'Unknown'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['category_name'] = df['category_name'].replace(r'\\\\N', 'Unknown', regex=True)\ndf['category_name'].fillna(\"Unknown\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling NaN values in 'sku' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['sku'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Obsevations\n- 20 NaN values for **'sku'** exist in the dataset and these values can be replaced.\n\n##### Action\n- Replace NaN values with a new sku code **'Missing'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sku'].fillna(\"Missing\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling missing values in 'Sales_commission_code' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sales_commission_code'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['sales_commission_code'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- The column has a large number of NaN values and there are more than 7000 types of values in this column\n- The column does not seem to add any value for further analysis and can be dropped at a later stage\n- At this stage, NaN values as well as unicode labels can be replaced with 'Missing'\n\n##### Actions\n- Replacing NaN and unicode values with **'Missing'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sales_commission_code'].fillna(\"Missing\",inplace=True)\ndf['sales_commission_code'] = df['sales_commission_code'].replace(r'\\\\N', 'Missing', regex=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling missing values in 'Customer ID' and 'Customer Since' columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Customer ID'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- There are a total of 11 rows where the 'Customer ID' column is NaN and exactly the same rows in 'Customer since' are also NaN, which makes sense and shows that these columns have a relationship.\n- All 11 records are from FY18, with the first record from 01-2018.\n- For keeping the records in dataset for analysis, a fake 'Customer ID' value of '0' can be assigned with '01-2018' assigned to all records in 'Customer Since' column\n\n##### Actions\n- Replaced 'Customer ID' with value **'0'** and 'Customer Since' with value **'01-2018'** for all NaN values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Customer ID'].fillna(\"0\",inplace=True)\ndf['Customer Since'].fillna(\"1-2018\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking for Null values again and setting appropriate datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Convert the datatypes of columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[[\"item_id\"]] = df[[\"item_id\"]].astype(\"str\")\ndf[[\"Month\"]] = df[[\"Month\"]].astype(\"int\")\ndf[[\"Year\"]] = df[[\"Year\"]].astype(\"int\")\ndf[[\"qty_ordered\"]] = df[[\"qty_ordered\"]].astype(\"int\")\ndf[[\"Customer ID\"]] = df[[\"Customer ID\"]].astype(\"str\")\ndf[[\"increment_id\"]] = df[[\"increment_id\"]].astype(\"str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"#### Transactions by Order Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\ndf1 = df.groupby('status').size().reset_index(name='count').sort_values(by='count', ascending=False)\ndf1['Percentage'] = 100 * df1['count']  / df1['count'].sum()\n\n# Use textposition='auto' for direct text\nfig = go.Figure(data=[go.Bar(\n            x=df1['status'], \n            y=df1['count'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Transactions by Order Status\",\n    xaxis_title=\"Order Status\",\n    yaxis_title=\"count\",    \n    )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observartions\n- Highest number of transactions **(315K or 54%)** belong to the **Completed** category\n- A very high number of transactions **(201K or 34%)** are getting cancelled\n- A sizeable number of transactions **(67K or 11.5%)** have some sort of refund associated.\n- Almost **46%** of transactions are not getting completed for some reason, meaning a lot can be done to **improve the conversion ratio**\n\n##### Actions\n- Analyze any relationship between **'Order Status' and 'Product Category'** so that it can be seen which product transactions are getting completed or cancelled. Also which products have the most refunds associated.\n- Analyze the cancellation and refunds as Revenue lost\n- Analyze any relationship between **'Order Status' and 'Payment Method'**"},{"metadata":{},"cell_type":"markdown","source":"#### Transactions by Category Name"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.groupby('category_name').size().reset_index(name='count').sort_values(by='count', ascending=False)\ndf1['Percentage'] = 100 * df1['count']  / df1['count'].sum()\n\n# Use textposition='auto' for direct text\nfig = go.Figure(data=[go.Bar(\n            x=df1['category_name'], \n            y=df1['count'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Transactions by Product Category\",\n    xaxis_title=\"Product Category\",\n    yaxis_title=\"count\",    \n    )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- Highest number of transactions **(115K or 20%)** happened for **Mobile & Tablets** whereas least number of transactions happened for **Books**"},{"metadata":{},"cell_type":"markdown","source":"#### Combined impact of Category Name and Order Status on Transactions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\npx.histogram(df, x='category_name', color = 'status', barmode='relative', title=\"Product Category wise Order Status\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n**Completed Orders**\n- **Mens Fashion** has the highest number of transactions followed closely by **Mobile & Tablets**\n\n**Cancelled Orders**\n- Common amongst all the Product categories, but more transactions are cancelled than completed for Mobile & Tablets, Others, Entertainment and Unknown Product categories.\n- Highest number of transactions belong to **Mobile & Tablets** which are even greater than number of transactions which are completed.\n\n**Refunds**\n- Highest number of refunds happen for **Mobile & Tablets, Men's Fashion and Women's Fashion**\n\n##### Actions\n- Explore the same trends for 'Total Sales' and see if there is any symmetry or transactions do not have the same monetary impact"},{"metadata":{},"cell_type":"markdown","source":"#### Does Sales Amount follow the same pattern as Transactions??"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' Total Sales for all Transactions (inclusive of Discounts): ', df['grand_total'].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculation for sum\ndf1 = df.groupby('status')['grand_total'].sum().reset_index(name='sum').sort_values(by='sum', ascending=False)\ndf1['Percentage'] = 100 * df1['sum']  / df1['sum'].sum()\nfig = go.Figure(data=[go.Bar(\n            x=df1['status'], \n            y=df1['sum'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            marker = dict(color='rgba(255, 0, 0, 1)',line=dict(color='rgba(255, 0, 0, 1)',width=1)),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Total Sales by Order Status\",\n    xaxis_title=\"Order Status\",\n    yaxis_title=\"Total Sales\",    \n    )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- Almost **58% or Rs 2.9 Bn** of the total sales amount is **'cancelled'** which has a much higher percentage than the number of **cancelled transactions**.\n- E-commerce store has earned **32.73% or Rs 1.6 Bn** worth of revenue from Sales against a potential revenue of **Rs 4.98 Bn**\n\n##### Actions\n- A percentage wise comparison of 'Transactions' and 'Total Sales' needs to be done for better understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculation for sum\ndf1 = df.groupby('status')['grand_total'].sum().reset_index(name='sum')\ndf1['Percentage'] = 100 * df1['sum']  / df1['sum'].sum()\n\n# Calculation for count\ndf2 = df.groupby('status').size().reset_index(name='count')\ndf2['Percentage'] = 100 * df2['count']  / df2['count'].sum()\n\nx = df1['status'];\n\ntrace1 = {\n  'x': x,\n  'y': df2['Percentage'],\n  'name': 'Transactions',\n  'type': 'bar'\n};\n\ntrace2 = {\n  'x': x,\n  'y': df1['Percentage'],\n  'name': 'Total Sales',\n  'marker': dict(color='rgba(255, 0, 0, 1)'),\n  'type': 'bar'\n};\n\ndata = [trace1, trace2];\n\nfig = go.Figure(data=data)\n\nfig.update_layout(\n    title=\"Transactions and Total Sales by Order Status\",\n    xaxis_title=\"Order Status\",\n    yaxis_title=\"% of Total\",    \n    )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observation\n- **'Cancelled'** transactions have much higher monetary value than **'Completed'** transactions.\n- Almost **9% of revenue** is lost through **'Refund'**. **'Fraud' and 'Pending'** have minor contribution\n\n##### Actions\n- Explore the Total Sales generated only by the 'Completed' order status\n- Explore the Total Sales generated by order status other than 'Completed'"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df.loc[df['status']=='Completed',['category_name','grand_total']]\ndf1 = temp.groupby('category_name')['grand_total'].sum().reset_index(name='sum').sort_values(by='sum', ascending=False)\ndf1['Percentage'] = 100 * df1['sum']  / df1['sum'].sum()\n\n# Use textposition='auto' for direct text\nfig = go.Figure(data=[go.Bar(\n            x=df1['category_name'], \n            y=df1['sum'],\n            text=df1['Percentage'].apply(lambda x: '{0:1.2f}%'.format(x)),\n            marker=dict(color='rgba(255, 0, 0, 1)'),\n            textposition='auto'\n        )])\n\nfig.update_layout(\n    title=\"Total Sales of Completed Transactions by Product Category\",\n    xaxis_title=\"Product Category\",\n    yaxis_title=\"Total Sales\",    \n    )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Best Selling Product Category\n\n##### Observations\n- **Mobile & Tablets** is the Best Selling category as it has the highest contribution to sales\n- **Mens Fashion**, despite having the most completed transactions, is the **5th highest contributor**\n- **Appliances** and **Entertainment** have 2nd and 3rd highest contribution to revenue, although the number of completed transactions for these products is low.\n- **Top 5** Productcategories are contributing almost **78% of the overall reveune**\n\n##### Actions\n- Dive deep in the best selling category to check the associated 'sku' column and see if top products can be pinpointed"},{"metadata":{},"cell_type":"markdown","source":"#### To be continued"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}