{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scripts for creating an abstract if it is not available","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import pos_tag\nfrom nltk.tokenize import sent_tokenize,word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\nfrom nltk.stem import PorterStemmer,WordNetLemmatizer\nimport json \nfrom numpy import random","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocess the key words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\npst=PorterStemmer()\nwnl=WordNetLemmatizer()\nrisk_factors={\n    \"hypertension\",\n    \"diabetes\",\n    \"male\",\n    \"heart disease\",\n    \"COPD\",\n    \"Smoking Status\",\n    \"Age\",\n    \"cerebrovascular disease\",\n    \"cardiovascular disease\",\n    \"cancer\",\n    \"respiratory system disease\",\n    \"kidney disease\",\n    \"respiratory disease\",\n    \"drinking\",\n    \"overweight\",\n    \"obese\",\n    \"chronic liver disease\"\n}\n\nmaterial_factors={    \n    'viral shedding',\n    'stool',\n    'nasopharynx',\n    'urine',\n    'blood',\n    'virus persist',\n    'inanimate surfaces',\n    'virus remain viable',\n     'persistence on different materials',\n    'adhesion to hydrophilic surfaces',\n    'adhesion to hydrophobic surfaces',\n    'cleaning agents',\n    'decontamination',\n    'physical'\n\n}\nMaterial={\n    'steel',\n    'copper',\n    'plastic',\n    'glass',\n    'wood',\n    'paper',\n    'cardboard',\n    'textile',\n    'fabric',\n    'bed',\n    'sheet',\n    'rail',\n    'door',\n    'knob',\n    'lever'\n}\n\n\nStudy_design={'Systematic review','meta-analysis',\n              'Prospective observational study',\n              'Retrospective observational study',\n              'Cross-sectional study',\n              'Expert review',\n              'Editorial',\n              'Ecological regression',\n              'Simulation'\n             }\n\nkey_words={'cases',\n           'pneumonia',\n           'bronchitis',\n           'pulmonary disease',\n           'source disease',\n           'virus',\n           'virus caused'}\n\nkey_words.update(material_factors)\nkey_words.update(Study_design)\n#key_words.update(risk_factors)\n#key_words=pst.stem(key_words)\nj=0\nkey_words_lemma={'%'}\nfor x in key_words:\n    key_words_lemma.add(wnl.lemmatize(x))\n    j=j+1\n\nprint(key_words_lemma)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"metadata_df=pd.read_csv('../input/CORD-19-research-challenge/metadata.csv')\nmetadata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove items without a source","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metadata_df.shape)\nmetadata_df.dropna(how='all',subset=['pdf_json_files','pmc_json_files'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Find articles without abstracts","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nno_abstracts_article=metadata_df[metadata_df.abstract.isna()].index\n\nfor s in metadata_df[metadata_df.abstract.notna()].index:\n    if len(metadata_df.abstract.loc[s])<250:        \n        break\n        no_abstracts_article.append(s)\n        i=i+1\nprint(no_abstracts_article)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a function to create the abstract","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_abstract(index_loc,key_words_lemma,key_word_weight=200,sentence_length_weight=0,threshold_value_sent=200):\n    if (metadata_df['pdf_json_files'].notna().loc[index_loc]):\n        path='../input/CORD-19-research-challenge/'+metadata_df.loc[index_loc]['pdf_json_files']\n    else:\n        if (metadata_df['pmc_json_files'].notna().loc[index_loc]):\n            path='../input/CORD-19-research-challenge/'+metadata_df.loc[index_loc]['pmc_json_files']\n        else:\n            path=-1\n            \n    if (path is not -1) :\n        file_source=open(path,'r')\n        string_source=\"\"\n        for x in file_source:\n            string_source=string_source+x\n        #load json file\n        json_obj_source=json.loads(string_source)\n        stoplist=stopwords.words('english')\n        new_abstr=\"\"\n        j=0\n        for x in json_obj_source['body_text']:\n            sentences=sent_tokenize(x['text'])\n            score_sentences=[]\n            for y in sentences:\n                #y=pst.stem(y)\n                y=wnl.lemmatize(y)\n                s=[word for word in y.split() if word not in [stoplist,'The','the','of','in','is','an','as','it','a','to']]\n                score=0\n                for z in s:\n                    if z in key_words_lemma:\n                        score=score+key_word_weight        \n                score=score+len(s)*sentence_length_weight\n                score_sentences.append(score)\n            i=0\n            for y in sentences:        \n                if (score_sentences[i]>=threshold_value_sent):\n                    new_abstr=new_abstr+y\n                i=i+1\n            #print(new_abstr)\n            metadata_df.at[index_loc,'abstract']=new_abstr\n        return 1\n    else:\n        #not valid path\n        return 0\n        \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each article withou abstratc create one","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for index_loc in no_abstracts_article:\n    create_abstract(index_loc,key_words_lemma)\n    #metadata_df.at[index_loc,'abstract']=new_abstr\n    print(metadata_df.at[index_loc,'abstract'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creat columns to save data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata_df['Study']=\"-\"\nmetadata_df['Material']=\"-\"\nmetadata_df['Method']=\"-\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in metadata_df.index:\n    title=metadata_df['title'].loc[i]\n    for kw in Study_design:\n        if (type(title)=='str'):\n            if (title.find(kw) is not -1):\n                metadata_df['Study'].loc[i]= kw\n        else:\n            abstract=metadata_df['abstract'].loc[i]\n            if (type(abstract)=='str'):\n                if (abstract.find(kw) is not -1):\n                    metadata_df['Study'].loc[i]= kw\n    \n    for kw in Material:\n        if (type(title)=='str'):\n            if (title.find(kw) is not -1):\n                metadata_df['Material'].loc[i]= kw\n        else:\n            abstract=metadata_df['abstract'].loc[i]\n            if (type(abstract)=='str'):\n                if (abstract.find(kw) is not -1):\n                    metadata_df['Material'].loc[i]= kw\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(metadata_df['Study']!=\"-\").any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(metadata_df['Material']!=\"-\").any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save backup file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata_df.to_csv(\"metadata_df_abstracts4all.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Restore data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#metadata_df=pd.read_csv(\"metadata_df_abstracts4all.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text2test=\"BACKGROUND: AlkB-like proteins are members of the 2-oxoglutarate- and Fe(II)-dependent oxygenase superfamily. In Escherichia coli the protein protects RNA and DNA against damage from methylating agents. 1-methyladenine and 3-methylcytosine are repaired by oxidative demethylation and direct reversal of the methylated base back to its unmethylated form. Genes for AlkB homologues are widespread in nature, and Eukaryotes often have several genes coding for AlkB-like proteins. Similar domains have also been observed in certain plant viruses. The function of the viral domain is unknown, but it has been suggested that it may be involved in protecting the virus against the post-transcriptional gene silencing (PTGS) system found in plants. We wanted to do a phylogenomic mapping of viral AlkB-like domains as a basis for analysing functional aspects of these domains, because this could have some relevance for understanding possible alternative roles of AlkB homologues e.g. in Eukaryotes. RESULTS: Profile-based searches of protein sequence libraries showed that AlkB-like domains are found in at least 22 different single-stranded RNA positive-strand plant viruses, but mainly in a subgroup of the Flexiviridae family. Sequence analysis indicated that the AlkB domains probably are functionally conserved, and that they most likely have been integrated relatively recently into several viral genomes at geographically distinct locations. This pattern seems to be more consistent with increased environmental pressure, e.g. from methylating pesticides, than with interaction with the PTGS system. CONCLUSIONS: The AlkB domain found in viral genomes is most likely a conventional DNA/RNA repair domain that protects the viral RNA genome against methylating compounds from the environment.\"\nsent2test=sent_tokenize(text2test)\nprint(sent2test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntokenized_sentences=[word_tokenize(sentence) for sentence in sent2test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(tokenized_sentences)\ntagged_sent=[pos_tag(sentence) for sentence in tokenized_sentences]\nfrom nltk import ne_chunk\n#chunk_sent=[ne_chunk(sentence) for sentence in tagged_sent]\n#print(chunk_sent)\nfor sentence in tagged_sent:\n    print(ne_chunk(sentence))\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nchart_parser=nltk.parse.chart.Chart(tokenized_sentences)\nchart_parser.leaves()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}