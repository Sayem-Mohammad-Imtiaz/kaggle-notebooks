{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Random Forest CLF on the Titanic Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T01:01:08.261925Z","iopub.execute_input":"2021-07-26T01:01:08.262317Z","iopub.status.idle":"2021-07-26T01:01:08.273028Z","shell.execute_reply.started":"2021-07-26T01:01:08.262282Z","shell.execute_reply":"2021-07-26T01:01:08.271584Z"}}},{"cell_type":"markdown","source":"![Imgur](https://i.imgur.com/8pw2dfj.jpg)","metadata":{}},{"cell_type":"markdown","source":"Photo by <a href=\"https://unsplash.com/@kmitchhodge?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">K. Mitch Hodge</a> on <a href=\"https://unsplash.com/s/photos/titanic?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>\n  ","metadata":{}},{"cell_type":"markdown","source":"## Index\n\n1. Basic EDA\n    - 1.1 Comparative piecharts\n    - 1.2 Stacked bar charts\n    \n\n2. Feature Engineering \n    - 2.1 Extracting Salutations from Names\n    - 2.2 Making a 'Family' column\n    - 2.3 Using Mean Salutation ages to compute missing values in Age\n    \n  \n3. Data Preprocessing\n    - 3.1 Onehot and Label Encoding \n    \n\n4. Random Forest CLF\n    - 4.1 Train test split\n    - 4.2 Model Training\n    - 4.3 Model Score\n    \n\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:22.982567Z","iopub.execute_input":"2021-07-28T05:47:22.982949Z","iopub.status.idle":"2021-07-28T05:47:22.996318Z","shell.execute_reply.started":"2021-07-28T05:47:22.982917Z","shell.execute_reply":"2021-07-28T05:47:22.99547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combining Training and Test set. We'll seperate them later.\n\ntrain_path = '/kaggle/input/titanic/train.csv'\ntest_path = '/kaggle/input/titanic/test.csv'\ntrain_df = pd.read_csv(train_path, encoding = \"utf-8\")\ntest_df = pd.read_csv(test_path, encoding=\"utf-8\")\nmain_df = pd.concat([train_df, test_df])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:22.998564Z","iopub.execute_input":"2021-07-28T05:47:22.999037Z","iopub.status.idle":"2021-07-28T05:47:23.027038Z","shell.execute_reply.started":"2021-07-28T05:47:22.998993Z","shell.execute_reply":"2021-07-28T05:47:23.025786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.028984Z","iopub.execute_input":"2021-07-28T05:47:23.02928Z","iopub.status.idle":"2021-07-28T05:47:23.048882Z","shell.execute_reply.started":"2021-07-28T05:47:23.029253Z","shell.execute_reply":"2021-07-28T05:47:23.047344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Exploratory Data Analysis  \n\nLet's divide the dataset according to survivors and victims. We'll see how the data looks like.","metadata":{}},{"cell_type":"markdown","source":"![Imgur](https://i.imgur.com/dduSGYD.png)","metadata":{}},{"cell_type":"code","source":"survived = main_df[main_df[\"Survived\"] == 1]\ndied = main_df[main_df[\"Survived\"] == 0]","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.050771Z","iopub.execute_input":"2021-07-28T05:47:23.051187Z","iopub.status.idle":"2021-07-28T05:47:23.064333Z","shell.execute_reply.started":"2021-07-28T05:47:23.051145Z","shell.execute_reply":"2021-07-28T05:47:23.062843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1 Comparative Piecharts","metadata":{}},{"cell_type":"code","source":"labels = ['Survived', 'Died']\nvalues = [len(survived),\n        len(died)]\nfig = go.Figure()\nfig = make_subplots(\n    rows=1, cols=4,\n    specs=[[{'rowspan': 1, 'colspan': 2, 'type': 'domain'}, {}, {'rowspan': 1, 'colspan': 2, 'type': 'bar'}, {}]],\n    print_grid=False)\n\n\nfig.add_trace(go.Pie(labels=labels, values=values, hole=.5, marker={\"colors\": ['#035E7B', '#DB2B39']}), row=1, col=1)\nfig.add_trace(go.Bar(x=labels, y=values, marker_color=['#035E7B', '#DB2B39']), row=1, col=3)\nfig.update_layout(title = \"Fate of Titanic Passengers\")\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.065787Z","iopub.execute_input":"2021-07-28T05:47:23.066456Z","iopub.status.idle":"2021-07-28T05:47:23.121573Z","shell.execute_reply.started":"2021-07-28T05:47:23.066403Z","shell.execute_reply":"2021-07-28T05:47:23.120839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pie charts\n\ndef getLen(dataset, category, value):\n    return len(dataset[dataset[category] == value])\n\n\nlabel1 = [\"Male\", \"Female\"]\nlabel2 = label1\nval1 = [getLen(survived, \"Sex\", \"male\"), getLen(survived, \"Sex\", \"female\")]\nval2 = [getLen(died, \"Sex\", \"male\"), getLen(died, \"Sex\", \"female\")]\n\n\nlabel3 = [\"Pclass 1\", \"Pclass 2\", \"Pclass 3\"]\nlabel4 = label3\nval3 = [getLen(survived, \"Pclass\", 1), getLen(\n    survived, \"Pclass\", 2), getLen(survived, \"Pclass\", 3)]\nval4 = [getLen(died, \"Pclass\", 1), getLen(\n    died, \"Pclass\", 2), getLen(died, \"Pclass\", 3)]\n\n\nlabel5 = [\"Cherboug\", \"Queenstown\", \"Southampton\"]\nlabel6 = label5\nval5 = [getLen(survived, \"Embarked\", \"C\"), getLen(\n    survived, \"Embarked\", \"Q\"), getLen(survived, \"Embarked\", \"S\")]\nval6 = [getLen(died, \"Embarked\", \"C\"), getLen(\n    died, \"Embarked\", \"Q\"), getLen(died, \"Embarked\", \"S\")]\n#### Configuring Subplot Grid ##################################\n\nfig = make_subplots(\n    rows=9, cols=4,\n    specs=[[{'rowspan': 3, 'colspan' : 2, 'type':'domain'},{}, {'rowspan': 3, 'colspan' : 2, 'type':'domain'}, {}],\n           [{'type':'domain'},{'type':'domain'}, {'type':'domain'}, {'type':'domain'}],\n           [{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}],\n           [{'rowspan': 3, 'colspan' : 2, 'type':'domain'}, {'type':'domain'}, {'rowspan': 3, 'colspan' : 2, 'type':'domain'}, {'type':'domain'}],\n           [{'type':'domain'}, {'type':'domain'}, {'type':'domain'}, {'type':'domain'}],\n          [{'type':'domain'},{'type':'domain'},{'type':'domain'}, {'type':'domain'}],\n          [{'rowspan': 3, 'colspan' : 2, 'type':'domain'},{'type':'domain'},{'rowspan': 3, 'colspan' : 2, 'type':'domain'}, {'type':'domain'}],\n          [{'type':'domain'},{'type':'domain'},{'type':'domain'}, {'type':'domain'}],\n          [{'type':'domain'},{'type':'domain'},{'type':'domain'}, {'type':'domain'}]],\n    print_grid=False)\n\n\n\n############# Adding Subplots ##################################\n\nfig.add_trace(go.Pie(labels=label1, values=val1,textinfo='label+percent', insidetextorientation='radial'),\n              row = 1, col = 1) \nfig.add_trace(go.Pie(labels=label2, values=val2, textinfo='label+percent', insidetextorientation='radial'),\n              row = 1, col = 3)\nfig.add_trace(go.Pie(labels=label3, values=val3,textinfo='label+percent', insidetextorientation='radial'),\n              4, 1)\nfig.add_trace(go.Pie(labels=label4, values=val4, textinfo='label+percent', insidetextorientation='radial'),\n              4, 3)\nfig.add_trace(go.Pie(labels=label5, values=val5,textinfo='label+percent', insidetextorientation='radial'),\n              7, 1)\nfig.add_trace(go.Pie(labels=label6, values=val6, textinfo='label+percent', insidetextorientation='radial'),\n              7, 3)\n\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.update_traces(hole=.25, hoverinfo=\"label+percent+name\")\nfig.update_layout(height=1000, width=1000, showlegend=False, title_text=\"Titanic at first glance.\",\n                  annotations=[dict(text='Survived', x=0.02, y=1, font_size=20, showarrow=False),\n                               dict(text='Died', x=0.98, y=1,\n                                    font_size=20, showarrow=False),\n                               dict(text='Sex', x=0.495, y=0.88,\n                                    font_size=20, showarrow=False),\n                               dict(text='Pass. Class', x=0.495, y=0.5,\n                                    font_size=20, showarrow=False),\n                               dict(text='Embarked', x=0.495, y=0.15, font_size=20, showarrow=False)],\n                  font=dict(\n                      family=\"Fira Code, monospace\",  # I like this font.\n                      size=12,\n                      color=\"black\"\n                  ))\nfig.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.122866Z","iopub.execute_input":"2021-07-28T05:47:23.123322Z","iopub.status.idle":"2021-07-28T05:47:23.20623Z","shell.execute_reply.started":"2021-07-28T05:47:23.123275Z","shell.execute_reply":"2021-07-28T05:47:23.20545Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Class to generate Stacked Bar Charts.","metadata":{}},{"cell_type":"code","source":"def get_em_data(dataset, town):\n    return dataset[dataset[\"Embarked\"] == town]\n\ndef get_pclass(dataset, cl):\n    return len(dataset[dataset[\"Pclass\"] == cl])/len(dataset) * 100\n\ndef get_fare_bins(dataset, bin):\n    return len(dataset[dataset[\"Fare_Bins\"] == bin])/len(dataset) * 100\n\n\nclass StackedBars:\n    def __init__(self, dataset, get_function, x_labels, y_labels, config, colors):\n        self.dataset = dataset\n        self.get_function = get_function\n        self.x_labels, self.y_labels = x_labels, y_labels\n        self.colors = colors\n        self.config = config\n\n    def generate_figure(self, startIndex):\n        fig = go.Figure()\n        i = startIndex\n        col = 0\n        for x in self.x_labels:\n            fig.add_trace(go.Bar(\n                y=self.y_labels,\n                x=[self.get_function(x, i) for x in self.dataset],\n                name=x,\n                orientation='h',\n                marker=dict(\n                    color=self.colors[col],\n                    line=dict(color='black', width=1)\n                )\n            ))\n            i += 1\n            col += 1\n\n        fig.update_layout(\n            barmode='stack', title=self.config[\"title\"], xaxis=self.config[\"xaxis\"], font={'family': 'Fira Code, monospace', 'size': 12, 'color': 'black'})\n        fig.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.208144Z","iopub.execute_input":"2021-07-28T05:47:23.208668Z","iopub.status.idle":"2021-07-28T05:47:23.220472Z","shell.execute_reply.started":"2021-07-28T05:47:23.208632Z","shell.execute_reply":"2021-07-28T05:47:23.219495Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_labels = [\"Southampton\", \"Queenstown\", \"Cherboug\"]\n\n\ncolors_survived = ['rgba(20, 111, 163, 0.3)',\n                   'rgba(20, 111, 163, 0.7)', 'rgba(20, 111, 163, 1)']\ncolors_died = ['rgba(240, 45, 58, 0.3)',\n               'rgba(240, 45, 58, 0.7)', 'rgba(240, 45, 58, 1)']\n\nconfig_survived = {\"title\": \"Survived\",\n          \"xaxis\": {'title': {'text': \"% of Passengers\"}}}\n\nconfig_died = {\"title\": \"Died\",\n                \"xaxis\": {'title': {'text': \"% of Passengers\"}}}\n\n\ns_survived, q_survived, c_survived = get_em_data(\n    survived, \"S\"), get_em_data(survived, \"Q\"), get_em_data(survived, \"C\")\ns_died, q_died, c_died = get_em_data(died, \"S\"), get_em_data(\n    died, \"Q\"), get_em_data(died, \"C\")\n\nx_labels = [\"Pclass 1\", \"Pclass 2\", \"Pclass 3\"]  \ndataset_survived = [s_survived, q_survived, c_survived]\ndataset_died = [s_died, q_died, c_died]\n\n\npclass_bars = StackedBars(dataset = dataset_survived, x_labels = x_labels, y_labels = y_labels, get_function= get_pclass, colors = colors_survived, config = config_survived)\n\n\npclass_bars2 = StackedBars(dataset=dataset_died, x_labels=x_labels, y_labels=y_labels,\n                          get_function=get_pclass, colors=colors_died, config=config_died)\n                          \npclass_bars.generate_figure(1)\npclass_bars2.generate_figure(1)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.222466Z","iopub.execute_input":"2021-07-28T05:47:23.222847Z","iopub.status.idle":"2021-07-28T05:47:23.28727Z","shell.execute_reply.started":"2021-07-28T05:47:23.222814Z","shell.execute_reply":"2021-07-28T05:47:23.28615Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Feature Engineering\nLet's take a look at our preprocessing map!","metadata":{}},{"cell_type":"markdown","source":"![Imgur](https://i.imgur.com/WNGbNOn.png)","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Custom Preprocessing/Feature Engineering functions.","metadata":{}},{"cell_type":"code","source":"import re\nfrom sklearn.preprocessing import Normalizer, StandardScaler, OneHotEncoder, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\ndef label_sal(x): #assigns weighted labels to Salutations.\n    if x in [\"Mr.\", \"Jonkheer.\"]:\n        return 0\n    elif x in [\"Miss.\", \"Ms.\"]:\n        return 0\n    elif x == \"Mrs.\":\n        return 0\n    elif x == \"Master.\":\n        return 1\n    elif x == \"Rev.\":\n        return 1\n    elif x == \"Dr.\":\n        return 1\n    elif x == \"Don.\":\n        return 2.5\n    elif x == \"Dona.\":\n        return 2.5\n    elif x == \"Sir.\":\n        return 2.5\n    elif x in [\"Lady.\", \"Mlle.\"]:\n        return 2.5\n    elif x == \"Capt.\":\n        return 1\n    elif x == \"Major.\":\n        return 2\n    elif x == \"Col.\":\n        return 2\n    else:\n        return 0\n\ndef cap_sal(x): #Extracts Salutations from Name Column. \n    pattern = re.search(',.+?(?= )', x)\n    sal = pattern.group()\n    x = label_sal(sal[2:])\n    return x\n\n\ndef bin_fare(x): #Creates bins for Fare\n    if x < 50:\n        return 0\n    elif 50 <= x < 100:\n        return 1\n    elif 100 <= x < 150:\n        return 2\n    elif 150 <= x < 200:\n        return 3\n    else:\n        return 4\n\n\ndef one_hot_gender(x):#One hot encoding for Sex\n    if x == \"male\":\n        return 0\n    else:\n        return 1\n\n\ndef age_bin(x): #Bins for Age groups.\n    if x < 10:\n        return 0\n    elif 10 <= x < 18:\n        return 1\n    elif 18 <= x < 30:\n        return 2\n    elif 30 <= x < 40:\n        return 3\n    elif 40 <= x < 50:\n        return 4\n    elif 50 <= x < 60:\n        return 5\n    else:\n        return 6\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.288631Z","iopub.execute_input":"2021-07-28T05:47:23.288921Z","iopub.status.idle":"2021-07-28T05:47:23.304346Z","shell.execute_reply.started":"2021-07-28T05:47:23.288893Z","shell.execute_reply":"2021-07-28T05:47:23.303517Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Let's apply our functions to raw data.\n\nWe'll go column by column and understand why we are applying preprocessing functions to them.","metadata":{}},{"cell_type":"code","source":"main_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.305472Z","iopub.execute_input":"2021-07-28T05:47:23.305956Z","iopub.status.idle":"2021-07-28T05:47:23.338711Z","shell.execute_reply.started":"2021-07-28T05:47:23.305911Z","shell.execute_reply":"2021-07-28T05:47:23.337889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Salutations\n\nSalutations have been extracted from the Names column of the dataset. Salutations imply social hierarchy. Someone addressed as \"Mr\" is likely to have belonged to 3rd Class as compared to someone addressed as \"Don.\". I have assigned different weights to the Salutations so there is a clear seperation.","metadata":{}},{"cell_type":"code","source":"main_df[\"Salutations\"] = [cap_sal(x) for x in main_df[\"Name\"]]\nmain_df = main_df.drop(columns= [\"Name\",\"Cabin\", \"Ticket\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.339891Z","iopub.execute_input":"2021-07-28T05:47:23.340329Z","iopub.status.idle":"2021-07-28T05:47:23.359915Z","shell.execute_reply.started":"2021-07-28T05:47:23.340284Z","shell.execute_reply":"2021-07-28T05:47:23.358837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parch and SibSp\nLet's combine Parch and SibSp to give a family count. We'll add a +1 to include the person as well.","metadata":{}},{"cell_type":"code","source":"main_df[\"Family\"] = main_df[\"SibSp\"] + main_df[\"Parch\"] + 1\nmain_df = main_df.drop(columns=[\"Parch\", \"SibSp\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.362051Z","iopub.execute_input":"2021-07-28T05:47:23.362415Z","iopub.status.idle":"2021-07-28T05:47:23.376873Z","shell.execute_reply.started":"2021-07-28T05:47:23.362377Z","shell.execute_reply":"2021-07-28T05:47:23.376014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Dealing with Age\n\nThe Age column has a lot of missing values. That's problematic. We need to impute Age values to ensure that our data is complete. Initially I used the Sklearn Imputer to fill in Age with their mean values. However, a better way to impute age is to find the \"Salutation mean age\" for each Salutation. For example, people with the salutation \"Master.\" have a mean age of 5. Imputing their ages with the global mean is bound to give bad results. So I used the average salutation age to compute ages for every missing value.","metadata":{}},{"cell_type":"code","source":"sal_grp = main_df.groupby(\"Salutations\").mean()\nsal_grp.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.377986Z","iopub.execute_input":"2021-07-28T05:47:23.378466Z","iopub.status.idle":"2021-07-28T05:47:23.399214Z","shell.execute_reply.started":"2021-07-28T05:47:23.378381Z","shell.execute_reply":"2021-07-28T05:47:23.398179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_na = main_df[main_df[\"Age\"].isna()]\nage_na.loc[age_na[\"Salutations\"] == 0.0, \"Age\"] = 30\nage_na.loc[age_na[\"Salutations\"] == 1.0, \"Age\"] = 44\nage_na.loc[age_na[\"Salutations\"] == 2.0, \"Age\"] = 52\nage_na.loc[age_na[\"Salutations\"] == 2.5, \"Age\"] = 37\nage_na.loc[age_na[\"Salutations\"] == 3.0, \"Age\"] = 5\nsep_df = main_df[main_df[\"Age\"] > 0.0]\nmain_df = pd.concat([age_na, sep_df])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.400796Z","iopub.execute_input":"2021-07-28T05:47:23.401196Z","iopub.status.idle":"2021-07-28T05:47:23.41894Z","shell.execute_reply.started":"2021-07-28T05:47:23.401157Z","shell.execute_reply":"2021-07-28T05:47:23.417661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df[\"Age_Bin\"] = [age_bin(x) for x in main_df[\"Age\"]] # Making an Age bin.\nmain_df = main_df.drop(columns=[\"Age\"])\npx.histogram(main_df, x = \"Age_Bin\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.420144Z","iopub.execute_input":"2021-07-28T05:47:23.420516Z","iopub.status.idle":"2021-07-28T05:47:23.508137Z","shell.execute_reply.started":"2021-07-28T05:47:23.420485Z","shell.execute_reply":"2021-07-28T05:47:23.507097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Why do we need bins for Fare?\n\nFare data has outliers which can impact our model accuracy. Binning the data will help deal with outliers.","metadata":{}},{"cell_type":"code","source":"px.histogram(main_df, x = \"Fare\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.511208Z","iopub.execute_input":"2021-07-28T05:47:23.511534Z","iopub.status.idle":"2021-07-28T05:47:23.588859Z","shell.execute_reply.started":"2021-07-28T05:47:23.511504Z","shell.execute_reply":"2021-07-28T05:47:23.587769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df[\"Fare_Bins\"] = [bin_fare(x) for x in main_df[\"Fare\"]]\nmain_df = main_df.drop(columns = [\"Fare\"])\npx.histogram(main_df, x = \"Fare_Bins\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.590495Z","iopub.execute_input":"2021-07-28T05:47:23.590797Z","iopub.status.idle":"2021-07-28T05:47:23.670431Z","shell.execute_reply.started":"2021-07-28T05:47:23.590769Z","shell.execute_reply":"2021-07-28T05:47:23.669282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Onehot and Label Encoding.\n\nWe'll encode categorical values.","metadata":{}},{"cell_type":"code","source":"main_df[\"Sex\"] = [one_hot_gender(x) for x in main_df[\"Sex\"]] #Onehot encoding Sex","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.671747Z","iopub.execute_input":"2021-07-28T05:47:23.672053Z","iopub.status.idle":"2021-07-28T05:47:23.678531Z","shell.execute_reply.started":"2021-07-28T05:47:23.672023Z","shell.execute_reply":"2021-07-28T05:47:23.677619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nmain_df[\"Embarked\"] = main_df[\"Embarked\"].replace(np.nan, \"Unknown\")\nlenc = LabelEncoder()\nmain_df[\"Embarked\"] = lenc.fit_transform(main_df[\"Embarked\"])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.679971Z","iopub.execute_input":"2021-07-28T05:47:23.680376Z","iopub.status.idle":"2021-07-28T05:47:23.692917Z","shell.execute_reply.started":"2021-07-28T05:47:23.680344Z","shell.execute_reply":"2021-07-28T05:47:23.691751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df_test = main_df[891:] # Seperating Preprocessed Test Data\nmain_df_1 = main_df.drop(columns = [\"PassengerId\"])\nmain_df_1 = main_df_1.dropna() # Preprocessed Training Data","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.694197Z","iopub.execute_input":"2021-07-28T05:47:23.694495Z","iopub.status.idle":"2021-07-28T05:47:23.709847Z","shell.execute_reply.started":"2021-07-28T05:47:23.694467Z","shell.execute_reply":"2021-07-28T05:47:23.708867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some last minute EDA on Processed Data","metadata":{}},{"cell_type":"code","source":"survived = main_df_1[main_df_1[\"Survived\"] == 1]\ndied = main_df_1[main_df_1[\"Survived\"] == 0]","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.711684Z","iopub.execute_input":"2021-07-28T05:47:23.712137Z","iopub.status.idle":"2021-07-28T05:47:23.724163Z","shell.execute_reply.started":"2021-07-28T05:47:23.712089Z","shell.execute_reply":"2021-07-28T05:47:23.722569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\"title\": \"Fare Brackets\",\n          \"xaxis\": {'domain': [0.0, 1.0], 'title': {'text': \"% of Passengers\"}},\n          \"font\": {'family': 'Fira Code, monospace', 'size': 12, 'color': 'black'}}\ncolors = ['#F8B4C4', '#EF577B', '#E01544', '#950E2D', '#5D091C']\nbars = StackedBars(dataset = [survived, died], get_function = get_fare_bins, x_labels=[\n                   \"<50\", \"50 <= x < 100\", \"100 <= x < 150\", \"150 <= x < 200\", \">200\"],\n                   y_labels = [\"Survived\", 'Died'], config = config, colors = colors)\nbars.generate_figure(0)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.725511Z","iopub.execute_input":"2021-07-28T05:47:23.726492Z","iopub.status.idle":"2021-07-28T05:47:23.76297Z","shell.execute_reply.started":"2021-07-28T05:47:23.726409Z","shell.execute_reply":"2021-07-28T05:47:23.76198Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"survived_male = survived[survived[\"Sex\"] == 0]\nsurvived_female = survived[survived[\"Sex\"] == 1]\n\ndied_male = died[died[\"Sex\"] == 0]\ndied_female = died[died[\"Sex\"] == 1]\n\n\ndef get_age_bins(dataset, bin):\n    return len(dataset[dataset[\"Age_Bin\"] == bin])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.764218Z","iopub.execute_input":"2021-07-28T05:47:23.764707Z","iopub.status.idle":"2021-07-28T05:47:23.777147Z","shell.execute_reply.started":"2021-07-28T05:47:23.76466Z","shell.execute_reply":"2021-07-28T05:47:23.776166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\"title\": \"Age Brackets\",\n          \"xaxis\": {'domain': [0.0, 1.0], 'title': {'text': \"Count of Passengers\"}}}\n          \ncolors = ['#FFC2C2', '#FF7070', '#FF3333',\n          '#F50000', '#B80000', '#8F0000', '#520000']\n\nbars = StackedBars(dataset=[survived_male, survived_female, died_male, died_female], get_function=get_age_bins, x_labels=[\n                   \"<10\", \"10 <= Age < 18\", \"18 <= Age < 30\", \"30 <= Age < 40\", \"40 <= Age < 50\", \"50 <= Age < 60\", \"> 60\"],\n                   y_labels=[\"Male Survivors\", \"Female Survivors\", \"Male Victims\", 'Female Victims'], config=config, colors=colors)\nbars.generate_figure(0)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.778617Z","iopub.execute_input":"2021-07-28T05:47:23.779115Z","iopub.status.idle":"2021-07-28T05:47:23.833735Z","shell.execute_reply.started":"2021-07-28T05:47:23.779068Z","shell.execute_reply":"2021-07-28T05:47:23.832422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Machine Learning.\n","metadata":{}},{"cell_type":"markdown","source":"![Imgur](https://i.imgur.com/8HaxQfM.png)","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Train Test Split.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, y_train = main_df_1.drop(columns=[\"Survived\"]), main_df_1[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.3)\n\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.835329Z","iopub.execute_input":"2021-07-28T05:47:23.835887Z","iopub.status.idle":"2021-07-28T05:47:23.849576Z","shell.execute_reply.started":"2021-07-28T05:47:23.835797Z","shell.execute_reply":"2021-07-28T05:47:23.848477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.8511Z","iopub.execute_input":"2021-07-28T05:47:23.851455Z","iopub.status.idle":"2021-07-28T05:47:23.870014Z","shell.execute_reply.started":"2021-07-28T05:47:23.851422Z","shell.execute_reply":"2021-07-28T05:47:23.868976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Model Training","metadata":{}},{"cell_type":"code","source":"from random import randint\nparam_forest= {'max_depth': [5, 6, 7],\n         'n_estimators': [75, 80, 85, 90],\n         'max_features': [5, 3, 2, 1, None],\n         'criterion': ['gini'],\n         'bootstrap': [True, False]}","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.871358Z","iopub.execute_input":"2021-07-28T05:47:23.871771Z","iopub.status.idle":"2021-07-28T05:47:23.883846Z","shell.execute_reply.started":"2021-07-28T05:47:23.871726Z","shell.execute_reply":"2021-07-28T05:47:23.882935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nsearch_clf = GridSearchCV(RandomForestClassifier(), param_forest, cv = 5)\nsearch_clf.fit(X_train, y_train)\ny_pred  = search_clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:47:23.899645Z","iopub.execute_input":"2021-07-28T05:47:23.900045Z","iopub.status.idle":"2021-07-28T05:49:00.085776Z","shell.execute_reply.started":"2021-07-28T05:47:23.900002Z","shell.execute_reply":"2021-07-28T05:49:00.084716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:49:00.087161Z","iopub.execute_input":"2021-07-28T05:49:00.087468Z","iopub.status.idle":"2021-07-28T05:49:00.094199Z","shell.execute_reply.started":"2021-07-28T05:49:00.087438Z","shell.execute_reply":"2021-07-28T05:49:00.092968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3 Model Accuracy","metadata":{}},{"cell_type":"code","source":"print(\"Training accuracy for model is\", accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:51:14.24264Z","iopub.execute_input":"2021-07-28T05:51:14.242987Z","iopub.status.idle":"2021-07-28T05:51:14.249438Z","shell.execute_reply.started":"2021-07-28T05:51:14.242959Z","shell.execute_reply":"2021-07-28T05:51:14.24823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T05:49:48.700531Z","iopub.execute_input":"2021-07-28T05:49:48.700917Z","iopub.status.idle":"2021-07-28T05:49:48.707554Z","shell.execute_reply.started":"2021-07-28T05:49:48.700887Z","shell.execute_reply":"2021-07-28T05:49:48.706713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Thoughts\nI spent almost 2 weeks on understanding the data, preprocessing and hypertuning the parameters. A lot of time was spent reading the discussion forums. Over the course of 10+ submissions, I reached Top 17%. Let's see if I can do better next time!","metadata":{}}]}