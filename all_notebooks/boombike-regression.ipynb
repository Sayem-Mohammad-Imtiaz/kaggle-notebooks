{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BoomBikes Regression\n\n## Objective:  To understand the factors affecting the demand for the shared bikes in the American market after quarantine.\n\n**To find:**\n   - Which variables are significant in predicting the demand for shared bikes?\n   - How well those variables describe the bike demands?","metadata":{}},{"cell_type":"code","source":"# Importing packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_palette('pastel')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:31.802055Z","iopub.execute_input":"2021-06-07T05:55:31.802612Z","iopub.status.idle":"2021-06-07T05:55:32.627414Z","shell.execute_reply.started":"2021-06-07T05:55:31.802515Z","shell.execute_reply":"2021-06-07T05:55:32.626592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing dataset\ndf = pd.read_csv('../input/boombikes/day.csv')\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:32.629625Z","iopub.execute_input":"2021-06-07T05:55:32.630048Z","iopub.status.idle":"2021-06-07T05:55:32.658848Z","shell.execute_reply.started":"2021-06-07T05:55:32.630007Z","shell.execute_reply":"2021-06-07T05:55:32.657983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are 730 rows and 16 predictors.**","metadata":{}},{"cell_type":"code","source":"# Let's understand the dataset\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:45.998387Z","iopub.execute_input":"2021-06-07T05:55:45.998714Z","iopub.status.idle":"2021-06-07T05:55:46.031507Z","shell.execute_reply.started":"2021-06-07T05:55:45.998687Z","shell.execute_reply":"2021-06-07T05:55:46.030532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mix of categorical and numerical data types.\n<br> cnt is the target variable.**","metadata":{}},{"cell_type":"code","source":"# Let's look at the values.\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.033853Z","iopub.execute_input":"2021-06-07T05:55:46.034261Z","iopub.status.idle":"2021-06-07T05:55:46.096411Z","shell.execute_reply.started":"2021-06-07T05:55:46.034213Z","shell.execute_reply":"2021-06-07T05:55:46.095179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Range is varied. Will have to scale later.**","metadata":{}},{"cell_type":"code","source":"# Any null values?\n# Although we can see that there are no null values from Non null count above, \n# Better to confirm once. \ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.097715Z","iopub.execute_input":"2021-06-07T05:55:46.098091Z","iopub.status.idle":"2021-06-07T05:55:46.106826Z","shell.execute_reply.started":"2021-06-07T05:55:46.098052Z","shell.execute_reply":"2021-06-07T05:55:46.105806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Alright, dataset with no null values. That's good.**","metadata":{}},{"cell_type":"code","source":"# How does our data look like?\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.108225Z","iopub.execute_input":"2021-06-07T05:55:46.108576Z","iopub.status.idle":"2021-06-07T05:55:46.128144Z","shell.execute_reply.started":"2021-06-07T05:55:46.108542Z","shell.execute_reply":"2021-06-07T05:55:46.127323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"import datetime\ndf['dteday'] = pd.to_datetime(df['dteday'], format = '%d-%m-%Y')\ndf[['dteday', 'holiday', 'workingday']]\ndf[(df['weekday'] == 0) & (df['yr'] == 1)].tail(60)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.131219Z","iopub.execute_input":"2021-06-07T05:55:46.131501Z","iopub.status.idle":"2021-06-07T05:55:46.193023Z","shell.execute_reply.started":"2021-06-07T05:55:46.131475Z","shell.execute_reply":"2021-06-07T05:55:46.191736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[(df['holiday'] == 0) & (df['workingday'] == 0) & (df['yr'] == 1)]\ndf[df['yr'] == 1].head(31)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.196106Z","iopub.execute_input":"2021-06-07T05:55:46.196463Z","iopub.status.idle":"2021-06-07T05:55:46.221611Z","shell.execute_reply.started":"2021-06-07T05:55:46.196432Z","shell.execute_reply":"2021-06-07T05:55:46.220489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It was found that encoding weekdays and holidays was not done properly. \n#Ideally we would ask the company to correct data issues. \n# Since it is not possible here, we will just continue as it is.","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.223011Z","iopub.execute_input":"2021-06-07T05:55:46.223396Z","iopub.status.idle":"2021-06-07T05:55:46.233501Z","shell.execute_reply.started":"2021-06-07T05:55:46.223362Z","shell.execute_reply":"2021-06-07T05:55:46.232548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's start by removing unwanted variables.\ndf = df.drop(['instant','dteday','casual','atemp','registered'], axis = 1)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.23484Z","iopub.execute_input":"2021-06-07T05:55:46.235253Z","iopub.status.idle":"2021-06-07T05:55:46.262278Z","shell.execute_reply.started":"2021-06-07T05:55:46.235212Z","shell.execute_reply":"2021-06-07T05:55:46.261457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Deleting atemp as it is highly related to temp.\n<br>Deleting instant, day, casual, registered as they are not important.\n<br>A quick google search says that humidity and windspeed are not directly related. Hence keeping both of them.**","metadata":{}},{"cell_type":"code","source":"# Looking at holiday and workingday. They both seem to be same\ndf[['holiday','workingday']].sample(15)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.26317Z","iopub.execute_input":"2021-06-07T05:55:46.263513Z","iopub.status.idle":"2021-06-07T05:55:46.280611Z","shell.execute_reply.started":"2021-06-07T05:55:46.263488Z","shell.execute_reply":"2021-06-07T05:55:46.279999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['workingday'] == 0]['holiday'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.281488Z","iopub.execute_input":"2021-06-07T05:55:46.281833Z","iopub.status.idle":"2021-06-07T05:55:46.290883Z","shell.execute_reply.started":"2021-06-07T05:55:46.281808Z","shell.execute_reply":"2021-06-07T05:55:46.290255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From data dictionay we know that** \n <br>holiday:\n  - 0 => not a public holiday, i.e., weekend or weekday, hence working day can be 0 or 1\n  - 1 => public holiday, i.e., working day = 0\n<br>**Hence if we delete holiday, we might loose the information about public holdiays.\n<br>So, we'll keep it till we check VIF.**\n","metadata":{}},{"cell_type":"code","source":"# Correcting the data types. \ndf['season'].replace({1:'spring', 2:'summer',3:'fall',4:'winter'}, inplace = True)\ndf['mnth'].replace({1:'jan', 2:'feb',3:'march',4:'april',5:'may',6:'june',7:'july',\n                     8:'august',9:'sept',10:'oct',11:'nov',12:'dec'}, inplace = True)\ndf['workingday'].replace({1:'working', 0:'holiday'}, inplace = True)\ndf['holiday'].replace({1:'pubholiday', 0:'n_pubholiday'}, inplace = True)\ndf['weekday'].replace({6:'mon', 0:'tue',1:'wed',2:'thu',3:'fri',4:'sat',5:'sun'}, inplace = True)\ndf['weathersit'].replace({1:'clear', 2:'misty',3:'light_rain_snow',4:'heavy_rain_snow'}, inplace = True)\ndf['yr'].replace({0:'2018', 1:'2019'}, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.291792Z","iopub.execute_input":"2021-06-07T05:55:46.292159Z","iopub.status.idle":"2021-06-07T05:55:46.312358Z","shell.execute_reply.started":"2021-06-07T05:55:46.292133Z","shell.execute_reply":"2021-06-07T05:55:46.311585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Same trend follows with weekday and working day. We know that by default saturdays and sunday will be holdiay.\n<br>But if we delete one of them, we'll loose data on weekdays that were a holiday. \n<br>That is monday which was a holiday, i.e, public holdiay. But there are only 21 of them.** \n","metadata":{}},{"cell_type":"code","source":"# Let's check\ndf[df['workingday'] == 'holiday'][['weekday','workingday','holiday']]\n## Hence, we can say that there are holidays which are not public holdiay nor weekend. So better to keep all 3.","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.313243Z","iopub.execute_input":"2021-06-07T05:55:46.313627Z","iopub.status.idle":"2021-06-07T05:55:46.330635Z","shell.execute_reply.started":"2021-06-07T05:55:46.3136Z","shell.execute_reply":"2021-06-07T05:55:46.329984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's look at the data\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.331761Z","iopub.execute_input":"2021-06-07T05:55:46.332159Z","iopub.status.idle":"2021-06-07T05:55:46.363184Z","shell.execute_reply.started":"2021-06-07T05:55:46.332125Z","shell.execute_reply":"2021-06-07T05:55:46.36228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"# Let's start by looking at pairplot\nsns.pairplot( data = df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:46.364185Z","iopub.execute_input":"2021-06-07T05:55:46.364619Z","iopub.status.idle":"2021-06-07T05:55:48.874214Z","shell.execute_reply.started":"2021-06-07T05:55:46.364589Z","shell.execute_reply":"2021-06-07T05:55:48.873465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see that humidity and windspeed are not linear with our target variable.\n<br>So, we'll go ahead and remove it.\n<br>But there is no mulicollinearity. So, that is good.**","metadata":{}},{"cell_type":"code","source":"# Deleting humidity and windspeed as it is not linear with our target.\ndf.drop(['hum','windspeed'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:48.875188Z","iopub.execute_input":"2021-06-07T05:55:48.875553Z","iopub.status.idle":"2021-06-07T05:55:48.880025Z","shell.execute_reply.started":"2021-06-07T05:55:48.875527Z","shell.execute_reply":"2021-06-07T05:55:48.879304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Storing categorical variables as a list\ncat_vars = ['season','yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n# Looking at the count of the categories.\nplt.figure(figsize = (18,25))\nplt.figure(figsize = (18,15))\ncount=1\nfor i in cat_vars:\n    plt.subplot(4,2,count)\n    sns.countplot(x = i, data = df)\n    count+=1\n\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-07T05:55:48.881396Z","iopub.execute_input":"2021-06-07T05:55:48.881688Z","iopub.status.idle":"2021-06-07T05:55:49.836858Z","shell.execute_reply.started":"2021-06-07T05:55:48.881661Z","shell.execute_reply":"2021-06-07T05:55:49.835968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the above countplot we can see that:**\n- During the fall more bikes were rented.\n- Both years have same number of datapoints.\n- We have less data for Feb. Maybe due to cold weather.\n- Since there are more working days than holidays (unfortunately!) the count is also less.\n- Most of the year, weather can be clear, hence count is more here. \n\n**However, since this is countplot, it can get affected by the number of data points in each category.\n<br> Hence, let's compare with our target variable.**","metadata":{}},{"cell_type":"markdown","source":"#### Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"# Let's now check how many bikes were rented throughout each category.\nplt.figure(figsize = (18,15))\ncount=1\nfor i in cat_vars:\n    plt.subplot(4,2,count)\n    sns.barplot(y = \"cnt\",x = i, data = df)\n    count+=1\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:49.838331Z","iopub.execute_input":"2021-06-07T05:55:49.83861Z","iopub.status.idle":"2021-06-07T05:55:51.289588Z","shell.execute_reply.started":"2021-06-07T05:55:49.838583Z","shell.execute_reply":"2021-06-07T05:55:51.288558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the above plots we can see that:**\n-  During the fall, bikes were rented more. Nice weather may be the reason behind this.\n- The number bikes rented doubled in 2019 than 2018. Maybe the company started getting recognition.\n- June to Sept is Summer to Fall in US which is quite pleasent and people like to roam out in open. Hence, number is more.\n- During week or holidays does not seem to have much effect. Maybe people are renting for all purposes throughout the week.\n- And nobody rides bike when it is snowing or raining for obvious reasons. Hence the number is highest during a clear day.\n\n**Therefore we can guess that month, season and weather situation are having more effect on the target variable than others. We will confirm it later with help of correlation.**","metadata":{}},{"cell_type":"markdown","source":"## Data Preperation","metadata":{}},{"cell_type":"code","source":"# Converting categorical to dummy variables\ndf = pd.concat([df, pd.get_dummies(df[cat_vars],drop_first = True)], axis = 1)\ndf.drop(cat_vars, axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.290874Z","iopub.execute_input":"2021-06-07T05:55:51.291176Z","iopub.status.idle":"2021-06-07T05:55:51.307139Z","shell.execute_reply.started":"2021-06-07T05:55:51.291141Z","shell.execute_reply":"2021-06-07T05:55:51.306043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- From the above pairplot we saw that target vairable is positively related with temp and 2019. That is as these two increased, the number of rentals increases. We noticed this trend in the above plots too. \n- Feb and Spring, working day and saturday, October and Winter seems to have correlation. However, to decide whether to delete them will be made based on VIF.","metadata":{}},{"cell_type":"code","source":"# Splitting into train and test\nfrom sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, train_size = 0.7, random_state = 100)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.308553Z","iopub.execute_input":"2021-06-07T05:55:51.308954Z","iopub.status.idle":"2021-06-07T05:55:51.525921Z","shell.execute_reply.started":"2021-06-07T05:55:51.308901Z","shell.execute_reply":"2021-06-07T05:55:51.525192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling temp and cnt variables.\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\n# Fitting & Transforming Train \ndf_train[['cnt','temp']] = scaler.fit_transform(df_train[['cnt','temp']])\n\n# Transforming test\ndf_test[['cnt','temp']] = scaler.transform(df_test[['cnt','temp']])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.526986Z","iopub.execute_input":"2021-06-07T05:55:51.527351Z","iopub.status.idle":"2021-06-07T05:55:51.546769Z","shell.execute_reply.started":"2021-06-07T05:55:51.527325Z","shell.execute_reply":"2021-06-07T05:55:51.545968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if properly scaled\ndf_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.550113Z","iopub.execute_input":"2021-06-07T05:55:51.550496Z","iopub.status.idle":"2021-06-07T05:55:51.626851Z","shell.execute_reply.started":"2021-06-07T05:55:51.550467Z","shell.execute_reply":"2021-06-07T05:55:51.625882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividing train as X, y\ny_train = df_train.pop('cnt')\nX_train = df_train","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.628139Z","iopub.execute_input":"2021-06-07T05:55:51.628655Z","iopub.status.idle":"2021-06-07T05:55:51.633663Z","shell.execute_reply.started":"2021-06-07T05:55:51.628616Z","shell.execute_reply":"2021-06-07T05:55:51.632793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Regression","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.635228Z","iopub.execute_input":"2021-06-07T05:55:51.635581Z","iopub.status.idle":"2021-06-07T05:55:51.648598Z","shell.execute_reply.started":"2021-06-07T05:55:51.635544Z","shell.execute_reply":"2021-06-07T05:55:51.647822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll start by using RFE to coarse tune our model.\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nlr = LinearRegression()\nrfe = RFE(lr, n_features_to_select = 10)\nrfe = rfe.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.64955Z","iopub.execute_input":"2021-06-07T05:55:51.649965Z","iopub.status.idle":"2021-06-07T05:55:51.876095Z","shell.execute_reply.started":"2021-06-07T05:55:51.649926Z","shell.execute_reply":"2021-06-07T05:55:51.875015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns and their rank have been stored as a dataframe.\nrank = pd.DataFrame(list(zip( X_train.columns, rfe.support_, rfe.ranking_)))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.87753Z","iopub.execute_input":"2021-06-07T05:55:51.878122Z","iopub.status.idle":"2021-06-07T05:55:51.883918Z","shell.execute_reply.started":"2021-06-07T05:55:51.87808Z","shell.execute_reply":"2021-06-07T05:55:51.8831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see which all are dropped  and which are selected by RFE.\nrank.sort_values(by = 2)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.884898Z","iopub.execute_input":"2021-06-07T05:55:51.885182Z","iopub.status.idle":"2021-06-07T05:55:51.911456Z","shell.execute_reply.started":"2021-06-07T05:55:51.885154Z","shell.execute_reply":"2021-06-07T05:55:51.910096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Out of 27 columns, 10 are retained as expected.**\n","metadata":{}},{"cell_type":"code","source":"# Save these as a separate training data.\nX_train_RFE = X_train[list(X_train.columns[rfe.support_])]\nX_train_RFE.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.916063Z","iopub.execute_input":"2021-06-07T05:55:51.918503Z","iopub.status.idle":"2021-06-07T05:55:51.944393Z","shell.execute_reply.started":"2021-06-07T05:55:51.918438Z","shell.execute_reply":"2021-06-07T05:55:51.943346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's build a model with the selected 10 values.\nimport statsmodels.api as sm\nX_train_RFE = sm.add_constant(X_train_RFE)\nmodel1 = sm.OLS(y_train, X_train_RFE).fit()\nprint(model1.summary())","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:51.949174Z","iopub.execute_input":"2021-06-07T05:55:51.952171Z","iopub.status.idle":"2021-06-07T05:55:52.805398Z","shell.execute_reply.started":"2021-06-07T05:55:51.952111Z","shell.execute_reply":"2021-06-07T05:55:52.804095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the summary we can make following inferences:**\n- The R^2 is 0.822 and adjusted R^2 is 0.818. There is no huge difference between the two, which indeed is a good sign.\n- The p values are 0 except for weekday_mon. Hence, we'll check VIF before removing this.\n- Few of the variables have negative coefficients, for example season_spring, public holiday, misty, rainy days etc.This means that they effect the target negatively. However, their p values are < 0.05, which is okay. \n- We would think that during spring, the number of rentals will be high. However, the coefficient is negative, which is strange. \n- Rain, snow and misty weather do make the roads unsafe for travel, hence here if the rentals are reducing, it makes sense.\n- The coefficient for public holiday is also negative. These days are those which is spent by families together, or there is a huge procession / crowd going on. We could infer that because of this number of rentals is reducing during holidays.\n\n**Let's know more with VIF.**\n","metadata":{}},{"cell_type":"code","source":"# Checking Variance Inflation Factor\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n#Let's check the documentation to know more about this.\nhelp(variance_inflation_factor)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:52.80827Z","iopub.execute_input":"2021-06-07T05:55:52.808521Z","iopub.status.idle":"2021-06-07T05:55:52.816434Z","shell.execute_reply.started":"2021-06-07T05:55:52.808498Z","shell.execute_reply":"2021-06-07T05:55:52.815457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check VIF for one variable\nvariance_inflation_factor(X_train_RFE.values,2)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:52.818015Z","iopub.execute_input":"2021-06-07T05:55:52.818274Z","iopub.status.idle":"2021-06-07T05:55:52.828252Z","shell.execute_reply.started":"2021-06-07T05:55:52.81825Z","shell.execute_reply":"2021-06-07T05:55:52.826974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hence to check the VIF we need to give the values as a matrix with index number of the independent variable.**","metadata":{}},{"cell_type":"code","source":"# Now we will check VIF for all variables by storing it in database.\nvif = pd.DataFrame()\nvif['Features'] = X_train_RFE.columns\nvif['VIF'] = [variance_inflation_factor(X_train_RFE.values, i) for i in range(X_train_RFE.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif.sort_values(by = 'VIF', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:52.830081Z","iopub.execute_input":"2021-06-07T05:55:52.830815Z","iopub.status.idle":"2021-06-07T05:55:52.858269Z","shell.execute_reply.started":"2021-06-07T05:55:52.830768Z","shell.execute_reply":"2021-06-07T05:55:52.857394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the table above we can see that, Constant has highest VIF but we need this, hence ignore.<br> The VIF of weekday_mon is 1.01, very low actually. But it is insignificant (high p vlaue). So, we will drop this variable.**","metadata":{}},{"cell_type":"code","source":"X = X_train_RFE.drop('weekday_mon', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:52.863208Z","iopub.execute_input":"2021-06-07T05:55:52.863498Z","iopub.status.idle":"2021-06-07T05:55:52.868304Z","shell.execute_reply.started":"2021-06-07T05:55:52.863469Z","shell.execute_reply":"2021-06-07T05:55:52.867339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building the model again\nX_lr = sm.add_constant(X)\nmodel2 = sm.OLS(y_train, X_lr).fit()\nprint(model2.summary())","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:52.869437Z","iopub.execute_input":"2021-06-07T05:55:52.8698Z","iopub.status.idle":"2021-06-07T05:55:52.899293Z","shell.execute_reply.started":"2021-06-07T05:55:52.869775Z","shell.execute_reply":"2021-06-07T05:55:52.898597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**According to the summary:**\n- R^2 has reduced by 0.001 but adjusted R^2 is same. Deleting the variable was a good idea because R^2 and adjusted R^2 are little bit closer.\n- All p values are < .05 which makes them significant. \n- Those which had negative coefficient are still negative. We can then conclude that they effect target negatively. That is the target variable will increase when these variables decrease. \n","metadata":{}},{"cell_type":"markdown","source":"## Residual Analysis","metadata":{}},{"cell_type":"code","source":"# Checking for multicollinearity.\nfig, axes = plt.subplots(figsize = (20,10))\nsns.heatmap(df.corr(), annot = True, cmap = 'coolwarm', ax = axes, mask = (df.corr()<0.4) & (df.corr()>-0.4) )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:52.90019Z","iopub.execute_input":"2021-06-07T05:55:52.900456Z","iopub.status.idle":"2021-06-07T05:55:53.748125Z","shell.execute_reply.started":"2021-06-07T05:55:52.900422Z","shell.execute_reply":"2021-06-07T05:55:53.747292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(figsize = (20,10))\nsns.heatmap(X_lr.corr(), annot = True, cmap = 'coolwarm', mask = (X_lr.corr()<0.4) & (X_lr.corr()>-0.4))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:53.749215Z","iopub.execute_input":"2021-06-07T05:55:53.749636Z","iopub.status.idle":"2021-06-07T05:55:54.112001Z","shell.execute_reply.started":"2021-06-07T05:55:53.749608Z","shell.execute_reply":"2021-06-07T05:55:54.110966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif2 = pd.DataFrame()\nvif2['Features'] = X_lr.columns\nvif2['VIF'] = [variance_inflation_factor(X_lr.values, i) for i in range(X_lr.shape[1])]\nvif2","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.113287Z","iopub.execute_input":"2021-06-07T05:55:54.113541Z","iopub.status.idle":"2021-06-07T05:55:54.135889Z","shell.execute_reply.started":"2021-06-07T05:55:54.113516Z","shell.execute_reply":"2021-06-07T05:55:54.134375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Though correlation coefficient is 0.6, the VIF for season spring is 4.729 < 5. Hence we can ignore it.**","metadata":{}},{"cell_type":"code","source":"# Calculating Residuals.\ny_pred = model2.predict(X_lr)\nres = y_train - y_pred","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.137233Z","iopub.execute_input":"2021-06-07T05:55:54.137648Z","iopub.status.idle":"2021-06-07T05:55:54.144247Z","shell.execute_reply.started":"2021-06-07T05:55:54.137607Z","shell.execute_reply":"2021-06-07T05:55:54.142928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking normality of errors.\nfrom statsmodels.graphics.gofplots import qqplot\nqqplot(res, line = 's')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.145817Z","iopub.execute_input":"2021-06-07T05:55:54.146142Z","iopub.status.idle":"2021-06-07T05:55:54.287888Z","shell.execute_reply.started":"2021-06-07T05:55:54.146113Z","shell.execute_reply":"2021-06-07T05:55:54.28668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(res)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.289442Z","iopub.execute_input":"2021-06-07T05:55:54.289817Z","iopub.status.idle":"2021-06-07T05:55:54.462474Z","shell.execute_reply.started":"2021-06-07T05:55:54.289779Z","shell.execute_reply":"2021-06-07T05:55:54.461188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking Homoscedasity or Constant Variance\nsns.regplot(res, y_pred, line_kws = {'color':'red'})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.463894Z","iopub.execute_input":"2021-06-07T05:55:54.464292Z","iopub.status.idle":"2021-06-07T05:55:54.706473Z","shell.execute_reply.started":"2021-06-07T05:55:54.464244Z","shell.execute_reply":"2021-06-07T05:55:54.705531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# No Autocorrelation\n# In the summary we saw that Durbin - Watson test value is 2.074. We know that the value = 2 indicates no autocrrelation. \n# Hence, the assumption is followed.","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.707728Z","iopub.execute_input":"2021-06-07T05:55:54.7081Z","iopub.status.idle":"2021-06-07T05:55:54.711609Z","shell.execute_reply.started":"2021-06-07T05:55:54.708061Z","shell.execute_reply":"2021-06-07T05:55:54.710742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions using Final model","metadata":{}},{"cell_type":"code","source":"# Storing the names of selected features\nindex = list(X_lr.columns)\nindex.remove('const')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.713052Z","iopub.execute_input":"2021-06-07T05:55:54.713467Z","iopub.status.idle":"2021-06-07T05:55:54.725792Z","shell.execute_reply.started":"2021-06-07T05:55:54.713427Z","shell.execute_reply":"2021-06-07T05:55:54.724802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting the features and storing it as X_test\nX_test = df_test[index]\nX_test = sm.add_constant(X_test)\ny_test = df_test.pop('cnt')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.727598Z","iopub.execute_input":"2021-06-07T05:55:54.728056Z","iopub.status.idle":"2021-06-07T05:55:54.745149Z","shell.execute_reply.started":"2021-06-07T05:55:54.728009Z","shell.execute_reply":"2021-06-07T05:55:54.744196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicting on the test set\ny_test_pred = model2.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.746553Z","iopub.execute_input":"2021-06-07T05:55:54.746869Z","iopub.status.idle":"2021-06-07T05:55:54.752883Z","shell.execute_reply.started":"2021-06-07T05:55:54.74683Z","shell.execute_reply":"2021-06-07T05:55:54.751853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating R^2 and adjusted R^2\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_true = y_test, y_pred = y_test_pred)\nadj_r2 = 1 - ((1 - r2)*(X_test.shape[0] - X_test.shape[1]) / (X_test.shape[0] - X_test.shape[1] - 1))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.754395Z","iopub.execute_input":"2021-06-07T05:55:54.754682Z","iopub.status.idle":"2021-06-07T05:55:54.766049Z","shell.execute_reply.started":"2021-06-07T05:55:54.754654Z","shell.execute_reply":"2021-06-07T05:55:54.765149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's compare them\nr2, adj_r2","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.767366Z","iopub.execute_input":"2021-06-07T05:55:54.767789Z","iopub.status.idle":"2021-06-07T05:55:54.782739Z","shell.execute_reply.started":"2021-06-07T05:55:54.767748Z","shell.execute_reply":"2021-06-07T05:55:54.781911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This is really good. There is only 0.01 difference between R^2 and adjusted R^2. The model performed excetionally well on test data. Also 80% of the variance is now explained by the model.**","metadata":{}},{"cell_type":"code","source":"# Now let's see how much do each features contribute to the target variable.\nmodel2.params\n# Parameters or coefficients tells us how much is the count going to vary with unit change of our features. ","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.783936Z","iopub.execute_input":"2021-06-07T05:55:54.784209Z","iopub.status.idle":"2021-06-07T05:55:54.79733Z","shell.execute_reply.started":"2021-06-07T05:55:54.784185Z","shell.execute_reply":"2021-06-07T05:55:54.796488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cnt = 0.141396 + 0.489605 temp - 0.064774 season_spring + 0.052311 season_summer + 0.095684 season_winter + 0.233162 yr_2019 + 0.095415 mnth_sept - 0.099109 holiday_pubholiday - 0.299799 weathersit_light_rain_snow - 0.077023 weathersit_misty             ","metadata":{}},{"cell_type":"markdown","source":"**We can say that temperature has the greatest effect on rentals.**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T05:55:54.798273Z","iopub.execute_input":"2021-06-07T05:55:54.798644Z","iopub.status.idle":"2021-06-07T05:55:54.810037Z","shell.execute_reply.started":"2021-06-07T05:55:54.798618Z","shell.execute_reply":"2021-06-07T05:55:54.809135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}