{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation,MaxPooling2D\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nimport numpy as np\nimport os\nfrom keras.layers import Input\n\nfrom keras.optimizers import SGD \nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import *\nfrom keras.models import Model,Sequential\nfrom keras.layers import *\nfrom keras.activations import *\nfrom keras.callbacks import *\nimport numpy as np\nimport pandas as pd \nfrom numpy import zeros, newaxis\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_train=[]\nlabels_train_abnormal = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/train-abnormal.csv\")) \nlabels_train_acl = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/train-acl.csv\")) \nlabels_train_men = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/train-meniscus.csv\")) \nlabels_train.append(1)\nlabels_train.append(0)\nlabels_train.append(0)\n\nfor i in range (0,1129):\n    labels_train.append(labels_train_abnormal[i,1])\n    labels_train.append(labels_train_acl[i,1])\n    labels_train.append(labels_train_men[i,1])\nlabels_train=np.array(labels_train).reshape(-1, 3)\nlabels_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom PIL import Image\nX_Train_ax = []\nY_Train_ax=[]\nX_Train_cor=[]\nY_Train_cor=[]\nX_Train_sag=[]\nY_Train_sag=[]\n\nfor patient_ID in range(1130):\n    label=labels_train[patient_ID]\n    if(patient_ID<10):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/000'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/000'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/000'+str(patient_ID)+'.npy'\n    elif(patient_ID<100):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/00'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/00'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/00'+str(patient_ID)+'.npy'\n    elif(patient_ID<1000):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/0'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/0'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/0'+str(patient_ID)+'.npy'\n    else:\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/'+str(patient_ID)+'.npy'\n\n    d1Image = np.load(pathd1)\n    d2Image = np.load(pathd2)\n    d3Image = np.load(pathd3)\n    startd1=int((d1Image.shape[0]/2)-4)\n    endd1=int((d1Image.shape[0]/2)+4)\n    startd2=int((d2Image.shape[0]/2)-4)\n    endd2=int((d2Image.shape[0]/2)+4)\n    startd3=int((d3Image.shape[0]/2)-4)\n    endd3=int((d3Image.shape[0]/2)+4)\n\n    \n    image_tensor=d1Image[startd1:endd1,:,:].reshape(256,256,8)\n    X_Train_ax.append(image_tensor)\n    Y_Train_ax.append(label)\n    image_tensor2=d2Image[startd2:endd2,:,:].reshape(256,256,8)\n    X_Train_cor.append(image_tensor2)\n    Y_Train_cor.append(label)\n    image_tensor3=d3Image[startd3:endd3,:,:].reshape(256,256,8)\n    X_Train_sag.append(image_tensor3)\n    Y_Train_sag.append(label)\n\n    \nprint(np.asarray(X_Train_ax).shape)\nprint(np.asarray(Y_Train_ax).shape)\nprint(np.asarray(X_Train_cor).shape)\nprint(np.asarray(Y_Train_cor).shape)\nprint(np.asarray(X_Train_sag).shape)\nprint(np.asarray(Y_Train_sag).shape)\nX_Train_ax = np.array(X_Train_ax)\nY_Train_ax = np.array(Y_Train_ax)\nX_Train_cor = np.array(X_Train_cor)\nY_Train_cor = np.array(Y_Train_cor)\nX_Train_sag = np.array(X_Train_sag)\nY_Train_sag = np.array(Y_Train_sag)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_test=[]\nlabels_test_abnormal = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/valid-abnormal.csv\")) \nlabels_test_acl = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/valid-acl.csv\")) \nlabels_test_men = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/valid-meniscus.csv\")) \nlabels_test.append(0)\nlabels_test.append(0)\nlabels_test.append(0)\n\nfor i in range (118):\n    labels_test.append(labels_test_abnormal[i,1])\n    labels_test.append(labels_test_acl[i,1])\n    labels_test.append(labels_test_men[i,1])\nlabels_test=np.array(labels_test).reshape(-1, 3)\nlabels_test\n\nfrom PIL import Image\nX_Test_ax = []\nY_Test_ax=[]\nX_Test_cor=[]\nY_Test_cor=[]\nX_Test_sag=[]\nY_Test_sag=[]\n\nfor patient_ID in range(119):\n    label=labels_test[patient_ID]\n    patient_ID=1130+patient_ID\n    if(patient_ID<10):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/000'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/000'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/000'+str(patient_ID)+'.npy'\n    elif(patient_ID<100):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/00'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/00'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/00'+str(patient_ID)+'.npy'\n    elif(patient_ID<1000):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/0'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/0'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/0'+str(patient_ID)+'.npy'\n    else:\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/'+str(patient_ID)+'.npy'\n\n    d1Image = np.load(pathd1)\n    d2Image = np.load(pathd2)\n    d3Image = np.load(pathd3)\n    startd1=int((d1Image.shape[0]/2)-4)\n    endd1=int((d1Image.shape[0]/2)+4)\n    startd2=int((d2Image.shape[0]/2)-4)\n    endd2=int((d2Image.shape[0]/2)+4)\n    startd3=int((d3Image.shape[0]/2)-4)\n    endd3=int((d3Image.shape[0]/2)+4)\n\n    \n    image_tensor=d1Image[startd1:endd1,:,:].reshape(256,256,8)\n    X_Test_ax.append(image_tensor)\n    Y_Test_ax.append(label)\n    image_tensor2=d2Image[startd2:endd2,:,:].reshape(256,256,8)\n    X_Test_cor.append(image_tensor2)\n    Y_Test_cor.append(label)\n    image_tensor3=d3Image[startd3:endd3,:,:].reshape(256,256,8)\n    X_Test_sag.append(image_tensor3)\n    Y_Test_sag.append(label)\n\n    \n    \n    \nprint(np.asarray(X_Test_ax).shape)\nprint(np.asarray(Y_Test_ax).shape)\nprint(np.asarray(X_Test_cor).shape)\nprint(np.asarray(Y_Test_cor).shape)\nprint(np.asarray(X_Test_sag).shape)\nprint(np.asarray(Y_Test_sag).shape)\nX_Test_ax = np.array(X_Test_ax)\nY_Test_ax = np.array(Y_Test_ax)\nX_Test_cor = np.array(X_Test_cor)\nY_Test_cor = np.array(Y_Test_cor)\nX_Test_sag = np.array(X_Test_sag)\nY_Test_sag = np.array(Y_Test_sag)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_Test_ax_ab=Y_Test_ax[:,0]\nY_Train_ax_ab=Y_Train_ax[:,0]\nY_Test_ax_acl=Y_Test_ax[:,1]\nY_Train_ax_acl=Y_Train_ax[:,1]\nY_Test_ax_men=Y_Test_ax[:,2]\nY_Train_ax_men=Y_Train_ax[:,2]\n\nY_Test_cor_ab=Y_Test_cor[:,0]\nY_Train_cor_ab=Y_Train_cor[:,0]\nY_Test_cor_acl=Y_Test_cor[:,1]\nY_Train_cor_acl=Y_Train_cor[:,1]\nY_Test_cor_men=Y_Test_cor[:,2]\nY_Train_cor_men=Y_Train_cor[:,2]\n\nY_Test_sag_ab=Y_Test_sag[:,0]\nY_Train_sag_ab=Y_Train_sag[:,0]\nY_Test_sag_acl=Y_Test_sag[:,1]\nY_Train_sag_acl=Y_Train_sag[:,1]\nY_Test_sag_men=Y_Test_sag[:,2]\nY_Train_sag_men=Y_Train_sag[:,2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"InputShape=(256,256,8)\nNumClasses=2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VGG"},{"metadata":{"trusted":true},"cell_type":"code","source":"def VGG():\n    modelVGG = Sequential()\n    modelVGG.add(Conv2D(input_shape=InputShape,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    modelVGG.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    modelVGG.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    modelVGG.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    modelVGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    modelVGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n    modelVGG.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    modelVGG.add(Flatten())\n    modelVGG.add(Dense(units=4096,activation=\"relu\"))\n    modelVGG.add(Dense(units=4096,activation=\"relu\"))\n    modelVGG.add(Dense(units=1, activation=\"sigmoid\"))\n    return modelVGG","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG1=VGG()\nmodelVGG1.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG1.fit(X_Train_ax, Y_Train_ax_ab, epochs=10, batch_size=5)\nprint(modelVGG1.evaluate(X_Test_ax, Y_Test_ax_ab, verbose=2))\nmodelVGG1.save_weights('modelVGG1.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG2=VGG()\nmodelVGG2.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG2.fit(X_Train_ax, Y_Train_ax_acl, epochs=10, batch_size=5)\nprint(modelVGG2.evaluate(X_Test_ax, Y_Test_ax_acl, verbose=2))\nmodelVGG2.save_weights('modelVGG2.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG3=VGG()\nmodelVGG3.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG3.fit(X_Train_ax, Y_Train_ax_men, epochs=10, batch_size=5)\nprint(modelVGG3.evaluate(X_Test_ax, Y_Test_ax_men, verbose=2))\nmodelVGG3.save_weights('modelVGG3.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VGG COR\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG4=VGG()\nmodelVGG4.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG4.fit(X_Train_cor, Y_Train_cor_ab, epochs=10, batch_size=5)\nprint(modelVGG4.evaluate(X_Test_cor, Y_Test_cor_ab, verbose=2))\nmodelVGG4.save_weights('modelVGG4.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG5=VGG()\nmodelVGG5.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG5.fit(X_Train_cor, Y_Train_cor_acl, epochs=10, batch_size=5)\nprint(modelVGG5.evaluate(X_Test_cor, Y_Test_cor_acl, verbose=2))\nmodelVGG5.save_weights('modelVGG5.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG6=VGG()\nmodelVGG6.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG6.fit(X_Train_cor, Y_Train_cor_men, epochs=10, batch_size=5)\nprint(modelVGG6.evaluate(X_Test_cor, Y_Test_cor_men, verbose=2))\nmodelVGG6.save_weights('modelVGG6.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VGG SAG"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG7=VGG()\nmodelVGG7.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG7.fit(X_Train_sag, Y_Train_sag_ab, epochs=10, batch_size=5)\nprint(modelVGG7.evaluate(X_Test_sag, Y_Test_sag_ab, verbose=2))\nmodelVGG7.save_weights('modelVGG7.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG8=VGG()\nmodelVGG8.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG8.fit(X_Train_sag, Y_Train_sag_acl, epochs=10, batch_size=5)\nprint(modelVGG8.evaluate(X_Test_sag, Y_Test_sag_acl, verbose=2))\nmodelVGG8.save_weights('modelVGG8.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG9=VGG()\nmodelVGG9.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelVGG9.fit(X_Train_sag, Y_Train_sag_men, epochs=10, batch_size=5)\nprint(modelVGG9.evaluate(X_Test_sag, Y_Test_sag_men, verbose=2))\nmodelVGG9.save_weights('modelVGG9.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MOBILE NET"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_conv_block(tensor, channels, strides, alpha=1.0, name=''):\n    channels = int(channels * alpha)\n\n    x = Conv2D(channels,\n               kernel_size=(3, 3),\n               strides=strides,\n               use_bias=False,\n               padding='same',\n               name='{}_conv'.format(name))(tensor)\n    x = BatchNormalization(name='{}_bn'.format(name))(x)\n    x = Activation('relu', name='{}_act'.format(name))(x)\n    return x\n\n\ndef get_dw_sep_block(tensor, channels, strides, alpha=1.0, name=''):\n    \"\"\"Depthwise separable conv: A Depthwise conv followed by a Pointwise conv.\"\"\"\n    channels = int(channels * alpha)\n\n    # Depthwise\n    x = DepthwiseConv2D(kernel_size=(3, 3),\n                        strides=strides,\n                        use_bias=False,\n                        padding='same',\n                        name='{}_dw'.format(name))(tensor)\n    x = BatchNormalization(name='{}_bn1'.format(name))(x)\n    x = Activation('relu', name='{}_act1'.format(name))(x)\n\n    # Pointwise\n    x = Conv2D(channels,\n               kernel_size=(1, 1),\n               strides=(1, 1),\n               use_bias=False,\n               padding='same',\n               name='{}_pw'.format(name))(x)\n    x = BatchNormalization(name='{}_bn2'.format(name))(x)\n    x = Activation('relu', name='{}_act2'.format(name))(x)\n    return x\n\n\ndef MobileNet(shape, num_classes, alpha=1.0, include_top=True, weights=None):\n    x_in = Input(shape=shape)\n\n    x = get_conv_block(x_in, 32, (2, 2), alpha=alpha, name='initial')\n\n    layers = [\n        (64, (1, 1)),\n        (128, (2, 2)),\n        (128, (1, 1)),\n        (256, (2, 2)),\n        (256, (1, 1)),\n        (512, (2, 2)),\n        *[(512, (1, 1)) for _ in range(5)],\n        (1024, (2, 2)),\n        (1024, (2, 2))\n    ]\n\n    for i, (channels, strides) in enumerate(layers):\n        x = get_dw_sep_block(x, channels, strides, alpha=alpha, name='block{}'.format(i))\n\n    if include_top:\n        x = GlobalAvgPool2D(name='global_avg')(x)\n        x = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=x_in, outputs=x)\n\n    if weights is not None:\n        model.load_weights(weights, by_name=True)\n\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MobileNet AXIAL"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet1=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet1.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet1.fit(X_Train_ax, Y_Train_ax_ab, epochs=10, batch_size=5)\nprint(modelMobileNet1.evaluate(X_Test_ax, Y_Test_ax_ab, verbose=2))\nmodelMobileNet1.save_weights('modelMobileNet1.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet2=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet2.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet2.fit(X_Train_ax, Y_Train_ax_acl, epochs=10, batch_size=5)\nprint(modelMobileNet2.evaluate(X_Test_ax, Y_Test_ax_acl, verbose=2))\nmodelMobileNet2.save_weights('modelMobileNet2.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet3=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet3.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet3.fit(X_Train_ax, Y_Train_ax_men, epochs=10, batch_size=5)\nprint(modelMobileNet3.evaluate(X_Test_ax, Y_Test_ax_men, verbose=2))\nmodelMobileNet3.save_weights('modelMobileNet3.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MobileNet COR"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet4=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet4.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet4.fit(X_Train_cor, Y_Train_cor_ab, epochs=10, batch_size=5)\nprint(modelMobileNet4.evaluate(X_Test_cor, Y_Test_cor_ab, verbose=2))\nmodelMobileNet4.save_weights('modelMobileNet4.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet5=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet5.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet5.fit(X_Train_cor, Y_Train_cor_acl, epochs=10, batch_size=5)\nprint(modelMobileNet5.evaluate(X_Test_cor, Y_Test_cor_acl, verbose=2))\nmodelMobileNet5.save_weights('modelMobileNet5.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet6=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet6.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet6.fit(X_Train_cor, Y_Train_cor_men, epochs=10, batch_size=5)\nprint(modelMobileNet6.evaluate(X_Test_cor, Y_Test_cor_men, verbose=2))\nmodelMobileNet6.save_weights('modelMobileNet6.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MobileNet SAG"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet7=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet7.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet7.fit(X_Train_sag, Y_Train_sag_ab, epochs=10, batch_size=5)\nprint(modelMobileNet7.evaluate(X_Test_sag, Y_Test_sag_ab, verbose=2))\nmodelMobileNet7.save_weights('modelMobileNet7.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet8=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet8.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\n\nmodelMobileNet8.fit(X_Train_sag, Y_Train_sag_acl, epochs=10, batch_size=5)\nprint(modelMobileNet8.evaluate(X_Test_sag, Y_Test_sag_acl, verbose=2))\nmodelMobileNet8.save_weights('modelMobileNet8.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelMobileNet9=MobileNet(shape=InputShape,num_classes=NumClasses)\nmodelMobileNet9.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelMobileNet9.fit(X_Train_sag, Y_Train_sag_men, epochs=10, batch_size=5)\nprint(modelMobileNet9.evaluate(X_Test_sag, Y_Test_sag_men, verbose=2))\nmodelMobileNet9.save_weights('modelMobileNet9.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RESNET\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# Common imports\nimport numpy as np\nimport os\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import f1_score, recall_score, precision_score\n\n\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils, to_categorical\nfrom keras.utils.data_utils import get_file\nfrom keras.callbacks import Callback\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\nimport keras.backend as K\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#identity_block\n\ndef identity_block(X, f, filters, stage, block):\n\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolutional_block(X, f, filters, stage, block, s = 2):\n    \"\"\"\n    Implementation of the convolutional block as defined in Figure 4\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n    \n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve Filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    # Second component of main path\n    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH ####\n    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResNet50(input_shape = (256, 256, 8)):\n    \"\"\"\n    Implementation of the popular ResNet50 the following architecture:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n\n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 3, block='a', s = 2)\n    X = identity_block(X, 3, [64, 64, 256], stage=3, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=3, block='c')\n    X = identity_block(X, 3, [64, 64, 256], stage=3, block='d')\n\n    # Stage 4 \n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n\n    # Stage 5 \n    X = convolutional_block(X, f = 3, filters = [256,256, 1024], stage = 5, block='a', s = 2)\n    X = identity_block(X, 3, [256,256, 1024], stage=5, block='b')\n    X = identity_block(X, 3, [256,256, 1024], stage=5, block='c')\n\n    # AVGPOOL\n    X = AveragePooling2D(pool_size=(2,2), name='avg_pool')(X)\n    \n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(1, activation='sigmoid')(X)\n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RESNET AXIAL"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN1 = ResNet50(input_shape = (256, 256, 8))\nmodelRN1.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN1.fit(X_Train_ax, Y_Train_ax_ab, epochs=10, batch_size=5)\nprint(modelRN1.evaluate(X_Test_ax, Y_Test_ax_ab, verbose=2))\nmodelRN1.save_weights('modelRN1.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN2 = ResNet50(input_shape = (256, 256, 8))\nmodelRN2.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN2.fit(X_Train_ax, Y_Train_ax_acl, epochs=10, batch_size=5)\nprint(modelRN2.evaluate(X_Test_ax, Y_Test_ax_acl, verbose=2))\nmodelRN2.save_weights('modelRN2.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN3 = ResNet50(input_shape = (256, 256, 8))\nmodelRN3.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN3.fit(X_Train_ax, Y_Train_ax_men, epochs=10, batch_size=5)\nprint(modelRN3.evaluate(X_Test_ax, Y_Test_ax_men, verbose=2))\nmodelRN3.save_weights('modelRN3.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RESNET COR"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN4 = ResNet50(input_shape = (256, 256, 8))\nmodelRN4.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN4.fit(X_Train_cor, Y_Train_cor_ab, epochs=10, batch_size=5)\nprint(modelRN4.evaluate(X_Test_cor, Y_Test_cor_ab, verbose=2))\nmodelRN4.save_weights('modelRN4.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN5 = ResNet50(input_shape = (256, 256, 8))\nmodelRN5.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN5.fit(X_Train_cor, Y_Train_cor_acl, epochs=10, batch_size=5)\nprint(modelRN5.evaluate(X_Test_cor, Y_Test_cor_acl, verbose=2))\nmodelRN5.save_weights('modelRN5.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN6 = ResNet50(input_shape = (256, 256, 8))\nmodelRN6.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN6.fit(X_Train_cor, Y_Train_cor_men, epochs=10, batch_size=5)\nprint(modelRN6.evaluate(X_Test_cor, Y_Test_cor_men, verbose=2))\nmodelRN6.save_weights('modelRN6.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RESNET SAG"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN7 = ResNet50(input_shape = (256, 256, 8))\nmodelRN7.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN7.fit(X_Train_sag, Y_Train_sag_ab, epochs=10, batch_size=5)\nprint(modelRN7.evaluate(X_Test_sag, Y_Test_sag_ab, verbose=2))\nmodelRN7.save_weights('modelRN7.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN8 = ResNet50(input_shape = (256, 256, 8))\nmodelRN8.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN8.fit(X_Train_sag, Y_Train_sag_acl, epochs=10, batch_size=5)\nprint(modelRN8.evaluate(X_Test_sag, Y_Test_sag_acl, verbose=2))\nmodelRN8.save_weights('modelRN8.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelRN9 = ResNet50(input_shape = (256, 256, 8))\nmodelRN9.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.SGD(learning_rate=0.002, momentum=0.9),metrics=[\"accuracy\"])\nmodelRN9.fit(X_Train_sag, Y_Train_sag_men, epochs=10, batch_size=5)\nprint(modelRN9.evaluate(X_Test_sag, Y_Test_sag_men, verbose=2))\nmodelRN9.save_weights('modelRN9.h5')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TRANSFER LEARNING - VGG19**"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_train=[]\nlabels_train_abnormal = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/train-abnormal.csv\")) \nlabels_train_acl = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/train-acl.csv\")) \nlabels_train_men = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/train-meniscus.csv\")) \nlabels_train.append(1)\nlabels_train.append(0)\nlabels_train.append(0)\n\nfor i in range (0,1129):\n    labels_train.append(labels_train_abnormal[i,1])\n    labels_train.append(labels_train_acl[i,1])\n    labels_train.append(labels_train_men[i,1])\nlabels_train=np.array(labels_train).reshape(-1, 3)\n\n\n\nfrom PIL import Image\nX_Train_ax = []\nY_Train_ax=[]\nX_Train_cor=[]\nY_Train_cor=[]\nX_Train_sag=[]\nY_Train_sag=[]\n\nfor patient_ID in range(1130):\n    label=labels_train[patient_ID]\n    if(patient_ID<10):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/000'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/000'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/000'+str(patient_ID)+'.npy'\n    elif(patient_ID<100):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/00'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/00'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/00'+str(patient_ID)+'.npy'\n    elif(patient_ID<1000):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/0'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/0'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/0'+str(patient_ID)+'.npy'\n    else:\n        pathd1='../input/mrnet-v1/MRNet-v1.0/train/' + 'axial/'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/train/' + 'coronal/'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/train/' + 'sagittal/'+str(patient_ID)+'.npy'\n\n    d1Image = np.load(pathd1)\n    d2Image = np.load(pathd2)\n    d3Image = np.load(pathd3)\n    startd1=int((d1Image.shape[0]/2)-1)\n    endd1=int((d1Image.shape[0]/2)+2)\n    startd2=int((d2Image.shape[0]/2)-1)\n    endd2=int((d2Image.shape[0]/2)+2)\n    startd3=int((d3Image.shape[0]/2)-1)\n    endd3=int((d3Image.shape[0]/2)+2)\n\n    \n    image_tensor=d1Image[startd1:endd1,:,:].reshape(256,256,3)\n    X_Train_ax.append(image_tensor)\n    Y_Train_ax.append(label)\n    image_tensor2=d2Image[startd2:endd2,:,:].reshape(256,256,3)\n    X_Train_cor.append(image_tensor2)\n    Y_Train_cor.append(label)\n    image_tensor3=d3Image[startd3:endd3,:,:].reshape(256,256,3)\n    X_Train_sag.append(image_tensor3)\n    Y_Train_sag.append(label)\n\n    \nprint(np.asarray(X_Train_ax).shape)\nprint(np.asarray(Y_Train_ax).shape)\nprint(np.asarray(X_Train_cor).shape)\nprint(np.asarray(Y_Train_cor).shape)\nprint(np.asarray(X_Train_sag).shape)\nprint(np.asarray(Y_Train_sag).shape)\nX_Train_ax = np.array(X_Train_ax)\nY_Train_ax = np.array(Y_Train_ax)\nX_Train_cor = np.array(X_Train_cor)\nY_Train_cor = np.array(Y_Train_cor)\nX_Train_sag = np.array(X_Train_sag)\nY_Train_sag = np.array(Y_Train_sag)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_test=[]\nlabels_test_abnormal = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/valid-abnormal.csv\")) \nlabels_test_acl = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/valid-acl.csv\")) \nlabels_test_men = pd.DataFrame.to_numpy(pd.read_csv(\"../input/mrnet-v1/MRNet-v1.0/valid-meniscus.csv\")) \nlabels_test.append(0)\nlabels_test.append(0)\nlabels_test.append(0)\n\nfor i in range (118):\n    labels_test.append(labels_test_abnormal[i,1])\n    labels_test.append(labels_test_acl[i,1])\n    labels_test.append(labels_test_men[i,1])\nlabels_test=np.array(labels_test).reshape(-1, 3)\nlabels_test\n\nfrom PIL import Image\nX_Test_ax = []\nY_Test_ax=[]\nX_Test_cor=[]\nY_Test_cor=[]\nX_Test_sag=[]\nY_Test_sag=[]\n\nfor patient_ID in range(119):\n    label=labels_test[patient_ID]\n    patient_ID=1130+patient_ID\n    if(patient_ID<10):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/000'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/000'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/000'+str(patient_ID)+'.npy'\n    elif(patient_ID<100):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/00'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/00'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/00'+str(patient_ID)+'.npy'\n    elif(patient_ID<1000):\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/0'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/0'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/0'+str(patient_ID)+'.npy'\n    else:\n        pathd1='../input/mrnet-v1/MRNet-v1.0/valid/' + 'axial/'+str(patient_ID)+'.npy'\n        pathd2='../input/mrnet-v1/MRNet-v1.0/valid/' + 'coronal/'+str(patient_ID)+'.npy'\n        pathd3='../input/mrnet-v1/MRNet-v1.0/valid/' + 'sagittal/'+str(patient_ID)+'.npy'\n\n    d1Image = np.load(pathd1)\n    d2Image = np.load(pathd2)\n    d3Image = np.load(pathd3)\n    startd1=int((d1Image.shape[0]/2)-1)\n    endd1=int((d1Image.shape[0]/2)+2)\n    startd2=int((d2Image.shape[0]/2)-1)\n    endd2=int((d2Image.shape[0]/2)+2)\n    startd3=int((d3Image.shape[0]/2)-1)\n    endd3=int((d3Image.shape[0]/2)+2)\n\n    \n    image_tensor=d1Image[startd1:endd1,:,:].reshape(256,256,3)\n    X_Test_ax.append(image_tensor)\n    Y_Test_ax.append(label)\n    image_tensor2=d2Image[startd2:endd2,:,:].reshape(256,256,3)\n    X_Test_cor.append(image_tensor2)\n    Y_Test_cor.append(label)\n    image_tensor3=d3Image[startd3:endd3,:,:].reshape(256,256,3)\n    X_Test_sag.append(image_tensor3)\n    Y_Test_sag.append(label)\n\n    \n    \n    \nprint(np.asarray(X_Test_ax).shape)\nprint(np.asarray(Y_Test_ax).shape)\nprint(np.asarray(X_Test_cor).shape)\nprint(np.asarray(Y_Test_cor).shape)\nprint(np.asarray(X_Test_sag).shape)\nprint(np.asarray(Y_Test_sag).shape)\nX_Test_ax = np.array(X_Test_ax)\nY_Test_ax = np.array(Y_Test_ax)\nX_Test_cor = np.array(X_Test_cor)\nY_Test_cor = np.array(Y_Test_cor)\nX_Test_sag = np.array(X_Test_sag)\nY_Test_sag = np.array(Y_Test_sag)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_Test_ax_ab=Y_Test_ax[:,0]\nY_Train_ax_ab=Y_Train_ax[:,0]\nY_Test_ax_acl=Y_Test_ax[:,1]\nY_Train_ax_acl=Y_Train_ax[:,1]\nY_Test_ax_men=Y_Test_ax[:,2]\nY_Train_ax_men=Y_Train_ax[:,2]\n\nY_Test_cor_ab=Y_Test_cor[:,0]\nY_Train_cor_ab=Y_Train_cor[:,0]\nY_Test_cor_acl=Y_Test_cor[:,1]\nY_Train_cor_acl=Y_Train_cor[:,1]\nY_Test_cor_men=Y_Test_cor[:,2]\nY_Train_cor_men=Y_Train_cor[:,2]\n\nY_Test_sag_ab=Y_Test_sag[:,0]\nY_Train_sag_ab=Y_Train_sag[:,0]\nY_Test_sag_acl=Y_Test_sag[:,1]\nY_Train_sag_acl=Y_Train_sag[:,1]\nY_Test_sag_men=Y_Test_sag[:,2]\nY_Train_sag_men=Y_Train_sag[:,2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\npretrained_model = tf.keras.applications.ResNet50(input_shape=(256,256,3), include_top=False)\npretrained_model.trainable = False\n\nmodelTL = tf.keras.Sequential([\n    pretrained_model,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n    \n])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"layers tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in modelTL.layers[:4]:\n    layer.trainable=False\nfor layer in modelTL.layers[4:]:\n    layer.trainable=True\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"model training"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nmodelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Nadam',metrics=[\"accuracy\"])\nmodelTL.fit(X_Train_sag, Y_Train_sag_men, epochs=10, batch_size=32)\nprint(modelTL.evaluate(X_Test_sag, Y_Test_sag_men, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Nadam',metrics=[\"accuracy\"])\nmodelTL.fit(X_Train_sag, Y_Train_sag_acl, epochs=10, batch_size=32)\nprint(modelTL.evaluate(X_Test_sag, Y_Test_sag_acl, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Nadam',metrics=[\"accuracy\"])\nmodelTL.fit(X_Train_sag, Y_Train_sag_ab, epochs=10, batch_size=10)\nprint(modelTL.evaluate(X_Test_sag, Y_Test_sag_ab, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Adamax',metrics=[\"accuracy\"]) #more epochs\nmodelTL.fit(X_Train_cor, Y_Train_cor_men, epochs=50, batch_size=32)\nprint(modelTL.evaluate(X_Test_cor, Y_Test_cor_men, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Adamax',metrics=[\"accuracy\"]) #more epochs\nmodelTL.fit(X_Train_cor, Y_Train_cor_acl, epochs=10, batch_size=32)\nprint(modelTL.evaluate(X_Test_cor, Y_Test_cor_acl, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Adamax',metrics=[\"accuracy\"]) #more epochs\nmodelTL.fit(X_Train_cor, Y_Train_cor_ab, epochs=10, batch_size=32)\nprint(modelTL.evaluate(X_Test_cor, Y_Test_cor_ab, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Adamax',metrics=[\"accuracy\"]) #more epochs\nmodelTL.fit(X_Train_ax, Y_Train_ax_men, epochs=50, batch_size=32)\nprint(modelTL.evaluate(X_Test_ax, Y_Test_ax_men, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Adamax',metrics=[\"accuracy\"]) #more epochs\nmodelTL.fit(X_Train_ax, Y_Train_ax_acl, epochs=10, batch_size=32)\nprint(modelTL.evaluate(X_Test_ax, Y_Test_ax_acl, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelTL.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='Adamax',metrics=[\"accuracy\"]) #more epochs\nmodelTL.fit(X_Train_ax, Y_Train_ax_ab, epochs=10, batch_size=32)\nprint(modelTL.evaluate(X_Test_ax, Y_Test_ax_ab, verbose=2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}