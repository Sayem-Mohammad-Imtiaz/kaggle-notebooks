{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## I. Filter Methods\n1. Constant Features\n1. Quasi-Constant Features\n1. Duplicate Features\n1. Correlation\n1. Chi Square\n1. ANOVA\n1. Single Feature Model performance metrics\n1. Target Mean Encoding\n\n## II. Wrapper Methods\n1. Step Forward\n1. Step Backward\n1. Exhaustive\n\n## III. Embedded Methods\n1. Regression Coefficients\n1. Regularization\n1. Trees","metadata":{}},{"cell_type":"code","source":"!pip install fast_ml --upgrade","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:46:57.21444Z","iopub.execute_input":"2021-07-04T18:46:57.214782Z","iopub.status.idle":"2021-07-04T18:47:02.576371Z","shell.execute_reply.started":"2021-07-04T18:46:57.214754Z","shell.execute_reply":"2021-07-04T18:47:02.575419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fast_ml.utilities import display_all\nfrom fast_ml import eda\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 1000)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nSEED = 2021\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T18:47:02.578001Z","iopub.execute_input":"2021-07-04T18:47:02.578258Z","iopub.status.idle":"2021-07-04T18:47:02.589387Z","shell.execute_reply.started":"2021-07-04T18:47:02.578231Z","shell.execute_reply":"2021-07-04T18:47:02.588458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dataset-1/dataset_1.csv')\nprint('Shape of Dataframe : ', df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:47:05.43032Z","iopub.execute_input":"2021-07-04T18:47:05.430665Z","iopub.status.idle":"2021-07-04T18:47:06.711827Z","shell.execute_reply.started":"2021-07-04T18:47:05.430634Z","shell.execute_reply":"2021-07-04T18:47:06.710899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.memory_usage()/1024","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:14:43.27275Z","iopub.execute_input":"2021-06-28T09:14:43.273307Z","iopub.status.idle":"2021-06-28T09:14:43.299647Z","shell.execute_reply.started":"2021-06-28T09:14:43.273261Z","shell.execute_reply":"2021-06-28T09:14:43.298606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_all(eda.df_info(df))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:14:04.197424Z","iopub.execute_input":"2021-06-28T09:14:04.197888Z","iopub.status.idle":"2021-06-28T09:14:04.873286Z","shell.execute_reply.started":"2021-06-28T09:14:04.197858Z","shell.execute_reply":"2021-06-28T09:14:04.872272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['var_1','var_20']].info()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:12:48.640993Z","iopub.execute_input":"2021-06-28T09:12:48.641365Z","iopub.status.idle":"2021-06-28T09:12:48.656294Z","shell.execute_reply.started":"2021-06-28T09:12:48.641333Z","shell.execute_reply":"2021-06-28T09:12:48.65508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Constant Features","metadata":{}},{"cell_type":"code","source":"constant_features = [var for var in df.columns if df[var].nunique(dropna=False) ==1]\nprint(len(constant_features))\nprint(constant_features)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T06:13:23.532977Z","iopub.execute_input":"2021-06-24T06:13:23.533594Z","iopub.status.idle":"2021-06-24T06:13:23.678747Z","shell.execute_reply.started":"2021-06-24T06:13:23.533536Z","shell.execute_reply":"2021-06-24T06:13:23.677552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (df['var_23'].nunique(dropna=False))\nprint (df['var_23'].unique())","metadata":{"execution":{"iopub.status.busy":"2021-06-24T06:13:30.132469Z","iopub.execute_input":"2021-06-24T06:13:30.132961Z","iopub.status.idle":"2021-06-24T06:13:30.141866Z","shell.execute_reply.started":"2021-06-24T06:13:30.13292Z","shell.execute_reply":"2021-06-24T06:13:30.140466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (df['var_294'].nunique(dropna=False))\nprint (df['var_294'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (df['var_167'].nunique(dropna=False))\nprint (df['var_167'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Quasi-Constant Features","metadata":{}},{"cell_type":"code","source":"quasi_constant_feats = []\nthreshold = .99\n#var = 'var_101'\nfor var in df.columns:\n    s = df[var].value_counts(normalize=True, dropna=False)\n    if s.iloc[0]>=threshold:\n        quasi_constant_feats.append(var)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(quasi_constant_feats))\nprint(quasi_constant_feats)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_constant_features(df, threshold=0.99, dropna=False):\n    '''\n    For a given dataframe, identify the constant and quasi constant features.\n    To get all the constant & quasi constant features in a list - constant_features_df['Var'].to_list()\n    \n    Parameters:\n    -----------\n        df: 'dataframe'\n        threshold: 'float'. default = 0.99\n        dropna: 'bool'. default = false\n        \n    Returns:\n    --------\n        constant_features_df: 'dataframe'\n    '''\n    constant_features = []\n    constant_features_df = pd.DataFrame(columns=['Desc', 'Var', 'Value', 'Perc'])\n    all_vars = list(df.columns)\n    i=0\n    for var in all_vars:\n        s = df[var].value_counts(normalize=True, dropna=dropna)\n        value = s.index[0]\n        perc = s.iloc[0]\n    \n        if perc==1:\n            constant_features_df.loc[i] = ['Constant', var, value, 100*perc]\n\n        elif perc>threshold:\n            constant_features_df.loc[i] = ['Quasi Constant', var, value, 100*perc]\n    \n        i=i+1\n    \n    constant_features_df = constant_features_df.sort_values(by='Perc', ascending=False, ignore_index=True) \n\n    return constant_features_df","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:20:43.795211Z","iopub.execute_input":"2021-06-25T09:20:43.795543Z","iopub.status.idle":"2021-06-25T09:20:43.80287Z","shell.execute_reply.started":"2021-06-25T09:20:43.795513Z","shell.execute_reply":"2021-06-25T09:20:43.801897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"constant_features = get_constant_features(df, threshold=0.99, dropna=False)\nconstant_features","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:20:48.51398Z","iopub.execute_input":"2021-06-25T09:20:48.514492Z","iopub.status.idle":"2021-06-25T09:20:49.450143Z","shell.execute_reply.started":"2021-06-25T09:20:48.514448Z","shell.execute_reply":"2021-06-25T09:20:49.449325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(constant_features['Var'].to_list())","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:20:53.998011Z","iopub.execute_input":"2021-06-25T09:20:53.998353Z","iopub.status.idle":"2021-06-25T09:20:54.007707Z","shell.execute_reply.started":"2021-06-25T09:20:53.998324Z","shell.execute_reply":"2021-06-25T09:20:54.005122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold=0.99\nconstant_features = []\nconstant_features_df = pd.DataFrame(columns=['Desc', 'Var', 'Value', 'Perc'])\nall_vars = list(df.columns)\ni=0\nfor var in all_vars:\n    s = df[var].value_counts(normalize=True, dropna=False)\n    value = s.index[0]\n    perc = s.iloc[0]\n    \n    if perc==1:\n        constant_features_df.loc[i] = ['Constant', var, value, 100*perc]\n    \n    elif perc>threshold:\n        constant_features_df.loc[i] = ['Quasi Constant', var, value, 100*perc]\n    \n    i=i+1\n#     if df[var].nunique() ==1:\n#         constant_features.append(var)\n#         constant_features_df.loc[i] = ['Constant', var, 100]\n#         i=i+1\n\n# new_vars = list(set(all_vars) - set(constant_features))\n\n\n# for var in new_vars:\n#     s = df[var].value_counts(normalize=True, dropna=False)\n#     if s.iloc[0]>threshold:\n#         constant_features_df.loc[i] = ['Quasi Constant', var, 100*s.iloc[0]]\n#         i=i+1\n        \nconstant_features_df = constant_features_df.sort_values(by='Perc', ascending=False, ignore_index=True) \n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:24:05.982662Z","iopub.execute_input":"2021-06-24T07:24:05.983223Z","iopub.status.idle":"2021-06-24T07:24:07.033258Z","shell.execute_reply.started":"2021-06-24T07:24:05.983188Z","shell.execute_reply":"2021-06-24T07:24:07.031932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Duplicate Features","metadata":{}},{"cell_type":"code","source":"l1 = [1,2,3,4,5,6, 'a']\nl2 = [1,2,3,4,5,6, 'a']\n\nfor x in l1:\n    for y in l2:\n        if x==y:\n            continue\n        else:\n            print(x, '---', y)\n    l2.remove(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['var_1'].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:25.287685Z","iopub.execute_input":"2021-06-25T09:24:25.288082Z","iopub.status.idle":"2021-06-25T09:24:25.296895Z","shell.execute_reply.started":"2021-06-25T09:24:25.288047Z","shell.execute_reply":"2021-06-25T09:24:25.295736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['var_6'].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:25:32.326748Z","iopub.execute_input":"2021-06-25T09:25:32.32709Z","iopub.status.idle":"2021-06-25T09:25:32.334415Z","shell.execute_reply.started":"2021-06-25T09:25:32.32706Z","shell.execute_reply":"2021-06-25T09:25:32.333445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['var_7'].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:25:18.194345Z","iopub.execute_input":"2021-06-25T09:25:18.194676Z","iopub.status.idle":"2021-06-25T09:25:18.201655Z","shell.execute_reply.started":"2021-06-25T09:25:18.194646Z","shell.execute_reply":"2021-06-25T09:25:18.200648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['var_6', 'var_7']].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:25:44.087168Z","iopub.execute_input":"2021-06-25T09:25:44.087515Z","iopub.status.idle":"2021-06-25T09:25:44.10415Z","shell.execute_reply.started":"2021-06-25T09:25:44.087482Z","shell.execute_reply":"2021-06-25T09:25:44.102442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicate_features_df = pd.DataFrame(columns = ['Desc', 'feature1', 'feature2'])\nduplicate_features_ = []\nduplicate_pairs_ = {}\n#duplicate_df = pd.DataFrame(columns = ['feature', 'duplicate_features'])\n\nix=0\nfor i,v1 in enumerate(df.columns,0):\n    #tmp_df = pd.DataFrame()\n    duplicate_feat = []\n    if v1 not in duplicate_features_:\n        for v2 in df.columns[i+1:]:\n            if df[v1].nunique() == df[v2].nunique():\n                \n                if df[v1].equals(df[v2]):\n                    duplicate_features_.append(v2)\n                    duplicate_feat.append(v2)\n                    duplicate_features_df.loc[ix] = ['Duplicate Values', v1, v2]\n                    ix=ix+1\n                \n                elif df[[v1, v2]].drop_duplicates().shape[0] == df[v1].nunique():\n                    duplicate_features_df.loc[ix] = ['Duplicate Index', v1, v2]\n                    ix=ix+1\n                    \n        if duplicate_feat:\n            duplicate_pairs_[v1] = duplicate_feat\n            #tmp_df['feature'] = [v1]\n            #tmp_df['duplicate_features'] = [duplicate_feat]\n            #duplicate_df = duplicate_df.append(tmp_df)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:02:07.653874Z","iopub.execute_input":"2021-07-04T18:02:07.654291Z","iopub.status.idle":"2021-07-04T18:03:15.046184Z","shell.execute_reply.started":"2021-07-04T18:02:07.654259Z","shell.execute_reply":"2021-07-04T18:03:15.045345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_duplicate_features(df):\n    '''\n    For a given dataframe, identify the duplicate features\n    To get all the constant & quasi constant features in a list - duplicate_features_df['feature1'].to_list()\n    \n    Parameters:\n    -----------\n        df: 'dataframe'\n        \n    Returns:\n    --------\n        duplicate_features_df: 'dataframe'\n    \n    '''\n    duplicate_features_df = pd.DataFrame(columns = ['Desc', 'feature1', 'feature2'])\n    duplicate_features_ = []\n    ix=0\n    for i,v1 in enumerate(df.columns,0):\n        if v1 not in duplicate_features_:\n            for v2 in df.columns[i+1:]:\n                if df[v1].nunique() == df[v2].nunique():\n                    # This check for duplicate values\n                    if df[v1].equals(df[v2]):\n                        duplicate_features_.append(v2)\n                        duplicate_feat.append(v2)\n                        duplicate_features_df.loc[ix] = ['Duplicate Values', v1, v2]\n                        ix=ix+1\n                    \n                    # This check for duplicate index\n                    elif df[[v1, v2]].drop_duplicates().shape[0] == df[v1].nunique():\n                        duplicate_features_df.loc[ix] = ['Duplicate Index', v1, v2]\n                        ix=ix+1\n    duplicate_features_df = duplicate_features_df.sort_values(by='Desc', ascending=False, ignore_index=True)\n    \n    return duplicate_features_df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T19:05:46.902157Z","iopub.execute_input":"2021-07-04T19:05:46.902471Z","iopub.status.idle":"2021-07-04T19:05:46.909014Z","shell.execute_reply.started":"2021-07-04T19:05:46.902443Z","shell.execute_reply":"2021-07-04T19:05:46.908061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_duplicate_features(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T19:05:51.403694Z","iopub.execute_input":"2021-07-04T19:05:51.404011Z","iopub.status.idle":"2021-07-04T19:06:57.522471Z","shell.execute_reply.started":"2021-07-04T19:05:51.403982Z","shell.execute_reply":"2021-07-04T19:06:57.521498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['var_2'].equals(df['var_234'])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:04:41.02254Z","iopub.execute_input":"2021-07-04T18:04:41.02289Z","iopub.status.idle":"2021-07-04T18:04:41.028288Z","shell.execute_reply.started":"2021-07-04T18:04:41.022861Z","shell.execute_reply":"2021-07-04T18:04:41.027379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['var_2', 'var_234']].drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:05:07.403797Z","iopub.execute_input":"2021-07-04T18:05:07.404128Z","iopub.status.idle":"2021-07-04T18:05:07.415835Z","shell.execute_reply.started":"2021-07-04T18:05:07.404099Z","shell.execute_reply":"2021-07-04T18:05:07.415012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['var_2', 'var_234']]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:03:42.813212Z","iopub.execute_input":"2021-07-04T18:03:42.813541Z","iopub.status.idle":"2021-07-04T18:03:42.824644Z","shell.execute_reply.started":"2021-07-04T18:03:42.813511Z","shell.execute_reply":"2021-07-04T18:03:42.823737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicate_features_df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:03:22.993396Z","iopub.execute_input":"2021-07-04T18:03:22.993754Z","iopub.status.idle":"2021-07-04T18:03:23.006482Z","shell.execute_reply.started":"2021-07-04T18:03:22.993723Z","shell.execute_reply":"2021-07-04T18:03:23.005592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(duplicate_features_)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T23:00:14.431521Z","iopub.execute_input":"2021-05-23T23:00:14.431829Z","iopub.status.idle":"2021-05-23T23:00:14.43601Z","shell.execute_reply.started":"2021-05-23T23:00:14.431796Z","shell.execute_reply":"2021-05-23T23:00:14.43527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(duplicate_pairs_)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T23:00:20.067264Z","iopub.execute_input":"2021-05-23T23:00:20.067596Z","iopub.status.idle":"2021-05-23T23:00:20.071933Z","shell.execute_reply.started":"2021-05-23T23:00:20.067565Z","shell.execute_reply":"2021-05-23T23:00:20.071202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[item for sub_list in list(duplicate_pairs_.values()) for item in sub_list]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T23:26:08.5703Z","iopub.execute_input":"2021-05-23T23:26:08.570916Z","iopub.status.idle":"2021-05-23T23:26:08.576353Z","shell.execute_reply.started":"2021-05-23T23:26:08.570877Z","shell.execute_reply":"2021-05-23T23:26:08.575735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicate_df","metadata":{"execution":{"iopub.status.busy":"2021-05-23T23:17:20.650118Z","iopub.execute_input":"2021-05-23T23:17:20.650466Z","iopub.status.idle":"2021-05-23T23:17:20.665862Z","shell.execute_reply.started":"2021-05-23T23:17:20.650432Z","shell.execute_reply":"2021-05-23T23:17:20.664734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_duplicate_features (df):\n    \n    duplicate_features_ = []\n    duplicate_pairs_ = {}\n\n    for i,v1 in enumerate(df.columns,0):\n        duplicate_feat = []\n        if v1 not in duplicate_features_:\n            for v2 in df.columns[i+1:]:\n                if df[v1].equals(df[v2]):\n                    duplicate_features_.append(v2)\n                    duplicate_feat.append(v2)\n            if duplicate_feat:\n                duplicate_pairs_[v1] = duplicate_feat\n                \n    return duplicate_features_\n\ndef get_duplicate_pairs (df):\n    '''\n    To get list of duplicate features from this dictionary run this command\n    [item for sub_list in list(duplicate_pairs_.values()) for item in sub_list]\n    \n    '''\n    duplicate_features_ = []\n    duplicate_pairs_ = {}\n\n    for i,v1 in enumerate(df.columns,0):\n        duplicate_feat = []\n        if v1 not in duplicate_features_:\n            for v2 in df.columns[i+1:]:\n                if df[v1].equals(df[v2]):\n                    duplicate_features_.append(v2)\n                    duplicate_feat.append(v2)\n            if duplicate_feat:\n                duplicate_pairs_[v1] = duplicate_feat\n                \n    return duplicate_pairs_\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"duplicate_df.duplicate_features.to_list()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T23:18:47.587095Z","iopub.execute_input":"2021-05-23T23:18:47.587457Z","iopub.status.idle":"2021-05-23T23:18:47.595497Z","shell.execute_reply.started":"2021-05-23T23:18:47.587421Z","shell.execute_reply":"2021-05-23T23:18:47.594277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(duplicate_pairs_, columns=['feature1', 'duplicate_features'])","metadata":{"execution":{"iopub.status.busy":"2021-05-23T23:01:18.733301Z","iopub.execute_input":"2021-05-23T23:01:18.733783Z","iopub.status.idle":"2021-05-23T23:01:18.743629Z","shell.execute_reply.started":"2021-05-23T23:01:18.73375Z","shell.execute_reply":"2021-05-23T23:01:18.742853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_duplicate_features(df):\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Correlated Features\nFind group of correlated features. Group of 3,4 features ","metadata":{}},{"cell_type":"code","source":"df_corr = df.corr()\ndf_corr = pd.DataFrame(df_corr.unstack())\ndf_corr = df_corr.reset_index()\ndf_corr.columns = ['feature1', 'feature2', 'corr']\ndf_corr['abs_corr'] = df_corr['corr'].abs()\n\nprint('original corr dataframe Shape', df_corr.shape)\n\ncorr_thresh = 0.8\n# Removing correlation below the threshold\ndf_corr = df_corr.query(f'abs_corr >= {corr_thresh}')\n\n# Removing correlations within the same features\ndf_corr = df_corr[~(df_corr['feature1']==df_corr['feature2'])]\n\n# Removing cases where first v1 was compared with v2 and then later v2 compared with v1\nfor v1 in df_corr['feature1'].unique():\n    for v2 in df_corr['feature2'].unique():\n        drop_ix = df_corr[(df_corr['feature1']==v2) & (df_corr['feature2'] == v1)].index\n        df_corr.drop(index=drop_ix, inplace=True)\n        \n# Creating correlation groups        \ndf_corr['corr_group'] = (df_corr.groupby(by='feature1').cumcount()==0).astype('int')\ndf_corr['corr_group'] = df_corr['corr_group'].cumsum()\n\n# Formating changes\ndf_corr.sort_values(by='corr_group', inplace=True)\ndf_corr.reset_index(drop=True, inplace=True)\ndf_corr = df_corr[[ 'corr_group', 'feature1', 'feature2', 'corr', 'abs_corr']]\nprint('Final corr dataframe Shape', df_corr.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_correlated_pairs(df, threshold=0.9):\n    \n    df_corr = df.corr()\n    df_corr = pd.DataFrame(df_corr.unstack())\n    df_corr = df_corr.reset_index()\n    df_corr.columns = ['feature1', 'feature2', 'corr']\n    df_corr['abs_corr'] = df_corr['corr'].abs()\n\n    #print('original corr dataframe Shape', df_corr.shape)\n\n    # Removing correlation below the threshold\n    df_corr = df_corr.query(f'abs_corr >= {threshold}')\n\n    # Removing correlations within the same features\n    df_corr = df_corr[~(df_corr['feature1']==df_corr['feature2'])]\n\n    # Removing cases where first v1 was compared with v2 and then later v2 compared with v1\n    for v1 in df_corr['feature1'].unique():\n        for v2 in df_corr['feature2'].unique():\n            drop_ix = df_corr[(df_corr['feature1']==v2) & (df_corr['feature2'] == v1)].index\n            df_corr.drop(index=drop_ix, inplace=True)\n\n    # Creating correlation groups        \n    df_corr['corr_group'] = (df_corr.groupby(by='feature1').cumcount()==0).astype('int')\n    df_corr['corr_group'] = df_corr['corr_group'].cumsum()\n\n    # Formating changes\n    df_corr.sort_values(by='corr_group', inplace=True)\n    df_corr.reset_index(drop=True, inplace=True)\n    df_corr = df_corr[[ 'corr_group', 'feature1', 'feature2', 'corr', 'abs_corr']]\n    #print('Final corr dataframe Shape', df_corr.shape)\n    \n    return df_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr.corr_group.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr.corr_group.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_corr.query('corr_group==4')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Mutual Information\n\nhigher the mi value ; higher the importance of feature","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df.drop(columns='target').copy()\ny_train = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi = mutual_info_classif(X_train.fillna(0), y_train, random_state=2021)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi = pd.Series(mi)\nmi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi.index = X_train.columns\nmi = mi.sort_values(ascending=False)\nmi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(mi, columns = ['mi_value'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Chi Square\n\nSmallest the p-value higher the importance of the feature","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/titanic/train.csv')\ntrain.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import chi2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Sex.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Embarked.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Sex'] = train['Sex'].map({'male': 1, 'female':0})\ntrain['Embarked'] = train['Embarked'].map({'S': 0, 'C':1, 'Q':2})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_vars = ['Pclass', 'Sex', 'SibSp','Parch', 'Embarked']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train[cat_vars]\ny_train = train['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chi_score = chi2(X_train.fillna(99), y_train)\nchi_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = {'chi_score': chi_score[0], 'p_value': chi_score[1]}\npd.DataFrame(data =d, index=X_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. ANOVA","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import f_classif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df.drop(columns='target').copy()\ny_train = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anova_score = f_classif(X_train.fillna(0), y_train)\nanova_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = {'anova_score': anova_score[0], 'p_value': anova_score[1]}\npd.DataFrame(data =d, index=X_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Univariate Model Performance Metrics****","metadata":{}},{"cell_type":"code","source":"X_train = df.drop(columns='target').copy()\ny_train = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values = []\nfor feat in X_train.columns:\n    X = X_train[feat].fillna(0).to_frame()\n    model = DecisionTreeClassifier()\n    model.fit(X, y_train)\n    y_prob = model.predict_proba(X)[:,1]\n    roc_value = roc_auc_score(y_train, y_prob)\n    roc_values.append(roc_value)\nlen(roc_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values = pd.Series(roc_values)\nroc_values.index = X_train.columns\nroc_values.sort_values(ascending=False, inplace=True)\nroc_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values[roc_values>0.51]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Target Mean Encoding","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/titanic/train.csv')\nprint(train.shape)\n\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\nprint(test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_vars = ['Pclass', 'Sex', 'SibSp','Parch', 'Embarked']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain.fillna('Missing', inplace=True)\ndf_train, df_test = train_test_split(train, train_size=0.8, random_state=2021)\n\ny_train = df_train['Survived'].copy()\nX_train = df_train.drop(columns = 'Survived').copy()\n\ny_test = df_test['Survived'].copy()\nX_test = df_test.drop(columns = 'Survived').copy()\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for v in cat_vars:\n\n    mapper = df_train.groupby(by=v)['Survived'].mean().to_dict()\n    \n    X_train[v] = X_train[v].map(mapper)\n    X_test[v] = X_test[v].map(mapper)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_values = []\n\nfor v in cat_vars:\n    y_pred = X_test[v]\n    roc_value = roc_auc_score(y_test, y_pred)\n    roc_values.append(roc_value)\n    \nroc_values = pd.Series(roc_values)\nroc_values.index = cat_vars\nroc_values.sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# II. Wrapper Methods\n\n1. Step Forward\n\nhttp://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/#example-1-a-simple-sequential-forward-selection-example","metadata":{}},{"cell_type":"code","source":"X_train = df.drop(columns='target').copy()\ny_train = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sfs1 = SFS(RandomForestClassifier(n_jobs=-1),\n           k_features=10,\n           forward=True,\n           floating=False,\n           verbose=2,\n           scoring='roc_auc',\n           cv=3\n          )\n\nsfs1.fit(X_train.fillna(0), y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Backward Selection","metadata":{}},{"cell_type":"code","source":"from mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sfs2 = SFS(RandomForestClassifier(),\n ExhaustiveFeatureSelector         k_features = 10,\n           forward=False,\n           floating=True,\n           verbose=2,\n           scoring = 'roc_auc',\n           cv=3\n          )\n\nsfs2.fit(X_train.fillna(0), y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Exhaustive Search ","metadata":{}},{"cell_type":"code","source":"from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efs = EFS(RandomForestClassifier(),\n          min_features=10,\n          max_features=20, \n          print_progress=True, \n          scoring ='roc_auc',\n          cv=2,\n          n_jobs=-1\n         )\n\nefs.fit(X_train.fillna(0), y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# III. Embedded Methods","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IV. Hybrid Methods\n\n## 1. Feature Shuffling","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dataset-1/dataset_2.csv')\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:36:27.030013Z","iopub.execute_input":"2021-05-23T09:36:27.030533Z","iopub.status.idle":"2021-05-23T09:36:30.189137Z","shell.execute_reply.started":"2021-05-23T09:36:27.0305Z","shell.execute_reply":"2021-05-23T09:36:30.1883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df['target'].copy()\nX = df.drop(columns = 'target').copy()\nX.fillna(0, inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=SEED)\n\nmodel = RandomForestClassifier(n_estimators=50, max_depth=4, random_state=SEED)\nmodel.fit(X_train, y_train)\nprint(model)\n\n#train\ny_train_pred = model.predict_proba(X_train)[:,1]\ntrain_roc = roc_auc_score(y_train, y_train_pred)\nprint('Train ROC Score:', train_roc)\n\n#test\ny_test_pred = model.predict_proba(X_test)[:,1]\ntest_roc = roc_auc_score(y_test, y_test_pred)\nprint('Test ROC Score:', test_roc)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T09:36:34.468384Z","iopub.execute_input":"2021-05-23T09:36:34.468863Z","iopub.status.idle":"2021-05-23T09:36:41.460143Z","shell.execute_reply.started":"2021-05-23T09:36:34.468833Z","shell.execute_reply":"2021-05-23T09:36:41.459207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Shuffle features 1 by 1 and calculate roc score value","metadata":{}},{"cell_type":"code","source":"X_train_c = X_train.copy()\nprint(X_train_c['var_1'])\n\nX_train_c['var_1'] = X_train_c['var_1'].sample(frac=1, random_state=SEED).reset_index(drop=True)\nprint(X_train_c['var_1'])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T23:39:56.71603Z","iopub.execute_input":"2021-05-22T23:39:56.716545Z","iopub.status.idle":"2021-05-22T23:39:56.738838Z","shell.execute_reply.started":"2021-05-22T23:39:56.716508Z","shell.execute_reply":"2021-05-22T23:39:56.737529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_c['var_1'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T23:40:16.014745Z","iopub.execute_input":"2021-05-22T23:40:16.015169Z","iopub.status.idle":"2021-05-22T23:40:16.021406Z","shell.execute_reply.started":"2021-05-22T23:40:16.015136Z","shell.execute_reply":"2021-05-22T23:40:16.020578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_shift = []\nfor f in X_train.columns:\n    X_train_c = X_train.copy(deep=True)\n    shuff = X_train_c[f].sample(frac=1, random_state=SEED)\n    shuff.index = X_train_c[f].index\n    X_train_c[f] = shuff\n    \n    shuffle_pred = model.predict_proba(X_train_c)[:,1]\n    shuffle_roc = roc_auc_score(y_train, shuffle_pred)\n    \n    drift = train_roc - shuffle_roc\n    performance_shift.append(drift)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T10:10:32.872112Z","iopub.execute_input":"2021-05-23T10:10:32.872484Z","iopub.status.idle":"2021-05-23T10:10:48.440871Z","shell.execute_reply.started":"2021-05-23T10:10:32.87245Z","shell.execute_reply":"2021-05-23T10:10:48.439966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_shift = pd.Series(performance_shift)\nperformance_shift.index = X_train.columns\nperformance_shift.sort_values(ascending=False, inplace=True)\nperformance_shift","metadata":{"execution":{"iopub.status.busy":"2021-05-23T10:12:06.818129Z","iopub.execute_input":"2021-05-23T10:12:06.818478Z","iopub.status.idle":"2021-05-23T10:12:06.828339Z","shell.execute_reply.started":"2021-05-23T10:12:06.818449Z","shell.execute_reply":"2021-05-23T10:12:06.827647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Recursive Feature Elimination","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/dataset-1/dataset_2.csv')\nprint('Dataframe shape', df.shape)\n\ny=df['target'].copy()\nX = df.drop(columns = 'target').copy()\nX.fillna(0, inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=SEED)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T21:49:49.613097Z","iopub.execute_input":"2021-05-23T21:49:49.613568Z","iopub.status.idle":"2021-05-23T21:49:51.807144Z","shell.execute_reply.started":"2021-05-23T21:49:49.613534Z","shell.execute_reply":"2021-05-23T21:49:51.806166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recursive_feature_elimination(model, X_train, y_train, X_valid, y_valid):\n    rfe_df = pd.DataFrame(columns = ['dropped_feature', 'num_features', 'train_roc', 'valid_roc'])\n    features_to_drop = []\n\n    for i in range(0, len(X_train.columns)):\n        X_train_c = X_train.copy()\n        X_valid_c = X_valid.copy()\n\n        X_train_c = X_train_c.drop(columns = features_to_drop)\n        X_valid_c = X_valid_c.drop(columns = features_to_drop)\n\n        #model = RandomForestClassifier(n_estimators=50, max_depth=4, random_state=SEED)\n        model.fit(X_train_c, y_train)\n        #print(model)\n\n        #train\n        y_train_pred = model.predict_proba(X_train_c)[:,1]\n        train_roc = roc_auc_score(y_train, y_train_pred)\n        #print('Train ROC Score:', train_roc)\n\n        #test\n        y_valid_pred = model.predict_proba(X_valid_c)[:,1]\n        valid_roc = roc_auc_score(y_test, y_valid_pred)\n        #print('Test ROC Score:', test_roc)\n\n        data = {'feature': X_train_c.columns, 'fi': model.feature_importances_}\n        fi = pd.DataFrame(data)\n        fi.sort_values(by = 'fi', ascending=False, inplace=True)\n\n        lowest_fi = list(fi['feature'])[-1]\n        features_to_drop.append(lowest_fi)\n\n        if i ==0:\n            drop_f = 'None'\n        else:\n            drop_f = features_to_drop[-1]\n\n        rfe_df.loc[i] = [drop_f, len(X_train_c.columns), train_roc, valid_roc]\n\n    print('Done')\n    rfe_df['train_roc_rank'] =rfe_df['train_roc'].rank(method='min', ascending=False).astype('int')\n    rfe_df['valid_roc_rank'] =rfe_df['valid_roc'].rank(method='min', ascending=False).astype('int')\n    \n    return rfe_df","metadata":{"execution":{"iopub.status.busy":"2021-05-23T22:33:37.82347Z","iopub.execute_input":"2021-05-23T22:33:37.823898Z","iopub.status.idle":"2021-05-23T22:33:37.834459Z","shell.execute_reply.started":"2021-05-23T22:33:37.823863Z","shell.execute_reply":"2021-05-23T22:33:37.833615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=50, max_depth=4, random_state=SEED)\nrfe_df = recursive_feature_elimination(model, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T22:34:51.558998Z","iopub.execute_input":"2021-05-23T22:34:51.559339Z","iopub.status.idle":"2021-05-23T22:43:02.676656Z","shell.execute_reply.started":"2021-05-23T22:34:51.559296Z","shell.execute_reply":"2021-05-23T22:43:02.675553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_all(rfe_df)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T22:43:30.066762Z","iopub.execute_input":"2021-05-23T22:43:30.067124Z","iopub.status.idle":"2021-05-23T22:43:30.099482Z","shell.execute_reply.started":"2021-05-23T22:43:30.067086Z","shell.execute_reply":"2021-05-23T22:43:30.098447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(roc_df['dropped_feature'])[1:97]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T22:01:04.738081Z","iopub.execute_input":"2021-05-23T22:01:04.738677Z","iopub.status.idle":"2021-05-23T22:01:04.74659Z","shell.execute_reply.started":"2021-05-23T22:01:04.738639Z","shell.execute_reply":"2021-05-23T22:01:04.745521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}