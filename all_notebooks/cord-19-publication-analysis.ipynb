{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport glob\nimport datetime\nimport json\nimport re\nimport numpy as np\n\n# bokeh\nfrom bokeh.io import output_notebook, push_notebook\nfrom bokeh.io import show, save, output_file\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, HoverTool, DatetimeTickFormatter, NumeralTickFormatter\nfrom bokeh.palettes import Set1_9 as palette\nfrom ipywidgets import interact, IntSlider\nimport ipywidgets as widget\noutput_notebook()\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\n\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Extraction**"},{"metadata":{},"cell_type":"markdown","source":"Load all sources metadata"},{"metadata":{"trusted":true},"cell_type":"code","source":"root_path = '/kaggle/input/CORD-19-research-challenge'\ndf_metadata = pd.read_csv('%s/metadata.csv' % root_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"publish_time to datetime function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def publish_time_to_datetime(publish_time):\n    if(str(publish_time) == 'nan'):\n        return_date = None\n        \n    else:\n        list_publish_time = re.split('[ -]',publish_time)\n        if len(list_publish_time) >2 :\n            try:\n                #'2020 Jan 27'\n                #'2017 Apr 7 May-Jun'\n                return_date = datetime.datetime.strptime('-'.join(list_publish_time[:3]), '%Y-%b-%d')\n\n            except :                \n                try :\n                    #'2020 03 16'\n                    return_date = datetime.datetime.strptime('-'.join(list_publish_time[:3]), '%Y-%m-%d')\n                    \n                except:\n                    #'2015 Jul-Aug'\n                    return_date = datetime.datetime.strptime('-'.join(list_publish_time[:2]), '%Y-%b')\n\n        elif len(list_publish_time) == 2:\n            #'2015 Winter' -> 1 fev            \n            if(list_publish_time[1] == 'Winter'):\n                return_date = datetime.datetime(int(list_publish_time[0]), 2, 1)\n\n            #'2015 Spring' -> 1 may            \n            elif(list_publish_time[1] == 'Spring'):\n                return_date = datetime.datetime(int(list_publish_time[0]), 5, 1)\n                \n            #'2015 Autumn' -> 1 nov\n            elif(list_publish_time[1] in ['Autumn','Fall']):\n                return_date = datetime.datetime(int(list_publish_time[0]), 11, 1)            \n            else:\n                #\"2015 Oct\"\n                return_date = datetime.datetime.strptime('-'.join(list_publish_time), '%Y-%b')\n\n        elif len(list_publish_time) == 1:\n            #'2020'\n            return_date = datetime.datetime.strptime('-'.join(list_publish_time), '%Y')\n\n    return return_date","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the json"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# thanks to Frank Mitchell\njson_filenames = glob.glob(f'{root_path}/**/*.json', recursive=True)\ndf_data = pd.DataFrame()\n\n# set a break_limit for quick test (-1 for off)\nbreak_limit = -1\nprint_debug = False\n\nfor i,file_name in enumerate(json_filenames):\n    if(print_debug):print(file_name)\n    \n    # get the sha\n    sha = file_name.split('/')[6][:-5]\n    if(print_debug):print(sha)\n    \n    # get the all_sources information\n    df_metadata_sha = df_metadata[df_metadata['sha'] == sha]\n   \n    if(df_metadata_sha.shape[0] > 0):\n        s_metadata_sha = df_metadata_sha.iloc[0]\n    \n        # treat only if full text\n        if(s_metadata_sha['has_full_text']):\n            dict_to_append = {}\n            dict_to_append['sha'] = sha\n            dict_to_append['dir'] = file_name.split('/')[4]\n\n            # publish time into datetime format        \n            datetime_publish_time = publish_time_to_datetime(s_metadata_sha['publish_time'])\n\n            if(datetime_publish_time is not None):\n                dict_to_append['publish_time'] = datetime_publish_time\n                dict_to_append['title'] = s_metadata_sha['title']\n\n                # thanks to Frank Mitchell\n                with open(file_name) as json_data:\n                    data = json.load(json_data)\n\n                    # get abstract\n                    abstract_list = [data['abstract'][x]['text'] for x in range(len(data['abstract']))]            \n                    abstract = \"\\n \".join(abstract_list)\n                    dict_to_append['abstract'] = abstract\n\n\n                    # get body\n                    body_list = [data['body_text'][x]['text'] for x in range(len(data['body_text']))]            \n                    body = \"\\n \".join(body_list)\n                    dict_to_append['body'] = body\n\n\n                df_data = df_data.append(dict_to_append, ignore_index=True)\n\n    else:\n        if(print_debug):print('not found')\n                \n    if (break_limit != -1):\n        if (i>break_limit):\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set sha as index\ndf_data.index = df_data['sha']\ndf_data = df_data.drop(['sha'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Publish date analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_publish_month = df_data.title.groupby(df_data['publish_time'].dt.to_period(\"M\")).count()\n\nsource = ColumnDataSource(data=dict(\n    month = df_publish_month.index,\n    month_tooltips = df_publish_month.index.strftime('%Y/%m'),\n    publication_count = df_publish_month.values\n))\n\ntooltips = [('month','@month_tooltips'),('publication_count','@publication_count')]\ntools = ['pan', 'box_zoom', 'wheel_zoom', 'reset', HoverTool(tooltips=tooltips, names=['hover_tool'])]\np = figure(plot_height=600,  plot_width=800,tooltips=tooltips, active_drag=\"pan\", active_scroll='wheel_zoom')\np.line('month','publication_count',source=source)\np.xaxis.formatter=DatetimeTickFormatter(months=[\"%Y/%m\"])\np.title.text = 'Publication count per Month'\np.xaxis[0].axis_label = 'Months'\np.yaxis[0].axis_label = 'Publication count'\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two signs which show that the publication dates entered in metadata.csv are sometimes incorrect:\n- there is a publication peak in December each year\n- publications have publication dates in the future"},{"metadata":{},"cell_type":"markdown","source":"# **Publication processing**"},{"metadata":{},"cell_type":"markdown","source":"Concatenation"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntitle_weight = 4\nabstract_weight = 2\nbody_weight = 1\n\ndef concat(s_publication):\n    s_return = ''\n    \n    # title\n    if(str(s_publication['title']) != 'nan'):\n        for i in range(title_weight + 1):\n            s_return = s_return + s_publication['title'] + ' '\n\n    # abstract\n    for i in range(abstract_weight + 1):\n        s_return = s_return + s_publication['abstract'] + ' '\n        \n    # body\n    for i in range(body_weight + 1):\n        s_return = s_return + s_publication['body'] + ' '\n        \n    return s_return\n\ndf_data['publication_processing'] = df_data.apply(concat, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to release memory\ndf_data = df_data.drop([['title','abstract','body']], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleaning : lower and new line removal"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf_data['publication_processing'] = df_data['publication_processing'].str.lower()\ndf_data['publication_processing'] = df_data['publication_processing'].str.replace('\\n',' ')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tokenize"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# keep only alpha\ntokenizer = nltk.RegexpTokenizer('[A-Za-z]+')\n# by step to prevent memory error\nstep = 500\nstop = int(df_data.shape[0]/step)+1\ns_temp = pd.Series()\nfor i in range(stop):\n    if(i == stop - 1):\n        print('tokenize publication %s to %s' % (i*step,df_data.shape[0]))\n    else:\n        print('tokenize publication %s to %s' % (i*step,(i+1)*step -1))\n    df_data['publication_processing'].iloc[i*step:(i+1)*step] = df_data['publication_processing'].iloc[i*step:(i+1)*step].apply(lambda x:tokenizer.tokenize(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"run before"},{"metadata":{},"cell_type":"markdown","source":"Remove the stop words"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlist_stopwords_english = list(nltk.corpus.stopwords.words('english'))\ndf_data['publication_processing'] = df_data['publication_processing'].apply(\n    lambda x:[w for w in x if not w in list_stopwords_english])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lemmatize"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize_list(list_word):\n    list_return = []\n    for str_word in list_word:\n        list_return.append(lemmatizer.lemmatize(str_word))\n    return list_return\n    \ndf_data['publication_processing'] = df_data['publication_processing'].apply(\n    lemmatize_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Term Frequency**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# int8 msut be sufficient (0-255) for term frequency\ndtype='int8'\ncv = CountVectorizer(analyzer=lambda x: x, dtype=dtype)\ncounted_values = cv.fit_transform(df_data['publication_processing']).toarray()\ndf_tf = pd.DataFrame(\n    counted_values,\n    columns=cv.get_feature_names(),\n    index=df_data['publication_processing'].index\n)\n# to sparse\ndf_tf = df_tf.astype(pd.SparseDtype(dtype, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ns_word_use = df_tf[df_tf>0].count().sort_values(ascending = False)/df_tf.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsource = ColumnDataSource(data=dict(\n    word = s_word_use.index,\n    word_x = list(range(s_word_use.shape[0])),\n    use = s_word_use.values,\n    use_tooltips = s_word_use.apply(lambda x: '%i %%' % (100*x)).values\n))\n\ntooltips = [('word','@word'),('use','@use_tooltips')]\ntools = ['pan', 'box_zoom', 'wheel_zoom', 'reset', HoverTool(tooltips=tooltips, names=['hover_tool'])]\np = figure(plot_height=600,  plot_width=800,tooltips=tooltips, active_drag=\"pan\", active_scroll='wheel_zoom')\np.line('word_x','use',source=source)\np.title.text = 'Word use'\n\np.xaxis[0].axis_label = 'Word'\ndict_x_overrides = pd.DataFrame(s_word_use.index)[0].astype('str').to_dict()\np.xaxis.major_label_overrides = dict_x_overrides\np.xaxis.major_label_orientation = \"vertical\"\n\np.yaxis[0].axis_label = 'Use'\np.yaxis.formatter=NumeralTickFormatter(format=\"0 %%\")\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Problem :\n- How to differiante common word such as also, study, etc..  from medical word as virus, pathology, etc..\n- How to manage publication in no english language"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}