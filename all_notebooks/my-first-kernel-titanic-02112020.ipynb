{"cells":[{"metadata":{},"cell_type":"markdown","source":"To note: I've learned lots of tricks and patterns from Dr.Yassine Ghouzam. He is a great machine learning scientist. Every work out of his magical hands is classic. Thank you very much!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ngender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ntrain = pd.read_csv(\"../input/titanic/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_len = len(train)\ntrain_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_wo_Sv = train.drop(labels='Survived', axis= 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combing train and test datasets together for consistent data cleaning:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total = pd.concat([train_wo_Sv,test], axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Age collumn, first to fill null values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total['Age'].fillna(value = train_test_total.Age.mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Name collumn, to extract the tile using regex, then to replace the low frequent title with 'Rare':"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ntrain_test_total['Title'] = train_test_total.Name.str.extract('([a-zA-Z]+)\\.', expand = True)\ntrain_test_total['Title'] = train_test_total.Title.replace('Mme','Mrs')\ntrain_test_total['Title'] = train_test_total.Title.replace('Mlle','Miss')\ntrain_test_total['Title'] = train_test_total.Title.replace('Ms','Miss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_counts = train_test_total.Title.value_counts()\nleast_frequent_title = title_counts[title_counts<=10].index\nleast_frequent_title\n\ntrain_test_total['Title'] = train_test_total['Title'].replace(least_frequent_title,'Rare')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Fare collumn, to fill na with median value:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total['Fare'] = train_test_total['Fare'].fillna(train_test_total['Fare'].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Embarked collumn, to fill na with first mode value:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total['Embarked'] = train_test_total['Embarked'].fillna(train_test_total['Embarked'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total.drop(labels=['PassengerId','Cabin','Name','Ticket'], axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total['Family'] = train_test_total['Parch'] + train_test_total['SibSp'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To catogerize Age:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total['Age'] = pd.qcut(train_test_total['Age'], 5, labels=['child','young','mid_age','old','very_old'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To catogerize Fare:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total['Fare'] = pd.qcut(train_test_total['Fare'], 5, labels=['low','low_medium','medium','high','very_high'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabelencoder = LabelEncoder()\ntrain_test_total['Sex'] = labelencoder.fit_transform(train_test_total['Sex'])\ntrain_test_total['Embarked'] = labelencoder.fit_transform(train_test_total['Embarked'])\ntrain_test_total['Title'] = labelencoder.fit_transform(train_test_total['Title'])\ntrain_test_total['Age'] = labelencoder.fit_transform(train_test_total['Age'])\ntrain_test_total['Fare'] = labelencoder.fit_transform(train_test_total['Fare'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total = pd.get_dummies(train_test_total, columns= ['Pclass','Embarked','Title','Family','Age','Fare'], drop_first= True, prefix= ['P_','Em_','T_','F_','Age_','Fare_'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_total.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modelling:****"},{"metadata":{},"cell_type":"markdown","source":"To extract the training and test datasets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cleaned = train_test_total.iloc[:train_len,:]\ntest_cleaned = train_test_total.iloc[train_len:,:]\nX_train = train_cleaned\nY_train = train.Survived","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To import the various classifier classes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To combine the classifiers into the list:"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 2\nclassifiers = []\n\nclassifiers.append(RandomForestClassifier(criterion = 'entropy', random_state = random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = random_state),learning_rate = 0.1,random_state = random_state))\nclassifiers.append(GradientBoostingClassifier(random_state = random_state))\nclassifiers.append(ExtraTreesClassifier(criterion = 'entropy', random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p =2))\nclassifiers.append(SVC(random_state = random_state))\nclassifiers.append(SVC(kernel = 'linear',random_state = random_state))\nclassifiers.append(GaussianNB())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 1. To fit and transform the training sets using Cross_Val_Score method:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncv_results = []\nfor classifier in classifiers:\n    cv_results.append(cross_val_score(estimator = classifier, X = X_train, y = Y_train, scoring = 'accuracy', cv = 10, n_jobs = -1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 2. To incoprate the cross_val_score results into cv_mean and cv_std, respectively:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_mean = []\ncv_std = []\n\nfor cv_result in cv_results:\n    cv_mean.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n    \ncv_vis = pd.DataFrame({'CrossValMean':cv_mean,'CrossValError': cv_std ,'Algorithm':['RandomForest','Adaboost','Gradientboost','Extratrees',\n                                                            'LinearDiscriminat','LogisticReg','KNeighbor','Kernel_SVC','SVC','GaussianNB']})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 3. To visualize the accuracies and corresponding algorithm:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize= (8,5))\nsns.barplot(y = 'Algorithm',x = 'CrossValMean', data= cv_vis, orient='h', **{'xerr': cv_std})\nplt.xlabel('Mean Accuracy', fontsize = 15)\nplt.ylabel('Algorithm', fontsize = 15)\nplt.yticks(rotation = 35)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. 1. To apply GridSearch on best performing models: SVC, LogisticRegression, LinearDiscrimination, Gradientboost:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient boosting tunning\n\nGBC_classifier = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01], \n              }\n\ngsGBC = GridSearchCV(GBC_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Discriminant Analysis tunning\n\nLDA_classifier = LinearDiscriminantAnalysis()\ngb_param_grid = {\n              }\n\ngsLDA = GridSearchCV(LDA_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLDA.fit(X_train,Y_train)\n\nLDA_best = gsLDA.best_estimator_\n\n# Best score\ngsLDA.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression tunning\n\nLR_classifier = LogisticRegression()\ngb_param_grid = {\n                  'C': [0.1,1, 10, 50, 100,]\n              }\n\ngsLR = GridSearchCV(LR_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLR.fit(X_train,Y_train)\n\nLR_best = gsLR.best_estimator_\n\n# Best score\ngsLR.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kernel SVC tunning\n\nKSVC_classifier = SVC(probability=True)\ngb_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [0.1,1, 10, 50, 100,]\n              }\n\ngsKSVC = GridSearchCV(KSVC_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsKSVC.fit(X_train,Y_train)\n\nKSVC_best = gsKSVC.best_estimator_\n\n# Best score\ngsKSVC.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensemble Voting:"},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('gbc', GBC_best), ('lda', LDA_best),\n('lr', LR_best), ('ksvc',KSVC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To predict and submit results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived = pd.Series(votingC.predict(test_cleaned), name=\"Survived\")\n\nresults = pd.concat([test.PassengerId,test_Survived],axis=1)\n\nresults.to_csv(\"ensemble_python_voting.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}