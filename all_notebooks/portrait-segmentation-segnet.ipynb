{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\n\nimport shutil\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\n# Don't Show Warning Messages\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set up the canvas for the subplots\nplt.figure(figsize=(7,7))\nplt.tight_layout()\nplt.axis('Off')\n\n\n# Our subplot will contain 4 rows and 4 columns\n# plt.subplot(nrows, ncols, plot_number)\n\n# image\nplt.subplot(1,2,1)\npath = '../input/aisegmentcom-matting-human-datasets/clip_img/1803151818/clip_00000000/1803151818-00000003.jpg'\nimage = plt.imread(path)\nplt.title('RGB Image')\nplt.imshow(image)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,2,2)\npath = '../input/aisegmentcom-matting-human-datasets/matting/1803151818/matting_00000000/1803151818-00000003.png'\nmask = plt.imread(path)\nplt.title('RGBA Image')\nplt.imshow(mask)\nplt.axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/aisegmentcom-matting-human-datasets/clip_img/1803151818/clip_00000000/1803151818-00000003.jpg'\n\nimg=cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nf = np.zeros((800,600,4),np.uint8)\nf[:,:,:3] = img\n\nf[:,:,3] = mask[:,:,3]*255\nplt.imshow(f)\nprint(type(f[:,:,3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = list(f[:,:,3].flatten())\np.count(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f[:,:,3].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(mask[:,:,3].flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(mask[:,:,3]).dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask[:,:,3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ana = list(mask[:,:,3].flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(ana)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ana.count(0)+ana.count(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(mask[:,:,3],cmap = \"gray\") # 0 opaque 1 transparent","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#                                        # * 1. 1. * MAIN PROGRAM STARTS****"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, load_model\nfrom keras.layers import Input, UpSampling2D\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import BatchNormalization, Activation, Dense, Dropout,UpSampling2D,Conv2DTranspose\nfrom keras import backend as K\nimport keras\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = pd.read_csv(\"../input/portraitsegmentation/mfinal.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#                                                                           # TRAIN GENERATOR"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_generator( df,batch_size=16, IMG_HEIGHT = 128, IMG_WIDTH = 128):\n    \n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for  i in range(0,28000,16):\n        \n            X_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n            Y_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float)\n            \n            for x in range(16):\n                \n                \n                path = df[\"clip_paths\"][x+i]\n               \n                image = cv2.imread(path)\n                \n                \n                image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n                \n              \n                X_train[x] = image\n            \n#------------\n\n                path = df[\"matted_paths\"][x+i]\n\n                # read the image\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n\n                # select the alpha channel\n                k = mask[:, :, 3]\n                \n                \n                \n                k = np.expand_dims(k, axis=-1)\n                \n                # resize the mask\n                k = resize(k, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n                k = k>0.5\n                # insert the image into Y_train\n                Y_train[x] = k\n\n            yield X_train, Y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# #VALIDTION GENERATOR"},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_generator( df1,batch_size=16, IMG_HEIGHT = 128, IMG_WIDTH = 128):\n    \n    IMG_CHANNELS = 3\n\n    \n    while True:\n        \n       \n        for  i in range(28000,34000,16):\n           \n            \n            \n            X_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n            \n            Y_train = np.zeros((batch_size, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float)\n\n\n            for x in range(16):\n                \n               \n                path = df1[\"clip_paths\"][x+i]\n                image = cv2.imread(path)\n                image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n               \n               \n               \n                X_train[x] = image\n               \n            # ===============\n                \n                path =  df1[\"matted_paths\"][x+i]\n\n               \n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n\n                \n                k = mask[:, :, 3]\n                k = np.expand_dims(k, axis=-1)\n                k = resize(k, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n                k = k>0.5\n                \n                Y_train[x] = k\n\n            yield X_train, Y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL CODE"},{"metadata":{},"cell_type":"markdown","source":"#  U-NET"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def unet():\n\n    inputs = Input((128,128,3))\n\n\n\n\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n    c3 = Dropout(0.2) (c3)\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n    c4 = Dropout(0.2) (c4)\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n    c5 = Dropout(0.3) (c5)\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.2) (c6)\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.2) (c7)\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n    return model"},{"metadata":{},"cell_type":"markdown","source":"# SEGNET"},{"metadata":{"trusted":true},"cell_type":"code","source":"def segnet():\n    \n    input1=Input((256,256,3))\n    conv1=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(input1)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    c1=BatchNormalization()(conv2)\n    drop1 = Dropout(0.1)(c1)\n    pool1 =MaxPooling2D(pool_size=(2, 2))(drop1)\n    \n    conv1=Conv2D(128,3,activation='relu',padding='same',kernel_initializer='he_normal')(pool1)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(128,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    c2=BatchNormalization()(conv2)\n    drop2 = Dropout(0.1)(c2)\n    pool2 =MaxPooling2D(pool_size=(2, 2))(drop2) \n    \n    conv1=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(pool2)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    conv3=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch2)\n    c3=BatchNormalization()(conv3)\n    drop3 = Dropout(0.1)(c3)\n    pool3 =MaxPooling2D(pool_size=(2, 2))(drop3) \n    \n    conv1=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(pool3)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    conv3=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch2)\n    c4=BatchNormalization()(conv3)\n    drop4 = Dropout(0.1)(c4)\n    pool4 =MaxPooling2D(pool_size=(2, 2))(drop4) \n    \n    conv1=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(pool4)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    conv3=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch2)\n    c5=BatchNormalization()(conv3)\n    drop5 = Dropout(0.1)(c5)\n    pool5 =MaxPooling2D(pool_size=(2, 2))(drop5) \n    \n\n    \n    up1 =Conv2D(1024,2, activation = 'relu', padding = 'same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(pool5))\n    merge1 = concatenate([c5,up1], axis =3)\n    \n    conv1=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(merge1)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    conv3=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch2)\n    batch3=BatchNormalization()(conv3)\n    batch3 = Dropout(0.2)(batch3)\n    \n    \n    up2 =Conv2D(512,2, activation = 'relu', padding = 'same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(batch3))\n    merge2 = concatenate([c4,up2], axis =3)\n    \n    conv1=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(merge2)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    conv3=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch2)\n    batch3=BatchNormalization()(conv3)\n    batch3 = Dropout(0.2)(batch3)\n    \n\n    up3 =Conv2D(256,2, activation = 'relu', padding = 'same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(batch3))\n    merge3 = concatenate([c3,up3], axis =3)\n\n    conv1=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(merge3)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    conv3=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch2)\n    batch3=BatchNormalization()(conv3)\n    batch3 = Dropout(0.2)(batch3)\n    \n\n    up4 =Conv2D(128,2, activation = 'relu', padding = 'same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(batch3))\n    merge4 = concatenate([c2,up4], axis =3) \n\n    conv1=Conv2D(128,2,activation='relu',padding='same',kernel_initializer='he_normal')(merge4)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(128,2,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    batch2 = Dropout(0.2)(batch2)\n    \n    \n    up5 =Conv2D(64,1, activation = 'relu', padding = 'same',kernel_initializer='he_normal')(UpSampling2D(size = (2,2))(batch2))\n    merge5 = concatenate([c1,up5], axis =3) \n\n    conv1=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(merge5)\n    batch1=BatchNormalization()(conv1)\n    conv2=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(batch1)\n    batch2=BatchNormalization()(conv2)\n    \n    \n    output=Conv2D(1,(1,1),activation='sigmoid')(batch2)\n    \n    model=Model(input1,output)\n    model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\nIMG_CHANNELS = 3\nnum_train_samples = 28000\nnum_val_samples = 60000\ntrain_batch_size = BATCH_SIZE\nval_batch_size = BATCH_SIZE\n\n\ntrain_steps = 1750\n\nval_steps = 375\nIMG_HEIGHT = 256\nIMG_WIDTH = 256\nIMG_CHANNELS = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = train_generator(c,batch_size=BATCH_SIZE, IMG_HEIGHT = 256, IMG_WIDTH = 256)\nval_gen = val_generator(c,batch_size=BATCH_SIZE, IMG_HEIGHT = 256, IMG_WIDTH = 256)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAINING"},{"metadata":{"trusted":true},"cell_type":"code","source":"#segnet_model=segnet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"keras.utils.plot_model(segnet_model,to_file=\"model.png\",\n    show_shapes=True)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#history = segnet_model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=5,validation_data=val_gen, validation_steps=val_steps,verbose=1)\n                                                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#segnet_model.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\n\nimport shutil\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\n\nimport warnings\nwarnings.filterwarnings('ignore')"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\nprint(history.history.keys()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# PREDICTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"segnet_trained = load_model(\"../input/potraitsegmentationv1/model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\npath = \"../input/potraitimages/pics/billgates.jpg\"\nimg= cv2.imread(path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg=cv2.resize(img,(256,256))\nplt.imshow(img)\n\n\nim = Image.fromarray(img)\nim.save(\"input.jpeg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(path):\n    img=cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img=cv2.resize(img,(256,256))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction(path):\n    img=read_image(path)\n    img=img.reshape(1,256,256,3)\n    pred=segnet_trained.predict(img)\n    pred=pred.reshape(256,256)\n    pre=pred>0.5\n    pre=pre.astype(int)\n    ind=np.where(pre==0)\n    img=img.reshape((256,256,3))\n    m=img.copy()\n    m[ind[0],ind[1],:]=255\n    return img,m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a,b=prediction(\"../input/potraitimages/pics/billgates.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(b)\nfrom PIL import Image\nim = Image.fromarray(b)\nim.save(\"b.jpeg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=read_image(path)\nimg=img.reshape(1,256,256,3)\npred=segnet_trained.predict(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=pred.reshape(256,256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pred>.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(pred[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pred.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind=np.where(x==0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list(ind[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=read_image(path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=read_image(path)\nimg=img.reshape(1,256,256,3)\npred=segnet_trained.predict(img)\npred=pred.reshape(256,256)\nimg=img.reshape((256,256,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.zeros(( 256,256), dtype=np.float)\nf = np.zeros((256,256,4),np.uint8)\nf[:,:,:4] = img.copy()\nx = pred > 0.5\nf[:,:,3] = pred*255\nplt.imshow(f)\nprint(type(f[:,:,3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n\nimg = Image.open('./b.jpeg')\nimg = img.convert(\"RGBA\")\n\nimgnp = np.array(img)\n\nwhite = np.sum(imgnp[:,:,:3], axis=2)\nwhite_mask = np.where(white == 255*3, 1, 0)\n\nalpha = np.where(white_mask, 0, imgnp[:,:,-1])\n\nimgnp[:,:,-1] = alpha \n\nimg = Image.fromarray(np.uint8(imgnp))\nimg.save(\"tb2.png\", \"PNG\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}