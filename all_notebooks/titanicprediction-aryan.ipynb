{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#DATA WRANGLING AND ANALYSING\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rnd\n\n#DATA VISUALISATION\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n#MACHINE LEARNING\nfrom sklearn.svm import SVC , LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_path='../input/titanic-machine-learning-from-disaster/train.csv' #Importing train and test csv files\ntest_path='../input/titanic-machine-learning-from-disaster/test.csv'\ntrain_df=pd.read_csv(train_path)\ntest_df=pd.read_csv(test_path)\ncombine=[train_df,test_df]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()\nprint(train_df.columns.values) # Columns names in train.csv file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()  # Information about csv files\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe(include=['O'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean().sort_values(by='Survived',\n                                                                                      ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Sex','Survived']].groupby(['Sex'],as_index=False).mean().sort_values(by='Survived',\n                                                                               ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['SibSp','Survived']].groupby('SibSp').mean().sort_values(by='Survived',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Parch','Survived']].groupby(['Parch']).mean().sort_values(by='Survived',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g=sns.FacetGrid(train_df,col='Survived')\ng.map(plt.hist,'Age',bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g=sns.FacetGrid(train_df,col='Survived',row='Pclass',height=2.2,aspect=1.6)\ng.map(plt.hist,'Age',bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid=sns.FacetGrid(train_df,row='Embarked',height=2.2,aspect=1.6)\ngrid.map(sns.pointplot,'Pclass','Survived','Sex',palette='deep')\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid=sns.FacetGrid(train_df,row='Embarked',col='Survived',height=2.2,aspect=1.6)\ngrid.map(sns.barplot,'Sex','Fare',alpha=0.5,ci=None)\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop(['Ticket','Cabin'],axis=1)\ntest_df=test_df.drop(['Ticket','Cabin'],axis=1)\ncombine=[train_df,test_df]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Title']=dataset.Name.str.extract('([A-Za-z]+)\\.',expand=False)\n    \npd.crosstab(train_df['Title'],train_df['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['Title']=dataset['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Rare')\n    dataset['Title']=dataset['Title'].replace('Mlle','Miss')\n    dataset['Title']=dataset['Title'].replace('Ms','Miss')\n    dataset['Title']=dataset['Title'].replace('Mme','Mrs')\n    \n\ntrain_df[['Survived','Title']].groupby(['Title'],as_index=False).mean().sort_values(by='Survived',ascending=False)\n#train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_mapping={\"Mr\":1,\"Miss\":2,\"Mrs\":3,\"Master\":4,\"Rare\":5}\nfor dataset in combine:\n    dataset['Title']=dataset['Title'].map(title_mapping)\n    dataset['Title']=dataset['Title'].fillna(0)\n    \ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop(['Name','PassengerId'],axis=1)\ntest_df=test_df.drop(['Name'],axis=1)\ncombine=[train_df,test_df]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset[\"Sex\"]=dataset[\"Sex\"].map({'female':0,'male':1}).astype(int)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid=sns.FacetGrid(train_df,row='Pclass',col='Survived',height=2.2,aspect=1.6)\ngrid.map(plt.hist,'Age',alpha=0.5,bins=20)\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"guess_ages=np.zeros((2,3))\nfor dataset in combine:\n    for i in range(0,2):\n        for j in range(0,3):\n            guess_df=dataset[(dataset['Sex']==i) & (dataset['Pclass']==j+1)]['Age'].dropna()\n            \n            age_guess=guess_df.median()\n            \n            guess_ages[i,j]=int(age_guess/0.5+0.5)*0.5\n            \n            \n    for i in range(0,2):\n        for j in range(0,3):\n            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex==i) & (dataset.Pclass==j+1),'Age']=guess_ages[i,j]\n            \ntrain_df.head()\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['AgeBand']=pd.cut(train_df[\"Age\"],5)\ntrain_df[['Survived','AgeBand']].groupby('AgeBand',as_index='False').mean().sort_values(by='Survived',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[dataset['Age']<=16,'Age']=0\n    dataset.loc[(dataset['Age']>16) & (dataset['Age']<=32),'Age']=1\n    dataset.loc[(dataset['Age']>16) & (dataset['Age']<=48),'Age']=2\n    dataset.loc[(dataset['Age']>16) & (dataset['Age']<=64),'Age']=3\n    dataset.loc[dataset['Age']>64,'Age']\n    \ntrain_df.head()\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop(\"AgeBand\",axis=1)\ncombine=[train_df,test_df]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['FamilySize']=dataset['Parch']+dataset['SibSp']+1\n    \ntrain_df[['Survived','FamilySize']].groupby('FamilySize').mean().sort_values(by='Survived',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset['IsAlone']=0\n    dataset.loc[dataset['FamilySize']==1 , 'IsAlone']=1\ntrain_df[['Survived','IsAlone']].groupby('IsAlone').mean().sort_values(by='Survived',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop(['Parch','FamilySize','SibSp'],axis=1)\ntest_df=test_df.drop(['Parch','FamilySize','SibSp'],axis=1)\ncombine=[train_df,test_df]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NEW FEATURE\nfor dataset in combine:\n    dataset['Age*Class']=dataset['Age']*dataset['Pclass']\ntrain_df.loc[:,['Age','Pclass','Age*Class']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_port=train_df.Embarked.dropna().mode()[0]\nfreq_port\nfor dataset in combine:\n    dataset['Embarked']=dataset['Embarked'].fillna(freq_port)\n    \nfor dataset in combine:\n    dataset['Embarked']=dataset['Embarked'].map({'S':0,\"C\":1,\"Q\":2}).astype(int)\n    \ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Fare'].fillna(dataset['Fare'].dropna().median(),inplace=True)\ntrain_df.head()\n\ntrain_df['FareBand']=pd.qcut(dataset['Fare'],4)\n\ntrain_df[[\"Survived\",\"FareBand\"]].groupby('FareBand').mean().sort_values(by='Survived',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[dataset['Fare']<=7.91,'Fare']=0\n    dataset.loc[(dataset['Fare']>7.91) & (dataset['Fare']<=14.454),\"Fare\"]=1\n    dataset.loc[(dataset['Fare']>14.454) & (dataset['Fare']<=31.472),\"Fare\"]=2\n    dataset.loc[(dataset['Fare']>31.472) & (dataset['Fare']<=512.329),\"Fare\"]=3\n    dataset['Fare']=dataset['Fare'].astype(int)\n    \ntrain_df=train_df.drop(['FareBand'],axis=1)\ncombine=[train_df,test_df]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=train_df.drop(\"Survived\",axis=1)\nY_train=train_df['Survived']\nX_test=test_df.drop([\"PassengerId\"],axis=1).copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MODEL\n#SUPPORT VECTOR MACHINE\nsvc=SVC()\nsvc.fit(X_train,Y_train)\ny_predict=svc.predict(X_test)\nacc_svc=round(svc.score(X_train,Y_train)*100,2)\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train,Y_train)\ny_predict=knn.predict(X_test)\nscc=round(knn.score(X_train,Y_train)*100,2)\nscc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random=RandomForestClassifier(n_estimators=100)\nrandom.fit(X_train,Y_train)\ny_predict=random.predict(X_test)\nscc=round(random.score(X_train,Y_train)*100,2)\nscc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.DataFrame({\"PassengerId\":test_df['PassengerId'],\"Survived\":y_predict})\n#submission\nsubmission.to_csv('submission.csv',index=False)\nsubmission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}