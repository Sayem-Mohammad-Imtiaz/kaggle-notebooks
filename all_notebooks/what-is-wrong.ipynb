{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # (e.g. pd.read_csv)\ntransaction = pd.read_csv('../input/anomaly-detection/creditcard.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    transaction.drop('Class', axis=1), transaction['Class'], test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nparams = {\n    'num_leaves': [500,600,700,800],\n    'feature_fraction': list(np.arange(0.1,0.5,0.1)),\n    'bagging_fraction': list(np.arange(0.1,0.5,0.1)),\n    'min_data_in_leaf': [100,120,140,160],\n    'learning_rate': [0.05],\n    'reg_alpha': list(np.arange(0.1,0.5,0.1)),\n    'reg_lambda': list(np.arange(0.1,0.5,0.1)),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgbm\nmodel = lgbm.LGBMClassifier(random_state=42,metric='auc',verbosity=-1,objective='binary',max_depth=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\ngrid = RandomizedSearchCV(model,param_distributions=params,n_iter=15,cv=3,scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint(roc_auc_score(y_test,grid.predict_proba(X_test)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,grid.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'reg_lambda': 0.4,\n 'reg_alpha': 0.4,\n 'num_leaves': 700,\n 'min_data_in_leaf': 120,\n 'learning_rate': 0.05,\n 'feature_fraction': 0.2,\n 'bagging_fraction': 0.1}\n\n\nparams = {\n 'reg_lambda': 0.1,\n 'reg_alpha': 0.1,\n 'num_leaves': 800,\n 'min_data_in_leaf': 100,\n 'learning_rate': 0.05,\n 'feature_fraction': 0.4,\n 'bagging_fraction': 0.1,\n 'verbosity' : -1,\n  'objective' : 'binary',\n  'random_state' : 42,\n  'metric' : 'auc',\n  'max_depth' : -1,\n  'boosting_type': 'gbdt',\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport gc\n\nn_folds = 5\nfolds = KFold(n_splits=n_folds)\ncolumns = X_train.columns\ny_preds = np.zeros(X_test.shape[0])\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X_train, y_train)):\n    X_train, X_valid = X_train[columns].iloc[train_index], X_train[columns].iloc[valid_index]\n    y_train, y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n    \n    temp_train = lgbm.Dataset(X_train, label=y_train)\n    temp_valid = lgbm.Dataset(X_valid, label=y_valid)\n    clf = lgbm.train(params,temp_train, 10000, valid_sets = [temp_train, temp_valid],\n                      verbose_eval=200, early_stopping_rounds=500)\n    \n    y_pred_valid = clf.predict(X_valid)\n    print(\"AUC: \",roc_auc_score(y_valid, y_pred_valid))\n    y_preds += clf.predict(X_test) / n_folds\n    \n    #del X_train, X_valid, y_train, y_valid\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pylab as plt\n\nMat1 = pd.DataFrame({\"Class\":y_test, \"Prediction\": y_preds.tolist()})\nsns.lmplot( x=\"Class\", y=\"Prediction\", data=Mat1, fit_reg=False, hue='Class', height=8, aspect=17/8.27)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(Mat1['Prediction'], hist=False)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"Class\", y=\"Prediction\", data=Mat1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n\ndef plot_conf_Mat(Matrix):\n# Creates a confusion matrix\n    cm = confusion_matrix(Matrix['Class'].astype(np.int64), Matrix['Prediction'].astype(np.int64)) \n\n# Transform to df for easier plotting\n    cm_df = pd.DataFrame(cm,\n                     index = ['Class','Prediction'], \n                     columns = ['Class','Prediction'])\n\n    plt.figure(figsize=(5.5,4))\n    sns.heatmap(cm, annot=True)\n    plt.title('CM \\nAccuracy:{0:.3f}'.format(accuracy_score(Matrix['Class'].astype(np.int64), Matrix['Prediction'].astype(np.int64))))\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\nplot_conf_Mat(Mat1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}