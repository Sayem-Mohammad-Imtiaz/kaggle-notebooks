{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nfrom urllib.request import urlopen # Read csv file\n\n# nltk.download('punkt')\n# nltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read all files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read cv file (pdf or txt)\ncv = urlopen('https://raw.githubusercontent.com/iboraham/indeed-web-scraping/master/cv/cv.txt').read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read d.scientist csv\nds = pd.read_csv('../input/data-science-job-market-in-uk/data_scientist.csv')\nds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read m.learning engineers csv\nml = pd.read_csv('../input/data-science-job-market-in-uk/ml.csv')\nml.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get desc of the jobs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# trim skills and reqs from desc of jobs\ndef empty_count(str_series):\n    counter = 0\n    for ind in str_series:\n        if ind == []:\n            counter+=1\n    return counter\nds_desc=ds.Description.str.lower()\nml_desc=ml.Description.str.lower()\nds_qualifs=ds_desc.str.findall(r'((?:qualifications|requirements|desirable|skills|required|role)+(?:\\:|\\?|\\n)(?:.|\\s)*)')\nml_qualifs=ml_desc.str.findall(r'((?:qualifications|requirements|desirable|skills|required|role)+(?:\\:|\\?|\\n)(?:.|\\s)*)')\nempty_count(ml_qualifs)/len(ml_qualifs)*100, empty_count(ds_qualifs)/len(ds_qualifs)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concat\nml_desc_ready=ml_desc.str.cat(sep=';;;')\nds_desc_ready=ds_desc.str.cat(sep=';;;')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate similarity between cv and jobs desc's"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a text corpus containing all words of documents. Use tokenisation and stop word removal.\nimport string\nds_lowers = ds_desc_ready.lower()\nml_lowers = ml_desc_ready.lower()\ncv_lowers = cv.lower()\ncv_lowers = str(cv_lowers)\n\n# punctuation\ntranslator = str.maketrans('', '', string.punctuation)\nds_clean = ds_lowers.translate(translator)\nml_clean = ml_lowers.translate(translator)\ncv_clean = cv_lowers.translate(translator)\n\n# tokenize\nds_tokens = nltk.word_tokenize(ds_clean)\nml_tokens = nltk.word_tokenize(ml_clean)\ncv_tokens = nltk.word_tokenize(cv_clean)\n\n\n# Use stopwords\nfrom nltk.corpus import stopwords\nds_filtered = [w for w in ds_tokens if not w in stopwords.words('english')]\nml_filtered = [w for w in ml_tokens if not w in stopwords.words('english')]\ncv_filtered = [w for w in cv_tokens if not w in stopwords.words('english')]\nds = ' '.join(ds_filtered)\nml = ' '.join(ml_filtered)\ncv = ' '.join(cv_filtered)\n\n\n#Stemming is optional\n'''\nfrom nltk.stem.porter import *\nfrom collections import Counter\nstemmer = PorterStemmer()\nds_stemmed = []\nfor item in ds_filtered:\n    ds_stemmed.append(stemmer.stem(item))\nml_stemmed = []\nfor item in ml_filtered:\n    ml_stemmed.append(stemmer.stem(item))\nds = ' '.join([el[0] for el in Counter(ds_stemmed).most_common(200)])\nml = ' '.join([el[0] for el in Counter(ml_stemmed).most_common(200)])\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert the documents into tf-idf vectors\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer(stop_words='english')\ndocs = [ds,ml,cv]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the cosine-similarity between them or any new document for similarity measure.\ntfidf = vect.fit_transform(docs)\nsimilarity = tfidf*tfidf.T\nsimilarity=similarity.toarray()\n\n# another method\nfrom sklearn.metrics.pairwise import cosine_similarity\ncos_sim = cosine_similarity(tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"docs_name = ['ds','ml','cv']\nresults = pd.DataFrame(data=similarity,index=docs_name,columns=docs_name)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As a result, I should improve my resume for these fields."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}