{"cells":[{"metadata":{},"cell_type":"markdown","source":"Tutorial tirado de https://towardsdatascience.com/deep-clustering-for-financial-market-segmentation-2a41573618cf"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from time import time\nimport keras.backend as K\nfrom keras.engine.topology import Layer, InputSpec\nfrom keras.layers import Dense, Input\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom keras import callbacks\nfrom keras.initializers import VarianceScaling\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import silhouette_score\nimport numpy as np\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Data preparation\ndata = pd.read_csv('/kaggle/input/ccdata/CC GENERAL.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting features\n# O campo cust_id é unico e não serve para clusterização, por isso é descartado\ndata_x = data.drop(['CUST_ID'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-escala tudo para o intervalo entre 0 e 1\n# Pois o kmeans é sensitivo para a escala de valores das features, já que usa distância euclidiana como métrica de similaridade\nfrom sklearn.preprocessing import MinMaxScaler\nnumeric_columns = data_x.columns.values.tolist()\nscaler = MinMaxScaler()\ndata_x[numeric_columns] = scaler.fit_transform(data_x[numeric_columns])\ndata_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lidando com dados faltando\ndata_x.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Completando os dados que faltam com zero\ndata_x.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementation of the DEC Method in Keras\n\n-   Step 1: Estimating the number of clusters\n-   Step 2: Creating and training a K-means model\n-   Step 3: Creating and training an autoencoder\n-   Step 4: Implementing DEC Soft Labeling\n-   Step 5: Creating a new DEC model\n-   Step 6: Training the New DEC Model\n-   Step 7: Using the Trained DEC Model for Predicting Clustering Classes\n-   Step 8: Jointly Refining DEC Model\n-   Step 9: Using Refined DEC Model for Predicting Clustering Classes\n-   Step 10: Comparing with K-means\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating and training autoencoder\ndef autoencoder(dims, act='relu', init='glorot_uniform'):\n    \"\"\"\n    Fully connected symmetric auto-encoder model.\n  \n    dims: list of the sizes of layers of encoder like [500, 500, 2000, 10]. \n          dims[0] is input dim, dims[-1] is size of the latent hidden layer.\n\n    act: activation function\n    \n    return:\n        (autoencoder_model, encoder_model): Model of autoencoder and model of encoder\n    \"\"\"\n    n_stacks = len(dims) - 1\n    \n    input_data = Input(shape=(dims[0],), name='input')\n    x = input_data\n    \n    # internal layers of encoder\n    for i in range(n_stacks-1):\n        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n\n    # latent hidden layer\n    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)\n\n    x = encoded\n    # internal layers of decoder\n    for i in range(n_stacks-1, 0, -1):\n        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n\n    # decoder output\n    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n    \n    decoded = x\n    \n    autoencoder_model = Model(inputs=input_data, outputs=decoded, name='autoencoder')\n    encoder_model     = Model(inputs=input_data, outputs=encoded, name='encoder')\n    \n    return autoencoder_model, encoder_model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_x.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data_x.values\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Estimating the number of clusters\n# Para treinar o kmeans é necessário ter o numero de clusters\n# O número de clusters é estimado explorando os valores de silhouette de diferentes execuções de k-means\n\n# um valor de silhouette mede o quão similar um dado é dentro do seu cluster, comparado com os outros clusters\n# o valor vai de -1  a +1 \n# onde um valor alto indica que o dado bate com seu próprio cluster, caso seja baixo, é pq bate mais com os clusters vizinhos \n\nfor num_clusters in range(2,10):\n    clusterer = KMeans(n_clusters=num_clusters, n_jobs=4)\n    preds = clusterer.fit_predict(x)\n    score = silhouette_score(x, preds, metric='euclidean')\n    print('For n_clusters = {}, Kmeans silhouette score is {}'.format(num_clusters, score))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 3 \nn_epochs   = 100\nbatch_size = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating and Training K-means model\nkmeans = KMeans(n_clusters=n_clusters, n_jobs=4)\ny_pred_kmeans = kmeans.fit_predict(x) #x == valores do csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Tamanho das camadas\n# configuração generica do autoencoder da rede neural de qualquer dataset\ndims = [x.shape[-1], 500, 500, 2000, 10]\ninit = VarianceScaling(scale=1./3., mode='fan_in', distribution='uniform')\npretrain_optimizer = SGD(lr=1, momentum=0.9)\npretrain_epochs = n_epochs\nbatch_size = batch_size\nsave_dir='/kaggle/output'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dims","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criação do modelo de autoencoder\n\nautoencoder, encoder = autoencoder(dims, init=init)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nfrom IPython.display import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(autoencoder, to_file='autoencoder.png', show_shapes=True)\nImage(filename='autoencoder.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(autoencoder, to_file='encoder.png', show_shapes=True)\nImage(filename='encoder.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinamento do autoencoder\nautoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\nautoencoder.fit(x,x, batch_size=batch_size, epochs=pretrain_epochs)\nautoencoder.save_weights('ae_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.load_weights('ae_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nUm dos componentes chaves de DEC é o soft labeling, que é a atribuição a uma classe estimada para cada dado, \nde forma que possa ser refinado iterativamente\n'''\nclass ClusteringLayer(Layer):\n    '''\n    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n    '''\n\n    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n        super(ClusteringLayer, self).__init__(**kwargs)\n        self.n_clusters = n_clusters\n        self.alpha = alpha\n        self.initial_weights = weights\n        self.input_spec = InputSpec(ndim=2)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 2\n        input_dim = input_shape[1]\n        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n        self.clusters = self.add_weight(name='clusters', shape=(self.n_clusters, input_dim), initializer='glorot_uniform') \n        \n        if self.initial_weights is not None:\n            self.set_weights(self.initial_weights)\n            del self.initial_weights\n        self.built = True\n\n    def call(self, inputs, **kwargs):\n        ''' \n        student t-distribution, as used in t-SNE algorithm.\n        It measures the similarity between embedded point z_i and centroid µ_j.\n                 q_ij = 1/(1+dist(x_i, µ_j)^2), then normalize it.\n                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n                 (i.e., a soft assignment)\n       \n        inputs: the variable containing data, shape=(n_samples, n_features)\n        \n        Return: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n        '''\n        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n        q **= (self.alpha + 1.0) / 2.0\n        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure all of the values of each sample sum up to 1.\n        \n        return q\n\n    def compute_output_shape(self, input_shape):\n        assert input_shape and len(input_shape) == 2\n        return input_shape[0], self.n_clusters\n\n    def get_config(self):\n        config = {'n_clusters': self.n_clusters}\n        base_config = super(ClusteringLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\nmodel = Model(inputs=encoder.input, outputs=clustering_layer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, to_file='model.png', show_shapes=True)\nImage(filename='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=n_clusters, n_init=20)\ny_pred = kmeans.fit_predict(encoder.predict(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_last = np.copy(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DEEP CLUSTERING**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the new DEC model\n# computing an auxiliary target distribution\ndef target_distribution(q):\n    weight = q ** 2 / q.sum(0)\n    return (weight.T / weight.sum(1)).T\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = 0\nindex = 0\nmaxiter = 1000\nupdate_interval = 100\nindex_array = np.arange(x.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tol = 0.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ite in range(int(maxiter)):\n    if ite % update_interval == 0:\n        q = model.predict(x, verbose=0)\n        p = target_distribution(q)\n    \n    idx = index_array[index*batch_size : min((index+1)*batch_size, x.shape[0])]\n    loss = model.train_on_batch(x=x[idx], y=p[idx])\n    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n    print ('ite: {}'.format(str(ite)))\n    \nmodel.save_weights('DEC_model_final.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('DEC_model_final.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Using Trained DEC Model for Predicting Clustering Classes\nq = model.predict(x, verbose=0)\np = target_distribution(q)\n\ny_pred = q.argmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_all = data_x.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_all['cluster'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_all['cluster'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_embedded = TSNE(n_components=2).fit_transform(x)\nx_embedded.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vis_x = x_embedded[:, 0]\nvis_y = x_embedded[:, 1]\nplt.scatter(vis_x, vis_y, c=y_pred, cmap=plt.cm.get_cmap(\"jet\", 256))\nplt.colorbar(ticks=range(256))\nplt.clim(-0.5, 9.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_kmeans.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(vis_x, vis_y, c=y_pred_kmeans, cmap=plt.cm.get_cmap('jet', 256))\nplt.colorbar(ticks=range(100))\nplt.clim(-0.5, 9.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = silhouette_score(x, y_pred_kmeans, metric='euclidean')\nprint (\"For n_clusters = {}, Kmeans silhouette score is {})\".format(n_clusters, score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = silhouette_score (x, y_pred, metric='euclidean')\nprint (\"For n_clusters = {}, Deep clustering silhouette score is {})\".format(n_clusters, score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for num_clusters in range(2,10):\n    clusterer = KMeans(n_clusters=num_clusters, n_jobs=4)\n    preds = clusterer.fit_predict(x)\n    # centers = clusterer.cluster_centers_\n    score = silhouette_score (x, preds, metric='euclidean')\n    print (\"For n_clusters = {}, Kmeans silhouette score is {})\".format(num_clusters, score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Need to re-run autoencoder function declaration!!!\ndef autoencoder(dims, act='relu', init='glorot_uniform'):\n    \"\"\"\n    Fully connected auto-encoder model, symmetric.\n    Arguments:\n        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n        act: activation, not applied to Input, Hidden and Output layers\n    return:\n        (ae_model, encoder_model), Model of autoencoder and model of encoder\n    \"\"\"\n    n_stacks = len(dims) - 1\n    # input\n    input_data = Input(shape=(dims[0],), name='input')\n    x = input_data\n    \n    # internal layers in encoder\n    for i in range(n_stacks-1):\n        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n\n    # hidden layer\n    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n\n    x = encoded\n    # internal layers in decoder\n    for i in range(n_stacks-1, 0, -1):\n        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n\n    # output\n    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n    decoded = x\n    return Model(inputs=input_data, outputs=decoded, name='AE'), Model(inputs=input_data, outputs=encoded, name='encoder')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Jointly Refining DEC Model\n'''\n ideia principal é aprender simultaneamente a representação da feature e \n fazer as atribuições do cluster usando DNN. \n \n Esse código usa o autoencoder pre-treinado e o modelo de kmeans para definir um novo \n modelo que pega o dataset pre-processado como input e dá como output as classes de clsuterização da predição \n'''\nautoencoder.load_weights('ae_weights.h5')\nclustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\nmodel = Model(inputs=encoder.input, outputs=[clustering_layer, autoencoder.output])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplot_model(model, to_file='model.png', show_shapes=True)\nImage(filename='model.png')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=n_clusters, n_init=20)\ny_pred = kmeans.fit_predict(encoder.predict(x))\nmodel.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\ny_pred_last = np.copy(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer=pretrain_optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ite in range(int(maxiter)):\n    if ite % update_interval == 0:\n        q, _  = model.predict(x, verbose=0)\n        p = target_distribution(q)  # update the auxiliary target distribution p\n\n        # evaluate the clustering performance\n        y_pred = q.argmax(1)\n\n        # check stop criterion\n        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n        y_pred_last = np.copy(y_pred)\n        if ite > 0 and delta_label < tol:\n            print('delta_label ', delta_label, '< tol ', tol)\n            print('Reached tolerance threshold. Stopping training.')\n            break\n    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n    loss = model.train_on_batch(x=x[idx], y=[p[idx], x[idx]])\n    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n\nmodel.save_weights('b_DEC_model_final.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('b_DEC_model_final.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation of model prediction\nq, _ = model.predict(x, verbose=0)\np = target_distribution(q)\n\n# evaluate the clustering performance\ny_pred = q.argmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = silhouette_score(x, y_pred, metric='euclidean')\nprint (\"For n_clusters = {}, Deep clustering silhouette score is {})\".format(n_clusters, score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(vis_x, vis_y, c=y_pred, cmap=plt.cm.get_cmap(\"jet\", 256))\nplt.colorbar(ticks=range(256))\nplt.clim(-0.5, 9.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nplt.scatter(vis_x, vis_y, c=y_pred_kmeans, cmap=plt.cm.get_cmap(\"jet\", 256))\nplt.colorbar(ticks=range(256))\nplt.clim(-0.5, 9.5)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_all['cluster'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_all['cluster'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cluster_0 = data_all[data_all['cluster'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cluster_0.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndata_cluster_1 = data_all[data_all['cluster'] == 1]\ndata_cluster_1.describe()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cluster_2 = data_all[data_all['cluster'] == 2]\ndata_cluster_2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=2)\nx_pca = pca.fit_transform(x)\n\nx_pca.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nvis_x = x_pca[:, 0]\nvis_y = x_pca[:, 1]\nplt.scatter(vis_x, vis_y, c=y_pred, cmap=plt.cm.get_cmap(\"jet\", 256))\nplt.colorbar(ticks=range(256))\nplt.clim(-0.5, 9.5)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}