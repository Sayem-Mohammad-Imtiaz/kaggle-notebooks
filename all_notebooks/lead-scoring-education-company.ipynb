{"cells":[{"metadata":{},"cell_type":"markdown","source":"Problem Statement\nAn education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses.\n\nThe company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos.\n\nWhen these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals.\n\nOnce these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%.\n\nNow, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as ‘Hot Leads’.\n\nIf they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone. A typical lead conversion process can be represented using the following funnel:image.jpg\n\nLead Conversion Process - Demonstrated as a funnel As you can see, there are a lot of leads generated in the initial stage (top) but only a few of them come out as paying customers from the bottom.\n\nIn the middle stage, you need to nurture the potential leads well (i.e. educating the leads about the product, constantly communicating etc. ) in order to get a higher lead conversion.\n\nX Education has appointed you to help them select the most promising leads, i.e. the leads that are most likely to convert into paying customers.\nThe company requires you to build a model wherein you need to assign a lead score to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance.\n\nThe CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.\n\nData\nYou have been provided with a leads dataset from the past with around 9000 data points. This dataset consists of various attributes such as Lead Source, Total Time Spent on Website, Total Visits, Last Activity, etc. which may or may not be useful in ultimately deciding whether a lead will be converted or not. The target variable, in this case, is the column ‘Converted’ which tells whether a past lead was converted or not wherein 1 means it was converted and 0 means it wasn’t converted.\n\nAnother thing that you also need to check out for are the levels present in the categorical variables.\n\nMany of the categorical variables have a level called 'Select' which needs to be handled because it is as good as a null value.\n\nGoal\nBuild a logistic regression model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# visulaisation\nfrom matplotlib.pyplot import xticks\n%matplotlib inline\n\n# Data display coustomization\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 100)\n\ndata = pd.DataFrame(pd.read_csv('../input/leads-dataset/Leads.csv'))\ndata.head(5) \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# As we can observe that there are select values for many column.\n#This is because customer did not select any option from the list, hence it shows select.\n# Select values are as good as NULL.\n\n# Converting 'Select' values to NaN.\ndata = data.replace('Select', np.nan)\nround(100*(data.isnull().sum()/len(data.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(data.loc[:,list(round(100*(data.isnull().sum()/len(data.index)), 2)>70)].columns, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As Lead quality is based on the intution of employee, so if left blank we can impute 'Not Sure' in NaN safely.\ndata['Lead Quality'] = data['Lead Quality'].replace(np.nan, 'Not Sure')\nsns.countplot(data['Lead Quality'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2,2, figsize = (10,7.5))\nplt1 = sns.countplot(data['Asymmetrique Activity Index'], ax = axs[0,0])\nplt2 = sns.boxplot(data['Asymmetrique Activity Score'], ax = axs[0,1])\nplt3 = sns.countplot(data['Asymmetrique Profile Index'], ax = axs[1,0])\nplt4 = sns.boxplot(data['Asymmetrique Profile Score'], ax = axs[1,1])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Asymmetrique Activity Index','Asymmetrique Activity Score','Asymmetrique Profile Index','Asymmetrique Profile Score'],1)\nround(100*(data.isnull().sum()/len(data.index)), 2)\nsns.countplot(data.City)\nxticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Around 60% of the data is Mumbai so we can impute Mumbai in the missing values.\ndata['City'] = data['City'].replace(np.nan, 'Mumbai')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.Specialization)\nxticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It maybe the case that lead has not entered any specialization if his/her option is not availabe on the list,\n#  may not have any specialization or is a student.\n# Hence we can make a category \"Others\" for missing values.\ndata['Specialization'] = data['Specialization'].replace(np.nan, 'Others')\nround(100*(data.isnull().sum()/len(data.index)), 2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize = (15,7.5))\nsns.countplot(data.Tags)\nxticks(rotation = 90)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Blanks in the tag column may be imputed by 'Will revert after reading the email'.\ndata['Tags'] = data['Tags'].replace(np.nan, 'Will revert after reading the email')\ndata['What matters most to you in choosing a course'] = data['What matters most to you in choosing a course'].replace(np.nan, 'Better Career Prospects')\ndata['What is your current occupation'] = data['What is your current occupation'].replace(np.nan, 'Unemployed')\n# Country is India for most values so let's impute the same in missing values.\ndata['Country'] = data['Country'].replace(np.nan, 'India')\n# Rest missing values are under 2% so we can drop these rows.\ndata.dropna(inplace = True)\nround(100*(data.isnull().sum()/len(data.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"Lead Origin\", hue = \"Converted\", data = data)\nxticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference\nAPI and Landing Page Submission have 30-35% conversion rate but count of lead originated from them are considerable.\nLead Add Form has more than 90% conversion rate but count of lead are not very high.\nLead Import are very less in count.\nTo improve overall lead conversion rate, we need to focus more on improving lead converion of API and Landing Page Submission origin and generate more leads from Lead Add Form."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y = 'Total Time Spent on Website', x = 'Converted', data = data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference\nLeads spending more time on the weblise are more likely to be converted.\nWebsite should be made more engaging to make leads spend more time."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize = (15,7.5))\nsns.countplot(x = \"Lead Source\", hue = \"Converted\", data = data)\nxticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Lead Source'] = data['Lead Source'].replace(['google'], 'Google')\ndata['Lead Source'] = data['Lead Source'].replace(['Click2call', 'Live Chat', 'NC_EDM', 'Pay per Click Ads', 'Press_Release',\n  'Social Media', 'WeLearn', 'bing', 'blog', 'testone', 'welearnblog_Home', 'youtubechannel'], 'Others')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"Lead Source\", hue = \"Converted\", data = data)\nxticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference\nGoogle and Direct traffic generates maximum number of leads.\nConversion Rate of reference leads and leads through welingak website is high.\nTo improve overall lead conversion rate, focus should be on improving lead converion of olark chat, organic search, direct traffic, and google leads and generate more leads from reference and welingak website."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize = (10,5))\nsns.countplot(x = \"What is your current occupation\", hue = \"Converted\", data = data)\nxticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Lead Number','What matters most to you in choosing a course','Search','Magazine','Newspaper Article','X Education Forums','Newspaper',\n           'Digital Advertisement','Through Recommendations','Receive More Updates About Our Courses','Update me on Supply Chain Content',\n           'Get updates on DM Content','I agree to pay the amount through cheque','A free copy of Mastering The Interview'],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"varlist =  ['Do Not Email', 'Do Not Call']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the housing list\ndata[varlist] = data[varlist].apply(binary_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy = pd.get_dummies(data[['Lead Origin', 'Lead Source', 'Last Activity', 'Specialization','What is your current occupation',\n                              'Tags','Lead Quality','City','Last Notable Activity']], drop_first=True)\n# Adding the results to the master dataframe\ndata = pd.concat([data, dummy], axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Country','Lead Origin', 'Lead Source', 'Last Activity', 'Specialization','What is your current occupation','Tags','Lead Quality','City','Last Notable Activity'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport warnings\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.feature_selection import RFE, f_regression\nfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso)\nfrom sklearn import tree, linear_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import  GradientBoostingClassifier\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_curve, auc\nfrom matplotlib.legend_handler import HandlerLine2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n    \"\"\"pretty print for confusion matrixes\"\"\"\n    columnwidth = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n    empty_cell = \" \" * columnwidth\n    \n    # Begin CHANGES\n    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n    \n    if len(fst_empty_cell) < len(empty_cell):\n        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n    # Print header\n    print(\"    \" + fst_empty_cell, end=\" \")\n    # End CHANGES\n    \n    for label in labels:\n        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n        \n    print()\n    # Print rows\n    for i, label1 in enumerate(labels):\n        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n        for j in range(len(labels)):\n            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n            if hide_zeroes:\n                cell = cell if float(cm[i, j]) != 0 else empty_cell\n            if hide_diagonal:\n                cell = cell if i != j else empty_cell\n            if hide_threshold:\n                cell = cell if cm[i, j] > hide_threshold else empty_cell\n            print(cell, end=\" \")\n        print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=[f for f in data.columns if f not in ['Prospect ID','Converted']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total Features',len(features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importance\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nclf=RandomForestClassifier()\n\nfeatures_with_customer_id=features.copy()\nfeatures_with_customer_id.append('Prospect ID')\nx_train,x_test,y_train,y_test = train_test_split(data[features_with_customer_id],data['Converted'],test_size=0.3,random_state=42)\nx_train_backup=x_train\nx_test_backup=x_test\nx_train=x_train[features]\nx_test=x_test[features]\n\nclf.fit(x_train, y_train)\npredictions_train = clf.predict(x_train)\npredictions_test = clf.predict(x_test)\n\ndef accuracy_report(labels,predictions):\n   precision, recall, fscore, support = score(labels, predictions)\n   avg_fscore=f1_score(labels, predictions, average='macro')\n   cm = confusion_matrix(labels, predictions, labels=[0,1])\n   print('precision of 1: ',precision[1],', recall of 1:',recall[1])\n   print_cm(cm, [0,1])\n\nprint('Confusion matrix for Train')\naccuracy_report(y_train,predictions_train)\nprint('Confusion matrix for Test')\naccuracy_report(y_test,predictions_test)\n\n#feature selection\ndef feature_selection(features,clf,threshold):\n    important_features=[]\n    feature_importance=[]\n    feature_score = pd.DataFrame(columns=['feature','importance_score'])\n    \n    for feature in zip(features, clf.feature_importances_):      \n      feature_score.loc[len(feature_score.index)] = [feature[0],feature[1]]\n    \n    feature_importance=feature_score.sort_values(by=['importance_score'],ascending=False).reset_index().head(threshold)\n    important_features=feature_importance['feature'].to_list()\n    return important_features,feature_importance,feature_score\n\nimportant_features,feature_importance,feature_score = feature_selection(x_train.columns,clf,20)\nfeature_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ModelSelection(test_data,features,label,dummy_variables_list):\n    MLA = [\n    \n    ensemble.BaggingClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    RandomForestClassifier(),\n           \n    XGBClassifier(),\n        \n    linear_model.LogisticRegressionCV(),\n    linear_model.SGDClassifier(),\n            \n    svm.SVC(probability=True),\n        \n    tree.DecisionTreeClassifier(),\n                \n    ]\n    \n    MLA_columns = ['MLA Name', 'MLA Parameters','MLA Score']\n    MLA_compare = pd.DataFrame(columns = MLA_columns)\n    features_with_customer_id=features.copy()\n    features_with_customer_id.append('Prospect ID')\n    x_train,x_test,y_train,y_test = train_test_split (test_data[features_with_customer_id],test_data[label],test_size=0.3,random_state=0)\n    print('features used: ',features)\n    x_train_backup=x_train\n    x_test_backup=x_test\n    x_train=x_train[features]\n    x_test=x_test[features]\n    #x_train=pd.get_dummies(x_train, columns=dummy_variables_list)\n    #x_test=pd.get_dummies(x_test, columns=dummy_variables_list)\n    row_index = 0\n    MLA_predict = test_data[label]\n    for alg in MLA:\n\n        MLA_name = alg.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n        alg.fit(x_train, y_train)\n        MLA_predict[MLA_name] = alg.predict(x_test)\n        MLA_compare.loc[row_index, 'MLA Score']=alg.score(x_test,y_test)\n        row_index+=1\n\n    \n    MLA_compare.sort_values(by = ['MLA Score'], ascending = False, inplace = True)\n    return MLA_compare,x_train,x_test,y_train,y_test,x_train_backup,x_test_backup","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MLA_compare,x_train,x_test,y_train,y_test,x_train_backup,x_test_backup=ModelSelection(data,important_features,'Converted','')\nprint(MLA_compare[['MLA Name','MLA Score']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate the classfiers and make a list\nclassifiers = [RandomForestClassifier(), \n               XGBClassifier(), \n               ]\n\n# Define a result table as a DataFrame\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n\n# Train the models and record the results\nfor cls in classifiers:\n    model = cls.fit(x_train, y_train)\n    yproba = model.predict_proba(x_test)[::,1]\n    \n    fpr, tpr, _ = roc_curve(y_test,  yproba)\n    auc = roc_auc_score(y_test, yproba)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\n\n# Set name of the classifiers as index labels\nresult_table.set_index('classifiers', inplace=True)\n\nfig = plt.figure(figsize=(8,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importance\nclf=RandomForestClassifier()\n\nfeatures_with_customer_id=important_features.copy()\nfeatures_with_customer_id.append('Prospect ID')\nx_train,x_test,y_train,y_test = train_test_split(data[features_with_customer_id],data['Converted'],test_size=0.3,random_state=42)\nx_train_backup=x_train\nx_test_backup=x_test\nx_train=x_train[important_features]\nx_test=x_test[important_features]\n\nclf.fit(x_train, y_train)\npredictions_train = clf.predict(x_train)\npredictions_test = clf.predict(x_test)\n\ndef accuracy_report(labels,predictions):\n   precision, recall, fscore, support = score(labels, predictions)\n   avg_fscore=f1_score(labels, predictions, average='macro')\n   cm = confusion_matrix(labels, predictions, labels=[0,1])\n   print('precision of 1: ',precision[1],', recall of 1:',recall[1])\n   print_cm(cm, [0,1])\n\nprint('Confusion matrix for Train')\naccuracy_report(y_train,predictions_train)\nprint('Confusion matrix for Test')\naccuracy_report(y_test,predictions_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importance\nclf=XGBClassifier()\n\nfeatures_with_customer_id=important_features.copy()\nfeatures_with_customer_id.append('Prospect ID')\nx_train,x_test,y_train,y_test = train_test_split(data[features_with_customer_id],data['Converted'],test_size=0.3,random_state=42)\nx_train_backup=x_train\nx_test_backup=x_test\nx_train=x_train[important_features]\nx_test=x_test[important_features]\n\nclf.fit(x_train, y_train)\npredictions_train = clf.predict(x_train)\npredictions_test = clf.predict(x_test)\n\ndef accuracy_report(labels,predictions):\n   precision, recall, fscore, support = score(labels, predictions)\n   avg_fscore=f1_score(labels, predictions, average='macro')\n   cm = confusion_matrix(labels, predictions, labels=[0,1])\n   print('precision of 1: ',precision[1],', recall of 1:',recall[1])\n   print_cm(cm, [0,1])\n\nprint('Confusion matrix for Train')\naccuracy_report(y_train,predictions_train)\nprint('Confusion matrix for Test')\naccuracy_report(y_test,predictions_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probability threshold\ndef proba_threhsold(probas,probas_threshold):\n    new_predictions=[]\n    for p in probas:\n      if (p[1]>p[0]):\n        new_predictions.append(1)\n      elif ((p[1]>probas_threshold)):\n        new_predictions.append(1)\n      else:\n        new_predictions.append(0)\n    return new_predictions\n\n#feature importance\nclf=XGBClassifier()\n\nclf.fit(x_train[important_features], y_train)\npredictions_train_prob = clf.predict_proba(x_train[important_features])\npredictions_test_prob = clf.predict_proba(x_test[important_features])\n\nprobas_threshold=0.05\n\ntrain_predicted=proba_threhsold(predictions_train_prob,probas_threshold)\ntest_predicted=proba_threhsold(predictions_test_prob,probas_threshold)\n\nprint('Confusion matrix for Train')\naccuracy_report(y_train,train_predicted)\nprint('Confusion matrix for Test')\naccuracy_report(y_test,test_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hyper parameter tuning\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom xgboost import XGBClassifier\nimport pickle\n\ndef timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n     \n    \ncount_0=y_train.tolist().count(0)\ncount_1=y_train.tolist().count(1)\n\nparams = {\n        'min_child_weight': [1,3], # ,5 default 1 higher values reduces overfitting, prevents model from learning relationship which are specific to particular sample \n        'gamma': [0.2, 0.5], #default 0, higher value reduces overfitting, min gain for loss function on possible split. node is split only when the resulting split gives a positive reduction in the loss function.\n        'subsample': [0.8, 1.0], #default 1, lower values prevents overfitting, 0.5 to 1. number of samples to consider for a tree. 1 means all samples.\n        'n_estimators':[100,200], #number of trees\n        'eval_metric':['auc'], #'error',\n        'max_depth':[3,4,6],\n        'reg_lambda': [0,1],  #ridge regularization (shrinks coeff)\n        #'colsample_bytree':[0.8,1], # default is 1 number of features to consider for single tree\n        #'reg_alpha': [0,1], #lasso regularization (makes coeff 0)\n        'max_delta_step':[0,1], #default is 0. used when class imbalanced. absolute capping on features weight\n        'scale_pos_weight':[1,count_0/count_1], #default is 1, count(0)/count(1) in tranining. #greater than 1 for class imbalance\n        }\nxgb = XGBClassifier(learning_rate=0.05, objective='binary:logistic', silent=True, nthread=-1)\n\n\nfolds = 3\nparam_comb = 500\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params,n_iter=param_comb,  scoring='roc_auc', n_jobs=4, cv=skf.split(x_train,y_train), verbose=3, random_state=1001 )\nstart_time = timer(None)\nrandom_search.fit(x_train, y_train)\nprint(random_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probability threshold\ndef proba_threhsold(probas,probas_threshold):\n    new_predictions=[]\n    for p in probas:\n      if (p[1]>p[0]):\n        new_predictions.append(1)\n      elif ((p[1]>probas_threshold)):\n        new_predictions.append(1)\n      else:\n        new_predictions.append(0)\n    return new_predictions\n\n#feature importance\nclf=XGBClassifier( subsample= 0.8, \n                   scale_pos_weight= 1,\n                   reg_lambda= 0,\n                   n_estimators= 100,\n                   min_child_weight= 1,\n                   max_depth= 4,\n                   max_delta_step= 0,\n                   gamma= 0.2,\n                   eval_metric= 'auc')\n\nclf.fit(x_train[important_features], y_train)\npredictions_train_prob = clf.predict_proba(x_train[important_features])\npredictions_test_prob = clf.predict_proba(x_test[important_features])\n\nprobas_threshold=0.10\n\ntrain_predicted=proba_threhsold(predictions_train_prob,probas_threshold)\ntest_predicted=proba_threhsold(predictions_test_prob,probas_threshold)\n\nprint('Confusion matrix for Train')\naccuracy_report(y_train,train_predicted)\nprint('Confusion matrix for Test')\naccuracy_report(y_test,test_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nx_train_backup['Probability of not defaulter'] = predictions_train_prob[:,0]\nx_train_backup['Probability of being defaulter'] = predictions_train_prob[:,1]\nx_test_backup['Probability of not defaulter'] = predictions_test_prob[:,0]\nx_test_backup['Probability of being defaulter'] = predictions_test_prob[:,1]\nx_train_backup['type'] = 'train'\nx_test_backup['type'] = 'test'\nfinal_predictions = pd.concat([x_train_backup,x_test_backup])\nfinal_predictions=final_predictions[['customer_id','Probability of not defaulter','Probability of being defaulter','type']]\n\nresult = pd.merge(data,\n                 final_predictions,\n                 on='customer_id')\nresult.to_csv('predictions.csv')\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PCA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=XGBClassifier()\n\nfeatures_with_customer_id=features.copy()\nfeatures_with_customer_id.append('Prospect ID')\nx_train,x_test,y_train,y_test = train_test_split(data[features_with_customer_id],data['Converted'],test_size=0.3,random_state=42)\nx_train_backup=x_train\nx_test_backup=x_test\nx_train=x_train[features]\nx_test=x_test[features]\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=50)\nx_train = pca.fit_transform(x_train)\nx_test = pca.transform(x_test)\n#explained_variance = pca.explained_variance_ratio_\n\nclf.fit(x_train, y_train)\npredictions_train = clf.predict(x_train)\npredictions_test = clf.predict(x_test)\n\ndef accuracy_report(labels,predictions):\n   precision, recall, fscore, support = score(labels, predictions)\n   avg_fscore=f1_score(labels, predictions, average='macro')\n   cm = confusion_matrix(labels, predictions, labels=[0,1])\n   print('precision of 1: ',precision[1],', recall of 1:',recall[1])\n   print_cm(cm, [0,1])\n\nprint('Confusion matrix for Train')\naccuracy_report(y_train,predictions_train)\nprint('Confusion matrix for Test')\naccuracy_report(y_test,predictions_test)\n\n#feature selection\ndef feature_selection(features,clf,threshold):\n    important_features=[]\n    feature_importance=[]\n    feature_score = pd.DataFrame(columns=['feature','importance_score'])\n    \n    for feature in zip(features, clf.feature_importances_):      \n      feature_score.loc[len(feature_score.index)] = [feature[0],feature[1]]\n    \n    feature_importance=feature_score.sort_values(by=['importance_score'],ascending=False).reset_index().head(threshold)\n    important_features=feature_importance['feature'].to_list()\n    return important_features,feature_importance,feature_score\n\nimportant_features,feature_importance,feature_score = feature_selection(range(1, 50),clf,50)\nfeature_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\ntrain_results = []\ntest_results = []\nfor estimator in n_estimators:\n    model = XGBClassifier(n_estimators=estimator)\n    model.fit(x_train, y_train)\n    train_pred = model.predict(x_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = model.predict(x_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\nline1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\nline2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}