{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font style=\"color:red;\">Grid Search for Finding the Best Set of Hyper Parameters</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## <font color=blue> Basic Initialisation </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common imports\nimport pandas as pd\nimport numpy as np\nimport time\nimport os\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verifying pathname of dataset before loading - for Kaggle\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));\n        print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color=blue>Loading Dataset </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Datasets\ndef loadDataset(file_name):\n    df = pd.read_csv(file_name,engine = 'python')\n    return df\nstart_time= time.time()\ndf_train = loadDataset(\"/kaggle/input/dataset-of-malicious-and-benign-webpages/Webpages_Classification_train_data.csv/Webpages_Classification_train_data.csv\")\ndf_test = loadDataset(\"/kaggle/input/dataset-of-malicious-and-benign-webpages/Webpages_Classification_test_data.csv/Webpages_Classification_test_data.csv\")\n#Ensuring correct sequence of columns \ndf_train = df_train[['url','content','label']]\ndf_test = df_test[['url','content','label']]\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## <font color=blue> Preprocessing the Dataset </font>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"start_time= time.time()\ndf_test['content'] = df_test['content'].str.lower()\ndf_test.drop(columns=['url'],inplace=True)\ndf_test.rename(columns={'content':'text'},inplace=True)\ndf_train['content'] = df_train['content'].str.lower()\ndf_train.drop(columns=['url'],inplace=True)\ndf_train.rename(columns={'content':'text'},inplace=True)\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Converting Label value to 0,1\nstart_time= time.time()\ndf_test['label'].replace(to_replace =\"good\", value =1, inplace=True)\ndf_train['label'].replace(to_replace =\"good\", value =1, inplace=True)\ndf_test['label'].replace(to_replace =\"bad\", value =0, inplace=True)\ndf_train['label'].replace(to_replace =\"bad\", value =0, inplace=True)\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Earmarking Validation, Train & Test Sets","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#Selection lower numbers as of now for fast testing\ntrain= df_train.iloc[:300000,]\nval= df_train.iloc[300001:310000,]\ntest= df_test.iloc[:200000,]\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')\nprint(len(test), 'test examples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Converting the dataframes into X, y numpy arrays \nX_train = train['text'].to_numpy()\ny_train = train['label'].astype(int).to_numpy()\nX_val = val['text'].to_numpy()\ny_val = val['label'].astype(int).to_numpy()\nX_test = test['text'].to_numpy()\ny_test = test['label'].astype(int).to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=blue> Preparing the Tensor Flow Deep Learning Model and SciKit GridSearch</font>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Using Transfer Learning from Tensorflow hub- Universal Text Encoder\nstart_time= time.time()\n# Word Embedder with fixed 20 vector output\nencoder = hub.load(\"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\")\n# Use the ecoder from a local file\n#encoder = hub.load(\"datasets/PretrainedTFModel/1\")\nprint(\"***Total Time taken --- %s seconds ---***\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=blue>Grid Search for Best Optimisation Algorithm</font>","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Use scikit-learn to grid search \nimport numpy\nfrom sklearn.model_selection import GridSearchCV\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n# Function to create model, required for KerasClassifier\ndef create_model(optimizer='adam'):\n    model = keras.Sequential([\n    hub.KerasLayer(encoder, input_shape=[],dtype=tf.string,trainable=True),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(16, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid'),\n    ])\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=4, batch_size=2048)\n# define the grid search parameters\noptimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adam']\n#optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\nparam_grid = dict(optimizer=optimizer)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,cv=3)\ngrid_result = grid.fit(X_train,y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=blue>Grid Search for Best Learning Rate</font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use scikit-learn to grid search the Learning Rate of ADAM Optimizer\nimport numpy\nfrom sklearn.model_selection import GridSearchCV\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n# Function to create model, required for KerasClassifier\ndef create_model(learning_rate=0.001):\n    model = keras.Sequential([\n    hub.KerasLayer(encoder, input_shape=[],dtype=tf.string,trainable=True),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(16, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid'),\n    ])\n    model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n    return model\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=5, batch_size=2048,verbose=0)\n# define the grid search parameters\nlearning_rate = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001,0.000001,0.0000001]\nparam_grid = dict(learning_rate=learning_rate)\ngrid = GridSearchCV(estimator=model,param_grid=param_grid,n_jobs=1,cv=3)\ngrid_result = grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}