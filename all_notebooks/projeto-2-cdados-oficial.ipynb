{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A.Introdução"},{"metadata":{},"cell_type":"markdown","source":"Este projeto foi motivado pela curiosidade de compreender o impacto de variáveis sociais, como o estado onde a pessoa habita, tipo de instituição escolar, situação de conclusão do ensino médio, entre outros, na nota na prova de Matemáticas e suas Tecnologias. Assim, buscamos entender mais precisamente como esses fatores influenciam no resultado do aluno.  A base de dados usada foi a de Microdados do ENEM 2019, do INEP. A base tinha mais 5 milhões de linhas e 136 colunas, cada linha representando um candidato e cada coluna representando uma das variáveis sociais. Portanto, primeiro foi feita uma coleta de uma amostra aleatória e depois uma limpeza dessa amostra. Foram eliminadas as linhas das pessoas que tinham faltado a prova de Matemática, já que esses casos não contribuiam para chegar no objetivo do estudo. Além disso, as colunas das variáveis da base de dados originais foram reduzidas a 11, sendo essas as consideradas mais impactantes para a nota de matemática do aluno no ENEM."},{"metadata":{},"cell_type":"markdown","source":"Bibliotecas importadas:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom scipy import stats\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import r2_score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coleta de uma amostra aleatória do dataset: \nFoi necessário coletar uma porcentagem da base de dados pois ela era muito extensa (mais de 5 milhões de linhas). Além disso, essa coleta precisava ser aleatória pois os dados estavam ordenados por estado."},{"metadata":{"trusted":true},"cell_type":"code","source":"# baseado no código elaborado por Davi Reis Vieira de Souza\n\nfonte = '../input/enem-2019/DADOS/MICRODADOS_ENEM_2019.csv' #arquivo\n\nseed = 31123 # define o padrao de aleatoriedade\nnp.random.seed(seed)\n\ntotal_linhas = sum(1 for l in open(fonte,encoding=\"ISO-8859-1\") )#conta quantas linhas tem o data set\nprint(f'Total de Linhas: {total_linhas}')\n\np = 0.025 \ntamanho = int(total_linhas*p)# calcula quanto é 2.5% dos dados \nprint(f'Total de Linhas para Estudo: {tamanho}')\n\nindex = random.sample(range(1, total_linhas), total_linhas - tamanho)# lista de numeros aleatorios\n\ndados = pd.read_csv(fonte,encoding=\"ISO-8859-1\",delimiter=\";\",skiprows=index)# selecions linhas da base de dados com base na lista de numero aleatórios\ndados.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.head(15) # visualizacao da amostra de dados aleatória ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.SG_UF_RESIDENCIA.value_counts() #confirma a presenca de todos os estados ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B. Minerando Dados e Características do Dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"# como a variável target é a nota de matemática, vamos usar somente os dados dos candidatos que estavam presentes nessa prova (1 indica presença)\ndados = dados.loc[dados['TP_PRESENCA_MT']==1]\nprint(len(dados)) # agora a base de dados reduziu um pouco","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#só as colunas das variáveis features que vamos usar\ncolunas = ['SG_UF_RESIDENCIA', 'NU_IDADE', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'IN_TREINEIRO', 'NU_NOTA_MT']\ndados = dados[colunas]\ndados.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#legenda das variaveis features\nvariaveis=np.array([[\"SG_UF_RESIDENCIA\", \"Sigla da Unidade da Federação de residência\"],[\"NU_IDADE\",\"Idade\"], [\"TP_SEXO\", \"Sexo\"], [\"TP_ESTADO_CIVIL\", \"Estado Civil\"], [\"TP_COR_RACA\", \"Cor/raça\"], [\"TP_NACIONALIDADE\", \"Nacionalidade\"], [\"TP_ST_CONCLUSAO\", \"Situação de conclusão do Ensino Médio\"], [\"TP_ANO_CONCLUIU\", \"Ano de Conclusão do Ensino Médio\"], [\"TP_ESCOLA\", \"Tipo de escola do Ensino Médio\"], [\"TP_ENSINO\", \"Tipo de instituição que concluiu ou concluirá o Ensino Médio\"], [\"IN_TREINEIRO\", \"Indica se o inscrito fez a prova com intuito de apenas treinar seus conhecimentos\"]])\n\nvariaveis_df=pd.DataFrame(variaveis, columns=[\"Nome no Data Frame\", \"Descrição\"])\n\nvariaveis_df.index = variaveis_df.index + 1\nvariaveis_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#legenda dos valores das variáveis\nestadocivil=np.array([[0,\"Não informado\"],[1, \"Solteiro(a)\"], [2,\"Casado(a)/Mora com companheiro(a)\"], [3,\"Divorciado(a)/Desquitado(a)/Separado(a)\"], [4, \"Viúvo(a)\"]])\n\nestadocivil_df=pd.DataFrame(estadocivil, columns=[\"Valor\", \"Estado Civil\"])\n\ndisplay(estadocivil_df.style.hide_index())\n\n\n\ncor_raca=np.array([[0,\"Não declarado\"],[1, \"Branca\"], [2,\"Preta\"], [3,\"Parda\"], [4, \"Amarela\"], [5, \"Indígena\"]])\n\ncor_raca_df=pd.DataFrame(cor_raca, columns=[\"Valor\", \"Cor/Raça\"])\n\ndisplay(cor_raca_df.style.hide_index())\n\n\nnacionalidade=np.array([[0,\"Não informado\"],[1, \"Brasileiro(a)\"], [2,\"Brasileiro(a) Naturalizado(a)\"], [3,\"Estrangeiro(a)\"], [4, \"Brasileiro(a) Nato(a), nascido(a) no exterior\"]])\n\nnacionalidade_df=pd.DataFrame(nacionalidade, columns=[\"Valor\", \"Nacionalidade\"])\n\ndisplay(nacionalidade_df.style.hide_index())\n\n\n\nstconclusao=np.array([[1,\"Já concluí o Ensino Médio\"],[2, \"Estou cursando e concluirei o Ensino Médio em 2019\"], [3,\"Estou cursando e concluirei o Ensino Médio após 2019\"], [4,\"Não concluí e não estou cursando o Ensino Médio\"]])\n\nstconclusao_df=pd.DataFrame(stconclusao, columns=[\"Valor\", \"Situação de Conclusão do Ensino Médio\"])\n\ndisplay(stconclusao_df.style.hide_index())\n\n\n\nanoconclusao=np.array([[0,\"Não informado\"],[1, \"2018\"], [2,\"2017\"], [3,\"2016\"], [4, \"2015\"], [5, \"2014\"],[6, \"2013\"],[7, \"2012\"],[8, \"2011\"],[9, \"2010\"],[10, \"2009\"],[11, \"2008\"],[12, \"2007\"],[13, \"Antes de 2007\"]])\n\nanoconclusao_df=pd.DataFrame(anoconclusao, columns=[\"Valor\", \"Ano de Conclusão do Ensino Médio\"])\n\ndisplay(anoconclusao_df.style.hide_index())\n\n        \ntipoescola=np.array([[1, \"Não Respondeu\"], [2,\"Pública\"], [3,\"Privada\"]])\n\ntipoescola_df=pd.DataFrame(tipoescola, columns=[\"Valor\", \"Tipo de Escola\"])\n\ndisplay(tipoescola_df.style.hide_index())\n\n        \ntipoensino=np.array([[1, \"Ensino Regular\"], [2,\"Educação Especial - Modalidade Substitutiva\"]])\n\ntipoensino_df=pd.DataFrame(tipoensino, columns=[\"Valor\", \"Tipo de Ensino\"])\n\ndisplay(tipoensino_df.style.hide_index())\n\n\ntreineiro=np.array([[0, \"Não\"], [1,\"Sim\"]])\n\ntreineiro_df=pd.DataFrame(treineiro, columns=[\"Valor\", \"Se é treineiro\"])\n\ndisplay(treineiro_df.style.hide_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análise exploratória: cruzando cada variável feature com a variável target (Nota de matemática)"},{"metadata":{},"cell_type":"markdown","source":"Observação: Cada vez que o código é rodado, uma nova amostra aleatória de dados é gerada, portanto a análise a seguir pode ter pequenas impertinências dependendo da amostra gerada."},{"metadata":{"trusted":true},"cell_type":"code","source":"#1) Sigla da Unidade da Federação de residência\ndados.groupby(\"SG_UF_RESIDENCIA\").NU_NOTA_MT.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n1. O número de candidatos por estado varia bastante, o que pode estar relacionado com o número de habitantes daquele estado, seu nível de desenvolvimento ou a amostra coletada.\n2.  É possível prever que a média dos estados que tem 0 como valor mínimo será prejudicada em relação aos estados que tem por volta de 360 como mínimo. Os valores 0 indicam que alguma prova foi anulada (por cola por exemplo), pois pelo modelo TRI, é impossível tirar 0, mesmo deixando todas as questoes em branco ou errando todas.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#2)Idade\nfaixasdeidade=pd.cut(dados.NU_IDADE, bins=range(0,100,10))\ndados[\"faixas_de_idade\"] = faixasdeidade\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados.groupby(\"faixas_de_idade\").NU_NOTA_MT.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n1. É estranho o fato de existirem algumas pessoas com idades entre 0 e 10 anos.\n2. Como esperado, a maior parte da amostra tem de 10 a 20 anos, pois nessa faixa etária acontece a conclusão do ensino médio e, para uma parte da população, a entrada na faculdade. E também como esperado essa faixa etária tem a maior média de nota na prova de matemática, já que normalmente o contato com os conteúdos da prova foi mais recente do que para outras faixas etárias.\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"#3)Sexo\ndados.groupby(\"TP_SEXO\").NU_NOTA_MT.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n\n1. Existem mais mulheres do que homens prestando a prova.\n2. A média das notas das mulheres é menor que a dos homens."},{"metadata":{"trusted":true},"cell_type":"code","source":"dados_m = dados.loc[dados['TP_SEXO']=='M']\ndados_f = dados.loc[dados['TP_SEXO']=='F']\n\nplt.figure(figsize=(17,5))\n\nplt.subplot(131)\nplt.hist(dados.NU_NOTA_MT, density = True)\nplt.title('Notas de matematica')\nplt.ylabel('densidade')\nplt.xlabel(\"nota\")\n\nplt.subplot(132)\nplt.hist(dados_m.NU_NOTA_MT, density = True)\nplt.title('Notas de matematica dos homens')\nplt.ylabel('densidade')\nplt.xlabel(\"nota\")\n\nplt.subplot(133)\nplt.hist(dados_f.NU_NOTA_MT, density = True)\nplt.title('Notas de matematica das mulheres')\nplt.ylabel('densidade')\nplt.xlabel(\"nota\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#4) Estado Civil\ndisplay(estadocivil_df.style.hide_index())#note a legenda\ndados.groupby(\"TP_ESTADO_CIVIL\").NU_NOTA_MT.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões\n\n1. A grande maioria dos candidatos é solteiro(a),o que faz sentindo, pois são jovens que estão concluindo o ensino médio.\n2. É curioso o fato de que as pessoas que são Divorciadas ou Viúvas (3 e 4) tem a nota mínima de 360, ou seja ninguém desses grupos cometeu alguma infração na prova e teve a prova zerada."},{"metadata":{"trusted":true},"cell_type":"code","source":"#5) Cor/Raça\n\ndisplay(cor_raca_df.style.hide_index())\n\ndados.groupby(\"TP_COR_RACA\").NU_NOTA_MT.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n\n1.  A maior parte dos prestadores da prova são pardos, em torno de 42mil pessoas, sendo a segunda maior parcela de pessoas brancas. Apenas 11mil pessoas pretas fizeram a prova, ou seja, aproximadamente 12% do total\n2. A  maior média de notas na prova de matemática é do grupo de pessoas brancas, o que comprova a estrutura racista brasileira em que a população branco tem maior acesso à um estudo de qualidade."},{"metadata":{"trusted":true},"cell_type":"code","source":"#6) Nacionalidade\ndisplay(nacionalidade_df.style.hide_index())\n\ndados.groupby(\"TP_NACIONALIDADE\").NU_NOTA_MT.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n\n1. A maior parte dos prestadores da prova são brasileiros, e este grupo também é o único com integrantes que cometeram infrações e tiveram a prova zerada.\n2. É curioso o fato de que os Brasileiros natos nascidos no exterior (pessoas que são filhos de brasileiros porém nasceram no exterior) tem a maior média das notas das provas de matemática."},{"metadata":{"trusted":true},"cell_type":"code","source":"#8) Situação de conclusão de ensino médio\ndisplay(stconclusao_df.style.hide_index())\n\ndados.groupby(\"TP_ST_CONCLUSAO\").NU_NOTA_MT.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n\n1. Como o esperado, a menor média de notas pertence a pessoas que abandonaram o ensino no meio de suas vidas escolares, pois não foram expostas a todos os conteúdos. \n2. A maior parte dos prestadores da prova já conluiram o ensino médio."},{"metadata":{"trusted":true},"cell_type":"code","source":"#9) Ano de conclusao do ensino médio\ndisplay(anoconclusao_df.style.hide_index())\n\ndados.groupby(\"TP_ANO_CONCLUIU\").NU_NOTA_MT.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n1. É curioso o fato de que a maior parte dos candidatos tem o seu ano de conclusão do Ensino Médio não informado\n2. As médias por ano de conclusão do Ensino Médio estão bem próximas uma da outra."},{"metadata":{"trusted":true},"cell_type":"code","source":"#10) Tipo de escola no ensino médio\ndisplay(tipoescola_df.style.hide_index())\n\ndados.groupby(\"TP_ESCOLA\").NU_NOTA_MT.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n1. A maior parte dos candidatos não respondeu de qual tipo de escola eles fazem parte.\n2. A média dos alunos de escolas privadas é consideravelmente maior, o que é um indicativo de qualidade comparativo entre escolas públicas e privadas no Brasil."},{"metadata":{"trusted":true},"cell_type":"code","source":"publica = dados.loc[dados['TP_ESCOLA']==2]\nprivada = dados.loc[dados['TP_ESCOLA']==3]\n\nplt.figure(figsize=(17,5))\n\n\nplt.subplot(132)\nplt.hist(publica.NU_NOTA_MT,bins=range(0,1000, 50), density = True)\nplt.title('Notas das pessoas de escola pública')\nplt.ylabel('densidade')\nplt.xlabel(\"nota\")\n\nplt.subplot(133)\nplt.hist(privada.NU_NOTA_MT, bins=range(0,1000, 50),density = True)\nplt.title('Notas das pessoas de escola privada')\nplt.ylabel('densidade')\nplt.xlabel(\"nota\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#11) Tipo de ensino no ensino médio\ndisplay(tipoensino_df.style.hide_index())\n\ndados.groupby(\"TP_ENSINO\").NU_NOTA_MT.describe()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n\n1. A maior  parte dos alunos são do Ensino Regular. E a média desses alunos é maior do que os alunos de educação especial."},{"metadata":{"trusted":true},"cell_type":"code","source":"#12) Se é ou não treinero\ndisplay(treineiro_df.style.hide_index())\n\ndados.groupby(\"IN_TREINEIRO\").NU_NOTA_MT.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusões:\n\n1. A maior parte dos alunos que prestam a prova não são treineiros. \n2. Os treineiros possume maior média, talvez por estarem menos nervosos na prova"},{"metadata":{"trusted":true},"cell_type":"code","source":"treineiro_sim = dados.loc[dados['IN_TREINEIRO']==1]\ntreineiro_nao = dados.loc[dados['IN_TREINEIRO']==0]\n\nplt.figure(figsize=(17,5))\n\n\nplt.subplot(132)\nplt.hist(treineiro_sim.NU_NOTA_MT, density = True)\nplt.title('Notas dos treineiros')\nplt.ylabel('densidade')\nplt.xlabel(\"nota\")\n\nplt.subplot(133)\nplt.hist(treineiro_nao.NU_NOTA_MT, density = True)\nplt.title('Notas dos não treineiros')\nplt.ylabel('densidade')\nplt.xlabel(\"nota\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **Storytelling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(dados, height=1.5);#fazendo o cruzamento de todas as variáveis entre si","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De maneira geral, os gráficos são bem dispersos, indicando que existe fraca covariância entre as variáveis. O mesmo se nota na última coluna, que mostra o cruzamento de cada variável com a variável target. No canto inferior direito, há um histograma das notas de Matemática, que pode ser melhor visualizado a seguir."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.hist(dados.NU_NOTA_MT, bins=50,density = True);\nplt.title(\"Histograma das notas de Matemática\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aqui, pode-se perceber como as notas começam a partir de 300-350 aproximadamente, reforçando que esse é foi valor mínimo pelo modelo TRI. Os zeros presentes são provenientes de provas anuladas. Nota-se também que a maior densidade está nos valores próximos a 500 e que partir do pico, existe um decaimento da densidade num formato de cauda parecido com uma normal."},{"metadata":{},"cell_type":"markdown","source":" # C. Modelos de Predição e Estatísticas de Validação "},{"metadata":{"trusted":true},"cell_type":"code","source":"#tratando os dados para o uso das tecnicas de predicao.Todos valores devem ser numéricos para a aplicação dessas técnicas\nk=0\ndados['Masculino'] = 0\ndados['Feminino'] = 0\nfor i in dados['TP_SEXO']:\n    if i == 'M':\n        dados.iloc[k,13] = 1\n    else:\n        dados.iloc[k,14] = 1\n    k += 1\ndados = dados.drop(columns=['TP_SEXO'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados\n# observar ultimas colunas: Agora as strings M e F foram transformadas em valores de 1 e 0 (verdadeiro e falso)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fazendo o mesmo com a variável estado\nEstados = {'AC':0,'AL':1,'AM':2,'AP':3,'BA':4,'CE':5,'DF':6,'ES':7,'GO':8,'MA':9,'MT':10,'MS':11,'MG':12,'PA':13,'PB':14,'PR':15,'PE':16,'PI':17,'RR':18,'RO':19,'RJ':20,'RN':21,'RS':22,'SC':23,'SP':24,'SE':25,'TO':26}\nfor i in Estados:\n    dados[i]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 0\nfor i in dados['SG_UF_RESIDENCIA']:\n    for j,k in Estados.items():\n        if i == j:\n            dados.iloc[t,14+k]=1\n            t+=1\ndados = dados.drop(columns=['SG_UF_RESIDENCIA'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados = dados.dropna()#tirando NaNs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dados","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(len(dados)*0.8)#define treinamento como 80% dos dados\nFeatures = dados[['NU_IDADE', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO', 'IN_TREINEIRO','Masculino','Feminino','AC','AL','AM','AP','BA','CE','DF','ES','GO','MA','MT','MS','MG','PA','PB','PR','PE','PI','RR','RO','RJ','RN','RS','SC','SP','SE','TO']]\nTarget = dados['NU_NOTA_MT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train, X_test, y_test = Features[:train_size], Target[:train_size], Features[train_size:], Target[train_size:]#cria subdatasets de treinamento e teste para features e target\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modelo de Predição 1: A técnica de Regressão Linear tem como objetivo determinar os coeficientes da função polinomial que recebe as features (informações do candidato) como input e calcula o target (nota de matematica) no output. Para a validação desse modelo, precisamos validar suas suposições, como a de que os erros seguem uma distribuição normal. Para isso, são utilizados 2 métodos, sendo estes, teste Omnibus e teste Jarque-Bera. Também é feito o teste \"t\": valor P, no qual as features não relevantes são descartadas. Para esse teste, o alpha definido foi de 5%. Por fim, para analisar o desempenho da regressão podemos utilizar o valor R-squared eum gráfico que relaciona os dados de teste com os dados preditos. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def regress(X,Y):\n    X_cp = sm.add_constant(X)\n    model = sm.OLS(Y,X_cp)\n    results = model.fit()\n    return results\n\nresults = regress(X_train, y_train)\nresults.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Atenção: como a amostra de dados gerada é aleatória, os valores-p mudam para cada amostra. Assim, a análise a seguir foi feita com base numa amostra específica gerada****\n\nTeste valor P : Com base no teste do valores p (observados na coluna P>|t|), em que se deve verificar se o valor-p é menor que alpha(5%), retira-se as variáveis TP_ESTADO_CIVIL, TP_ENSINO, IN_TREINEIRO, Sexo e todos os estados. Assim, resta somente as variáveis que aparentam causar maior impacto na anota de Matemática."},{"metadata":{"trusted":true},"cell_type":"code","source":"Features = dados[['NU_IDADE', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = regress(X_train, y_train)\nresults.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora, pode-se realizar os testes Omnibus e Jarque-Bera. Ambos os testes consistem em analisar se a Prob(Omnibus) ou a Jarque-Bera (JB) são maiores que alpha(5%). Como esse não é o caso, podemos concluir que os resíduos não seguem uma distribuição normal, quebrando uma das suposições do modelo de regressão linear. "},{"metadata":{},"cell_type":"markdown","source":"Mesmo com essa suposição quebrada, uma maneira de compreender o desempenho do modelo é com R-squared. Na tabela com o resumo dos resultados, temos que esse parâmetro é 0.209, o que significa uma baiza adequação ao cenário estudado, visto que varia de 0 a 1, sendo 1 o desejado.\n\nFinalmente, como uma das suposições do modelo não é verdadeira e R-squares deixa a desejar, o modelo não pode ser considerado válido, ou seja, não podemos usar o polinômio com coeficientes encontrados para prever a nota de matemática. O modelo linear não é ideal para esse contexto. Uma possível solução seria o uso de um modelo de regressão mais adequado e robusto. "},{"metadata":{},"cell_type":"markdown","source":"Modelo de Predição 2:\nA técnica Random Forest Regression é ideal para casos de datasets com muitas features, pois o modelo consiste na criação de \"Árvores\" que separam, para cada variável, os dados em subgrupos (galhos). Inicialmente, o método escolhe, a partir de uma amostra aleatória, a feature que gera maior impacto na nota de matematica (target), ou seja, a mudança dessa feature influencia diretamente no valor da nota. Essa feature será o fator para a criação de subgrupos. Estes subgrupos passarão pelo mesmo processo de separação, agora com a próxima feature mais relevante, até que todas as features tenham sido aplicadas na árvore. Esse processo é repetido até que se use todos os dados de treinamento, formando algumas árvores. Assim, os dados de teste de uma pessoa são designados a todas as árvores para prever sua nota de matemática. A nota prevista será a média de todos os valores gerado pelas árvores.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"regr = RandomForestRegressor(max_depth=40, random_state=42) #define hiperparametros\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr.fit(X_train, y_train) # treina o modelo\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = regr.predict(X_test)# testa o modelo\nprint(y_predict)# notas previstas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, y_predict)\nplt.title(\"Y teste vs Y predito\")\nplt.ylabel(\"Y predito\")\nplt.xlabel(\"Y teste\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Num cenário ideal, esse gráfico deveria formar uma linha crescente, ou seja, os valores do teste(em x) seriam os mesmos do predito(em y). É possível perceber que o gráfico acima está bem longe desse formato ideal, mas mesmo assim, demonstra algum comportamento nesse sentido. "},{"metadata":{"trusted":true},"cell_type":"code","source":"regr.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O valor acima é o R-squared do modelo Random Forest. Novamente, entende-se que está bem distante do ideal, que seria 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nplt.subplot(121)\nplt.hist(y_predict, bins=range(0,1000,50),density = True);\n\nplt.title(\"Histograma das notas previstas de Matemática\")\nplt.ylabel(\"densidade\")\n\n\nplt.subplot(122)\n\nplt.hist(y_test, bins=range(0,1000,50),density = True);\n\nplt.title(\"Histograma das notas reais de Matemática\")\nplt.ylabel(\"densidade\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apesar de não ser uma boa estratégia para avaliar teoricamente as predições do modelo,a visualização do histograma ofere uma perspectiva mais tangível."},{"metadata":{},"cell_type":"markdown","source":"# E. Conclusão "},{"metadata":{},"cell_type":"markdown","source":"Conclusao:\n    Ambos os modelos se mostraram incapazes de prever a nota de Matemática do Enem de 2019. O primeiro, a Regressão Linear, é um modelo bem simples e já era esperado que não fosse gerar bons resultados, visto que busca encontrar uma única funcão capaz de representar os resultados, que variam de acordo com 11 variáveis diferentes. Já com segundo modelo, o Random Forest Regression, esperava-se melhores resultados, pois funciona de maneira mais complexa e aleatória, gerando múltiplos resultados para cada candidato e depois avaliando-os. Mesmo assim, não obtivemos sucesso, já que os dados previstos variaram significativamente em relação aos testados. Uma possível saída poderia ter sido escolher outras variáveis como features, como por exemplo a notas nas outras provas. É importante destacar que a escolha das features foi feita com base nas nossa suposições do grau de relação entre certa condição social e o desempenho do aluno, e isso pode ser sido um equívoco inicial."},{"metadata":{},"cell_type":"markdown","source":"# F. Referências Bibliográficas "},{"metadata":{},"cell_type":"markdown","source":"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\nhttps://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_predict.html#sphx-glr-auto-examples-model-selection-plot-cv-predict-py\nhttps://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html\nhttps://towardsdatascience.com/a-quick-and-dirty-guide-to-random-forest-regression-52ca0af157f8#:~:text=Random%20forest%20is%20a%20type,prediction%20of%20the%20individual%20trees.\nhttps://medium.com/swlh/random-forest-and-its-implementation-71824ced454f\nhttps://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem\n\n"},{"metadata":{},"cell_type":"markdown","source":"Trabalho em grupo:\nTrabalhando no kaggle, tivemos problemas em gerar commits de pessoas diferentes e optamos por trabalhar em uma conta só. Assim, elaboramos uma pequena apresentação das subdivisões de trabalho. \n\nAna:\n*  Implementou o código que permite coletar uma amostra aleatória da base de dados com a ajuda do Davi Reis. \n* Gerou os gráficos/tabelas do cruzamento de cada feature com a target.\n* Legenda das variaveis e dos valores das variaveis.\n* Storytelling\n* Analise critica\n\n\nLuana:\n* Comentou as tabelas cruzadas, explorando a relação que cada feature poderia ter com a variável target. \n* Escreveu a introdução.\n* Referencias bibliograficas\n* Titulos e legendas dos graficos\n\nPietro: \n* Implementou o modelo random forest\n* Implementou o modelo de regressao linear\n* Texto de descricao dos dois modelos\n* Preparou o dataframe para os modelos de predicao\n* Analise critica \n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}