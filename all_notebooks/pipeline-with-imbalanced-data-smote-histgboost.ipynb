{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Churn Prediction üèÉ‚Äçüí®"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/churn-modeling-dataset/Churn_Modelling.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<blockquote><p style=\"font-size:16px; color:#159364; font-family:verdana;\">üí¨ We don't need of the <b>RowNumber, CustomerId, Surname </b> columns, <code> so just drop üóë</code></p></blockquote>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1, inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<blockquote><p style=\"font-size:16px; color:#159364; font-family:verdana;\">üí¨The data is balanced?</p></blockquote>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Exited'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em;\">\n    üìå &nbsp; Only 20% of the Exited labels are of the type 1 in the whole dataset, so we need  to apply some data balancing technique. In this notebook we will use the SMOTE technique.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### Show data by geografy"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nax = sns.countplot(x=\"Geography\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split the data in train and validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Exited', axis=1)\ny = df['Exited']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em;\">\n    üìå &nbsp; Note that we have an imbalanced dataset, so \"it is desirable to split the dataset into train and test sets in a way that preserves the same proportions of examples in each class as observed in the original dataset\". We can do this using the <code> stratify </code> parameter.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[**Reference**](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Divide data into training and validation subsets\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<blockquote><p style=\"font-size:16px; color:#159364; font-family:verdana;\">üí¨ Select Numerical and Categorical columns</p></blockquote>"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = ['Geography', 'Gender']\n\n# Select numerical columns\nnumerical_cols = ['CreditScore',\n                  'Age',\n                  'Tenure',\n                  'Balance',\n                  'NumOfProducts',\n                  'HasCrCard',\n                  'IsActiveMember',\n                  'EstimatedSalary']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using ColumnTransformer"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_cols),\n        ('cat', OneHotEncoder(), categorical_cols)\n    ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmt = SMOTE(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define the HistGradientBoostingClassifier model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nmodel = HistGradientBoostingClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create the Pipeline"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em;\">\n    üìå &nbsp; The pipeline have the following steps: <b> Preprocessing, SMOTE, Model</b> .\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('smote', smt),\n                            ('model', model)\n                          ])\n\n# Preprocessing of training data, fit model \npipeline.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[**Reference**](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.pipeline.Pipeline.html)"},{"metadata":{},"cell_type":"markdown","source":"### Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pipeline.predict(x_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_valid, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New data"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data = pd.DataFrame({'CreditScore': 500, 'Geography': 'Spain', 'Gender': 'Female', 'Age': 30,\n                  'Tenure': 1, 'Balance': 0., 'NumOfProducts': 2, 'HasCrCard': 0, 'IsActiveMember': 1, \n                  'EstimatedSalary': 10258.2}, index=[0])\nnew_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.predict(new_data)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}