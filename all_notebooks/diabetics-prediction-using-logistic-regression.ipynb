{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets, linear_model\nfrom mpl_toolkits.mplot3d import axes3d\nimport seaborn as sns\nimport plotly.plotly as py\nfrom sklearn.preprocessing import scale\nimport sklearn.linear_model as skl_lm\nfrom sklearn.metrics import mean_squared_error, r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''#For LR\nimport statsmodels.api as sm\n#For LR That looks like R\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.mosaicplot import mosaic\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import os\n#print(os.getcwd())\n#os.chdir('D:\\\\DS_Notes\\\\Datasets_new\\\\')\n# Importing the dataset\ndata = pd.read_csv('../input/diabetes2.csv')\n# displaying the data set\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that there are no null values. Hence the data is clean."},{"metadata":{"trusted":true},"cell_type":"code","source":"#get_ipython().magic('matplotlib inline')\nsns.boxplot(data.Outcome,data.Glucose)\n#sns.boxplot(data.Outcome,data.BloodPressure)\n#sns.boxplot(data.Outcome,data.SkinThickness)\n#sns.boxplot(data.Outcome,data.Insulin)\n#sns.boxplot(data.Outcome,data.BMI)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_n=data[['Glucose','Age','DiabetesPedigreeFunction','BMI','Insulin','SkinThickness','BloodPressure']]\nsns.pairplot(data_n , height=4, kind=\"reg\",markers=\".\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By default, this function will create a grid of Axes such that each variable in data will by shared in the y-axis across a single row and in the x-axis across a single column. The diagonal Axes are treated differently, drawing a plot to show the univariate distribution of the data for the variable in that column.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data.corr()\nprint(corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"corr() is used to find the pairwise correlation of all columns in the dataframe. Any na values are automatically excluded. For any non-numeric data type columns in the dataframe it is ignored."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr,cmap=cmap, vmax=.3,square=True,linewidths=6, cbar_kws={\"shrink\": .5})\ncolormap = plt.cm.viridis\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(data.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white',\nannot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"truediabetes= data.loc[data['Outcome']==1]\ntruediabetes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"falsediabetes= data.loc[data['Outcome']==0]\nfalsediabetes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(truediabetes)\nlen(falsediabetes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nsb.pairplot(data.dropna(), hue='Outcome', palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['Outcome'] == 0, 'Glucose'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['Outcome']==1, 'Glucose'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nfor column_index, column in enumerate(falsediabetes.columns):\n    if column == 'Outcome':\n        continue\nplt.subplot(4, 4, column_index + 1)\nsb.violinplot(x='Outcome', y=column, data=falsediabetes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nfor column_index, column in enumerate(truediabetes.columns):\n    if column == 'Outcome':\n        continue\nplt.subplot(4, 4, column_index + 1)\nsb.violinplot(x='Outcome', y=column, data=truediabetes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class distribution\nplt.figure(figsize=(10, 10))\nprint(\" class distribution \")\nprint(data.groupby('Outcome').size())\n\n'''print(\" == Univariate Plots: box and whisker plots. determine outliers = \")\ndata.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\nplt.show()\nprint(\" Univariate Plots: histograms. determine if the distribution is normal-like\")\ndata.hist()\nplt.show()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n#import xgboost as xgb\nimport pydot\nfrom IPython.display import Image\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.externals.six import StringIO\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\nfrom sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\npd.set_option('display.notebook_repr_html', False)\nget_ipython().magic('matplotlib inline')\nplt.style.use('seaborn-white')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\narray = data.values\narray\ntype(array)\n\nX = array[:,0:8] # independent variables for train\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = array[:,8] # dependant variable\ny[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size = 0.33\n\nfrom sklearn.model_selection import train_test_split\n#pip install -U scikit-learn\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr = skl_lm.LogisticRegression()\n\nregr.fit(X_train, y_train)\n\npred = regr.predict(X_test)\n\nregr.score(X_test,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_df = pd.DataFrame(confusion_matrix(y_test,pred).T, index=regr.classes_,\ncolumns=regr.classes_)\ncm_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)\nprint(classification_report(y_test, pred))\n\nregr.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score, cohen_kappa_score\nfpr, tpr, _ = roc_curve(y_test, pred)\n# Calculate the AUC\nroc_auc = auc(fpr, tpr)\nprint('ROC AUC: %0.2f' % roc_auc)\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\nregr.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = sklearn.model_selection.train_test_split(data, train_size = 0.7)\nprint(\"For Main Data Set :\",data[\"Outcome\"].count())\nprint(\"For Train Set :\",train[\"Outcome\"].count())\nprint(\"For Test Set :\",test[\"Outcome\"].count())\nx_train=train[['Glucose','Age','DiabetesPedigreeFunction','BMI','Insulin','SkinThickness','BloodPressure','Pregnancies']]\nx_test=test[['Glucose','Age','DiabetesPedigreeFunction','BMI','Insulin','SkinThickness','BloodPressure','Pregnancies']]\ny_train=train[\"Outcome\"]\ny_test=test[\"Outcome\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est = smf.Logit(y_train,x_train).fit()\nest.summary()\n\nregr = skl_lm.LogisticRegression()\nregr.fit(x_train, y_train)\npred = regr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_df = pd.DataFrame(confusion_matrix(y_test, pred).T, index=regr.classes_,\ncolumns=regr.classes_)\ncm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score, cohen_kappa_score\nfpr, tpr, _ = roc_curve(y_test, pred)\n# Calculate the AUC\nroc_auc = auc(fpr, tpr)\nprint('ROC AUC: %0.2f' % roc_auc)\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr.score(x_test,y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}