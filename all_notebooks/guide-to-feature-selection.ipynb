{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import chi2, SelectKBest\nimport xgboost\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/company-bankruptcy-prediction/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,25))\nsns.heatmap(df.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There are so many features that correlations matrix doesn't make much sense here."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Bankrupt?'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Bankrupt?',axis=1)\ny = df['Bankrupt?']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model AUC with all the features included(base)\n## We are using XGBOOST, as it has overall good performance in this type of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgboost.XGBRegressor()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\nsklearn.metrics.roc_auc_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using different transformers to see which one give the highest AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler = sklearn.preprocessing.StandardScaler()\nrobust_scaler = sklearn.preprocessing.RobustScaler()\nminmax_scaler = sklearn.preprocessing.MinMaxScaler()\nnormalizer_scaler = sklearn.preprocessing.Normalizer()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.Feature selection using sklearn's SelectKBest"},{"metadata":{"trusted":true},"cell_type":"code","source":"bestfeatures = SelectKBest(score_func=chi2, k=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit = bestfeatures.fit(X,y)\ndfscore = pd.DataFrame(fit.scores_)\ndfcolumn = pd.DataFrame(X.columns)\nfeatureScore = pd.concat([dfcolumn,dfscore],axis=1)\nfeatureScore.columns = ['Features','Score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScore.sort_values('Score',ascending=False,inplace=True)\nfeatureScore.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Selecting one features from features with similar Score"},{"metadata":{},"cell_type":"markdown","source":"### 1.1.1 Using every 3rd column"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_feature = []\nfor i in range (0, len(featureScore.Features.to_list()),3):\n    new_feature.append(featureScore.Features.to_list()[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1, X_test1, y_train1, y_test1 = train_test_split(df[new_feature], y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler.fit(X_train1)\nX_train1 = standard_scaler.transform(X_train1)\nstandard_scaler.fit(X_test1)\nX_test1 = standard_scaler.transform(X_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgboost.XGBRegressor()\nmodel.fit(X_train1, y_train1)\npred1 = model.predict(X_test1)\nsklearn.metrics.roc_auc_score(y_test1, pred1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1.2 Using every 2nd columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_feature1 = []\nfor i in range (0, len(featureScore.Features.to_list()),2):\n    new_feature1.append(featureScore.Features.to_list()[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[new_feature1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2, X_test2, y_train2, y_test2 = train_test_split(df[new_feature1], y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler.fit(X_train2)\nX_train2 = standard_scaler.transform(X_train2)\nstandard_scaler.fit(X_test2)\nX_test2 = standard_scaler.transform(X_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgboost.XGBRegressor()\nmodel.fit(X_train2, y_train2)\npred2 = model.predict(X_test2)\nsklearn.metrics.roc_auc_score(y_test2, pred2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1.3 Using every 4th columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_feature2 = []\nfor i in range (0, len(featureScore.Features.to_list()),4):\n    new_feature2.append(featureScore.Features.to_list()[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[new_feature2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train3, X_test3, y_train3, y_test3 = train_test_split(df[new_feature2], y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler.fit(X_train3)\nX_train3 = standard_scaler.transform(X_train3)\nstandard_scaler.fit(X_test3)\nX_test3 = standard_scaler.transform(X_test3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgboost.XGBRegressor()\nmodel.fit(X_train3, y_train3)\npred3 = model.predict(X_test3)\nsklearn.metrics.roc_auc_score(y_test3, pred3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1.4 Using random top features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(50,80):\n    top_features = featureScore.Features.to_list()[:i]\n    X_trains, X_tests, y_trains, y_tests = train_test_split(df[top_features], y, test_size=0.3, random_state=42)\n    standard_scaler.fit(X_trains)\n    X_trains = standard_scaler.transform(X_trains)\n    standard_scaler.fit(X_tests)\n    X_tests = standard_scaler.transform(X_tests)\n    model.fit(X_trains, y_trains)\n    preds = model.predict(X_tests)\n    results = sklearn.metrics.roc_auc_score(y_tests, preds)\n    print(i, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_76_features = featureScore.Features.to_list()[:76]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train4, X_test4, y_train4, y_test4 = train_test_split(df[top_76_features], y, test_size=0.3, random_state=42)\n\nstandard_scaler.fit(X_train4)\nX_train4 = standard_scaler.transform(X_train4)\nstandard_scaler.fit(X_test4)\nX_test4 = standard_scaler.transform(X_test4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train4, y_train4)\npred4 = model.predict(X_test4)\nsklearn.metrics.roc_auc_score(y_test4, pred4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **So using every 2nd column gives us the best AUC score**\n===================================================================================================================================="},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection Using Information Gain"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mutual_info =  mutual_info_classif(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info = mutual_info.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_33_features = mutual_info.index[:33].to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train5, X_test5, y_train5, y_test5 = train_test_split(df[top_33_features], y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standard_scaler.fit(X_train5)\nX_train5 = standard_scaler.transform(X_train5)\nstandard_scaler.fit(X_test5)\nX_test5 = standard_scaler.transform(X_test5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train5, y_train5)\npred5 = model.predict(X_test5)\nsklearn.metrics.roc_auc_score(y_test5, pred5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  **Conclusion**\n\n\n### Machine learning algorithm doesn't understand what feature means and what they effect in decision making, what it understand is numbers and the patterns within it. So, after trying different combinations and few selection techniqies, the highest Area Under Curve accuracy in acheived was 92.86% with the Sklearn's SelectKBest's top 76 features according to their features score in Chi square Test. All features are given below."},{"metadata":{"trusted":true},"cell_type":"code","source":"top_76_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}