{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport shutil\nfrom sklearn.datasets import load_files\n\n#Import required packages\n# import numpy as np\nimport cv2\nimport random\n# import os\nimport sys\n# import shutil\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nimport configparser\nimport secrets\n\nfrom keras.utils import np_utils\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n\nfrom keras.preprocessing import image                  \nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import ImageFile               ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\n\n* As the dataset size is very less we need to augment the data ","metadata":{}},{"cell_type":"code","source":"DATA_AUG = os.path.join(os.getcwd(),\"prepare_augmented_data\")\n\nif not os.path.exists(DATA_AUG):\n    os.makedirs(DATA_AUG)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(\"../input/identify-the-dance-form/train.csv\")\ndata_test = pd.read_csv(\"../input/identify-the-dance-form/test.csv\")\n\ndata_train['Image'] = data_train['Image'].apply(lambda x:os.path.join(\"../input/identify-the-dance-form/\",\"train\",x))\ndata_test['Image'] = data_test['Image'].apply(lambda x:os.path.join(\"../input/identify-the-dance-form/\",\"test\",x))\n\nprint(\"The number of training images is \",data_train.shape[0])\nprint(\"The number of testing images is \",data_test.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['target'].value_counts().index\n\ndance_dist = list()\nfor idx,num_files in enumerate(data_train['target'].value_counts()):\n    dance_dist.append({\n        \"DanceName\":data_train['target'].value_counts().index[idx],\n        \"NumFiles\":num_files\n    })\ndance_dist = pd.DataFrame(dance_dist)\n\n\ndance_dist.head(10) # shows the classwise distribution of data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# putting images belonging to different classes into different folders with corresponding classname\n# Preparing dataset for augmentation\nfor i in range(data_train.shape[0]):\n    if not os.path.exists(os.path.join(DATA_AUG,data_train.iloc[i,1])):\n        os.makedirs(os.path.join(DATA_AUG,data_train.iloc[i,1]))\n    shutil.copy(data_train.iloc[i,0],os.path.join(DATA_AUG,data_train.iloc[i,1],data_train.iloc[i,0].split(\"/\")[-1]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the data augmentation definition\n\ngen_per_image = 4\ngen_per_class = 300\n#path to the folder containing the data ready for augmentation\npath = DATA_AUG\nrotation_range = 5\nwidth_shift_range = 0.02\nheight_shift_range = 0.02\nshear_range = 0.01\nzoom_range = 0.05\nhorizontal_flip = False\nfill_mode = \"nearest\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def increase_brightness(img, value):\n    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    h, s, v = cv2.split(hsv)\n\n    lim = 255 - value\n    v[v > lim] = 255\n    v[v <= lim] += value\n\n    final_hsv = cv2.merge((h, s, v))\n    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n    return img\n\ndef change_contrast(img, level):\n    img = Image.fromarray(img.astype('uint8'))\n    factor = (259 * (level + 255)) / (255 * (259 - level))\n    def contrast(c):\n        return 128 + factor * (c - 128)\n    return np.array(img.point(contrast))\n\ndef pad_img(img):\n    h, w = img.shape[:2]\n    new_h = int((5 + secrets.randbelow(16)) * h / 100) + h\n    new_w = int((5 + secrets.randbelow(16)) * w / 100) + w\n\n    full_sheet = np.ones((new_h, new_w, 3)) * 255\n\n    p_X = secrets.randbelow(new_h - img.shape[0])\n    p_Y = secrets.randbelow(new_w - img.shape[1])\n\n    full_sheet[p_X : p_X + img.shape[0], p_Y : p_Y + img.shape[1]] = img\n\n    full_sheet = cv2.resize(full_sheet, (w, h), interpolation = cv2.INTER_AREA)\n\n    return full_sheet.astype(np.uint8)\n\ndef preprocess_img(img):\n    img = np.array(img)\n\n    x = secrets.randbelow(2)\n\n    if x == 0:\n        # img = pad_img(img)\n        img = increase_brightness(img, secrets.randbelow(26))\n        img = change_contrast(img, secrets.randbelow(51))\n    else:\n        # img = pad_img(img)\n        img = change_contrast(img, secrets.randbelow(51))\n        img = increase_brightness(img, secrets.randbelow(26))\n\n    return img\n\ndef copy_org(doc_type):\n    files = os.listdir(os.path.join(path, doc_type))\n\n    for file in files:\n        shutil.copy(os.path.join(path, doc_type, file), os.path.join(os.getcwd(),\"augmented_data\",doc_type, file))\n\n\n#Initialise the parameters for Augmentation.\ndatagen = ImageDataGenerator(\n        rotation_range = rotation_range,\n        width_shift_range = width_shift_range,\n        height_shift_range = height_shift_range,\n        shear_range = shear_range,\n        zoom_range = zoom_range,\n        horizontal_flip = horizontal_flip,\n        fill_mode = fill_mode,\n        preprocessing_function = preprocess_img)\n\ndef generator(doc_type, total):\n    # print(doc_type + \" \" + set_type)\n    print(doc_type)\n    # src_path = os.path.join(path, doc_type, set_type)\n    src_path = os.path.join(path,doc_type)\n    dst_path = os.path.join(os.getcwd(), \"augmented_data\",doc_type)\n    # files = os.listdir(src_path)\n    files = os.listdir(src_path)\n    m = len(files)\n\n    for i in range(total):\n        k = secrets.randbelow(m)\n        img_cv = cv2.resize(cv2.imread(os.path.join(src_path, files[k])), (500, 500), interpolation = cv2.INTER_AREA)\n        cv2.imwrite(\"temp_img.jpg\", img_cv)\n        img = load_img(\"temp_img.jpg\")  # this is a PIL image\n        # img = load_img(os.path.join(src_path, files[k]))  # this is a PIL image\n        imgarr = img_to_array(img)  # this is a Numpy array with shape (?, ?, ?)\n\n        gen_file_name = doc_type + \"_\" + str(i)\n\n        # cv2.imwrite(os.path.join(dst_path, gen_file_name + \".jpg\"), cv2.imread(os.path.join(src_path, files[k])))\n\n        imgarr = imgarr.reshape((1,) + imgarr.shape)  # this is a Numpy array with shape (1, ?, ?, ?)\n\n        n = 1\n        for batch in datagen.flow(imgarr, batch_size=1, save_to_dir=dst_path, save_prefix=gen_file_name, save_format='jpeg'):\n            n += 1\n            if n > gen_per_image:\n                break  # otherwise the generator would loop indefinitely\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Contains all the labels\ndoc_types = os.listdir(path)\n\nfor doc_type in doc_types:\n    if not os.path.exists(os.path.join(os.getcwd(), \"augmented_data\",doc_type)):\n        os.makedirs(os.path.join(os.getcwd(),\"augmented_data\",doc_type))\n    # generator(doc_type, set_types[0], gen_per_class)\n    generator(doc_type,gen_per_class)\n    copy_org(doc_type)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"# creating the new train.csv\nDATA_DIR = os.path.join(os.getcwd(), \"augmented_data\")\ndef create_csv(DATA_DIR,filename):\n    data = list()\n    class_names = os.listdir(DATA_DIR)\n    for class_name in class_names:\n        file_names = os.listdir(os.path.join(DATA_DIR,class_name))\n        for file_name in file_names:\n            data.append({\n                \"FileName\":os.path.join(DATA_DIR,class_name,file_name),\n                \"ClassName\":class_name\n            })\n    data = pd.DataFrame(data)\n    data.to_csv(filename,index=False)\n\ncreate_csv(DATA_DIR,\"train_augmented.csv\")\n\n\ndata = pd.read_csv(os.path.join(os.getcwd(),\"train_augmented.csv\"))\n# data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DIR = os.path.join(\"../input/identify-the-dance-form/\",\"test\")\nTRAIN_DIR = os.path.join(os.getcwd(),\"augmented_data\")\nMODEL_PATH = os.path.join(os.getcwd(),\"model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(TEST_DIR):\n    print(\"Testing data does not exists\")\nif not os.path.exists(TRAIN_DIR):\n    print(\"Training data does not exists\")\nif not os.path.exists(MODEL_PATH):\n    print(\"Model path does not exists\")\n    os.makedirs(MODEL_PATH)\n    print(\"Model path created\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(os.path.join(os.getcwd(),\"train_augmented.csv\"))\ndata_test = pd.read_csv(os.path.join(\"../input/identify-the-dance-form/\",\"test.csv\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The number of training images is \",data_train.shape[0])\nprint(\"The number of testing images is \",data_test.shape[0]) # for submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['FileName'] = data_train['FileName'].apply(lambda x:os.path.join(TRAIN_DIR,\"/\".join(x.split(\"/\")[-2:])))\ndata_test['Image'] = data_test['Image'].apply(lambda x:os.path.join(\"../input/identify-the-dance-form/\",\"test\",x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nf = data_train['ClassName'].value_counts(sort=False)\nlabels = data_train['ClassName'].value_counts(sort=False).index.tolist()\ny = np.array(nf)\nwidth = 1/1.5\nN = len(y)\nx = range(N)\n\nfig = plt.figure(figsize=(20,15))\nay = fig.add_subplot(211)\n\nplt.xticks(x, labels, size=15)\nplt.yticks(size=15)\n\nay.bar(x, y, width, color=\"blue\")\n\nplt.title('Bar Chart',size=25)\nplt.xlabel('ClassName',size=15)\nplt.ylabel('Count',size=15)\n\nplt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. The classes are well separated and equally balanced into 8 classes","metadata":{}},{"cell_type":"code","source":"#preparing the dictionary for labels encoding \n\nlabels_list = list(set(data_train['ClassName'].values.tolist()))\nlabels_id = {label_name:id for id,label_name in enumerate(labels_list)}\nprint(labels_id)\ndata_train['ClassName'].replace(labels_id,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = to_categorical(data_train['ClassName'])\nprint(labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting data into train and test set in 80:20 ratio\n\nxtrain,xtest,ytrain,ytest = train_test_split(data_train.iloc[:,0],labels,test_size = 0.2,random_state=42)\ndef path_to_tensor(img_path):\n    # loads RGB image as PIL.Image.Image type\n    img = image.load_img(img_path, target_size=(64, 64))\n    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"           \nImageFile.LOAD_TRUNCATED_IMAGES = True                 \n\n# pre-process the data for Keras\ntrain_tensors = paths_to_tensor(xtrain).astype('float32')/255 - 0.5\nvalid_tensors = paths_to_tensor(xtest).astype('float32')/255 - 0.5\ntest_tensors = paths_to_tensor(data_test.iloc[:,0]).astype('float32')/255 - 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(64,64,3), kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu', kernel_initializer='glorot_normal'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(8, activation='softmax', kernel_initializer='glorot_normal'))\n\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,to_file=\"model_dance_recognition.png\",show_shapes=True,show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath = os.path.join(MODEL_PATH,\"dance_recognition-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',period=1)\ncallbacks_list = [checkpoint]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"model_history = model.fit(train_tensors,ytrain,validation_data = (valid_tensors, ytest),epochs=10, batch_size=40, shuffle=True,callbacks=callbacks_list)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Analysis\nFinding the Confusion matrix,Precision,Recall and F1 score to analyse the model thus created","metadata":{}},{"cell_type":"code","source":"def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    fig.savefig(os.path.join(MODEL_PATH,\"confusion_matrix.png\"))\n    return fig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_heatmap(n_labels, n_predictions, class_names):\n    labels = n_labels #sess.run(tf.argmax(n_labels, 1))\n    predictions = n_predictions #sess.run(tf.argmax(n_predictions, 1))\n\n#     confusion_matrix = sess.run(tf.contrib.metrics.confusion_matrix(labels, predictions))\n    matrix = confusion_matrix(labels.argmax(axis=1),predictions.argmax(axis=1))\n    row_sum = np.sum(matrix, axis = 1)\n    w, h = matrix.shape\n\n    c_m = np.zeros((w, h))\n\n    for i in range(h):\n        c_m[i] = matrix[i] * 100 / row_sum[i]\n\n    c = c_m.astype(dtype = np.uint8)\n\n    \n    heatmap = print_confusion_matrix(c, class_names, figsize=(18,10), fontsize=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = list()\nfor name,idx in labels_id.items():\n    class_names.append(name)\nprint(class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred = model.predict(valid_tensors,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_heatmap(ytest,ypred,class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Precision Recall F1 Score","metadata":{}},{"cell_type":"code","source":"ypred_class = np.argmax(ypred,axis=1)\n# print(ypred_class[:10])\nytest = np.argmax(ytest,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(ytest,ypred_class)\nprint('Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(ytest, ypred_class,average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(ytest,ypred_class,average='weighted')\nprint('Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(ytest,ypred_class,average='weighted')\nprint('F1 score: %f' % f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = model.predict(test_tensors,verbose=1)\ntest_pred_class = model.predict_classes(test_tensors)\n# print(test_pred_class)\n# print(test_pred_class.shape)\n# print(test_pred_class.shape)\n\nid_labels = dict()\nfor label,idx in labels_id.items():\n    id_labels[idx]=label\n# print(id_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Submission file","metadata":{}},{"cell_type":"code","source":"data_submit = list()\nfor i in range(test_pred_class.shape[0]):\n    data_submit.append({\n        \"Image\":data_test.iloc[i,0].split(\"/\")[-1],\n        \"target\":id_labels[test_pred_class[i]]\n    })\ndata_submit = pd.DataFrame(data_submit)\ndata_submit.to_csv(\"submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}