{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n\n### Minería de Datos: Curso académico 2020-2021\n\n### Integrantes:\n\n* Gonzalo Pinto Perez\n* Yeremi Martin Huaman Torres\n"},{"metadata":{},"cell_type":"markdown","source":"# 1. Preliminares"},{"metadata":{},"cell_type":"markdown","source":"Cargamos las librerias que vamos a utilizar"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\nfrom scipy.stats import shapiro\nfrom sklearn.compose import make_column_transformer\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fijamos la semilla"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Funcion que utilizaremos durante el transcurso de la práctica"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"Función para eliminar los datos anomalos\"\ndef outlier_rejection(X, y):\n    model = IsolationForest(max_samples=100,\n                            contamination=0.4,\n                            random_state=27912)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Cargamos el conjunto de datos de la base de datos `pima-indians-diabetes-database` y `breast-cancer-wisconsin-data` :"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\nfilepathWisconsin = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindexDiabetes = None\ntargetDiabetes = \"Outcome\"\n\nindexWisconsin = \"id\"\ntargetWisconsin = \"diagnosis\"\n\ndataDiabetes = utils.load_data(filepath, indexDiabetes, targetDiabetes)\n\ndataWisconsin = utils.load_data(filepathWisconsin, indexWisconsin, targetWisconsin)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que hemos cargado bien los datos obteniendo una muestra no sesgada"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDiabetes.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataWisconsin.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos que tenemos un dato incorrecto en dataWisconsin : \"Unnamed:32\" por lo tanto lo eliminamos."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataWisconsin = dataWisconsin.drop(dataWisconsin.columns[31], axis = 'columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Volvemos a comprobar "},{"metadata":{"trusted":true},"cell_type":"code","source":"dataWisconsin.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separamos el conjunto de datos en dos subconjuntos, uno con las variables predictoras (X) y otro con la variable objetivo(y)"},{"metadata":{"trusted":true},"cell_type":"code","source":"(XDiabetes, yDiabetes) = utils.divide_dataset(dataDiabetes, target=\"Outcome\")\n\n(XWisconsin, yWisconsin) = utils.divide_dataset(dataWisconsin, target=\"diagnosis\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que los datos se han separado correctamente, primero las variables predictoras"},{"metadata":{"trusted":true},"cell_type":"code","source":"XDiabetes.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XWisconsin.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y ahora la variable clase"},{"metadata":{"trusted":true},"cell_type":"code","source":"yDiabetes.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yWisconsin.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para realizar el proceso de holdout tenemos que dividir el conjunto de datos entre dos subconjuntos, uno que sirva de muestra de entrenamiento (el 70%) y otro que sirva de muestra de prueba (el 30%)."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(XDiabetes_train, XDiabetes_test, yDiabetes_train, yDiabetes_test) = train_test_split(XDiabetes, yDiabetes,\n                                                      stratify=yDiabetes,\n                                                      random_state=seed,\n                                                      train_size=train_size)\n(XWisconsin_train, XWisconsin_test, yWisconsin_train, yWisconsin_test) = train_test_split(XWisconsin, yWisconsin,\n                                                      stratify=yWisconsin,\n                                                      random_state=seed,\n                                                      train_size=train_size)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se han separado correctamente las variables predictoras:"},{"metadata":{"trusted":true},"cell_type":"code","source":"XDiabetes_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XDiabetes_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XWisconsin_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XWisconsin_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se han separado correctamente las variables clase:"},{"metadata":{"trusted":true},"cell_type":"code","source":"yDiabetes_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yDiabetes_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yWisconsin_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yWisconsin_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Analisis exploratorio, preprocesamiento de datos, algoritmos de clasificación y evaluacion de modelos de la base datos pima indians diabetes"},{"metadata":{},"cell_type":"markdown","source":"# 3.1 Análisis exploratorio de datos de la base de datos pima indians diabetes"},{"metadata":{},"cell_type":"markdown","source":"Para facilitar el análisis exploratorio volvemos a juntar las variables predictoras con las variables clases tanto con el conjunto de datos de prueba como el conjunto de datos de entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDiabetes_train = utils.join_dataset(XDiabetes_train, yDiabetes_train)\ndataDiabetes_test = utils.join_dataset(XDiabetes_test, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lo primero que hacemos es ver el numero de casos y variables del problema:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDiabetes_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tras esto podemos observar que este problema tiene excesivo número de casos, lo cual puede suponer un inconveniente para la creación de modelos y su posterior evaluación."},{"metadata":{},"cell_type":"markdown","source":"Obtenemos más información sobre el problema que nos podría ser de utilidad posteriormente como el tipo de las variables:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDiabetes_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Los distintos estados que puede tener de la variable clase:"},{"metadata":{"trusted":true},"cell_type":"code","source":"yDiabetes.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Una vez obtenida esta información y tras haber analizado las posibles anomalias del problema vamos a continuar el análisis exploratorio del problema creando distintas gráficas, analizando los resultados y sacando conclusiones que nos podrá ser útiles en el posterior preprocesamiento de datos."},{"metadata":{},"cell_type":"markdown","source":"Empezamos realizando un histograma de los datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(dataDiabetes_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Este primer gráfico nos muestra datos muy relevantes. Lo primero en lo que nos fijamos es en la distribución que tienen las variables en este gráfico, destacando a simple vista las que parecen que tienen una distribución normal con tendencia central en forma de campana de gaus, las cuales son: Glucose, BloodPresure y BMI. Esto puede suponer en un principio que estas variables serán más fáciles de tratar en el preprocesamiento de datos pero si nos fijamos más de cerca podemos darnos cuenta de que los valores mínimos de estas variables son o 0 o en algunas situaciones valores negativos inferiroes a 0, valores que no tienen sentido para estas variables, por lo tanto en el procesamiento de datos lo primero que tendremos que hacer será reemplazar los ceros de estas variables por valores viables.\nA continuación si nos fiajamos en el resto de la variables(Pregnancies, SkinThickness, Insulin,DiabetesPedigreeFunction y Age), y nos damos cuenta de que todas ellas contienen una distribución con tendencia exponencial decreciente o de otra manera, que sigue una distribución sesgada positivamente, esta distribución es bastante problemática ya que al extenderse con un amplio siesgo y al haber un gran casos (como hemos comentado anteriormente), el conjunto de datos tendrá una cantidad considerable de outliers o datos anómales de los cuales tendremos que eliminar algunos en el preprocesamiento para que los modelos resultantes tenga una precisión mejor. Además si analizamos estas últimas variables podremos descubrir que las variables SkinThickness y Insulin vuelven a tener la misma problemática que hemos comentado con anterioridad, estas variables pueden tener el valor 0 aunque por lógica no lo deberían de aceptar, por lo tanto tendremos que reemplazar los ceros en estas variables al igual que en las mencionadas anteriormente."},{"metadata":{},"cell_type":"markdown","source":"Posteriormente realizamos un diagrama de barras de los datos para comprobar la distribución de la variable objetivo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(dataDiabetes_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Como podemos observar, la variable objetivo está claramente desbalaceda ya que hay casi el doble de casos negativos (0) que el de casos positivos, por lo que para evitar problemas con el estudio del problema lo que tendremos que hacer será balancear de alguna manera el número de casos para que tengamos el mismo número de casos positivos como el negativo."},{"metadata":{},"cell_type":"markdown","source":"A continuación realizamos una matriz de gráficos del tipo nube puntos para comprobar la distribución de los datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(dataDiabetes_train, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tras observar la matriz de gráficos del tipo nube puntos podemos comprobar lo que ibamos observando en los anteriores gráficos, hay un exceso de casos que nos impiden observar correctamente la distribución de la variable objetivo para realizar correctamente una discretización de forma correcta. "},{"metadata":{},"cell_type":"markdown","source":"Para acabar con los gráficos, realizaremos un gráfico de matriz de correlación para comprobar si tenemos que eliminar alguna de las variables predictoras del conjunto de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(dataDiabetes_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observando el gráfico podemos llegar a la conclusión de que ninguna el máximo nivel de correlación que tenemos entre dos variables es el de BMI y SckinThickness, siendo este 0.6, no obstante no lo consideramos lo suficientemente alto como para eliminar una de las dos variables antes durante el preprocesamiento de datos antes de realizar la generación de los modelos."},{"metadata":{},"cell_type":"markdown","source":"A continuación seguimos realizando el análisis exploratorio analizando las variables numericas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDiabetes.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar que hay 768 datos, y lo más posible esque gran parte de esos casos los podramos menospreciar para desarrolar la calificación del modelo resultante"},{"metadata":{},"cell_type":"markdown","source":"Y seguimos analizando las variables categóricas o en este caso la variable objetivo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataDiabetes.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esta salida corrobora las conclusiones que hemos sacado de lo que llevamos de análisis, pues nos indica que hay demasiados casos y que la variable 0 se repite demasiado, ya que su frecuencia es de 500 teniendo en cuenta que hay 750 casos, y de esta manera no estaríamos ante un problema balanceado."},{"metadata":{},"cell_type":"markdown","source":"# 3.2 Preprocesamiento de datos de la base de datos pima indians diabetes"},{"metadata":{},"cell_type":"markdown","source":"Limpieza de datos:"},{"metadata":{},"cell_type":"markdown","source":"Primero eliminamos los ceros de aquellas variables (recordar que dichas variables eran Bloodpresure, BMI, Glucose, Insulin y SkinThickness) donde hemos detectado ceros y que no deberian de tenerlo. Para ello donde haya un cero, sustituiremos el cero por la media que tenga esa variable predictora con respecto a la variable objetivo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = dataDiabetes.loc[dataDiabetes['Outcome'] == 1]\ndf2 = dataDiabetes.loc[dataDiabetes['Outcome'] == 0]\ndf1 = df1.replace({'BloodPressure':0}, np.median(df1['BloodPressure']))\ndf2 = df2.replace({'BloodPressure':0}, np.median(df2['BloodPressure']))\ndataframe = [df1, df2]\ndataDiabetes = pd.concat(dataframe)\n\ndf1 = dataDiabetes.loc[dataDiabetes['Outcome'] == 1]\ndf2 = dataDiabetes.loc[dataDiabetes['Outcome'] == 0]\ndf1 = df1.replace({'BMI':0}, np.median(df1['BMI']))\ndf2 = df2.replace({'BMI':0}, np.median(df2['BMI']))\ndataframe = [df1, df2]\ndataDiabetes = pd.concat(dataframe)\n\ndf1 = dataDiabetes.loc[dataDiabetes['Outcome'] == 1]\ndf2 = dataDiabetes.loc[dataDiabetes['Outcome'] == 0]\ndf1 = df1.replace({'Glucose':0}, np.median(df1['Glucose']))\ndf2 = df2.replace({'Glucose':0}, np.median(df2['Glucose']))\ndataframe = [df1, df2]\ndataDiabetes = pd.concat(dataframe)\n\ndf1 = dataDiabetes.loc[dataDiabetes['Outcome'] == 1]\ndf2 = dataDiabetes.loc[dataDiabetes['Outcome'] == 0]\ndf1 = df1.replace({'Insulin':0}, np.median(df1['Insulin']))\ndf2 = df2.replace({'Insulin':0}, np.median(df2['Insulin']))\ndataframe = [df1, df2]\ndataDiabetes = pd.concat(dataframe)\n\ndf1 = dataDiabetes.loc[dataDiabetes['Outcome'] == 1]\ndf2 = dataDiabetes.loc[dataDiabetes['Outcome'] == 0]\ndf1 = df1.replace({'SkinThickness':0}, np.median(df1['SkinThickness']))\ndf2 = df2.replace({'SkinThickness':0}, np.median(df2['SkinThickness']))\ndataframe = [df1, df2]\ndataDiabetes = pd.concat(dataframe)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Despues utilizamos Synthteic Minority Oversampling Technigque (SMOTE) para eliminar el desbalanceo que existe en los datos de entrenamiento del problema creando muestran usando los datos de entrenamiento actuales."},{"metadata":{"trusted":true},"cell_type":"code","source":"smt = SMOTE()\nXDiabetes_train, yDiabetes_train = smt.fit_sample(XDiabetes_train, yDiabetes_train)\ndataDiabetes_train = utils.join_dataset(XDiabetes_train, yDiabetes_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que hemos corregido el desbalanceo original, realizando de nuevo un de diagramas de barras"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(dataDiabetes_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y al analizarlo podemos concluir que finalmente los datos de entrenamiento del problema se han balanceado."},{"metadata":{},"cell_type":"markdown","source":"A continuación vamos a escalar nuestros datos para tratar con datos anómalos u outliers para hacer que los datos anómalos estén menos sesgados con respecto a los otros. Para ello utilizaremos StandarScaler que \"escala\" la propiedad restando por la media y diviendo por la desviación estándar"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nyDiabetes = dataDiabetes.Outcome\nXDiabetes = dataDiabetes.drop('Outcome', axis = 1)\ncolumns = XDiabetes.columns\nscaler = StandardScaler()\nXDiabetes = scaler.fit_transform(XDiabetes)\ndataDiabetes_x = pd.DataFrame(XDiabetes, columns = columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez escalada, volvemos a dividir el conjunto de datos inicial entre datos de entrenamiento y de test, para generar estos dos subconjuntos pero sin datos anómalos."},{"metadata":{"trusted":true},"cell_type":"code","source":"XDiabetes_train, XDiabetes_test, yDiabetes_train, yDiabetes_test = train_test_split(dataDiabetes_x, yDiabetes,\n                                                                    stratify=yDiabetes, random_state = seed, train_size = train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y a continuación vamos a realizar la discretización. Como en el diagrama de tipos puntos de nube no podemos tener una referencia clara del punto o la forma de realizar la discretización vamosa  realizar la discretización de tres formas diferentes; de igual anchura, de igual profundidad y en k-medias. Obviamente, estas tres discretizaciones del problema y al tener este una variable objetivo de tipo categorico pudiendo tener dos valores (0 o 1), todas las discretizaciones tendrán dos intervalos pues intentamos que en cada interavalo estén agrupados el mayor número de variables de un único tipo posible. Estas discretizaciones son las siguientes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndiscretizer2u = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizer2q = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizer2k = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  3.3 Algoritmos de clasificación de la base de datos pima indians diabetes"},{"metadata":{},"cell_type":"markdown","source":"A continuación vamos a generar los distintos modelos basados en los 2 algoritmos que nos pide inicialmente el enunciado de la práctica."},{"metadata":{},"cell_type":"markdown","source":"*Algoritmo Zero-R:*"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Algoritmo Cart o algoritmo de clasificación y regresión de árboles:*"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y al árbol de regresión le aplicamos las tres discretizaciones que hemos preparado:"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizeUniform_tree_model = make_pipeline(discretizer2u, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizeQuantile_tree_model = make_pipeline(discretizer2q, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizeKmeans_tree_model = make_pipeline(discretizer2k, tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A continuación, si el rescalado de los datos anómalos no ha sido suficiente, vamos a aplicar una pipeline a los algoritmos ya desarrollados que utiliza una función basada en el algoritmo IsolationForest que se encargará de eliminar los posibles datos outliers o anómalos que queden en los datos y en la parte de evaluación nos encargaremos de analizar los resultados obtenidos y comapararnos con la versión de los algoritmos sin dicha pipeline."},{"metadata":{},"cell_type":"markdown","source":"*Algoritmo zero_r_model con eliminación de outlier o datos anómalos con anterioridad*"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_modelPipe = make_pipeline(FunctionSampler(func=outlier_rejection),zero_r_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Algoritmo tree_mode con eliminación de outlier o datos anómalos con anterioridad*"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_modelPipe = make_pipeline(FunctionSampler(func=outlier_rejection),tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Algoritmo tree_mode con discretización y eliminación de outlier o datos anómalos con anterioridad*"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizeUniform_tree_modelPipe = make_pipeline(FunctionSampler(func=outlier_rejection),discretizeUniform_tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizeQuantile_tree_modelPipe= make_pipeline(FunctionSampler(func=outlier_rejection),discretizeQuantile_tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizeKmeans_tree_modelPipe = make_pipeline(FunctionSampler(func=outlier_rejection),discretizeKmeans_tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y finalmente, hemos aprovechado el tipo de problema que supone esta base de datos con datos anómalos y la función que tenemos para implementar pipelines que eliminen con anterioridad los datos anómalos para implementar tres tipos de algoritmos de ajuste de modelos: Regresión logística, Máquina de vector de soporte o SVC y el modelo random forest."},{"metadata":{},"cell_type":"markdown","source":"*Pipeline creado para aplicar el modelo de regresión logística*"},{"metadata":{"trusted":true},"cell_type":"code","source":"LogisticRegresionPipe = make_pipeline(FunctionSampler(func=outlier_rejection),\n                     LogisticRegression(solver='lbfgs', multi_class='auto',\n                                        random_state=27912))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Pipeline creado para aplicar el modelo de la máquina de vector soporte:*"},{"metadata":{"trusted":true},"cell_type":"code","source":"SupportVectorMachinePipe= make_pipeline(FunctionSampler(func=outlier_rejection),\n                     SVC(kernel = 'rbf',random_state=27912))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Pipeline creado para aplicar el modelo de random forest:*"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nRandomForestPipe= make_pipeline(FunctionSampler(func=outlier_rejection),\n                     RandomForestClassifier(n_estimators=300, bootstrap = True, max_features = 'sqrt',random_state=27912))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  3.4 Evaluación de modelos de la base de datos pima indians diabetes"},{"metadata":{},"cell_type":"markdown","source":"Evaluación modelo Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como era de esperar el modelo Zero-R al ser el modelo más tribial da una precisión que de aún sin ser mala del todo, es bastante mejorable aún tras haber realizado todo el preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Evaluación del modelo CART o algoritmo de regresión de árboles"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En este algoritmo notamos finalmente la primera mejora del preprocesamiento de datos teniendo una gran mejora en la precisión del modelo"},{"metadata":{},"cell_type":"markdown","source":"Evalución del modelo CART discretizado de tres maneras distintas"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretizeUniform_tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretizeQuantile_tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretizeKmeans_tree_model,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tras observar la precisión de los modelos y tras realizarle las tres discretizaciones posibles podemos observar que de todas las discretizaciones la que ofrece la mejor precisión es la discretización en frecuencia y esto es debido a que los procesos realizados durante el preprocesamiento de datos han reducido el siesgo de los datos y han convertido este problema en un problema balanceado, intentando \"juntar\" las variables predictoras y objetivos de los casos en las que las categorias de las variable objetivo son iguales."},{"metadata":{},"cell_type":"markdown","source":"*Evaluación de con el pipeline de reducción de datos anómalos aplicado*"},{"metadata":{},"cell_type":"markdown","source":"Evaluación del modelo Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_modelPipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como era de esperar el modelo Zero-R aún aplicando un pipeline que deberia de mejorar su redimiento, es un algoritmo tan trivial que ni consigue mejorar su precisión ni empeorarla, simplemente se queda igual"},{"metadata":{},"cell_type":"markdown","source":"Evaluación del modelo CART o algoritmo de regresión de árboles"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_modelPipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tras aplciarle el pipeline, el algoritmo CART ha obtenido incluso una mejor precisión que la que obtuvo sin aplicarsela debido a que está a eliminado incluso más outliers o datos anómalos de los que ya había en los datos antes de aplicarle el preprocesamiento de datos."},{"metadata":{},"cell_type":"markdown","source":"Evalución del modelo CART discretizado de tres maneras distintas"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretizeUniform_tree_modelPipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretizeQuantile_tree_modelPipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretizeKmeans_tree_modelPipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tras observar los resultados de estas tres discretizaciones junto con la aplicación de la pipeline podemos sacar ciertas conclusiones importantes.La discretización basada en anchura al ser una discretización que se basa en los máximos y los mínimos al emplear la pipeline y eliminar aún más outliers o datos anómalos es la que más ha conseguido mejorar la precisión del modelo obtenido. Mientras tanto, las otras dos variables no se ven afectadas demasiado por la eliminación extra de los outleirs o datos anómalos utilizando la piple, aunque la discretización con mejores resultados sigue siendo la basada en frecuencia,debido a lo argumentado en apartados anteriores, pues en el preprocesamiento de datos se ha intentado eliminar el sesgo entre datos."},{"metadata":{},"cell_type":"markdown","source":"*Algorimtos de ajustes de modelos*"},{"metadata":{},"cell_type":"markdown","source":"Regresión lineal"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(LogisticRegresionPipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Máquina del vector soporte"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(SupportVectorMachinePipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomForest"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(RandomForestPipe,\n               XDiabetes_train, XDiabetes_test,\n               yDiabetes_train, yDiabetes_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finalmente tras ver las precisiones obtenidas por estos tres algoritmos podemos concluir que aunque en el enunciado inicial se nos pidiese únicamente la aplicación de los algoritmos Zero-R y CART, el uso de algoritmos para generar modelos basados en el ajuste de modelos es el más recomendable para estos problemas con outliers o datos anómalos; ya que estos tres algoritmos han obtenido muy buenas preciones en sus modelos superando a la precisión que da el modelo del algoritmo Zero-R, y el último algoritmo, RandomForest, incluso ha conseguido obtener una precisión similar a la que da el algoritmo CART sin aplicarle la pipeline."},{"metadata":{},"cell_type":"markdown","source":"# 4. Análisis exploratorio, preprocesamiento de datos, algoritmos de clasificación y evaluacion de modelos de la base datos breast cancer wisconsin data\n\n"},{"metadata":{},"cell_type":"markdown","source":"# 4.1 Análisis exploratorio de la base datos breast cancer wisconsin data"},{"metadata":{},"cell_type":"markdown","source":"Antes que nada obtendremos el conjunto de datos de entrenamiento y el de prueba"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataWisconsin_test= utils.join_dataset(XWisconsin_test,yWisconsin_test)\ndataWisconsin_train= utils.join_dataset(XWisconsin_train,yWisconsin_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Descripcion del conjunto**\n\nTendremos que tener conocimento de:\n* Numeros de casos\n* Tipos de variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataWisconsin_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obsevamos que el conjunto de datos de entrenamiento tenemos 398 casos y 31 variables (31 variables predictoras y 1 variable clase). \n\nPara conocer el tipo de variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"dataWisconsin_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos que tenemos que las 31 seran de tipo numerico (float64) y la variable diagnosis es categorica esta contendra los siguientes casos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"yWisconsin_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Vizualizacion de la variables**\n\nDebemos representar y analizar las distribuciones de las variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(dataWisconsin_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En este histograma muestra la densidad de las instancias para las diferencia variables.\n\nMuestran una distribucion normal\nuna distribución normal con tendencia central en forma de campana, la mayoria de caracteriticas."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(dataWisconsin_train)\nB,M= yWisconsin_train.value_counts()\nprint('Numero de Benig: ',B)\nprint('Numero de Malignant : ',M)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observando el conjunto de datos de entrenamiento tenemos 250 Benig y 148 Malignant, tenemos dos variables objetivos y que no tenemos el misma numero de casos, esto quiere decir que la muestra esta desbalanceada.\n\nAl tener muchas caracteristicas resulta dificil poder visualizar algunas graficas por ejemplo el diagrama de nubes de puntos, por ello divimos estas caracteristicas en 3, respectivamente(mean, re y worst)"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(dataWisconsin_train, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_train = dataWisconsin_train.iloc[:,[0,1,2,3,4,5,6,7,8,9,30]]\nse_train = dataWisconsin_train.iloc[:,[10,11,12,13,14,15,16,17,18,19,30]]\nworst_train = dataWisconsin_train.iloc[:,[20,21,22,23,24,25,26,27,28,29,30]]\nutils.plot_pairplot(mean_train, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(se_train, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(worst_train, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Respecto a estas graficas podemas darnos cuenta que las variables radius_mean, perimeter_mean, area_mean estan muy relacionados, obviamente es puede ser por que para obtener el perimetro y el area es necesario saber el radio. Puede que sea factible descartar estas variables y quedarnos con solo radio.\n\nPodemos ver en la matriz de correlacion observamos que radio, perimetro, area si estan muy correlacionados, ademas de concavidad, compactness y concave_point, por lo que podemos utilizar uno de elllos y descartar los otros."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(mean_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(se_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.heatmap(worst_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.2 Preprocesamiento de datos de la base datos breast cancer wisconsin data"},{"metadata":{},"cell_type":"markdown","source":"**Transformacion de los datos:**\n\nComo hemos observado en el analisis exploratorio, una accion posible es la eliminacion de variables, por no resultar muy util o redundante.\n\nEntonces que datos descartar: Nos quedaremos con radius_mean por ejemplo entre area_mean,perimeter_mean,radius_mean y tambien con concavidad entre (concavidad,compactness,concave_points) en cada caso lo mismo (mean,worst,se) Por lo tanto tendremos de las 30 variables, entonces tendremos 18 variables a utilizar.\n\nCreamos una lista de nombres de las caracteristicas con intencion de quitarlas:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"droplist= ['perimeter_mean','area_mean','perimeter_se','area_se','perimeter_worst','area_worst','concave points_mean','compactness_mean',\n          'concave points_se','compactness_se','concave points_worst','compactness_worst']\nnewdataWisconsin= dataWisconsin.drop(droplist,axis=1)\n\nnewdataWisconsin.sample(5,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se hallan borrado "},{"metadata":{"trusted":true},"cell_type":"code","source":"newdataWisconsin.sample(5,random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A partir de estos datos realizamos el holdout:\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"(nXW, nyW) = utils.divide_dataset(newdataWisconsin, target=\"diagnosis\")\ntrain_size = 0.7\n\n(nXW_train, nXW_test, nyW_train, nyW_test) = train_test_split(nXW, nyW,\n                                                      stratify=nyW,\n                                                      random_state=seed,\n                                                      train_size=train_size)\nnewdataW_test= utils.join_dataset(nXW_test,nyW_test)\nnewdataW_train= utils.join_dataset(nXW_train,nyW_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Probaremos si discretizar es un opcion viable para este conjunto de datos, por lo que creamos los discretizadores (anchura,frecuencia,k-medias):"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer2uW = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")\ndiscretizer2qW = KBinsDiscretizer(n_bins=2, strategy=\"quantile\")\ndiscretizer2kW = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  4.3 Algoritmos de clasificación de la base datos breast cancer wisconsin data"},{"metadata":{},"cell_type":"markdown","source":"Generamos los distintos clasificadores:\n\n- Algoritmo Zero_R\n- Algoritmo CART\n\nTambien crearemos un estimador que permite integrar la eliminacion de atributos dentro de un pipeline (delete_transformer). Este realizara la misma funcion que se hizo en el prepocesamiento (Transformacion de los datos)."},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_transformer = make_column_transformer(('drop',['perimeter_mean','area_mean','perimeter_se','area_se','perimeter_worst','area_worst','concave points_mean','compactness_mean',\n          'concave points_se','compactness_se','concave points_worst','compactness_worst']),remainder='passthrough')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tambien crearemos distintos pipelines para compraborar si las mejoras que realizamos resultan correctas o no."},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_zeroR=make_pipeline(delete_transformer, zero_r_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_treemodel=make_pipeline(delete_transformer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_modeluW = make_pipeline(discretizer2uW,tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_modelqW = make_pipeline(discretizer2qW, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_modelkW = make_pipeline(discretizer2kW, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_treemodel_discretizeu=make_pipeline(delete_transformer,discretizer2uW,tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_treemodel_discretizeq=make_pipeline(delete_transformer,discretizer2qW,tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_treemodel_discretizek=make_pipeline(delete_transformer,discretizer2kW,tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  4.4 Evaluación de modelos de la base datos breast cancer wisconsin data"},{"metadata":{},"cell_type":"markdown","source":"Primero evaluaremos el Algoritmo-Zero-R "},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Probamos si eliminando los valores redundantes resulta en alguna mejora"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(delete_zeroR,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como era de esperar el modelo Zero-R al ser el modelo más malo, ya que considera a todos los datos como Benignos e introduciendo la eliminacion de datos no resulta de ayuda.\n\nAhora probemos con el arbol de decision:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resulta en una gran mejora con respecto al Zero-R, probemos ahora si eliminando caracteristicas es correcto."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(delete_treemodel,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resulta en una mejor evaluacion.\nProbemos con el conjunto de datos discretizado en el arbol de decision  en cada caso (anchura,frecuencia,k-medias) respecticamente."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_modeluW,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_modelqW,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_modelkW,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos que la evaluacion para anchura y frencuencia no mejora con respecto al conjunto sin discretizar, pero por k-medias si.\n\nEntonces que pasaria si utilizamos sobre estos pipeline la eliminacion de caracteristicas redundantes."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(delete_treemodel_discretizeu,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(delete_treemodel_discretizeq,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(delete_treemodel_discretizek,\n               XWisconsin_train, XWisconsin_test,\n               yWisconsin_train, yWisconsin_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finalmente tras ver las precisiones obtenidas son las siguientes:\n\n- Zero_R: 0.62573 sin eliminacion y con eliminacion son la misma\n- Arbol de decision: 0.90643 sin eliminacion y 0.94737 con eliminacion\n- Discretizacion + Arbol de decision:\n\n    1. Anchura : 0,90058 sin eliminacion y 0.80702 con eliminacion\n    2. Frecuencia: 0.89474 sin eliminacion y 0.88304 con eliminacion\n    3. k-medias: 0.92398 sin eliminacion y con eliminacion misma\n    \nEn estas tres opciones podemos decir que el que nos da mayor resultado es arbol de decision + eliminacion con un 0.94737 y el peor Zero_R, pero obviando este el siguiente seria discretizacion(anchura) + eliminacion + arbol de decision con 0.80702.\n\nObservando detenidamente los resultados la discretizacion sobre las caracteristicas eliminadas resulta en un considerable descendo en la precision por lo tanto no seria correcto discretizar cuando se eliminan caracteristicas.\n\nPor otro lado si solo discretizamos(k-medias) + arbol de decision resultamos en un 0.92398 que resulta en buena precision en comparacion con las otras discretizaciones y tambien en el caso de realizar el arbol de decision sin discretizar."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}