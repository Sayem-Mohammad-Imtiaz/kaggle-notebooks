{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello everyone! This is an example of building a simple language recognition model for a Ukrainian Open Speech To Text Dataset","metadata":{}},{"cell_type":"markdown","source":"Based on this example: https://www.tensorflow.org/tutorials/audio/simple_audio","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nimport re\nfrom sklearn.model_selection import train_test_split\nimport os\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom IPython import display\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\nfrom collections import Counter\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:14.154991Z","iopub.execute_input":"2021-08-25T13:33:14.155337Z","iopub.status.idle":"2021-08-25T13:33:14.171546Z","shell.execute_reply.started":"2021-08-25T13:33:14.155293Z","shell.execute_reply":"2021-08-25T13:33:14.170633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/ukrainian-ostotextdataset42-dataframe/Ukrainian_Open_Speech_To_Text Dataset.csv')\n\ndata['number_of_words'] = data['text'].apply(lambda x: len(str(x).split()))\ndata['words'] = data['text'].apply(lambda x: str(x).split())\nprint(data)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:14.173001Z","iopub.execute_input":"2021-08-25T13:33:14.173598Z","iopub.status.idle":"2021-08-25T13:33:29.316923Z","shell.execute_reply.started":"2021-08-25T13:33:14.173559Z","shell.execute_reply":"2021-08-25T13:33:29.315406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)\nprint(data.shape)\n\nprint(data.loc[data['number_of_words'] == 1])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:29.318596Z","iopub.execute_input":"2021-08-25T13:33:29.318965Z","iopub.status.idle":"2021-08-25T13:33:29.899804Z","shell.execute_reply.started":"2021-08-25T13:33:29.318928Z","shell.execute_reply":"2021-08-25T13:33:29.898954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets=data['dataset'].unique()\ndata=data.dropna()#.fillna(value='', inplace=True)\n#data=data.loc[data['dataset'] == 'VR/']\n\n#data=data.loc[data['dataset'] != '1TVUKRAINIAN/']\n#data=data.loc[data['dataset'] != 'GROSHI/']\n#data=data.loc[data['dataset'] != 'MON/']\n\ndata=data.loc[data['number_of_words'] == 1]\ndata['count'] = data.groupby('text')['text'].transform('count')\n\ndata=data.loc[data['count'] > 10]\ndata=data[['path','text']]\ndata['text'] = data['text'].str.replace(',','-')\nprint('kaggle datasets:',datasets)\ncommands=data['text'].unique()\nprint('commands:',len(commands))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:29.901351Z","iopub.execute_input":"2021-08-25T13:33:29.901836Z","iopub.status.idle":"2021-08-25T13:33:32.268688Z","shell.execute_reply.started":"2021-08-25T13:33:29.901798Z","shell.execute_reply":"2021-08-25T13:33:32.267719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data=data.dropna()#.fillna(value='', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:32.269979Z","iopub.execute_input":"2021-08-25T13:33:32.270334Z","iopub.status.idle":"2021-08-25T13:33:32.274647Z","shell.execute_reply.started":"2021-08-25T13:33:32.270298Z","shell.execute_reply":"2021-08-25T13:33:32.273519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(data))\nval_size=0.2#0.2\ntest_size=0.1\n#val_size=round(val_size*len(data))\n#test_size=round(test_size*len(data))\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_val_files_pd,test_files_pd,_,__= train_test_split(data,data['text'],test_size=test_size,stratify=data['text'], random_state=10)\n\ntrain_files_pd,val_files_pd,_,__= train_test_split(train_val_files_pd,train_val_files_pd['text'],test_size=val_size,stratify=train_val_files_pd['text'], random_state=11)\n#train_files_pd = data[:len(data)-val_size-test_size]\n#val_files_pd = data[len(data)-val_size-test_size: len(data)-test_size]\n#test_files_pd = data[len(data)-test_size:]\n\ntrain_files=train_files_pd.to_numpy()\nval_files=val_files_pd.to_numpy()\ntest_files=test_files_pd.to_numpy()\n\nprint('Training set size', len(train_files))\nprint('Validation set size', len(val_files))\nprint('Test set size', len(test_files))","metadata":{"_uuid":"1964381b66d2d5d35c9b328c3f17ed23f702ae57","execution":{"iopub.status.busy":"2021-08-25T13:33:32.276152Z","iopub.execute_input":"2021-08-25T13:33:32.276508Z","iopub.status.idle":"2021-08-25T13:33:32.602558Z","shell.execute_reply.started":"2021-08-25T13:33:32.276472Z","shell.execute_reply":"2021-08-25T13:33:32.600959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(file_path):\n  parts = tf.strings.split(file_path, os.path.sep)\n\n  # Note: You'll use indexing here instead of tuple unpacking to enable this \n  # to work in a TensorFlow graph.\n  return parts[-2]","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:32.605177Z","iopub.execute_input":"2021-08-25T13:33:32.605635Z","iopub.status.idle":"2021-08-25T13:33:32.610298Z","shell.execute_reply.started":"2021-08-25T13:33:32.605593Z","shell.execute_reply":"2021-08-25T13:33:32.609202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_audio(audio_binary):\n  audio, _ = tf.audio.decode_wav(audio_binary)\n  return tf.squeeze(audio, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:32.612408Z","iopub.execute_input":"2021-08-25T13:33:32.612759Z","iopub.status.idle":"2021-08-25T13:33:32.62045Z","shell.execute_reply.started":"2021-08-25T13:33:32.612718Z","shell.execute_reply":"2021-08-25T13:33:32.619619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_waveform_and_label(file_path):\n    label = file_path[1]\n    audio_binary = tf.io.read_file(file_path[0])\n    print(audio_binary)\n    waveform = decode_audio(audio_binary)\n    return waveform, label","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:32.621945Z","iopub.execute_input":"2021-08-25T13:33:32.622322Z","iopub.status.idle":"2021-08-25T13:33:32.629058Z","shell.execute_reply.started":"2021-08-25T13:33:32.622257Z","shell.execute_reply":"2021-08-25T13:33:32.628225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\nfiles_ds = tf.data.Dataset.from_tensor_slices(train_files)\nprint(files_ds)\nwaveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\nprint(files_ds)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:32.632077Z","iopub.execute_input":"2021-08-25T13:33:32.63236Z","iopub.status.idle":"2021-08-25T13:33:32.804911Z","shell.execute_reply.started":"2021-08-25T13:33:32.632334Z","shell.execute_reply":"2021-08-25T13:33:32.804069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 3\ncols = 3\nn = rows*cols\nfig, axes = plt.subplots(rows, cols, figsize=(10, 12))\nfor i, (audio, label) in enumerate(waveform_ds.take(n)):\n  r = i // cols\n  c = i % cols\n  ax = axes[r][c]\n  ax.plot(audio.numpy())\n  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n  label = label.numpy().decode('utf-8')\n  ax.set_title(label)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:32.806123Z","iopub.execute_input":"2021-08-25T13:33:32.806441Z","iopub.status.idle":"2021-08-25T13:33:34.096545Z","shell.execute_reply.started":"2021-08-25T13:33:32.806414Z","shell.execute_reply":"2021-08-25T13:33:34.095727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_spectrogram(waveform):\n  # Padding for files with less than 16000 samples\n  #if waveform.get_shape().as_list()[0]:\n  print (([50000] -tf.shape(waveform))<0)\n  if ([50000] -tf.shape(waveform))<0:\n    waveform=tf.slice(waveform, [0], [50000])\n  zero_padding = tf.zeros([50000] - tf.shape(waveform), dtype=tf.float32)\n  #print(waveform.get_shape().as_list()[0])  \n  #print(tf.slice(waveform, [0], [100000], name=None\n\n\n  # Concatenate audio with padding so that all audio clips will be of the \n  # same length\n  waveform = tf.cast(waveform, tf.float32)\n  equal_length = tf.concat([waveform, zero_padding], 0)\n  spectrogram = tf.signal.stft(\n      equal_length, frame_length=255, frame_step=128)\n\n  spectrogram = tf.abs(spectrogram)\n\n  return spectrogram","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:34.097666Z","iopub.execute_input":"2021-08-25T13:33:34.098005Z","iopub.status.idle":"2021-08-25T13:33:34.105001Z","shell.execute_reply.started":"2021-08-25T13:33:34.097967Z","shell.execute_reply":"2021-08-25T13:33:34.10384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for waveform, label in waveform_ds.take(1):\n  label = label.numpy().decode('utf-8')\n  spectrogram = get_spectrogram(waveform)\n\nprint('Label:', label)\nprint('Waveform shape:', waveform.shape)\nprint('Spectrogram shape:', spectrogram.shape)\nprint('Audio playback')\ndisplay.display(display.Audio(waveform, rate=16000))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:34.106458Z","iopub.execute_input":"2021-08-25T13:33:34.107014Z","iopub.status.idle":"2021-08-25T13:33:34.518454Z","shell.execute_reply.started":"2021-08-25T13:33:34.106912Z","shell.execute_reply":"2021-08-25T13:33:34.517664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_spectrogram(spectrogram, ax):\n  # Convert to frequencies to log scale and transpose so that the time is\n  # represented in the x-axis (columns).\n  log_spec = np.log(spectrogram.T)\n  height = log_spec.shape[0]\n  width = log_spec.shape[1]\n  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n  Y = range(height)\n  ax.pcolormesh(X, Y, log_spec)\n\n\nfig, axes = plt.subplots(2, figsize=(12, 8))\ntimescale = np.arange(waveform.shape[0])\naxes[0].plot(timescale, waveform.numpy())\naxes[0].set_title('Waveform')\naxes[0].set_xlim([0, 16000])\nplot_spectrogram(spectrogram.numpy(), axes[1])\naxes[1].set_title('Spectrogram')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:34.519835Z","iopub.execute_input":"2021-08-25T13:33:34.520211Z","iopub.status.idle":"2021-08-25T13:33:34.799802Z","shell.execute_reply.started":"2021-08-25T13:33:34.520172Z","shell.execute_reply":"2021-08-25T13:33:34.798857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_spectrogram_and_label_id(audio, label):\n  spectrogram = get_spectrogram(audio)\n  spectrogram = tf.expand_dims(spectrogram, -1)\n  label_id = tf.argmax(label == commands)\n  return spectrogram, label_id","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:34.801283Z","iopub.execute_input":"2021-08-25T13:33:34.801638Z","iopub.status.idle":"2021-08-25T13:33:34.80661Z","shell.execute_reply.started":"2021-08-25T13:33:34.8016Z","shell.execute_reply":"2021-08-25T13:33:34.805766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spectrogram_ds = waveform_ds.map(\n    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:34.807925Z","iopub.execute_input":"2021-08-25T13:33:34.808508Z","iopub.status.idle":"2021-08-25T13:33:35.035793Z","shell.execute_reply.started":"2021-08-25T13:33:34.808469Z","shell.execute_reply":"2021-08-25T13:33:35.034887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 3\ncols = 3\nn = rows*cols\nfig, axes = plt.subplots(rows, cols, figsize=(10, 10))\nfor i, (spectrogram, label_id) in enumerate(spectrogram_ds.take(n)):\n  r = i // cols\n  c = i % cols\n  ax = axes[r][c]\n  plot_spectrogram(np.squeeze(spectrogram.numpy()), ax)\n  ax.set_title(commands[label_id.numpy()])\n  ax.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:35.037305Z","iopub.execute_input":"2021-08-25T13:33:35.037785Z","iopub.status.idle":"2021-08-25T13:33:35.775135Z","shell.execute_reply.started":"2021-08-25T13:33:35.037747Z","shell.execute_reply":"2021-08-25T13:33:35.771812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_dataset(files):\n  files_ds = tf.data.Dataset.from_tensor_slices(files)\n  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n  output_ds = output_ds.map(\n      get_spectrogram_and_label_id,  num_parallel_calls=AUTOTUNE)\n  return output_ds","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:35.776431Z","iopub.execute_input":"2021-08-25T13:33:35.776783Z","iopub.status.idle":"2021-08-25T13:33:35.78196Z","shell.execute_reply.started":"2021-08-25T13:33:35.776746Z","shell.execute_reply":"2021-08-25T13:33:35.780791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = spectrogram_ds\nval_ds = preprocess_dataset(val_files)\ntest_ds = preprocess_dataset(test_files)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:35.786079Z","iopub.execute_input":"2021-08-25T13:33:35.786608Z","iopub.status.idle":"2021-08-25T13:33:35.984685Z","shell.execute_reply.started":"2021-08-25T13:33:35.786578Z","shell.execute_reply":"2021-08-25T13:33:35.983786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\ntrain_ds = train_ds.batch(batch_size)\nval_ds = val_ds.batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:35.986416Z","iopub.execute_input":"2021-08-25T13:33:35.986748Z","iopub.status.idle":"2021-08-25T13:33:35.993319Z","shell.execute_reply.started":"2021-08-25T13:33:35.986712Z","shell.execute_reply":"2021-08-25T13:33:35.991526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for spectrogram, _ in spectrogram_ds.take(1):\n  input_shape = spectrogram.shape\nprint('Input shape:', input_shape)\nnum_labels = len(commands)\nprint('num_labels:', num_labels)\nnorm_layer = preprocessing.Normalization()\n#norm_layer.adapt(spectrogram_ds.map(lambda x, _: x))\n\nmodel = models.Sequential([\n    layers.Input(shape=input_shape),\n    preprocessing.Resizing(96, 96), \n    norm_layer,\n    layers.Conv2D(512, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Conv2D(256, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Flatten(),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(num_labels),\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:35.994621Z","iopub.execute_input":"2021-08-25T13:33:35.994996Z","iopub.status.idle":"2021-08-25T13:33:36.193346Z","shell.execute_reply.started":"2021-08-25T13:33:35.994961Z","shell.execute_reply":"2021-08-25T13:33:36.192509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'],\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:36.194661Z","iopub.execute_input":"2021-08-25T13:33:36.195025Z","iopub.status.idle":"2021-08-25T13:33:36.213143Z","shell.execute_reply.started":"2021-08-25T13:33:36.194987Z","shell.execute_reply":"2021-08-25T13:33:36.212282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 30\nhistory = model.fit(\n    train_ds, \n    #steps_per_epoch =20,\n    validation_data=val_ds,  \n    epochs=EPOCHS,\n    #callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T13:33:36.21463Z","iopub.execute_input":"2021-08-25T13:33:36.216197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = history.history\nplt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_audio = []\ntest_labels = []\n\nfor audio, label in test_ds:\n  test_audio.append(audio.numpy())\n  test_labels.append(label.numpy())\n\ntest_audio = np.array(test_audio)\ntest_labels = np.array(test_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(test_audio), axis=1)\ny_true = test_labels\n\ntest_acc = sum(y_pred == y_true) / len(y_true)\nprint(f'Test set accuracy: {test_acc:.0%}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}