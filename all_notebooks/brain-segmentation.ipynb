{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Importing necessary modules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport random\nfrom itertools import chain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom glob import glob\n\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom skimage.color import rgb2gray","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model,save_model\nfrom tensorflow.keras.layers import (Input, Activation,\n                                     BatchNormalization, \n                                     Dropout, Lambda, Conv2D,\n                                     Conv2DTranspose, MaxPooling2D,\n                                     concatenate)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import io\nfrom tensorflow.keras.layers import *\nfrom sklearn.preprocessing import StandardScaler, normalize\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/lgg-mri-segmentation/kaggle_3m/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '../input/lgg-mri-segmentation/kaggle_3m/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"WIDTH = HEIGHT = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# data containing path to Brain MRI and their corresponding mask\nbrain_df = pd.read_csv('../input/lgg-mri-segmentation/kaggle_3m/data.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_df.info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_map = []\nfor sub_dir_path in glob(\"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"+\"*\"):\n    #if os.path.isdir(sub_path_dir):\n    try:\n        dir_name = sub_dir_path.split('/')[-1]\n        for filename in os.listdir(sub_dir_path):\n            image_path = sub_dir_path + '/' + filename\n            data_map.extend([dir_name, image_path])\n    except Exception as e:\n        print(e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\"patient_id\" : data_map[::2],\n                   \"path\" : data_map[1::2]})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imgs = df[~df['path'].str.contains(\"mask\")]\ndf_masks = df[df['path'].str.contains(\"mask\")]\n\n# File path line length images for later sorting\nBASE_LEN = 89 # len(/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_ <-!!!43.tif)\nEND_IMG_LEN = 4 # len(/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->.tif)\nEND_MASK_LEN = 9 # (/kaggle/input/lgg-mri-segmentation/kaggle_3m/TCGA_DU_6404_19850629/TCGA_DU_6404_19850629_43 !!!->_mask.tif)\n\n# Data sorting\nimgs = sorted(df_imgs[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\nmasks = sorted(df_masks[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n\n# Sorting check\nidx = random.randint(0, len(imgs)-1)\nprint(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final dataframe\nbrain_df = pd.DataFrame({\"patient_id\": df_imgs.patient_id.values,\n                         \"image_path\": imgs,\n                         \"mask_path\": masks\n                        })\ndef pos_neg_diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    if value > 0 : \n        return 1\n    else:\n        return 0\n    \nbrain_df['mask'] = brain_df['mask_path'].apply(lambda x: pos_neg_diagnosis(x))\nbrain_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_df['mask'].value_counts().index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use plotly to plot interactive bar chart\nimport plotly.graph_objects as go\n\nfig = go.Figure([go.Bar(x = brain_df['mask'].value_counts().index, y = brain_df['mask'].value_counts())])\nfig.update_traces(marker_color = 'rgb(0,200,0)', marker_line_color = 'rgb(0,255,0)',\n                  marker_line_width = 7, opacity = 0.6)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading images\nmask_files = glob(root +'*/*_mask*')\nimg_files = list(map(lambda x: x.replace('_mask',''),mask_files))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(img_files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Images","metadata":{}},{"cell_type":"code","source":"plt.imshow(cv2.imread(brain_df.image_path[623]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.imread(brain_df.mask_path[623]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.imread(brain_df.mask_path[623]).max()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic visualizations: Visualize the images (MRI and Mask) in the dataset separately \nimport random\nfig, axs = plt.subplots(4,2, figsize=(10,18))\ncount = 0\nfor x in range(4):\n    i = random.randint(0, len(brain_df)) # select a random index\n    axs[count][0].title.set_text(\"Brain MRI\") # set title\n    axs[count][0].imshow(cv2.imread(brain_df.image_path[i])) # show MRI \n    axs[count][1].title.set_text(\"Mask - \" + str(brain_df['mask'][i])) # plot title on the mask (0 or 1)\n    axs[count][1].imshow(cv2.imread(brain_df.mask_path[i])) # Show corresponding mask\n    count += 1\n\nfig.tight_layout()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display random iteration of images from the dataset with their masks\n#fig = plt.figure(figsize=(13, 13))\n#rnd_no = np.random.randint(0,len(img_files)-9)\n#for ind, i in enumerate(range(rnd_no, rnd_no+9)):\n    \n #   fig.add_subplot(3,3,ind+1)\n    \n    # get image & mask file paths\n  #  img_path = img_files[i]\n   # msk_path = mask_files[i]\n    \n    # read images\n    #img = cv2.imread(img_path)\n    #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    #msk = cv2.imread(msk_path)\n    \n    # display images\n    #plt.imshow(img)\n   # plt.imshow(msk, alpha=0.5)\n    #plt.title(img_path.split('/')[-1].split('.')[0])#\n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom skimage import io\ncount = 0\nfig, axs = plt.subplots(12, 3, figsize = (20, 50))\nfor i in range(len(brain_df)):\n    if brain_df['mask'][i] ==1 and count <12:\n        img = io.imread(brain_df.image_path[i])\n        axs[count][0].title.set_text('Brain MRI')\n        axs[count][0].imshow(img, cmap='hot')\n\n        mask = io.imread(brain_df.mask_path[i])\n        axs[count][1].title.set_text('Mask')\n        axs[count][1].imshow(mask, cmap = 'hot')\n\n\n        img[mask == 255] = (255, 0, 0)\n        axs[count][2].title.set_text('MRI with Mask')\n        axs[count][2].imshow(img, cmap='hot')\n        count+=1\n\nfig.tight_layout()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading dataset paths and slitting into train, valid and test sets","metadata":{}},{"cell_type":"code","source":"# loading the dataset paths\ndf = pd.DataFrame(data={\"images\": img_files,\n                     \"masks\": mask_files})\n\n# train-valid-test split\ndf_train, df_test = train_test_split(df, test_size=.1)\ndf_train, df_val = train_test_split(df_train, test_size=.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image augmentation ","metadata":{}},{"cell_type":"code","source":"# Augmentation\ndef train_generator(df, batch_size, aug_dict,\n                   image_color_mode = \"rgb\",\n                   mask_color_mode = \"grayscale\",\n                   image_save_prefix = \"image\",\n                   mask_save_prefix = \"mask\",\n                   save_to_dir = None,\n                   target_size = (256, 256),\n                   seed=1):\n    \"\"\"\n    Returns sequence of Augmented images\n    by reading the path names from the dataframe\n    \"\"\"\n    \n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n                        df,\n                        x_col='images',\n                        class_mode=None,\n                        color_mode = image_color_mode,\n                        target_size = target_size,\n                        batch_size = batch_size,\n                        save_to_ir = save_to_dir,\n                        save_prefix = image_save_prefix,\n                        seed = seed\n    )\n    \n    mask_generator = mask_datagen.flow_from_dataframe(\n                        df,\n                        x_col='masks',\n                        class_mode=None,\n                        color_mode = mask_color_mode,\n                        target_size = target_size,\n                        batch_size = batch_size,\n                        save_to_ir = save_to_dir,\n                        save_prefix = image_save_prefix,\n                        seed = seed\n    )\n    \n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_data(img, mask):\n    \"\"\"\n    Preprocessing function: \n    Normalizes Image arrays.\n    Normalizes and thresholds Mask arrays.\n    \"\"\"\n    img = img / 255\n    \n    mask = mask / 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loss Metrics: Sorenson-Dice Loss & Jaccard Distance","metadata":{}},{"cell_type":"code","source":"# Sorenson-Dice loss\nsmooth = 100\n\ndef dice_coef(y_true, y_pred):\n    \n    return ((2* K.sum(y_true*y_pred))/\n            (K.sum(y_true) + K.sum(y_pred) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n# Jaccard Distance\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth)/(sum_ - intersection + smooth)\n    \n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    \n    return -iou(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Architecture: U-NET","metadata":{}},{"cell_type":"code","source":"def unet(input_size=(HEIGHT, WIDTH, 3)):\n    inputs = Input(input_size)\n    \n    # block 1 - Downscaling\n    conv1 = Conv2D(64, (3,3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3,3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2,2))(bn1)\n    \n    # block 2 - Downscaling\n    conv2 = Conv2D(128, (3,3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3,3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2,2))(bn2)\n    \n    # block 3 - Downscaling\n    conv3 = Conv2D(256, (3,3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3,3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2,2))(bn3)\n    \n    # block 4 - Downscaling\n    conv4 = Conv2D(512, (3,3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(128, (3,3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2,2))(bn4)\n    \n    # block 5\n    conv5 = Conv2D(1024, (3,3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3,3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n    \n    # block 6 - Upscaling\n    up6 = concatenate(\n        [Conv2DTranspose(512, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3,3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3,3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n    \n    # block 7 - Upscaling\n    up7 = concatenate(\n        [Conv2DTranspose(256, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3,3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3,3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n    \n    # block 8 - Upscaling\n    up8 = concatenate(\n        [Conv2DTranspose(128, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3,3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3,3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n    \n    # block 9 - Upscaling\n    up9 = concatenate(\n        [Conv2DTranspose(64, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3,3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3,3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n    \n    # block 10 - Output layer\n    conv10 = Conv2D(1, (1,1), activation='sigmoid')(bn9)\n    \n    return Model(inputs=[inputs], outputs=[conv10])\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training parameters\nEPOCHS = 100\nBATCH_SIZE = 32\nALPHA = 0.0001 # learning rate\nDECAY_RATE = ALPHA/EPOCHS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.iloc[726]['images']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.iloc[726]['masks']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Initilializing 'train' and 'valid' augmented image generators","metadata":{}},{"cell_type":"code","source":"train_generator_args = dict(\n    rotation_range=.2,\n    width_shift_range=.05,\n    height_shift_range=.05,\n    shear_range=.05,\n    zoom_range=.05,\n    horizontal_flip=True,\n    fill_mode='nearest')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = train_generator(df_train, BATCH_SIZE,\n                           train_generator_args,\n                           target_size=(HEIGHT, WIDTH))\n\nval_gen = train_generator(df_val, BATCH_SIZE,\n                           dict(),\n                           target_size=(HEIGHT, WIDTH))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting Model parameters","metadata":{}},{"cell_type":"code","source":"# Setting Model parameters and compiling\nmodel = unet(input_size=(HEIGHT, WIDTH, 3))\nOPTIMIZER = Adam(lr=ALPHA, epsilon=None, decay=DECAY_RATE)\nmodel.compile(\n    optimizer=OPTIMIZER,\n    loss=dice_coef_loss,\n    metrics=['binary_accuracy', iou, dice_coef]    \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving Models\n\ncallbacks = [ModelCheckpoint('brain_seg_unet.hdf5',\n                             verbose=1,\n                             save_best_only=True), EarlyStopping(monitor='val_loss', verbose=1, patience=4)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training model","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_gen,\n                   steps_per_epoch=len(df_train)/BATCH_SIZE,\n                   epochs=EPOCHS,\n                   callbacks=callbacks,\n                   validation_data=val_gen,\n                   validation_steps=len(df_val)/BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nplt.figure(1)\n\nplt.plot(list_trainloss,'ro-')\nplt.plot(list_testloss, 'bo-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'ro-')\nplt.plot(list_testdice, 'bo-')\nplt.xlabel('iteration')\nplt.ylabel('dice score')\nplt.title('dice score graph', fontsize = 15)\nplt.legend(['Training','Testing'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('brain_seg_unet.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['images'].iloc[index])\n    img = cv2.resize(img ,(256, 256))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['masks'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}