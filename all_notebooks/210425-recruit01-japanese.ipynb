{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Recruit Restaurant Visitor Forecasting\n表題のコンペのコードv2<br>\n処理時間およそ70min<br>\n* 特徴量を作成(日付、店舗のピーク曜日、座標、カテゴリ)\n* カテゴリ変数を変換(店舗IDと店舗カテゴリ)\n* ラグ特徴量(7,14,21日前の平均と、直前の同じ曜日の来店者数)\n<br><br>\n【モデル学習方法】<br>\n* 4/23のvisitorsを予測\n* 4/23のvisitors数を踏まえた特徴量を生成する　←ラグ特徴量を作るのにループさせているので時間がかかる\n* 4/24のvisitorsを予測\n* 4/24のvisitors数を踏まえた特徴量を生成する\n<br>\nhttps://www.kaggle.com/c/recruit-restaurant-visitor-forecasting","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# air_visit_data = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/air_visit_data.csv\")\n# weatherData = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/WeatherData.csv\")\n# air_reserve = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/air_reserve.csv\")\n# air_store_info = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/air_store_info.csv\")\n# area_name_mapping = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/area_name_mapping.csv\")\n# date_info = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/date_info.csv\")\n# hpg_reserve = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/hpg_reserve.csv\")\n# hpg_store_info = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/hpg_store_info.csv\")\n# store_id_relation = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/store_id_relation.csv\")\n\n#test = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/test.csv\")\n\n# sample_submit = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# データの読み込み\n天気や日付の情報も入れているが、使っていない","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/air_visit_data.csv\")\nweatherData = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/WeatherData.csv\")\ndate_info = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/date_info.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# date_infoを確認","metadata":{}},{"cell_type":"code","source":"date_info = date_info.rename(columns={'calendar_date': \"visit_date\"})\ndate_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 曜日と祝日情報をマージする\ntrainのvisit_dateについて、date_infoの情報を参照して結合する","metadata":{}},{"cell_type":"code","source":"train = train.merge(date_info, on=\"visit_date\",how=\"left\")\n# 曜日はあとで別の方法で加えるので、一旦削除\ntrain = train.drop(columns=\"day_of_week\")\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trainセットとわかるようにタグ付けする","metadata":{}},{"cell_type":"code","source":"train[\"set\"] = \"train\"\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trainデータを、目的変数と説明変数に分ける","metadata":{}},{"cell_type":"code","source":"train_x = train.drop(columns = \"visitors\")\ntrain_y = pd.DataFrame()\ntrain_y[\"visitors\"] = train[\"visitors\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train_yが200以上のものは外れ値として来店者数を0\n本当は、その店舗の平均来店者数にすべきなのかもしれない","metadata":{}},{"cell_type":"code","source":"# train_yのvisitorsが200を超える場合は0にする\ntrain_y.loc[train_y[\"visitors\"] > 200, \"visitors\"] = 0\n# visitorsでソートして表示\ntrain_y.sort_values(by='visitors', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 日付を切り分ける\n毎月〇日は安い、とか、〇月はセール！とかありそうなので","metadata":{}},{"cell_type":"code","source":"# 2017-04-18\t\ndef back_year(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    return txt_split[0]\n\ndef back_month(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    #04月のような記述にならないように、int型で返す\n    return int(txt_split[1])\n\ndef back_day(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    return int(txt_split[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# year,month,dayの列を作成","metadata":{}},{"cell_type":"code","source":"# year列を新規に作成する。visit_date列の値をback_year関数に入れて処理する\ntrain_x.loc[:,\"year\"] = train_x[\"visit_date\"].apply(back_year)\ntrain_x.loc[:,\"month\"] = train_x[\"visit_date\"].apply(back_month)\ntrain_x.loc[:,\"day\"] = train_x[\"visit_date\"].apply(back_day)\ntrain_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 曜日を取得する\n一番効くと思っている","metadata":{}},{"cell_type":"code","source":"import datetime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#月火水木金土日→[0,1,2,3,4,5,6]で返す\ndt = datetime.datetime(2021, 4, 26)\nprint(dt.weekday())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#月火水木金土日→[0,1,2,3,4,5,6]で返す\ndef back_day_of_the_week(txt):\n    visit_date = txt\n    txt_split = txt.rsplit(\"-\",2)\n    dt = datetime.datetime(int(txt_split[0]), int(txt_split[1]), int(txt_split[2]))\n    return dt.weekday()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 曜日の列を追加","metadata":{}},{"cell_type":"code","source":"train_x.loc[:,\"day_of_the_week\"] = train_x[\"visit_date\"].apply(back_day_of_the_week)\ntrain_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visit_dateは削除\n他のday,year,monthで代替できるので","metadata":{}},{"cell_type":"code","source":"train_x = train_x.drop(columns='visit_date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sample submissionを読み込み、testデータに使う","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/sample_submission.csv\")\ntest[\"set\"] = \"test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x = test.drop(columns=\"visitors\")\ntest_y = pd.DataFrame()\ntest_y[\"visitors\"] = test[\"visitors\"]\n# test_yの来店者数は全て-1で埋める(→ラグ特徴量計算でマイナスを平均に加えるのは不適切と考えやめた)\n# test_y[\"visitors\"] = -1\ntest_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_x.id[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test_xのidを切り分ける\ntest_x(sample_submit)のidが、店舗名と日付で別々になっているので、<br>\ntrain_x(air_visit_data)と同じ形式(air_store_idとvisit_date)になるように<br>\n切り分けたい","metadata":{}},{"cell_type":"code","source":"# アンダーバー区切りで、右から1つのアンダーバーを分けたpandasデータフレームを返す\ntxt = test_x.id[0]\nprint(txt)\ntxt_split = txt.rsplit(\"_\",1)\nprint(txt_split)\nprint(txt_split[0])\nprint(txt_split[1])\ntest_x.date_of_customer = txt_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"上記のように書けば切り分けられることがわかった","metadata":{}},{"cell_type":"markdown","source":"# 切り分ける関数を定義する\nidを引数にして、分割後の店舗名と日付を返す関数をそれぞれつくる","metadata":{}},{"cell_type":"code","source":"def back_store_name(txt):\n    id = txt\n    #_区切りで右から1番目の文字を切り分ける\n    txt_split = txt.rsplit(\"_\",1)\n    # 切り分けた文字列のうち、0番目を返す\n    return txt_split[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def back_date_name(txt):\n    id = txt\n    txt_split = txt.rsplit(\"_\",1)\n    return txt_split[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 新しく作った変数(air_store_idとvisit_date)を、test_xに追加する","metadata":{}},{"cell_type":"code","source":"#新しい列の名前 = 引数として関数に入れて処理する列の名前\ntest_x.loc[:,\"air_store_id\"] = test_x[\"id\"].apply(back_store_name)\ntest_x.loc[:,\"visit_date\"] = test_x[\"id\"].apply(back_date_name)\ntest_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 祝日フラグを追加","metadata":{}},{"cell_type":"code","source":"test_x = test_x.merge(date_info, on=\"visit_date\",how=\"left\")\n# 曜日はあとで別の方法で加えるので、一旦削除\ntest_x = test_x.drop(columns=\"day_of_week\")\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 日付情報をYear,Month,Dayに変更","metadata":{}},{"cell_type":"code","source":"# year列を新規に作成する。visit_date列の値をback_year関数に入れて処理する\ntest_x.loc[:,\"year\"] = test_x[\"visit_date\"].apply(back_year)\ntest_x.loc[:,\"month\"] = test_x[\"visit_date\"].apply(back_month)\ntest_x.loc[:,\"day\"] = test_x[\"visit_date\"].apply(back_day)\ntest_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 日付情報から曜日を取得","metadata":{}},{"cell_type":"code","source":"test_x.loc[:,\"day_of_the_week\"] = test_x[\"visit_date\"].apply(back_day_of_the_week)\ntest_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test_xのGWを休日(土曜)に変更\ntest_xに含まれるGW(5/3-5/5)の曜日を変更する<br>\n条件によりday_of_the_weekを書き換える<br>\n当初日曜日にしていたが、土曜日の方がave_visitorsが多いので土曜に変えた","metadata":{}},{"cell_type":"code","source":"# test_dataの5/3-5/5までを日曜日に変更(日曜日=6)\ntest_x.loc[(test_x['month'] == 5) & (test_x['day'] == 3), 'day_of_the_week'] = 5\ntest_x.loc[(test_x['month'] == 5) & (test_x['day'] == 4), 'day_of_the_week'] = 5\ntest_x.loc[(test_x['month'] == 5) & (test_x['day'] == 5), 'day_of_the_week'] = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# idとvisit_date行は削除\nidは不要。これで、test_xとtrain_xが同じ形式で取得できた<br>\nvisit_dateも、month,day,yearで代替しているので削除","metadata":{}},{"cell_type":"code","source":"test_x = test_x.drop(columns='id')\ntest_x = test_x.drop(columns='visit_date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# カテゴリ変数の変換\nカテゴリ変数をLabelEncoderで実施するために、<br>\n全てのカテゴリ変数(ここだと店舗名)を取得する<br>\n# まず、air_store_idだけをもつDataFrameを定義する","metadata":{}},{"cell_type":"code","source":"train_le = pd.DataFrame()\ntrain_le[\"air_store_id\"] = train_x.air_store_id\ntest_le = pd.DataFrame()\ntest_le[\"air_store_id\"] = test_x.air_store_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2つ(train_leとtest_le)を合体する","metadata":{}},{"cell_type":"code","source":"merge_data_le = pd.merge(train_le,test_le, how=\"outer\")\n# merge_data = merge_data[\"air_store_id\"]\n# train_le = train_x(\"air_store_id\")\n# test_le = test_x(\"air_store_id\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラベルエンコーディングをかける\ntrain_all_leというDataFrameにラベルエンコーディングをかける。<br>\nair_store_idにラベルエンコーディングがかけられて数値に変換される<br>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder #Library for LabelEncoding\n\nfor c in merge_data_le:\n    le = LabelEncoder()\n    le.fit(merge_data_le[c])\n    train_le[c] = le.transform(train_le[c])\n    test_le[c]= le.transform(test_le[c])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラベルエンコーディングしたDataFrameをtrain_x,test_xに結合\n先に、エンコーディング前のair_store_idを削除してから、結合する<br>\nエンコ前後の対応表を作りたいので、train_x_encに保存しておく","metadata":{}},{"cell_type":"code","source":"# エンコード前後の対応確認用、本筋とは関係ない\ntrain_x_enc = train_x.join(train_le, lsuffix='_enc')\ntest_x_enc = test_x.join(test_le, lsuffix='_enc')\n\n# エンコードしたものを入れる\ntrain_x = train_x.drop(columns = \"air_store_id\")\ntrain_x = train_x.join(train_le)\ntest_x = test_x.drop(columns = \"air_store_id\")\ntest_x = test_x.join(test_le)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# データ型を確認\nどこかで、train_x、train_yともに<br>\nyearがint64でなくなってしまっている","metadata":{}},{"cell_type":"code","source":"test_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x.year.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# yearのデータ型をint64に変更\nxgboostで読める型に変更する","metadata":{}},{"cell_type":"code","source":"train_x[\"year\"] = train_x.year.astype(\"int64\")\ntest_x[\"year\"] = test_x.year.astype(\"int64\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train_xとtrain_yを結合してtrain_allにする","metadata":{}},{"cell_type":"code","source":"train_all = train_x.join(train_y)\ntrain_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test_yとtest_xを結合してtest_allにする","metadata":{}},{"cell_type":"code","source":"test_all = test_x.join(test_y)\ntest_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train_allとtest_allをマージしmerge_dataとする\nこれで、trainとtestが同じ形式で得られた。\n以降は、train_allとtest_allをマージしてmerge_dataにして特徴量を追加し、<br>\n最終的に切り分ける事にする","metadata":{}},{"cell_type":"code","source":"merge_data = pd.concat([train_all,test_all])\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA\n店舗IDごとにデータがいくつあるのか、日付が何種類あるのか<br>\ntrainに含まれるのは829店舗で、各店舗には100～300日ぶんのデータがある<br>\ntestに含まれるのは821店舗で、各店舗には39日ぶんのデータがある<br>","metadata":{}},{"cell_type":"code","source":"print(train_x)\n# 店IDごとにデータがいくつあるか確認している\nprint(train_x.groupby(\"air_store_id\").count()[\"day\"])\n# testデータについても同様\nprint(test_x.groupby(\"air_store_id\").count()[\"day\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 曜日ごとの来店者数を確認する\n平均は、平日17-19人、金曜日23人、土曜日26人、日曜日23人<br>\n最大来店者数が800人超えているデータもあるので、外れ値は無くした方がいいかも","metadata":{}},{"cell_type":"code","source":"# train_xとtrain_yを結合する\ntrain_all = train_x.join(train_y)\n# 曜日ごとに、来店者数の合計、データの数、max、minを出力する\nweek_visitors = train_all.groupby(['day_of_the_week']).visitors.agg([sum,len,max,min])\nweek_visitors[\"ave\"] = week_visitors[\"sum\"] // week_visitors[\"len\"]\nweek_visitors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 店舗ごとの平均来店者数\n平均115人来店する店舗(id71番)が一番多い","metadata":{}},{"cell_type":"code","source":"store_visitors = train_all.groupby(['air_store_id']).visitors.agg([sum,len,max,min])\nstore_visitors[\"ave\"] = store_visitors[\"sum\"] // store_visitors[\"len\"]\n# 来店者数の平均でソート\nstore_visitors.sort_values(by='ave', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_visitors.sort_values(by='max', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=store_visitors['ave'], y=store_visitors['max'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=store_visitors['ave'], y=store_visitors['max'], hue=store_visitors['len'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 直近4月のデータを眺める\nたぶん、4月が一番傾向的に近いはず。<br>\n店舗ID = 7 の店の４月のデータを見てみる<br>\n(ちなみに、4月のデータのない店舗もある)","metadata":{}},{"cell_type":"code","source":"train_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_0 = train_all.loc[train_all.air_store_id == 3]\nid_0 = id_0.loc[id_0.month == 4]\n# id_0 = id_0.loc[id_0.day == 2]\nid_0_data = pd.DataFrame()\nid_0_data[\"visitors\"] = id_0.visitors\nid_0_data[\"month\"] = id_0.month\nid_0_data[\"day\"] = id_0.day\nid_0_data[\"day_of_the_week\"] = id_0.day_of_the_week\nid_0_data = id_0_data.reset_index(drop=True)\nid_0_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(\"id=2 store visitors\")\nsns.barplot(x=id_0_data.day, y=id_0_data['visitors'])\nplt.ylabel(\"visitors\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 曜日の影響度\n月の来店者数の合計、平均、max,minを曜日ごとに算出","metadata":{}},{"cell_type":"code","source":"id_0_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_0_data_ana = id_0_data.groupby(['day_of_the_week']).visitors.agg([sum,len,max,min])\nid_0_data_ana[\"ave\"] = id_0_data_ana[\"sum\"] // id_0_data_ana[\"len\"]\nid_0_data_ana","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 最もvisitorsが多い列のindexを返す","metadata":{}},{"cell_type":"code","source":"max_ave_index = id_0_data_ana['ave'].idxmax()\nmax_ave_index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all.loc[train_all.air_store_id == 663]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 店舗ごとに、trainデータから特徴量を作成\n* その店舗の平均来店者数\n* 各曜日の来店者の平均(日曜日～土曜部)\n* 祝日の来店者数の平均\n* 店ごとの来店者数のmax\n* 店ごとの来店者数のmin","metadata":{}},{"cell_type":"code","source":"%%time\ncolumns =[\"air_store_id\",\"v_ave_all\",\"v_ave_0\", \"v_ave_1\",\"v_ave_2\",\"v_ave_3\",\"v_ave_4\", \"v_ave_5\",\"v_ave_6\",\"v_ave_holiday\",\"max_visitors\",\"min_visitors\"]\nv_ave =pd.DataFrame(columns=columns)\n\n#2017/3-4月のみの平均値をとる\ntrain_2017 = train_all.loc[(train_all.year == 2017)]\ntrain_cho = train_2017.loc[(train_2017.month == 1) |(train_2017.month == 2) | (train_2017.month == 3)]\n\nfor c in range(0, 829,1):\n    \n\n    \n    data_ave = train_cho.loc[train_cho.air_store_id == c]\n    data_ave_0 = data_ave.loc[train_all.day_of_the_week == 0] #店舗IDの日曜日の来店者数のDataFrame\n    data_ave_1 = data_ave.loc[train_all.day_of_the_week == 1] #店舗IDの月曜日の来店者数のDataFrame\n    data_ave_2 = data_ave.loc[train_all.day_of_the_week == 2]\n    data_ave_3 = data_ave.loc[train_all.day_of_the_week == 3]\n    data_ave_4 = data_ave.loc[train_all.day_of_the_week == 4]\n    data_ave_5 = data_ave.loc[train_all.day_of_the_week == 5]\n    data_ave_6 = data_ave.loc[train_all.day_of_the_week == 6] #店舗IDの土曜日の来店者数のDataFrame\n    \n    \n    data_ave_h = data_ave.loc[train_all.holiday_flg == 1] #祝日の来店者数\n\n    v_ave_all = data_ave.visitors.mean() #店舗そのものの平均来店者数\n    v_ave_0 =  data_ave_0.visitors.mean() #日曜日の平均\n    v_ave_1 =  data_ave_1.visitors.mean()\n    v_ave_2 =  data_ave_2.visitors.mean()\n    v_ave_3 =  data_ave_3.visitors.mean()\n    v_ave_4 =  data_ave_4.visitors.mean()\n    v_ave_5 =  data_ave_5.visitors.mean()\n    v_ave_6 =  data_ave_6.visitors.mean()\n    \n    \n    \n    v_ave_h =  data_ave_h.visitors.mean() #祝日の来店者数の平均\n    max_visitors =  data_ave.visitors.max()\n    min_visitors =  data_ave.visitors.min()\n    \n    # 例外\n    # 以下の店舗は欠損するので0で埋める\n    if c == 110:\n        v_ave_all = 0\n        max_visitors = 0\n        min_visitors = 0\n        \n    if c == 663:\n        v_ave_all = 0\n        max_visitors = 0\n        min_visitors = 0\n        \n    if c == 387:\n        v_ave_all = 0\n        max_visitors = 0\n        min_visitors = 0\n        \n    if c == 579:\n        v_ave_all = 0\n        max_visitors = 0\n        min_visitors = 0\n    \n    # 以下の店舗は4月にしかデータがないので手動で平均値を算出した\n    if c == 453:\n        v_ave_all = 86.8\n        max_visitors = 120\n        min_visitors = 40\n        v_ave_0 =  0\n        v_ave_1 =  82.333\n        v_ave_2 =  107\n        v_ave_3 =  97.3\n        v_ave_4 =  101.6\n        v_ave_5 =  77\n        v_ave_6 =  55.66\n    \n    v_ave_store = [[c, v_ave_all,v_ave_0, v_ave_1, v_ave_2, v_ave_3, v_ave_4, v_ave_5, v_ave_6, v_ave_h, max_visitors, min_visitors]]\n    v_ave_temp = pd.DataFrame(v_ave_store, columns=columns)\n    \n\n        \n    \n    # 算出期間が短いと欠損が出る可能性があるので、修正する\n    v_ave_temp.loc[v_ave_temp[\"v_ave_0\"].isnull() == True, \"v_ave_0\"] = v_ave_all\n    v_ave_temp.loc[v_ave_temp[\"v_ave_1\"].isnull() == True, \"v_ave_1\"] = v_ave_all\n    v_ave_temp.loc[v_ave_temp[\"v_ave_2\"].isnull() == True, \"v_ave_2\"] = v_ave_all\n    v_ave_temp.loc[v_ave_temp[\"v_ave_3\"].isnull() == True, \"v_ave_3\"] = v_ave_all\n    v_ave_temp.loc[v_ave_temp[\"v_ave_4\"].isnull() == True, \"v_ave_4\"] = v_ave_all\n    v_ave_temp.loc[v_ave_temp[\"v_ave_5\"].isnull() == True, \"v_ave_5\"] = v_ave_all\n    v_ave_temp.loc[v_ave_temp[\"v_ave_6\"].isnull() == True, \"v_ave_6\"] = v_ave_all\n    v_ave_temp.loc[v_ave_temp[\"v_ave_holiday\"].isnull() == True, \"v_ave_holiday\"] = v_ave_all\n    v_ave_temp\n    \n    v_ave = pd.concat([v_ave,v_ave_temp])\n\n#インデックス振りなおす\nv_ave = v_ave.reset_index(drop=True)\n# v_ave.loc[v_ave.air_store_id==110]\nv_ave","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 欠損地のあるindexを探してくる\nv_ave[pd.isnull(v_ave.v_ave_holiday)]\n# v_ave.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# データ型をint64に変更","metadata":{}},{"cell_type":"code","source":"v_ave[\"air_store_id\"] = v_ave.air_store_id.astype(\"int64\")\nv_ave[\"max_visitors\"] = v_ave.max_visitors.astype(\"int64\")\nv_ave[\"min_visitors\"] = v_ave.min_visitors.astype(\"int64\")\n\nv_ave","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 来店者数が多い曜日のindexを特徴量に入れる\n全ての行について、店舗で最も来店者数が多い曜日をindxで返す関数を使って、\n特徴量をtest_xに追加する","metadata":{}},{"cell_type":"markdown","source":"# 店舗ごとに、来店者数が多い曜日のindexをもつDataFrameを作成する\n全ての行について、店舗で最も来店者数が多い曜日をindxで返す関数を使って、\n特徴量をtest_xに追加する","metadata":{}},{"cell_type":"code","source":"def cal_max_ave_index(t):\n    air_store_id, id2 = t\n    #train_allから、来店者の数を算出する(testを含むとvisitors=0が入るのでtrain_allだけでやる)\n    id_0 = train_all.loc[train_all.air_store_id == air_store_id]\n    id_0_data = pd.DataFrame()\n    id_0_data[\"visitors\"] = id_0.visitors\n    id_0_data[\"day_of_the_week\"] = id_0.day_of_the_week\n    id_0_data = id_0_data.reset_index(drop=True)\n    id_0_data_ana = id_0_data.groupby(['day_of_the_week']).visitors.agg([sum,len])\n    id_0_data_ana[\"ave\"] = id_0_data_ana[\"sum\"] // id_0_data_ana[\"len\"]\n    max_ave_index = id_0_data_ana['ave'].idxmax()\n    return max_ave_index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 先に、air_store_id一覧を用意しておく","metadata":{}},{"cell_type":"code","source":"all_id = merge_data.air_store_id.unique()\nall_id = pd.DataFrame(all_id, columns=[\"air_store_id\"])\nall_id = all_id.sort_values(by='air_store_id', ascending=True)\nall_id = all_id.reset_index(drop=True)\nall_id[\"id2\"] = all_id[\"air_store_id\"] * 2\nall_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 平均来店者数の多い曜日(ピーク曜日)を調べる\nair_store_id一覧に、最も平均来店者数が多い曜日を追加する","metadata":{}},{"cell_type":"code","source":"%%time\nall_id.loc[:,\"max_ave_day\"] = all_id[[\"air_store_id\",\"id2\"]].apply(cal_max_ave_index, axis=1)\nall_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 店舗情報を利用する","metadata":{}},{"cell_type":"code","source":"air_store_info = pd.read_csv(\"../input/recruit-restaurant-visitor-forecasting-data/air_store_info.csv\")\n\nstore_le = pd.DataFrame()\nstore_le[\"air_store_id\"] = air_store_info.air_store_id\ngenre_le = pd.DataFrame()\ngenre_le[\"air_genre_name\"] = air_store_info.air_genre_name\narea_le = pd.DataFrame()\narea_le[\"air_area_name\"] = air_store_info.air_area_name\n\narea_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラベルエンコーディングで店舗のジャンルを分ける\n・store_id<br>\n・ジャンル<br>\n・エリア<br>\nに対してそれぞれラベルエンコーディングする","metadata":{}},{"cell_type":"code","source":"# store_idのラベルエンコーディング\nfor c in store_le:\n    store_le[c] = le.transform(store_le[c])\nstore_le\n\n# ジャンルのラベルエンコーディング\nfor c in genre_le:\n    le_g = LabelEncoder()\n    le_g.fit(genre_le[c])\n    genre_le[c] = le_g.transform(genre_le[c])\ngenre_le\n\nfor c in area_le:\n    le_a = LabelEncoder()\n    le_a.fit(area_le[c])\n    area_le[c] = le_a.transform(area_le[c])\narea_le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラベルエンコーディングした特徴量を結合\nこれで、店舗IDごとに座標、エリア、ジャンルが入ったDataframe「air_store_info」を得られる","metadata":{}},{"cell_type":"code","source":"air_store_info = air_store_info.drop(columns = \"air_store_id\")\nair_store_info = air_store_info.join(store_le)\nair_store_info = air_store_info.drop(columns = \"air_genre_name\")\nair_store_info = air_store_info.join(genre_le)\nair_store_info = air_store_info.drop(columns = \"air_area_name\")\nair_store_info = air_store_info.join(area_le)\n# 最も来店者の多い曜日情報と結合するためにソートしindexをつけなおす\nair_store_info = air_store_info.sort_values(by='air_store_id')\n# indexをつけなおす\nair_store_info = air_store_info.reset_index(drop=True)\nair_store_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 平均来客数の多い曜日(ピーク曜日)と結合する\n先に作成した、店舗ごとに最も平均来客数が多い曜日のDataFrame「all_id」と結合する","metadata":{}},{"cell_type":"code","source":"air_store_info = air_store_info.rename(columns={'air_store_id': 'air_store_id_info'})\nair_store_info = air_store_info.join(all_id)\nair_store_info","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# merge_dataに店舗情報を追加\nvlookupみたいな操作をする。参照して追加するみたいな<br>\nmerge_dataには、trainもtestも、xもyも全部含まれる<br>\nair_store_infoの店舗IDごとの情報を、各データに追加する","metadata":{}},{"cell_type":"code","source":"merge_data = merge_data.merge(air_store_info, on=\"air_store_id\",how=\"left\")\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 全てのIDを持つDataFrameを作成する","metadata":{}},{"cell_type":"code","source":"all_id_only = pd.DataFrame()\nall_id_only[\"id\"] = all_id.air_store_id\nall_id_only","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 前週の同じ曜日の来店者数を算出してlast_weekに持たせる\n前週の同じ曜日の来店者数を、店舗ごとに求める。<br>\n処理に30秒くらいかかる\n","metadata":{}},{"cell_type":"code","source":"%%time\nlast_week = pd.DataFrame()\n\n# for c in range(0,829,1):\nfor c in range(0, 829,1):\n    \n    last_week_0 = pd.DataFrame()\n    last_week_1 = pd.DataFrame()\n    last_week_2 = pd.DataFrame()\n    last_week_3 = pd.DataFrame()\n    last_week_4 = pd.DataFrame()\n    last_week_5 = pd.DataFrame()\n    last_week_6 = pd.DataFrame()\n    \n    store = merge_data.loc[merge_data.air_store_id == c]\n\n    store_d = store.loc[store.day_of_the_week == 0]\n    last_week_0[\"day_of_the_week\"] = store_d.day_of_the_week\n    last_week_0[\"today\"] = store_d.visitors\n    last_week_0[\"last_week\"] = store_d[\"visitors\"].shift(1)\n    # 欠損はその店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    last_week_0 = last_week_0.fillna(ave)\n    last_week = pd.concat([last_week, last_week_0])\n\n    store_d = store.loc[store.day_of_the_week == 1]\n    last_week_1[\"day_of_the_week\"] = store_d.day_of_the_week\n    last_week_1[\"today\"] = store_d.visitors\n    last_week_1[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    last_week_0 = last_week_0.fillna(ave)\n    last_week = pd.concat([last_week, last_week_1])\n\n    store_d = store.loc[store.day_of_the_week == 2]\n    last_week_2[\"day_of_the_week\"] = store_d.day_of_the_week\n    last_week_2[\"today\"] = store_d.visitors\n    last_week_2[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    last_week_0 = last_week_0.fillna(ave)\n    last_week = pd.concat([last_week, last_week_2])\n\n    store_d = store.loc[store.day_of_the_week == 3]\n    last_week_3[\"day_of_the_week\"] = store_d.day_of_the_week\n    last_week_3[\"today\"] = store_d.visitors\n    last_week_3[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    last_week_0 = last_week_0.fillna(ave)\n    last_week = pd.concat([last_week, last_week_3])\n\n    store_d = store.loc[store.day_of_the_week == 4]\n    last_week_4[\"day_of_the_week\"] = store_d.day_of_the_week\n    last_week_4[\"today\"] = store_d.visitors\n    last_week_4[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    last_week_0 = last_week_0.fillna(ave)\n    last_week = pd.concat([last_week, last_week_4])\n\n    store_d = store.loc[store.day_of_the_week == 5]\n    last_week_5[\"day_of_the_week\"] = store_d.day_of_the_week\n    last_week_5[\"today\"] = store_d.visitors\n    last_week_5[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    last_week_0 = last_week_0.fillna(ave)\n    last_week = pd.concat([last_week, last_week_5])\n\n    store_d = store.loc[store.day_of_the_week == 6]\n    last_week_6[\"day_of_the_week\"] = store_d.day_of_the_week\n    last_week_6[\"today\"] = store_d.visitors\n    last_week_6[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    last_week_0 = last_week_0.fillna(ave)\n    last_week = pd.concat([last_week, last_week_6])\n    \n\n\nlast_week = last_week.sort_index()\nlast_week","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_week.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# テストデータのvisitorsを埋める\n事前に予測しておく。visitors_pre_predを入れる","metadata":{}},{"cell_type":"code","source":"merge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_temp = merge_data.loc[merge_data.set == 'test']\ntest_temp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v_ave","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# v_aveで埋めていく","metadata":{}},{"cell_type":"code","source":"# for c in range(0,829,1):\n# for c in range(0,10,1):\n# waringがうるさいので、withの範囲内にあるものはワーニング出さないようにする\nimport warnings\nwarnings.resetwarnings()\nwith warnings.catch_warnings():\n    warnings.simplefilter('ignore')\n    test_visitors = pd.DataFrame()\n    for c in range(0,829,1):\n        test_temp_store = test_temp.loc[test_temp.air_store_id == c]\n        test_temp_store_0 = test_temp_store.loc[test_temp_store.day_of_the_week == 0]\n        test_temp_store_0[\"visitors\"] = v_ave.at[c,\"v_ave_0\"]\n        test_visitors = pd.concat([test_visitors, test_temp_store_0])\n\n        test_temp_store_1 = test_temp_store.loc[test_temp_store.day_of_the_week == 1]\n        test_temp_store_1[\"visitors\"] = v_ave.at[c,\"v_ave_1\"]\n        test_visitors = pd.concat([test_visitors, test_temp_store_1])\n        \n        test_temp_store_2 = test_temp_store.loc[test_temp_store.day_of_the_week == 2]\n        test_temp_store_2[\"visitors\"] = v_ave.at[c,\"v_ave_2\"]\n        test_visitors = pd.concat([test_visitors, test_temp_store_2])\n        \n        test_temp_store_3 = test_temp_store.loc[test_temp_store.day_of_the_week == 3]\n        test_temp_store_3[\"visitors\"] = v_ave.at[c,\"v_ave_3\"]\n        test_visitors = pd.concat([test_visitors, test_temp_store_3])\n\n        test_temp_store_4 = test_temp_store.loc[test_temp_store.day_of_the_week == 4]\n        test_temp_store_4[\"visitors\"] = v_ave.at[c,\"v_ave_4\"]\n        test_visitors = pd.concat([test_visitors, test_temp_store_4])\n        \n        test_temp_store_5 = test_temp_store.loc[test_temp_store.day_of_the_week == 5]\n        test_temp_store_5[\"visitors\"] = v_ave.at[c,\"v_ave_5\"]\n        test_visitors = pd.concat([test_visitors, test_temp_store_5])\n        \n        test_temp_store_6 = test_temp_store.loc[test_temp_store.day_of_the_week == 6]\n        test_temp_store_6[\"visitors\"] = v_ave.at[c,\"v_ave_6\"]\n        test_visitors = pd.concat([test_visitors, test_temp_store_6])\n\ntest_visitors = test_visitors.sort_index()\ntest_visitors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_visitors[[\"air_store_id\",\"day\",\"visitors\"]].tail(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# merge_dataに統合\ntestデータのvisitorsを、trainデータの店舗ごとの曜日ごと平均で与えてみる","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# 一応、直前のmerege_dataを補完\nmerge_data_temp = merge_data\n\n# train_tempとtest_visitorsを結合\n# 何も処理していないtrainデータと、visitorsを店舗の曜日ごとの平均で書き換えたtest_visitorsで書き換える\ntrain_temp = merge_data.loc[merge_data.set == 'train']\nmerge_data = pd.concat([train_temp, test_visitors])\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data.loc[merge_data.air_store_id == c]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラグ特徴量の追加\n 7,14,21日周期のラグ特徴量を算出してlag_allに持たせる","metadata":{}},{"cell_type":"code","source":"%%time\nstore_all_7 = pd.DataFrame()\nstore_all_3 = pd.DataFrame()\nstore_all_14 = pd.DataFrame()\nstore_all_21 = pd.DataFrame()\n\nfor c in range(0,829,1):\n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 7周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag7\"] = store[\"visitors\"].shift(0).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_7 = pd.concat([store_all_7, store])\n    \n    \n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 直近3日の平均\n    x_lag = pd.DataFrame()\n    x_lag[\"lag3\"] = store[\"visitors\"].shift(0).rolling(window=3).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_3 = pd.concat([store_all_3, store])\n\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 14周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag14\"] = store[\"visitors\"].shift(7).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_14 = pd.concat([store_all_14, store])\n    \n    # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n    store = merge_data.loc[merge_data.air_store_id == c]\n    # 21周期前のlagを取得\n    x_lag = pd.DataFrame()\n    x_lag[\"lag21\"] = store[\"visitors\"].shift(14).rolling(window=7).mean()\n    store = store.join(x_lag)\n    # 欠損値は、その店舗の平均来店者数で埋める\n    ave = store_visitors['ave'][c]\n    store = store.fillna(ave)\n    store_all_21 = pd.concat([store_all_21, store])\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# idでソートしなおす\nstore_all_7 = store_all_7.sort_index()\nstore_all_3 = store_all_3.sort_index()\nstore_all_14 = store_all_14.sort_index()\nstore_all_21 = store_all_21.sort_index()\n# ラグ特徴量を結合してlag_all\nlag_all = pd.DataFrame()\nlag_all[\"lag7\"] = store_all_7.lag7\nlag_all[\"lag3\"] = store_all_3.lag3\nlag_all[\"lag14\"] = store_all_14.lag14\nlag_all[\"lag21\"] = store_all_21.lag21\nlag_all.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ラグ特徴量をmerge_dataに追加","metadata":{}},{"cell_type":"code","source":"merge_data = merge_data.join(lag_all)\nmerge_data = merge_data.join(last_week, rsuffix='_last')\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckm = merge_data.loc[merge_data.set == \"test\"]\nckm.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckm[['air_store_id', 'visitors', \"month\", \"day\",\"set\",\"lag7\",\"lag14\",\"lag21\"]].tail(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 各店舗の来店者数情報も追加\nv_aveで算出した、各店舗の情報を追加","metadata":{}},{"cell_type":"code","source":"merge_data = merge_data.merge(v_ave, on=\"air_store_id\",how=\"left\")\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# リークする危険があるのでか必ずtodayをdropして消す\nmerge_data = merge_data.drop(columns='today')\nmerge_data = merge_data.drop(columns='day_of_the_week_last')\nmerge_data = merge_data.drop(columns='id2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 全期間のデータをmerge_data_allとして残す","metadata":{}},{"cell_type":"code","source":"#期間短くする前のmerge_dataは、merge_data_all(全期間のデータ)として残す\nmerge_data_all = merge_data\nmerge_data_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge_data_allへはここで修復できる\nmerge_data = merge_data_all\nmerge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学習を早くするために、データを絞る\nデータ量が多く、xgboostの学習に30minかかるので、2017年4月-5月だけにデータを絞る。<br>\n28万行→4.7万行に減らせる。トレーニングデータの数で言えば、25.5万→2.2万<br><br>\n【学習データを絞らない場合は、ここをコメントアウト】","metadata":{}},{"cell_type":"code","source":"# #2017年の3-5月のデータだけを使う\n# merge_data = merge_data.loc[(merge_data.year == 2017)]\n# merge_data = merge_data.loc[(merge_data.month == 1)\n#                             | (merge_data.month == 2)\n#                             | (merge_data.month == 3)\n#                             | (merge_data.month == 4)\n#                             | (merge_data.month == 5)]\n# merge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4/1-4/22までをvalidationデータとする\n4/23以降はテストデータ","metadata":{}},{"cell_type":"code","source":"# merge_data.loc[(merge_data['month'] == 4) & (merge_data['day'] <= 22), 'set'] = 'va'\n# merge_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_data.loc[merge_data.set == \"va\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 特徴量を落としてみる\n意味のある特徴量、ない特徴量を整理したい(基本的に全部あった方がいい認識だが)\n* ラグ特徴量lag7-21をとらないだけでRMSLEが1.10→1.57に下がった\n","metadata":{}},{"cell_type":"code","source":"# merge_data = merge_data.drop(columns=\"lag7\")\n# merge_data = merge_data.drop(columns=\"lag14\")\n# merge_data = merge_data.drop(columns=\"lag21\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 以上で、特徴量エンジニアリングは終了\n\n# データをtrain_fitとtest_fitに分割する\nmodel学習に使うデータとして分割する。\n来店者数が0より以上の場合、trainデータとして認識する","metadata":{}},{"cell_type":"code","source":"train_fit = pd.DataFrame()\ntrain_fit = merge_data.loc[merge_data.set == \"train\"]\ntrain_fit_y = pd.DataFrame()\ntrain_fit_y[\"visitors\"] = train_fit.visitors\ntrain_fit_x = train_fit.drop(columns=\"visitors\")\ntrain_fit_x = train_fit_x.drop(columns=\"set\")\n\ntest_fit = pd.DataFrame()\ntest_fit = merge_data.loc[merge_data.set == \"test\"]\ntest_fit_x = test_fit.drop(columns=\"visitors\")\ntest_fit_x = test_fit_x.drop(columns=\"set\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit = pd.DataFrame()\nva_fit = merge_data.loc[merge_data.set == \"va\"]\nva_fit_y = pd.DataFrame()\nva_fit_y[\"visitors\"] = va_fit.visitors\nva_fit_x = va_fit.drop(columns=\"visitors\")\nva_fit_x = va_fit_x.drop(columns=\"set\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fit_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fit_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_fit_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_fit_x[[\"air_store_id\",\"day_of_the_week\",\"day\",\"lag7\",\"lag14\",\"lag21\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# xgbのパラメータを決定","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier as XGB\nfrom sklearn.metrics import mean_squared_log_error\n\nModel = XGB(n_estimators=100, random_state=71,max_depth=4,colsample_bylevel=0.4,\n           gamma=0.0,alpha=0.0, min_child_weight=4,subsample=0.8,colsample_bytree=0.95\n           )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# モデル学習して予測、RMSLEを算出\n* xgboostで学習させる\n* 4月(validationデータ)のvisitorsをhold-outで予測\n* RMSLEを計算する","metadata":{}},{"cell_type":"code","source":"%%time\nModel.fit(train_fit_x, train_fit_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# hold-outでのvalidationデータの予測\n時系列的にうしろのデータを使って単純なバリデーション<br>\nバリデーションデータない場合はコメントアウト","metadata":{}},{"cell_type":"code","source":"# # モデルで予測する\n# pred = Model.predict(va_fit_x)\n\n# # 予測値からRMSLEを算出する\n# score = np.sqrt(mean_squared_log_error(va_fit_y, pred))\n# print(\"---------------RMSLE-score----------------\")\n# score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# テストデータの予測","metadata":{}},{"cell_type":"code","source":"pred_test = Model.predict(test_fit_x)\npred_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 店舗110と663は、全て0で埋める\nと思ったが、testデータ中に110,663は存在しないらいい","metadata":{}},{"cell_type":"code","source":"# submission_fill0 = pd.DataFrame()\n# submission_fill0[\"visitors\"] = pred\n# test_fit_x_reindex = test_fit_x.reset_index()\n# submission_fill0 = submission_fill0.join(test_fit_x_reindex[\"air_store_id\"])\n\n# submission_fill0.loc[submission_fill0['air_store_id'] == 663, 'visitors'] = 0\n# submission_fill0.loc[submission_fill0.air_store_id == 663]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 提出データの作成","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"id\"] = test.id\nsubmission[\"visitors\"] = pred_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission_21.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 来店者平均値から算出\ntest_fit_xのラグ特徴量を計算するために入れたvisitorsの値をそのまま出力する。<br>\n3-4月の曜日ごとの来店者数の平均をとってtestデータに当てはめると、<br>\nPriveateで0.55572のスコアが得られる","metadata":{}},{"cell_type":"code","source":"submission_ave = pd.DataFrame()\ntest_visitors_reindex = pd.DataFrame()\nsubmission_ave[\"id\"] = test.id\ntest_visitors_reindex = test_visitors.reset_index(drop=True)\nsubmission_ave[\"visitors\"] = test_visitors_reindex.visitors\nsubmission_ave","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_ave.to_csv(\"submission_test_v.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_v","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 予測データと実際のデータを比較するデータフレームを作る","metadata":{}},{"cell_type":"code","source":"compare_v = va_fit_x\ncompare_v = compare_v.join(va_fit_y)\ncompare_v_reindex = compare_v.reset_index(drop=True)\npred_v[\"visitors_pred\"] = pd.DataFrame(pred)\ncompare_v_reindex = compare_v_reindex.join(pred_v)\ncompare_v_reindex[\"delta\"] = compare_v_reindex[\"visitors_pred\"] - compare_v_reindex[\"visitors\"]\ncompare_v_reindex[\"delta_abs\"] = abs(compare_v_reindex[\"delta\"])\nck = compare_v_reindex[[\"air_store_id\",\"month\",\"day\",\"day_of_the_week\",\"visitors_pred\",\"visitors\",\"delta\",\"delta_abs\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 誤差の大きいデータを表示する","metadata":{}},{"cell_type":"code","source":"ck_bad = ck.sort_values(by='delta_abs', ascending=False).head(100)\nck_bad.sort_values(by='air_store_id', ascending=False).tail(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(\n    ck_bad['visitors'], bins=100, color='#123456', label='data',\n    kde=False,\n    rug=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ID=453の店舗の来店者数の経緯を見る","metadata":{}},{"cell_type":"code","source":"visitor_453 = merge_data.loc[merge_data.air_store_id == 453]\nvisitor_453 = visitor_453[[\"air_store_id\",\"month\",\"day\",\"day_of_the_week\",\"visitors\"]]\nvisitor_453 = visitor_453.reset_index()\nvisitor_453 = visitor_453.drop(columns = \"index\")\nvisitor_453 = visitor_453.reset_index()\nvisitor_453","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x=\"index\", y=\"visitors\", data=visitor_453)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 各曜日で来店者数の情報を表示","metadata":{}},{"cell_type":"code","source":"visitor_453.loc[visitor_453.day_of_the_week == 6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visitor_371 = merge_data.loc[merge_data.air_store_id == 371]\nvisitor_371 = visitor_371[[\"air_store_id\",\"month\",\"day\",\"day_of_the_week\",\"visitors\"]]\nvisitor_371 = visitor_371.reset_index()\nvisitor_371 = visitor_371.drop(columns = \"index\")\nvisitor_371 = visitor_371.reset_index()\nvisitor_371","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x=\"index\", y=\"visitors\", data=visitor_371)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visitor_371.loc[visitor_371.day_of_the_week == 4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 可視化する","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=va_fit_y['visitors'], y=pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column = [\"visitors_pred\"]\npred_d = pd.DataFrame(pred, columns=column)\npred_d","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_d[pd.isnull(pred_d.visitors_pred)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_fit_y_reset = va_fit_y.reset_index()\nva_df = va_fit_x.reset_index()\nva_df = va_df.join(va_fit_y_reset,lsuffix='_y')\nva_df = va_df.join(pred_d)\nva_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_df[\"delta\"] = va_df[\"visitors\"] - va_df[\"visitors_pred\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"va_df = va_df.drop(columns = \"index_y\")\nva_df = va_df.drop(columns = \"air_store_id_info\")\nva_df.head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot = sns.scatterplot(x=va_df['visitors'], y=va_df[\"visitors_pred\"])\nplot = sns.scatterplot(x=va_df['visitors'], y=va_df[\"visitors\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=va_df['visitors'], y=va_df[\"delta\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4月の来店者数を予測する\nまず、4月の来店者数を予測する。","metadata":{}},{"cell_type":"code","source":"%%time\n\nfor n in range(23, 31, 1):\n    \n    # 特定の日付について、予測値をtest_predに追加する\n    test_pred = test_fit_x.loc[(test_fit_x.month == 4) & (test_fit_x.day == n)]\n    pred = Model.predict(test_pred)\n    test_pred[\"visitors\"] = pred\n    test_pred_0 = pd.DataFrame()\n    test_pred_0[\"visitors_predict\"] = test_pred.visitors\n\n    # visitors_predictをmerge_dataに結合する\n    merge_data = merge_data.merge(test_pred_0, left_index = True, right_index = True, how=\"left\")\n\n    # 追加した、visitors_predictのうち、NaNじゃない列は、visitorsの値にvisitors_predictの値を代入する\n    merge_data['visitors'] = merge_data['visitors'].where(merge_data['visitors_predict'].isnull() == True, merge_data['visitors_predict'])\n\n    # その後、visitors_predictは削除する\n    merge_data = merge_data.drop(columns =\"visitors_predict\")\n\n    # 2017年4月以降のデータで、テストデータのラグ特徴量を再度計算する\n    merge_data_trim = merge_data.loc[(merge_data.month >= 4) & (merge_data.year == 2017)]\n\n    # 既にある特徴量は一旦削除する\n    merge_data_trim = merge_data_trim.drop(['lag7', 'lag14', 'lag21', 'last_week'], axis=1)\n\n    # 前週の同じ曜日の来店者数を取得する\n    last_week = pd.DataFrame()\n\n    # for c in range(0,829,1):\n    for c in range(0, 829,1):\n\n        last_week_0 = pd.DataFrame()\n        last_week_1 = pd.DataFrame()\n        last_week_2 = pd.DataFrame()\n        last_week_3 = pd.DataFrame()\n        last_week_4 = pd.DataFrame()\n        last_week_5 = pd.DataFrame()\n        last_week_6 = pd.DataFrame()\n\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n\n        store_d = store.loc[store.day_of_the_week == 0]\n        last_week_0[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_0[\"today\"] = store_d.visitors\n        last_week_0[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_0])\n\n        store_d = store.loc[store.day_of_the_week == 1]\n        last_week_1[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_1[\"today\"] = store_d.visitors\n        last_week_1[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_1])\n\n        store_d = store.loc[store.day_of_the_week == 2]\n        last_week_2[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_2[\"today\"] = store_d.visitors\n        last_week_2[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_2])\n\n        store_d = store.loc[store.day_of_the_week == 3]\n        last_week_3[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_3[\"today\"] = store_d.visitors\n        last_week_3[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_3])\n\n        store_d = store.loc[store.day_of_the_week == 4]\n        last_week_4[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_4[\"today\"] = store_d.visitors\n        last_week_4[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_4])\n\n        store_d = store.loc[store.day_of_the_week == 5]\n        last_week_5[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_5[\"today\"] = store_d.visitors\n        last_week_5[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_5])\n\n        store_d = store.loc[store.day_of_the_week == 6]\n        last_week_6[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_6[\"today\"] = store_d.visitors\n        last_week_6[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_6])\n\n    last_week = last_week.sort_index()\n\n    # 7,14,21日のラグ特徴量を取得する\n    store_all_7 = pd.DataFrame()\n    store_all_14 = pd.DataFrame()\n    store_all_21 = pd.DataFrame()\n\n    for c in range(0,829,1):\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 7周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag7\"] = store[\"visitors\"].shift(0).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_7 = pd.concat([store_all_7, store])\n\n\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 14周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag14\"] = store[\"visitors\"].shift(7).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_14 = pd.concat([store_all_14, store])\n\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 21周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag21\"] = store[\"visitors\"].shift(14).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_21 = pd.concat([store_all_21, store])\n\n    # idでソートしなおす\n    store_all_7 = store_all_7.sort_index()\n    store_all_14 = store_all_14.sort_index()\n    store_all_21 = store_all_21.sort_index()\n    # ラグ特徴量を結合してlag_all\n    lag_all = pd.DataFrame()\n    lag_all[\"lag7\"] = store_all_7.lag7\n    lag_all[\"lag14\"] = store_all_14.lag14\n    lag_all[\"lag21\"] = store_all_21.lag21\n\n    # 特徴量を追加する\n    merge_data_trim = merge_data_trim.join(lag_all)\n    merge_data_trim = merge_data_trim.join(last_week, rsuffix='_last')\n    \n    # 予測した値を残して、ループ処理後に参照できるようにする\n    pred_visitors_all = merge_data_trim.loc[:,[\"air_store_id\",\"month\",\"day\", 'visitors','last_week']]\n\n    # リークする危険があるのでか必ずtodayをdropして消す\n    merge_data_trim = merge_data_trim.drop(columns='today')\n    merge_data_trim = merge_data_trim.drop(columns='visitors')\n    merge_data_trim = merge_data_trim.drop(columns='day_of_the_week_last')\n    \n\n    # test_fit_xを初期化する\n    test_fit_x = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n\n    #　テストデータのみ切り分けて、次の予測に用いる\n    test_fit_x = merge_data_trim.loc[merge_data_trim.set == \"test\"]\n    test_fit_x = test_fit_x.drop(columns='set')\n    \nprint(\"done\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5月のデータを予測する(private_leaderboardと思われる)\n基本的に、4月と同じモデルで予測する","metadata":{}},{"cell_type":"code","source":"%%time\n\nfor n in range(1, 32, 1):\n    \n    # 特定の日付について、予測値をtest_predに追加する\n    test_pred = test_fit_x.loc[(test_fit_x.month == 5) & (test_fit_x.day == n)]\n    pred = Model.predict(test_pred)\n    test_pred[\"visitors\"] = pred\n    test_pred_0 = pd.DataFrame()\n    test_pred_0[\"visitors_predict\"] = test_pred.visitors\n\n    # visitors_predictをmerge_dataに結合する\n    merge_data = merge_data.merge(test_pred_0, left_index = True, right_index = True, how=\"left\")\n\n    # 追加した、visitors_predictのうち、NaNじゃない列は、visitorsの値にvisitors_predictの値を代入する\n    merge_data['visitors'] = merge_data['visitors'].where(merge_data['visitors_predict'].isnull() == True, merge_data['visitors_predict'])\n\n    # その後、visitors_predictは削除する\n    merge_data = merge_data.drop(columns =\"visitors_predict\")\n\n    # 2017年4月以降のデータで、テストデータのラグ特徴量を再度計算する\n    merge_data_trim = merge_data.loc[(merge_data.month >= 4) & (merge_data.year == 2017)]\n\n    # 既にある特徴量は一旦削除する\n    merge_data_trim = merge_data_trim.drop(['lag7', 'lag14', 'lag21', 'last_week'], axis=1)\n\n    # 前週の同じ曜日の来店者数を取得する\n    last_week = pd.DataFrame()\n\n    # for c in range(0,829,1):\n    for c in range(0, 829,1):\n\n        last_week_0 = pd.DataFrame()\n        last_week_1 = pd.DataFrame()\n        last_week_2 = pd.DataFrame()\n        last_week_3 = pd.DataFrame()\n        last_week_4 = pd.DataFrame()\n        last_week_5 = pd.DataFrame()\n        last_week_6 = pd.DataFrame()\n\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n\n        store_d = store.loc[store.day_of_the_week == 0]\n        last_week_0[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_0[\"today\"] = store_d.visitors\n        last_week_0[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_0])\n\n        store_d = store.loc[store.day_of_the_week == 1]\n        last_week_1[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_1[\"today\"] = store_d.visitors\n        last_week_1[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_1])\n\n        store_d = store.loc[store.day_of_the_week == 2]\n        last_week_2[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_2[\"today\"] = store_d.visitors\n        last_week_2[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_2])\n\n        store_d = store.loc[store.day_of_the_week == 3]\n        last_week_3[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_3[\"today\"] = store_d.visitors\n        last_week_3[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_3])\n\n        store_d = store.loc[store.day_of_the_week == 4]\n        last_week_4[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_4[\"today\"] = store_d.visitors\n        last_week_4[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_4])\n\n        store_d = store.loc[store.day_of_the_week == 5]\n        last_week_5[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_5[\"today\"] = store_d.visitors\n        last_week_5[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_5])\n\n        store_d = store.loc[store.day_of_the_week == 6]\n        last_week_6[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_6[\"today\"] = store_d.visitors\n        last_week_6[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_6])\n\n    last_week = last_week.sort_index()\n\n    # 7,14,21日のラグ特徴量を取得する\n    store_all_7 = pd.DataFrame()\n    store_all_14 = pd.DataFrame()\n    store_all_21 = pd.DataFrame()\n\n    for c in range(0,829,1):\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 7周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag7\"] = store[\"visitors\"].shift(0).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_7 = pd.concat([store_all_7, store])\n\n\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 14周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag14\"] = store[\"visitors\"].shift(7).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_14 = pd.concat([store_all_14, store])\n\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 21周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag21\"] = store[\"visitors\"].shift(14).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_21 = pd.concat([store_all_21, store])\n\n    # idでソートしなおす\n    store_all_7 = store_all_7.sort_index()\n    store_all_14 = store_all_14.sort_index()\n    store_all_21 = store_all_21.sort_index()\n    # ラグ特徴量を結合してlag_all\n    lag_all = pd.DataFrame()\n    lag_all[\"lag7\"] = store_all_7.lag7\n    lag_all[\"lag14\"] = store_all_14.lag14\n    lag_all[\"lag21\"] = store_all_21.lag21\n\n    # 特徴量を追加する\n    merge_data_trim = merge_data_trim.join(lag_all)\n    merge_data_trim = merge_data_trim.join(last_week, rsuffix='_last')\n    \n    # 予測した値を残して、ループ処理後に参照できるようにする\n    pred_visitors_all = merge_data_trim.loc[:,[\"set\", \"air_store_id\",\"month\",\"day\", 'visitors','last_week']]\n\n    # リークする危険があるのでか必ずtodayをdropして消す\n    merge_data_trim = merge_data_trim.drop(columns='today')\n    merge_data_trim = merge_data_trim.drop(columns='visitors')\n    merge_data_trim = merge_data_trim.drop(columns='day_of_the_week_last')\n    \n\n    # test_fit_xを初期化する\n    test_fit_x = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n\n    #　テストデータのみ切り分けて、次の予測に用いる\n    test_fit_x = merge_data_trim.loc[merge_data_trim.set == \"test\"]\n    test_fit_x = test_fit_x.drop(columns='set')\n    \nprint(\"done\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = pred_visitors_all.loc[(pred_visitors_all.set == \"test\")]\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 提出データを用意する\nsubmissionデータの判定にためには、columns名「visitors」が入っている必要がある","metadata":{}},{"cell_type":"code","source":"%%time\n\nfor n in range(23, 31, 1):\n    \n    # 特定の日付について、予測値をtest_predに追加する\n    test_pred = test_fit_x.loc[(test_fit_x.month == 4) & (test_fit_x.day == n)]\n    pred = Model.predict(test_pred)\n    test_pred[\"visitors\"] = pred\n    test_pred_0 = pd.DataFrame()\n    test_pred_0[\"visitors_predict\"] = test_pred.visitors\n\n    # visitors_predictをmerge_dataに結合する\n    merge_data = merge_data.merge(test_pred_0, left_index = True, right_index = True, how=\"left\")\n\n    # 追加した、visitors_predictのうち、NaNじゃない列は、visitorsの値にvisitors_predictの値を代入する\n    merge_data['visitors'] = merge_data['visitors'].where(merge_data['visitors_predict'].isnull() == True, merge_data['visitors_predict'])\n\n    # その後、visitors_predictは削除する\n    merge_data = merge_data.drop(columns =\"visitors_predict\")\n\n    # 2017年4月以降のデータで、テストデータのラグ特徴量を再度計算する\n    merge_data_trim = merge_data.loc[(merge_data.month >= 4) & (merge_data.year == 2017)]\n\n    # 既にある特徴量は一旦削除する\n    merge_data_trim = merge_data_trim.drop(['lag7', 'lag14', 'lag21', 'last_week'], axis=1)\n\n    # 前週の同じ曜日の来店者数を取得する\n    last_week = pd.DataFrame()\n\n    # for c in range(0,829,1):\n    for c in range(0, 829,1):\n\n        last_week_0 = pd.DataFrame()\n        last_week_1 = pd.DataFrame()\n        last_week_2 = pd.DataFrame()\n        last_week_3 = pd.DataFrame()\n        last_week_4 = pd.DataFrame()\n        last_week_5 = pd.DataFrame()\n        last_week_6 = pd.DataFrame()\n\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n\n        store_d = store.loc[store.day_of_the_week == 0]\n        last_week_0[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_0[\"today\"] = store_d.visitors\n        last_week_0[\"last_week\"] = store_d[\"visitors\"].shift(1)\n        # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_0])\n\n        store_d = store.loc[store.day_of_the_week == 1]\n        last_week_1[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_1[\"today\"] = store_d.visitors\n        last_week_1[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_1])\n\n        store_d = store.loc[store.day_of_the_week == 2]\n        last_week_2[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_2[\"today\"] = store_d.visitors\n        last_week_2[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_2])\n\n        store_d = store.loc[store.day_of_the_week == 3]\n        last_week_3[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_3[\"today\"] = store_d.visitors\n        last_week_3[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_3])\n\n        store_d = store.loc[store.day_of_the_week == 4]\n        last_week_4[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_4[\"today\"] = store_d.visitors\n        last_week_4[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_4])\n\n        store_d = store.loc[store.day_of_the_week == 5]\n        last_week_5[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_5[\"today\"] = store_d.visitors\n        last_week_5[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_5])\n\n        store_d = store.loc[store.day_of_the_week == 6]\n        last_week_6[\"day_of_the_week\"] = store_d.day_of_the_week\n        last_week_6[\"today\"] = store_d.visitors\n        last_week_6[\"last_week\"] = store_d[\"visitors\"].shift(1)\n            # 欠損はその店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        last_week_0 = last_week_0.fillna(ave)\n        last_week = pd.concat([last_week, last_week_6])\n\n    last_week = last_week.sort_index()\n\n    # 7,14,21日のラグ特徴量を取得する\n    store_all_7 = pd.DataFrame()\n    store_all_14 = pd.DataFrame()\n    store_all_21 = pd.DataFrame()\n\n    for c in range(0,829,1):\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 7周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag7\"] = store[\"visitors\"].shift(0).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_7 = pd.concat([store_all_7, store])\n\n\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 14周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag14\"] = store[\"visitors\"].shift(7).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_14 = pd.concat([store_all_14, store])\n\n        # cで指定した店舗idを持つDataFrameを拾ってくる(店舗別にラグ特徴量を得るために)\n        store = merge_data_trim.loc[merge_data_trim.air_store_id == c]\n        # 21周期前のlagを取得\n        x_lag = pd.DataFrame()\n        x_lag[\"lag21\"] = store[\"visitors\"].shift(14).rolling(window=7).mean()\n        store = store.join(x_lag)\n        # 欠損値は、その店舗の平均来店者数で埋める\n        ave = store_visitors['ave'][c]\n        store = store.fillna(ave)\n        store_all_21 = pd.concat([store_all_21, store])\n\n    # idでソートしなおす\n    store_all_7 = store_all_7.sort_index()\n    store_all_14 = store_all_14.sort_index()\n    store_all_21 = store_all_21.sort_index()\n    # ラグ特徴量を結合してlag_all\n    lag_all = pd.DataFrame()\n    lag_all[\"lag7\"] = store_all_7.lag7\n    lag_all[\"lag14\"] = store_all_14.lag14\n    lag_all[\"lag21\"] = store_all_21.lag21\n\n    # 特徴量を追加する\n    merge_data_trim = merge_data_trim.join(lag_all)\n    merge_data_trim = merge_data_trim.join(last_week, rsuffix='_last')\n    \n    # 予測した値を残して、ループ処理後に参照できるようにする\n    pred_visitors_all = merge_data_trim.loc[:,[\"air_store_id\",\"month\",\"day\", 'visitors','last_week']]\n\n    # リークする危険があるのでか必ずtodayをdropして消す\n    merge_data_trim = merge_data_trim.drop(columns='today')\n    merge_data_trim = merge_data_trim.drop(columns='visitors')\n    merge_data_trim = merge_data_trim.drop(columns='day_of_the_week_last')\n    \n\n    # test_fit_xを初期化する\n    test_fit_x = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n\n    #　テストデータのみ切り分けて、次の予測に用いる\n    test_fit_x = merge_data_trim.loc[merge_data_trim.set == \"test\"]\n    test_fit_x = test_fit_x.drop(columns='set')\n    \nprint(\"done\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# indexでソートする\npred = pred.sort_index()\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = pred.reset_index(drop=True)\npred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x_enc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_visitors_all.visitors\nsubmission_ck = test_x_enc\nsubmission_ck = submission_ck.join(pred.visitors)\nsubmission_ck = submission_ck.join(pred.air_store_id, lsuffix='_pred')\nsubmission_ck\n# submission.at[252108,\"visitors\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=submission_ck['air_store_id_pred'], y=submission_ck['air_store_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"id\"] = test.id\nsubmission[\"visitors\"] = submission_ck.visitors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({\"id\":test[\"id\"], \"visitors\": pred})\n# submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 提出用データの作成","metadata":{}},{"cell_type":"code","source":"submission.to_csv(\"submission_13.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 提出用データのダウンロード\n提出用データをダウンロードする<br>\nデータフレームの情報があれば、ダウンロードリンクを作成できる。","metadata":{}},{"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"submission.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe\ncreate_download_link(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 提出したデータを読み込む","metadata":{}},{"cell_type":"code","source":"submit = pd.read_csv(\"/kaggle/working/submission_05.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 提出したデータと、予測に使ったデータを結合する","metadata":{}}]}