{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Counting values in the Attributes","metadata":{}},{"cell_type":"code","source":"df[\"anaemia\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"diabetes\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"high_blood_pressure\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"sex\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"smoking\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"DEATH_EVENT\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Describing the dataset","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist(bins=50, figsize=(20, 15))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the dataset for training and testing purpose","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_set, test_set  = train_test_split(df, test_size=0.2, random_state=42)\nprint(f\"Rows in train set: {len(train_set)}\\nRows in test set: {len(test_set)}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the dataset in unbiased form","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(df, df['smoking']):\n    strat_train_set = df.loc[train_index]\n    strat_test_set = df.loc[test_index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strat_test_set['smoking'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"41/19","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strat_train_set['smoking'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"162/77","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitted_df = strat_train_set.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking Correlation between dependent and independent Variables","metadata":{}},{"cell_type":"code","source":"corr_matrix = splitted_df.corr()\ncorr_matrix['DEATH_EVENT'].sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nattributes = [\"DEATH_EVENT\", \"serum_creatinine\", \"age\", \"high_blood_pressure\",\"anaemia\"]\nscatter_matrix(splitted_df[attributes], figsize = (20,15))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitted_df.plot(kind=\"scatter\", y=\"serum_creatinine\", x=\"DEATH_EVENT\", alpha=0.8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.boxplot(y=\"age\", x=\"DEATH_EVENT\", data=splitted_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(y=\"anaemia\", data=splitted_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Eliminating the target Attribute","metadata":{}},{"cell_type":"code","source":"splitted_df = strat_train_set.drop(\"DEATH_EVENT\", axis=1)\nsplitted_df_labels = strat_train_set[\"DEATH_EVENT\"].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Pipeline","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nmy_pipeline = Pipeline([\n    #     ..... add as many as you want in your pipeline\n    ('std_scaler', StandardScaler()),\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitted_df_pipeline = my_pipeline.fit_transform(splitted_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model using Support Vector Machine","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(kernel = \"linear\",random_state=42)\nsvc_model = svc.fit(splitted_df_pipeline,splitted_df_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"some_data = splitted_df.iloc[:5]\nsome_labels = splitted_df_labels.iloc[:5]\nprepared_data = my_pipeline.transform(some_data)\nsvc_model.predict(prepared_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(some_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\nprint(\"confusion matrix:  \\n\",confusion_matrix(splitted_df_labels,svc_model.predict(splitted_df_pipeline)))\nprint(\"=\"*100)\nprint(\"f1-score: \",f1_score(splitted_df_labels,svc_model.predict(splitted_df_pipeline)))\nprint(\"=\"*100)\nprint(\"Accuracy:  \",accuracy_score(splitted_df_labels,svc_model.predict(splitted_df_pipeline)))\nprint(\"=\"*100)\nprint(\"Classification Report:  \\n\",classification_report(splitted_df_labels,svc_model.predict(splitted_df_pipeline)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using better evaluation technique - Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(svc_model, splitted_df_pipeline, splitted_df_labels, scoring=\"accuracy\", cv=5)\nprint(\"Avg Score:  \",scores.mean(),\"\\n\",\"Std deviation:  \",scores.std())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the model on test data","metadata":{}},{"cell_type":"code","source":"x_test = strat_test_set.drop(\"DEATH_EVENT\",axis=1)\ny_test = strat_test_set[\"DEATH_EVENT\"].copy()\nx_test_prepared = my_pipeline.transform(x_test)\nfinal_predictions = svc_model.predict(x_test_prepared)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"confusion matrix:  \\n\",confusion_matrix(y_test,final_predictions))\nprint(\"=\"*100)\nprint(\"f1-score: \",f1_score(y_test,final_predictions))\nprint(\"=\"*100)\nprint(\"Accuracy:  \",accuracy_score(y_test,final_predictions))\nprint(\"=\"*100)\nprint(\"Classification Report:  \\n\",classification_report(y_test,final_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_scores = cross_val_score(svc_model, x_test_prepared, y_test, scoring=\"accuracy\", cv=3)\nprint(\"Avg Score:  \",test_scores.mean(),\"\\n\",\"Std deviation:  \",test_scores.std())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{}},{"cell_type":"code","source":"from joblib import dump, load\ndump(svc_model, 'HealthFailurePrediction.joblib') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}