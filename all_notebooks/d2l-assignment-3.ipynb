{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as tfsm\nimport torchvision.models as models\n\nfrom pathlib import Path\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm.notebook import tqdm, trange","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_images_df(IMG_DIR):\n    df_list = []\n    for class_dir in list(IMG_DIR.iterdir()):\n        class_name = class_dir.name\n        all_images = list(class_dir.iterdir())\n        for img in all_images:\n            df_list.append([str(img), class_name])\n    df = pd.DataFrame(df_list, columns=[\"img_path\",\"class\"])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = Path('/kaggle/input/100-bird-species')\n\nVALID_DIR = BASE_DIR/'valid'\nTRAIN_DIR = BASE_DIR/'train'\nTEST_DIR = BASE_DIR/'test'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = get_images_df(TRAIN_DIR)\nvalid_df = get_images_df(VALID_DIR)\ntest_df = get_images_df(TEST_DIR)\n\nclass2idx = {x:i for i, x in enumerate(list(train_df['class'].unique()))}\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Bird Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BirdDataset(Dataset):\n    \n    def __init__(self, images_df, class2idx, transforms = None):\n        \n        super().__init__()\n        self.images_df = images_df\n        self.class2idx = class2idx\n        self.transforms = transforms\n        self.idx2class = {v:k for k, v in class2idx.items()}\n        \n    def __getitem__(self, index):\n    \n        image_path = self.images_df.iloc[index]['img_path']\n        image_class = self.images_df.iloc[index]['class']\n        \n        #Reading image\n        image = Image.open(image_path)\n\n        label = self.class2idx[image_class]\n        \n        #Applying transforms on image\n        if self.transforms:\n            image = self.transforms(image)\n        \n        return image, label\n        \n        \n        \n    def __len__(self):\n        return len(self.images_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_transform(train=False):\n    if train:\n        transforms = [tfsm.ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4),\n                      tfsm.RandomHorizontalFlip(),\n                      tfsm.RandomVerticalFlip(),\n                      tfsm.RandomRotation(2.8),\n                      tfsm.ToTensor(),\n                      tfsm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                      ]\n    else:\n        transforms = [tfsm.ToTensor(),\n                      tfsm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                      ]\n        \n    return tfsm.Compose(transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://www.kaggle.com/jainamshah17/pytorch-starter-image-classification\ndef calc_accuracy(true,pred):\n    pred = F.softmax(pred, dim = 1)\n    true = torch.zeros(pred.shape[0], pred.shape[1]).scatter_(1, true.unsqueeze(1), 1.)\n    acc = (true.argmax(-1) == pred.argmax(-1)).float().detach().numpy()\n    acc = float((100 * acc.sum()) / len(acc))\n    return round(acc, 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shared_step(batch, model, device, optimizer, criterion, phase='Train'):\n    images , labels = batch\n    images , labels = images.to(device) , labels.to(device)\n    if phase=='Train':\n        preds = model(images)\n    else:\n        with torch.no_grad():\n            preds = model(images)\n    loss = criterion(preds, labels)\n\n    if phase=='Train':\n        loss.backward()\n        optimizer.step()\n        \n    acc = calc_accuracy(labels.cpu(), preds.cpu())\n    loss_value = loss.item()\n    \n    return loss_value, acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_epoch(model, train_dl, valid_dl, device, optimizer, criterion, print_every=500):\n    #Epoch Loss & Accuracy\n    train_epoch_loss = []\n    train_epoch_accuracy = []\n    _iter = 1\n    \n    #Val Loss & Accuracy\n    val_epoch_loss = []\n    val_epoch_accuracy = []\n    \n    # training phase\n    model.train()\n    for batch in train_dl:\n        train_loss, train_acc =  shared_step(batch, model, device, optimizer, criterion, phase='Train')\n        \n        train_epoch_loss.append(train_loss)\n        train_epoch_accuracy.append(train_acc)\n        if _iter % print_every == 0 and print_every !=-1:\n            print(\"> Iteration {} < \".format(_iter), end=\"\")\n            print(\" Iter Loss = {}\".format(round(train_loss, 4)), end=\"\")\n            print(\" Iter Accuracy = {} % \\n\".format(train_acc))\n        \n        _iter += 1\n\n    # validation phase\n    model.eval()\n    for batch in valid_dl:\n        valid_loss, valid_acc =  shared_step(batch, model, device, optimizer, criterion, phase='valid')\n        val_epoch_loss.append(valid_loss)\n        val_epoch_accuracy.append(valid_acc)\n    \n    train_epoch_loss = np.mean(train_epoch_loss)\n    train_epoch_accuracy = np.mean(train_epoch_accuracy)\n    \n    val_epoch_loss = np.mean(val_epoch_loss)\n    val_epoch_accuracy = np.mean(val_epoch_accuracy)\n    \n    return {\"train_loss\":train_epoch_loss,\n            \"train_acc\":train_epoch_accuracy,\n            \"val_loss\":val_epoch_loss,\n            \"val_acc\":val_epoch_accuracy\n            }\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, train_dl, valid_dl, device, optimizer, criterion, n_epochs = 200, print_every=500):\n    best_val_loss = 1e10\n    train_acc = []\n    train_loss = []\n    val_acc = []\n    val_loss = []\n    t = trange(1,n_epochs+1, desc='Epoch ', leave=True, ncols=800)\n    with tqdm(bar_format='{desc}{bar}' , ncols=800) as line1:\n        for epoch in t:\n            result = one_epoch(model, train_dl, valid_dl, device, optimizer, criterion,print_every=print_every)\n            train_acc.append(result[\"train_acc\"])\n            train_loss.append(result[\"train_loss\"])\n            val_acc.append(result[\"val_acc\"])\n            val_loss.append(result[\"val_loss\"])\n            status = f\"Epoch {epoch}/{n_epochs}: train_acc = {result['train_acc']:0.4}% \"\n            status = status + f\"train_loss = {result['train_loss']:0.4} \"\n            status = status + f\"val_acc = {result['val_acc']:0.4}% \"\n            status = status + f\"val_loss = {result['val_loss']:0.4} \"\n            t.set_description(status)\n            t.refresh()\n            if result[\"val_loss\"] < best_val_loss:\n                if epoch == 1:\n                    l1 = f\"Epoch {epoch}: Validation loss {result['val_loss']:0.4} saving the model\"\n                else:\n                    l1 = f\"Epoch {epoch}: found better validation loss was {best_val_loss:0.4}, now {result['val_loss']:0.4}\"\n                    \n                best_val_loss = result[\"val_loss\"]\n                torch.save(model.state_dict(), \"bestVal.pt\")\n                line1.set_description(l1)\n        \n        train_history = {\"train_acc\":train_acc,\n                         \"train_loss\":train_loss,\n                         \"val_acc\":val_acc,\n                         \"val_loss\":val_loss\n                        }\n    return train_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(model_name, num_classes=255, pretrained=True):\n    defined = [\"densenet121\", \"resnet18\", \"resnet34\", \"resnext50\"]\n    try:\n        assert model_name in defined\n    except:\n        print(\"Model is not defined use one of\\n\", defined)\n        return\n    if model_name == \"densenet121\":\n        model = models.densenet121(pretrained = pretrained)\n        model.classifier = nn.Sequential(\n            nn.Linear(1024, 4096, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(4096, 2048, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(2048, num_classes)\n        );\n        \n    if model_name == \"resnet18\":\n        model = models.resnet18(pretrained = pretrained)\n        model.fc = nn.Sequential(\n            nn.Linear(512, 1024, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(1024, 2048, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(2048, num_classes)\n        );\n        \n        \n    if model_name == \"resnet34\":\n        model = models.resnet34(pretrained = pretrained)\n        model.fc = nn.Sequential(\n            nn.Linear(512, 1024, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(1024, 2048, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(2048, num_classes)\n        );\n    \n    if model_name == \"resnext50\":\n        model = models.resnext50_32x4d(pretrained = pretrained)\n        model.fc = nn.Sequential(\n            nn.Linear(2048, 4096, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(4096, 2048, bias = True),\n            nn.ReLU(inplace = True),\n            nn.Dropout(0.4),\n            nn.Linear(2048, num_classes)\n        );\n        \n    return model ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = BirdDataset(train_df,class2idx, transforms=get_transform(train=True))\nvalid_ds = BirdDataset(valid_df,class2idx, transforms=get_transform(train=False))\ntest_ds = BirdDataset(test_df,class2idx, transforms=get_transform(train=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"img, label = train_ds[20]\nplt.imshow(img.permute(1,2,0).numpy())\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\ntrain_dl = DataLoader(\n    dataset = train_ds,\n    batch_size = batch_size,\n    shuffle=True,\n    num_workers = 2,\n)\n\nvalid_dl = DataLoader(\n    dataset = valid_ds,\n    batch_size = batch_size,\n    shuffle=False,\n    num_workers = 2,\n)\n\ntest_dl = DataLoader(\n    dataset = test_ds,\n    batch_size = batch_size,\n    shuffle=False,\n    num_workers = 2,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ntorch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(class2idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_model(\"resnet34\", num_classes, pretrained=True)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.75)\ncriterion = nn.CrossEntropyLoss()\nmodel.to(device);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#n_print = int((len(train_ds)//batch_size)/2)\ntrain_history = train(model, train_dl, valid_dl, device, optimizer, criterion, n_epochs =50, print_every=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,8))\nax.plot(train_history['train_loss'], label=\"Training Loss\")\nax.plot(train_history['val_loss'], label=\"validation Loss\")\nplt.xticks(np.arange(0, len(train_history['train_loss'])+1, 10))\nax.legend(loc='upper right',bbox_to_anchor=(1.01, 1.09));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_losses = []\ntest_accuracy = []\nmodel.load_state_dict(torch.load('bestVal.pt'))\nmodel.eval()\nfor batch in test_dl:\n    test_loss, test_acc =  shared_step(batch, model, device, optimizer, criterion, phase='test')\n    test_losses.append(test_loss)\n    test_accuracy.append(test_acc)\n    \navg_test_loss = np.mean(test_loss)\navg_test_accuracy = np.mean(test_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Average testing accuracy = {avg_test_accuracy:.3}%, average testing loss = {avg_test_loss:.3}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}