{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install optuna\n\nimport tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom numpy.random import rand\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn as sns\nimport missingno as msno\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport optuna\nfrom optuna.integration import TFKerasPruningCallback\nfrom keras.backend import clear_session\n\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\nfrom keras import regularizers\nfrom keras.utils.vis_utils import plot_model\n\nfrom subprocess import check_output\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calcFamMembers(x, y):\n    if x == 1:\n        return y + 2\n    else:\n        return y + 2  \n#x = Total income y= nr of family members 10% expense per person subtracted from total income    \ndef AvailIncome(x, y, z, n): \n    emi = float(z)*1000/float(n)\n    return float(x) - (float(x) * 0.2 * float(y)) - emi\n\ndef Inc_Loan_Ratio(x,y):\n    if x>0:\n        return y*1000/x\n    else:\n        return 0\n    \n    \n    \ndef makenumbers(combined, Training = False):    \n    combined['Married'] = combined['Married'].replace({'No':0})\n    combined['Married'] = combined['Married'].replace({'Yes':1})\n    combined['Dependents'] = combined['Dependents'].replace({'0':0})\n    combined['Dependents'] = combined['Dependents'].replace({'1':1})\n    combined['Dependents'] = combined['Dependents'].replace({'2':2})\n    combined['Dependents'] = combined['Dependents'].replace({'3+':3})    \n    return combined\n\n\ndef multiplyloandata_pcversion(numberofmultiples, loandata, cols=[]):\n    multiple = numberofmultiples\n    rows = loandata.shape[0]\n    print(\"input rows: \", rows)\n    frames = []\n    frames.append(loandata)\n    for i in range(multiple):\n        temp = loandata.copy(deep=True)\n        for col in cols:\n            temp[col] = (temp[col] + temp[col] * rand(rows) * 0.05).round(2)\n        frames.append(temp)\n    new = pd.concat(frames)\n    new = new.sample(frac=1).reset_index(drop=True)\n    print(\"output dataframe shape: \", new.shape)\n    return new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def processfeatures(combined, Training = False):\n    \n    if Training:\n        combined['Credit_History'][combined['Loan_Status'] == 'Y'] = 1\n        combined['Credit_History'][combined['Loan_Status'] == 'N'] = 0 \n        combined['Loan_Status'] = combined['Loan_Status'].replace({'Y':1})\n        combined['Loan_Status'] = combined['Loan_Status'].replace({'N':0})        \n        combined.dropna(how='any', inplace = True)\n    combined = combined.drop(['Loan_ID'], axis=1)\n    #combined = combined.drop(['Married'], axis=1)\n    \n\n\n    combined['Gender'].fillna(combined['Gender'].mode()[0],inplace = True)\n    combined['Married'].fillna(combined['Married'].mode()[0],inplace = True)\n    combined['Education'].fillna(combined['Education'].mode()[0],inplace = True)\n    combined['Dependents'].fillna(combined['Dependents'].mode()[0],inplace = True)\n    combined['Loan_Amount_Term'].fillna(combined['Loan_Amount_Term'].mode()[0],inplace = True)\n    combined['Loan_Amount_Term'] = combined['Loan_Amount_Term']\n    combined['LoanAmount'].fillna(combined['LoanAmount'].mode()[0],inplace = True)\n    combined['Self_Employed'].fillna(combined['Self_Employed'].mode()[0],inplace = True)    \n    \n    combined['Property_Area'].fillna(combined['Property_Area'].mode()[0],inplace = True)    \n    combined['Total_income'] = combined['ApplicantIncome'] + combined['CoapplicantIncome']\n    combined['Total_income'] = combined['Total_income']\n    combined = makenumbers(combined, False)\n    combined['AvailIncome'] = combined.apply(lambda \n                                             row: AvailIncome(row['Total_income'],row['Dependents'],row['LoanAmount'],row['Loan_Amount_Term']), axis=1)  \n    combined['FMems'] = combined.apply(lambda row: calcFamMembers(row['Married'], row['Dependents']), axis=1)\n    combined['Inc_Loan_Ratio'] = combined.apply(lambda row: Inc_Loan_Ratio(row['AvailIncome'], row['LoanAmount']), axis=1)\n    addlcols = ['Married','Dependents']\n    combined = combined.drop(addlcols, axis=1)\n    categorise = ['Gender','Property_Area','Education','Self_Employed','Credit_History']\n    combined = pd.get_dummies(combined, columns = categorise)\n    return combined","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oritrain = pd.read_csv('../input/analytics-vidhya-loan-prediction/train.csv')\noritest = pd.read_csv('../input/analytics-vidhya-loan-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputdf = processfeatures(oritrain, True)\nscale_features = ['ApplicantIncome','CoapplicantIncome','AvailIncome','Total_income',\n                  'LoanAmount','FMems','Loan_Amount_Term','Inc_Loan_Ratio']\n#inputdf = multiplyloandata_pcversion(150, inputdf, cols=scale_features)\n#inputdf[scale_features] = StandardScaler().fit_transform(inputdf[scale_features])\ninputdf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropcols = ['ApplicantIncome','CoapplicantIncome','Loan_Amount_Term','Total_income',\n            'Gender_Male','Education_Graduate','Self_Employed_No','Credit_History_0.0']\n            \ninputdf = inputdf.drop(dropcols, axis=1)\ninputdf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputdf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Loan_Status\", y=\"AvailIncome\", kind=\"swarm\",hue=\"FMems\", data=inputdf, height=5, aspect=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(\n    data=inputdf.corr(),\n    annot=True,\n    fmt='.2f',\n    cmap='RdYlGn'\n)\n\nfig = plt.gcf()\nfig.set_size_inches(14, 10)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputdf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = inputdf.Loan_Status\nX = inputdf.drop(['Loan_Status'], axis = 1)\n\n# Split your data into training and testing (80% / 20%)\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    random_state=42,\n    test_size=0.30\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.metrics import Metric\nfrom tensorflow.python.keras.metrics import AUC\nimport functools\nfrom keras import backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import roc_auc_score\n    \ndef as_keras_metric(method):\n\n    @functools.wraps(method)\n    def wrapper(self, args, **kwargs):\n        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n        value, update_op = method(self, args, **kwargs)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([update_op]):\n            value = tf.identity(value)\n        return value\n    return wrapper\n\ndef auroc(y_true, y_pred):\n    return tf.py_function (roc_auc_score, (y_true, y_pred), tf.double)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study_name = \"LoanPredict\"\ncheckpoint_path = './LoanPredict.hdf5'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\nsaveBestmodel = keras.callbacks.ModelCheckpoint(checkpoint_path,\n                              monitor='val_accuracy',\n                              save_weights_only=False,\n                              save_best_only=True,\n                              verbose=0\n                             )\n\ndef objective(trial):\n    # Clear clutter from previous Keras session graphs.\n    clear_session()\n\n    num_epochs = 600\n        # Create callbacks for early stopping and pruning.\n    callbacks = [\n        keras.callbacks.EarlyStopping(patience=4),\n        TFKerasPruningCallback(trial, \"val_accuracy\"),\n        saveBestmodel\n    ]    \n    model = Sequential()\n    for i in range(3):                        \n        model.add(Dense(int(trial.suggest_discrete_uniform(\n            'FC_{}_num_hidden_units'.format(i), 16, 80, 8)),\n                        activation = \"relu\",\n                        input_dim=11\n                       )\n                 )              \n    model.add(Dense(1, activation = 'sigmoid'))\n    lr = trial.suggest_uniform(\"lr\", 1e-5, 1e-3)\n    model.compile(loss = 'binary_crossentropy', optimizer = Adam(lr=lr), metrics=['accuracy'])\n    batch_size = trial.suggest_int('Batch_size', 256, 1024, 128) \n    history = model.fit(X_train, \n                       y_train,\n                       validation_data= (X_test, y_test),\n                       epochs=num_epochs,\n                       batch_size = batch_size,\n                       callbacks=callbacks,\n                       verbose=0\n                       )\n    score = model.evaluate(X_test, y_test, verbose=1)\n    return score[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.logging.disable_default_handler()\nstudy = optuna.create_study(\n        sampler=optuna.samplers.TPESampler(\n            consider_prior=True, prior_weight=1.0, \n            consider_magic_clip=True, consider_endpoints=False, \n            n_startup_trials=10, n_ei_candidates=24, \n            seed=None), \n        pruner=optuna.pruners.SuccessiveHalvingPruner(\n            min_resource=2, reduction_factor=4, min_early_stopping_rate=1),\n        study_name = study_name, \n        direction=\"maximize\",\n)\n\n#study.optimize(objective, n_trials=100, timeout=600)\nstudy.optimize(objective, timeout=120)\n\nprint(\"Number of finished trials: {}\".format(len(study.trials)))\nprint(\"Best trial number:\", study.best_trial.number)\ntrial = study.best_trial\nprint(\"  Value: {}\".format(trial.value))\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_intermediate_values(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_parallel_coordinate(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = tf.keras.models.load_model(checkpoint_path)\n#Load the optimized model which is saved at checkpoint_path\nprint(checkpoint_path)\nnew_model = keras.models.load_model(checkpoint_path)\nnew_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(new_model, show_shapes = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preddf = processfeatures(oritest, False)\npreddf[scale_features] = StandardScaler().fit_transform(preddf[scale_features])\npreddf = preddf.drop(dropcols, axis=1)\ny_predict = new_model.predict(preddf)\npy_pred = np.where(y_predict > 0.45, 1, 0)\n\nResultdf= pd.Series(py_pred.ravel()).to_frame('Loan_Status')\nResultdf['Loan_Status'] = Resultdf['Loan_Status'].replace({0:'N'})\nResultdf['Loan_Status'] = Resultdf['Loan_Status'].replace({1:'Y'})\ndf = pd.DataFrame()\ndf['Loan_ID'] = oritest['Loan_ID']\ndf['Loan_Status'] = Resultdf['Loan_Status']\nresfile = \"./result3.csv\"\ndf.to_csv(resfile, index=False, line_terminator='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}