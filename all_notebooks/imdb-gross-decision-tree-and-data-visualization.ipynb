{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"dbb0f449-cae7-4855-96f3-f614662e04ce"},"source":"## IMDB 5000 Movie Dataset Introduction\nIn this note book, I first visualize the datasets in the IMDB 5000 movies and we found that some of the currency might not be unify in the budget column. Besides, some data also missing and display as NaN in the dataset. Instead of fill those NaN data as 0, we drop all of them in case of data bias in the budget, gross and so on. \nAfter that, we visualize part of data such as gross, budget and group them by years. Meanwhile, we also split the genres, language and visualize which categories and language are more popular in the datasets. \nBesides, we use linear model to analyze gross, budget and IMDB score to see which factors are significant to these indicators. However, the result isn't quite clear and the correlation are all below 0.5 and we could only preliminary derive some factor like number of votes could have higher connection with the gross or IMDB scores. \nIn the end, we used another library (Graphlab, which could only execute on python 2.7 and below) to make a decision tree to predict the high and low gross (we separate the datasets into high gross which has gross higher than 100 million and other data belongs to low gross). After that, we derived a decision tree model which works quite well (Its Accuracy ~ 0.8 and it's F1 score also around 0.8) and it classified data based on some nodes like number of voted user < 83K” and “budget > 69 million”. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9af902fc-3607-e4a1-f268-705659fd7b40"},"outputs":[],"source":"## Input library \n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom IPython.display import display\nfrom __future__ import division\n\nmpl.rc('savefig', dpi=100)\nplt.style.use('ggplot')\npd.set_option('display.max_rows', 10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8c807973-1a33-cc8d-f6a9-3c66b177c7d4"},"source":"## Data Visualization"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8236ea32-890b-572f-4428-96fcca519eba"},"outputs":[],"source":"# Load data\ndata = pd.read_csv('../input/movie_metadata.csv')\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d07bf71-ee76-f586-6488-db1aecd650b1"},"outputs":[],"source":"# Currency unify\ndata[\"TrueBudget\"] = data[\"budget\"]\nfor i in range(len(data.language)):\n    if \"Korean\" == data[\"language\"][i]:\n        data[\"TrueBudget\"][i] = data[\"TrueBudget\"][i]/1000\n    if \"Mandarin\" == data[\"language\"][i]:\n        data[\"TrueBudget\"][i] = data[\"TrueBudget\"][i]/7\n    if \"Japanese\" == data[\"language\"][i]:\n        data[\"TrueBudget\"][i] = data[\"TrueBudget\"][i]/100\n    if \"Cantonese\" == data[\"language\"][i]:\n        data[\"TrueBudget\"][i] = data[\"TrueBudget\"][i]/10\n    if \"Hindi\" == data[\"language\"][i]:\n        data[\"TrueBudget\"][i] = data[\"TrueBudget\"][i]/68"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a405ea48-b3c2-269b-c728-0684cab0ac6e"},"outputs":[],"source":"# Drop NaN data\ndata = data.dropna()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"65e0a035-c767-390a-f00c-7dca7e25851f"},"outputs":[],"source":"# Establish the data Genres table\ndata_Genres = pd.DataFrame()\ndata_Genres[\"Action\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Action\" in x else \"False\")\ndata_Genres[\"Adventure\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Adventure\" in x else \"False\")\ndata_Genres[\"Animation\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Animation\" in x else \"False\")\ndata_Genres[\"Biography\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Biography\" in x else \"False\")\ndata_Genres[\"Comedy\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Comedy\" in x else \"False\")\ndata_Genres[\"Crime\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Crime\" in x else \"False\")\ndata_Genres[\"Documentary\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Documentary\" in x else \"False\")\ndata_Genres[\"Drama\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Drama\" in x else \"False\")\ndata_Genres[\"Family\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Family\" in x else \"False\")\ndata_Genres[\"Fantasy\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Fantasy\" in x else \"False\")\ndata_Genres[\"Film-Noir\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Film-Noir\" in x else \"False\")\ndata_Genres[\"History\"] = data[\"genres\"].apply(lambda x : \"True\" if \"History\" in x else \"False\")\ndata_Genres[\"Horror\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Horror\" in x else \"False\")\ndata_Genres[\"Music\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Music\" in x else \"False\")\ndata_Genres[\"Musical\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Musical\" in x else \"False\")\ndata_Genres[\"Mystery\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Mystery\" in x else \"False\")\ndata_Genres[\"Romance\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Romance\" in x else \"False\")\ndata_Genres[\"Sci-Fi\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Sci-Fi\" in x else \"False\")\ndata_Genres[\"Sport\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Sport\" in x else \"False\")\ndata_Genres[\"Thriller\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Thriller\" in x else \"False\")\ndata_Genres[\"War\"] = data[\"genres\"].apply(lambda x : \"True\" if \"War\" in x else \"False\")\ndata_Genres[\"Western\"] = data[\"genres\"].apply(lambda x : \"True\" if \"Western\" in x else \"False\")\npd.set_option('display.max_columns', 30)\ndata_Genres.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4d9ae78-2bc5-1949-1a99-ef6ee1ffd2a3"},"outputs":[],"source":"data_Genres_Counts = pd.DataFrame()\ndata_Genres_Counts = data_Genres.apply(pd.value_counts)\ndata_Genres_Counts = data_Genres_Counts.drop(data_Genres_Counts.index[[0]])\nGenres_title = list(data_Genres_Counts.columns.values)\nGenres_index = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\ndata_Genres_Counts = data_Genres_Counts.transpose()\nplt.bar(Genres_index, data_Genres_Counts[\"True\"], align='center')\nplt.xticks(Genres_index, Genres_title, rotation = 90)\nplt.show()\npd.set_option('display.max_rows', 25)\ndisplay(data_Genres_Counts)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5599a4f3-3d71-fe15-efd7-4fafa4d9ff5a"},"outputs":[],"source":"data.corr()"},{"cell_type":"markdown","metadata":{"_cell_guid":"69d59f0a-94bd-8e5e-abed-c981c528a98c"},"source":"## Overview Data - Data Visualization"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b9779da-9220-4266-b14f-d5c294237a04"},"outputs":[],"source":"## See the gross and budget change by year\ndata_groupby_year = data.groupby(data[\"title_year\"])\ndata_groupby_year_mean = data_groupby_year.mean()\nGross = plt.scatter(data_groupby_year_mean.index, data_groupby_year_mean[\"gross\"], s = data_groupby_year[\"gross\"].count())\nBudget = plt.scatter(data_groupby_year_mean.index, data_groupby_year_mean[\"budget\"],color = \"r\" ,s = data_groupby_year[\"budget\"].count())\nplt.legend((Gross, Budget), ('Gross', 'Budget'),)\nplt.xlabel(\"Year\")\nplt.ylabel(\"Money($10,000,000)\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b055d0c-44b0-9633-09c0-8e545979e275"},"outputs":[],"source":"## See the people participation by year\nplt.subplot(211)\nnum_critic_for_reviews = plt.scatter(data_groupby_year_mean.index, data_groupby_year_mean[\"num_critic_for_reviews\"], s = data_groupby_year[\"gross\"].count())\nplt.xlabel(\"Year\")\nplt.ylabel(\"num of reviews\")\nplt.subplot(212)\nnum_voted_users = plt.scatter(data_groupby_year_mean.index, data_groupby_year_mean[\"num_voted_users\"], marker = \"x\",color = \"r\" ,s = data_groupby_year_mean[\"budget\"].count())\nplt.xlabel(\"Year\")\nplt.ylabel(\"num of voted\")\nplt.tight_layout()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a91bf8e5-18c4-7b23-7de9-d5db79d2f6ac"},"outputs":[],"source":"# Box plot\ndata.boxplot(column=\"gross\", by=\"language\", rot= 90, grid=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a30547b8-561d-931e-d0a5-14912c2fc4b5"},"source":"## Model & Predicting for IMDB score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6543e219-aa59-feef-ce95-5bd880dbdb61"},"outputs":[],"source":"## Formula for regression on IMDb_score\nlinear_formula_imdb = \"imdb_score ~ \\\nC(color) + num_critic_for_reviews + duration + gross + num_voted_users \\\n+ cast_total_facebook_likes + facenumber_in_poster + num_user_for_reviews \\\n+ TrueBudget + title_year + aspect_ratio + movie_facebook_likes \\\n+ actor_1_facebook_likes + actor_2_facebook_likes + actor_3_facebook_likes\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37c09337-456b-7db8-0c61-1c941f065ed5"},"outputs":[],"source":"linear_model_imdb = smf.ols(formula=linear_formula_imdb, data=data)\nlinear_model_fit_imdb = linear_model_imdb.fit()\nlinear_model_fit_imdb.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bcfb9460-ad76-3b82-462a-9e3a6f4935ee"},"outputs":[],"source":"predicted_imdbScore = linear_model_fit_imdb.predict(data)\nplt.scatter(data[\"imdb_score\"], predicted_imdbScore)\nplt.xlabel(\"Actual Score\")\nplt.ylabel(\"Predicted Score\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"0bafea9d-ac01-7d74-1a64-d34df0989e2e"},"source":"## Model & Predicting for Budget score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4865d8b1-a250-6a65-adb6-bedff6264e49"},"outputs":[],"source":"#Divide the numerical data and the string data\nstr_list = []\nfor colname, colvalue in data.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\nstr_list.remove(\"color\")\n\nnum_list = data.columns.difference(str_list)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22a64dd1-407a-cb91-3e3b-88855223db87"},"outputs":[],"source":"num_data = data[num_list]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c56c8d4e-5f7b-c292-1ac1-64d0a89da4de"},"outputs":[],"source":"#Create the linear fit model for budget\nlinear_model_formula_budget = \"TrueBudget ~ director_facebook_likes + actor_1_facebook_likes + actor_2_facebook_likes + \\\nactor_3_facebook_likes + cast_total_facebook_likes + title_year + aspect_ratio + C(color)\"\nlinear_model_budget = smf.ols(formula=linear_model_formula_budget, data=num_data)\nlinear_model_fit_budget = linear_model_budget.fit()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5016635a-e1df-2401-8903-34055df479df"},"outputs":[],"source":"linear_model_fit_budget.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9032c5ec-3c79-3524-e182-3ccd524602b5"},"outputs":[],"source":"predicted_budget = linear_model_fit_budget.predict()\nplt.scatter(num_data[\"TrueBudget\"],predicted_budget)\nplt.xlabel(\"Actual Budget\")\nplt.ylabel(\"Predicted Budget\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c234430-f5f4-65ec-bd0c-af823a6f575c"},"outputs":[],"source":"#Correnlation between predicted data and original data\npredicted_budget = linear_model_fit_budget.predict()\npredicted_budget = pd.Series(predicted_budget, name=\"PredictedBudget\")\npredicted_budget.corr(num_data[\"TrueBudget\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d15a9cc-a00d-7359-41ce-8f5e395caac3"},"outputs":[],"source":"#Visualization for budget change by years\nplt.scatter(num_data[\"title_year\"],num_data[\"budget\"])\nplt.gca().set_yscale('log')\nplt.xlabel(\"Title Year\")\nplt.ylabel(\"Actual Budget\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"83791c33-bdbc-2a88-4b1b-522f0a638d62"},"source":"## Model & Predicting for Gross score\nBuild linear model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f70b9def-71d5-35aa-f61d-7b6ccdd742c8"},"outputs":[],"source":"# check the data correlation to decide which variable use on the gross prediction\nprint(data.corr()[\"gross\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ec60838-0a59-550f-0f02-29a19d5369b9"},"outputs":[],"source":"import statsmodels.formula.api as smf\n# Build a simple linear model model ~ choose only corr above 0.3\nsimple_model_formula_Gross = \"gross ~ num_voted_users + num_critic_for_reviews + num_user_for_reviews \\\n                                    + TrueBudget + movie_facebook_likes\"\n# set up the simple linear model\nsimple_model_Gross = smf.ols(formula=simple_model_formula_Gross, data=data)\nsimple_model_fit_Gross = simple_model_Gross.fit()\n# observe the p-value and R-square\nsimple_model_fit_Gross.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ca26bc6-c741-1c20-796b-41cea4427b11"},"outputs":[],"source":"# predict the gross by simple linear model\npredicted_gross_simple = simple_model_fit_Gross.predict()\npredicted_gross_simple = pd.Series(predicted_gross_simple, name=\"PredictedGross\")\n# check the correlation\nprint(\"The correlation of simple linear model is : %.3f\" % predicted_gross_simple.corr(data[\"gross\"]))\n# plt scatter chart of actual data and predicted gross\nplt.scatter(data[\"gross\"], predicted_gross_simple)\nplt.gca().set_xscale(\"log\")\nplt.gca().set_yscale(\"log\")\nplt.xlabel(\"Actual Gross\")\nplt.ylabel(\"Predicted Gross\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"faa1ae77-6d18-25f1-1bc9-c11e077542c3"},"outputs":[],"source":"# Build the whole model\nimport statsmodels.formula.api as smf\nlinear_model_formula_Gross = \"gross ~ num_voted_users + num_critic_for_reviews + num_user_for_reviews \\\n                        + cast_total_facebook_likes + actor_1_facebook_likes + actor_2_facebook_likes \\\n                        + actor_3_facebook_likes + actor_2_facebook_likes + duration + cast_total_facebook_likes \\\n                        + imdb_score + actor_1_facebook_likes + director_facebook_likes + aspect_ratio + \\\n                        TrueBudget + title_year + facenumber_in_poster + duration + movie_facebook_likes\"\nlinear_model_Gross = smf.ols(formula=linear_model_formula_Gross, data=data)\nlinear_model_fit_Gross = linear_model_Gross.fit()\nlinear_model_fit_Gross.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e7b90da-0adf-85bb-626c-b210b75ed625"},"outputs":[],"source":"# predict the gross by the whole linear model\npredicted_gross = linear_model_fit_Gross.predict()\npredicted_gross = pd.Series(predicted_gross, name=\"PredictedGross\")\n# check the correlation\nprint(\"The correlation of simple linear model is : %.3f\" % predicted_gross.corr(data[\"gross\"]))\n# plt scatter chart of actual data and predicted gross\nplt.scatter(data[\"gross\"], predicted_gross)\nplt.gca().set_xscale(\"log\")\nplt.gca().set_yscale(\"log\")\nplt.xlabel(\"Actual Gross\")\nplt.ylabel(\"Predicted Gross\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc06e6d8-8424-3234-18fb-bece681e29a8"},"outputs":[],"source":"# Log scale\nlogGross = np.log(data[\"gross\"])\nlogPredictGross = np.log(predicted_gross)\nprint(\"The correlation of log scale is : %.3f\" %logGross.corr(logPredictGross))\nplt.scatter(logGross,logPredictGross)\nplt.xlabel(\"Actual Gross\")\nplt.ylabel(\"Predicted Gross\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b83878d8-8114-1983-7465-544498de3310"},"outputs":[],"source":"## Building model by training data and valid by vaildation\nnp.random.seed(0)\n\n# Let N_test be 20% (or 1/5th) of the data, and use a random shuffle\n# to partition the data.\nN_rows = len(data)\nN_test = N_rows//5\nshuffled_row_indices = np.random.permutation(N_rows)\ntest_rows = shuffled_row_indices[:N_test]\ntrain_rows = shuffled_row_indices[N_test:]\n\ntest_data = data.loc[test_rows,:]\ntrain_data = data.loc[train_rows,:]\n\n# Plot the training data in blue and the test data in red\nplt.plot(train_data[\"num_voted_users\"], train_data['gross'],'x', c='blue', label='training')\nplt.plot(test_data[\"num_voted_users\"], test_data[\"gross\"], 'x', c='red', label='testing')\nplt.gca().set_xscale(\"log\")\nplt.gca().set_yscale(\"log\")\nplt.xlabel(\"num_voted_users\")\nplt.ylabel(\"gross\")\nplt.legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2ed4c0a-edb6-4ff4-57cf-76baf4742579"},"outputs":[],"source":"train_data = train_data.dropna()\ntest_data = test_data.dropna()\nsimple_model_formula = \"gross ~ num_voted_users\"\nsimple_model = smf.ols(formula=simple_model_formula, data=train_data)\nsimple_model_fit = simple_model.fit()\n# One variable Simple Model\nprint('Test data true mean gross: $%.2f' % np.mean(test_data[\"gross\"]))\ntest_price_predicted = simple_model_fit.predict(test_data)\nprint('Test data predicted mean price: $%.2f' % np.mean(test_price_predicted))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4560eda2-bbd8-c3f6-212e-025519d08ac9"},"outputs":[],"source":"print('Test data true mean gross: $%.2f' % np.mean(test_data[\"gross\"]))\ntest_price_predicted_fulldata = linear_model_fit_Gross.predict(test_data)\nprint('Test data predicted mean price: $%.2f' % np.mean(test_price_predicted_fulldata))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3659539f-e5db-77cf-bb3d-11aea4de2b47"},"outputs":[],"source":"err = test_data[\"gross\"] - test_price_predicted\nerr_rms = np.sqrt(np.mean(err ** 2))\nprint('Simple model of RMSE from sqft of gross: $%.2f' % err_rms)\nerr = test_data[\"gross\"] - test_price_predicted_fulldata\nerr_rms = np.sqrt(np.mean(err ** 2))\nprint('linear model of RMSE from sqft of gross: $%.2f' % err_rms)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6cefca1-9165-747a-c23b-afb2b6f64fd8"},"outputs":[],"source":"plt.plot(train_data[\"num_voted_users\"],\n         train_data[\"gross\"],\n         'x', c='blue', label=\"training data\")\nplt.plot(train_data[\"num_voted_users\"],\n         simple_model_fit.fittedvalues,\n         c='red', label=\"simple fit\")\nplt.legend()\nplt.xlabel(\"num_voted_users\")\nplt.ylabel(\"gross\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"18b884af-94d8-5049-55da-39c28cefeb3b"},"source":"## Decision Tree"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d1fbea0-9f4b-fc03-e162-6f8ed28de687"},"outputs":[],"source":"## Only work on Python 2.7 and below, it won't work on Python 3.0 or above\nimport graphlab\ngraphlab.canvas.set_target('ipynb')\n# import data into graph lab\ndata_graphlab = graphlab.SFrame('movie_metadata.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9ece3e3-b5be-876e-6ed7-f1c3f37cac59"},"outputs":[],"source":"# data overview\ndata_graphlab.show()\ndata_decision_tree = data_graphlab.dropna()\nlen(data_decision_tree)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a86ac27f-dfa3-73e8-106e-b10045b43442"},"outputs":[],"source":"# based on above hist diagram, deciding the high box office is about top 20%\nhigh_gross = data_decision_tree[data_decision_tree['gross'] >= 1*1e8 ]\nlow_gross = data_decision_tree[data_decision_tree['gross'] < 1*1e8 ]\n\nprint(\"Box office above $100,000,000 is : %s\" % len(high_gross))\nprint(\"Box office below $100,000,000 is : %s\" % len(low_gross))\nprint(\"Percent of high and low box office is : %.2f\" %(len(high_gross)/len(low_gross)))data_decision_tree['gross'].show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"743cf0d2-1c70-d3a8-6187-75ff6c9f90be"},"outputs":[],"source":"features = ['num_voted_users',\n            'num_user_for_reviews',\n            'num_critic_for_reviews',\n            'movie_facebook_likes',\n            'director_facebook_likes',\n            'actor_1_facebook_likes',\n            'actor_2_facebook_likes',\n            'actor_3_facebook_likes',\n            'cast_total_facebook_likes',\n            'director_name',\n            'actor_1_name',\n            'actor_2_name',\n            'actor_3_name',\n            'imdb_score',\n            'movie_title',\n            'title_year',\n            'content_rating',\n            'language',\n            'country',\n            'genres',\n            'color',\n            'budget',\n           ]\ntarget = 'gross_HL'\ndata_dTree = data_decision_tree[ features + [target]]\nHigh_gross_raw = data_decision_tree[data_decision_tree[target] == +1 ]\nLow_gross_raw = data_decision_tree[data_decision_tree[target] == -1 ]\nprint(\"Box office above $10,000,000 is : %s\" % len(High_gross_raw))\nprint(\"Box office below $10,000,000 is : %s\" % len(Low_gross_raw))# Divide the gross into high and low gross\ndata_decision_tree['gross_HL'] = data_decision_tree['gross'].apply(lambda x : +1 if x>= 1*1e8 else -1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2f52e863-fa70-ad16-8a06-8fa3d3431bae"},"outputs":[],"source":"percentage = len(High_gross_raw)/float(len(Low_gross_raw))\n\nHigh_gross = High_gross_raw\nLow_gross = Low_gross_raw.sample(percentage, seed=1)\n\n# Append the high gross data with the downsampled version of low gross data\ngross_data = High_gross.append(Low_gross)\nprint \"Percentage of high gross data               :\", len(High_gross) / float(len(gross_data))\nprint \"Percentage of low gross data                :\", len(Low_gross) / float(len(gross_data))\nprint \"Total number of gross in our new dataset :\", len(gross_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0aa47c2-e773-e684-939d-877acf6580d2"},"outputs":[],"source":"# split the train and validation data\ntrain_data, validation_data = gross_data.random_split(.75, seed=1)\nprint(\"trian data has : %d\" % len(train_data))\nprint(\"validation data has : %d\" % len(validation_data))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83fa6f6b-d3c2-8599-82d4-7cd6885b4c57"},"outputs":[],"source":"decision_tree_model = graphlab.decision_tree_classifier.create(\n    train_data, validation_set=None, target=target, features=features)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0607702-0afa-9304-289b-f8c5e40ffd9f"},"outputs":[],"source":"WARNING: The number of feature dimensions in this problem is very large in comparison with the number of examples. Unless an appropriate regularization value is set, this model may not provide accurate predictions for a validation/test set.\nDecision tree classifier:\n--------------------------------------------------------\nNumber of examples          : 899\nNumber of classes           : 2\nNumber of feature columns   : 22\nNumber of unpacked features : 22\n+-----------+--------------+-------------------+-------------------+\n| Iteration | Elapsed Time | Training-accuracy | Training-log_loss |\n+-----------+--------------+-------------------+-------------------+\n| 1         | 0.009019     | 0.927697          | 0.511922          |\n+-----------+--------------+-------------------+-------------------+"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"689add89-5b9f-5b01-f56d-16e9eea8327e"},"outputs":[],"source":"decision_tree_model.show(view=\"Evaluation\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"a096968a-5c7f-b470-8da6-4aad18c9efcc"},"source":"![Evaluation of decision tree model ][1]\n\n\n  [1]: https://drive.google.com/file/d/0B4UueDDReN7QU3M2YmpOVUdEVm8/view?usp=sharing"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8369736-a888-47d5-3f60-4f21fab88d5f"},"outputs":[],"source":"small_model = graphlab.decision_tree_classifier.create(\n    train_data, validation_set=None, target=target, features=features, max_depth=3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"25a492e7-71d1-6424-84eb-6db631b1a074"},"source":"![small model of decision tree figure][1]\n\n\n  [1]: https://drive.google.com/file/d/0B4UueDDReN7QN1VBa2d4TlpMaGM/view?usp=sharing"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38cdcf76-e1cd-6315-b643-f96d4d1f1b92"},"outputs":[],"source":"# set up the validation data\nvalidation_high_gross = validation_data[validation_data[target] == 1]\nvalidation_low_gross = validation_data[validation_data[target] == -1]\n\nsample_validation_data_high_gross = validation_high_gross[0:2]\nsample_validation_data_low_gross = validation_low_gross[0:2]\n\nsample_validation_data = sample_validation_data_low_gross.append(sample_validation_data_high_gross)\nsample_validation_data[\"gross_HL\"]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d8404fd-1916-52e8-69ef-5a3bdfb0e80a"},"outputs":[],"source":"# check the sample validation result -> 50% accuracy\ndecision_tree_model.predict(sample_validation_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7820e82a-bb5a-1411-8ab1-8b5117539223"},"outputs":[],"source":"decision_tree_model.predict(sample_validation_data, output_type='probability')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49de8a92-e28c-1515-f904-fba7c3636191"},"outputs":[],"source":"print (\"The accuracy of training data in small model is : %.2f\" % small_model.evaluate(train_data)['accuracy'])\nprint (\"The accuracy of validation data in small model is : %.2f\" % small_model.evaluate(validation_data)['accuracy'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"807f7572-a194-2801-dda4-282405bc2882"},"source":"The accuracy of training data in small model is : 0.84\nThe accuracy of validation data in small model is : 0.80"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf8b3bbc-1ce4-12e1-c37c-8f93dbc9a8e1"},"outputs":[],"source":"print(\"The accuracy of training data in decision tree model is : %.2f\" % decision_tree_model.evaluate(train_data)['accuracy'])\nprint(\"The accuracy of validation data decision tree model is : %.2f\" % decision_tree_model.evaluate(validation_data)['accuracy'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"87e55e09-6a85-6db6-0004-1b49fb648f33"},"source":"The accuracy of training data in decision tree model is : 0.93\nThe accuracy of validation data decision tree model is : 0.81"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}