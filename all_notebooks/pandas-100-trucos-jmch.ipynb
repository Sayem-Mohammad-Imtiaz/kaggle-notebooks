{"cells":[{"metadata":{},"cell_type":"markdown","source":"Jose Mario Castro Hernandez 1665023"},{"metadata":{},"cell_type":"markdown","source":"# Bienvenido a este Kernel\n\n* Este kernel es una recopilación de trucos de pandas publicados semanalmente por Kevin Markham.\n\nPuede encontrar los trucos originales de los 100 pandas (creados por [Kevin Markham] (https://www.linkedin.com/in/justmarkham/) de Data School) en esta página:\n\nhttps://www.dataschool.io/python-pandas-tips-and-tricks/\n\n## <span style = \"color: green\"> * Si quieres aprender ** sklearn ** revisa este kernel con trucos y consejos: </span>\n\nhttps://www.kaggle.com/python10pm/sklearn-24-best-tips-and-tricks"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"tabla_de_contenidos\"></a>\n# Tabla de contenidos\n\n[Importar bibliotecas y configurar algunas funciones auxiliares](#Importaciones)\n\n[Truco 100: carga de muestra de un archivo de big data](#truco100)\n\n[Truco 99: Cómo evitar Innominado: 0 columnas](#truco99)\n\n[Truco 98: convierte un DF ancho en uno largo](#truco98)\n\n[Truco 97: convierte el año y el día del año en una sola columna de fecha y hora](#truco97)\n\n[Truco 96: parcelas interactivas listas para usar en pandas](#truco96)\n\n[Truco 95: cuenta los valores perdidos](#truco95)\n\n[Truco 94: ahorra memoria fijando tu fecha](#truco94)\n\n[Truco 93: combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando frecuencias)](#truco93)\n\n[Truco 92: columna de objeto limpio con datos mixtos usando expresiones regulares](#truco92)\n\n[Truco 91: Crear un conjunto de datos de series de tiempo para realizar pruebas](#truco91)\n\n[Truco 90: mover columnas a una ubicación específica](#truco90)\n\n[Truco 89: Divide los nombres en nombre y apellido](#truco89)\n\n[Truco 88: reacomodar columnas en un DF](#truco88)\n\n[Truco 87: agregue su fecha y hora por y filtre los fines de semana](#truco87)\n\n[Truco 86: agregaciones con nombre: evita el índice múltiple](#truco86)\n\n[Truco 86bis: agregaciones con nombre en varias columnas; evita el índice múltiple](#truco86bis)\n\n[Truco 85: convierte un tipo de valores en otros](#truco85)\n\n[Truco 84: Mostrar menos filas en una df(femenino)](#truco84)\n\n[Truco 83: Corrija los tipos de datos al importar el df](#truco83)\n\n[Truco 82: seleccionar datos por etiqueta y posición (iloc y loc encadenados)](#truco82)\n\n[Truco 81: use aplicar (tipo) para ver si tiene tipos de datos mixtos](#truco81)\n\n[Truco 80: seleccione varias secciones de columnas de un df](#truco80)\n\n[Truco 79: recuento de filas que coinciden con una condición](#truco79)\n\n[Truco 78: realice un seguimiento de la procedencia de sus datos cuando utilice varias fuentes](#truco78)\n\n[Truco 77: combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando dónde)](#truco77)\n\n[Truco 76: filtra en pandas solo las categorías más grandes.](#truco76)\n\n[Truco 75: cuenta el número de palabras en una serie de pandas](#truco75)\n\n[Truco 74: Webscraping usando read_html () y parámetro de coincidencia](#truco74)\n\n[Truco 73: eliminar una columna y almacenarla como una serie separada](#truco73)\n\n[Truco 72: Convertir variable continua en categórica (corte y qcut)](#truco72)\n\n[Truco 71: leer datos de un PDF (tabula py)](#truco71)\n\n[Truco 70: Imprime la versión actual de pandas y sus dependencias\n](#truco70)\n\n[Truco 69: comprueba si 2 series son \"similares\"\n](#truco69)\n\n[Truco 68: Webscraping usando read_html ()\n](#truco68)\n\n[Truco 67: crea nuevas columnas o sobrescribe usando Assing y establece un título para el df\n](#truco67)\n\n[Truco 66: Cree un montón de columnas nuevas usando un bucle for y f-strings df [f '{col} _new']\n](#truco66)\n\n[Truco 65: seleccione columnas usando f-strings (nuevo en pandas 3.6+)\n](#truco65)\n\n[Truco 64: corrección de \"SettingWithCopyWarning\" al crear nuevas columnas\n](#truco64)\n\n[Truco 63: Calcule el recuento continuo con grupos usando cumcount () + 1\n](#truco63)\n\n[Truco 62: Corregir \"SettingWithCopyWarning\" al cambiar columnas usando loc\n](#truco62)\n\n[Truco 61: leer JSON de la web en un df\n](#truco61)\n\n[Truco 60: Creación de totales acumulados con la función cumsum\n](#truco60)\n\n[Truco 59: combine la salida de una agregación con el df original usando transform\n](#truco59)\n\n[Truco 58: use encabezados y saltos para deshacerse de datos incorrectos o filas vacías durante la importación\n](#truco58)\n\n[Truco 57: Accediendo a los grupos de un objeto groupby (get_group ())\n](#truco57)\n\n[Truco 56: Aplicar asignaciones o funciones a todo el df (applymap)\n](#truco56)\n\n[Truco 55: filtrar un df con múltiples criterios usando reducir\n](#truco55)\n\n[Truco 54: Calcula la diferencia entre cada fila y la anterior (diff ())\n](#truco54)\n\n[Truco 53: mezclar filas de un df (df.sample ())\n](#truco53)\n\n[Truco 52: Hacer tramas con pandas\n](#truco52)\n\n[Truco 51: Concatenar cadenas de 2 columnas\n](#truco51)\n\n[Truco 50: agregación con nombre con varias columnas que pasan tupples (nuevo en pandas 0.25)\n](#truco50)\n\n[Truco 49: Muestreo con pandas (con reemplazo y pesos)\n](#truco49)\n\n[Truco 48: Parámetros útiles al usar pd.read_csv ()\n](#truco48)\n\n[Truco 47: crea una fila para cada elemento en una lista (explotar)\n](#truco47)\n\n[Truco 46: Almacene NaN en un tipo entero con Int64 (no int64)\n](#truco46)\n\n[Truco 45: Cree filas para valores separados por comas en una celda (Assing y explotar)\n](#truco45)\n\n[Truco 44: usa una variable local dentro de una consulta en pandas (usando @)\n](#truco44)\n\n[Truco 43: ¡Crea una fila para cada elemento de una lista (explotar)! ¡¡¡Truco 47 duplicado !!!\n](#truco43)\n\n[Truco 42: Nueva función de agregación -> last ()\n](#truco42)\n\n[rick 41: Categorías ordenadas (de pandas.api.types import CategoricalDtypee)\n](#truco41)\n\n[Truco 40: Estilo que df rápido con hide_index () y set_caption ()\n](#truco40)\n\n[Truco 39: una codificación en caliente (get_dummies ())\n](#truco39)\n\n[Truco 38: Pandas datetime (muchos ejemplos)\n](#truco38)\n\n[Truco 37: Pandas cortando loc e iloc (6 ejemplos)\n](#truco37)\n\n[Truco 36: Convertir de UTC a otra zona horaria\n](#truco36)\n\n[Truco 35: consulta una columna que tenga espacios en el nombre (usando comillas invertidas)\n](#truco35)\n\n[Truco 34: Explore un conjunto de datos con creación de perfiles\n](#truco34)\n\n[Truco 33: opciones de visualización de pandas\n](#truco33)\n\n[Truco 32: filtrar un df con consulta y evitar variables intermedias\n](#truco32)\n\n[Truco 31: Ver todas las columnas de un gran df\n](#truco31)\n\n[Truco 30: Pandas se fusionan -> ver de dónde vienen las columnas (indicador = Verdadero\n](#truco30)\n\n[Truco 29: acceda a numpy dentro de pandas (sin importar numpy como np)\n](#truco29)\n\n[Truco 28: agregando por múltiples columnas (usando agg)\n](#truco28)\n\n[Truco 27: agregación sobre series temporales (remuestreo)\n](#truco27)\n\n[Truco 26: formatear diferentes columnas de un df (usando diccionarios)\n](#truco26)\n\n[Truco 25: 3 formas de cambiar el nombre de las columnas\n](#truco25)\n\n[Truco 24: copie datos de Excel a pandas rápidamente (read_clipboard ())\n](#truco24)\n\n[Truco 23: Complete los valores faltantes en los datos de series de tiempo (interpolar ())\n](#truco23)\n\n[Truco 22: Crea DataFrames para probar\n](#truco22)\n\n[Truco 21: divide una columna de cadena en varias columnas\n](#truco21)\n\n[Truco 20: crea columnas de fecha y hora a partir de varias columnas\n](#truco20)\n\n[Truco 19: muestra el uso de memoria de un df y cada columna\n](#truco19)\n\n[Truco 18: leer y escribir en un archivo comprimido (csv.zip)\n](#truco18)\n\n[Truco 17: seleccione varias filas y columnas con loc\n](#truco17)\n\n[Truco 16: convierta valores continuos en categóricos (cortar ())\n](#truco16)\n\n[Truco 15: Remodelar una MultiIndex df (desapilar ())](#truco15)\n\n[Truco 14: Creando juguete df (3 métodos)\n](#truco14)\n\n[Truco 13: Evita la serie de listas TRAP\n](#truco13)\n\n[Truco 12: fusionar conjuntos de datos y verificar la unicidad\n](#truco12)\n\n[Truco 11: cambie el nombre de todas las columnas con el mismo patrón\n](#truco11)\n\n[Truco 10: comprueba la igualdad de 2 series\n](#truco10)\n\n[Truco 9: ¡Reduzca el uso de memoria de un df al importar! ¡¡¡Truco 83 duplicado !!!\n](#truco9)\n\n[Truco 8: ¡Usar glob para generar un df a partir de varios archivos! ¡¡¡Truco 78 duplicado !!!\n](#truco8)\n\n[Truco 7: lidiar con los valores perdidos (NaN)\n](#truco7)\n\n[Truco 6: divide un df en 2 subconjuntos aleatorios\n](#truco6)\n\n[Truco 5: convierte números almacenados como cadenas (coaccionar)\n](#truco5)\n\n[Truco 4: seleccione columnas por dtype\n](#truco4)\n\n[Truco 3: filtrar un df por múltiples condiciones (isin e inverso usando ~)\n](#truco3)\n\n[Truco 2: orden inverso de una df](#truco2)\n\n[Truco 1: agregue un prefijo o sufijo a todas las columnas\n](#truco1)\n"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"Importaciones\"></a>\n\n# Importar bibliotecas y configurar algunas funciones auxiliares\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# librerias basicas\nimport os\nimport numpy as np\nimport pandas as pd\n\n# esto nos permitirá imprimir todos los archivos a medida que generamos más en el kernel\ndef print_files():\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n# Revisa el truco 91 para un ejemplo\ndef generate_sample_data(): # crea un df falso para probar\n    number_or_rows = 20\n    num_cols = 7\n    cols = list(\"ABCDEFG\")\n    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n    df.index = pd.util.testing.makeIntIndex(number_or_rows)\n    return df\n\n# Revisa el truco 91 para un ejemplo\ndef generate_sample_data_datetime(): # crea un df falso para probar\n    number_or_rows = 365*24\n    num_cols = 2\n    cols = [\"sales\", \"customers\"]\n    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n    df.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\n    return df\n\n# mostrar varias impresiones en una celda. Esto nos permitirá condensar cada truco en una celda.\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nprint_files()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco100\"></a>\n# Truco 100: carga de muestra de big data\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/us-accidents/US_Accidents_June20.csv\")\nprint(\"La forma del df es {}\".format(df.shape))\n\ndel df\n\ndf = pd.read_csv(\"/kaggle/input/us-accidents/US_Accidents_June20.csv\", skiprows = lambda x: x>0 and np.random.rand() > 0.01)\nprint(\"La forma del df es {}. ¡Se ha reducido 10 veces!\".format(df.shape))\n\n\n'''\nComo trabaja:\nskiprows acepta una función que se evalúa con el índice entero.\nx > 0 se asegura de que los encabezados no se omitan\nnp.random.rand() > 0.01 devuelve True 99% del empate, por lo que se salta el 99% del tiempo.\nTenga en cuenta que estamos usando skiprows\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco99\"></a>\n# Truco 99: Como evitar Innominado: 0 columnas\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"zip_code\": [12345, 56789, 101112, 131415],\n\"factory\": [100, 400, 500, 600],\n\"warehouse\": [200, 300, 400, 500],\n\"retail\": [1, 2, 3, 4]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# guardar a csv\ndf.to_csv(\"trick99data.csv\")\n\ndf = pd.read_csv(\"trick99data.csv\")\ndf\n# Para evitar Innominado: 0\n\ndf = pd.read_csv(\"trick99data.csv\", index_col=0)\n# o al guardar df = pd.read_csv (\"trick99data.csv\", index = False)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco98\"></a>\n# Truco 98: convierte un DF ancho en uno largo\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"zip_code\": [12345, 56789, 101112, 131415],\n\"factory\": [100, 400, 500, 600],\n\"warehouse\": [200, 300, 400, 500],\n\"retail\": [1, 2, 3, 4]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Nosotros tenemos que tranquilizar\n\n# location_type se genera automáticamente a partir de las columnas que quedan después de especificar id_vars (también puede pasar una lista)\ndf = df.melt(id_vars = \"zip_code\", var_name = \"location_type\", value_name = \"distance\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco97\"></a>\n# Truco 97: convierte el año y el día del año en una sola columna de fecha y hora\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Truco 97\n# Convertir\nd = {\\\n\"año\": [2019, 2019, 2020],\n\"dia_de_año\": [350, 365, 1]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: crea una columna combinada\n\ndf[\"combinado\"] = df[\"año\"]*1000 + df[\"dia_de_año\"]\ndf\n\n# Paso 2: convertir a fecha y hora\n\ndf[\"fecha\"] = pd.to_datetime(df[\"combinado\"], format = \"%Y%j\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco96\"></a>\n# Truco 96: parcelas interactivas listas para usar en pandas\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.__version__)\n# Se requiere la versión 0.25 o superior de Pandas y necesita hvplot\n\n\nimport pandas as pd\ndf = pd.read_csv(\"../input/drinks-by-country/drinksbycountry.csv\")\ndf\n\n# este no es interactivo\n\ndf.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\")\n\n# corre !pip install hvplot\n#pd.options.plotting.backend = \"hvplot\"\n#df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\", c = \"continent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco95\"></a>\n# Truco 95: cuenta los valores perdidos\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"col1\": [2019, 2019, 2020],\n\"col2\": [350, 365, 1],\n\"col3\": [np.nan, 365, None]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Solucion 1\ndf.isnull().sum().sum()\n\n# Solucion 2\ndf.isna().sum()\n\n# Solucion 3\ndf.isna().any()\n\n# Solucion 4:\ndf.isna().any(axis = None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco94\"></a>\n# Truco 94: ahorra memoria fijando tu fecha\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/titanic/train.csv\", usecols = [\"Pclass\", \"Sex\", \"Parch\", \"Cabin\"])\ndf\n\n# veamos cuanto ocupa nuestro df en memoria\ndf.memory_usage(deep = True)\n\n# convertir a tipos de datos mas pequeños\n\ndf = df.astype({\"Pclass\":\"int8\",\n                \"Sex\":\"category\", \n                \"Parch\": \"Sparse[int]\", # la mayoria de los valores son 0\n\n                \"Cabin\":\"Sparse[str]\"}) # la mayoria de los valores son NaN\n\n\ndf.memory_usage(deep = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco93\"></a>\n# Truco 93: combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando frecuencias)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"genero\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: cuenta las frecuencias\n\nfrequencies = df[\"genero\"].value_counts(normalize = True)\nfrequencies\n\n# Paso 2: establezca su umbral y filtre las categorías más pequeñas\n\nthreshold = 0.1\nsmall_categories = frequencies[frequencies < threshold].index\nsmall_categories\n\n# Paso 3: reemplace los valores\n\ndf[\"genero\"] = df[\"genero\"].replace(small_categories, \"Otro\")\ndf[\"genero\"].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco92\"></a>\n# Truco 92: columna de objeto limpio con datos mixtos usando expresiones regulares\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"d = {\"customer\": [\"A\", \"B\", \"C\", \"D\"], \"sales\":[1100, 950.75, \"$400\", \"$1250.35\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Step 1: check the data types\ndf[\"sales\"].apply(type)\n\n# Step 2: use regex\ndf[\"sales\"] = df[\"sales\"].replace(\"[$,]\", \"\", regex = True).astype(\"float\")\ndf\ndf[\"sales\"].apply(type)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco91\"></a>\n# Truco 91: Crear un conjunto de datos de series de tiempo para realizar pruebas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Solucion 1\nnumber_or_rows = 365*24 # horas en el año\npd.util.testing.makeTimeDataFrame(number_or_rows, freq=\"H\")\n\n# Solucion 2\nnum_cols = 2\ncols = [\"ventas\", \"clientes\"]\ndf = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\ndf.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco90\"></a>\n# Truco 90: mover columnas a una ubicación específica\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[15, 20], \"B\":[20, 25], \"C\":[30 ,40], \"D\":[50, 60]}\ndf = pd.DataFrame(d)\ndf\n\n# Usando insertar\ndf.insert(3, \"C2\", df[\"C\"]*2)\ndf\n\n# Otra solucion\ndf[\"C3\"] = df[\"C\"]*3 # crea nuevas columnas, estará al final\n\ncolumns = df.columns.to_list() # crea una lista con todas las columnas\n\nlocation = 4 # especifique la ubicacion donde desea su nueva columna\n\ncolumns = columns[:location] + [\"C3\"] + columns[location:-1] # reaorganizar la lista\n\ndf = df[columns] # cree el marco de datos con el orden de columnas que desee\n\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco89\"></a>\n# Truco 89: Divide los nombres en nombre y apellido\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.Series([\"Geordi La Forge\", \"Deanna Troi\", \"Data\"]).to_frame()\ndf.rename({0:\"names\"}, inplace = True, axis = 1)\ndf\n#                              dividir en el primer espacio  \ndf[\"first_name\"] = df[\"names\"].str.split(n = 1).str[0]\ndf[\"last_name\"] = df[\"names\"].str.split(n = 1).str[1]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco88\"></a>\n# Truco 88: Reorganizar columnas en una df(femenino)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\n\n# Solucion 1\ndf[[\"A\", \"C\", \"D\", \"F\", \"E\", \"G\", \"B\"]].head() # doesn't modify in place\n\n# Solucion 2\ncols_to_move = [\"A\", \"G\", \"B\"]\n\nnew_order = cols_to_move + [c for c in df.columns if c not in cols_to_move] # genera tu nueva orden\ndf[new_order].head()\n\n# Solucion 3: usando indice\ncols = df.columns[[0, 5 , 3, 4, 2, 1, 6]] # df.columns devuelve una serie con índice, usamos la lista para ordenar el índice como queramos -> así ordenamos las columnas\n\ndf[cols].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco87\"></a>\n# Truco 87: agregue su fecha y hora por y filtre los fines de semana\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()\ndf.shape\ndf.head()\n\n# Paso 1: remuestrear por D. Básicamente agregue por día y use to_frame () para convertirlo en marco\n\ndaily_sales = df.resample(\"D\")[\"sales\"].sum().to_frame()\ndaily_sales\n\n# Paso 2: filtra los fines de semana\n\nweekends_sales = daily_sales[daily_sales.index.dayofweek.isin([5, 6])]\nweekends_sales\n\n'''\ndayofweek day\n0         Monday\n1         Tuesday\n2         Wednesday\n3         Thursday\n4         Friday\n5         Saturday\n6         Sunday\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco86\"></a>\n# Truco 86: agregaciones con nombre: evita el índice múltiple\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.head()\n\n# Problema 1\nprint(\"El problema se basa en que no sabemos el nombre de la columna.\")\ndf.groupby(\"Pclass\")[\"Age\"].agg([\"mean\", \"max\"])\n\n# Problema 2\nprint(\"El problema se basa en que tenemos multiindice\")\ndf.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"]})\n\n# Solucion nueva en pandas 0.25 y superior\n\nprint(\"Ahora hemos resuelto los problemas anteriores especificando el nombre final de la columna que queremos.\")\nprint(\"PERO SOLO FUNCIONA CON COLUMNA. PARA ESTE TIPO DE OPERACIONES EN MÚLTIPLES COLUMNAS VERIFIQUE LA PROXIMA CELDA\")\ndf.groupby(\"Pclass\")[\"Age\"].agg(age_mean = \"mean\", age_max = \"max\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco86bis\"></a>\n# Truco 86bis: agregaciones con nombre en varias columnas; evita el índice múltiple\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_agg(x):\n    names = {\n        'age_mean': x['Age'].mean(),\n        'age_max':  x['Age'].max(),\n        'fare_mean': x['Fare'].mean(),\n        'fare_max': x['Fare'].max()\n    } # definir sus operaciones y nombres de columnas personalizados\n\n\n    return pd.Series(names, index=[ key for key in names.keys()]) # todas las columnas que cree en el diccionario anterior estarán en esta lista de comprensión\n\n\ndf.groupby('Pclass').apply(my_agg)\n\n# referencia\n# https://stackoverflow.com/questions/44635626/rename-result-columns-from-pandas-aggregation-futurewarning-using-a-dict-with\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco85\"></a>\n# Truco 85: convierte un tipo de valores en otros\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Haz algunas funciones rapidas en el DF\n\nd = {\"gender\":[\"male\", \"female\", \"male\"], \"color\":[\"red\", \"green\", \"blue\"], \"age\":[25, 30, 15]}\ndf = pd.DataFrame(d)\ndf\n\n# Solucion\nmap_dict = {\"male\":\"M\", \"female\":\"F\"}\ndf[\"gender_mapped\"] = df[\"gender\"].map(map_dict) # usar diccionarios para mapear valores\n\ndf[\"color_factorized\"] = df[\"color\"].factorize()[0] # using factorize: devuelve una tupla de matrices (array ([0, 1, 2]), Index (['red', 'green', 'blue'], dtype = 'object')) por eso seleccionamos [0]\n\ndf[\"age_compared_boolean\"] = df[\"age\"] < 18 # rdevuelve un valor booleano True False\n\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco84\"></a>\n# Truco 84: Mostrar menos filas en una df(femenino)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Este df ocupa demasiado espacio\")\ndf = generate_sample_data()\ndf\n\nprint(\"usando set_option para ahorrar espacio en la pantalla\")\npd.set_option(\"display.max_rows\", 6)\ndf\n\nprint(\"usa reset_option all para restablecer los valores predeterminados\")\npd.reset_option(\"all\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco83\"></a>\n# Truco 83: Corrija los tipos de datos al importar el df\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n\n# Paso 1: vamos al tipo de fecha de las columnas\n\ncol_types = df.dtypes.to_frame()\ncol_types.rename({0:\"type\"}, inplace = True, axis = 1)\ncol_types\ncol_types.to_csv(\"trick83data.csv\")\n\n# Paso 2: Vamos a importar los datos anteriores y convertirlos en un diccionario.\n\ncol_dict = pd.read_csv(\"trick83data.csv\", index_col = 0)[\"type\"].to_dict()\n\n# Paso 3: edite el diccionario con los tipos de datos correctos\n\nprint(\"diccionario original\")\ncol_dict\ncol_dict[\"country\"] = \"category\"\ncol_dict[\"continent\"] = \"category\"\nprint(\"diccionario modificado\")\ncol_dict\n\n# Paso 4: usa el diccionario para importar los datos\n\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", dtype=col_dict)\ndf.dtypes\n\n# Nota: tenga en cuenta que puede usar el dict del paso 1 y pegarlo así\n\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", \\\ndtype=\n{'country': 'category',\n 'beer_servings': 'int64',\n 'spirit_servings': 'int64',\n 'wine_servings': 'int64',\n 'total_litres_of_pure_alcohol': 'float64',\n 'continent': 'category'})\n# Sin embargo, si tiene muchas columnas, esto puede resultar confuso.\n\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco82\"></a>\n# Truco 82: seleccionar datos por etiqueta y posición (iloc y loc encadenados)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", index_col=\"country\")\ndf.iloc[15:20, :].loc[:, \"beer_servings\":\"wine_servings\"]\n# iloc se usa para filtrar las filas y ubicar las columnas\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco81\"></a>\n# Truco 81: use aplicar (tipo) para ver si tiene tipos de datos mixtos\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"customer\":[\"A\", \"B\", \"C\", \"D\", \"E\"], \"sales\":[100, \"100\", 50, 550.20, \"375.25\"]}\ndf = pd.DataFrame(d)\n# todo parece, pero esta operación bloquea df [\"ventas\"]. sum (). Tenemos tipos de datos mixtos\n\ndf.dtypes\ndf[\"sales\"].apply(type) # Vaya, podemos ver que tenemos int, str, flota en una columna\n\ndf[\"sales\"].apply(type).value_counts() # Ver el numero de cada valor\n\n\ndf[\"sales\"] = df[\"sales\"].astype(float) # convertir los datos a flotar\n\ndf[\"sales\"].sum()\ndf[\"sales\"].apply(type).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco80\"></a>\n# Truco 80: seleccione varias secciones de columnas de un df\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data().T\ncols_str = list(map(str, list(df.columns))) # para que podamos hacer df [\"0\"] como cadena para el ejemplo\n\ndf.columns = cols_str\n\n# Usando la concatenacion de pandas\n\n# si alguna vez se siente confundido acerca del eje = 1 o el eje = 0, simplemente coloque eje = \"columnas\" o eje = \"filas\"\n\npd.concat([df.loc[:, \"0\":\"2\"], df.loc[:, \"6\":\"10\"], df.loc[:, \"16\":\"19\"]], axis = \"columns\") # ------------------> aquí estamos seleccionando columnas convertidas en cadenas\n\n\n# Usando listas\n\n# tenga en cuenta que df.columns es una serie con índice, por lo que estamos usando índice para filtrar # -------------------------> aquí estamos seleccionando el índice de columnas\n\ndf[list(df.columns[0:3]) + list(df.columns[6:11]) + list(df.columns[16:20])]\n\n# Usando numpy\n\ndf.iloc[:, np.r_[0:3, 6:11, 16:20]] # probablemente la solución mas hermosa\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco79\"></a>\n# Truco 79: recuento de filas que coinciden con una condición\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\ndf.shape\n\n# valores absolutos\n(df[\"A\"] < 5).sum()\nprint(\"En las columnas A tenemos {} de filas por debajo de 5\".format((df[\"A\"] < 5).sum()))\n\n# porcentaje\n(df[\"A\"] < 5).mean()\nprint(\"En las columnas A, los valores inferiores a 5 representan el {}%\".format((df[\"A\"] < 5).mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco78\"></a>\n# Truco 78: realice un seguimiento de la procedencia de sus datos cuando utilice varias fuentes\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# generemos algunos datos falsos\n\ndf1 = generate_sample_data()\ndf2 = generate_sample_data()\ndf3 = generate_sample_data()\n# df1.cabeza()\n# df2.cabeza()\n# df3.cabeza()\ndf1.to_csv(\"trick78data1.csv\")\ndf2.to_csv(\"trick78data2.csv\")\ndf3.to_csv(\"trick78data3.csv\")\n\n# Paso 1 generar lista con el nombre del archivo\n\nlf = []\nfor _,_, files in os.walk(\"/kaggle/working/\"):\n    for f in files:\n        if \"trick78\" in f:\n            lf.append(f)\n            \nlf\n\n# Puede usar esto en su maquina local\n\n#de glob import glob\n\n#files = glob(\"trick78.csv\")\n\n# Paso 2: crear una nueva columna llamada nombre de archivo y el valor es archivo\n\n# Aparte de esto, solo estamos concatenando los diferentes marcos de datos\n\ndf = pd.concat((pd.read_csv(file).assign(filename = file) for file in lf), ignore_index = True)\ndf.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco77\"></a>\n# Truco 77: combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando dónde)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"genre\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf[\"genre\"].value_counts()\n\n# Paso 1: cuenta las frecuencias\n\ntop_four = df[\"genre\"].value_counts().nlargest(4).index\ntop_four\n\n# Paso 2: actualice el df\n\ndf_updated = df.where(df[\"genre\"].isin(top_four), other = \"Other\")\ndf_updated[\"genre\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco76\"></a>\n# Truco 76: filtra en pandas solo las categorías más grandes.\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.columns = map(str.lower, list(df.columns)) # convertir encabezados a tipo inferior\n\ndf.shape\n# seleccione los 3 mejores géneros\n\ntop_genre = df[\"genre\"].value_counts().to_frame()[0:3].index\n\n# Ahora vamos a filtrar la df con el género superior\ndf_top = df[df[\"genre\"].isin(top_genre)]\ndf_top\ndf_top.shape\ndf_top[\"genre\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco75\"></a>\n# Truco 75: cuenta el número de palabras en una serie de pandas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\", usecols=[\"Title\"])\ndf[\"Words\"] = df[\"Title\"].str.count(\" \") + 1\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco74\"></a>\n# Truco 74: Webscraping usando read_html () y parámetro de coincidencia\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ejecute esto en su máquina local\n\n# url = \"https://es.wikipedia.org/wiki/Twitter\"\n# tables = pd.read_html(url)\n# len(tables)\n\n# matching_tables = pd.read_html(url, match = \"Followers\")\n# matching_tables[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco73\"></a>\n# Truco 73: eliminar una columna y almacenarla como una serie separada\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.head()\n\nmeta = df.pop(\"Metascore\").to_frame()\ndf.head()\nmeta.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco72\"></a>\n# Truco 72: Convertir variable continua en categórica (corte y qcut)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.head()\n\n# Usando cortar puede especificar los bordes del contenedor\n\npd.cut(df[\"Metascore\"], bins = [0, 25, 50, 75, 99]).head()\n\n# Usando qcut puede especificar el número de bins y llenar generar de aproximadamente el mismo tamaño\n\npd.qcut(df[\"Metascore\"], q = 3).head()\n\n# cut y qcut aceptan el tamaño de la bandeja de etiquetas\n\npd.qcut(df[\"Metascore\"], q = 4, labels = [\"awful\", \"bad\", \"average\", \"good\"]).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco71\"></a>\n# Truco 71: leer datos de un PDF (tabula py)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tendrás que ejecutarlo en tu máquina local\n#from tabula import read_pdf\n# df = read_pdf (\"test.pdf\", pages = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco70\"></a>\n# Truco 70: Imprime la versión actual de pandas y sus dependencias\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.__version__)\nprint(pd.show_versions())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco69\"></a>\n# Truco 69: comprueba si 2 series son \"similares\"\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[1, 2, 3, 4,], \"B\":[1.0, 2.0, 3.0, 4.0], \"C\":[1.00000, 2.00000, 3.00000, 4.000003], \"D\":[1.0, 2.0, 3.0, 4.0], \"E\":[4.0, 2.0, 3.0, 1.0]}\ndf = pd.DataFrame(d)\ndf\n\ndf[\"A\"].equals(df[\"B\"]) # Ellos requieren tipos de datos idénticos\ndf[\"B\"].equals(df[\"C\"])\ndf[\"B\"].equals(df[\"D\"])\ndf[\"B\"].equals(df[\"E\"]) # y el mismo orden\n\n\nprint(pd.testing.assert_series_equal(df[\"A\"], df[\"B\"], check_names=False, check_dtype=False)) # pasa la afirmación\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco68\"></a>\n# Truco 68: Webscraping usando read_html ()\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tendra que ejecutar esto en su máquina local\n\n#apple_stocks = pd.read_html(\"https://finance.yahoo.com/quote/AAPL/history?p=AAPL\")\n#pd.concat([apple_stocks[0], apple_stocks[1]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco67\"></a>\n# Truco 67: crea nuevas columnas o sobrescribe usando Assing y establece un título para el df\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", usecols=[\"continent\", \"beer_servings\"])\ndf.head()\n\n(df.assign(continent = df[\"continent\"].str.title(),\n           beer_ounces = df[\"beer_servings\"]*12,#                                     esto te permitira establecer un titulo\n\n           beer_galons = lambda df: df[\"beer_ounces\"]/128).query(\"beer_galons > 30\").style.set_caption(\"Average beer consumption\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco66\"></a>\n# Truco 66: Cree un montón de columnas nuevas usando un bucle for y f-strings df [f '{col} _new']\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"d = {\"state\":[\"ny\", \"CA\", \"Tx\", \"FI\"], \"country\":[\"USA\", \"usa\", \"UsA\", \"uSa\"], \"pop\":[1000000, 2000000, 30000, 40000]}\ndf = pd.DataFrame(d)\ndf\n\nint_types = [\"int64\"]\n# creando nuevas columnas\n\nfor col in df.columns:\n    ctype = str(df[col].dtype)\n    if ctype in int_types:\n        df[f'{col}_millions'] = df[col]/1000000\n    elif ctype == \"object\":\n        df[f'{col}_new'] = df[col].str.upper()\n        # tambien puedes soltar las columnas\n\n        df.drop(col, inplace = True, axis = \"columns\")\n        \ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco65\"></a>\n# Truco 65: seleccione columnas usando f-strings (nuevo en pandas 3.6+)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf\n\ndrink = \"wine\"\n\n# nos permite iterar rapidamente sobre columnas\n\ndf[f'{drink}_servings'].to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco64\"></a>\n# Truco 64: corrección de \"SettingWithCopyWarning\" al crear nuevas columnas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\ndf\n\n# Recibiendo esta desagradable advertencia\n\nmales = df[df[\"gender\"] == \"Male\"]\nmales[\"abbreviation\"] = \"M\"\n\n# Arreglando el error\n\nprint(\"Arreglando la advertencia con impresión\")\nmales = df[df[\"gender\"] == \"Male\"].copy()\nmales[\"abbreviation\"] = \"M\"\nmales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco63\"></a>\n# Truco 63: Calcule el recuento continuo con grupos usando cumcount () + 1\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[\"Car\", \"Truck\", \"Car\", \"Truck\", \"cAr\", \"Car\", \"Truck\", \"Moto\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Arreglando columnas\ndf[\"salesperson\"] = df[\"salesperson\"].str.title()\ndf[\"item\"] = df[\"item\"].str.title()\n\ndf[\"count_by_person\"] = df.groupby(\"salesperson\").cumcount() + 1\ndf[\"count_by_item\"] = df.groupby(\"item\").cumcount() + 1\ndf[\"count_by_both\"] = df.groupby([\"salesperson\",\"item\"]).cumcount() + 1\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco62\"></a>\n# Truco 62: Corregir \"SettingWithCopyWarning\" al cambiar columnas usando loc\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\ndf\n\n# Recibiendo esta desagradable advertencia\n\ndf[df[\"gender\"] == \"Male\"][\"gender\"] = 1\ndf[df[\"gender\"] == \"Female\"][\"gender\"] = 0\n\n\nprint(\"Arreglar usando loc\")\ndf.loc[df[\"gender\"] == \"Male\", \"gender\"] = 1\ndf.loc[df[\"gender\"] == \"Female\", \"gender\"] = 0\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco61\"></a>\n# Truco 61: leer JSON de la web en un df\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"https://github.com/justmarkham?tab=repositories\"\n\n# ejecutarlo en su máquina local\n# df = pd.read_json(url)\n# df = df[df[\"fork\"] == False]\n# df.shape\n# df.head()\n\n# lc = [\"name\", \"stargazers_count\", \"forks_count\"]\n# df[lc].sort_values(\"stargazers_count\", asending = False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco60\"></a>\n# Truco 60: Creación de totales acumulados con la función cumsum\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\ndf = pd.DataFrame(d)\ndf\n\ndf[\"running_total\"] = df[\"item\"].cumsum()\ndf[\"running_total_by_person\"] = df.groupby(\"salesperson\")[\"item\"].cumsum()\ndf\n\n# otras funciones útiles son cummax (), cummin (), cumprod ()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco59\"></a>\n# Truco 59: combine la salida de una agregación con el df original usando transform\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"orderid\":[1, 1, 1, 2, 2, 3, 4, 5], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Esta es la salida que queremos agregar al df original\")\ndf.groupby(\"orderid\")[\"item\"].sum().to_frame()\n\ndf[\"total_items_sold\"] = df.groupby(\"orderid\")[\"item\"].transform(sum)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco58\"></a>\n# Truco 58: use encabezados y saltos para deshacerse de datos incorrectos o filas vacías durante la importación\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tenemos filas vacías y datos incorrectos\n\ndf = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\")\ndf\n\n# importando datos correctos\n\ndf = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\", header = 2, skiprows = [3,4])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco57\"></a>\n# Truco 57: Accediendo a los grupos de un objeto groupby (get_group ())\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\")\ndf\n\ngbdf = df.groupby(\"Genre\")\ngbdf.get_group(\"Horror\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco56\"></a>\n# Truco 56: Aplicar asignaciones o funciones a todo el df (applymap)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"A\":[\"Male\", \"Female\", \"Female\", \"Male\"], \"B\":[\"x\", \"y\", \"z\", \"A\"], \"C\":[\"male\", \"female\", \"male\", \"female\"], \"D\":[1, 2, 3, 4]})\ndf\n\n# primero usemos applymap para convertir y estandarizar el texto\n\ndf = df.applymap(lambda x: x.lower() if type(x) == str else x)\n\nmapping = {\"male\":0, \"female\":1}\n\nprint(\"PROBLEMA: Se aplica a toda la df pero se vuelve a ejecutar Ninguna\")\ndf.applymap(mapping.get)\n\nprint(\"Obtenga el resultado correcto pero debe especificar las columnas. Si no desea hacer esto, verifique el siguiente resultado\")\ndf[[\"A\", \"C\"]].applymap(mapping.get)\n\nprint(\"Mapa de aplicación condicional: si se puede asignar -> mapa, si no, devolver el mismo valor\")\ndf = df.applymap(lambda x: mapping[x] if x in mapping.keys() else x)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco55\"></a>\n# Truco 55: filtrar un df con múltiples criterios usando reducir\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf\n\nprint(\"Filtro clásico difícil de leer y mantener.\")\ndf[(df[\"continent\"] == \"Europe\") & (df[\"beer_servings\"] > 150) & (df[\"wine_servings\"] > 50) & (df[\"spirit_servings\"] < 60)]\n\nprint(\"Puede dividirlo en varias líneas para que sea más legible. Pero sigue siendo difícil de leer.\")\ndf[\n    (df[\"continent\"] == \"Europe\") & \n    (df[\"beer_servings\"] > 150) & \n    (df[\"wine_servings\"] > 50) & \n    (df[\"spirit_servings\"] < 60)\n]\n\nprint(\"Criterios de guardado de soluciones como objetos\")\n\ncr1 = df[\"continent\"] == \"Europe\"\ncr2 = df[\"beer_servings\"] > 150\ncr3 = df[\"wine_servings\"] > 50\ncr4 = df[\"spirit_servings\"] < 60\n\ndf[cr1 & cr2 & cr3 & cr4]\n\nprint(\"Solución usando reducir\")\nfrom functools import reduce\n\n# crea nuestros criterios utilizando lambda\n# lambda toma 2 parámetros, x y y\n# Reducir las combina y para cada cr en el (cr1, cr2, cr3, cr4)\ncriteria = reduce(lambda x, y: x & y, (cr1, cr2, cr3, cr4))\ndf[criteria]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco54\"></a>\n# Truco 54: Calcula la diferencia entre cada fila y la anterior (diff ())\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf[\"A_diff\"] = df[\"A\"].diff() # calcular la diferencia entre 2 filas\n\ndf[\"A_diff_pct\"] = df[\"A\"].pct_change()*100 # calcula la variación porcentual entre 2 filas\n\n\n# agrega algo de estilo\ndf.style.format({\"A_diff_pct\":'{:.2f}%'})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco53\"></a>\n# Truco 53: mezclar filas de un df (df.sample ())\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\n\ndf.sample(frac = 0.5, random_state = 2)\ndf.sample(frac = 0.5, random_state = 2).reset_index(drop = True) # restablecer el índice después de barajar\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco52\"></a>\n# Truco 52: Hacer tramas con pandas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\n\ndf.plot(kind = \"line\")\ndf.plot(kind = \"bar\")\ndf.plot(kind = \"barh\")\ndf.plot(kind = \"hist\")\ndf.plot(kind = \"box\")\ndf.plot(kind = \"kde\")\ndf.plot(kind = \"area\")\n\n# las siguientes parcelas requieren x y y\n\ndf.plot(x = \"A\", y = \"B\", kind = \"scatter\")\ndf.plot(x = \"A\", y = \"B\", kind = \"hexbin\")\ndf.plot(x = \"A\", y = \"B\", kind = \"pie\") # aquí puede pasar solo x pero necesita agregar subparcelas = Verdadero\n\n\n# otras parcelas están disponibles a través de pd.plotting\n\n# más sobre trazar https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco51\"></a>\n# Truco 51: Concatenar cadenas de 2 columnas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\n# Solución 1: usando str.cat\n \ndf[\"Name\"].str.cat(df[\"Sex\"], sep = \", \").head()\n\n# usando + signo\n\ndf[\"Name\"] + \", \" + df[\"Sex\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco50\"></a>\n# Truco 50: agregación con nombre con varias columnas que pasan tupples (nuevo en pandas 0.25)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\n# Grupo típico\nprint(\"Problema: Multiíndice\")\ndf.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"], \"Survived\": \"mean\"})\n\n# Tenga en cuenta que esto se ha cubierto en 86 y 86 bis.\n\n# Esta es solo una forma más de hacerlo.\n\nprint(\"Agregación con nombre\")\ndf.groupby(\"Pclass\").agg(avg_age = (\"Age\", \"mean\"),\n                        max_age = (\"Age\", \"max\"), \n                        survival_rate = (\"Survived\", \"mean\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco49\"></a>\n# Truco 49: Muestreo con pandas (con reemplazo y pesos)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\": [100, 200, 300, 400, 100], \"W\":[10, 5, 0, 3, 8]}\ndf = pd.DataFrame(d)\ndf\n\n# con reemplazo\n\ndf.sample(n = 5, replace = True, random_state = 2)\n\n# sumando pesos\n\ndf.sample(n = 5, replace = True, random_state = 2, weights = \"W\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco48\"></a>\n# Truco 48: Parámetros útiles al usar pd.read_csv ()\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf.head()\ndf.dtypes\n\n# Vamos a importar las columnas country y beer_servings, convertirlas a string y float64 respectevly\n# Importa solo las primeras 5 filas y subproceso 0 como nans\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\",\n                    usecols=[\"country\", \"beer_servings\"],\n                    dtype={\"country\":\"category\", \"beer_servings\":\"float64\"},\n                    nrows = 5,\n                    na_values = 0.0)\ndf.head()\ndf.dtypes\n\n#más sobre read_csv en https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco47\"></a>\n# Truco 47: crea una fila para cada elemento en una lista (explotar)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"Players\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n\nprint(\"Tenga en cuenta que tenemos una lista de jugadores para cada equipo. Generemos una fila para cada jugador.\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Usando explotar para generar nuevas filas para cada jugador.\")\ndf1 = df.explode(\"Players\")\ndf1\n\nprint(\"Invierta esta operación con groupby y agg\")\ndf[\"Imploded\"] = df1.groupby(df1.index)[\"Players\"].agg(list)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco46\"></a>\n# Truco 46: Almacene NaN en un tipo entero con Int64 (no int64)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Serie predeterminada\")\nser1 = pd.Series([10, 20])\nser1\n\nprint(\"Agreguemos una NaN a una serie int64\")\nser1 = pd.Series([10, 20, np.nan])\nser1 # Observe que se ha convertido a float64\n\nprint(\"Pero si usamos Int64, todo funcionará.\")\nser1 = pd.Series([10, 20, np.nan], dtype = \"Int64\")\nser1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco45\"></a>\n# Truco 45: Cree filas para valores separados por comas en una celda (Assing y explotar)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"Players\":[\"Ter Stegen, Semedo, Piqué, Lenglet, Alba, Rakitic, De Jong, Sergi Roberto, Messi, Suárez, Griezmann\",\n               \"Courtois, Carvajal, Varane, Sergio Ramos, Mendy, Kroos, Valverde, Casemiro, Isco, Benzema, Bale\"]}\n\nprint(\"Tenga en cuenta que tenemos una lista de jugadores para cada equipo separados por comas. Generemos una fila para cada jugador.\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Observe que nos hemos convertido a algo similar visto en el ejemplo 47.\")\ndf.assign(Players = df[\"Players\"].str.split(\",\"))\n\nprint(\"Ahora agregue explotar y listo.\")\ndf.assign(Players = df[\"Players\"].str.split(\",\")).explode(\"Players\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco44\"></a>\n# Truco 44: usa una variable local dentro de una consulta en pandas (usando @)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf\n\n# crear una media de variable local\n\nmean = df[\"A\"].mean()\n\n# ahora usemos dentro de una consulta de pandas usando @\n\ndf.query(\"A > @mean\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco43\"></a>\n# Truco 43: ¡Crea una fila para cada elemento de una lista (explotar)! ¡¡¡Truco 47 duplicado !!!\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parece que este truco está duplicado, pasa al siguiente\n# Decidí quedarme, así que en el futuro no habrá confusión si consulta el material original\n# y este kernel\nd = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"Players\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n\nprint(\"Tenga en cuenta que tenemos una lista de jugadores para cada equipo. Generemos una fila para cada jugador.\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Usando explotar para generar nuevas filas para cada jugador.\")\ndf1 = df.explode(\"Players\")\ndf1\n\nprint(\"Invierta esta operación con groupby y agg\")\ndf[\"Imploded\"] = df1.groupby(df1.index)[\"Players\"].agg(list)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco42\"></a>\n# Truco 42: Nueva función de agregación -> last ()\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"patient\":[1, 2, 3, 1, 1, 2], \"visit\":[2015, 2016, 2014, 2016, 2017, 2020]}\ndf = pd.DataFrame(d)\ndf.sort_values(\"visit\")\n\nprint(\"Hagamos la última visita para cada paciente.\")\ndf.groupby(\"patient\")[\"visit\"].last().to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco41\"></a>\n# Trick 41: Categorías ordenadas (de pandas.api.types import CategoricalDtypee)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pandas.api.types import CategoricalDtype\nd = {\"ID\":[100, 101, 102, 103], \"quality\":[\"bad\", \"very good\", \"good\", \"excellent\"]}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Creemos nuestro propio orden categórico\")\ncat_type = CategoricalDtype([\"bad\", \"good\", \"very good\", \"excellent\"], ordered = True)\ndf[\"quality\"] = df[\"quality\"].astype(cat_type)\ndf\n\nprint(\"Ahora podemos usar la clasificación lógica\")\ndf = df.sort_values(\"quality\", ascending = True)\ndf\n\nprint(\"También podemos filtrar esto como si fueran números. ASOMBROSO.\")\ndf[df[\"quality\"] > \"bad\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco40\"></a>\n# Truco 40: Estilo que df rápido con hide_index () y set_caption ()\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\nprint(\"Df Original\")\ndf\n\ndf.style.hide_index().set_caption(\"Styled df with no index and a caption\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco39\"></a>\n# Truco 39: una codificación en caliente (get_dummies ())\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\", usecols = [2, 4, 5, 11], nrows = 10)\ndf\n\npd.get_dummies(df) # Observe que podemos eliminar una columna de cada una ya que esta información está contenida en las demás\n\n\npd.get_dummies(df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco38\"></a>\n# Truco 38: Pandas datetime (muchos ejemplos)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()\ndf = df.sample(500)\ndf[\"Year\"] = df[\"index\"].dt.year\ndf[\"Month\"] = df[\"index\"].dt.month\ndf[\"Day\"] = df[\"index\"].dt.day\ndf[\"Hour\"] = df[\"index\"].dt.hour\ndf[\"Minute\"] = df[\"index\"].dt.minute\ndf[\"Second\"] = df[\"index\"].dt.second\ndf[\"Nanosecond\"] = df[\"index\"].dt.nanosecond\ndf[\"Date\"] = df[\"index\"].dt.date\ndf[\"Time\"] = df[\"index\"].dt.time\ndf[\"Time_Time_Zone\"] = df[\"index\"].dt.timetz\ndf[\"Day_Of_Year\"] = df[\"index\"].dt.dayofyear\ndf[\"Week_Of_Year\"] = df[\"index\"].dt.weekofyear\ndf[\"Week\"] = df[\"index\"].dt.week\ndf[\"Day_Of_week\"] = df[\"index\"].dt.dayofweek\ndf[\"Week_Day\"] = df[\"index\"].dt.weekday\ndf[\"Week_Day_Name\"] = df[\"index\"].dt.weekday_name\ndf[\"Quarter\"] = df[\"index\"].dt.quarter\ndf[\"Days_In_Month\"] = df[\"index\"].dt.days_in_month\ndf[\"Is_Month_Start\"] = df[\"index\"].dt.is_month_start\ndf[\"Is_Month_End\"] = df[\"index\"].dt.is_month_end\ndf[\"Is_Quarter_Start\"] = df[\"index\"].dt.is_quarter_start\ndf[\"Is_Quarter_End\"] = df[\"index\"].dt.is_quarter_end\ndf[\"Is_Leap_Year\"] = df[\"index\"].dt.is_leap_year\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco37\"></a>\n# Truco 37: Pandas cortando loc e iloc (6 ejemplos)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf\n\n# usando loc -> etiquetas\n\ndf.loc[0, \"A\"]\n\n# usando iloc -> posición\n\ndf.iloc[0, 0]\n\n# mezcla de etiquetas y posición con loc\n\ndf.loc[0, df.columns[0]]\n\n# mezcla de etiquetas y posición con loc\n\ndf.loc[df.index[0], \"A\"]\n\n# mezcla de etiquetas y posición con iloc\n\ndf.iloc[0, df.columns.get_loc(\"A\")]\n\n# mezcla de etiquetas y posición con iloc\n\ndf.iloc[df.index.get_loc(0), 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco36\"></a>\n# Truco 36: Convertir de UTC a otra zona horaria\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = pd.Series(range(1552194000, 1552212001, 3600))\ns = pd.to_datetime(s, unit = \"s\")\ns\n\n# establecer la zona horaria en la zona horaria actual (UTC)\n\n\ns = s.dt.tz_localize(\"UTC\")\ns\n\n# establecer zona horaria en otra zona horaria (Chicago)\n\ns = s.dt.tz_convert(\"America/Chicago\")\ns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco35\"></a>\n# Truco 35: consulta una columna que tenga espacios en el nombre (usando comillas invertidas)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"colum_without_space\":np.array([1, 2, 3, 4, 5, 6]), \"column with space\":np.array([1, 2, 3, 4, 5, 6])*2}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Consultar una columna sin espacio\")\ndf.query(\"colum_without_space > 4\")\nprint(\"Consultar una columna con espacio usando comillas invertidas ``\")\nprint(\"Esto es una tilde ``\")\ndf.query(\"`columna con espacio` > 8\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco34\"></a>\n# Truco 34: Explore un conjunto de datos con creación de perfiles\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\n\ndf = generate_sample_data()\n\ndf\n\nprint(\"Generación de informes con perfiles de pandas\")\ndf.profile_report()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco33\"></a>\n# Truco 33: opciones de visualización de pandas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)|"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use pd.describe_option() to see all\n# max_rows\n# max_columns\n# max_colwidth\n# precision\n# date_dayfirst\n# date_yearfirst\n\ndf = generate_sample_data_datetime()[:10].reset_index()\ndf[\"sales\"] = df[\"sales\"].astype(\"float\")\ndf\n\npd.set_option(\"display.max_rows\",5)\npd.set_option(\"display.max_columns\",3)\npd.set_option('display.width', 1000)\npd.set_option('display.date_dayfirst', True)\npd.describe_option()\n\npd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n#pd.reset_option('display.width') # restaurar uno por uno","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco32\"></a>\n# Truco 32: filtrar un df con consulta y evitar variables intermedias\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:10]\ndf[\"A\"] = pd.Series([\"APP\", \"GOO\", \"APP\", \"GOO\", \"MIC\", \"MIC\", \"APP\", \"GOO\", \"MIC\", \"APP\"])\ndf.rename(columns = {\"A\":\"stock\"}, inplace = True)\nprint(\"DF Original\")\ndf\n\nprint(\"Filtrar datos usando variables intermedias\")\ntemp = df.groupby(\"stock\").mean()\ntemp \n\nfv = temp[\"B\"].sort_values(ascending = False)[1] # filtrar por el segundo gran. De esta forma cada vez que generamos datos de muestra tendremos un resultado\n\ntemp[temp[\"B\"] < fv]\n\nprint(\"Filtrar mediante consulta\")\ndf.groupby(\"stock\").mean().query(\"B < {}\".format(fv))\ndf.groupby(\"stock\").mean().query(\"B < @fv\")\ndf.groupby(\"stock\").mean().query(\"B < 10\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco31\"></a>\n# Truco 31: Ver todas las columnas de un gran df\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n\n\ndf = generate_sample_data()\ndf1 = df.copy(deep = True)\ndf = df.append(df1)\n\nprint(\"Imagina que tenemos un gran df donde podemos ver todas las columnas ...\")\ndf.T.head() # Nosotros estamos transponiendo SOLO PARA CREAR UN DF GIGANTE\n\n# Solucion 1\nprint(\"Solución 1 usando pd.set_option display.max_columns\")\npd.set_option(\"display.max_columns\", None)\ndf.T.head()\npd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n\n# Solucion 2\nprint(\"Otra solución inteligente con Traspose\")\ndf.T.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco30\"></a>\n# Truco 30: Pandas se fusionan -> ver de dónde vienen las columnas (indicador = Verdadero)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf1 = df.copy(deep = True)\ndf1 = df1.drop([0, 1, 2], axis = \"rows\") # suelte un índice solo para ver el funcionamiento de ejemplo\ndf.head()\ndf1.head()\n\npd.merge(df, df1, how = \"left\", indicator = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco29\"></a>\n# Truco 29: acceda a numpy dentro de pandas (sin importar numpy como np)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pandas se basa en numpy, por lo que podemos acceder a todas las funciones de numpy de pandas\n\npd.np.random.rand(2, 3)\npd.np.nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco28\"></a>\n# Truco 28: agregando por múltiples columnas (usando agg)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\nprint(\"DF Original\")\ndf\n\nprint(\"Porciones de cerveza por continente\")\ndf.groupby(\"continent\")[\"beer_servings\"].mean()\n\nprint(\"Usando agg para pasar múltiples funciones\")\ndf.groupby(\"continent\")[\"beer_servings\"].agg([\"mean\", \"count\"])\n\nprint(\"Usar describir sobre un objeto groupby\")\ndf.groupby(\"continent\")[\"beer_servings\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco27\"></a>\n# Truco 27: agregación sobre series temporales (remuestreo)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()\n\nprint(\"DF Original\")\ndf\nprint(\"Volvamos a muestrear / agrupar por mes\")\ndf.resample(\"M\")[\"sales\"].sum()\n\nprint(\"Volvamos a muestrear / agrupar por día\")\ndf.resample(\"D\")[\"sales\"].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco26\"></a>\n# Truco 26: formatear diferentes columnas de un df (usando diccionarios)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()[:10]\ndf.rename(columns = {\"index\":\"time\"}, inplace = True)\ndf[\"sales_100\"] = df[\"sales\"]*100\nprint(\"DF Original\")\ndf.head()\n\n# declarar un dictado de formato: individual para cada columna\nfd = {\"time\":\"{:%d/%m/%y}\", \"sales\":\"${:.2f}\", \"customers\":\"{:,}\"}\ndf.style.format(fd)\ndf\n\n# agregue más formato\n\n(df.style.format(fd)\n .hide_index()\n .highlight_min(\"sales\", color =\"red\")\n .highlight_max(\"sales\", color =\"green\")\n .background_gradient(subset = \"sales_100\", cmap =\"Blues\")\n .bar(\"customers\", color = \"lightblue\", align = \"zero\")\n .set_caption(\"A df with different stylings\")\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco25\"></a>\n# Truco 25: 3 formas de cambiar el nombre de las columnas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head(2)\n\n# Solucion 1\ndf.rename({\"A\":\"col_1\", \"B\":\"col_2\"}, axis = \"columns\", inplace = True)\ndf.head(2)\n\n# Solucion 2\ndf.columns = [\"col1\", \"col2\", \"col3\", \"col4\",\"col5\", \"col6\", \"col7\"] # list must be equal to the columns number\ndf.head(2)\n\n# Solucion 3\ndf.columns = df.columns.str.title() # aplicar cualquier método de cadena a los nombres de las columnas\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco24\"></a>\n# Truco 24: copie datos de Excel a pandas rápidamente (read_clipboard ())\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tendrá que verificar esto en su máquina local\n# Útil para importar rápidamente\n# Paso 1: copie una tabla de la hoja de Excel usando ctrl + c (al portapapeles)\n# Paso 2: ejecuta este comando\n# df = pd.read_clipboard ()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco23\"></a>\n# Truco 23: Complete los valores faltantes en los datos de series de tiempo (interpolar ())\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"col1\":[100, 120 ,140, np.nan, 160], \"col2\":[9, 10, np.nan, 7.5, 6.5]}\ndf = pd.DataFrame(d)\ndf.index = pd.util.testing.makeDateIndex()[0:5]\nprint(\"DF Original\")\ndf\nprint(\"DataFrame después de interpolar\")\ndf.interpolate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco22\"></a>\n# Truco 22: Crea DataFrames para probar\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Contiene valores aleatorios\")\ndf1 = pd.util.testing.makeDataFrame() #contiene valores aleatorios\ndf1\nprint(\"Contiene valores perdidos\")\ndf2 = pd.util.testing.makeMissingDataframe() # contiene valores perdidos\n\ndf2\nprint(\"Contiene valores de fecha y hora\")\ndf3 = pd.util.testing.makeTimeDataFrame() # contiene valores de fecha y hora\n\ndf3\nprint(\"Contiene valores mixtos\")\ndf4 = pd.util.testing.makeMixedDataFrame() # contiene valores mixtos\n\ndf4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco21\"></a>\n# Truco 21: divide una columna de cadena en varias columnas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"name\":[\"John Artur Doe\", \"Jane Ann Smith\", \"Nico P\"], \"location\":[\"Los Angeles, CA\", \"Washington, DC\", \"Barcelona, Spain\"]}\ndf = pd.DataFrame(d)\ndf\n\ndf[[\"first\", \"middle\", \"last\"]] = df[\"name\"].str.split(\" \", expand = True)\ndf[\"city\"] = df[\"location\"].str.split(\",\", expand = True)[0]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco20\"></a>\n# Truco 20: crea columnas de fecha y hora a partir de varias columnas\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"day\":[1, 2, 10 ,25, 12], \"month\":[1, 2, 4, 5, 6], \"year\":[2000, 2001, 2010, 2015, 2020]}\ndf = pd.DataFrame(d)\ndf[\"date\"] = pd.to_datetime(df[[\"day\", \"month\", \"year\"]])\ndf\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco19\"></a>\n# Truco 19: muestra el uso de memoria de un df y cada columna\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()\ndf.columns = [\"date\", \"sales\", \"customers\"]\ndf\n\nprint(\"Muestra el uso global de la memoria del df\")\ndf.info(memory_usage = \"deep\")\nprint()\nprint(\"Muestra el uso de memoria de cada columna.\")\ndf.memory_usage(deep = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco18\"></a>\n# Truco 18: leer y escribir en un archivo comprimido (csv.zip)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\n\nprint(\"Escribir datos en un archivo csv.zip\")\ndf.to_csv(\"trick18data.csv.zip\")\n\nprint(\"Eliminando df\")\ndel df\n\nprint(\"Importación de datos de un archivo csv.zip\")\ndf = pd.read_csv(\"/kaggle/working/trick18data.csv.zip\", index_col=0)\ndf.head()\n\n# otros archivos de compresión admitidos .gz, .bz2, .xz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco17\"></a>\n# Truco 17: seleccione varias filas y columnas con loc\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\nprint(\"DF Original\")\ndf\n\nprint(\"Usando una rebanada (inclusive)\")\ndf.loc[0:4, \"A\":\"E\"]\n\nprint(\"Usando una lista\")\ndf.loc[[0,4], [\"A\",\"E\"]]\n\nprint(\"Usando una condicion\")\ndf.loc[df[\"A\"] > 10, [\"A\",\"E\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco16\"></a>\n# Truco 16: convierta valores continuos en categóricos (cortar ())\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf[\"A\"] = df[\"A\"] + 5\ndf.rename(columns = {\"A\":\"age\"}, inplace = True)\ndf.sample(5)\n\ndf[\"age_groups\"] = pd.cut(df[\"age\"], bins = [0, 18, 65, 99], labels = [\"kids\", \"adult\", \"elderly\"])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco15\"></a>\n# Truco 15: Remodelar una MultiIndex df (desapilar ())\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(\"DF Original\")\ndf.head()\n\nprint(\"Groupby y crear un MultiIndex df\")\nprint(\"Tenga en cuenta que tenemos un df con MultiIndex (Sex y Pclass)\")\ndf.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().to_frame()\n\nprint(\"Remodelar usando desapilar\")\nprint(\"Ahora podemos interactuar con él como con un df normal.\")\ndf.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().unstack()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco14\"></a>\n# Truco 14: Creando juguete df (3 métodos)\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Método 1: de un dictado\n\npd.DataFrame({\"A\":[10 ,20], \"B\":[30, 40]})\n\n# Método 2: usando numpy\n\npd.DataFrame(np.random.rand(2, 3), columns = list(\"ABC\"))\n\n# Método 3: usar funcionalidades integradas de pandas\n\npd.util.testing.makeMixedDataFrame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco13\"></a>\n# Truco 13: Evita la serie de listas TRAP\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[1, 2, 3], \"B\":[[10, 20], [40, 50], [60, 70]]}\ndf = pd.DataFrame(d)\nprint(\"Observe que la columna B tiene listas de valores\")\ndf\nprint(\"Conviértelo a serie normal\")\ndf_ = df[\"B\"].apply(pd.Series)\ndf_\n\nprint(\"Únete a los 2 df\")\npd.merge(df, df_, left_index = True, right_index = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco12\"></a>\n# Truco 12: fusionar conjuntos de datos y verificar la unicidad\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:10]\ndf1 = df.copy(deep = True)\ndf = df.drop([0, 1, 2])\ndf1 = df1.drop([8, 9])\ndf\ndf1\n\ndf_one_to_one = pd.merge(df, df1, validate = \"one_to_one\")\ndf_one_to_one\n\ndf_one_to_many = pd.merge(df, df1, validate = \"one_to_many\")\ndf_one_to_many\n\ndf_many_to_one = pd.merge(df, df1, validate = \"many_to_one\")\ndf_many_to_one\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco11\"></a>\n# Truco 11: cambie el nombre de todas las columnas con el mismo patrón\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.columns = [\"Passenger ID\", \"Survived\", \"Pclass\", \"Name         \", \"Sex\", \"Age\", \"Sib SP\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"] # creating column names for the example\ndf\ndf1 = df.copy(deep = True)\n\nprint(\"Reemplazar todos los espacios con undescore y convertir a menor\")\nprint(\"Observe que la columna SP de pasajero y hermano ahora tiene un guión bajo\")\ndf.columns = df.columns.str.replace(\" \", \"_\").str.lower()\ndf.head()\n\nprint(\"Quite la parte blanca final (al final) y conviértala en menor\")\nprint(\"Observe que la columna SP de pasajero y hermano ahora tiene un guión bajo\")\ndf1.columns = df1.columns.str.lower().str.rstrip()\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco10\"></a>\n# Truco 10: comprueba la igualdad de 2 series\n\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[[\"A\", \"B\"]][:5]\ndf[\"A\"] = pd.Series([15, 15, 18, np.nan, 12])\ndf[\"B\"] = pd.Series([15, 15, 18, np.nan, 12])\ndf\n\nprint(\"No use ==, no maneja NaN correctamente\")\nprint(\"Observe que el elemento 4 de cada lista es np.nan pero == aún devuelve False\")\ndf[\"A\"] == df[\"B\"]\n\nprint(\"Usando iguales. Ahora obtenemos True, por lo que las 2 series son iguales\")\ndf[\"A\"].equals(df[\"B\"])\n\nprint(\"Igual también funciona para df\")\ndf1 = df.copy(deep = True)\ndf.equals(df1)\n\nprint(\"== de df tiene el mismo problema que para la serie\")\ndf == df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco9\"></a>\n# Truco 9: ¡Reduzca el uso de memoria de un df al importar! ¡¡¡Truco 83 duplicado !!!\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"])\ndf.dtypes\ndf.memory_usage(deep = True)\n\nprint(\"Importando solo unas pocas columnas y convirtiendo al tipo de archivo adecuado\")\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"], \\\n                dtype = {\"Genre\":\"category\", \"Metascore\":\"Int64\", \"Year\":\"int8\"})\ndf.dtypes\ndf.memory_usage(deep = True) # observe cómo el género y el año consumen ahora menos memoria","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco8\"></a>\n# Truco 8: ¡Usar glob para generar un df a partir de varios archivos! ¡¡¡Truco 78 duplicado !!!\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# generemos algunos datos falsos\ndf1 = generate_sample_data()\ndf2 = generate_sample_data()\ndf3 = generate_sample_data()\n# df1.head()\n# df2.head()\n# df3.head()\ndf1.to_csv(\"trick8data1.csv\", index = False)\ndf2.to_csv(\"trick8data2.csv\", index = False)\ndf3.to_csv(\"trick8data3.csv\", index = False)\n\n# Paso 1 generar lista con el nombre del archivo\nlf = []\nfor _,_, files in os.walk(\"/kaggle/working/\"):\n    for f in files:\n        if \"trick8data\" in f:\n            lf.append(f)\n            \nlf\n\n# Puede usar esto en su máquina local\n#desde glob import glob\n#files = glob (\"truco8.csv\")\n\n# Paso 2: hacemos lo mismo que en el truco 78, excepto que no creamos una nueva columna del origen de las filas (archivo del que provienen)\ndf = pd.concat((pd.read_csv(file) for file in lf), ignore_index = True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco7\"></a>\n# Truco 7: lidiar con los valores perdidos (NaN)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.util.testing.makeMissingDataframe().reset_index() # contiene valores perdidos\ndf.rename(columns = {\"index\":\"A\"})\ndf1 = df.copy(deep = True)\ndf\n\nprint(\"Calcule el% de valores perdidos en cada fila\")\ndf.isna().mean() # calcular el% de valores perdidos en cada fila\nprint(\"Descartando cualquier columna que tenga valores perdidos. Solo quedará la columna A\")\ndf.dropna(axis = \"columns\") # eliminar cualquier columna que tenga valores perdidos\nprint(\"Descartando cualquier fila que tenga valores perdidos.\")\ndf1.dropna(axis = \"rows\") # eliminar cualquier fila que tenga valores perdidos\nprint(\"Columna descartada donde los valores faltantes están por encima de un umbral\")\ndf.dropna(thresh = len(df)*0.95, axis = \"columns\") # eliminar cualquier fila que tenga valores perdidos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco6\"></a>\n# Truco 6: divide un df en 2 subconjuntos aleatorios\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf_1 = df.sample(frac = 0.7)\ndf_2 = df.drop(df_1.index) # solo funciona si el índice df es único\n\n\ndf.shape\ndf_1.shape\ndf_2.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco5\"></a>\n# Truco 5: convierte números almacenados como cadenas (coaccionar)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"col1\":[\"1\", \"2\", \"3\", \"stuff\"], \"col2\":[\"1\", \"2\", \"3\", \"4\"]}\ndf = pd.DataFrame(d)\ndf.astype({\"col2\":\"int\"}) # tsu fallará para col1 -> ValueError: literal inválido para int () con base 10: 'cosas'\n\nprint(\"Tenga en cuenta que ahora las cosas se convirtieron a NaN\")\ndf.apply(pd.to_numeric, errors = \"coerce\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco4\"></a>\n# Truco 4: seleccione columnas por dtype\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()[:10].reset_index()\ndf[\"string_col\"] = list(\"ABCDEABCDE\")\ndf[\"sales\"] = df[\"sales\"].astype(\"float\")\nprint(\"DF Original\")\ndf\n\nprint(\"Seleccionar columnas numéricas\")\ndf.select_dtypes(include = \"number\")\n\nprint(\"Seleccionar columnas de cadena\")\ndf.select_dtypes(include = \"object\")\n\nprint(\"Seleccionar columnas de fecha y hora\")\ndf.select_dtypes(include = [\"datetime\", \"timedelta\"])\n\nprint(\"Seleccionar varios\")\ndf.select_dtypes(include = [\"number\", \"object\", \"datetime\", \"timedelta\"])\n\nprint(\"Seleccione pasando los tipos que necesita\")\ndf.select_dtypes(include = [\"int8\", \"int16\", \"int32\", \"int64\", \"float\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco3\"></a>\n# Truco 3: filtrar un df por múltiples condiciones (isin e inverso usando ~)\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\ndf[\"A\"] = [1, 2, 3, 4, 5]\n\nprint(\"Filtrar usando múltiples |\")\ndf[(df[\"A\"] == 1) | (df[\"A\"] == 3)]\n\nprint(\"Filtrar usando isin\")\ndf[df[\"A\"].isin([1, 3])]\n\nprint(\"Invertir usando ~ (ctrl + alt + 4)\")\ndf[~df[\"A\"].isin([1, 3])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco2\"></a>\n# Truco 2: orden inverso de una df\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\ndf\n\nprint(\"Orden de columna inverso\")\ndf.loc[:, ::-1]\n\nprint(\"Orden de filas inverso\")\ndf.loc[::-1]\n\nprint(\"Invertir el orden de las filas y restablecer el índice\")\ndf.loc[::-1].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco1\"></a>\n# Truco 1: agregue un prefijo o sufijo a todas las columnas\n[Volver a la tabla de contenidos](#tabla_de_contenidos)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\nprint(\"DF Original\")\ndf\n\nprint(\"Agregar prefijo\")\ndf.add_prefix(\"1_\")\n\nprint(\"Agregar sufijo\")\ndf.add_suffix(\"_Z\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# El fin\n# Muchas gracias. Si hiciste hasta el final, habrás aprendido muchos pandas"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}