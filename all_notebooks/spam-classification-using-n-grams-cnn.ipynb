{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.layers import Embedding\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\nfrom keras.layers.merge import concatenate\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.vis_utils import plot_model\nfrom numpy import array\n\ndef get_data(train_file, test_file = None):\n    if test_file == None:\n        frame = pd.read_csv(train_file)\n        data = frame.values\n        np.random.shuffle(data)\n        return data\n    else:\n        train_frame = pd.read_csv(train_file)\n        test_frame = pd.read_csv(test_file)\n\n        train_data = train_frame.values\n        test_data = test_frame.values\n        np.random.shuffle(train_data)\n        np.random.shuffle(test_data)\n\n        return train_data, test_data\n\ndef get_training_testing_sets(train_file, test_file = None):\n    if test_file == None:\n        data = get_data(train_file)\n        train_data, test_data = train_test_split(data)\n    else:\n\n        train_data, test_data = get_data(train_file, test_file)\n\n    X_train = train_data[:, 1]\n    Y_train = train_data[:, 0]\n    X_test = test_data[:, 1]\n    Y_test = test_data[:, 0]\n\n    print(X_train.shape, X_test.shape)\n    \n    return X_train, Y_train, X_test, Y_test\n\ndef get_tokenizer(lines):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(lines)\n    return tokenizer\n\ndef max_length(lines):\n    return max([len(sentence.split()) for sentence in lines])\n\ndef encode_text(tokenizer, lines, length):\n    encoded = tokenizer.texts_to_sequences(lines)\n    padded = pad_sequences(encoded, maxlen=length, padding='post')\n    return padded\n\ndef define_model(length, vocab_size, channels, kernel_size):\n    inputs = {}\n    embedding = {}\n    conv = {}\n    drop = {}\n    pool = {}\n    flat = {}\n    for channel in range(1, channels + 1):\n        inputs[channel] = Input(shape = (length,))\n        embedding[channel] = Embedding(vocab_size, 100)(inputs[channel])\n        conv[channel] = Conv1D(filters = 32, kernel_size = kernel_size[channel], activation = 'relu')(embedding[channel])\n        drop[channel] = Dropout(0.5)(conv[channel])\n        pool[channel] = MaxPooling1D(pool_size = 2)(drop[channel])\n        flat[channel] = Flatten()(pool[channel])\n    merged = concatenate(list(flat.values()))\n    dense = Dense(10, activation = 'relu')(merged)\n    outputs = Dense(1, activation = 'sigmoid')(dense)\n    \n    model = Model(list(inputs.values()), outputs=outputs)\n    \n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    \n    print(model.summary())\n    plot_model(model, show_shapes = True, to_file = 'multichannel.png')\n    return model\n\n\nX_train, Y_train, X_test, Y_test = get_training_testing_sets('../input/SPAM text message 20170820 - Data.csv')\nfor i in range(Y_train.shape[0]):\n    Y_train[i] = (Y_train[i] == 'spam')\n\nfor i in range(Y_test.shape[0]):\n    Y_test[i] = (Y_test[i] == 'spam')\n\n\ntokenizer = get_tokenizer(X_train)\nlength = max_length(X_train)\nvocab_size = len(tokenizer.word_index) + 1\nX_train = encode_text(tokenizer, X_train, length)\nmodel = define_model(length, vocab_size, 3, {1 : 8, 2 : 6, 3 : 4})\nmodel.fit([X_train, X_train, X_train], array(Y_train), epochs = 20, batch_size = 16)\n\ntokenizer = get_tokenizer(X_test)\nvocab_size = len(tokenizer.word_index) + 1\nX_test = encode_text(tokenizer, X_test, length)\nloss, acc = model.evaluate([X_test,X_test,X_test],array(Y_test), verbose=0)\n\nmodel.save('model.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(acc)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}