{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## THEORY QUESTIONS","metadata":{"id":"65B-6XpluOR1"}},{"cell_type":"markdown","source":"**Q1) What is overfitting and how to avoid it?**  \n**Answer -** Overfitting in data science means when model learns or fit the details and noise of training data to the extent that it negatively effect the performance, as model will fail to predict future observations reliabily.  \nWays to avoid Overfitting:- \n\n\n1.   Remove extra features\n2.   To ensure number of data points are greater than independent variables\n3.   Cross-Validation, this can be done by dividing Test cases in every proportion for decreasing biased outcomes.\n","metadata":{"id":"HNwyCKc1m_6M"}},{"cell_type":"markdown","source":"**Q2) What is RMSE and MSE? How can you calculate them?**  \n**Answer -** RMSE stands for Root Mean Square Error, it is the standard deviation of the predicted values.  \nTo calculate RMSE:-  \n\n\n1.   calculate the mean of values  \n$U = \\frac{X1 + X2 + ...... + Xn}{n}$\n2.   Sum the squared diffrence of mean value and actual value  \n$\\sum_{i=1}^n (Xi - U)^2$ \n3.   Calculate the mean of above Summation  \n$\\frac{\\sum_{i=1}^n (Xi - U)^2}{n}$ \n4.   Take square root of above obtained value  \n$RMSE =\\sqrt{\\frac{\\sum_{i=1}^n (Xi - U)^2}{n}}$ \n\n\nMSE stands for Mean Square Error, it is the Average of the squared difference.  \nTo calculate MSE:-  \n\n\n1.   calculate the mean of values  \n$U = \\frac{X1 + X2 + ...... + Xn}{n}$  \n2. Sum the squared diffrence of mean value and actual value  \n$\\sum_{i=1}^n (Xi - U)^2$  \n3. Calculate the mean of above Summation  \n$MSE = \\frac{\\sum_{i=1}^n (Xi - U)^2}{n}$\n ","metadata":{"id":"c_H8cpTwq_V5"}},{"cell_type":"markdown","source":"**Q3) What is Line of best fit?**  \n**Answer -** Line of best fit refers to a line through a scatter plot of data points that best expresses the relationship between those points. Statistical models used to find line of best fit (least squares method) to arrive at the geometric equation for the line.","metadata":{"id":"wVFkVhgyzBMo"}},{"cell_type":"markdown","source":"**Q4) Explain multivariant linear regression using a real-life example.**  \n**Answer -** Multiple linear regression (MLR) is a statistical technique that uses several explanatory variables to predict the outcome of a response variable.  \nFor example, we can estimate prices of grains in agricultural markets for every day.It's daily price(Y) fluctuations depend on last day's temperature(T), last day's humidity(H), last day's sold out stock(S), last day's market arrivals(A), last day's price of substitute commodity(C) etc. We can form following multiple regression equation.  \n$Y = w0 + w1*T + w2*H + w3*S + w4*A + w5*C + error$  \nThus, from above example we can see that Y(daily price) is a response variable and other mentioned factors are independent/explanatory variables which are responsible for Y value.","metadata":{"id":"FV-TWYA10EaG"}},{"cell_type":"markdown","source":"**Q5) How can we improve the accuracy of a linear regression model?**  \n**Answer -** To improve the accuracy of a linear regression model we can:-  \n\n\n1.   Add more data points,\"data to tell for itself\". This will decrease the biased outcomes and increase the accuracy of model.\n2.   By effectively treating missing and outlier values\n3.   By calculating RMSE and MSE for the predicted and actual values, Lower the RMSE and MSE Higher the accuracy\n4.   Algorithm tuning can be used by altering algorithm parameters which can give higher accuracy for certain parameters.\n\n","metadata":{"id":"w28ZaSwOANVF"}},{"cell_type":"markdown","source":"# SIMPLE LINEAR REGRESSION WITH PYTHON","metadata":{"id":"2aiCCVrSuEqy"}},{"cell_type":"code","source":"# importing libraries to work with\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression","metadata":{"id":"_ARn5kord85Y","execution":{"iopub.status.busy":"2021-08-16T08:48:25.399452Z","iopub.execute_input":"2021-08-16T08:48:25.399927Z","iopub.status.idle":"2021-08-16T08:48:25.404778Z","shell.execute_reply.started":"2021-08-16T08:48:25.399892Z","shell.execute_reply":"2021-08-16T08:48:25.403728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating data frame from CSV file using pandas library\ndata = pd.read_csv(\"../input/salary-data/salary_data.csv\")\ndata.head(10)","metadata":{"id":"HGw_Ax29er2g","outputId":"4a4447b5-f565-4bb5-e3f2-c309583fb6bf","execution":{"iopub.status.busy":"2021-08-16T08:48:25.408325Z","iopub.execute_input":"2021-08-16T08:48:25.40879Z","iopub.status.idle":"2021-08-16T08:48:25.465178Z","shell.execute_reply.started":"2021-08-16T08:48:25.408752Z","shell.execute_reply":"2021-08-16T08:48:25.464124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above Dataframe has only one independent variable and one dependent variable having 30 rows","metadata":{"id":"s5CnH35Rjquk"}},{"cell_type":"markdown","source":"Preprocessing of input data is necessary, Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data. To achieve mean value 0 and standard deviation of 1 we use `sklearn.preprocessing.StandardScaler().fit(X).transform(X.astype(float))` which transform all the data.","metadata":{"id":"9D6ebijFkw_v"}},{"cell_type":"code","source":"X = data[[\"YearsExperience\"]].values\ny = data[[\"Salary\"]].values\nX = preprocessing.StandardScaler().fit(X).transform(X.astype(float))","metadata":{"id":"85hfpKubfGJc","execution":{"iopub.status.busy":"2021-08-16T08:48:25.466804Z","iopub.execute_input":"2021-08-16T08:48:25.467131Z","iopub.status.idle":"2021-08-16T08:48:25.478291Z","shell.execute_reply.started":"2021-08-16T08:48:25.467101Z","shell.execute_reply":"2021-08-16T08:48:25.477079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We split the data into Test and Train datsets using `sklearn.model_selection.train_test_split()`.  \nWe wrote a program to check which *test_size* give best acuurate model at *random_state=0*","metadata":{"id":"86Lnf9PymDWV"}},{"cell_type":"code","source":"k=0.1\nx_rmse = [i/10 for i in range(1,10)]\nrmse = []\nfor i in range(1,11):\n  if i == 10:\n    k = x_rmse[rmse.index(min(rmse))]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=k, random_state=0)\n    ln_reg = LinearRegression().fit(X_train, y_train)\n  else:\n     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=k, random_state=0)\n     ln_reg = LinearRegression().fit(X_train, y_train)\n     rmse.append((np.mean((ln_reg.predict(X_test) - y_test) ** 2))**(0.5))\n     k += 0.1\n\nplt.plot(x_rmse, rmse, color='red')\nplt.title('Test_size VS RMSE')\nplt.xlabel('Test_size')\nplt.ylabel('RMSE')\nplt.annotate('Minimum', xy =(k, min(rmse)), xytext=(k-0.06,min(rmse)+2000),arrowprops = dict(facecolor ='cyan',shrink = 0.05))\nplt.show()\n\n","metadata":{"id":"1I80X0pNgAqi","outputId":"59ab226e-6b3c-4648-869f-7cdf5aabaabf","_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-08-16T08:48:25.480217Z","iopub.execute_input":"2021-08-16T08:48:25.480511Z","iopub.status.idle":"2021-08-16T08:48:25.91161Z","shell.execute_reply.started":"2021-08-16T08:48:25.480483Z","shell.execute_reply":"2021-08-16T08:48:25.910557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above graph we observed at *test_size=0.2* model gives least RMSE value, Thus we split the train and test data according to it.\nWe formed Simple Linear Regression model using `sklearn.linear_model.LinearRegression().fit()` to form the model.","metadata":{"id":"1JNGapypnG2W"}},{"cell_type":"markdown","source":"$R^2$  value is very high close to 1 which depicts that our model is accurate and 98.81% changeability can be explained by the model.  \n$R^2 = 1 - \\frac{u}{v}$  \n$u$ : Residual sum of squares  \n$v$ : Total sum of squares","metadata":{"id":"zCpQP_WWpZ5M"}},{"cell_type":"code","source":"ln_reg.score(X_test, y_test)","metadata":{"id":"4gd62gwKi8QQ","outputId":"606f2747-f74e-4cf2-8591-5fff146e3c12","execution":{"iopub.status.busy":"2021-08-16T08:48:25.913095Z","iopub.execute_input":"2021-08-16T08:48:25.913387Z","iopub.status.idle":"2021-08-16T08:48:25.921879Z","shell.execute_reply.started":"2021-08-16T08:48:25.91336Z","shell.execute_reply":"2021-08-16T08:48:25.921091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the Training set results\nplt.scatter(X_train, y_train, color='green')\nplt.plot(X_train, ln_reg.predict(X_train), color='blue')\nplt.title('Salary VS Experience (Training set)')\nplt.xlabel('Year of Experience')\nplt.ylabel('Salary')\nplt.show()\n\n# Visualizing the Test set results\nplt.scatter(X_test, y_test, color='green')\nplt.plot(X_test, ln_reg.predict(X_test), color='blue')\nplt.title('Salary VS Experience (Test set)')\nplt.xlabel('Year of Experience')\nplt.ylabel('Salary')\nplt.show()","metadata":{"id":"0KSILw3GlG4x","outputId":"9ffab694-ebcd-4c72-befe-805e7ca452aa","execution":{"iopub.status.busy":"2021-08-16T08:48:25.923547Z","iopub.execute_input":"2021-08-16T08:48:25.924111Z","iopub.status.idle":"2021-08-16T08:48:26.245151Z","shell.execute_reply.started":"2021-08-16T08:48:25.924071Z","shell.execute_reply":"2021-08-16T08:48:26.244112Z"},"trusted":true},"execution_count":null,"outputs":[]}]}