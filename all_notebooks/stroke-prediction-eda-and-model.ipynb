{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix, roc_auc_score, roc_curve\nsns.set_style('darkgrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1 : Reading and understanding data","metadata":{}},{"cell_type":"code","source":"# Reading the data\nstroke = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking shape of the data\nstroke.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking head of data\nstroke.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking info\nstroke.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking stats of data\nstroke.describe(include='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Checking for duplicates and Missing value treatment","metadata":{}},{"cell_type":"markdown","source":"**Here we are checking each id value to check the duplicates in the data. We are taking sum of all the boolean values and equating it to zero to check if it is true**","metadata":{}},{"cell_type":"code","source":"# Checking for duplicates\nsum(stroke.duplicated(subset='id'))==0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking null values in dataframe\nround(stroke.isnull().sum()*100/len(stroke),2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__As we can see bmi column has null values. Lets inspect this column for more details.__","metadata":{}},{"cell_type":"code","source":"# inspecting bmi column\nstroke['bmi'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets look at the distribution as well\nfrom scipy.stats import norm\nplt.figure(figsize = [12,8])\nsns.distplot(stroke.bmi, color='green')\nplt.axvline(stroke['bmi'].mean(),label='mean',color='red')\nplt.axvline(stroke['bmi'].median(),label='mean',color='blue')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__As we can see that mean and median seems to be close, we can replace the null values with median is not effected by outliers.__","metadata":{}},{"cell_type":"code","source":"# replacing null values with median\nstroke.bmi.fillna(28.1, axis = 0, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking null values again\nstroke.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__There are no null values in the dataset__","metadata":{}},{"cell_type":"markdown","source":"# Step 3: Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## a) Univariate analysis","metadata":{}},{"cell_type":"code","source":"# Checking data types of each column\nstroke.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping 1 to yes and 0 to no for hypertension and heart_disease columns\ncols = ['hypertension','heart_disease']\nfor col in cols:\n    stroke[col] = stroke[col].map({1: 'Yes',0:'No'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking head to confirm whether mapping is done or no\nstroke.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating numerical  columns in lists\n\nnumerical = list(stroke.select_dtypes(exclude='object').columns)\nnumerical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating categorical columns in list \n\ncategorical = list(stroke.select_dtypes(include='object').columns)\ncategorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking distribution plots for numerical columns\nplt.figure(figsize=[20,15])\nfor col in enumerate(numerical[1:]):\n    plt.subplot(2,2,col[0]+1)\n    sns.distplot(stroke[col[1]])\n    plt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking countplot for categorical columns \n\nplt.figure(figsize=[20,15])\nfor col in enumerate(categorical):\n    plt.subplot(4,2,col[0]+1)\n    sns.countplot(stroke[col[1]])\n    plt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## b) Bivariate analysis","metadata":{}},{"cell_type":"code","source":"# Scatter plot for age vs avg_glucose_level\n\nplt.figure(figsize=[12,8])\nsns.scatterplot(stroke.age, stroke.avg_glucose_level, color= 'b')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot for age vs bmi\nplt.figure(figsize=[12,8])\nsns.scatterplot(stroke.age, stroke.bmi, color= 'r')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot for age vs bmi\nplt.figure(figsize=[12,8])\nsns.scatterplot(stroke.avg_glucose_level, stroke.bmi, color= 'g')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking countplot with stroke for categorical columns \n\nplt.figure(figsize=[20,15])\nfor col in enumerate(categorical):\n    plt.subplot(4,2,col[0]+1)\n    sns.countplot(stroke[col[1]],hue=stroke.stroke)\n    plt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pair plot for the data\nplt.figure(figsize=[20,15])\nsns.pairplot(data = stroke, hue = 'stroke')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot for age vs avg_glucose_level\n\nplt.figure(figsize=[12,8])\nsns.scatterplot(stroke.age, stroke.avg_glucose_level, hue=stroke.stroke)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot for age vs avg_glucose_level\n\nplt.figure(figsize=[12,8])\nsns.scatterplot(stroke.age, stroke.bmi, hue=stroke.stroke)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot for age vs avg_glucose_level\n\nplt.figure(figsize=[12,8])\nsns.scatterplot(stroke.bmi, stroke.avg_glucose_level, hue=stroke.stroke)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## c) Multivariate analysis","metadata":{}},{"cell_type":"code","source":"# Correlation matrix\nstroke.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap for the data\nplt.figure(figsize=[12,8])\nsns.heatmap(stroke.corr(), cmap='RdYlGn', annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Outlier treatment","metadata":{}},{"cell_type":"code","source":"# Checking outliers in numerical columns\n\nplt.figure(figsize=[20,15])\nfor col in enumerate(numerical[1:-1]):\n    plt.subplot(2,2,col[0]+1)\n    sns.boxplot(stroke[col[1]])\n    plt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Capping outliers \n# x = stroke.describe()\n# for i in numerical[2:-1]:\n#     q1=x.loc['25%',i]\n#     q3=x.loc['75%',i]\n#     iqr=q3-q1\n#     uppl=q3+(1.5*iqr)\n#     lowl=q1-(1.5*iqr)\n#     stroke[i]=stroke[i].apply(lambda x:uppl if x>uppl else x )\n#     stroke[i]=stroke[i].apply(lambda x: lowl if x<lowl else x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Checking outliers in numerical columns\n\n# plt.figure(figsize=[20,15])\n# for col in enumerate(numerical[1:-1]):\n#     plt.subplot(2,2,col[0]+1)\n#     sns.boxplot(stroke[col[1]])\n#     plt.tight_layout()\n# plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5: Creating dummies","metadata":{}},{"cell_type":"code","source":"# Dropping id column from the data frame\nstroke.drop('id',1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = stroke.drop('stroke',1)\ny = stroke[['stroke']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"creating dummies for the X","metadata":{}},{"cell_type":"code","source":"X = pd.get_dummies(X, drop_first= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the heatmap after dummies creation\nplt.figure(figsize=[15,8])\nsns.heatmap(X.corr(), cmap='RdYlGn', annot = True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6: Train Test Split and Scaling","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=100, test_size = 0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape,  y_train.shape,y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_scale = ['age', 'avg_glucose_level', 'bmi']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating scaler instance\n\nscaler = MinMaxScaler()\n\n# Fit transform for X_train\nX_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n\n# Transforming X_test\nX_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7: Model Building","metadata":{}},{"cell_type":"markdown","source":"## Base model","metadata":{}},{"cell_type":"code","source":"# Creating logistic regression instance\nlogreg = LogisticRegression(solver='liblinear')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting model\nlogreg.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = logreg.predict(X_train)\ny_train_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_train,y_train_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Probabilities = logreg.predict_proba(X_train)[:,1]\nProbabilities","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(y_train, Probabilities)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_train,y_train_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(12, 8))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred, Probabilities, drop_intermediate = False )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_roc(y_train,Probabilities)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stroke.stroke.value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling  import SMOTE\nsmote = SMOTE(sampling_strategy='minority')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_sm, y_train_sm = smote.fit_resample(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg.fit(X_train_sm,y_train_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train_sm = logreg.predict(X_train_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_train_sm, y_pred_train_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true=y_train_sm, y_pred=y_pred_train_sm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_train_sm,y_pred_train_sm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}