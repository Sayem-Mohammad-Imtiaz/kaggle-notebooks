{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Category\"] = encoder.fit_transform(df[\"Category\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"Category\"]\nX = df[\"Message\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 69)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef normalize(data):\n    normalized = []\n    for i in data:\n        i = i.lower()\n        # get rid of urls\n        i = re.sub('https?://\\S+|www\\.\\S+', '', i)\n        # get rid of non words and extra spaces\n        i = re.sub('\\\\W', ' ', i)\n        i = re.sub('(?<=[a-z])\\'(?=[a-z])', '', i)\n        i = re.sub(\"(?<=[a-z])'(?=[a-z])\", \"\", i)\n        i = re.sub('\\n', '', i)\n        i = re.sub(' +', ' ', i)\n        i = re.sub('^ ', '', i)\n        i = re.sub(' $', '', i)\n        normalized.append(i)\n    return normalized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = normalize(X_train)\nX_test = normalize(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n\nmax_vocab = 10000\ntokenizer = Tokenizer(num_words=max_vocab)\ntokenizer.fit_on_texts(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize the text into vectors \nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\nX_train = pad_sequences(X_train, padding='post', maxlen=256)\nX_test = pad_sequences(X_test, padding='post', maxlen=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM\n\nmodel = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Embedding(max_vocab, 32))\nmodel.add(Bidirectional(LSTM(64, return_sequences = True)))\nmodel.add(Bidirectional(LSTM(16)))\nmodel.add(Dense(64, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = \"accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, epochs = 10, validation_split = 0.2, batch_size = 30, shuffle = True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}