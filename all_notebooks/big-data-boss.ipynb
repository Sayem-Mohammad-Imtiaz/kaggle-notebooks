{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Big Data Boss"},{"metadata":{},"cell_type":"markdown","source":"### This notebook contains\n1) Work on the Data Collected byu webscraping(Very Very less data)\n\n2) Work on the Data taken from Internet"},{"metadata":{},"cell_type":"markdown","source":"#### Data collected by me (Very very small data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nimport bs4\nimport csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = requests.get(\"https://www.imdb.com/list/ls025933303/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"soup = bs4.BeautifulSoup(res.text,\"lxml\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"head1= soup.select(\".lister-item-header\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"head1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Name,Year =[],[]\nfor i in soup.select('h3 > a'):\n    Name.append(i.text)\nfor i in range(len(head1)):\n    Year.append(head1[i].select(\"span\")[1].text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"head2= soup.select(\".runtime\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"runtime=[]\nfor i in head2:\n    runtime.append(i.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"runtime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rating=[]\ni=0\nwhile i < 575:\n    print(soup.select(\".ipl-rating-star__rating\")[i].text)\n    rating.append(soup.select(\".ipl-rating-star__rating\")[i].text)\n    i += 23","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rating","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"term = soup.select(\".genre\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genre=[]\nfor i in range(len(term)):\n    genre.append(term[i].text) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(Name)):\n    data.append({'Name' : Name[i],'Year':Year[i],'Runtime': runtime[i],'Rating': rating[i],'Genre': genre[i]})\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_columns = ['Name','Year','Runtime','Rating','Genre']\n\ncsv_file = \"data.csv\"\ntry:\n    with open(csv_file, 'w') as csvfile:\n        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n        writer.writeheader()\n        for data in data:\n            writer.writerow(data)\nexcept IOError:\n    print(\"I/O error\")  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Genre\"] = df[\"Genre\"].apply(lambda x: x.split()[0])\ndf[\"Genre\"] = df[\"Genre\"].apply(lambda x: x.replace(r\"/\", \"\"))\ndf[\"Genre\"] = df[\"Genre\"].apply(lambda x: x.replace(r\",\", \"\"))\n\ndf[\"Genre\"] = df[\"Genre\"].apply(lambda x: x.replace(r\"\\n\", \"\"))\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nplt.title(\"Genres\")\nsns.countplot(y = df[\"Genre\"])\nplt.xlabel(\"Count\")\nplt.ylabel(\"Genres\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Rating distribution\")\nsns.distplot(df[\"Rating\"])\nplt.xlabel(\"Rating\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Runtime'] = df[\"Runtime\"].apply(lambda x: x.split()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Runtime'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Runtime distribution\")\nsns.distplot(df[\"Runtime\"])\nplt.xlabel(\"Runtime\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Year\"] = df[\"Year\"].apply(lambda x: x[1:5])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Year.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nplt.title(\"Year\")\nsns.countplot(y = df[\"Year\"])\nplt.xlabel(\"Count\")\nplt.ylabel(\"Year\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n    print(f'length of unique values in {i}',len(set(df[i])))\n    print(f'some of the unique values in {i}',list(set(df[i]))[0:5])\n    print('---------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['Genre'] =='Drama', 'Genre'] = 0\ndf.loc[df['Genre'] =='Action', 'Genre'] = 1\ndf.loc[df['Genre'] =='Comedy', 'Genre'] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['Year','Runtime','Genre']:\n    df[i] = pd.to_numeric(df[i],errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(9,9))\nsns.heatmap(df.corr(), annot=True ,linewidth=0.5, fmt='.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualisations of data collected from internet "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/kollywood-movie-dataset-2011-2017/Kollywood Movie Dataset (2011 - 2017).csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here the 7 rating values are null lets fill them with the average value of Rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_rating = np.sum(data.Rating)/(416-7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Rating'].fillna(value=avg_rating, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Language'],axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    print(f'length of unique values in {i}',len(set(data[i])))\n    print(f'some of the unique values in {i}',list(set(data[i]))[0:5])\n    print('-'*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nplt.title(\"Year\")\nsns.countplot(y = data['Release Year'])\nplt.xlabel(\"Count\")\nplt.ylabel(\"Year\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Rating\")\nsns.distplot(data[\"Rating\"])\nplt.xlabel(\"Rating\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Genre'] = data['Genre'].apply(lambda x: x.split(' ')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Genre\"] = data[\"Genre\"].apply(lambda x: x.replace(r\"/\", \"\"))\ndata[\"Genre\"] = data[\"Genre\"].apply(lambda x: x.replace(r\",\", \"\"))\n\ndata[\"Genre\"] = data[\"Genre\"].apply(lambda x: x.replace(r\"\\n\", \"\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Genre.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using NLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import TweetTokenizer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_text(text):\n    stemmer = PorterStemmer()\n    stopwords_english = stopwords.words('english')\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n                               reduce_len=True)\n    text_tokens = tokenizer.tokenize(text)\n\n    texts_clean = []\n    for word in text_tokens:\n        if (word not in stopwords_english and  # remove stopwords\n                word not in string.punctuation):  # remove punctuation\n            stem_word = stemmer.stem(word)  # stemming word\n            texts_clean.append(stem_word)\n\n\n    return texts_clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_freqs(texts, ys):\n\n    yslist = np.squeeze(ys).tolist()\n\n    freqs = {}\n    for y, text in zip(yslist, texts):\n        for word in process_text(text):\n            pair = (word, y)\n            if pair in freqs:\n                freqs[pair] += 1\n            else:\n                freqs[pair] = 1\n\n    return freqs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Status'] = np.select([(data['Rating'] >= 5.5),(data['Rating'] < 5.5)],[1,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = data.apply(lambda row: row.Director+ \n                                  (row.Plot), axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.Status\ndata =data.drop(['Status'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data[0:332]\nX_test = data[332:]\ny_train= y[0:332]\ny_test = y[332:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freqs_buil = build_freqs(X_train.text,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(text, freqs):\n    word_l = process_text(text)\n    \n    x = np.zeros((1, 3)) \n    \n    x[0,0] = 1 \n    \n    \n    for word in word_l:\n        \n        x[0,1] += freqs.get((word,1.0), 0)\n        \n        x[0,2] += freqs.get((word,0.0), 0)\n        \n    assert(x.shape == (1, 3))\n    return x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.zeros((len(X_train), 3))\nfor i in range(0,len(X_train)):\n    X[i,:]= extract_features(X_train.text[i],freqs_buil)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(penalty= 'l2' ,random_state= 42 ,max_iter=20,solver='liblinear',class_weight= 'balanced')\nmodel.fit(X,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_t = np.zeros((len(X_test), 3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=332\nj=0\nwhile i <416:\n    X_t[j,:]= extract_features(X_test.text[i],freqs_buil)\n    i+=1\n    j+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test,y_pred)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model, X_t, y_test,labels=[0,1],normalize= 'true')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}