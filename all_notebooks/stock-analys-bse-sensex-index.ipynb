{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Stock Signalling - BSE Sensex Index\n\nIdea is to train a model based on the following indicators, to provide an indictor to be bullish or bearish in the market\n\n- Close Price\n- RSI\n- Stochastic RSI\n\nThe model is planned to be trained on 30 years of Sensex Data - [Source of Data](https://www.bseindia.com/indices/IndexArchiveData.html)  - From 01-Jan-1990 till date\n\nThe indicators are calculated using the libreary - [TA-LIB](https://mrjbq7.github.io/ta-lib/func_groups/momentum_indicators.html)\n\nHowever, I had tough time in installing this library. But found the custome implementation of RSI and Stoch RSI which gives exact same result as TA-LIB\n\n[Custom RSI Implementation](https://gist.github.com/ultragtx/6831eb04dfe9e6ff50d0f334bdcb847d)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Custom Implementation of MACD"},{"metadata":{"trusted":true},"cell_type":"code","source":"def macd(prices):\n    # Calculate exponentiall weighted moving averages:\n    day12 = prices.ewm(span=12).mean() \n    day26 = prices.ewm(span=26).mean()\n    macd = []  # List to hold the MACD line values\n    counter=0  # Loop to substantiate the MACD line\n    while counter < (len(day12)):\n        macd.append(day12.iloc[counter] - day26.iloc[counter])  # Subtract the 26 day EW moving average from the 12 day.\n        counter += 1\n    macd_df = pd.DataFrame(macd)\n    signal_df = macd_df.ewm(span=9).mean()\n    return macd_df, signal_df ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Customt Implmentation of RSI and Stochastic RSI\n\n\nhttps://gist.github.com/ultragtx/6831eb04dfe9e6ff50d0f334bdcb847d\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://gist.github.com/ultragtx/6831eb04dfe9e6ff50d0f334bdcb847d\ndef RSI2(series, period=14):\n    delta = series.diff().dropna()\n    ups = delta * 0\n    downs = ups.copy()\n    ups[delta > 0] = delta[delta > 0]\n    downs[delta < 0] = -delta[delta < 0]\n    ups[ups.index[period-1]] = np.mean( ups[:period] ) #first value is sum of avg gains\n    ups = ups.drop(ups.index[:(period-1)])\n    downs[downs.index[period-1]] = np.mean( downs[:period] ) #first value is sum of avg losses\n    downs = downs.drop(downs.index[:(period-1)])\n    rs = ups.ewm(com=period-1,min_periods=0,adjust=False,ignore_na=False).mean() / \\\n         downs.ewm(com=period-1,min_periods=0,adjust=False,ignore_na=False).mean() \n    return 100 - 100 / (1 + rs)\n\ndef StochRSI2(series, period=14, smoothK=3, smoothD=3):\n    # Calculate RSI \n    delta = series.diff().dropna()\n    ups = delta * 0\n    downs = ups.copy()\n    ups[delta > 0] = delta[delta > 0]\n    downs[delta < 0] = -delta[delta < 0]\n    ups[ups.index[period-1]] = np.mean( ups[:period] ) #first value is sum of avg gains\n    ups = ups.drop(ups.index[:(period-1)])\n    downs[downs.index[period-1]] = np.mean( downs[:period] ) #first value is sum of avg losses\n    downs = downs.drop(downs.index[:(period-1)])\n    rs = ups.ewm(com=period-1,min_periods=0,adjust=False,ignore_na=False).mean() / \\\n         downs.ewm(com=period-1,min_periods=0,adjust=False,ignore_na=False).mean() \n    rsi = 100 - 100 / (1 + rs)\n\n    # Calculate StochRSI \n    stochrsi  = (rsi - rsi.rolling(period).min()) / (rsi.rolling(period).max() - rsi.rolling(period).min())\n    stochrsi_K = stochrsi.rolling(smoothK).mean()\n    stochrsi_D = stochrsi_K.rolling(smoothD).mean()\n\n    return stochrsi, stochrsi_K, stochrsi_D","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"date_cols = ['Date']\nsensex = pd.read_csv('../input/bse-sensex-index-30-yrs/BSE Sensex Daily Close Jan1990 Oct2020.csv', parse_dates=date_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensex.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take previous n years for calculation\n\nn = 5 years"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_yrs = 5\nimport datetime\ndate = datetime.datetime.now() - datetime.timedelta(days=n_yrs*365)\nsensex_r = sensex[sensex['Date'] > date]\nsensex = sensex_r\n\nclose = sensex.Close","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate RSI and Stoch RSI"},{"metadata":{"trusted":true},"cell_type":"code","source":"macd_df, signal_df = macd(close)\n# type(macd_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sensex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsi = RSI2(close, period=14)\nrsi9 = RSI2(close, period=9)\nstochrrsi = StochRSI2(close)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add RSI, Stochastic RSI, MACD and MACD Signal to daily dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"sensex['rsi'] = rsi\nsensex['rsi9'] = rsi9\nsensex['stochrsi'] = stochrrsi[1]\nsensex['rsi_diff'] = sensex['rsi9'] - sensex['rsi']\nsensex['macd'] = macd_df[0].values\nsensex['signal'] = signal_df[0].values\nsensex['macd_diff'] = sensex['macd'] - sensex['signal']\nsensex.tail(50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How MACD signals the stock\n\nIf the MACD crosses the signal line upward\n\n```\n    if macd[i] > signal[i] and macd[i - 1] <= signal[i - 1]:\n        listLongShort.append(\"BUY\")\n    #  The other way around\n    elif macd[i] < signal[i] and macd[i - 1] >= signal[i - 1]:\n        listLongShort.append(\"SELL\")\n    #  Do nothing if not crossed\n    else:\n        listLongShort.append(\"HOLD\")\n```\n\n# How RSI signals the stock\n\nIf RSI is reaching 70, it means market will turn bearish soon. \nIf RSI reaches around 30 market will go bullish soon\n\n```\n    if rsi[i] >= 70 :\n        listLongShort.append(\"SELL\")\n    if rsi[i] <= 30 :\n        listLongShort.append(\"BUY\")\n    else:\n        listLongShort.append(\"HOLD\")\n```\n\n# How Stochastic RSI signals\n\nIf Stoch RSI reaches 100, it means market will go bearish soon\nIf Stoch RSI reaches 0, it means market will go bearish soon\n\n"},{"metadata":{},"cell_type":"markdown","source":"Calculate lookahead price action and % price change to the dataframe\nConsidering lookahead of 3 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"look_ahead = 3\nsensex['Close_ahead'] = sensex['Close'].shift(-look_ahead)\nsensex['Close_pct'] = (sensex['Close_ahead'] - sensex['Close'])/sensex['Close'] * 100\nsensex = sensex.dropna()\nsensex","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Pre Processing\n\nLet us make all the features to be normalized"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's decide features we want consider\n\nWe know RSI, Stoch RSI, MACD, Signal are important in deciding the stock signals. So we consider these as our features"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sensex[['rsi','stochrsi','macd','signal']]\ny = sensex['Close_pct']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nx = scaler.fit_transform(x)\ny.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Now for analysis purpose, we will round the RSI to integer and see how Look ahead Close % vary across the RSI range"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = sensex[['rsi','stochrsi','macd','signal','macd_diff','Close_pct']]\ndf1[500:550]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_int(f):\n    return round(f)\n\ndef get_tens(f):\n    tenth = round(f/10) * 10\n    return tenth\ndef get_rsi_flag(f):\n    if f < 35:\n        flag = 'low'\n    elif f > 65:\n        flag = 'high'\n    else:\n        flag = 'normal'\n    return flag\n\n\n# df1['rsi_i'] = df1['rsi'].apply(get_int)\n# df1['rsi_t'] = df1['rsi'].apply(get_tens)\n# df1['srsi_f'] = df1['stochrsi']*100\n# df1['srsi_i'] = df1['srsi_f'].apply(get_int)\n# df1['rsi_flag'] = df1['rsi'].apply(get_rsi_flag)\n\n# df2 = df1[['rsi_t','Close_pct']]\n# df2 =df2.groupby(['rsi_t']).median()\n# df2 = df2.reset_index()\n# # df1[df1['rsi_i'] == 30]\n# # df2[15:55]\n# df1.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(15, 6)\nplt.xlim(-100,100)\nplt.ylim(-10,10)\nsns.scatterplot(data=df1, x='macd_diff',y='Close_pct')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see the datapoints spread everywhere. We can not make any proper correlation between MACD difference and % of close (n days)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(15, 6)\nplt.xlim(20,80)\nplt.ylim(-5,5)\nsns.scatterplot(data=df1, x='rsi',y='Close_pct')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again with respect to RSI we see the data points everywhere. No easy correlation found"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig1, ax1 = plt.subplots()\ndate_time_obj1 = datetime.datetime.strptime('2020-01-01', '%Y-%m-%d')\ndate_time_obj2 = datetime.datetime.strptime('2020-10-19', '%Y-%m-%d')\nplt.xlim(date_time_obj1, date_time_obj2)\nfig1.set_size_inches(15, 6)\nsns.scatterplot(data=sensex,x='Date',y='rsi')\nsns.scatterplot(data=sensex,x='Date',y='Close_pct')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build the Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us split our data into training and testing sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# x_train, x_test, y_train, y_test = train_test_split(df1[['rsi','stochrsi','macd','signal','macd_diff']],df1[['Close_pct']],test_size=0.2)\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression (Baseline)\nBuild baseline model for future comparison. Let's build a linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = LinearRegression()\nmodel1.fit(x_train,y_train)\nmodel1.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Baseline model gives an R2 score of `0.045`. Which is pretty bad"},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Machine Regression\nLet's try to build SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = SVR(gamma=2.3)\nmodel2.fit(x_train,y_train)\nmodel2.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVR with `RBF kernel` with `gamma=5.3` gives the R2 score of `0.0521`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model2 = SVR(kernel='poly', degree=4, gamma=10 )\n# model2.fit(x_train,y_train)\n# model2.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVR with `POLY kernel` with `degree=4, gamma=10` gives the R2 score of `-0.0106`"},{"metadata":{},"cell_type":"markdown","source":"# XGBoost\nNow let us try with `XGBOOST` "},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = xgb.XGBRegressor(objective = 'reg:squarederror',\n                          learning_rate = 0.01,\n                          max_depth = 30,\n                          n_estimators = 170,\n                          alpha = 10\n                            \n                    )\nmodel3.fit(x_train,y_train)\npreds = model3.predict(x_test)\nr2score = metrics.r2_score(y_test,preds)\nr2score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost with following parameter got R2 score of `0.1549`\n\n```\nobjective = 'reg:squarederror',\n                          learning_rate = 0.07,\n                          max_depth = 15,\n                          n_estimators = 170,\n                          alpha = 9                  \n                            \n                    )                          \n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deep Neural Net\n\nLet's try to build a Neural Net for this regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(32,input_shape = (None,4), activation='relu'),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1, activation='linear')\n])\n\nmodel4.compile(optimizer =tf.optimizers.Adam(learning_rate=0.001),\n              loss='mean_squared_error'\n             )\n                \n                                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory = model4.fit(x = x_train, y = y_train, \n           epochs=1200,\n            verbose=0,\n           validation_split = 0.2\n          )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_loss(history):\n  plt.plot(history.history['loss'], label='loss')\n  plt.plot(history.history['val_loss'], label='val_loss')\n  plt.ylim([0,8])\n#   plt.xlim([1000, 1500])\n  plt.xlabel('Epoch')\n  plt.ylabel('Error')\n  plt.legend()\n  plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find R2 score of NN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model4.predict(x_test)\nr2score = metrics.r2_score(y_test,preds)\nr2score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis of the model complexity\n\n## Experiment 1\nWe could achieve R2 score of `-0.031` using following NN model\n\nWe can understand that the model complexity is very less (49 trainable params). This simple model with 1 layer with 8 nodes is not sufficient for better score. \n\nValidation Loss was around 5\n\n- Traininable parameters = 49\n- R2 score of `-0.031`  \n- Validation loss = 5\n- epochs = 1000\n\n```\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, None, 8)           40        \n_________________________________________________________________\ndense_4 (Dense)              (None, None, 1)           9         \n=================================================================\nTotal params: 49\nTrainable params: 49\nNon-trainable params: 0\n_________________________________________________________________\n```\n---\n## Experiment 2\n\nWe could achieve R2 score of `0.0335` using following NN model\nModel complexity is increased and hence the score (97 trainable params). Validation Loss was around 4.8\n\n- Traininable parameters = 97\n- R2 score of `0.0335`  \n- Validation loss = 4.8\n- epochs = 1000\n\nWith the same model when epochs was increased to 2000, R2 score was `0.1655`. Validation loss was around 4.4\n\n- Traininable parameters = 97\n- R2 score of `0.1655`  \n- Validation loss = 4.4\n- epochs = 2000\n\n\n```\nModel: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_5 (Dense)              (None, None, 16)          80        \n_________________________________________________________________\ndense_6 (Dense)              (None, None, 1)           17        \n=================================================================\nTotal params: 97\nTrainable params: 97\nNon-trainable params: 0\n_________________________________________________________________\n```\n---\n## Experiment 3\n\n\nStill using single hidden layer. \n\n- Traininable parameters = 193\n- R2 score of `0.14`  \n- Validation loss = 4.2\n- epochs = 2000\n\nLet us try to increase the epochs=3000 and see if validation loss decreases.\n- Traininable parameters = 193\n- R2 score of `0.2084`  \n- Validation loss = 3.95 \n- epochs = 3000\n\nBut R2 Score drastically increased to `0.208`. Validation loss slightly reduced\n```\nModel: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_7 (Dense)              (None, None, 32)          160       \n_________________________________________________________________\ndense_8 (Dense)              (None, None, 1)           33        \n=================================================================\nTotal params: 193\nTrainable params: 193\nNon-trainable params: 0\n```\n---\n## Experiment 4\n\nNow let us try to increase the complexity by adding one more layer to NN\n\n- Traininable parameters = 369\n- R2 score of `0.244`  \n- Validation loss = 3.3\n- epochs = 3000\n\n\nLet's try with still higher epochs and see if it reduces any more loss\nepochs = 4000\nR2 Score = 0.15\nValidation loss = 3.3\n\nWe can observe that loss reduced, but not that significantly. \n\n\nNN Summary\n```\nModel: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_9 (Dense)              (None, None, 16)          80        \n_________________________________________________________________\ndense_10 (Dense)             (None, None, 16)          272       \n_________________________________________________________________\ndense_11 (Dense)             (None, None, 1)           17        \n=================================================================\nTotal params: 369\nTrainable params: 369\nNon-trainable params: 0\n_________________________________________________________________\n```\n---\n## Experiment 5\n\nIn this experiment, let us increase the nodes in the 2 hidden layers and see the effect\n\n- Trainable parameter = 1249\n- epochs = 4000\n- Validation loss =  6 \n- R2 Score = `0.17`\n\nWe can see with 4000 epochs the model has overfitted\n\nIn the training history graph we can see with the least loss was around 3.3 (Epoch=1200)\n- Trainable parameter = 1249\n- epochs = 1200\n- Validation loss = 6 \n- R2 Score = `0.226`\n\nFor some reason validation loss did not reduce :-( \n\nNN Summary\n```\nModel: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_12 (Dense)             (None, None, 32)          160       \n_________________________________________________________________\ndense_13 (Dense)             (None, None, 32)          1056      \n_________________________________________________________________\ndense_14 (Dense)             (None, None, 1)           33        \n=================================================================\nTotal params: 1,249\nTrainable params: 1,249\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n---\n## Experiment n\nWe could achieve R2 score of `0.134` using following NN model\n\n```\nModel: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_25 (Dense)             (None, None, 64)          320       \n_________________________________________________________________\ndense_26 (Dense)             (None, None, 32)          2080      \n_________________________________________________________________\ndense_27 (Dense)             (None, None, 1)           33        \n=================================================================\nTotal params: 2,433\nTrainable params: 2,433\nNon-trainable params: 0\n```\n---\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}