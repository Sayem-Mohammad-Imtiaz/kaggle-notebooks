{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Doğrusal Regresyon Egzersizleri","metadata":{}},{"cell_type":"markdown","source":"50 adet Startup'ın araştırma ve geliştirmeye yönelik harcaması, yönetime yönelik harcaması, pazarlama harcaması, kazandıkları kar miktarı ve kuruldukları lokasyon bilgisi bulunmaktadır. Amaç kar miktarını tahmin etmektir. Bu bir sayısal tahmin problemidir ve bağımlı değişkenimiz \"Profit\".","metadata":{}},{"cell_type":"markdown","source":"Numpy, matplotlib.pyplot, pandas ve seaborn kütüphanelerini çekirdeğe dahil edelim.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dizinde bulunan veri çerçevemizi startups değişkenine atayalım. startups değişkenini df değişkenine kopyalayarak kullanmaya başlayalım.","metadata":{}},{"cell_type":"code","source":"startups = pd.read_csv(\"../input/50-startups/50_Startups.csv\", sep=\",\")\ndf = startups.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"İlk 5 gözlemini yazdıralım.","metadata":{}},{"cell_type":"code","source":"df.head() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veri çerçevesinin bilgilerini görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kaç gözlem ve öznitelikten oluştuğunu görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"→ 50 gözlem ve 5 değişkenden oluşuyor.","metadata":{}},{"cell_type":"markdown","source":"Eksik verileri kontrol edelim.","metadata":{}},{"cell_type":"code","source":"df.isna().sum() # görmüş olduğumuz gibi eksik verimiz yok","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Korelasyon matrisi çizdirelim.","metadata":{}},{"cell_type":"code","source":"corr = df.corr()\ncorr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"→ Korelasyon 1.0'e yaklaştıkça değerler arasındaki ilişki o kadar güçlenir. Burada **Profit** ile **R&D Spend** arasında 1'e yakın bir değer (0.972900) gözlenmiş bu demek oluyor ki ikisi arasında pozitif nerdeyse mükemmel bir ilişki vardır. **Marketing Spend** ile de **Administration** arasında da negatif bir ilişki olduğunu söyleyebiliriz.","metadata":{}},{"cell_type":"markdown","source":"Seaborn ile korelasyon matrisinin ısı haritasını çizdirelim.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R&D Spend ve Profit arasındaki korelasyonu daha iyi görebilmek için scatterplot çizdirelim.","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x = \"R&D Spend\", y = \"Profit\", data = df); ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(df[\"R&D Spend\"],df[\"Profit\"] , ci=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* profit sadece bir değişkene bağlı değil birden fazla feature olduğundan → multiple \n* multiple: bir y eksenine birden fazla şeyin etki etmesi demektir\n* y = b0+ b1.x1+ b2.x2 doğru denklemi\n* profit= b0+ b1.r&d +b2.administration+....\n* b0: constant/sabit/bias ~ y eksenini kestiği nokta\n* b1: coeff/katsayı ~eğim\n* amaç: min(MSE)\n* profit: bağımlı değişken~dependent variable\n* administration,r&d,Marketing Spend: bağımsız değişken~independent variable\n\n","metadata":{}},{"cell_type":"markdown","source":"Sayısal değişkenlerin dağılımını görmek için df üzerinden histogram çizdirelim.","metadata":{}},{"cell_type":"code","source":"df.hist(figsize =(15,20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"→Histogram şemaları verilerin devam eden ya da belirli zaman aralığındaki dağılımını göstermek için kullanılır. Değerlerin nerede yoğunlaştığını, maksimum ve minimum noktalarını, veriler arasındaki kopmalar ve olağandışı değerler olup olmadığı hakkında tahminde bulunulmasına yardımcı olur.\n\n* R&D Spend histogramını bakarsak; verilerin 0'dan 150 bin daha fazla tahmini olarak 170 bin gibi değerlere sahip olduğunu görebiliriz aynı zamanda verimizin 50bin ile 80 bin arasında daha yoğun olduğunu görüyoruz. Burada en küçük değer olarak sıfırı görüyoruz. Yani bazı startuplar araştırma geliştirmeye(Research and Development) bütçe ayırmadığı ya da çok küçük bir bütçe ayırdığını görebiliyoruz.\n\n* Marketing Spend histogramını bakarsak; verilerin 0 ve tahmini olarak 320 bin arasında daha yoğun olduğunu söyleyebiliriz. Yani bazı startuplar pazarlamaya hiç bütçe ayırmazken bazı startuplar ise çok büyük bütçeler ayırabiliyor.\n\n* Administration histogramını bakarsak; verilerin 90 bin ile 150 bin arasında daha yoğun olduğunu görebiliyoruz. Genel bir gözle bakarsak 100 bin  ile 200 bin aralığında bütçeden yapılan harcamalarsa en fazla harcama yönetime yapılmış.Yönetim bu parayı şirket karı için kullanmış olabilirler bu da profit'e yansır ya da sadece kendi giderleri için kullanmış olabilirler. Bu yüzden yönetim harcamaları ile karın korelasyonuna bakmak istiyorum.","metadata":{}},{"cell_type":"code","source":"df.corr()[\"Administration\"][\"Profit\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Administrationı ve Profit arasındaki korelasyona baktığımda \"0.20071656826872125\" değerini gördük. Yönetim bu parayı şirket karı için kullanmamış diyebiliriz. Belki bu harcamanın içinde maaşlar yer alıyor olabilir.","metadata":{}},{"cell_type":"markdown","source":"Veri çerçevesinin temel istatistik değerlerini görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Standart sapma çok yüksek neredeyse özniteliklerimin ortalama değerlerinin yarısı kadar.\n\n\n\n\nEğer bir veri ortalamaya yakın ise standart sapma düşük olur ama eğer ortalamaya uzakta bir dağılım söz konusuysa standart sapma değeri  büyük olur. Varyans standart sapmanın karesi olduğundan ortalamaları ve standart sapma değerleri ile varyans yorumu yapabiliriz.\n* Standart sapması en yüksek olan değer \"Marketing Spend\" dir. Bu yüzden en yüksek varyansa sahiptir.\n* Standart sapması en düşük değer ise \"Administration\" dir. Bu yüzden en küçük varyans değerine sahiptir.","metadata":{}},{"cell_type":"markdown","source":"State'a ait benzersiz değerleri görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df[\"State\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"get_dummies yardımıyla State'a dair kategorik öznitelik çıkarımlarında bulunalım. Çünkü State'ların birbirine üstünlüğü yok, nominaller. Ordinal değil.","metadata":{}},{"cell_type":"code","source":"df['State'] = pd.Categorical(df['State'])\ndfDummies = pd.get_dummies(df['State'], prefix = 'StateOf') \n#pd.get_dummies(),veri işleme için kullanılır. Kategorik verileri kukla veya gösterge değişkenlere dönüştürür.\n#prefix = 'StateOf' , sütun adlarına ön ek eklemek için kullanılır\ndfDummies.head()#50 değeri göstermeyip sadece ilk beş gözlemi getiriyorum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df, dfDummies], axis = 1)\ndf.head()\n#concat fonksiyonunu kullanırken sütunların isimlerini ayrıca belirtmemize gerek olmadan serileri birleştirebiliriz.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"State özniteliğini silip dummy olarak yaratılan State'lardan da birisini hariç tutarak veri çerçevemizi güncelleyelim.","metadata":{}},{"cell_type":"code","source":"df.drop([\"State\", \"StateOf_New York\"], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Modelde yer alan nitel vasıflı değişkenlere kukla değişken denir. Kukla değişkenler genel olarak ikil/binom (kadın,erkek) ve çoklu (mezuniyet: ilköğretim, ortaöğretim, lise, lisans, lisansüstü vb) biçimde iki yaklaşımla ölçülür.Binom ölçeklendirmede nitel değişken 1 ve 0 durumunu alır(kadın=1, erkek=0 gibi). Çoklu (polychotomous) ölçeklendirmede ise değişkene ait niteliksel vasıflar uygun ve aralarında anlamsal bir farklılığı yansıtacak bir biçimde sıralanır( ilköğretim =0, ortaöğretim=1, lise=2, lisans=3, lisansüstü=4 gibi).\n\n* Modelde eğer nitel bir değişkenin ikili yapıda tanımlarını kullanacak isek, model sağlıklı bir biçimde tahmin edilemez çünkü katsayılardan oluşan matrisinin tersi alınamaz. **Modelin sağlıklı bir biçimde tahmin edilebilmesi için genelde kontrol değişkeni olarak tanımlanan kukla değişkenini modelden düşürmemiz gerekir. Yani sizin araştırmadaki amacınız kadın olma vasfının bağımlı değişken üzerindeki etkisi is tabloda verilen \"cinsiyet\" ve \"erkek\" sütunlarını kullanmamamız gerekir.\n\n→ State özniteliğini ve statelerden birini seçip siliyorum.\n","metadata":{}},{"cell_type":"markdown","source":"Veri çerçevemizi bağımlı ve bağımsız değişkenler olmak üzere bölütleyelim.","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"Profit\", axis = 1)\ny = df[\"Profit\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bağımlı ve bağımsız değişkenleri kontrol edelim.","metadata":{}},{"cell_type":"code","source":"X.head(10) #bagimsiz değişkenleri görüyorum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head(10) #bağımlı değişken olan profiti görüntülüyorum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"→ Profit özniteliği 0 dan 10. gözleme gidildikçe azalmaktadır. Bu bağımsız değişkenlerden kaynaklanıyor.\n* Lineer regresyon yaptığımızda gözlem sırası karışacak, karışık şekilde öğrenmesini sağlayacağız yani önce karı artıran sonra azaltan değerleri bir arada öğrenmeyecek.","metadata":{}},{"cell_type":"markdown","source":"Bu bağımlı ve bağımsız değişkenlerden train ve test olmak üzere 4 parça oluşturalım. Bunu yapmak için train_test_split kullanalım.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n#Test size'ı %20 , Train(öğrenme) ise %80 olarak kullanıyorum burada öğrenme veri kümesini küçük tutarak sonuçların çok iyi olmasını engelliyorum.\n#Veri setimizdeki test size 10 veriye, train ise 40 veriye tekabül ediyor.\n#Random state belirtmek bu noktada önemli belirtilmezse, kodu her çalıştırdığımızda yeni bir rastgele değer oluşturulur.\n#train ve test veri kümelerinin her seferinde farklı değerleri olur. Python bu data'yı her seferinde farklı yerlerinden böler.\n#Eğer bir random_state değeri belirlersek her seferinde o değere göre böler. Yani aynı test verileriyle test etmiş oluruz.\n#Random state kullanarak rassallığı engelleriz.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4 parça değişkeni kontrol edelim.","metadata":{}},{"cell_type":"code","source":"X_train.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test #test olduğundan 10 veri geldi (%20 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test #Test olduğu için bu da 10 değer geldi.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LinearRegression'u çekirdeğe dahil edip modeli inşa edelim.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modeli eğitmek için bağımlı bağımsız değişkenlerden oluşturulan eğitim verilerini verelim.","metadata":{}},{"cell_type":"code","source":"model = lr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modele daha önce görmediği bağımlı test değişkenini tahmin ettirelim. Bu tahmin değerlerimizi y_pred değişkenine atayalım.","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict([[90000, 65000, 100000, 0, 0]])\ny_pred ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 90 bin research and development'a, 65 bin yönetim'e, 100 bin pazarlama'ya harcayan ve New York'lu olan startuplar 118664 dolar kar elde edecektir diye bir çıkarımında bulunabilirim. Burada New Yorku seçtim California = 0 ve Florida = 0 ise New York = 1 dir. Sadece iki değerin durumuna göre üçüncü durumu anlayabiliyoruz.","metadata":{}},{"cell_type":"markdown","source":"Tahminleri ve gerçek değerleri bir veri çerçevesinde toplayıp üzerinde göz gezdirelim.","metadata":{}},{"cell_type":"code","source":"df[\"kar_tahmin\"] = model.predict(X)\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"sklearn bünyesinde barınan metrics'i çekirdeğe dahil edelim ve MAE, MSE, RMSE değerlerini görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nMAE = mean_absolute_error(df[\"Profit\"], df[\"kar_tahmin\"])\nprint(\"Hata Mutlak Ortalama Degeri(MAE):\", MAE) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nMSE = mean_squared_error(df[\"Profit\"], df[\"kar_tahmin\"])\nprint(\"Hata Kareler Ortalaması Degeri(MSE):\", MSE)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nRMSE = math.sqrt(MSE)\nprint(\"Hata Kareler Ortalamasının Karekök Degeri(RMSE):\", RMSE) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelin R Squared değerini eğitim verileri üzerinden yazdıralım.","metadata":{}},{"cell_type":"code","source":"print(\"R Squared:\", model.score(X_train,y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* R Squared değeri modeldeki bağımsız değişkenlerin bağımlı değişkenleri ifade etmesidir. bu değer 1'e ne kadar yakınsa o kadar iyidir bizim modelimide bu 0.95018 çıktı 1'e yakın bir değer gayet iyi diyebiliriz.","metadata":{}},{"cell_type":"markdown","source":"Dileyenler statsmodel kullanarak hangi özniteliklerin model için %95 güvenilirlikle ne kadar anlamlı olup olmadığına da bakabilir. Modelde bazı feature selection işlemleri yaparak tekrardan eğitip yeni sonuçlar mukayese edilebilir.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nstmodel = sm.OLS(y, X).fit()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**OLS(Sıradan En Küçük Kareler Yöntemi)** doğrusal regresyon modeli kurulurken verilerin ortasından geçen eğime (çizgiye) en az kare farkı ile yaklaşmaya çalışan bir yöntemdir.","metadata":{}},{"cell_type":"code","source":"stmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***R^2 ifadesi:*** Bağımsız değişkenlerin bağımlı değişkendeki değişikliği açıklama yüzdesidir.\n* 0.988 oldukça yüksek bir rakam. R^2 ne kadar değişken eklenirse o kadar şişmektedir. Şişmenin önüne geçmek için düzeltilmiş R^2 değeri ortaya çıkar. Daha sağlıklı bir açıklanabilirlik oranı vermektedir.\n***F-statistic:*** Modelin anlamlılığını test etmek için kullanılan istatistiktir.\n***Prob(F- statistic:*** Modelin anlamlı olup olmadığını anlamak için kullanılır.\n* Prob(F- statistic 0.05 den oldukça küçük bir değere sahip. Bu yüzden modelin anlamlı olduğunu söyleyebiliriz. \n***coef:*** Bağımsız değişkenlerin katsayılarını ifade eder. (b1, b2, b3 katsayılarını ifade ediyor.) \n***std err:** Bağımsız değişkenlerin standart hata değeridir. Ne kadar küçükse, doğruluk seviyesi o kadar büyük olur.\n***t istatistiği*** anlamlılığı ifade eder. \n***P>t modellemek için kullandığımız bütün değişkenler anlamlıdır.**\n* 0.05 ten küçük değerler elde ettiğimiz sürece anlamlı değişkenler olur. ","metadata":{}},{"cell_type":"markdown","source":"* Burada önemli bir nokta ise State özniteliklerine baktığımızda P değerinin 0.05'ten büyük değerleri olduğunu görüyoruz. Bu model için iyi bir şey değil. Bnları sileceğim buna ek oalrak kar tahminini de sileceğim ki eski değerlerle işlem yapıp aynı sonuçları bulmayayım.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop([\"StateOf_California\", \"StateOf_Florida\", \"kar_tahmin\"], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1 = df.drop(\"Profit\", axis = 1)\nX1.head() \n#X'e yeni tablomuzu aktarıyorum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head() # y'de yani profitte bir değişiklik yapmadık zaten.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size = 0.2, random_state = 0)\n\n#Test size'ı %20 , Train(öğrenme) ise %80 olarak kullanıyorum burada öğrenme veri kümesini küçük tutarak sonuçların çok iyi olmasını engelliyorum.\n#Veri setimizdeki test size 10 veriye, train ise 40 veriye tekabül ediyor.\n#random state belirtmek bu noktada önemli belirtilmezse, kodu her çalıştırdığımızda yeni bir rastgele değer oluşturulur.\n#train ve test veri kümelerinin her seferinde farklı değerleri olur. Python bu datayı her seferinde farklı yerlerinden böler.\n#Eğer bir random_state değeri belirlersek her seferinde o değere göre böler. Yani aynı test verileriyle test etmiş oluruz. Rassallığ engelleriz.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = LinearRegression()\nmodel2 = lm.fit(X1_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred2 = model2.predict([[90000, 65000, 100000]])\ny_pred2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"kar_tahmin\"] = model2.predict(X1)\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Değerler eskisinden farklı. MSE RMSE ve R Squared değerlerini d bulup yeni modelin daha iyi mi yoksa daha kötü mü olduğuna bakalım.","metadata":{}},{"cell_type":"code","source":"MSE1 = mean_squared_error(df[\"Profit\"], df[\"kar_tahmin\"])\nprint(\"Hata Kareler Ortalaması Degeri(MSE1):\", MSE1)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Hata Kareler Ortalaması Degeri(MSE): 81957374.24681288 idi.\n* Yeni  MSE1 değeri 81056127.50873542 çok küçük de olsa bir düşüş var. Tahmin değerleri ile gerçek değerler arasında daha iyi bir regresyon olduğunu söyleyebiliriz.\n","metadata":{}},{"cell_type":"code","source":"RMSE1 = math.sqrt(MSE1)\nprint(\"Hata Kareler Ortalamasının Karekök Degeri(RMSE1):\", RMSE1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hata Kareler Ortalamasının Karekök Degeri(RMSE): 9053.031218703098 idi yeni RMSE1 değeri 9003.117654942393","metadata":{}},{"cell_type":"code","source":"model2.score(X1_train,y_train) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R Squared: 0.9501847627493607 idi r squared değerinin ise çok küçük bir düşüş yaşadığını görüyoruz.","metadata":{}}]}