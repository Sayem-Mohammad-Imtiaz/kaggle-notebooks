{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Building a Spam Filter with Multinomial Naive Bayes\n\nThis Notebook is the continuation of the Guided Project from [Dataquest](dataquest.io)'s course on Conditional Probability. The goal is to create a spam filter using multinomial [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.metrics import recall_score, precision_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sms_df = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv', header=1, encoding='latin-1', names=['Label', 'SMS', 'Unknown1', 'Unknown2', 'Unknown3'])\nsms_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.drop(['Unknown1','Unknown2','Unknown3'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"sms_df.groupby('Label').describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values in the 5571 entries. However, only 13% of the text messages are classified as spam."},{"metadata":{"trusted":true},"cell_type":"code","source":"list(sms_df[sms_df['Label'] == 'spam']['SMS'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_randomized = sms_df.sample(frac=1, random_state=1)\nsplit_index = round(len(data_randomized) * 0.8)\nsms_train = data_randomized[:split_index].reset_index(drop=True)\nsms_test = data_randomized[split_index:].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step is to replace the 'SMS' column with a set of columns, one for each word in the test dataset's vocabulary. For each row, the column represents the number of times the word appeared in the given SMS. \nTo simplify the vocabulary, all text messages will be stripped of punctuation and all letters are transformed to lowercase."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_and_split_message(message):\n    message = message.lower()\n    message = re.sub(r'\\W', ' ', message)\n    return message.split()\n\nsms_train['SMS'] = sms_train['SMS'].apply(clean_and_split_message)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocabulary = {word for sms_words in list(sms_train['SMS']) for word in sms_words}\nword_counts_per_sms = {unique_word: [0] * len(sms_train['SMS']) for unique_word in vocabulary}\n\nfor index, sms in enumerate(sms_train['SMS']):\n    for word in sms:\n        word_counts_per_sms[word][index] += 1\n        \nsms_train = pd.concat([sms_train, pd.DataFrame(word_counts_per_sms)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the data is in a suitable format, the next objective is to calculate the propability of a new message (decomposed into its words $w_1$, $w_2$, etc) being a spam message or a ham message using the following equations respectively:\n\\begin{equation}\nP(Spam  |  w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n\\end{equation}\n\\begin{equation}\nP(Ham  |  w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n\\end{equation}\n\nThe highest probability determines to which class our message belongs to.\n\nSince we want to apply Multinomial Naive Bayes, each parameter $ P(w_i|Spam) $ and $ P(w_i|Ham) $ is calculated using the following formulas: \n\n\\begin{equation}\nP(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n\\end{equation}\n\\begin{equation}\nP(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n\\end{equation}  \nwhere $ N_{Vocabulary} $ is the size of our vocabulary, $ N_{Ham} $ is the total number of words in all ham messages, $ N_{Ham} $ is the total number of words in all ham messages, $ N_{Spam} $ is the total number of words in all spam messages, and $ \\alpha $ is our smoothing parameter. We will use $ \\alpha = 1 $ (Laplace smoothing).\n\nLet us start by calculating the constants:"},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_cols = sms_train.columns[2:]\nN_ham = sms_train[sms_train['Label'] == 'ham'][vocabulary].sum(axis=1).sum()\nN_spam = sms_train[sms_train['Label'] == 'spam'][vocabulary].sum(axis=1).sum()\nalpha = 1\nP_ham = sms_train[sms_train['Label'] == 'ham'].shape[0]/sms_train.shape[0]\nP_spam = sms_train[sms_train['Label'] == 'spam'].shape[0]/sms_train.shape[0]\nN_vocab = len(vocabulary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As for the parameters, we will initialize two dictionaries, one for spam and one for ham messages, where each key is a word of our vocabulary, and its value is the associated probability as given by the formulas above. "},{"metadata":{"trusted":true},"cell_type":"code","source":"P_wi_given_ham = { wi:0 for wi in vocabulary}\nP_wi_given_spam = { wi:0 for wi in vocabulary}\nsms_train_ham = sms_train[sms_train['Label'] == 'ham']\nsms_train_spam = sms_train[sms_train['Label'] == 'spam']\n\nfor wi in vocabulary:\n    N_wi_given_ham = sms_train_ham[wi].sum()\n    N_wi_given_spam = sms_train_spam[wi].sum()\n    P_wi_given_ham[wi] = (N_wi_given_ham + alpha)/(N_ham + alpha*N_vocab)\n    P_wi_given_spam[wi] = (N_wi_given_spam + alpha)/(N_spam + alpha*N_vocab)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the most computationally expensive calculations only need to be done once, and one the training set alone, which means that there is little to calculate once a new message comes in. \nIn fact, all we need to do now is clean the new message and multiply some of the probabilites we calculated just above."},{"metadata":{"trusted":true},"cell_type":"code","source":"def classify(message):\n    message = clean_and_split_message(message)\n    \n    P_ham_given_message = P_ham\n    P_spam_given_message = P_spam\n    \n    for word in message:\n        if word in P_wi_given_ham:\n            P_ham_given_message *= P_wi_given_ham[word]\n        if word in P_wi_given_spam:\n            P_spam_given_message *= P_wi_given_spam[word]\n\n    if P_ham_given_message > P_spam_given_message:\n        return 'ham'\n    elif P_spam_given_message > P_ham_given_message:\n        return 'spam'\n    else:\n        return 'needs human classification'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(y_true, predicted):\n    return len(y_true[y_true == predicted])/len(y_true)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = sms_test['SMS'].apply(classify)\nprint(accuracy(sms_test['Label'], predictions))\nprint(recall_score(sms_test['Label'], predictions, pos_label='spam'))\nprint(precision_score(sms_test['Label'], predictions, pos_label='spam'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That is a more than an acceptable score. Also note that there were no instances where the classified needed human help.\n\nLet us look at the messages that were wrongly classified: "},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_test[sms_test['Label'] != predictions].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two things stand out, namely that the message 'We have sent JD for Customer Service cum Accounts Executive to ur mail id, For details contact us' appears twice, and that the last message is listed as 'spam' although it does not look like a typical spam message. I personally would have associated it to the ham messages. It is not impossible that there are other \"misclassified\" messages in the training set that could impact the final result."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}