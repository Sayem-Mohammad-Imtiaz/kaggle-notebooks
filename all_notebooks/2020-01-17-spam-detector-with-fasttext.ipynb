{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook contains a simple spam classifier trained on the SMS Spam Collection Dataset (data source: https://www.kaggle.com/uciml/sms-spam-collection-dataset).\n\nA very simple neural network architecture is used: just one 1D-convolutional layer, preceded by initial embedding layer. \nIn this version, a pre-trained fastText embedding is adopted and fine-tuned on the SMS texts corpus. Source: https://www.kaggle.com/facebook/fasttext-english-word-vectors-including-subwords.\n\nImbalance of classes (only 747 instances of \"spam\") is compensated by setting custom class weights for the training loss function.\n\nOnce trained, the model can be used for inference, i.e. predicting whether a particular SMS would be classified as \"spam\" or not. For test purposes, I handcrafted a bunch of messages which I would definitely not want to appear on my phone. A helper function 'check_if_spam' can be used to check for any other message (try it yourself...). Notice that due to very small size of the training sample, model predictions frequently run counterintuitive. More precisely, plenty of 'suspicious' texts are classified as non-spam.\n\nI took an inspiration for this project from the book: \nGULLI, KAPOOR, PAL [2019]: Deep Learning with TensorFlow 2 and Keras - Second Edition, Packt Publishing."},{"metadata":{},"cell_type":"markdown","source":"### Setup & Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras_preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Sequential\n\nfrom keras.layers import Embedding\nfrom keras.layers import Conv1D\nfrom keras.layers import SpatialDropout1D\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.layers import Dense\n\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import KeyedVectors","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/sms-spam-collection-dataset/'\n!ls $PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FT_PATH = '/kaggle/input/fasttext-english-word-vectors-including-subwords/wiki-news-300d-1M-subword.vec'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data loading & inspection"},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data = pd.read_csv(PATH+'spam.csv', encoding='latin_1')\nsms_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for missing values\n\nsms_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping (almost) empty columns as not important\n\ncols_to_drop = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\nsms_data.drop(columns=cols_to_drop, inplace=True)\nsms_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming feature and target columns\n\nfeat_name = 'sms_text'\ntarget_name = 'spam'\nsms_data.columns = [target_name, feat_name]\nsms_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking (binary) target distribution\n\nsms_data['spam'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking if all sms texts are unique\n\nlen(sms_data['sms_text'].unique()) == len(sms_data['sms_text'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting Tokenizer on the \"sms_text\" corpus\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(sms_data['sms_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing learned vocabulary with indices\n\n# tokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_tokens = len(tokenizer.word_index)\nprint('Encoded \"sms_text\" corpus with {} token indices'\n      .format(num_tokens))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing a few sample encodings\n\ntokenizer.texts_to_sequences(['we are your friends', \n                              'nothing last forever',                               \n                              'how do you feel today'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing example reverse encoding\n\ntokenizer.sequences_to_texts([[1, 86, 3], [49, 22, 3]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding whole \"sms_text\" data\nsequences = tokenizer.texts_to_sequences(sms_data['sms_text'])\n\n# padding sequences for equal length\nsequences = pad_sequences(sequences)\n\nnum_seq = sequences.shape[0]\nlen_seq = sequences.shape[1]\n\nprint('Encoded {} sequences and padded for equal length of {} tokens'\n      .format(num_seq, len_seq))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding (binary) target variable\n\nsms_data['target'] = [1 if is_spam == 'spam' else 0 for is_spam in sms_data['spam']]\nsms_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking if target and feature lengths match\n\nsms_data['target'].shape[0] == sequences.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling"},{"metadata":{},"cell_type":"markdown","source":"#### applying pre-trained embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading model (with limit set to 900ths of 1mn vectors available)\n\nft_model = KeyedVectors.load_word2vec_format(FT_PATH, limit=900000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# building the embedding matrix\n\nembedding_matrix = np.zeros((num_tokens + 1, 300))\n\nn_miss = 0\n\n# looping over the Tokenizer dictionary \n# and checking for corresponding embedding vectors\n# if no vector available for a particular word, its embedding weights are left as 'zeros'\nfor word, i in tokenizer.word_index.items():\n    if i >= num_tokens - 1:\n        break\n    try:\n        embedding_matrix[i] = ft_model.get_vector(word)\n    except:\n        n_miss += 1\n        \nprint('Generated embedding matrix: {} token vectors of {} dims'\n      .format(embedding_matrix.shape[0], embedding_matrix.shape[1]))\nprint('Warning: missing pre-trained embeddings for {} tokens'.format(n_miss))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### model architecture: \n\none-layer 1-dimensional Convolutional Neural Network with initial embedding layer\n\nembedding weights are fine-tuned as a part of model training"},{"metadata":{},"cell_type":"markdown","source":"##### setting layers parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# embedding layer parameters\n\ninput_dim = num_tokens + 1\noutput_dim = 300\ninput_length = len_seq\n\n# convolutional (1D) layer parameters\nfilters = 256\nkernel_size = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### setting up the learning process"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = 'adam'\nloss = 'binary_crossentropy'\nmetrics = ['accuracy']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### setting training parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 10\n\n# setting up the \"EarlyStopping\" callback\nearly_stop = EarlyStopping(monitor='val_loss', \n                           min_delta=0, \n                           patience=3, \n                           verbose=True, \n                           mode='auto', \n                           baseline=None, \n                           restore_best_weights=False)\n\ncallbacks = [early_stop]\n\nvalidation_split = 0.20\n\n# setting class weights for the loss function to adjust for class imbalance\n# 'spam' is set to weight 8x more\nclass_weight = {0: 1, 1: 8}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### defining model architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length, \n                    weights=[embedding_matrix], trainable=True))\nmodel.add(Conv1D(filters=filters, kernel_size=kernel_size))\nmodel.add(SpatialDropout1D(rate=0.25))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting target to a single array for simplicity\n\ntarget = sms_data['target'].values\ntarget","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training model with validation and early stopping\n\nmodel.fit(x=sequences, y=target, \n          batch_size=batch_size, epochs=epochs, \n          verbose=True, callbacks=callbacks, \n          validation_split=validation_split, \n          class_weight=class_weight)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Learning history"},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing history of 'accuracy'\n\nplt.figure()\nplt.plot(model.history.history['accuracy'], label='TRAIN ACC')\nplt.plot(model.history.history['val_accuracy'], label='VAL ACC')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing history of 'loss'\n\nplt.figure()\nplt.plot(model.history.history['loss'], label='TRAIN LOSS')\nplt.plot(model.history.history['val_loss'], label='VAL LOSS')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predictions for training sequences (in-sample check)\n\npred = model.predict_classes(sequences)\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing confusion matrix\n\ncm = confusion_matrix(y_true=target, y_pred=pred)\ncm = pd.DataFrame(cm)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the confusion matrix heatmap\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Re-training the model on full train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting the optimal number of epochs\n\nepochs = early_stop.stopped_epoch + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=sequences, y=target, \n          batch_size=batch_size, epochs=epochs, \n          verbose=True, \n          class_weight=class_weight)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nhelper function: check if a SMS text provided would be classified as spam or not\nargument: <string> with SMS text to be checked\nif no argument provided, read the user's input\n\"\"\"\n\ndef check_if_spam(sms=None):\n\n    # read user's input if no argument provided\n    if sms is None:\n        sms = input('Enter SMS text: ')\n    \n    # tokenize the SMS text and pad sequence to match training sequences length\n    sms = [sms,]\n    sequence = tokenizer.texts_to_sequences(sms)\n    sequence = pad_sequences(sequence, maxlen=len_seq)\n    \n    # predict class and give feedback\n    pred_class = model.predict_classes(sequence)\n    is_spam = 'This is SPAM !!!' if pred_class == 1 else 'This is not spam.'\n        \n    return is_spam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_sample = ['Final chance to win free tickets. Call now!', \n             'Suspicious activity detected. Follow this link to change password immediately.',\n             'Get over here and call me tonite. Only 2 USD for minute.',\n             'What are you waiting for! These are final days of our xmass promo deals.',\n             'We have new offers for you. Visit our webpage and see.',\n             'Binary FX options trading and 100 USD on your account. Hurry up.',\n             'Huge discounts this weekend. Check this site to learn more.',\n             'You can also earn easy money. Call us now.',\n             'Congratulations! to claim your reward you must reply immediately',\n             'For our database update we need a contact from you. Call us at.'\n            ]\n\nfor text in my_sample:\n    print('\\nChecking:     ', text)\n    print(check_if_spam(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# call the 'check_if_spam' function with no arguments to provide custom text\n# uncomment to see in action\n\n# check_if_spam()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper script to show random \"spam message\"\n\nspams = sms_data[sms_data['spam'] == 'spam']\nidx = np.random.randint(len(spams))\nspam = spams.iloc[idx]['sms_text']\nprint(spam)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}