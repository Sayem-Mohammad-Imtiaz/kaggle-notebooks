{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Loaing Necessary Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.layers import Conv1D, Embedding, GlobalAveragePooling1D \nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.preprocessing import image\n\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading Image Info from CSV and Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/memotion-dataset-7k/memotion_dataset_7k/labels.csv')\ndf.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\ndf = df.drop(columns = ['text_ocr', 'humour', 'sarcasm', 'offensive', 'motivational'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned = df.copy()\ncleaned.dropna(inplace=True)\ncleaned.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Loading Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"width = 100\nheight = 100\nX = []\nfor i in tqdm(range(cleaned.shape[0])):\n    if i in [119, 4799, 6781, 6784, 6786]:\n        pass\n    else:\n        path = '../input/memotion-dataset-7k/memotion_dataset_7k/images/'+cleaned['image_name'][i]\n        img = image.load_img(path,target_size=(width,height,3))\n        img = image.img_to_array(img)\n        img = img/255.0\n        X.append(img)\n        \nX = np.array(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping few rows to make shape consistent"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows_to_drop = ['image_120.jpg',\n              'image_4800.jpg',\n              'image_6782.jpg',\n              'image_6785.jpg',\n              'image_6787.jpg',\n              'image_6988.jpg',\n              'image_6989.jpg',\n              'image_6990.png',\n              'image_6991.jpg',\n              'image_6992.jpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images in rows_to_drop:\n    cleaned.drop(cleaned[cleaned['image_name'] == images].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = cleaned['overall_sentiment']\ntarget = pd.get_dummies(target)\ntarget.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.2, stratify=target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomContrast([.5,2]),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n  tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)\n])\n\npreprocess_input = tf.keras.applications.resnet_v2.preprocess_input\n\nrescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i in range(9):\n  augmented_image = data_augmentation(X)\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(augmented_image[0])\n  plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Base Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model_1 = tf.keras.applications.ResNet50(input_shape=X[0].shape,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model_2 = tf.keras.applications.VGG16(input_shape=X[0].shape,\n                                               include_top=False,\n                                               weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model_1.trainable = False\nbase_model_2.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model for Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_model():\n    image_input = tf.keras.Input(shape=(100, 100, 3), name = 'image_input')\n    image_layers = data_augmentation(image_input)\n    image_layers = preprocess_input(image_layers)\n    layer_bm_1 = base_model_1(image_input, training=False)\n    layer_bm_1 = Conv2D(2048, kernel_size=2,padding='valid')(layer_bm_1)\n    layer_bm_1 = Dense(512)(layer_bm_1)\n    layer_bm_2 = base_model_2(image_input, training=False)\n    layer_bm_2 = Dense(512)(layer_bm_2)\n    layers = tf.keras.layers.concatenate([layer_bm_1, layer_bm_2])\n    image_layers = GlobalAveragePooling2D()(layers)\n    image_layers = Dropout(0.2, name = 'dropout_layer')(image_layers)\n    return image_input, image_layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_input, image_layers = image_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Standardization and Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def standardization(data):\n    data = data.apply(lambda x: x.lower())\n    data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n    data = data.apply(lambda x: re.sub(r'.com', '', x, flags=re.MULTILINE))\n    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n    return data\n\ncleaned['text_corrected'] = standardization(cleaned.text_corrected)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vectorizing Layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nvocab_size = 10000\nsequence_length = 50\n\nvectorize_layer = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode='int',\n    output_sequence_length=sequence_length)\n\ntext_ds = np.asarray(cleaned['text_corrected'])\nvectorize_layer.adapt(tf.convert_to_tensor(text_ds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(cleaned.text_corrected, target, test_size = 0.2, stratify=target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim=16\n\ndef text_model():\n    text_input = tf.keras.Input(shape=(None,), dtype=tf.string, name='text')\n    text_layers = vectorize_layer(text_input)\n    text_layers = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\")(text_layers)\n\n    text_layers = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, activation='relu', return_sequences=True))(text_layers)\n    text_layers = tf.keras.layers.BatchNormalization()(text_layers)\n    text_layers = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, activation='relu', return_sequences=True))(text_layers)\n    text_layers = tf.keras.layers.BatchNormalization()(text_layers)\n\n    text_layers = tf.keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(text_layers)\n    \n    text_layers = tf.keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(text_layers)\n    \n    text_layers = tf.keras.layers.GlobalMaxPooling1D()(text_layers)\n\n    text_layers = tf.keras.layers.Dense(2048, activation=\"relu\")(text_layers)\n    text_layers = tf.keras.layers.Dropout(0.5)(text_layers)\n    return text_input, text_layers\n\ntext_input, text_layers = text_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combining and Evaluating"},{"metadata":{},"cell_type":"markdown","source":"### Task A: Overall Sentiment"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(layer_1, layer_2, image_input, text_input):\n    concatenate = tf.keras.layers.concatenate([layer_1, layer_2], axis=1)\n    semi_final_layer = tf.keras.layers.Dense(2048, activation='softmax')(concatenate)\n\n    prediction_layer = tf.keras.layers.Dense(5, activation='sigmoid', name = 'task_a')\n\n    output = prediction_layer(semi_final_layer)\n\n    model = tf.keras.Model(inputs = [image_input, text_input] , \n                           outputs = output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model(image_layers, text_layers, image_input, text_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n# Define the checkpoint directory to store the checkpoints\ncheckpoint_dir = './training_checkpoints'\n\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for decaying the learning rate.\n# You can define any decay function you need.\ndef decay(epoch):\n  if epoch < 3:\n    return 1e-1\n  elif epoch >= 3 and epoch < 5:\n    return 1e-2\n  else:\n    return 1e-5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Callback for printing the LR at the end of each epoch.\nclass PrintLR(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n                                                      model.optimizer.lr.numpy()))\n\ncallbacks = [\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n                                       save_weights_only=True),\n    tf.keras.callbacks.LearningRateScheduler(decay),\n    PrintLR()\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['binary_accuracy', 'accuracy'])\n\nhistory = model.fit(x = {\"image_input\": X_train, \"text_input\": X_text_train},\n                    y = y_train,\n                    batch_size=32,\n                    epochs=50,\n                    callbacks=callbacks\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_history = pd.DataFrame(history.history)\ndf_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(15, 5))\nfig.tight_layout(pad=5.0)\n\naxes[0].plot(df_history.loss)\naxes[0].set_xlabel('No of Epochs')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Loss vs Epochs')\n\naxes[1].plot(df_history.binary_accuracy)\naxes[1].plot(df_history.accuracy)\naxes[1].set_xlabel('No of Epochs')\naxes[1].set_ylabel('Loss')\naxes[1].set_title('Accuracy vs Epochs')\naxes[1].legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_ = model.evaluate(x = {\"image_input\": X_test, \"text_input\": X_text_test},\n                    y = y_test,\n                    batch_size=32,\n                    verbose=1\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})\nprediction = np.array(prediction)\nprediction = np.squeeze(prediction)\nprediction = 1/(1+np.exp(-np.array(prediction)))\nprediction = np.where(prediction > 0.5, 1, 0)\ny_true = y_test.values\n\nmicro_f1_score = f1_score(y_true[:,1], prediction[:,1], average='micro')\nmacro_f1_score = f1_score(y_true[:,1], prediction[:,1], average='macro')\n\nprint(\"Micro F1 score for Task A is \", micro_f1_score)\nprint(\"Macro F1 score for Task A is \", macro_f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nfig, axes = plt.subplots(1,2, figsize=(20, 4))\nfig.tight_layout(pad=5.0)\n\n\nx = list(y_test.columns)\n\naxes[0].imshow(X[random.randint(0,X_test.shape[0]),:,:,:])\n\naxes[1].bar(x, model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})[random.randint(0,X_test.shape[0]),:])\naxes[1].set_xlabel('Labels')\naxes[1].set_ylabel('Probanility')\naxes[1].set_title('Humuor Prob.')\naxes[1].set_xticks(x)\naxes[1].set_ylim(0,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(20, 4))\nfig.tight_layout(pad=5.0)\n\n\nx = list(y_test.columns)\n\naxes[0].imshow(X[random.randint(0,X_test.shape[0]),:,:,:])\n\naxes[1].bar(x, model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})[random.randint(0,X_test.shape[0]),:])\naxes[1].set_xlabel('Labels')\naxes[1].set_ylabel('Probanility')\naxes[1].set_title('Humuor Prob.')\naxes[1].set_xticks(x)\naxes[1].set_ylim(0,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(20, 4))\nfig.tight_layout(pad=5.0)\n\n\nx = list(y_test.columns)\n\naxes[0].imshow(X[random.randint(0,X_test.shape[0]),:,:,:])\n\naxes[1].bar(x, model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})[random.randint(0,X_test.shape[0]),:])\naxes[1].set_xlabel('Labels')\naxes[1].set_ylabel('Probanility')\naxes[1].set_title('Humuor Prob.')\naxes[1].set_xticks(x)\naxes[1].set_ylim(0,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(20, 4))\nfig.tight_layout(pad=5.0)\n\n\nx = list(y_test.columns)\n\naxes[0].imshow(X[random.randint(0,X_test.shape[0]),:,:,:])\n\naxes[1].bar(x, model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})[random.randint(0,X_test.shape[0]),:])\naxes[1].set_xlabel('Labels')\naxes[1].set_ylabel('Probanility')\naxes[1].set_title('Humuor Prob.')\naxes[1].set_xticks(x)\naxes[1].set_ylim(0,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(20, 4))\nfig.tight_layout(pad=5.0)\n\n\nx = list(y_test.columns)\n\naxes[0].imshow(X[random.randint(0,X_test.shape[0]),:,:,:])\n\naxes[1].bar(x, model.predict(x = {\"image_input\": X_test, \"text_input\": X_text_test})[random.randint(0,X_test.shape[0]),:])\naxes[1].set_xlabel('Labels')\naxes[1].set_ylabel('Probanility')\naxes[1].set_title('Humuor Prob.')\naxes[1].set_xticks(x)\naxes[1].set_ylim(0,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}