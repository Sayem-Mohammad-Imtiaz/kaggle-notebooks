{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is about \n\nHere we start study trajectories and clusters defined by trajectories for METABRIC data.\nIn particular we show that graph based clusters are in a sense similar to PAM50 clusters,\nwe also make Kaplanâ€“Meier survival analysis comparing PAM50 clusters vs graph-based clusters. \nWe show that graph clusters are not worse than stanard clusters. \n\nWe make several many plots and best ones will be inserted in publication.\n\nIn the last section we show that trajectories for completely random will look quite different - that is additional argument that trajectories for METABRIC make sense. \n\nPreprocessing and params for ElPiGraph are fixed in \"notebook Part 1\" i.e. take 1000 highly variables genes, PCA reduce to 30 dimension,\nconstruct ElPiGraph with 20 nodes, use \n\nPresent notebook gives an example of application of ClinTrajan package (in particular ElPiGraph) for analysis of METABRIC breast cancer dataset. It is based on notebook: https://github.com/auranic/ClinTrajan/blob/master/ClinTrajan_tutorial.ipynb \n\nClinTrajan package:\nhttps://github.com/auranic/ClinTrajan \n\nElPiGraph package: \nhttps://github.com/j-bac/elpigraph-python\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option('display.max_rows', 500)\n#pd.set_option('display.max_columns', 500)\n#pd.set_option('display.width', 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example of using ClinTrajan"},{"metadata":{},"cell_type":"markdown","source":"# Part 1. Quantification of Data"},{"metadata":{},"cell_type":"markdown","source":"### Importing/installing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom scipy.stats import mode\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom importlib import reload  \nimport scipy.stats\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lifelines\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.utils import concordance_index\n!pip install  --no-dependencies  git+https://github.com/j-bac/elpigraph-python.git\nimport elpigraph\n!pip install trimap\n\nimport sys\nsys.path.insert(0,'/kaggle/input/breast-cancer-omics-bulk-data/code/')# \"/path/to/your/package_or_module\")\nprint(sys.path)\n\nfrom clintraj_qi import *\nfrom clintraj_eltree import *\nfrom clintraj_util import *\nfrom clintraj_ml import *\nfrom clintraj_optiscale import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading data (categorical variables are assumed to be dummy-encoded already)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load omics data\ndf1 = pd.read_csv('/kaggle/input/breast-cancer-omics-bulk-data/METABRIC.txt', sep = '\\t', index_col = 0)\ndf1=df1.T\ni1 = [s.replace('BRCA-METABRIC-S1-','') for s in df1.index ]\n#print('number of common ids:', len(set(i2) & set(df1.index) ) )\ndf1.index = i1\ndf1\n# load clinical data\ndf2 = pd.read_csv('/kaggle/input/breast-cancer-omics-bulk-data/METABRIC_clinical.txt', sep = '\\t')#, index_col = 0)\ndf2 = df2.set_index('Patient ID')\ndf2\ndf = df2.join(df1, how = 'inner')\nprint('Joined data shape', df.shape)\ndf\nm = df['Relapse Free Status'].notnull()\nprint( m.sum() )\ndf = df[m].copy()\ndf['Relapse Free Status'] = df['Relapse Free Status'].map({'0:Not Recurred':0,'1:Recurred':1 } )\nprint(df.shape)\ndisplay(df.head())\n\ndf_full = df.copy()\ndf = df.iloc[:,37:] # OMICS data only","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df)\nquantify_nans(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing \n\nCut 1000 top variance variables \n\nStep is intended to use for gene expression data , so we leave 1000 out of dozen thousands of gene expressions \n\n\nDetect variable types\n\nQuantify (and optimize) the ordinal variables via optimal scaling\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_var = df.values.var(axis = 0)\nprint( X_var.shape, X_var[:5] )\nix = np.argsort(X_var)\ndf = df.iloc[:,ix[-1000:]]\nprint(df.shape)\n\n# Detect variable types\nvariable_types, binary, continuous, ordinal = detect_variable_type(df,10,verbose=False)\n# All variables for current data will be recognized as \"continous\"\nprint( type(variable_types), type(binary), type(continuous), type(ordinal) ) # All are list\nprint( variable_types[:3], binary[:3], continuous[:3], ordinal[:3] )\nprint()\n\n\n#Now we quantify (and optimize) the ordinal variables via optimal scaling\n# Now, we are ready to quantify the data table. We will do it by applying optimal scaling to the ordinal values.\ndf = remove_constant_columns_from_dataframe(df)\nvariable_names = [str(s) for s in df.columns[0:]]\nX = df.to_numpy().copy()\nX_original = X.copy()\nX_before_scaling = X.copy()\nX,cik = optimal_scaling(X,variable_types,verbose=True,vmax=0.6)\nX_save = X.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nvec4color = df_full[f]\n\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npca = PCA\nr = pca().fit_transform(X = X )\nplt.figure(figsize = (20,10))\nsns.scatterplot( x=r[:,0], y=r[:,1], hue = vec4color )\nplt.title('PCA for Omics data colored by Pam50 groups')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### OK, we finished preparing the data matrix X, which is now complete and properly quantified. We also keep the 'original matrix' X_original, with 'raw' values of the variables (will be needed for visualizations)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2. Computing the principal tree"},{"metadata":{},"cell_type":"markdown","source":"## Visualization function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ntry :\n    import umap\nexcept:\n    print('cannot import umap')\n\ndef plot_graph(edges, nodes_positions, data = None, dim_reduction = 'PCA', graph_color = 'black', graph_linewidth=2, \n               plot_data = True, data_linewidth = 1,  data_color = None, palette = None,  \n               data_transparency_alpha = 0.9,\n               showNodeNumbers = True, # Shows text with internal number of each node\n               umap_n_neighbors = 50, umap_min_dist = 0.99):\n  '''\n  #' Plots graphs defined by edges and nodes_positions, optionally - scatter plot the \"data\" on the same plot,\n  #' Optionally performs PCA/etc (depending on dim_reduction)\n  #'\n  #' @param edges Nx2-shape matrix with edges ends, i.e. edges[k,0], edges[k,1] - ends of k-th edge  \n  #' @param nodes_positions  matrix of nodes positions \n  #' @param data  \"original dataset\", basically arbitrary dataset for scatter plot, it should have same shape[1] as nodes_positions\n  #' @param plot_data  True/False - to scatterplot or not data\n  #' @param dim_reduction  'PCA', 'plot_first2axis', 'umap'\n  #' @param data_color can be a vector or predefined color - argument for c = data_color in scatter\n\n  #' @examples\n  # edges = np.array([ [0,1],[1,2],[2,0] ] )\n  # nodes_positions = np.random.rand(3,10) # 3 points in 10d space\n  # plot_graph(edges, nodes_positions)\n  #\n  # t = elpigraph_output\n  # edges = t[0]['Edges'][0]\n  # nodes_positions = t[0]['NodePositions']\n  # plot_graph(edges, nodes_positions)\n  '''\n  str_dim_reduction = dim_reduction\n  if dim_reduction in ['PCA', 'umap' ]: #  not 'plot_first2axis':\n    if dim_reduction.upper() == 'PCA':\n      reducer = PCA()\n    elif dim_reduction.lower() == 'umap':\n      n_neighbors = umap_n_neighbors#  50\n      min_dist= umap_min_dist # 0.99\n      #n_components=n_components\n      reducer = umap.UMAP( n_neighbors=n_neighbors,        min_dist=min_dist, n_components = 2)\n\n    if data is not None:\n      data2 = reducer.fit_transform(data)\n      if plot_data == True:\n        if data_color is None:\n          plt.scatter(data2[:,0],data2[:,1], linewidth = data_linewidth , alpha = data_transparency_alpha)# ,cmap=plt.cm.Paired) # ,c=np.array(irx) \n          plt.xlabel(str_dim_reduction+'1')\n          plt.ylabel(str_dim_reduction+'2')\n        else:\n          #plt.scatter(data2[:,0],data2[:,1] ,cmap=plt.cm.Paired,c= data_color, linewidth = data_linewidth, alpha = data_transparency_alpha ) \n          if palette is None:\n              sns.scatterplot( x=data[:,0], y=data[:,1], hue = data_color )# ,   palette=['tab:orange', 'tab:green','tab:pink','tab:brown','tab:purple']  )\n          else:\n            sns.scatterplot( x=data[:,0], y=data[:,1], hue = data_color,   palette=palette)# ['tab:orange', 'tab:green','tab:pink','tab:brown','tab:purple']  )\n\n          plt.xlabel(str_dim_reduction+'1')\n          plt.ylabel(str_dim_reduction+'2')\n    else:\n      reducer.fit(nodes_positions)\n\n    nodes_positions2 = reducer.transform( nodes_positions )\n  else:\n    if plot_data == True:\n      if data is not None:\n        if data_color is None:\n          plt.scatter(data[:,0],data[:,1] , linewidth = linewidth, alpha = data_transparency_alpha )# ,cmap=plt.cm.Paired) # ,c=np.array(irx) \n        else:\n          plt.scatter(data[:,0],data[:,1] ,cmap=plt.cm.Paired,c= data_color , linewidth = data_linewidth, alpha = data_transparency_alpha ) \n          #sns.scatterplot( x=data[:,0], y=data[:,1], hue = data_color )\n\n    nodes_positions2 = nodes_positions\n\n  plt.scatter(nodes_positions2[:,0],nodes_positions2[:,1],c = graph_color, linewidth = graph_linewidth)#, cmap=plt.cm.Paired)\n\n  edgeCount = edges.shape[0]\n  for k in range(edgeCount):\n    n0 = edges[k,0]\n    n1 = edges[k,1]\n    x_line = [ nodes_positions2[n0,0],  nodes_positions2[n1,0] ]\n    y_line = [ nodes_positions2[n0,1],  nodes_positions2[n1,1] ]\n    plt.plot(x_line, y_line, graph_color, linewidth = graph_linewidth) # 'black')\n\n  if showNodeNumbers:\n    for i in range(nodes_positions2.shape[0]):\n      plt.text(nodes_positions2[i,0],nodes_positions2[i,1],str(i),FontSize=20,bbox=dict(facecolor='grey', alpha=0.5))    \n    \nedges = np.array([ [0,1],[1,2],[2,0] ] )\nnodes_positions = np.random.rand(3,10) # 3 points in 10d space\nplot_graph(edges, nodes_positions)\nplt.title('Example graph plot with  plot_graph function')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First of all, we will reduce the dimension using PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_dimension = 30\nX = scipy.stats.zscore(X)\npca = PCA(n_components=X.shape[1],svd_solver='full')\nY = pca.fit_transform(X)\nv = pca.components_.T\nmean_val = np.mean(X,axis=0)\nX = Y[:,0:reduced_dimension]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We are ready to compute the principal tree, let us do it"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#import sys\n#print(sys.path)\n#sys.path.append('/home/zinovyev/anaconda3/lib/python3.7/site-packages')\n#print(sys.path)\n\nnnodes = 20\ntree_elpi = elpigraph.computeElasticPrincipalTree(X,nnodes, # drawPCAView=True,\n                                                  alpha=0.01,Mu=0.1,Lambda=0.05,\n                                                  FinalEnergy='Penalized')\ntree_elpi = tree_elpi[0]\n# some additional pruning of the graph\nprune_the_tree(tree_elpi)\n# extend the leafs to reach the extreme data points\ntree_extended = ExtendLeaves_modified(X, tree_elpi, Mode = \"QuantDists\", ControlPar = .5, DoSA = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nvec4colors = df_full[f].values\n\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\nplt.figure(figsize = (12,12))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.grid()\nplt.legend( fontsize =15 )\nplt.title('PCA for METABRIC dataset and PAM50(+Claudin-low) subtypes', fontsize =15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_groups_correspondence_approximate = {0:'Graph LumAB', 1:'Graph LumB',2:'Graph Basal',3:'Graph Her2',4:'Graph LumA'}\n\n# paritioning the data by tree branches\nvec_labels_by_branches = partition_data_by_tree_branches(X,tree_extended)\nprint(len(set(vec_labels_by_branches)),'labels generated')\nvec4colors = list( map(lambda x: dict_groups_correspondence_approximate[x] ,  vec_labels_by_branches ) )\n\nprint(pd.Series(vec_labels_by_branches).value_counts() )\nprint(pd.Series(vec4colors).value_counts() )\n\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\nplt.figure(figsize = (12,12))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors, palette =['tab:orange', 'tab:green','aqua','tab:brown','tab:purple'] ) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.grid()\nplt.legend( fontsize =15 )\nplt.title('PCA for METABRIC dataset and trajectory based subtypes', fontsize =15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = 0; fig = plt.figure(figsize = (24,12))\n\n\nc+=1; fig.add_subplot(1, 2 , c) \n\nf = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nvec4colors = df_full[f].values\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\n\n#plt.figure(figsize = (12,12))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.grid()\nplt.legend( fontsize =15 )\nplt.xlabel('PCA1', size =15)\nplt.ylabel('PCA2', size =15)\n\nplt.title('PCA for METABRIC dataset and PAM50(+Claudin-low) subtypes', fontsize =15)\n#plt.show()\n\n\n\n\n\n\nc+=1; fig.add_subplot(1, 2 , c) \n\ndict_groups_correspondence_approximate = {0:'Graph LumB', 1:'Graph LumAB',2:'Graph Basal',3:'Graph Her2',4:'Graph LumA'}\n\n# paritioning the data by tree branches\nvec_labels_by_branches = partition_data_by_tree_branches(X,tree_extended)\nprint(len(set(vec_labels_by_branches)),'labels generated')\nvec4colors = list( map(lambda x: dict_groups_correspondence_approximate[x] ,  vec_labels_by_branches ) )\n\nprint(pd.Series(vec_labels_by_branches).value_counts() )\nprint(pd.Series(vec4colors).value_counts() )\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\n#plt.figure(figsize = (12,12))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\n#plot_graph(edges, nodes_positions, data = X , data_color = vec4colors) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors, palette =['tab:orange', 'tab:green','aqua','tab:brown','tab:purple'] ) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.grid()\nplt.legend( fontsize =15 )\nplt.xlabel('PCA1', size =15)\nplt.ylabel('PCA2', size =15)\nplt.title('PCA for METABRIC dataset and trajectory based subtypes', fontsize =15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_full[f].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Survival by clusters PAM50 and trajectory based "},{"metadata":{"trusted":true},"cell_type":"code","source":"# dict_groups_correspondence_approximate = {0:'Graph LumAB', 1:'Graph LumB',2:'Graph Basal',3:'Graph Her2',4:'Graph LumA'}\n#['tab:orange', 'tab:green','aqua','tab:brown','tab:purple']\n\ndict_colors4graph_types = {'Graph LumA': 'tab:orange', 'Graph LumB':'tab:green','Graph LumAB':'aqua','Graph Her2':'tab:purple', 'Graph Basal':  'tab:brown'}\n\ndict_colors4pam50_types = {'LumA': 'tab:orange', 'LumB':'tab:green','Normal':'red','NC':'tab:pink','Her2':'tab:purple', 'Basal':  'tab:brown',\n                          'claudin-low':'tab:blue'}\n\nc1, c2 = 'Relapse Free Status (Months)', 'Relapse Free Status'\nT0 = df_full[c1] \nE0 = df_full[c2]\n\n\nc = 0; fig = plt.figure(figsize = (20,10))\n\n\nc+=1; fig.add_subplot(1, 2 , c) \nf = 'Pam50 + Claudin-low subtype'\nvec4types = df_full[f]\nfor uv in  np.unique( vec4types):\n    mask = vec4types == uv\n    print(uv, mask.sum())\n    if mask.sum() < 30 : continue\n  \n    T = T0[mask]\n    E = E0[mask]\n    #T = df['Overall Survival (Months)'][m]\n    #E =  df['Overall Survival Status'][m].map({'Living':1, 'Deceased':0} )\n    lbl = uv # dict_groups[uv]\n    kmf = KaplanMeierFitter(label=lbl)\n    kmf.fit(T,E)\n    kmf.plot(color = dict_colors4pam50_types[uv])    \nplt.xlim([0,250])\nplt.xlabel('timeline', size =15)\nplt.legend( fontsize =15)\nplt.ylim([0.30,1])\n\nplt.title('Relapse Free ' + ' Original PAM50 groups', fontsize =15) # str(c2.split(' ')[:2] ) ) \n\n\nc+=1; fig.add_subplot(1, 2 , c) \nfor uv in  np.unique( vec_labels_by_branches):\n    mask = vec_labels_by_branches == uv\n    print(uv, mask.sum())\n  \n    T = T0[mask]\n    E = E0[mask]\n    #T = df['Overall Survival (Months)'][m]\n    #E =  df['Overall Survival Status'][m].map({'Living':1, 'Deceased':0} )\n    lbl = dict_groups_correspondence_approximate[uv]\n    kmf = KaplanMeierFitter(label=lbl)\n    kmf.fit(T,E)\n    color = dict_colors4graph_types[dict_groups_correspondence_approximate[uv] ]\n    kmf.plot(color = color)  \nplt.legend( fontsize =15)\nplt.xlabel('timeline', size =15)\nplt.xlim([0,250])\nplt.ylim([0.3,1])\nplt.title('Relapse Free' + ' Graph based groups' , fontsize =15) # str(c2.split(' ')[:2] ) ) \n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# paritioning the data by tree branches\nvec_labels_by_branches = partition_data_by_tree_branches(X,tree_extended)\nprint(len(set(vec_labels_by_branches)),'labels generated')\n# paritioning the data by proximity to nodes\nnodep = tree_elpi['NodePositions']\npartition, dists = elpigraph.src.core.PartitionData(X = X, NodePositions = nodep, \n                                                    SquaredX = np.sum(X**2,axis=1,keepdims=1),\n                                                    MaxBlockSize = 100000000, TrimmingRadius = np.inf\n                                                    )\npartition_by_node = np.zeros(len(partition))\nfor i,p in enumerate(partition):\n    partition_by_node[i] = p[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot data via graph 2d embedding "},{"metadata":{"trusted":true},"cell_type":"code","source":"c1, c2 = 'Relapse Free Status (Months)', 'Relapse Free Status'\nT0 = df_full[c1].copy() \nE0 = df_full[c2].copy()\n    \nmp = {'claudin-low':'tab:blue',\n'LumA':'tab:orange',\n'LumB':'tab:green',\n'Normal':'tab:red',\n'Her2':'tab:purple',\n'Basal':'tab:brown',\n'NC':'tab:pink'}\ncolors = list( df_full['Pam50 + Claudin-low subtype'].map(mp).values )\n\nfig = plt.figure(figsize=(12, 12))\nax = fig.add_subplot(1,1,1)\n\nvisualize_eltree_with_data(tree_extended,X,X_original,v,mean_val,colors,variable_names,\n                          #highlight_subset=inds,\n                           Big_Point_Size=2,Normal_Point_Size=10,showNodeNumbers=True)\n\ncolors_sequence = list( map( lambda x: mp[x] , df_full['Pam50 + Claudin-low subtype'].value_counts().index) )\nadd_pie_charts(ax,tree_extended['NodePositions2D'],colors, colors_sequence ,partition,scale=30)\nplt.title('METABRIC metro map visualization', fontsize =15)\nplt.show()\nroot_node = 20\nprint('Root node=',root_node)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = 0; fig = plt.figure(figsize = (24,12))\n\n\nc+=1; fig.add_subplot(1, 2 , c) \n\nf = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nvec4colors = df_full[f].values\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\n\n#plt.figure(figsize = (12,12))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors, palette =['tab:blue', 'tab:orange', 'tab:green'\n                                                    ,'tab:red','tab:purple','tab:brown','tab:pink']) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.grid()\nplt.legend( fontsize =15 )\nplt.xlabel('PCA1', size =15)\nplt.ylabel('PCA2', size =15)\n\nplt.title('PCA for METABRIC dataset and PAM50(+Claudin-low) subtypes', fontsize =15)\n#plt.show()\n\n\n\nc1, c2 = 'Relapse Free Status (Months)', 'Relapse Free Status'\nT0 = df_full[c1].copy() \nE0 = df_full[c2].copy()\n    \nmp = {'claudin-low':'tab:blue',\n'LumA':'tab:orange',\n'LumB':'tab:green',\n'Normal':'tab:red',\n'Her2':'tab:purple',\n'Basal':'tab:brown',\n'NC':'tab:pink'}\ncolors = list( df_full['Pam50 + Claudin-low subtype'].map(mp).values )\n\n#fig = plt.figure(figsize=(12, 12))\nc+=1; ax =  fig.add_subplot(1, 2 , c) \n# ax = fig.add_subplot(1,1,1)\n\nvisualize_eltree_with_data(tree_extended,X,X_original,v,mean_val,colors,variable_names,\n                          #highlight_subset=inds,\n                           Big_Point_Size=2,Normal_Point_Size=10,showNodeNumbers=True)\n\ncolors_sequence = list( map( lambda x: mp[x] , df_full['Pam50 + Claudin-low subtype'].value_counts().index) )\nadd_pie_charts(ax,tree_extended['NodePositions2D'],colors, colors_sequence ,partition,scale=30)\nplt.title('METABRIC metro map visualization', fontsize =15)\n\nplt.show()\nroot_node = 20\nprint('Root node=',root_node)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8, 8))\nvisualize_eltree_with_data(tree_extended,X,X_original,v,mean_val,'k',variable_names,\n                          Color_by_partitioning = True, visualize_partition = vec4colors) # vec_labels_by_branches)\nplt.title('METABRIC metro map visualization, colored by PAM50 subtypes', fontsize =15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c1, c2 = 'Relapse Free Status (Months)', 'Relapse Free Status'\nT0 = df_full[c1].copy() \nE0 = df_full[c2].copy()\n    \nmp = {'claudin-low':'tab:blue',\n'LumA':'tab:orange',\n'LumB':'tab:green',\n'Normal':'tab:red',\n'Her2':'tab:purple',\n'Basal':'tab:brown',\n'NC':'tab:pink'}\ncolors = list( df_full['Pam50 + Claudin-low subtype'].map(mp).values )\n\nfig = plt.figure(figsize=(12, 12))\nax = fig.add_subplot(1,1,1)\n\nvisualize_eltree_with_data(tree_extended,X,X_original,v,mean_val,colors,variable_names,\n                          #highlight_subset=inds,\n                           Big_Point_Size=2,Normal_Point_Size=10,showNodeNumbers=True)\n\ncolors_sequence = list( map( lambda x: mp[x] , df_full['Pam50 + Claudin-low subtype'].value_counts().index) )\nadd_pie_charts(ax,tree_extended['NodePositions2D'],colors, colors_sequence ,partition,scale=30)\nplt.title('METABRIC metro map visualization', fontsize =15)\nplt.show()\nroot_node = 20\nprint('Root node=',root_node)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trajectories "},{"metadata":{"trusted":true},"cell_type":"code","source":"root_node = 20\nall_trajectories,all_trajectories_edges = extract_trajectories(tree_extended,root_node)\nprint(len(all_trajectories),' trajectories found.')\nProjStruct = project_on_tree(X,tree_extended)\nPseudoTimeTraj = quantify_pseudotime(all_trajectories,all_trajectories_edges,ProjStruct)\n\nfor i,pstt in enumerate(PseudoTimeTraj):\n    if len(all_trajectories_edges[i]) == 0: continue \n    #if i == 0: continue \n    #if i == 1: continue \n        \n    TrajName = 'Trajectory:'+str(pstt['Trajectory'][0])+'--'+str(pstt['Trajectory'][-1])\n    points = pstt['Points']\n    print(pstt)\n#pstt    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compare with trajectories on completely random data\n\nHere we provide additional argument that trajectories constructed for METABRIC make certain sense.\nWe construct trajectories for completely random Gaussian data cloud preprocessed similar to METABRIC:\ngenerate random normal 1979x1000 then reduce by pca to 1979x30 \n\nWe see that trajectiries are very different - much more many branching points, graph does not cover as good as for actual data, so on \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_save = X.copy()\nX_save.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA()\nX = np.random.randn(1979,1000)\nX = pca.fit_transform(X)\nX = X[:,:30]\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import sys\n#print(sys.path)\n#sys.path.append('/home/zinovyev/anaconda3/lib/python3.7/site-packages')\n#print(sys.path)\n\nnnodes = 20\ntree_elpi = elpigraph.computeElasticPrincipalTree(X,nnodes, # drawPCAView=True,\n                                                  alpha=0.01,Mu=0.1,Lambda=0.05,\n                                                  FinalEnergy='Penalized')\ntree_elpi = tree_elpi[0]\n# some additional pruning of the graph\n#prune_the_tree(tree_elpi)\n# extend the leafs to reach the extreme data points\ntree_extended = tree_elpi \n#tree_extended = ExtendLeaves_modified(X, tree_elpi, Mode = \"QuantDists\", ControlPar = .5, DoSA = False)\n\nf = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'#\nvec4colors = df_full[f].values\n\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\nplt.figure(figsize = (22,15))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , showNodeNumbers = False) # Shows text with internal number of each node\n               # , data_color = vec4colors) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.grid()\nplt.legend( fontsize =15 )\nplt.title( 'ElPiGraph for completely random Gaussian data cloud, preprocessed similar to METABRIC i.e. size (1979,1000) then PCA to 30d'+\n         '\\n conclusion: trajectories are very different from real METABRIC data')\n#plt.title('PCA for METABRIC dataset and PAM50(+Claudin-low) subtypes', fontsize =15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X_save.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}