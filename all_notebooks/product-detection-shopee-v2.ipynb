{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Product Detection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nimport itertools\nfrom glob import glob\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras import optimizers\nfrom keras.preprocessing import image\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.applications import InceptionResNetV2\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = [16, 8]\n\nprint('Using Tensorflow version:', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read files","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"folder  = '/kaggle/input/shopee-round-2-product-detection-challenge'\n\ntrain   = pd.read_csv(folder+'/train.csv')\ntest    = pd.read_csv(folder+'/test.csv')\n\nprint(\"Train size: \", train.shape)\nprint(\"Test size: \", test.shape)\nprint(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# path to the train and test folders where all the images are\ntrain_folder='/kaggle/input/shopee-round-2-product-detection-challenge/train/train' \ntest_folder ='/kaggle/input/shopee-round-2-product-detection-challenge/test/test'\n\n\n# combine all train and test images in one path\ntrain_image_path = []\n\nfor i in sorted(os.listdir(train_folder)):\n    train_image_path.append(glob(os.path.join(train_folder,str(i), \"*.jpg\")))\n    \ntest_image_path  = glob(os.path.join(test_folder, \"*jpg\"))\n\nprint(len(train_image_path)) # number of categories in train image path\nprint(len(test_image_path))  # total number of images in test image path","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to display image by category and by number of images\n\ndef display_train_image(path, cat, rangeimage, row, col):\n    \n    fig, axes = plt.subplots(nrows=row, ncols=col, figsize=(12,10))\n    \n    for idx in range(rangeimage):\n        image      = cv2.imread(path[cat][idx]) \n        image      = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        axes.ravel()[idx].imshow(image)\n        #axes.ravel()[idx].axis('off')   \n    plt.tight_layout()\n\ndef display_test_image(path, rangeimage, row, col):\n    \n    fig, axes = plt.subplots(nrows=row, ncols=col, figsize=(12,10))\n    \n    for idx in range(rangeimage):\n        image      = cv2.imread(path[idx]) \n        image      = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        axes.ravel()[idx].imshow(image)\n        #axes.ravel()[idx].axis('off')   \n    plt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# product image under first category \n\ndisplay_train_image(train_image_path, 0, 25, 5, 5) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# product image under last category\n\ndisplay_train_image(train_image_path, 41, 25, 5, 5) # last category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# images under test\n\ndisplay_test_image(test_image_path, 25, 5, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Separate images to train and validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configuration\nBATCH_SIZE = 128\nIMAGE_SIZE = (299,299)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255., \n                                   horizontal_flip  = True,\n                                   brightness_range = [0.4,0.6],\n                                   validation_split = 0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory   = train_folder,\n    target_size = IMAGE_SIZE ,\n    color_mode  = \"rgb\",\n    batch_size  = BATCH_SIZE,\n    class_mode  = \"categorical\",\n    shuffle     = True,\n    seed        = 42,\n    subset      = 'training'\n)\nvalidation_generator = train_datagen.flow_from_directory(\n    directory   = train_folder,\n    target_size = IMAGE_SIZE ,\n    color_mode  = \"rgb\",\n    batch_size  = BATCH_SIZE,\n    class_mode  = \"categorical\",\n    shuffle     = True,\n    seed        = 42,\n    subset      = 'validation'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying Transfer Learning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### InceptionResNetV2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inceptionresnet = InceptionResNetV2(weights='imagenet',\n                                   include_top = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inceptionresnet.summary()\nlen(inceptionresnet.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layers in (inceptionresnet.layers)[:781]:\n    layers.trainable = False\n\nX= inceptionresnet.layers[-2].output\npredictions = Dense(42, activation=\"softmax\")(X)\nmodel_final = Model(inputs= inceptionresnet.input, \n                    outputs = predictions)\n\n# model_final.compile(loss = \"categorical_crossentropy\", \n#                     optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), \n#                     metrics=[\"accuracy\"])\n\n\nmodel_final.compile(loss = \"categorical_crossentropy\", \n                    optimizer = 'adam', metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_final.load_weights(\"/kaggle/input/inceptionresnet/inceptionresnet2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS      = 5\n\ncheckpoint1 = ModelCheckpoint('batch1_inceptionresnet1.h5', \n                              monitor='val_loss', \n                              verbose=0, save_best_only=False, \n                              save_weights_only=True, \n                              mode='auto', period=1)\n\n\n\n\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n\nmodel_final.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=validation_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    callbacks=[checkpoint1],\n                    epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_final.save_weights(\"inceptionresnet1.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict test category using trained model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1/255.)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory  = '/kaggle/input/shopee-round-2-product-detection-challenge/test',\n    target_size= IMAGE_SIZE,\n    color_mode = \"rgb\",\n    batch_size = 1,\n    class_mode = None,\n    shuffle    = False,\n    seed       = 42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\ntest_generator.reset()\npred          =model_final.predict_generator(test_generator,\n                                             steps=STEP_SIZE_TEST,verbose=1)\n\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels                 = (train_generator.class_indices)\nlabels                 = dict((v,k) for k,v in labels.items())\npredictions            = [labels[k] for k in predicted_class_indices]\npredictions            = list(map(lambda c: str(c).zfill(2), predictions))\nfilenames              = test_generator.filenames\nfilenames2             = [file[5:] for file in filenames]\n\nresults=pd.DataFrame({\"filename\":filenames2,\n                      \"category\":predictions})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge predictions with test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"finalresults = pd.merge(test['filename'], results, how=\"left\", on=\"filename\")\n\nfinalresults.to_csv(\"result_inception2.csv\",index=False)\n\nfinalresults.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalresults.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}