{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 CoronaWhy NLP N-grams (Bigrams & Trigrams)"},{"metadata":{},"cell_type":"markdown","source":"Memory is a concern for this task so you'll see a few instances of some memory clean ups."},{"metadata":{},"cell_type":"markdown","source":"### Let's import all the tools we will need"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport nltk, re, string, collections\nfrom nltk.util import ngrams # function for making ngrams\nimport re\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.tokenize import word_tokenize","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we will load the data from one of our CoronaWhy datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/coronawhy/dataset_v6.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting this column as text column to make the data easier to process."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text'] = df['text'].astype(str)\ndf['text'] = df['text'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filter the data by keywords.  This is recommended because there is a LOT of data to parse through.  In this section we will filter the data by anything that contains the word 'age'."},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_keywords = ['age']\ndf = df[df['text'].str.contains('|'.join(filter_keywords))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Combining the text to search so we can process it for later."},{"metadata":{"trusted":true},"cell_type":"code","source":"text_to_search = ' '.join(df[\"text\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now that we have our text loaded, let's delete the data frame to save some memory"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing punctuation since we don't need that for N-grams."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get rid of punctuation\npunctuationNoPeriod = \"[\" + re.sub(\"\\.\",\"\",string.punctuation) + \"]\"\ntext_to_search = re.sub(punctuationNoPeriod, \"\", text_to_search)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing stop words.  We'll use the English stop words from NLTK plus some customized stop words we've been using for COVID-19"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's remove stop words\n# we will use the stop words provided by the NLTK\n# we will also add in some customized stop words used in other places for COVID-19\n\ncustomized_stop_words = [\n    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.', 'q', 'license',\n    'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da',  'dell',  'non', 'si', 'holder',\n    'p', 'h'\n]\n\nstop_words = list(stopwords.words('english')) + customized_stop_words\nprint(stop_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's tokenize the text and remove the stop words (this takes a while depending on the size of the data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's tokenize the words\ntext_tokens = word_tokenize(text_to_search)\ntext_to_search = [word for word in text_tokens if not word in stop_words]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we'll start with Bigrams."},{"metadata":{"trusted":true},"cell_type":"code","source":"# and get a list of all the bigrams\nesBigrams = ngrams(text_to_search, 2)\n\n# get the frequency of each bigram in our corpus\nesBigramFreq = collections.Counter(esBigrams)\n\n# what are the ten most popular bigrams\nesBigramFreq.most_common(25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now let's look at Trigrams."},{"metadata":{"trusted":true},"cell_type":"code","source":"# and get a list of all the trigrams\nesTrigrams = ngrams(text_to_search, 3)\n\n# get the frequency of each trigram in our corpus\nesTrigramFreq = collections.Counter(esTrigrams)\n\n# what are the ten most popular trigrams\nesTrigramFreq.most_common(25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning up some RAM here since we don't have unlimited memory with Kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"del esBigrams\ndel esBigramFreq\ndel esTrigrams\ndel esTrigramFreq","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we will look for Bigrams and Trigrams with specific words."},{"metadata":{"trusted":true},"cell_type":"code","source":"search_for_word = 'age' # Text we want the Bi/Trigrams to contain\n\n# reset the Bigrams\nesBigrams = ngrams(text_to_search, 2)\nesBigramFreq = collections.Counter(esBigrams)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now let's show the Bigrams containing our search word"},{"metadata":{"trusted":true},"cell_type":"code","source":"for gram, freq in esBigramFreq.most_common():\n    if gram[0] == search_for_word or gram[1] == search_for_word:\n        print(gram, freq)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean up memory again"},{"metadata":{"trusted":true},"cell_type":"code","source":"del esBigrams\ndel esBigramFreq","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now let's show the Trigrams containing our search word"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reset the Trigrams\nesTrigrams = ngrams(text_to_search, 3)\nesTrigramFreq = collections.Counter(esTrigrams)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for gram, freq in esTrigramFreq.most_common():\n    if gram[0] == search_for_word or gram[1] == search_for_word or gram[2] == search_for_word:\n        print(gram, freq)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}