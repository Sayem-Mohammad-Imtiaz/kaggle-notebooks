{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThis is a study of flight take off data from John F. Kennedy International Airport.\nOur goal is to predict the taxi-out time of a flight.\nYou can download the dataset [from Kaggle](https://www.kaggle.com/deepankurk/flight-take-off-data-jfk-airport).\n\n### Loading the dataset\n\nBefore we do anything, we're going to update `scikit-learn` to a newer neversion.\n","metadata":{"id":"9CeAG6d7A_Fb"}},{"cell_type":"code","source":"! pip install --upgrade scikit-learn","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's start by taking a look at the raw data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv(\"../input/flight-take-off-data-jfk-airport/M1_final.csv\")","metadata":{"id":"NgMaYw3j5OnW","execution":{"iopub.status.busy":"2021-07-22T11:32:22.558476Z","iopub.execute_input":"2021-07-22T11:32:22.558895Z","iopub.status.idle":"2021-07-22T11:32:22.67252Z","shell.execute_reply.started":"2021-07-22T11:32:22.558796Z","shell.execute_reply":"2021-07-22T11:32:22.669956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"id":"ec-lg9PK6UTi","outputId":"9feaf531-e7d7-4344-ea1b-4eee08f93a65","execution":{"iopub.status.busy":"2021-07-22T11:32:22.67396Z","iopub.status.idle":"2021-07-22T11:32:22.67479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"id":"NHz9BrTh6WA4","outputId":"66689709-aba2-4775-be42-ac447792dab1","execution":{"iopub.status.busy":"2021-07-22T11:32:22.676083Z","iopub.status.idle":"2021-07-22T11:32:22.676905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Description of the columns\n\nThere are $28820$ observations of $23$ variables.\nEach observation is an individual flight.\n- `MONTH`, `DAY_OF_MONTH`, `DAY_OF_WEEK` contain information about the date of the flight\n- `OP_UNIQUE_CARRIER` contains ID of the airline (i.e. `AA` stands for American Airlines)\n- `TAIL_NUM` is the tail number of the plane\n- `DEST` is the destination airport code\n- `DEP_DELAY` is the departure delay of the flight\n- `CRS_ELAPSED_TIME` is expected duration of the light\n- `DISTANCE` is the distance between airports\n- `CRS_DEP_M` is scheduled departure time (in minutes after midnight)\n- `DEP_TIME_M` is actual departure time (gate checkout)\n- `CRS_ARR_M` is scheduled arrival time\n- `Temperature`, `Dew Point`, `Humidity`, `Wind Speed`, `Wind Gust` and `Pressure` are the numeric characteristis of the weather\n- `Wind` is the direction of the wind (`CALM` if calm, `VAR` if wind blows from various directions)\n- `Condition` contains natural language description of the weather\n- `sch_dep` is the number of flights scheduled for departure\n- `sch_arr` is the number of flights scheduled for arrival \n- `TAXI_OUT` is the time between the actual pushback and wheels-off.\n\nThere are five caterogical variables: `OP_UNIQUE_CARRIER`, `TAIL_NUM`, `DEST`, `WIND` and `Condition`. \nThe rest of the variables is numerical.\n\n### Train/test split\n\nBefore we go any further, we need to split the dataset into a training and a test part.\nOur target variable is `TAXI_OUT`.\n","metadata":{"id":"8iG65hN368cD"}},{"cell_type":"code","source":"y = data[\"TAXI_OUT\"]\nX = data.drop(\"TAXI_OUT\", axis=1)\n\n#reproducibility\nseed = 1001\n\nfrom sklearn.model_selection import train_test_split \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)","metadata":{"id":"en49YVa--_ip","execution":{"iopub.status.busy":"2021-07-22T11:32:22.678158Z","iopub.status.idle":"2021-07-22T11:32:22.678975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Analysis\n\n### Are there any NaN values?","metadata":{"id":"sInOt0LoCQxK"}},{"cell_type":"code","source":"X_train.info()","metadata":{"id":"dty4WkVeCT09","outputId":"525f07ea-5d53-4f63-d55a-7f62aa65b139","execution":{"iopub.status.busy":"2021-07-22T11:32:22.680179Z","iopub.status.idle":"2021-07-22T11:32:22.680972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that all there are $23056$ non-null values in each column of the training data, except for `Wind`, where there are $23055$ non-null values.\n\nWe cannot have any missing value in the test set, either.\nHowever, there also is one missing value in the `Wind` variable.","metadata":{"id":"VyqoEWcqDWlX"}},{"cell_type":"code","source":"X_test.info()","metadata":{"id":"HMFtupyj82mM","outputId":"69c3c12d-d136-4bcf-ffb4-5079c48b722c","execution":{"iopub.status.busy":"2021-07-22T11:32:22.681789Z","iopub.status.idle":"2021-07-22T11:32:22.682355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Basic statistics","metadata":{"id":"N2Ywo-DzDpkB"}},{"cell_type":"code","source":"X_train.describe()","metadata":{"id":"nkiO_3W1ChTg","outputId":"ca217fd3-411d-47d1-aaf0-847c2a433b59","execution":{"iopub.status.busy":"2021-07-22T11:32:22.68315Z","iopub.status.idle":"2021-07-22T11:32:22.68366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the distributions\n\nWe're going to plot the distribution of each variable.\nLet's start with the numerical ones.","metadata":{"id":"0sN4RdejD0Tq"}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef plot_num_var_dist(var, kde=True, kde_plot=False, discrete=False):\n  if kde_plot:\n    sns.kdeplot(data=X_train, x=var)\n  else:\n    sns.histplot(data=X_train, x=var, kde=kde, discrete=discrete)","metadata":{"id":"rk-NmoV7Dja_","execution":{"iopub.status.busy":"2021-07-22T11:32:22.684436Z","iopub.status.idle":"2021-07-22T11:32:22.684945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"MONTH\", discrete=True)","metadata":{"id":"ZEmfYGNjEZr1","outputId":"e8ff242f-7fad-417e-a330-ea13a637c39d","execution":{"iopub.status.busy":"2021-07-22T11:32:22.685697Z","iopub.status.idle":"2021-07-22T11:32:22.686237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have data about departures from November, December, and January, distributed almost evenly.","metadata":{"id":"rTzzZTTVGCHx"}},{"cell_type":"code","source":"plot_num_var_dist(\"DAY_OF_MONTH\", discrete=True)","metadata":{"id":"gic6BD31FQ3f","outputId":"a37115d9-0b00-4b81-8956-548e78a2f8ee","execution":{"iopub.status.busy":"2021-07-22T11:32:22.687467Z","iopub.execute_input":"2021-07-22T11:32:22.687832Z","iopub.status.idle":"2021-07-22T11:32:22.706079Z","shell.execute_reply.started":"2021-07-22T11:32:22.687806Z","shell.execute_reply":"2021-07-22T11:32:22.704622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"DAY_OF_WEEK\", kde=False, discrete=True)","metadata":{"id":"CrPRi_h2F4lE","outputId":"51101411-3ef5-4d34-e721-3c3d37bae0f7","execution":{"iopub.status.busy":"2021-07-22T11:32:22.707037Z","iopub.status.idle":"2021-07-22T11:32:22.707491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is equal number of flights on Monday, Tuesday, Wednesday, Thursday and Sunday (about 3200).\nThere are more flights on Friday (about 3600) and fewer on Saturday (about 2800).","metadata":{"id":"DvRmHh7FIcxt"}},{"cell_type":"code","source":"plot_num_var_dist(\"DEP_DELAY\", kde_plot=True)","metadata":{"id":"IEGFLu-PG6Xb","outputId":"86d6b66a-b710-46a5-991a-86d2b1a9d899","execution":{"iopub.status.busy":"2021-07-22T11:32:22.708485Z","iopub.status.idle":"2021-07-22T11:32:22.708947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be excpected, there is a spike around $0$.","metadata":{"id":"I6udVrrvNnkG"}},{"cell_type":"code","source":"plot_num_var_dist(\"CRS_ELAPSED_TIME\")","metadata":{"id":"Non86rKrKmAY","outputId":"fcd5533f-b97e-439c-967a-4b02c123f383","execution":{"iopub.status.busy":"2021-07-22T11:32:22.715231Z","iopub.execute_input":"2021-07-22T11:32:22.715544Z","iopub.status.idle":"2021-07-22T11:32:22.731429Z","shell.execute_reply.started":"2021-07-22T11:32:22.715508Z","shell.execute_reply":"2021-07-22T11:32:22.730005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"DISTANCE\")","metadata":{"id":"KXHd7Pj4NpDo","outputId":"28883f9d-4b84-4622-fade-ae42aee31d99","execution":{"iopub.status.busy":"2021-07-22T11:32:22.732843Z","iopub.status.idle":"2021-07-22T11:32:22.733814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice that the distributon of `DISTANCE` and `CRS_ELAPSED_TIME` is very roughly the same.\nThis of course makes a lot of sense.","metadata":{"id":"zoHXWCKqP5u0"}},{"cell_type":"code","source":"plot_num_var_dist(\"CRS_DEP_M\")","metadata":{"id":"l3ZAZdC3P13f","outputId":"44a82f1a-217b-4657-8cc7-fd92200e188a","execution":{"iopub.status.busy":"2021-07-22T11:32:22.739547Z","iopub.execute_input":"2021-07-22T11:32:22.740052Z","iopub.status.idle":"2021-07-22T11:32:22.756Z","shell.execute_reply.started":"2021-07-22T11:32:22.740008Z","shell.execute_reply":"2021-07-22T11:32:22.754732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"DEP_TIME_M\")","metadata":{"id":"6rrdpp5IQj9O","outputId":"c8a8c250-edee-4ac2-af47-db830c31079c","execution":{"iopub.status.busy":"2021-07-22T11:32:22.757129Z","iopub.status.idle":"2021-07-22T11:32:22.757628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are also pretty similar. ","metadata":{"id":"DVIG-0BDQ6qo"}},{"cell_type":"code","source":"plot_num_var_dist(\"CRS_ARR_M\")","metadata":{"id":"Mucm77tuQuhy","outputId":"375612c8-ba0c-49c5-d816-0b8c4e282d3c","execution":{"iopub.status.busy":"2021-07-22T11:32:22.76393Z","iopub.execute_input":"2021-07-22T11:32:22.764245Z","iopub.status.idle":"2021-07-22T11:32:22.783314Z","shell.execute_reply.started":"2021-07-22T11:32:22.764217Z","shell.execute_reply":"2021-07-22T11:32:22.782095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"Temperature\", kde_plot=True)","metadata":{"id":"nl2cD66TRKJ7","outputId":"627102b3-ad31-44cc-e8da-6f7a68a39f8f","execution":{"iopub.status.busy":"2021-07-22T11:32:22.784384Z","iopub.status.idle":"2021-07-22T11:32:22.785031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This looks more or less like a normal distribution.","metadata":{"id":"bv15_Eu_TbDl"}},{"cell_type":"code","source":"X_train = X_train.astype({\"Dew Point\": \"int\"})\n\nplot_num_var_dist(\"Dew Point\", kde_plot=True)","metadata":{"id":"7htfZEr0Rg_3","outputId":"57d40e1f-2c41-4969-9138-5eb5ba7c421f","execution":{"iopub.status.busy":"2021-07-22T11:32:22.789923Z","iopub.execute_input":"2021-07-22T11:32:22.790251Z","iopub.status.idle":"2021-07-22T11:32:22.812295Z","shell.execute_reply.started":"2021-07-22T11:32:22.790223Z","shell.execute_reply":"2021-07-22T11:32:22.810481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"Humidity\", kde_plot=True)","metadata":{"id":"VTvULtRARslt","outputId":"9fe983ee-7839-403a-aa61-ca62d4b93300","execution":{"iopub.status.busy":"2021-07-22T11:32:22.813491Z","iopub.status.idle":"2021-07-22T11:32:22.813942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"Wind Speed\", kde_plot=True)","metadata":{"id":"YiPgIy6fTTtQ","outputId":"c7b06593-3eaf-4235-c310-911432c09d03","execution":{"iopub.status.busy":"2021-07-22T11:32:22.820157Z","iopub.execute_input":"2021-07-22T11:32:22.820465Z","iopub.status.idle":"2021-07-22T11:32:22.840095Z","shell.execute_reply.started":"2021-07-22T11:32:22.820437Z","shell.execute_reply":"2021-07-22T11:32:22.838742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"Wind Gust\")","metadata":{"id":"grXP0r3cTWhs","outputId":"7bcdebd2-eba0-496a-8839-53f6a33d1ca8","execution":{"iopub.status.busy":"2021-07-22T11:32:22.841098Z","iopub.status.idle":"2021-07-22T11:32:22.841725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is another variable with a spike at $0$.","metadata":{"id":"IkyFot0mHZ9z"}},{"cell_type":"code","source":"plot_num_var_dist(\"Pressure\", kde_plot=True)","metadata":{"id":"yAIwtkboTiVh","outputId":"dcac9f71-f285-45b0-c2bd-f6dc376c868c","execution":{"iopub.status.busy":"2021-07-22T11:32:22.853793Z","iopub.execute_input":"2021-07-22T11:32:22.854344Z","iopub.status.idle":"2021-07-22T11:32:22.870848Z","shell.execute_reply.started":"2021-07-22T11:32:22.85431Z","shell.execute_reply":"2021-07-22T11:32:22.869405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"sch_dep\", discrete=True)","metadata":{"id":"eARU-pgvTkMr","outputId":"eaf318a5-5396-44e3-d596-cf0be55cc8e7","execution":{"iopub.status.busy":"2021-07-22T11:32:22.871982Z","iopub.status.idle":"2021-07-22T11:32:22.872547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"sch_arr\", discrete=True)","metadata":{"id":"e1-ubGoXTq7l","outputId":"c384e9cc-ccd3-45aa-dc0a-0b6162828325","execution":{"iopub.status.busy":"2021-07-22T11:32:22.874107Z","iopub.execute_input":"2021-07-22T11:32:22.874403Z","iopub.status.idle":"2021-07-22T11:32:22.895892Z","shell.execute_reply.started":"2021-07-22T11:32:22.874375Z","shell.execute_reply":"2021-07-22T11:32:22.894619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's create countplots for categorical variables.","metadata":{"id":"evi6ZMLKUYXA"}},{"cell_type":"code","source":"def plot_cat_var_dist(var, n=20, figsize=(10,5)):\n  plt.figure(figsize=figsize)\n  sns.countplot(y=X_train[var], order=X_train[var].value_counts().iloc[:n].index, palette=\"crest\")","metadata":{"id":"K68WGassTtfz","execution":{"iopub.status.busy":"2021-07-22T11:32:22.901752Z","iopub.execute_input":"2021-07-22T11:32:22.902175Z","iopub.status.idle":"2021-07-22T11:32:22.906842Z","shell.execute_reply.started":"2021-07-22T11:32:22.902145Z","shell.execute_reply":"2021-07-22T11:32:22.905983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_cat_var_dist(\"OP_UNIQUE_CARRIER\")","metadata":{"id":"J54_k1BfUYCV","outputId":"b3af9c8f-21fa-4868-f636-f12334cc90c7","execution":{"iopub.status.busy":"2021-07-22T11:32:22.910765Z","iopub.execute_input":"2021-07-22T11:32:22.911202Z","iopub.status.idle":"2021-07-22T11:32:22.939485Z","shell.execute_reply.started":"2021-07-22T11:32:22.911172Z","shell.execute_reply":"2021-07-22T11:32:22.938303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a lot of unique values in `TAIL_NUM` column, so we can't really create a column for each one.\nInstead, let's consider twenty most common tail numbers.","metadata":{"id":"HLgSPXIQVoWm"}},{"cell_type":"code","source":"plot_cat_var_dist(\"TAIL_NUM\", n=20)","metadata":{"id":"gd4NOONLUti_","outputId":"ed84f2ac-ca31-4ec6-b7b2-202c0a2e1a91","execution":{"iopub.status.busy":"2021-07-22T11:32:22.94051Z","iopub.status.idle":"2021-07-22T11:32:22.9411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below, we plot twenty most common arrival destinations.","metadata":{"id":"s7sYFs1Jfa0E"}},{"cell_type":"code","source":"plot_cat_var_dist(\"DEST\", n=20)","metadata":{"id":"Ur7PmBvNVXAe","outputId":"e22a1daa-c107-47d7-8734-8ea8b0bde4dc","execution":{"iopub.status.busy":"2021-07-22T11:32:22.942372Z","iopub.execute_input":"2021-07-22T11:32:22.942823Z","iopub.status.idle":"2021-07-22T11:32:23.092488Z","shell.execute_reply.started":"2021-07-22T11:32:22.942757Z","shell.execute_reply":"2021-07-22T11:32:23.090474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_cat_var_dist(\"Wind\")","metadata":{"id":"zbvnyIMkbmiz","outputId":"71061374-f87b-44a7-f3f3-53c12aad768c","execution":{"iopub.status.busy":"2021-07-22T11:32:23.093767Z","iopub.status.idle":"2021-07-22T11:32:23.094664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_cat_var_dist(\"Condition\", n=25, figsize=(10,8))","metadata":{"id":"414oylaxcP2J","outputId":"0689edef-6d74-4e2e-8a9f-d210a69f4ed5","execution":{"iopub.status.busy":"2021-07-22T11:32:23.095976Z","iopub.status.idle":"2021-07-22T11:32:23.096976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, let's plot the target variable.","metadata":{"id":"b2vPtRGX-t7P"}},{"cell_type":"code","source":"sns.histplot(x=y_train, kde=True, discrete=True)","metadata":{"id":"yNTtLkZ7-sdU","outputId":"c78fbbdd-a40a-4253-e3b5-3d5e3295aa7e","execution":{"iopub.status.busy":"2021-07-22T11:32:23.098199Z","iopub.status.idle":"2021-07-22T11:32:23.098997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Violin plots\n\nLet's create a violin plot for each categorical variable.\nMost of them have too many unique values, so we're going to consider only the most common ones.","metadata":{"id":"vUMR8n2fEtvE"}},{"cell_type":"code","source":"import numpy as np\n\ndef violin(var, figsize=(10,10), n=10):\n  mask = np.in1d(X_train[var], X_train[var].value_counts().iloc[:n].index)\n  plt.figure(figsize=figsize)\n  sns.violinplot(data=X_train.loc[mask], x=var, y=y_train, palette=\"crest\")\n\nviolin(\"MONTH\", figsize=(7.5,7.5))","metadata":{"id":"MJFxaL6tEzdb","outputId":"163ce811-16c9-4c5a-e880-e1a2ec956e44","execution":{"iopub.status.busy":"2021-07-22T11:32:23.100223Z","iopub.status.idle":"2021-07-22T11:32:23.101039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"violin(\"OP_UNIQUE_CARRIER\", figsize=(20,7.5))","metadata":{"id":"WN-f3s48FeoT","outputId":"bf5d4d84-b0ff-4bac-e708-0044711cc0e9","execution":{"iopub.status.busy":"2021-07-22T11:32:23.102275Z","iopub.status.idle":"2021-07-22T11:32:23.103124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"violin(\"TAIL_NUM\",  figsize=(20,7.5), n=10)","metadata":{"id":"TsO-FYD3F7Be","outputId":"48d83ea7-26c1-4e36-ca76-b6e6704f5d69","execution":{"iopub.status.busy":"2021-07-22T11:32:23.104308Z","iopub.status.idle":"2021-07-22T11:32:23.105113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"violin(\"DEST\", figsize=(20,7.5), n=10)","metadata":{"id":"67_Xt0iXGbbt","outputId":"d0d1e750-04f5-4bc3-9c13-f9247334e818","execution":{"iopub.status.busy":"2021-07-22T11:32:23.106229Z","iopub.status.idle":"2021-07-22T11:32:23.106736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"violin(\"Wind\", figsize=(30,7.5), n=20)","metadata":{"id":"bYlpPvC4Gjfg","outputId":"e8fe5f3c-deb2-40c6-e124-dd72b55cdc58","execution":{"iopub.status.busy":"2021-07-22T11:32:23.107553Z","iopub.status.idle":"2021-07-22T11:32:23.108094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"violin(\"Condition\", figsize=(10,7.5), n=5)","metadata":{"id":"aC9jV4XTGxbW","outputId":"19ff4942-09ec-4b32-bcb9-db174e803af5","execution":{"iopub.status.busy":"2021-07-22T11:32:23.108864Z","iopub.status.idle":"2021-07-22T11:32:23.109412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PCA Visualization\n\nWe're going to use numerical columns to visualize the data in a 2D and 3D projection on principal components.\nBefore we do that, we're going to temporarily standarize the data.","metadata":{"id":"tdYmPJvJf_or"}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline      import Pipeline\n\ncategorical = [\"OP_UNIQUE_CARRIER\", \"TAIL_NUM\", \"DEST\", \"Wind\", \"Condition\"]\nnumerical = list(set(X_train.columns) - set(categorical))\n\nsteps2d = [(\"scaler\", StandardScaler()), (\"PCA\", PCA(n_components=2))]\npca2d = Pipeline(steps2d)\npca2d_dt = pca2d.fit_transform(X_train[numerical])\npca2d_dt = pd.DataFrame(pca2d_dt)\n\nplt.figure(figsize=(10,10))\nsns.scatterplot(x=pca2d_dt[0], y=pca2d_dt[1], hue=y_train, palette=\"crest\")","metadata":{"id":"YMC1dXlQdP64","outputId":"d61d0246-931e-45c1-948f-32a230b1df2f","execution":{"iopub.status.busy":"2021-07-22T11:32:23.11022Z","iopub.status.idle":"2021-07-22T11:32:23.110721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps3d = [(\"scaler\", StandardScaler()), (\"PCA\", PCA(n_components=3))]\npca3d = Pipeline(steps3d)\npca3d_dt = pca3d.fit_transform(X_train[numerical])\npca3d_dt = pd.DataFrame(pca3d_dt)\n\nfig = plt.figure()\nax = plt.axes(projection=\"3d\")\nax.scatter3D(pca3d_dt[0], pca3d_dt[1], pca3d_dt[2])","metadata":{"id":"tjgt15RegMeG","outputId":"28eec624-7c17-4760-9a25-f1991a97e301","execution":{"iopub.status.busy":"2021-07-22T11:32:23.1115Z","iopub.status.idle":"2021-07-22T11:32:23.112002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On the 2D plot we see two clusters, that almost could be separated by a plane.\nThere is also a line pattern of outliers on the right side of the plot.\n\n### Plotting the target variable\n\nWe're going to plot the target variable against every other numerical variable on a scatterplot.","metadata":{"id":"gJZtCZQbjZn0"}},{"cell_type":"code","source":"def scatter(var):\n  sns.scatterplot(y=y_train, x=X_train[var])\n\nscatter(\"MONTH\")","metadata":{"id":"W0epGU7khbwS","outputId":"c9f768b4-dcb0-4ecf-e901-32afd94790f1","execution":{"iopub.status.busy":"2021-07-22T11:32:23.112754Z","iopub.status.idle":"2021-07-22T11:32:23.113306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"DAY_OF_MONTH\")","metadata":{"id":"FiF6HPRyB5n4","outputId":"bb2beceb-63b8-46ea-9583-bc8eb5230cce","execution":{"iopub.status.busy":"2021-07-22T11:32:23.114068Z","iopub.status.idle":"2021-07-22T11:32:23.114564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"DAY_OF_WEEK\")","metadata":{"id":"BTLi6PGfB4R5","outputId":"85246522-0871-4662-e31b-27c2f841da26","execution":{"iopub.status.busy":"2021-07-22T11:32:23.115328Z","iopub.status.idle":"2021-07-22T11:32:23.115818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distributions above are pretyy even.","metadata":{"id":"keGAqxFGCDns"}},{"cell_type":"code","source":"scatter(\"DEP_DELAY\")","metadata":{"id":"3ZOYyxT0CTTC","outputId":"794aec34-00b6-45d6-8266-b1a35e1dcd7a","execution":{"iopub.status.busy":"2021-07-22T11:32:23.117152Z","iopub.execute_input":"2021-07-22T11:32:23.117531Z","iopub.status.idle":"2021-07-22T11:32:23.133063Z","shell.execute_reply.started":"2021-07-22T11:32:23.117503Z","shell.execute_reply":"2021-07-22T11:32:23.131904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"CRS_ELAPSED_TIME\")","metadata":{"id":"8j2hO_GCCYv3","outputId":"2aba6f61-94c5-482e-ddf7-ac4460b8fe5d","execution":{"iopub.status.busy":"2021-07-22T11:32:23.134135Z","iopub.status.idle":"2021-07-22T11:32:23.134792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"DISTANCE\")","metadata":{"id":"vDZNfeC9C-YJ","outputId":"3ad26c8c-c16e-46e7-de5b-c194e832dd2f","execution":{"iopub.status.busy":"2021-07-22T11:32:23.135769Z","iopub.status.idle":"2021-07-22T11:32:23.136281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we see a bunch of outliers, but the target variable's values doesn't seem to be affected by them.","metadata":{"id":"AqetxyhdCpoI"}},{"cell_type":"code","source":"scatter(\"CRS_DEP_M\")","metadata":{"id":"2Ao6dsbPDCyM","outputId":"957b65c2-0179-4f29-dab3-93c1b74d90c1","execution":{"iopub.status.busy":"2021-07-22T11:32:23.142485Z","iopub.execute_input":"2021-07-22T11:32:23.142842Z","iopub.status.idle":"2021-07-22T11:32:23.15826Z","shell.execute_reply.started":"2021-07-22T11:32:23.142809Z","shell.execute_reply":"2021-07-22T11:32:23.157048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"DEP_TIME_M\")","metadata":{"id":"ds-dJ8o2DIKh","outputId":"2835d39d-893b-48d5-ef09-ce648a5c2caf","execution":{"iopub.status.busy":"2021-07-22T11:32:23.159366Z","iopub.status.idle":"2021-07-22T11:32:23.160038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"CRS_ARR_M\")","metadata":{"id":"PSFFQ4_VDM9-","outputId":"fff46fa4-2489-4007-aab6-6ed9742419aa","execution":{"iopub.status.busy":"2021-07-22T11:32:23.161108Z","iopub.status.idle":"2021-07-22T11:32:23.161573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, wee see two clusters: a big one, and a smaller one.","metadata":{"id":"E3bhYvaYDiZL"}},{"cell_type":"code","source":"scatter(\"Temperature\")","metadata":{"id":"mE3-8nhGDfhR","outputId":"91732740-830d-4bcb-9aee-97eaadd324f3","execution":{"iopub.status.busy":"2021-07-22T11:32:23.168929Z","iopub.execute_input":"2021-07-22T11:32:23.169364Z","iopub.status.idle":"2021-07-22T11:32:23.186288Z","shell.execute_reply.started":"2021-07-22T11:32:23.169335Z","shell.execute_reply":"2021-07-22T11:32:23.18474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"Dew Point\")","metadata":{"id":"aFyUHD3WDbCN","outputId":"1810005e-a9f3-4d93-b0e9-181c2213fbe4","execution":{"iopub.status.busy":"2021-07-22T11:32:23.18726Z","iopub.status.idle":"2021-07-22T11:32:23.187702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"Humidity\")","metadata":{"id":"foLOPIALDqrQ","outputId":"23e4627c-d03b-4a71-f266-5cba61fb9bd6","execution":{"iopub.status.busy":"2021-07-22T11:32:23.189371Z","iopub.execute_input":"2021-07-22T11:32:23.189818Z","iopub.status.idle":"2021-07-22T11:32:23.204468Z","shell.execute_reply.started":"2021-07-22T11:32:23.189787Z","shell.execute_reply":"2021-07-22T11:32:23.20301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The line on the left seems very bizzare, as if the measurement was incorrect a couple of times.","metadata":{"id":"rQERWDLHD0pw"}},{"cell_type":"code","source":"scatter(\"Wind Speed\")","metadata":{"id":"NeIv2_zpDvZy","outputId":"759ab9d3-2ad0-4817-e7f8-03ea4169c48e","execution":{"iopub.status.busy":"2021-07-22T11:32:23.206097Z","iopub.status.idle":"2021-07-22T11:32:23.206688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"Wind Gust\")","metadata":{"id":"I7EztSLQEP7w","outputId":"d7aa670b-9f0d-4a51-f72d-d30e63e1a927","execution":{"iopub.status.busy":"2021-07-22T11:32:23.212839Z","iopub.execute_input":"2021-07-22T11:32:23.213202Z","iopub.status.idle":"2021-07-22T11:32:23.22918Z","shell.execute_reply.started":"2021-07-22T11:32:23.213162Z","shell.execute_reply":"2021-07-22T11:32:23.227885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"Pressure\")","metadata":{"id":"PsDaLFgLDzdQ","outputId":"937ad847-57ad-4a03-87d2-0f36b9e0bc6a","execution":{"iopub.status.busy":"2021-07-22T11:32:23.230208Z","iopub.status.idle":"2021-07-22T11:32:23.230834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"sch_dep\")","metadata":{"id":"znX7rNfyERGh","outputId":"e4821ce3-c66e-457e-c336-b79dd86f6de8","execution":{"iopub.status.busy":"2021-07-22T11:32:23.232314Z","iopub.execute_input":"2021-07-22T11:32:23.232792Z","iopub.status.idle":"2021-07-22T11:32:23.250064Z","shell.execute_reply.started":"2021-07-22T11:32:23.232762Z","shell.execute_reply":"2021-07-22T11:32:23.248563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter(\"sch_arr\")","metadata":{"id":"fKzPwsw-EYP9","outputId":"2725fdc4-9957-4a9f-895f-67ef05fc8f3c","execution":{"iopub.status.busy":"2021-07-22T11:32:23.25159Z","iopub.status.idle":"2021-07-22T11:32:23.252523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, we see traces of the second, smaller cluster.","metadata":{"id":"eSkgciSREjS-"}},{"cell_type":"markdown","source":"### Correlation heatmap\n\nBelow, we see a correlation heatmap of numerical features.","metadata":{"id":"-jVAiwYz5ery"}},{"cell_type":"code","source":"corr = X_train[numerical].corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, vmin=-1, vmax=1, center=0, square=True)","metadata":{"id":"sI2FxZ035cTv","outputId":"e82341c5-983b-419a-ead4-3034393eb6c1","execution":{"iopub.status.busy":"2021-07-22T11:32:23.263238Z","iopub.execute_input":"2021-07-22T11:32:23.263775Z","iopub.status.idle":"2021-07-22T11:32:23.280033Z","shell.execute_reply.started":"2021-07-22T11:32:23.263741Z","shell.execute_reply":"2021-07-22T11:32:23.27872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are two pairs of highly correlated features:\n- `DISTANCE` and `CRS_ELAPSED_TIME`: this is pretty obvious (the more distant the destination the longer the journey is going to take) and we noticed it before. I believe we can safely remove `DISTANCE` column.\n- `CRS_DEP_M` and `DEP_TIME_M`: this is also not surprising, first column contains scheduled departure time, the other the actual deprature time. Their difference is containted in the `DEP_DELAY` variable, so here we also most likely can remove one of the features.","metadata":{"id":"lDkDRbFZ6hIJ"}},{"cell_type":"markdown","source":"# Baseline performance\n\nTo create a baseline against which we're going to be testing more complex models, we're going to use `sklearn`'s `DummyRegressor`.","metadata":{"id":"Cg3m4oASYpav"}},{"cell_type":"code","source":"from sklearn.dummy import DummyRegressor\n\ndummy_clf = DummyRegressor(strategy=\"mean\")\ndummy_clf.fit(X_train, y_train)\ndummy_pred = dummy_clf.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\n\nbaseline_MSE = mean_squared_error(dummy_pred, y_test)\nbaseline_MSE","metadata":{"id":"9Jo98xvVayBo","outputId":"ad3b5646-d344-423c-9936-71b3ddbcc1e0","execution":{"iopub.status.busy":"2021-07-22T11:32:23.284637Z","iopub.execute_input":"2021-07-22T11:32:23.284974Z","iopub.status.idle":"2021-07-22T11:32:24.047069Z","shell.execute_reply.started":"2021-07-22T11:32:23.284941Z","shell.execute_reply":"2021-07-22T11:32:24.042467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction with mean value gives us baseline mean squared error of about $47$.\n\nLet's also create a simple linear regression model using the numerical columns and see what MSE it'll achieve.","metadata":{"id":"Nv5I-ZedcTRd"}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train[numerical], y_train)\nlr_preds = lr.predict(X_test[numerical])\n\nbaseline_MSE_lr = mean_squared_error(lr_preds, y_test)\nbaseline_MSE_lr","metadata":{"id":"4VGLkTbmcfge","outputId":"e93cc7ac-2f5d-4056-f861-874feec1fdbc","execution":{"iopub.status.busy":"2021-07-22T11:32:24.04842Z","iopub.status.idle":"2021-07-22T11:32:24.049103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering\n\n### Spikes at $0$\n\nWe cannot really do anything about `Wind Gust` variable.\nIt just has a lot of $0$ values.\nOn the other hand, take a look at the distribution of the `DEP_DELAY`.\nAn idea is to see if it is normally distributed using Shapiro-Wilk test.\nIf so, we could transform it using the inverse CDF function.","metadata":{"id":"a9uHmHokHKQh"}},{"cell_type":"code","source":"from scipy.stats import shapiro\n\nshapiro(X_train[\"DEP_DELAY\"])","metadata":{"id":"ZgRlixns20aE","outputId":"ce68b134-e2ef-4c46-dfca-e87b081cc1bf","execution":{"iopub.status.busy":"2021-07-22T11:32:24.050628Z","iopub.status.idle":"2021-07-22T11:32:24.051536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently not.\nThe `scipy` library gives us a warning about possible inaccuracy of the p-value, so let's confirm the Shapiro-Wilk test with Kolmogorov-Smirnov test.","metadata":{"id":"9ZQbmkF770ZO"}},{"cell_type":"code","source":"from scipy.stats import kstest\nfrom scipy.stats import norm\n\nkstest(X_train[\"DEP_DELAY\"], norm.cdf)","metadata":{"id":"Tg93wXvv701t","outputId":"c4ca2064-d3e0-4e28-913b-7cf5b929ba69","execution":{"iopub.status.busy":"2021-07-22T11:32:24.053098Z","iopub.status.idle":"2021-07-22T11:32:24.05357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another idea is to use a logarithm.\nThe variable has negative values, so first we'll shift to the right.","metadata":{"id":"mVZf1ztt_BHd"}},{"cell_type":"code","source":"def spike_transform(var, test=False):\n  if test:\n    return np.log(X_test[var] + 100)\n  else:\n    return np.log(X_train[var] + 100)\n\nsns.kdeplot(spike_transform(\"DEP_DELAY\"))","metadata":{"id":"_moNZV2r-6xO","outputId":"48ca74d2-2112-4929-d779-7a2e79980631","execution":{"iopub.status.busy":"2021-07-22T11:32:24.055114Z","iopub.status.idle":"2021-07-22T11:32:24.055648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This looks a bit better, the spike is not as sharp as it was before.","metadata":{"id":"8B70k7oEI20y"}},{"cell_type":"code","source":"X_train = X_train.assign(DEP_DELAY = lambda x: spike_transform(\"DEP_DELAY\"))","metadata":{"id":"GqHlj4HMwT0S","execution":{"iopub.status.busy":"2021-07-22T11:32:24.057591Z","iopub.status.idle":"2021-07-22T11:32:24.058213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also have to transform the `DEP_DELAY` column in the test set. ","metadata":{"id":"n4JteOOXot3H"}},{"cell_type":"code","source":"X_test = X_test.assign(DEP_DELAY = lambda x: spike_transform(\"DEP_DELAY\", test=True))","metadata":{"id":"aNUUTtces1OX","execution":{"iopub.status.busy":"2021-07-22T11:32:24.059295Z","iopub.status.idle":"2021-07-22T11:32:24.059826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As to `Wind Gust`, we'll leave it as it is.\nUsing a logarithm won't benefit us, because the value are not cenetered at zero, there's just a lot of $0$ in the column.","metadata":{"id":"5KOGJU2mJrIF"}},{"cell_type":"markdown","source":"### Deleteing highly correlated features\n\nWe've already decided to remove `DISTANCE` and `CRS_DEP_M` features.\nLet's do that now.","metadata":{"id":"gCOno6pm7UAS"}},{"cell_type":"code","source":"X_train = X_train.drop([\"DISTANCE\", \"CRS_DEP_M\"], axis=1)\nX_test = X_test.drop([\"DISTANCE\", \"CRS_DEP_M\"], axis=1)","metadata":{"id":"Mh6FIAHZ7rFr","execution":{"iopub.status.busy":"2021-07-22T11:32:24.061167Z","iopub.status.idle":"2021-07-22T11:32:24.061629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discretization of `Humidity` (and similar)\n\nRecall the distribution of the `Humidity` variable.","metadata":{"id":"zMDJzzjABVUd"}},{"cell_type":"code","source":"plot_num_var_dist(\"Humidity\", kde_plot=True)","metadata":{"id":"fnDOlc8EBOgW","outputId":"5a0fcc6f-d7df-4695-f308-bb73ee797743","execution":{"iopub.status.busy":"2021-07-22T11:32:24.063326Z","iopub.status.idle":"2021-07-22T11:32:24.064004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems a good idea would be to create a new variable, `Binary Humidity`. \nIt should be equal to zero if `Humidity` is smalelr than $20$ and equal two one otherwise.","metadata":{"id":"2cX1_fTSBebE"}},{"cell_type":"code","source":"def binary20(x):\n  if x < 20: return 0\n  else:      return 1\n\nX_train = X_train.assign(Binary_Humidity = lambda x:  X_train[\"Humidity\"].apply(binary20))\nX_test = X_test.assign(Binary_Humidity = lambda x: X_test[\"Humidity\"].apply(binary20))","metadata":{"id":"wBZog9STBcW3","execution":{"iopub.status.busy":"2021-07-22T11:32:24.065474Z","iopub.status.idle":"2021-07-22T11:32:24.066028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice that there are other columns like this.","metadata":{"id":"A1zvIRLGGaJn"}},{"cell_type":"code","source":"plot_num_var_dist(\"CRS_ELAPSED_TIME\")","metadata":{"id":"S6YyrD22FesI","outputId":"0040ad1e-36b6-4605-ec58-b4ee0d7b58c3","execution":{"iopub.status.busy":"2021-07-22T11:32:24.067097Z","iopub.status.idle":"2021-07-22T11:32:24.067568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"sch_arr\", discrete=True)","metadata":{"id":"L3uYUx2YG-LD","outputId":"62dd1567-c8e8-4e49-9703-607fece10d06","execution":{"iopub.status.busy":"2021-07-22T11:32:24.068515Z","iopub.status.idle":"2021-07-22T11:32:24.069015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_num_var_dist(\"CRS_ARR_M\")","metadata":{"id":"e6PX7JRJMV4d","outputId":"61ce26c2-0e07-4ce0-d95b-484f2f6a34ca","execution":{"iopub.status.busy":"2021-07-22T11:32:24.070464Z","iopub.status.idle":"2021-07-22T11:32:24.071262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `CRS_ELAPSED_TIME` needs $3$ values, rather than $2$.\nFor `sch_arr` and `CRS_ARR_M` we see that $2$ are enough.","metadata":{"id":"xYEAWBplHFE5"}},{"cell_type":"code","source":"def binary25(x):\n  if x < 25: return 0\n  else:      return 1\n\nX_train = X_train.assign(Binary_sch_arr = lambda x:  X_train[\"sch_arr\"].apply(binary25))\nX_test = X_test.assign(Binary_sch_arr = lambda x: X_test[\"sch_arr\"].apply(binary25))\n\ndef binary400(x):\n  if x < 400: return 0\n  else:      return 1\n\nX_train = X_train.assign(Binary_CRS_ARR_M = lambda x:  X_train[\"CRS_ARR_M\"].apply(binary400))\nX_test = X_test.assign(Binary_CRS_ARR_M = lambda x: X_test[\"CRS_ARR_M\"].apply(binary400))\n\ndef cet_transformer(x):\n  if x < 300:  return 0\n  if x < 4000: return 1\n  else:        return 2\n\nX_train = X_train.assign(Classes_CRS_ELAPSED_TIME = lambda x:  X_train[\"CRS_ELAPSED_TIME\"].apply(cet_transformer))\nX_test = X_test.assign(Classes_CRS_ELAPSED_TIME = lambda x: X_test[\"CRS_ELAPSED_TIME\"].apply(cet_transformer))","metadata":{"id":"0JeIiw7xHi4H","execution":{"iopub.status.busy":"2021-07-22T11:32:24.072413Z","iopub.status.idle":"2021-07-22T11:32:24.072939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filling missing values\n\nThere are two of them, both in the `Wind` variable.\nWe're going fill them with a special value.\nWe want to use `OridinalEncoder` anyways, so they will get their own class and perhaps the model will use this information to improve its predictions.","metadata":{"id":"-KALVTc19ou5"}},{"cell_type":"code","source":"X_train = X_train.fillna(\"missing\")\nX_test = X_test.fillna(\"missing\")","metadata":{"id":"KWq6USRMCSoM","execution":{"iopub.status.busy":"2021-07-22T11:32:24.073924Z","iopub.status.idle":"2021-07-22T11:32:24.074373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will also create a new column, `Wind_NA`, where value are equal to `0` if the corresponding values in the `Wind` column were not missing and equal to `1` when they were.","metadata":{"id":"OUkJKBrY2KTA"}},{"cell_type":"code","source":"def was_missing(x):\n  if x == \"missing\": return 1\n  else:              return 0\n\nX_train = X_train.assign(Wind_NA = lambda x:  X_train[\"Wind\"].apply(was_missing))\nX_test = X_test.assign(Wind_NA = lambda x: X_test[\"Wind\"].apply(was_missing))","metadata":{"id":"dOZpilb62d4r","execution":{"iopub.status.busy":"2021-07-22T11:32:24.075375Z","iopub.status.idle":"2021-07-22T11:32:24.075834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `Wind` variable\n\nThe `Wind` variable has a lot of unique values.","metadata":{"id":"t_Uy44gAuf5b"}},{"cell_type":"code","source":"X_train[\"Wind\"].unique()","metadata":{"id":"-H4NDkqKx10o","outputId":"0a242df2-777a-4ada-c8c1-b8c91eb55679","execution":{"iopub.status.busy":"2021-07-22T11:32:24.076944Z","iopub.status.idle":"2021-07-22T11:32:24.077408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use `OridinalEncoder` to encode it anyways, however we're also going to create two new variables, containing the direction of the wind on two axis.\nMore precisily, this is the mapping we will use:\n\n`E`   -> 1, 0 \\\\\n`ENE` -> 0.92, 0.38 \\\\\n`NE`  -> 0.7, 0.7\n`NNE` -> 0.38, 0.92 \\\\\n`N`   -> 0, 1\n\netc.\n\nSo we're assigning an angle $\\theta$ to each label and then pair $\\cos(\\theta), \\sin(\\theta)$. \nThis way the directions are actually distributed on a circle, which wouldn't be possible in one dimension.\n\nThis does not cover all the possible value in the `Wind` column.\nWe will assign $0$ to `CALM` values.\nWe will also assign $0$ to missing values, since we created a separate `Wind_NA` column anyways.\n\nWe're also going to map `VAR` values to $0$ and create separte column, `Wind_VAR`, which will indicate if the `Wind` column contained `Var` value in this row. ","metadata":{"id":"Rf9zeQIyymST"}},{"cell_type":"code","source":"def was_var(dir):\n  if dir == \"VAR\": return 1\n  else:            return 0\n\nwind_order = [\"E\", \"ENE\", \"NE\", \"NNE\", \n              \"N\", \"NNW\", \"NW\", \"WNW\",\n              \"W\", \"WSW\", \"SW\", \"SSW\",\n              \"S\", \"SSE\", \"SE\", \"ESE\"]\n\nwind_ang = {k: np.pi/8*i for i,k in enumerate(wind_order)}\n\ndef get_cos(dir):\n  if dir in set([\"VAR\", \"CALM\", \"missing\"]): \n    return 0\n  else:\n    return np.cos(wind_ang[dir])\n\ndef get_sin(dir):\n  if dir in set([\"VAR\", \"CALM\", \"missing\"]): \n    return 0\n  else:\n    return np.sin(wind_ang[dir])\n  \nX_train = X_train.assign(Wind_VAR = lambda x:  X_train[\"Wind\"].apply(was_var))\nX_test = X_test.assign(Wind_VAR = lambda x: X_test[\"Wind\"].apply(was_var))\n\nX_train = X_train.assign(Wind_COS = lambda x:  X_train[\"Wind\"].apply(get_cos))\nX_test = X_test.assign(Wind_COS = lambda x: X_test[\"Wind\"].apply(get_cos))\n\nX_train = X_train.assign(Wind_SIN = lambda x:  X_train[\"Wind\"].apply(get_sin))\nX_test = X_test.assign(Wind_SIN = lambda x: X_test[\"Wind\"].apply(get_sin))","metadata":{"id":"xq0a2EE43Cfr","execution":{"iopub.status.busy":"2021-07-22T11:32:24.078397Z","iopub.status.idle":"2021-07-22T11:32:24.078842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding the categorical variables\n\nThe categorical variables, except for `Condition`, are pretty simple.\nThey tend to have a lot of unique values, so we're simply going to use a `sklearn`'s `OridinalEncoder`.\nWe have to use `handle_unknown=\"use_encoded_value\"` parameter, since there are tail numbers in the test set that aren't present in the training set.\n\nWe're also standarizing here the rest of the columns, except for the `MONTH`, `DAY_OF_WEEK`, `DAY_OF_MONTH` and the variables we just created.","metadata":{"id":"BhVLpyYK0ZuJ"}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose       import ColumnTransformer\n\n# changed order of feature names\ndiff = lambda l1,l2: [x for x in l1 if x not in l2]\n\nto_encode = categorical\nto_omit = [\"MONTH\", \n           \"DAY_OF_MONTH\", \n           \"DAY_OF_WEEK\", \n           \"Binary_Humidity\",\t\n           \"Binary_sch_arr\", \n           \"Binary_CRS_ARR_M\", \n           \"Classes_CRS_ELAPSED_TIME\", \n           \"Wind_NA\",\n           \"Wind_VAR\",\n           \"Wind_COS\",\n           \"Wind_SIN\"]\n\nto_scale = diff(diff(X_train.columns, to_encode), to_omit)\n\nnames = to_encode + to_scale + to_omit\n\nenc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\nscl = StandardScaler()\nct = ColumnTransformer([(\"encode\", enc, to_encode), (\"scale\", scl, to_scale)], remainder=\"passthrough\")\n\nct.fit(X_train)\nX_train = pd.DataFrame(ct.transform(X_train), columns=names)\nX_test = pd.DataFrame(ct.transform(X_test), columns=names)","metadata":{"id":"njVI3irN1FWN","execution":{"iopub.status.busy":"2021-07-22T11:32:24.079752Z","iopub.status.idle":"2021-07-22T11:32:24.080226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names","metadata":{"id":"B0dIVJYK84zl","outputId":"dc58b7de-9f8e-46fa-fc70-99aeb657a61c","execution":{"iopub.status.busy":"2021-07-22T11:32:24.081143Z","iopub.status.idle":"2021-07-22T11:32:24.081591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Month column\n\nWe have three value in the `MONTH` column: `1` for January, `11` for November, and `12` for December.\nHowever the order should be November, December, January.\nAlso, January comes right after December, but in our data value assigned to December is much bigger than value assigned to January.\nWe might benefit from transforming this column in the following fashion.\nWe'll asign `1` to November, `2` to December, and `3` to January.","metadata":{"id":"C12gXr3PRuZT"}},{"cell_type":"code","source":"def month_transformer(x):\n  if x == 1:  return 3\n  if x == 11: return 1\n  if x == 12: return 2\n\nX_train = X_train.assign(MONTH = lambda x: X_train[\"MONTH\"].apply(month_transformer))\nX_test = X_test.assign(MONTH = lambda x: X_test[\"MONTH\"].apply(month_transformer))","metadata":{"id":"CDzVcmGTSk1k","execution":{"iopub.status.busy":"2021-07-22T11:32:24.082536Z","iopub.status.idle":"2021-07-22T11:32:24.083045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see if linear regression model achieves lower MSE after feature engineering.","metadata":{"id":"PrTeiF3Ld1vi"}},{"cell_type":"code","source":"lr.fit(X_train, y_train)\nlr_preds = lr.predict(X_test)\n\nmean_squared_error(lr_preds, y_test)","metadata":{"id":"WWy3mmpodiYU","outputId":"b3b0d3e1-90f7-4134-eb8f-b46b03048ae3","execution":{"iopub.status.busy":"2021-07-22T11:32:24.084222Z","iopub.status.idle":"2021-07-22T11:32:24.084694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is smaller by just a tiny bit.","metadata":{"id":"JvfXtYRmeIfy"}},{"cell_type":"markdown","source":"# Outlier detection\n\nWe're going to use a couple of automatic outlier detection algorithms and visualize the outcome.\n\nNotice that the PCA visualization will differ from the one we've seen before, as we've encoded categorical features.\n\n### Isolation Forest\n\nThe `threshold` parameter below wich the observations are considered to be outliers was chosen \"by trial and error\", that is I used some different value and chose the one that seemed to be most reasonable.","metadata":{"id":"NF3s0KAXQmay"}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\niforest = IsolationForest(n_estimators = 250, random_state=seed)\niforest.fit(X_train)\nif_scores = iforest.score_samples(X_train)\n\ndef set_labels(x, threshold):\n  if x < threshold: return \"Outlier\"\n  else:             return \"Inlier\" \n\nset_labels = np.vectorize(set_labels)","metadata":{"id":"W4BqC2ipRmu6","execution":{"iopub.status.busy":"2021-07-22T11:32:24.085674Z","iopub.status.idle":"2021-07-22T11:32:24.086148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps2d = [(\"scaler\", StandardScaler()), (\"PCA\", PCA(n_components=2))]\npca2d = Pipeline(steps2d)\npca2d_dt = pca2d.fit_transform(X_train)\npca2d_dt = pd.DataFrame(pca2d_dt)\n\nplt.figure(figsize=(10,10))\ng = sns.scatterplot(x=pca2d_dt[0], y=pca2d_dt[1], hue=set_labels(if_scores, -0.595))\ng.set(xlabel=\"PCA1\", ylabel=\"PCA2\", title=\"Isolation Forest outlier detection\")","metadata":{"id":"cpduZBVBQl-y","outputId":"816846ab-357c-4d1f-a86a-5ccaee2eaabc","execution":{"iopub.status.busy":"2021-07-22T11:32:24.087289Z","iopub.status.idle":"2021-07-22T11:32:24.088006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Local Outlier Factor","metadata":{"id":"xJLGMZJvYWQe"}},{"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor\n\nlofact = LocalOutlierFactor()\nlofact.fit(X_train)\nlof_scores = lofact.negative_outlier_factor_\n\nplt.figure(figsize=(10,10))\ng = sns.scatterplot(x=pca2d_dt[0], y=pca2d_dt[1], hue=set_labels(lof_scores, -1.4))\ng.set(xlabel=\"PCA1\", ylabel=\"PCA2\", title=\"Local Outlier Factor outlier detection\")","metadata":{"id":"pGdCc4_xYTf2","outputId":"a7a12832-741d-4bef-87a4-c290f0d24737","execution":{"iopub.status.busy":"2021-07-22T11:32:24.088953Z","iopub.status.idle":"2021-07-22T11:32:24.089407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both algorithms found a couple observations that can be considered as outliers.\nWe're going to simply remove them from the training data.","metadata":{"id":"AQHlz9rKinIs"}},{"cell_type":"code","source":"def mask_outliers(x, threshold):\n  if x < threshold: return True\n  else:             return False\n\nmask_outliers = np.vectorize(mask_outliers)\n\nmask_if = mask_outliers(if_scores, -0.6)\nmask_lof = mask_outliers(lof_scores, -1.25)\n\nmask = mask_if | mask_lof\n\nX_train = X_train.drop(X_train.loc[mask].index)\ny_train = y_train.drop(y_train.loc[mask].index)","metadata":{"id":"EsbeDlHgimYw","execution":{"iopub.status.busy":"2021-07-22T11:32:24.090427Z","iopub.status.idle":"2021-07-22T11:32:24.090867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Building the regressor\n\n### Model selection\n\nThe models we're going to try out are:\n- random forest\n- extra-trees regressor\n- gradient boosting\n- support vector machine\n- elastic net\n- multilayer perceptron\n- guassian process regression\n- gaussian naive bayes\n\nWe're going to use the MSE metric.\n","metadata":{"id":"8tel4LRvLk2o"}},{"cell_type":"code","source":"from sklearn.ensemble         import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.linear_model     import ElasticNet\nfrom sklearn.svm              import SVR\nfrom sklearn.naive_bayes      import GaussianNB\nfrom sklearn.neural_network   import MLPRegressor\n\nmodels = {\n    \"gb\": GradientBoostingRegressor(random_state=seed),\n    \"ranger\": RandomForestRegressor(random_state=seed),\n    \"extra\": ExtraTreesRegressor(random_state=seed),\n    \"enet\": ElasticNet(),\n    \"svm\": SVR(),\n    \"bayes\": GaussianNB(),\n    \"mlp\": MLPRegressor(random_state=seed)\n}","metadata":{"id":"a7ah-U8ULkZY","execution":{"iopub.status.busy":"2021-07-22T11:32:24.091981Z","iopub.status.idle":"2021-07-22T11:32:24.092447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's start by creating testing each model in a ten fold cross-validation on the training set.\n","metadata":{"id":"mJuTcMt-OUE-"}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncv_scores = {key: -cross_val_score(clf, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\") for key, clf in models.items()}\npd.DataFrame(cv_scores)","metadata":{"id":"DR8O9PX0VW_r","outputId":"1e0fd42b-63c2-4158-8d54-e07eca066bc2","execution":{"iopub.status.busy":"2021-07-22T11:32:24.093669Z","iopub.status.idle":"2021-07-22T11:32:24.09413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's also take a look at the means.","metadata":{"id":"qezqC_4wrAgY"}},{"cell_type":"code","source":"cv_scores_means = {key: np.mean(values) for key, values in cv_scores.items()}\ncv_scores_means","metadata":{"id":"PoAcNMBKqaUw","outputId":"36a5a048-a38d-458e-cb53-21e51b4c3793","execution":{"iopub.status.busy":"2021-07-22T11:32:24.095092Z","iopub.status.idle":"2021-07-22T11:32:24.095532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From now on, let's focus on the extra trees and random forest models, since they achieved the lowest MSE.","metadata":{"id":"PJdX1-EVrGVi"}},{"cell_type":"markdown","source":"### Hyperparameter tuning\n\nBelow, we're defining a search space of parameters. \n\nThis is just a prop search space for demonstration purposes.\nIt should definitely be adjusted before actual tuning.","metadata":{"id":"xoo29zKvruJJ"}},{"cell_type":"code","source":"search_space = {\n  \"extra\": {\n      \"n_estimators\": [750],\n      \"min_samples_split\": [2],\n      \"max_features\": [\"auto\"],\n      \"ccp_alpha\": [0]\n  },\n  \"ranger\": {\n      \"n_estimators\": [750],\n      \"min_samples_split\": [2],\n      \"max_features\": [\"auto\"],\n      \"ccp_alpha\": [0]\n  }\n}","metadata":{"id":"38GZfupsrQ_x","execution":{"iopub.status.busy":"2021-07-22T11:32:24.096387Z","iopub.status.idle":"2021-07-22T11:32:24.096829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's use `GridSearchCV` to tune the models.\nNote that we should more likely use `RandomSearchCV` for searching through wider search spaces than what we're dealing with here.","metadata":{"id":"OL0Rgldbuinx"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nrscv = [GridSearchCV(models[name], search_space[name]) for name in [\"extra\", \"ranger\"]]\nsearch = [rs.fit(X_train, y_train) for rs in rscv]","metadata":{"id":"HPENjNUWuiVq","execution":{"iopub.status.busy":"2021-07-22T11:32:24.097737Z","iopub.status.idle":"2021-07-22T11:32:24.098205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This are the scores:","metadata":{"id":"9zOnZrbgoGBg"}},{"cell_type":"code","source":"pd.DataFrame({\"extra\": [search[0].best_score_], \"ranger\": [search[1].best_score_]})","metadata":{"id":"h0a1QaBpvGI-","outputId":"022351e3-ed3f-4c53-cc58-608d420a3fa7","execution":{"iopub.status.busy":"2021-07-22T11:32:24.099228Z","iopub.status.idle":"2021-07-22T11:32:24.099665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use the better model for the final prediction.","metadata":{"id":"lh-VfgnyoNzm"}},{"cell_type":"code","source":"clf_final = search[0].best_estimator_\nclf_final.fit(X_train, y_train)\npreds = clf_final.predict(X_test)\n\nMSE = mean_squared_error(preds, y_test)","metadata":{"id":"KSi-4C-KnA_K","execution":{"iopub.status.busy":"2021-07-22T11:32:24.100578Z","iopub.status.idle":"2021-07-22T11:32:24.100997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MSE","metadata":{"id":"-IlMBSx2nyRM","outputId":"a26cbb0c-efc1-4a8b-a1a1-4fe8a37288bb","execution":{"iopub.status.busy":"2021-07-22T11:32:24.101761Z","iopub.status.idle":"2021-07-22T11:32:24.102194Z"},"trusted":true},"execution_count":null,"outputs":[]}]}