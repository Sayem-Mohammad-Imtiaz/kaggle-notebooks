{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize, RegexpTokenizer \nfrom nltk.stem import WordNetLemmatizer \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '#', printEnd = \"\\r\"):\n    \n    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n    filledLength = int(length * iteration // total)\n    bar = fill * filledLength + '-' * (length - filledLength)\n    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n    # Print New Line on Complete\n    if iteration == total: \n        print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenization(raw_text, tokenizer, stop_words):\n    \"\"\"\n    tokenize raw text DOCO\n    \"\"\"\n    return [token.lower() for token in tokenizer.tokenize(raw_text) if token.lower() not in stop_words]\n\ndef lemmatization(tokens, lemmatizer):\n    \"\"\"\n    lemmatize tokens\n    \"\"\"\n    return [lemmatizer.lemmatize(token) for token in tokens]\n\ndef bag_of_wordization(lemmas):\n    bow = {}\n    for lemma in lemmas:\n        if lemma in bow:\n            bow[lemma] += 1\n        else:\n            bow[lemma] = 1\n    return bow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = RegexpTokenizer(r'[A-Za-z]+')\nstop_words = set(stopwords.words('english')) \nlemmatizer = WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df = pd.read_csv('/kaggle/input/mpst-movie-plot-synopses-with-tags/mpst_full_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df = input_df[input_df.plot_synopsis.str.len() < input_df.plot_synopsis.str.len().quantile(0.9)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df[input_df['title'].str.contains('Paranormal')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bag_of_words_list = []\n\n\ndef cond(i, row, bag_of_words_list):\n    if row['title'] in [title for title, _ in bag_of_words_list]:\n        return False\n    \n    if (i < 400):\n        return True\n    \n    if ('harry' in row['title'].lower()):\n        return True\n    \n    if ('paranormal' in row['title'].lower()):\n        return True\n    \n    if ('ring' in row['title'].lower()):\n        return True \n    \n    if (('war' in row['title'].lower())):\n        return True\n    \n    if ('scary' in row['title'].lower()):\n        return True\n\n    if ('star' in row['title'].lower()):\n        return True\n    \n    return False\n    \nn = input_df.shape[0]\nprint(\"Bag of wording {} movies\".format(n))\nprintProgressBar(0, n, prefix = 'Progress:', suffix = 'Complete', length = 50)\nfor i, row in input_df.iterrows():\n#     printProgressBar(i, n, prefix = 'Progress:', suffix = 'Complete', length = 50)\n    if cond(i, row, bag_of_words_list):\n        raw_text = row['plot_synopsis'] + \" \" + row['tags']\n        title = row['title']\n        tokens = tokenization(raw_text, tokenizer, stop_words)\n        lemmas = lemmatization(tokens, lemmatizer)\n        bag_of_words = bag_of_wordization(lemmas)\n        \n        bag_of_words_list.append((title, bag_of_words))\nprintProgressBar(n, n, prefix = 'Progress:', suffix = 'Complete', length = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame()\n\nn = len(bag_of_words_list)\nprint(\"Loading {} movies\".format(n))\nprintProgressBar(0, n, prefix = 'Progress:', suffix = 'Complete', length = 50)\nfor i, bag_of_words in enumerate(bag_of_words_list):\n    printProgressBar(i, n, prefix = 'Progress:', suffix = 'Complete', length = 50)\n    \n    name, bow = bag_of_words \n    df = df.append(pd.DataFrame(data=bow, index=[name]))\n\ndf = df.fillna(0)    \nprintProgressBar(n, n, prefix = 'Progress:', suffix = 'Complete', length = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfrom sklearn import preprocessing\nfrom sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_embedded = TSNE(perplexity=100, n_iter=5000, learning_rate=30).fit_transform(df)\nX_embedded = dict()\nperplexity_range = [150,200,300]\n\nfor perplexity in perplexity_range:\n    print(perplexity)\n    X_embedded[perplexity] = TSNE(perplexity=20, n_iter=1000).fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_embedded = dict()\n\nfor perplexity in perplexity_range:\n    df_embedded[perplexity] = pd.DataFrame(data=X_embedded[perplexity], index=df.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for perplexity in perplexity_range:\n    \n    df_plot = df_embedded[perplexity].reset_index()\n    df_plot['Sagas'] = \"\"\n    df_plot.loc[df_plot['index'].str.upper().str.contains('HARRY POTTER'), 'Sagas'] = \"Harry Potter\"\n    df_plot.loc[df_plot['index'].str.upper().str.contains('LORD OF THE RING'), 'Sagas'] = \"Lord of The Rings\"\n    df_plot.loc[df_plot['index'].str.upper().str.contains('STAR WARS'), 'Sagas'] = \"Star Wars\"\n    df_plot.loc[df_plot['index'].str.upper().str.contains('SCARY MOVIE'), 'Sagas'] = \"Scary Movie\"\n    df_plot.loc[df_plot['index'].str.upper().str.contains('PARANORMAL ACT'), 'Sagas'] = \"Paranormal Activity\"\n    df_plot.loc[df_plot['index'].str.upper().str.contains('STAR TREK'), 'Sagas'] = \"Star Trek\"\n    \n    \n    fig = px.scatter(df_plot, x=0, y=1, hover_name='index', color='Sagas', title='Perplexity: {}'.format(perplexity))\n    fig.show()\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(input_df.loc[input_df['title']=='The Prestige', 'plot_synopsis'].to_list()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df.loc[input_df['title']==\"The A-Team\", 'plot_synopsis'].to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df.loc[input_df['title'].str.contains(\"Star Trek\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}