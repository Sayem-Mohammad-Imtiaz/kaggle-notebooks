{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#Decision Tree & Random Forest Implementation in python for BigMart\n\nWe will use Decision Tree & Random Forest in Predicting the outlet type for Bigmart dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:32.737831Z","iopub.execute_input":"2021-08-28T17:26:32.738195Z","iopub.status.idle":"2021-08-28T17:26:32.744926Z","shell.execute_reply.started":"2021-08-28T17:26:32.738163Z","shell.execute_reply":"2021-08-28T17:26:32.74393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/bigmart/final_bigmart_imputted.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:32.798952Z","iopub.execute_input":"2021-08-28T17:26:32.799238Z","iopub.status.idle":"2021-08-28T17:26:32.845547Z","shell.execute_reply.started":"2021-08-28T17:26:32.799214Z","shell.execute_reply":"2021-08-28T17:26:32.844799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(df.columns[[4, 5, 6, 7, 10, 11, 12, 13, 14]], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:32.853954Z","iopub.execute_input":"2021-08-28T17:26:32.854222Z","iopub.status.idle":"2021-08-28T17:26:32.86017Z","shell.execute_reply.started":"2021-08-28T17:26:32.854197Z","shell.execute_reply":"2021-08-28T17:26:32.858456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:32.899256Z","iopub.execute_input":"2021-08-28T17:26:32.89951Z","iopub.status.idle":"2021-08-28T17:26:32.920492Z","shell.execute_reply.started":"2021-08-28T17:26:32.899485Z","shell.execute_reply":"2021-08-28T17:26:32.919219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='Outlet_Type', data=df)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:32.984726Z","iopub.execute_input":"2021-08-28T17:26:32.985082Z","iopub.status.idle":"2021-08-28T17:26:33.156396Z","shell.execute_reply.started":"2021-08-28T17:26:32.985043Z","shell.execute_reply":"2021-08-28T17:26:33.155412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_col = []\nfor column in df.columns:\n    if df[column].dtype == object and len(df[column].unique()) <= 50:\n        categorical_col.append(column)\n        \ndf['Outlet_Type'] = df.Outlet_Type.astype(\"category\").cat.codes","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:33.158097Z","iopub.execute_input":"2021-08-28T17:26:33.158463Z","iopub.status.idle":"2021-08-28T17:26:33.168611Z","shell.execute_reply.started":"2021-08-28T17:26:33.158421Z","shell.execute_reply":"2021-08-28T17:26:33.16785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"categorical_col.remove('Outlet_Type')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:33.170736Z","iopub.execute_input":"2021-08-28T17:26:33.171135Z","iopub.status.idle":"2021-08-28T17:26:33.175691Z","shell.execute_reply.started":"2021-08-28T17:26:33.171096Z","shell.execute_reply":"2021-08-28T17:26:33.174749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Transform categorical data into dummies\n# categorical_col.remove(\"Attrition\")\n# data = pd.get_dummies(df, columns=categorical_col)\n# data.info()\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel = LabelEncoder()\nfor column in categorical_col:\n    df[column] = label.fit_transform(df[column])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-28T17:26:33.177387Z","iopub.execute_input":"2021-08-28T17:26:33.177886Z","iopub.status.idle":"2021-08-28T17:26:33.187691Z","shell.execute_reply.started":"2021-08-28T17:26:33.177848Z","shell.execute_reply":"2021-08-28T17:26:33.186914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Outlet_Type', axis=1)\ny = df.Outlet_Type\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:33.188791Z","iopub.execute_input":"2021-08-28T17:26:33.189214Z","iopub.status.idle":"2021-08-28T17:26:33.202013Z","shell.execute_reply.started":"2021-08-28T17:26:33.189175Z","shell.execute_reply":"2021-08-28T17:26:33.201061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying Tree & Random Forest algorithms","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:33.229444Z","iopub.execute_input":"2021-08-28T17:26:33.229744Z","iopub.status.idle":"2021-08-28T17:26:33.237813Z","shell.execute_reply.started":"2021-08-28T17:26:33.229714Z","shell.execute_reply":"2021-08-28T17:26:33.236455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Decision Tree Classifier\n\n**Decision Tree parameters:**\n- `criterion`: The function to measure the quality of a split. Supported criteria are \"`gini`\" for the Gini impurity and \"`entropy`\" for the information gain.\n***\n- `splitter`: The strategy used to choose the split at each node. Supported strategies are \"`best`\" to choose the best split and \"`random`\" to choose the best random split.\n***\n- `max_depth`: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than `min_samples_split` samples.\n***\n- `min_samples_split`: The minimum number of samples required to split an internal node.\n***\n- `min_samples_leaf`: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least ``min_samples_leaf`` training samples in each of the left and right branches.  This may have the effect of smoothing the model, especially in regression.\n***\n- `min_weight_fraction_leaf`: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n***\n- `max_features`: The number of features to consider when looking for the best split.\n***\n- `max_leaf_nodes`: Grow a tree with ``max_leaf_nodes`` in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.\n***\n- `min_impurity_decrease`: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n***\n- `min_impurity_split`: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree_clf = DecisionTreeClassifier(random_state=42)\ntree_clf.fit(X_train, y_train)\n\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:33.33461Z","iopub.execute_input":"2021-08-28T17:26:33.334945Z","iopub.status.idle":"2021-08-28T17:26:33.434754Z","shell.execute_reply.started":"2021-08-28T17:26:33.334914Z","shell.execute_reply":"2021-08-28T17:26:33.433567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Decision Tree Classifier Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {\n    \"criterion\":(\"gini\", \"entropy\"), \n    \"splitter\":(\"best\", \"random\"), \n    \"max_depth\":(list(range(1, 20))), \n    \"min_samples_split\":[2, 3, 4], \n    \"min_samples_leaf\":list(range(1, 20)), \n}\n\n\ntree_clf = DecisionTreeClassifier(random_state=42)\ntree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3)\ntree_cv.fit(X_train, y_train)\nbest_params = tree_cv.best_params_\nprint(f\"Best paramters: {best_params})\")\n\ntree_clf = DecisionTreeClassifier(**best_params)\ntree_clf.fit(X_train, y_train)\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(tree_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:26:33.436605Z","iopub.execute_input":"2021-08-28T17:26:33.437024Z","iopub.status.idle":"2021-08-28T17:29:07.556615Z","shell.execute_reply.started":"2021-08-28T17:26:33.436981Z","shell.execute_reply":"2021-08-28T17:29:07.555832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization of a tree","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nfrom six import StringIO\nfrom sklearn.tree import export_graphviz\nimport pydot\n\nfeatures = list(df.columns)\nfeatures.remove(\"Outlet_Type\")","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:29:07.558212Z","iopub.execute_input":"2021-08-28T17:29:07.558571Z","iopub.status.idle":"2021-08-28T17:29:07.562973Z","shell.execute_reply.started":"2021-08-28T17:29:07.558531Z","shell.execute_reply":"2021-08-28T17:29:07.562156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dot_data = StringIO()\nexport_graphviz(tree_clf, out_file=dot_data, feature_names=features, filled=True)\ngraph = pydot.graph_from_dot_data(dot_data.getvalue())\nImage(graph[0].create_png())","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:30:27.513182Z","iopub.execute_input":"2021-08-28T17:30:27.513518Z","iopub.status.idle":"2021-08-28T17:30:31.315027Z","shell.execute_reply.started":"2021-08-28T17:30:27.513487Z","shell.execute_reply":"2021-08-28T17:30:31.314101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(n_estimators=100)\nrf_clf.fit(X_train, y_train)\n\nprint_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\nprint_score(rf_clf, X_train, y_train, X_test, y_test, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T17:29:10.639497Z","iopub.execute_input":"2021-08-28T17:29:10.639884Z","iopub.status.idle":"2021-08-28T17:29:12.317767Z","shell.execute_reply.started":"2021-08-28T17:29:10.639833Z","shell.execute_reply":"2021-08-28T17:29:12.316982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}