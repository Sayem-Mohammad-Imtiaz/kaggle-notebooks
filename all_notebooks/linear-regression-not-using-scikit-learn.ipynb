{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25037979-37b6-2b69-c4de-0347cd6a0c8e"},"outputs":[],"source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n# Loading the data:\nhouse = pd.read_csv(\"../input/hou_all.csv\", header=None, sep=',')\nhouse.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV','BIAS_COL']\n# Pair-wise scatter-plot of all the attributes:\nsns.set(style='whitegrid', context='notebook')\ncols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV','BIAS_COL']\nsns.pairplot(house[cols].dropna())\nplt.show()\nprint(\"I had to make it smaller in here!\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc501fa2-18dd-b415-96b4-570d7deddad6"},"outputs":[],"source":"# Making a heatmap of all pair-wise correlation coefficients:\ncols2 = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ncorr_matrix = np.corrcoef(house[cols2].values.T)\nsns.set(font_scale=0.8)\nheatmap = sns.heatmap(corr_matrix, cbar=True, annot=True, square=True, fmt='.2f',\n\tannot_kws={'size':15}, yticklabels=cols2, xticklabels=cols2)\nfig = plt.gcf()\nfig.set_size_inches(12, 12)\nfig.savefig('test2png.png', dpi=100)\nfig.set_size_inches(12, 12, forward=True)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11acb021-18d2-2a35-5a4f-ff464d9ce046"},"outputs":[],"source":"'''\nFrom the pair-wise scatter-plots we see that there's a linear relationship between RM and MEDV.\nFrom the heat-map we see that RM and MEDV are fairly correlated as well.\nSo we choose RM to be trained.\n'''\ncols_x = ['RM', 'BIAS_COL']\nN = 506\nX = np.array(house[cols_x], dtype='float')\nY = np.array(house['MEDV'], dtype='float')\n# Make a function to fit:\ndef fit(X,Y):\n\treturn np.linalg.solve(X.T.dot(X),X.T.dot(Y))\n# Make a function to get the R^2:\ndef get_r2(actual,hat):\n\td1 = actual-hat\n\td2 = actual-actual.mean()\n\tr2 = 1 - d1.dot(d1)/d2.dot(d2)\n\treturn r2\n# Making the training set:\ntrain_indexes = np.random.choice(N, 350)\nXtrain = X[train_indexes]\nYtrain = Y[train_indexes]\n# Making the test set:\ntest_indexes = [index for index in range(N) if index not in train_indexes]\nXtest = X[test_indexes]\nYtest = Y[test_indexes]\n# Fitting the training set:\nw = fit(Xtrain,Ytrain)\nYtrain_hat = Xtrain.dot(w)\ntrain_r2 = get_r2(Ytrain,Ytrain_hat)\n# Fitting the test set:\nYtest_hat = Xtest.dot(w)\ntest_r2 = get_r2(Ytest,Ytest_hat)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b677023-d497-cd15-d28a-14a8ff68c066"},"outputs":[],"source":"# Displaying the training and test sets with their accuracies:\nplt.scatter(Ytrain_hat,Ytrain_hat-Ytrain,label='Training data')\nplt.scatter(Ytest_hat,Ytest_hat-Ytest,color='lightgreen',label='Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Residuals')\nplt.legend(loc='upper left')\nplt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')\nplt.show()\nprint(\"R sqaured of the training set is: \",train_r2)\nprint (\"R sqaured of the test set is: \",test_r2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"afcd2ffd-909c-e11c-41f3-aede8a44212c"},"outputs":[],"source":"# Doing an ordinary linear regression:\nX_O = np.array(house['RM'], dtype='float')\ndenominator = X_O.dot(X_O) - X_O.mean() * X_O.sum()\na = ( X_O.dot(Y) - Y.mean()*X_O.sum() ) / denominator\nb = ( Y.mean() * X_O.dot(X_O) - X_O.mean() * X_O.dot(Y) ) / denominator\nYhat = a*X_O + b\nr2 = get_r2(X_O,Y)\nplt.scatter(X_O, Y)\nplt.plot(X_O, Yhat,color='r')\nplt.show()\n# Estimating the coefficients of the regression model:\nprint(\"Slope: \",a)\nprint(\"Intercept: \",b)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a14ec32-3137-8557-96d1-e62004bfeec7"},"outputs":[],"source":"# Now using all the variables to improve the prediction accuracy:\ncols_x_all = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT','BIAS_COL']\nN = 506\nX_all = np.array(house[cols_x_all], dtype='float')\nY = np.array(house['MEDV'], dtype='float')\n# Making the training set:\ntrain_indexes = np.random.choice(N, 350)\nXtrain = X_all[train_indexes]\nYtrain = Y[train_indexes]\n# Making the test set:\ntest_indexes = [index for index in range(N) if index not in train_indexes]\nXtest = X_all[test_indexes]\nYtest = Y[test_indexes]\n# Fitting the training set:\nw = fit(Xtrain,Ytrain)\nYtrain_hat = Xtrain.dot(w)\ntrain_r2 = get_r2(Ytrain,Ytrain_hat)\n# Fitting the test set:\nYtest_hat = Xtest.dot(w)\ntest_r2 = get_r2(Ytest,Ytest_hat)\n# Displaying the training and test sets with their accuracies:\nplt.scatter(Ytrain_hat,Ytrain_hat-Ytrain,label='Training data')\nplt.scatter(Ytest_hat,Ytest_hat-Ytest,color='lightgreen',label='Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Residuals')\nplt.legend(loc='upper left')\nplt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')\nplt.show()\nprint(\"R sqaured of the training set is: \",train_r2)\nprint(\"R sqaured of the test set is: \",test_r2)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}