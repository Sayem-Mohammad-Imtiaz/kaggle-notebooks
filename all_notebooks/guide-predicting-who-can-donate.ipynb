{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Donors Prediction\n\n**In this notebook we are going to predict that weather a person is going to donate or not. \n\n**The dataset is a list of new contacts a client is interested in reaching out to in the next campaign they intend to carry out soon.**\n\n**So it's a classification problem.**\n\n**Let's begin**\n\n**Firstly we'll take a look of our dataset.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/donorsprediction/Raw_Data_for_train_test.csv')\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OK so TARGET_B is out target variable and others are my feature variables.**\n\n**Let's See weather our dataset is having null value or not. And if it's having some null values we have to clean our dataset.**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns[df.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To handle these NAN values we'll replace these values with the median.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill numeric rows with the median\nfor label, content in df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Fill missing numeric values with median since it's more robust than the mean\n            df[label] = content.fillna(content.median())\n            \ndf.columns[df.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So now our data have no missing values.**\n\n**Let's now check how many columns are categorical. If there are categorical columns we'll turn them to numerical columns.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn categorical variables into numbers\nfor label, content in df.items():\n    # Check columns which aren't numeric\n    if not pd.api.types.is_numeric_dtype(content):\n        # print the columns that are objectt type \n        print(label)\n        df[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hence our data is cleaned. We have replaced all null values as well as there's no categorical data now.\nLet's take a look of our cleaned dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There's no need of Target_D column. As we are taking TARGET_B as our target variable. So we can drop this **\n ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('TARGET_D', axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Great!!  Now our data needs just one thing more to be ready for modelling.**\n\n**We have to change data values all into one range by using **Standardization** so that our model can easily predict.**\n\n**For this we have to do following steps.**\n\n* Split data into x (input features) & y(target variable)\n* Then use Standard Scaler to to change data values of 'x' into one range.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# input features\nx = df.drop('TARGET_B', axis=1)\n\n# Target variable\ny = df['TARGET_B']\n\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import standard scaler\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\n# apply scaler\nx = ss.fit_transform(x)\n\nx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Yehh! our data is ready for modelling and then predicting wheather a persor will donate or not. ðŸ˜€**\n\n## Modelling\n\n**We'll use following models and then evaluate them to find which model works well:**\n\n* KNN\n* Random Forest\n* XGBoost Classifier\n\n### KNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n# define and configure the model\nmodel = KNeighborsClassifier()\n\n# fit the model\nmodel.fit(xtrain, ytrain)\n\n# evaluate the model\npreds = model.predict(xtest)\naccuracy_score(ytest, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# define and configure the model\nmodel = RandomForestClassifier()\n\n# fit the model\nmodel.fit(xtrain, ytrain)\n\n# evaluate the model\npreds = model.predict(xtest)\naccuracy_score(ytest, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoostClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# define and configure the model\nmodel = XGBClassifier()\n\n# fit the model\nmodel.fit(xtrain, ytrain)\n\n# evaluate the model\npreds = model.predict(xtest)\naccuracy_score(ytest, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**We can see Random forest perfomed best. So let's perform hyperperameter tuning for Random forest**","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# different randomforestregressor hyperperameters\nrf_grid = {'n_estimators' : np.arange(10, 100, 10),\n           'max_depth': [None, 3, 5, 10],\n           'min_samples_split' : np.arange(2, 20, 2),\n           'min_samples_leaf': np.arange(1, 20, 2),\n            'max_features' : [0.5, 1, 'sqrt', 'auto']}\n\n# instentiate randomizedsearchcv model\nrs_model= RandomizedSearchCV(RandomForestClassifier(n_jobs = -1, \n                                                  random_state=42),\n                                                  param_distributions = rf_grid,\n                                                  n_iter = 90,\n                                                  cv=5,\n                                                  verbose=True)\n\nrs_model.fit(xtrain, ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We got the best parameters for our model. Now Let's create an ideal model that have these as it's parameters.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ideal_model = RandomForestClassifier(n_estimators= 70,\n                                     min_samples_split = 8,\n                                     min_samples_leaf = 1,\n                                     max_features = 'auto',\n                                     max_depth = 10)\n\n# fit the model\nideal_model.fit(xtrain, ytrain)\n\n# evaluate the model\npreds = ideal_model.predict(xtest)\naccuracy_score(ytest, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So it's an ideal model for our dataset. Now Let's plot a ROC curve to visulaize the performence of our model.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\n# calculate the fpr and tpr for all thresholds of the classification\nprobs = ideal_model.predict_proba(xtest)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(ytest, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now since we have a good model to predict. Let's Predict wheather a person donates or not for our Test data**\n\n**Let's first import the data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/donorsprediction/Predict_donor.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So here also we can see the NAN values that we have to fix and then we'll convert Categorical features into numerical ones.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill numeric rows with the median\nfor label, content in test_df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Fill missing numeric values with median since it's more robust than the mean\n            test_df[label] = content.fillna(content.median())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn categorical variables into numbers\nfor label, content in test_df.items():\n    # Check columns which aren't numeric\n    if not pd.api.types.is_numeric_dtype(content):\n        # print the columns that are object type \n        print(label)\n        test_df[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now our dataset is cleaned. We can easily predict the Target variable for our dataset.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Target = ideal_model.predict(test_df)\nTarget","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PREDICTED_df = pd.DataFrame()\nPREDICTED_df['TARGET_B'] = Target\nPREDICTED_df['CONTROL_NUMBER'] = test_df['CONTROL_NUMBER']\nPREDICTED_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hence we have sucessfully predict weather a person will donate or not.**\n\n**PLEASE UPVOTE MY NOTEBOOK IF IT HELPED YOU ðŸ˜ŠðŸ˜Š**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}