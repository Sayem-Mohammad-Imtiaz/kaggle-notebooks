{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas\nfrom sklearn.model_selection import train_test_split\nimport numpy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Tweet= pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\nTweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\n# 数据清洗\n\ndef tweet_to_words(raw_tweet):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",raw_tweet) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) \n\ndef clean_tweet_length(raw_tweet):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",raw_tweet) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return(len(meaningful_words)) \n# 将标签转换成数字\nTweet['sentiment']=Tweet['airline_sentiment'].apply(lambda x: 0 if x=='negative' else (1 if x == 'neutral' else (2 if x == 'positive' else 0) ) )\nTweet.fillna('-1', inplace=True)\n\nTweet['clean_tweet'] = Tweet[['negativereason', 'name', 'text']].apply(lambda x: ' '.join(x), axis=1)\nTweet['clean_tweet']=Tweet['clean_tweet'].apply(lambda x: tweet_to_words(x))\nTweet['Tweet_length']=Tweet['text'].apply(lambda x: clean_tweet_length(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train,test = train_test_split(Tweet,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 转换成list，方便特征提取\ntrain_clean_tweet=[]\nfor tweet in train['clean_tweet']:\n    train_clean_tweet.append(tweet)\ntest_clean_tweet=[]\nfor tweet in test['clean_tweet']:\n    test_clean_tweet.append(tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nv = CountVectorizer(analyzer = \"word\")\ntrain_features= v.fit_transform(train_clean_tweet)\ntest_features=v.transform(test_clean_tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classifiers = [\n    LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200),\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    XGBClassifier(),\n    MLPClassifier(solver='sgd', alpha=1e-5,\n       hidden_layer_sizes=(5, 2), random_state=1, max_iter=500),\n    GradientBoostingClassifier(random_state=0)\n    \n]#gpu不能一次性加载这么多模型兵训练","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,train['sentiment'])\n        pred = fit.predict(test_features)\n    except Exception:\n        fit = classifier.fit(dense_features,train['sentiment'])\n        pred = fit.predict(dense_test)\n    predictions = [round(value) for value in pred]\n    accuracy = accuracy_score(test['sentiment'],predictions)\n    print(classification_report(test.sentiment,  predictions, labels=[0,1,2]))\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+ ' is: '+str(accuracy))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}