{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb440800-bf0c-4c82-b297-2ef63e789f4d"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9ecb8b9-22bd-f050-ac9d-f3eb6c10c8d7"},"outputs":[],"source":"import nltk\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize, ngrams\nfrom sklearn import ensemble\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nimport xgboost as xgb\n\neng_stopwords = set(stopwords.words('english'))\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  # default='warn'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20b287f9-1fe9-80ef-a58f-5780b4b11268"},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2034e1eb-1ec9-4eb0-17dd-9d42c3d6380c"},"outputs":[],"source":"train_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"280a6d05-50be-3ced-6657-c7d467306564"},"outputs":[],"source":"train_df.rename(columns ={'description_x':'question1','description_y':'question2','same_security':'is_similar'},inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50e87ad5-a6fa-aa5a-88c4-5657a9a9b83e"},"outputs":[],"source":"train_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cc3987f-d58e-29b5-4e16-c1a2c97302bb"},"outputs":[],"source":"test_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e3d93cf-5f04-1532-f437-7a9c80f62145"},"outputs":[],"source":"test_df.rename(columns={'description_x':'question1','description_y':'question2','same_security':'is_similar'},inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4042b59a-c4d5-d69c-c90b-73491eabc475"},"outputs":[],"source":"test_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecdaa6af-5957-f9bb-2c03-acae21f1e18d"},"outputs":[],"source":"##  Target Exploration\nis_sim = train_df['is_similar'].value_counts()\n\nplt.figure(figsize=(8,4))\nsns.barplot(is_sim.index, is_sim.values, alpha=0.8, color=color[1])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Is Similar', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ebbc5dd-2d90-6b72-0a0c-d962b12b1218"},"outputs":[],"source":"is_sim/is_sim.sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2fc2e6f-4d6b-19fe-4d7c-1a7055ba57f7"},"outputs":[],"source":"all_ques_df = pd.DataFrame(pd.concat([train_df['question1'], train_df['question2']]))\nall_ques_df.columns =[\"questions\"]\n\nall_ques_df[\"num_of_words\"] = all_ques_df[\"questions\"].apply(lambda x: len(str(x).split()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18777c10-a3a7-421e-94b2-883fa2b550c9"},"outputs":[],"source":"count_str = all_ques_df[\"num_of_words\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(count_str.index, count_str.values, alpha=0.8, color=color[0])\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Number of words in the question', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8dc862e5-548f-e3ac-1137-5112a68720eb"},"outputs":[],"source":"\nall_ques_df[\"num_of_chars\"] = all_ques_df[\"questions\"].apply(lambda x: len(str(x)))\ncount_str = all_ques_df[\"num_of_chars\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(count_str.index, count_str.values, alpha=0.8, color=color[3])\nplt.ylabel('Number of Occurrences', fontsize=20)\nplt.xlabel('Number of characters in the question', fontsize=20)\nplt.xticks(rotation='vertical')\nplt.show()      \n\n# del all_ques_df     "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17458475-5c69-97a2-8d5b-5681be133550"},"outputs":[],"source":"def get_unigrams(que):\n    return [word for word in word_tokenize(que.lower()) if word not in eng_stopwords]\n\n## Finding the intersection between two series in pandas and return len.\ndef get_common_unigrams(row):\n    return len( set(row[\"unigrams_ques1\"]).intersection(set(row[\"unigrams_ques2\"])) ) \n\ndef get_common_unigram_ratio(row):\n    return float(row[\"unigrams_common_count\"]) / max(len( set(row[\"unigrams_ques1\"]).union(set(row[\"unigrams_ques2\"])) ),1)\n\ntrain_df[\"unigrams_ques1\"] = train_df['question1'].apply(lambda x: get_unigrams(str(x)))\ntrain_df[\"unigrams_ques2\"] = train_df['question2'].apply(lambda x: get_unigrams(str(x)))\ntrain_df[\"unigrams_common_count\"] = train_df.apply(lambda row: get_common_unigrams(row), axis=1)\ntrain_df[\"unigrams_common_ratio\"] = train_df.apply(lambda row: get_common_unigram_ratio(row),axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e37628fd-3a8a-ded4-ebee-5a93872e9b81"},"outputs":[],"source":"count_str = train_df[\"unigrams_common_count\"].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(count_str.index, count_str.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Common unigrams count', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0309e0f-18d6-5d2e-7e0c-f1b191a1fd6f"},"outputs":[],"source":"plt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_similar\", y=\"unigrams_common_count\", data=train_df)\nplt.xlabel('Is similar', fontsize=12)\nplt.ylabel('Common unigrams count', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35bb0ba6-3159-d8bd-ccaa-91b58aff5785"},"outputs":[],"source":"plt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_similar\", y=\"unigrams_common_ratio\", data=train_df)\nplt.xlabel('Is similar', fontsize=12)\nplt.ylabel('Common unigrams ratio', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e6ba174f-4dd0-1e62-ddad-7fdc761088f4"},"outputs":[],"source":"def get_bigrams(que):\n    return [ i for i in ngrams(que,2)]\n\ndef get_common_bigrams(row):\n    return len( set(row['bigrams_ques1']).intersection(set(row['bigrams_ques2'])) )\n\ndef get_common_bigram_ratio(row):\n    return float(row[\"bigrams_common_count\"]) / max(len( set(row[\"bigrams_ques1\"]).union(set(row[\"bigrams_ques2\"])) ),1)\n\ntrain_df[\"bigrams_ques1\"] = train_df[\"unigrams_ques1\"].apply(lambda x: get_bigrams(x))\ntrain_df[\"bigrams_ques2\"] = train_df[\"unigrams_ques2\"].apply(lambda x: get_bigrams(x))\ntrain_df[\"bigrams_common_count\"] = train_df.apply(lambda row: get_common_bigrams(row), axis=1)\ntrain_df[\"bigrams_common_ratio\"] = train_df.apply(lambda row: get_common_bigram_ratio(row), axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93d16760-06c1-c809-90c2-e1f2893b8626"},"outputs":[],"source":"count_str = train_df['bigrams_common_count'].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(count_str.index, count_str.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Common bigrams count', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa22a934-dd8c-6e73-f562-593d94e45083"},"outputs":[],"source":"count_str = train_df['bigrams_common_ratio'].value_counts()\n\nplt.figure(figsize=(12,6))\nsns.barplot(count_str.index, count_str.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=10)\nplt.xlabel('Common bigrams ratio', fontsize=10)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce256983-fafd-22eb-a706-b57abd7a6ce5"},"outputs":[],"source":"\nplt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_similar\", y=\"bigrams_common_count\", data=train_df)\nplt.xlabel('Is similar', fontsize=12)\nplt.ylabel('Common bigrams count', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3b730f1a-a113-482f-8c4b-4fa6a3006e40"},"outputs":[],"source":"plt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_similar\", y=\"bigrams_common_ratio\", data=train_df)\nplt.xlabel('Is similar', fontsize=12)\nplt.ylabel('Common bigrams ratio', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbd80d01-052d-5d33-0012-3613684788fd"},"outputs":[],"source":"def feature_extraction(row):\n    que1 = str(row['question1'])\n    que2 = str(row['question2'])\n    out_list = []\n    # get unigram features #\n    unigrams_que1 = [word for word in que1.lower().split() if word not in eng_stopwords]\n    unigrams_que2 = [word for word in que2.lower().split() if word not in eng_stopwords]\n    common_unigrams_len = len(set(unigrams_que1).intersection(set(unigrams_que2)))\n    common_unigrams_ratio = float(common_unigrams_len) / max(len(set(unigrams_que1).union(set(unigrams_que2))),1)\n    out_list.extend([common_unigrams_len, common_unigrams_ratio])\n    \n    # get bigram features #\n    bigrams_que1 = [i for i in ngrams(unigrams_que1, 2)]\n    bigrams_que2 = [i for i in ngrams(unigrams_que2, 2)]\n    common_bigrams_len = len(set(bigrams_que1).intersection(set(bigrams_que2)))\n    common_bigrams_ratio = float(common_bigrams_len) / max(len(set(bigrams_que1).union(set(bigrams_que2))),1)\n    out_list.extend([common_bigrams_len, common_bigrams_ratio])\n    \n    # get trigram features #\n    trigrams_que1 = [i for i in ngrams(unigrams_que1, 3)]\n    trigrams_que2 = [i for i in ngrams(unigrams_que2, 3)]\n    common_trigrams_len = len(set(trigrams_que1).intersection(set(trigrams_que2)))\n    common_trigrams_ratio = float(common_trigrams_len) / max(len(set(trigrams_que1).union(set(trigrams_que2))),1)\n    out_list.extend([common_trigrams_len, common_trigrams_ratio])\n    return out_list"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f68761b-9707-0b35-fb9c-8022c3a77192"},"outputs":[],"source":"def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0):\n        params = {}\n        params[\"objective\"] = \"binary:logistic\"\n        params['eval_metric'] = 'logloss'\n        params[\"eta\"] = 0.02\n        params[\"subsample\"] = 0.7\n        params[\"min_child_weight\"] = 1\n        params[\"colsample_bytree\"] = 0.7\n        params[\"max_depth\"] = 4\n        params[\"silent\"] = 1\n        params[\"seed\"] = seed_val\n        num_rounds = 300 \n        plst = list(params.items())\n        xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n        if test_y is not None:\n                xgtest = xgb.DMatrix(test_X, label=test_y)\n                watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n                model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=100, verbose_eval=10)\n        else:\n                xgtest = xgb.DMatrix(test_X)\n                model = xgb.train(plst, xgtrain, num_rounds)\n                \n        pred_test_y = model.predict(xgtest)\n\n        loss = 1\n        if test_y is not None:\n                loss = log_loss(test_y, pred_test_y)\n                return pred_test_y, loss, model\n        else:\n            return pred_test_y, loss, modelv"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4879f4d4-0880-0a57-da58-4eaadcf19eae"},"outputs":[],"source":"train_X = np.vstack( np.array(train_df.apply(lambda row: feature_extraction(row), axis=1)) ) \ntest_X = np.vstack( np.array(test_df.apply(lambda row: feature_extraction(row), axis=1)) )\ntrain_y = np.array(train_df[\"is_similar\"])\ntest_id = np.array(test_df[\"test_id\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f0ac4ad-5e55-d2bf-a69f-03eef671ddcf"},"outputs":[],"source":"train_X_similar = train_X[train_y==1]\ntrain_X_non_similar = train_X[train_y==0]\n\ntrain_X = np.vstack([train_X_non_similar, train_X_similar, train_X_non_similar, train_X_non_similar])\ntrain_y = np.array([0]*train_X_non_similar.shape[0] + [1]*train_X_similar.shape[0] + [0]*train_X_non_similar.shape[0] + [0]*train_X_non_similar.shape[0])\ndel train_X_similar\ndel train_X_non_similar\nprint(\"Mean target rate : \",train_y.mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbabdf17-0476-1f64-0f64-3d0124c66500"},"outputs":[],"source":"kf = KFold(n_splits=20, shuffle=True, random_state=2016)\nfor dev_index, val_index in kf.split(range(train_X.shape[0])):\n    dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    preds, lloss, model = runXGB(dev_X, dev_y, val_X, val_y)\n    break"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ef3975d-12a0-fcde-c6ad-20db8427f6a8"},"outputs":[],"source":"xgtest = xgb.DMatrix(test_X)\npreds = model.predict(xgtest)\n\nout_df = pd.DataFrame({\"test_id\":test_id, \"is_similar\":preds})\nout_df.to_csv(\"issimilar_predicted.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f260e7b-903e-e916-513a-509b379e1480"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}