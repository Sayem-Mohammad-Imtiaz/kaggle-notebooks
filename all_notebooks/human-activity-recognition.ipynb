{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Human Activity Recognition\n\nThis project is to build a model that predicts the human activities such as Walking, Walking_Upstairs, Walking_Downstairs, Sitting, Standing or Laying.\n\nThis dataset is collected from 30 persons(referred as subjects in this dataset), performing different activities with a smartphone to their waists. The data is recorded with the help of sensors (accelerometer and Gyroscope) in that smartphone. This experiment was video recorded to label the data manually."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import LSTM ,Dense, Dropout\nfrom keras.optimizers import SGD, Adam\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_path = \"../input/human-activity-recognition/uci_har_dataset/UCI_HAR_Dataset/train/\"\ntest_path = \"../input/human-activity-recognition/uci_har_dataset/UCI_HAR_Dataset/test/\"\nfeatures_path = \"../input/human-activity-recognition/uci_har_dataset/UCI_HAR_Dataset/features.txt\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features \n\nWe need to extract features names from file `features.txt`"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = []\nwith open(features_path) as f:\n    features = [line.split()[1] for line in f.readlines()]\nprint('No of Features: {}'.format(len(features)))\nprint(\"No. of unique features:{}\".format(len(set(features))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows that there are duplicate feature names"},{"metadata":{"trusted":true},"cell_type":"code","source":"#LABELS\nlabels = {1: 'WALKING', \n          2:'WALKING_UPSTAIRS',\n          3:'WALKING_DOWNSTAIRS',\n          4:'SITTING',\n          5:'STANDING',\n          6:'LAYING'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The names of features need to be processed. We need to replace `() , \"-\"` from their names."},{"metadata":{"trusted":true},"cell_type":"code","source":"re=[]\nfor i , f in enumerate(features):\n    for j in range(i+1 , len(features)):\n        if features[i]==features[j] and features[i] not in re:\n            re.append(features[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i , f in enumerate(features):\n    features[i] = ''.join(e for e in f if e not in ['(',')' , '-' , ',']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **[NOTE]**\npandas doesnt handle duplicate column names so its better you defined `header=NONE` and later set `DataframeName.columns=[columnNames]`"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(train_path + \"X_train.txt\" , delim_whitespace=True ,header=None)\ntrain.columns = features\ntrain['subject'] = pd.read_csv(train_path + 'subject_train.txt' , header=None , squeeze=True)\ntest = pd.read_csv(test_path + \"X_test.txt\" , delim_whitespace=True ,header=None)\ntest.columns = features\ntest['subject'] = pd.read_csv(test_path + 'subject_test.txt' , header=None , squeeze=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = pd.read_csv(train_path + 'y_train.txt' , names=['Activity'] , squeeze=True)\ny_test = pd.read_csv(test_path + 'y_test.txt' , names=['Activity'] , squeeze=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Activity']= y_train\ntest['Activity'] = y_test\ntrain['ActivityName'] = y_train.map(labels)\ntest['ActivityName']  = y_test.map(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis\n\n1. Check for missing Values\n2. Duplicate Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of missing values in Training Data:\" , train.isnull().values.sum())\nprint(\"The number of missing values in Testing Data:\" , test.isnull().values.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of duplicate values in Training Data:\" , train.duplicated().sum())\nprint(\"The number of duplicate values in Testing Data:\" , test.duplicated().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Data Imbalance"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title('Subject Wise Data Distribution')\nsns.countplot(x='subject' , data=train )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\nplt.title('Activity based Subject Distribution')\nsns.countplot(x='subject' , hue='ActivityName', data=train )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**[Remember]** \nAcceleration is not so important in activities like Standing, Sitting, Laying"},{"metadata":{"trusted":true},"cell_type":"code","source":"accFeat=[]\nfor feat in features:\n    if feat.find('BodyAcc') != -1 and feat.find('Magmean') !=-1 and feat.find('Freq')==-1:\n        accFeat.append(feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotFacetGrid(feature, height):\n    \n    plt.figure(figsize=(10,10))\n    facetgrid=sns.FacetGrid(train , hue='ActivityName',height=height,aspect=3)\n    facetgrid.map(sns.distplot ,feature, hist=False).add_legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in accFeat:\n    plotFacetGrid(f,3) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**[Observation]**\nYou can separate low accelaration activity from high accelaration activities easily from the plot. Box plot will give you better intuitions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxplot(feature , ylabel):\n    \n    plt.figure(figsize=(5,5))\n    sns.boxplot(x='ActivityName', y=feature, data=train , showfliers=False )\n    plt.ylabel(ylabel)\n    plt.axhline(y=-0.8, xmin=0.1, xmax=0.9,dashes=(5,5), c='g') #line separating both type of activities\n    plt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in accFeat:\n    boxplot(f , f[5:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dimentionality Reduction using T-SNE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotTsne(X,y,perplexity):\n    \n    #performing dim reduction\n    X_reduce = TSNE(verbose=2, perplexity=perplexity).fit_transform(X)\n    \n    print('Creating plot for this t-sne visualization..')\n    data={'x':X_reduce[:,0],\n          'y':X_reduce[:,1],\n         'label':y}\n    #preparing dataframe from reduced data\n    df = pd.DataFrame(data)\n    \n    #draw the plot\n    sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, height=8,\\\n                   palette=\"Set1\",markers=['^','v','s','o', '1','2'])\n    \n    plt.title(\"perplexity : {}\".format(perplexity))\n    img_name = 'TSNE_perp_{}.png'.format(perplexity)\n    print('saving this plot as image in present working directory...')\n    plt.savefig(img_name)\n    plt.show()\n    print('Done')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= train.drop(['ActivityName'],axis=1)\ny= train['ActivityName']\nperplexity=[2,5,10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for p in perplexity:\n    plotTsne(X,y,perplexity=p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**[OBSERVATION]** \nWe can see that all the activities are well separated. But only Sitting and Standing are non separable."},{"metadata":{},"cell_type":"markdown","source":"# LSTM MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Activities are the class labels\n# It is a 6 class classification\nACTIVITIES = {\n    0: 'WALKING',\n    1: 'WALKING_UPSTAIRS',\n    2: 'WALKING_DOWNSTAIRS',\n    3: 'SITTING',\n    4: 'STANDING',\n    5: 'LAYING',\n}\n\n\"-----------------------RAW DATA--------------------------------------\"\n\n# Raw data signals\n# Signals are from Accelerometer and Gyroscope\n# The signals are in x,y,z directions\n# Sensor signals are filtered to have only body acceleration\n# excluding the acceleration due to gravity\n# Triaxial acceleration from the accelerometer is total acceleration\nSIGNALS = [\n    \"body_acc_x\",\n    \"body_acc_y\",\n    \"body_acc_z\",\n    \"body_gyro_x\",\n    \"body_gyro_y\",\n    \"body_gyro_z\",\n    \"total_acc_x\",\n    \"total_acc_y\",\n    \"total_acc_z\"\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path= \"../input/human-activity-recognition/uci_har_dataset/UCI_HAR_Dataset/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utility function to read the data from csv file\ndef _read_csv(filename):\n    return pd.read_csv(filename, delim_whitespace=True, header=None)\n\n\"----------------------------LOAD SIGNAL---------------------------------------------\"\n\n# Utility function to load the load\ndef load_signals(subset):\n    signals_data = []\n\n    for signal in SIGNALS:\n        filename = path+subset+'/Inertial Signals/'+signal+'_'+subset+'.txt'\n        signals_data.append(\n            _read_csv(filename).values\n        ) \n\n    # Transpose is used to change the dimensionality of the output,\n    # aggregating the signals by combination of sample/timestep.\n    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n    return np.transpose(signals_data, (1, 2, 0))\n\n\"-------------------------CONFUSION MATRIX----------------------------------------------\"\n\n# Utility function to print the confusion matrix\ndef confusion_matrix(Y_true, Y_pred):\n    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n\n    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n\n\n\"----------------------------LOAD Y-------------------------------------------------------\"\n\n\n\ndef load_y(subset):\n    \"\"\"\n    The objective that we are trying to predict is a integer, from 1 to 6,\n    that represents a human activity. We return a binary representation of \n    every sample objective as a 6 bits vector using One Hot Encoding\n    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n    \"\"\"\n    filename = path+subset+'/y_'+subset+'.txt'\n    y = _read_csv(filename)[0]\n\n    return pd.get_dummies(y).values\n\n\n\n\"---------------------------------LOAD DATA---------------------------------------------\"\n\n\ndef load_data():\n    \"\"\"\n    Obtain the dataset from multiple files.\n    Returns: X_train, X_test, y_train, y_test\n    \"\"\"\n    X_train, X_test = load_signals('train'), load_signals('test')\n    y_train, y_test = load_y('train'), load_y('test')\n\n    return X_train, X_test, y_train, y_test\n\n\n\"---------------------------------COUNT CLASSES--------------------------------------------\"\n\n# Utility function to count the number of classes\ndef _count_classes(y):\n    return len(set([tuple(category) for category in y]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing parameters\nepochs = 30\nbatch_size = 16\nn_hidden = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the train and test data\nX_train, X_test, Y_train, Y_test = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timesteps = len(X_train[0])\ninput_dim = len(X_train[0][0])\nn_classes = _count_classes(Y_train)\n\nprint(timesteps)\nprint(input_dim)\nprint(len(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiliazing the sequential model\nmodel = Sequential()\n# Configuring the parameters\nmodel.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n# Adding a dropout layer\nmodel.add(Dropout(0.5))\n# Adding a dense output layer with sigmoid activation\nmodel.add(Dense(n_classes, activation='sigmoid'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model\nmodel.fit(X_train,\n          Y_train,\n          batch_size=batch_size,\n          validation_data=(X_test, Y_test),\n          epochs=epochs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}