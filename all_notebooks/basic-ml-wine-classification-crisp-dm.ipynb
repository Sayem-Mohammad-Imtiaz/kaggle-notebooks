{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Thank you for opening this notebook !\n### In this notebook we will classify the wine quality using the red wine quality dataset. We will do the steps leaned on the CRISP-DM model, which is a standard for industry machine learning projects We will use the following models and compare their performance:\n1. Random Forest Classifier\n2. Support Vector Classifier\n3. K-Neighbors Classifier\n\n### Note that for a higher performance of the models you schould consider using some feature extraction/selection methods which we not used here."},{"metadata":{},"cell_type":"markdown","source":"# 1. Business Understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# See dataset description on kaggle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing requrired packages\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC  \nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport numpy as np \n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading dataset\nwine = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the data type\nprint('Data type: ', type(wine))\n# Plot the first five rows of the dataset\nwine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Check the number of values and datatypes for each column\nwine.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Check the dataset structure\nprint(f'Number of rows: {wine.shape[0]}\\nNumber of columns: {wine.shape[1]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot the statistical values for each column\nwine.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Detect missing values\nwine.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot each feature against quality\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'fixed acidity', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'volatile acidity', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'citric acid', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'residual sugar', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'chlorides', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'free sulfur dioxide', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'total sulfur dioxide', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'sulphates', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'alcohol', data = wine)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Histograms\nwine.hist(bins=20, figsize=(15,15));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot scatter matrix\npd.plotting.scatter_matrix(wine,  figsize=(20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot correlation heatmap with \ncorr = wine.corr()\nplt.figure(figsize=(15,15))\nax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, annot=True, square=False)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45, horizontalalignment='right')\nax.set_ylim(len(corr)-0.5, -0.5)\n\n# fix for mpl bug that cuts off top/bottom of seaborn visualization\nb, t = plt.ylim() # discover the values for bottom and top\nb += 0.5 # Add 0.5 to the bottom\nt -= 0.5 # Subtract 0.5 from the top\nplt.ylim(b, t) # update the ylim(bottom, top) values\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Preprocessing"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Preprocessing Data\nbins = (0, 6.5, 8)  # Define bins\ngroup_names = ['bad', 'good'] # Define names of classes\nwine['quality'] = pd.cut(wine['quality'], bins=bins, labels=group_names) # Bin quality values into the specified bins\n# This function is also useful for going from a continuous variable to a categorical variable\nwine['quality'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"label_quality = LabelEncoder() # Create instance of LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"wine['quality'] = label_quality.fit_transform(wine['quality']) # Transform data: bad --> 0, good --> 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"wine.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Anzahl an Werte Gut & Schlecht\nwine['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(wine['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Values() = von Pandas DataFrame zurÃ¼ck in ein Array\nX = wine.drop('quality', axis=1).values\ny = wine['quality'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"type(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 20% test 80% training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(f'Training data: X: {X_train.shape} y: {y_train.shape}')\nprint(f'Test data: X: {X_test.shape} y: {y_test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying Standard scaling\nfeature_scaler = StandardScaler()\nX_train = feature_scaler.fit_transform(X_train)\nX_test = feature_scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Modeling and Evaluation - Grid Search with Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Random Forest Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"RFC_base_classifier = RandomForestClassifier(n_estimators=100)   # Define base estimator","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"RFC_base_classifier.get_params()  # Show all changeable parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define parameter grid\n\ngrid_param_RFC = {\n    'n_estimators': [100, 120, 140, 160, 180, 200, 230, 260, 300, 500, 800, 1000],\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [None, 3, 4, 5, 7, 9, 10, 15, 20],\n    'bootstrap': [True, False]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Grid Search Instanz definieren (cv=5)\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_search_RFC = GridSearchCV(estimator=RFC_base_classifier,\n                           param_grid=grid_param_RFC,\n                           scoring='accuracy',\n                           cv=5,                     # CV=5 --> 5-fold cross-validation\n                           n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_RFC.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Show best parameter outcome\n\nbest_parameters_RFC = grid_search_RFC.best_params_\nprint(f'Best parameters: {best_parameters_RFC}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Mean cross-validation score of best model\n\nbest_result_RFC = grid_search_RFC.best_score_\nprint(f'Mean cross-validation score of best model: {best_result_RFC}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2. Support Vector Machine"},{"metadata":{"trusted":false},"cell_type":"code","source":"SVC_base_classifier = SVC()   # Define base estimator","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"SVC_base_classifier.get_params()  # Show all changeable parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Due to the fact that the calculation and therefore the grid search with SVM is computationally very\n# expensive, we get ourselves a first look at good parameter values with help of the RandomizedSearch\n# Instead of specifiing discrete values for the parameters 'C', 'gamma' and 'degree', we have to specify a \n# distribution of values. The aim of this process is to find the best kernel for the SVM and to get a first look\n# of a good parameter values for the other parameters. Therefore you can run the randomized_search_SVC.fit()\n# command multiple times and observe the output of the best parameters.\n\ndist_param_SVC = {\n    'C': np.arange(0.1, 10, 0.2),\n    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n    'gamma': np.arange(0.01, 1, 0.01),\n    'degree': np.arange(3, 10, 1)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nrandomized_search_SVC = RandomizedSearchCV(estimator=SVC_base_classifier,\n                           param_distributions=dist_param_SVC,\n                           scoring='accuracy',\n                           cv=5,\n                           n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"randomized_search_SVC.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Show best parameter outcome\n\nbest_parameters_SVC = randomized_search_SVC.best_params_\nprint(f'Best parameters: {best_parameters_SVC}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Mean cross-validation score\n\nbest_result_SVC = randomized_search_SVC.best_score_\nprint(f'Mean cross-validation score of best model: {best_result_SVC}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Now we want to get the exact best parameter values of the model with the normal GridSearch\n# With RandomizedSearch we have seen that the best kernel is the rbf-kernel. With this knowledge we can now compute\n# the other parameter values much faster, because we do not have to calculate every kernel.\n# For the other parameters you have to test a few intervals to find the best value.\n\ngrid_param_SVC = {\n    'C': [2, 2.5, 3, 3.5, 4, 4.5, 5, 6, 6.5, 7],\n    'kernel': ['rbf'],\n    'gamma': ['scale', 'auto', 0.2, 0.5, 0.6, 0.7, 0.8],\n    'degree': [4, 5, 6, 7, 8, 9]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_SVC = GridSearchCV(estimator=SVC_base_classifier,\n                           param_grid=grid_param_SVC,\n                           scoring='accuracy',\n                           cv=5,\n                           n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_SVC.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Show best parameter outcome\n\nbest_parameters_SVC = grid_search_SVC.best_params_\nprint(f'Best parameters: {best_parameters_SVC}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Mean cross-validation score of best model\n# Now we found the best parameter values for the SVC-model\n\nbest_result_SVC = grid_search_SVC.best_score_\nprint(f'Mean cross-validation score of best model: {best_result_SVC}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3. K-Nearest Neighbors"},{"metadata":{"trusted":false},"cell_type":"code","source":"knn_base_classifier = KNeighborsClassifier(n_neighbors=5) # Define base estimator","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"knn_base_classifier.get_params() # Show all changeable parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define parameter grid\n\ngrid_param_knn = {\n    'n_neighbors': [3, 5, 7, 9, 11, 13],\n    'weights': ['uniform', 'distance'],\n    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_knn = GridSearchCV(estimator=knn_base_classifier,\n                           param_grid=grid_param_knn,\n                           scoring='accuracy',\n                           cv=5,\n                           n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_search_knn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Show best parameter outcome\n\nbest_parameters_knn = grid_search_knn.best_params_\nprint(f'Best parameters: {best_parameters_knn}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Mean cross-validation score of best model\n\nbest_result_knn = grid_search_knn.best_score_\nprint(f'Mean cross-validation score of best model: {best_result_knn}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Evaluation of the optimized models on test data"},{"metadata":{},"cell_type":"markdown","source":"## 5.1. Random Forest Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Initialize RFC with the calculated best parameters\n# Note that a max_depth value of None can easily lead to overfitting\n\nRFC = RandomForestClassifier(n_estimators=200, max_depth=None, criterion='gini', bootstrap=True)\nRFC.fit(X_train, y_train)\npred_RFC = RFC.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Performance of model\nprint(classification_report(y_test, pred_RFC))\nconfmat_RFC = confusion_matrix(y_test, pred_RFC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot confusion matrix\n\nfig, ax = plt.subplots(figsize=(2.5, 2.5))\nax.matshow(confmat_RFC, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(confmat_RFC.shape[0]):\n    for j in range(confmat_RFC.shape[1]):\n        ax.text(x=j, y=i, \n               s=confmat_RFC[i, j],\n               va='center', ha='center')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2. Support Vector Machine"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Initialize SVC with the calculated best parameters\n\nSVC_clf = SVC(kernel='rbf', C=2, gamma=0.6, degree=4)\nSVC_clf.fit(X_train, y_train)\npred_SVC = SVC_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Performance of model\nprint(classification_report(y_test, pred_SVC))\nconfmat_SVC = confusion_matrix(y_test, pred_SVC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot confusion matrix\nfig, ax = plt.subplots(figsize=(2.5, 2.5))\nax.matshow(confmat_SVC, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(confmat_SVC.shape[0]):\n    for j in range(confmat_SVC.shape[1]):\n        ax.text(x=j, y=i, \n               s=confmat_SVC[i, j],\n               va='center', ha='center')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.3. K-Nearest Neighbors"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Initialize KNN with the calculated best parameters\n\nknn_clf = KNeighborsClassifier(n_neighbors=5, algorithm='auto', weights='distance')\nknn_clf.fit(X_train, y_train)\npred_knn = knn_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Performance of model\nprint(classification_report(y_test, pred_knn))\nconfmat_knn = confusion_matrix(y_test, pred_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Plot confusion matrix\nfig, ax = plt.subplots(figsize=(2.5, 2.5))\nax.matshow(confmat_knn, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(confmat_knn.shape[0]):\n    for j in range(confmat_knn.shape[1]):\n        ax.text(x=j, y=i, \n               s=confmat_knn[i, j],\n               va='center', ha='center')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Deployment"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Now we want to use the model on new, unseen data. Therefore we create a new, randomly specified data point\n# You can change the values of pH and alcohol to see different outcomes\n\npH = 3\nalcohol = 12\nXnew = [[7.8, 0.22, 0.99, 2.0, 0.01, 9.0, 18.0, 0.9968, pH, 1.8, alcohol]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Xnew = feature_scaler.transform(Xnew) #Use same transformer and model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ynew_RFC = RFC.predict(Xnew)\nynew_SVC = SVC_clf.predict(Xnew)\nynew_knn = knn_clf.predict(Xnew)\n\nif ynew_RFC==0:\n    label_RFC = 'bad'\nelse:\n    label_RFC = 'good'\n    \nif ynew_SVC==0:\n    label_SVC = 'bad'\nelse:\n    label_SVC = 'good'\n    \nif ynew_knn==0:\n    label_knn = 'bad'\nelse:\n    label_knn = 'good'\n\nprint('Result of classification: ')\nprint(f'Random Forest Classifier: Label = {ynew_RFC} --> {label_RFC} wine')\nprint(f'Support Vector Classifier: Label = {ynew_SVC} --> {label_SVC} wine')\nprint(f'K-Nearest Neighbors Classifier: Label = {ynew_knn} --> {label_knn} wine')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}